% This file was created with JabRef 2.9b.
% Encoding: ISO8859_1

@STRING{accepted = {Aceito para publicaçao}}

@STRING{Advisor = {Orientador}}

@STRING{Australia = {Austrália}}

@STRING{Austria = {Áustria}}

@STRING{Brazil = {Brasil}}

@STRING{Canada = {Canadá}}

@STRING{Finland = {Finlândia}}

@STRING{Germany = {Alemanha}}

@STRING{Greece = {Grécia}}

@STRING{Italy = {Itália}}

@STRING{Netherlands = {Países Baixos}}

@STRING{project = {Projeto de Pesquisa}}

@STRING{software = {Programa de computador}}

@STRING{standard = {Padrão}}

@STRING{Standard = {}}

@STRING{talk = {Palestra}}

@STRING{UAE = {United Arab Emirates}}

@STRING{UK = {Reino Unido}}

@STRING{usa = {United States}}

@STRING{USA = {EUA}}

@STRING{Webpage = {Página Web}}

@INPROCEEDINGS{Aaltonen-etal:2010,
  author = {Aaltonen, Kalle and Ihantola, Petri and Seppälä, Otto},
  title = {Mutation analysis vs. code coverage in automated assessment of students' testing skills},
  crossref = {proceedings:splash:2010},
  pages = {153--160},
  doi = {10.1145/1869542.1869567},
  abstract = {Learning to program should include learning about proper software testing. Some automatic assessment systems, e.g. Web-CAT, allow assessing student-generated test suites using coverage metrics. While this encourages testing, we have observed that sometimes students can get rewarded from high coverage although their tests are of poor quality. Exploring alternative methods of assessment, we have tested mutation analysis to evaluate students' solutions. Initial results from applying mutation analysis to real course submissions indicate that mutation analysis could be used to fix some problems of code coverage in the assessment. Combining both metrics is likely to give more accurate feedback.},
  keywords = {automated assessment, mutation analysis, mutation testing, programming assignments, test coverage}
}

@ARTICLE{Stal,
  author = {Stal Aanderaa and Patrick C. Fischer},
  title = {The Solvability of the Halting Problem for 2-State Post Machines},
  crossref = {journal:acm:jacm},
  volume = {14},
  number = {4},
  year = {1967},
  pages = {677--682},
  doi = {10.1145/321420.321426}
}

@INPROCEEDINGS{AarreniemiJokipelto-Tuominen:2004,
  author = {Aarreniemi-Jokipelto, Paivi and Tuominen, Juha},
  title = {Experiences with an Interactive Learning Environment in Digital TV},
  crossref = {proceedings:icalt:2004},
  pages = {296--300},
  doi = {10.1109/ICALT.2004.1357423},
  abstract = {In the Motive project, the Industrial IT Laboratory (INIT) of Helsinki University of Technology (HUT) is studying the use of digital TV as a learning environment for University courses. Funded by the European Social Fund, the project has used itsý last years to focus on user-interaction in the digital TV and flexible content production. Practical experience of the learning environment in use has been with the course Local Demands for Global Enterprising where HUT students have had a chance to study a module in an experimental digital TV environment in autumn 2002. That experiment continued with a new version of the course, which started on January 12th, 2004 in digital TV cable networks.},
  address = {Joensuu, Finlândia},
  booktitle = {IEEE International Conference on Advanced Learning Technologies},
  isbn = {0-7695-2181-9},
  lang = {en},
  month = aug,
  publisher = {IEEE Computer Society},
  year = {2004}
}

@ARTICLE{Aberdour:2007,
  author = {Mark Aberdour},
  title = {Achieving Quality in Open Source Software},
  crossref = {journal:ieee:software},
  volume = {24},
  number = {1},
  month = jan,
  year = {2007},
  pages = {58--64},
  doi = {10.1109/MS.2007.2},
  abstract = {The open source software community has published a substantial body of research on OSS quality. Focusing on this peer-reviewed body of work lets us draw conclusions from empirical data rather than rely on the large volume of evangelical opinion that has historically dominated this field. This body of published research has become much more critical and objective in its efforts to understand OSS development, and a consensus has emerged on the key components of high-quality OSS delivery. This article reviews this body of research anddraws out lessons learned, investigating how the approaches used to deliver high-quality OSS differ from, and can be incorporated into, closed-source software development.},
  owner = {magsilva},
  tags = {open source software, community},
  timestamp = {2013.10.11}
}

@ARTICLE{Abernethy-etal:2007,
  author = {Abernethy, Ken and Piegari, George and Reichgelt, Han},
  title = {Teaching Project Management: An Experiential Approach},
  crossref = {journal:ccsc:jcsc},
  volume = {22},
  number = {3},
  month = jan,
  year = {2007},
  pages = {198--205},
  abstract = {Project management is being increasingly recognized as an important area of study for computing programs. For example, the most recent Standish Group CHAOS Report concludes that an increased use of disciplined project management may explain an observed increase in the success rate of information technology projects. In addition, Information Technology (IT) has emerged as a new academic discipline, and project management is one of five core technology areas cited in ACM curriculum guidelines for the discipline. Given these factors, it is likely that many computing programs will consider making available a project management course within their curricula. In this paper, it is argued that an experiential approach may be most effective in such courses. A specific experiential approach to the teaching of project management is then described, and some preliminary assessment of the effectiveness of a course using this approach is given.},
  owner = {magsilva},
  timestamp = {2014.09.13}
}

@ARTICLE{Aboukhalil:2011,
  author = {Aboukhalil, Robert},
  title = {Of undergraduates and research},
  crossref = {journal:acm:xrds},
  volume = {18},
  number = {2},
  month = dec,
  year = {2011},
  pages = {6--6},
  doi = {10.1145/2043236.2043241}
}

@INPROCEEDINGS{Abrahamsson-etal:2003,
  author = {Abrahamsson, Pekka and Warsta, Juhani and Siponen, Mikko T. and Ronkainen, Jussi},
  title = {New directions on agile methods: a comparative analysis},
  crossref = {proceedings:icse:2003},
  pages = {244--254},
  doi = {10.1109/ICSE.2003.1201204},
  abstract = {Agile software development methods have caught the attention of software engineers and researchers worldwide. Scientific research is yet scarce. This paper reports results from a study, which aims to organize, analyze and make sense out of the dispersed field of agile software development methods. The comparative analysis is performed using the method's life-cycle coverage, project management support, type of practical guidance, fitness-for-use and empirical evidence as the analytical lenses. The results show that agile software development methods, without rationalization, cover certain/different phases of the software development life-cycle and most of the them do not offer adequate support for project management. Yet, many methods still attempt to strive for universal solutions (as opposed to situation appropriate) and the empirical evidence is still very limited Based on the results, new directions are suggested In principal it is suggested to place emphasis on methodological quality -- not method quantity.}
}

@INPROCEEDINGS{Accetta-etal:1986,
  author = {Mike Accetta and Robert Baron and William Bolosky and David Golub and Richard Rashid and Avadis Tevanian and Michael Young},
  title = {{Mach}: A New Kernel Foundation For {UNIX} Development},
  crossref = {proceedings:usenix:1986},
  pages = {93--112},
  abstract = {Mach is a multiprocessor operating system kernel and environment under development at Carnegie Mellon University. Mach provides a new foundation for UNIX development that spans networks of uniprocessors and multiprocessors. This paper describes Mach and the motivations that led to its design. Also described are some of the details of its implementation and current status.}
}

@ARTICLE{Achtenhagen:2001,
  author = {Achtenhagen, Frank},
  title = {Criteria for the development of complex teaching-learning environments},
  crossref = {journal:springer:is},
  volume = {29},
  number = {4},
  month = jul,
  year = {2001},
  pages = {361--380},
  doi = {10.1023/A:1011956117397},
  abstract = {This article tries to bring together recenttheory and practice in instructional design, onthe one side, and curricular as well asdidactic research results on the other. Thefocus is on processes that are necessary to themodeling of 'reality', with regard to thecorresponding scientific description of goalsand content-units and to the teaching andlearning processes. The steps in theconstruction and implementation processes arevisualized and discussed with reference to acomplex teaching-learning environment.},
  keywords = {commercial education, complex teaching-learning environment, didactics, exploration task, instructional design, model theory, virtual enterprise},
  keyword = {Humanities, Social Sciences and Law}
}

@ARTICLE{Ackerman-etal:2013,
  author = {Ackerman, Mark S. and Dachtera, Juri and Pipek, Volkmar and Wulf, Volker},
  title = {Sharing Knowledge and Expertise: The CSCW View of Knowledge Management},
  crossref = {journal:springer:cscw},
  volume = {22},
  number = {4--6},
  month = aug,
  year = {2013},
  pages = {531--573},
  doi = {10.1007/s10606-013-9192-8},
  abstract = {Knowledge Management (KM) is a diffuse and controversial term, which has been used by a large number of research disciplines. CSCW, over the last 20 years, has taken a critical stance towards most of these approaches, and instead, CSCW shifted the focus towards a practice-based perspective. This paper surveys CSCW researchers' viewpoints on what has become called `knowledge sharing' and `expertise sharing'. These are based in an understanding of the social contexts of knowledge work and practices, as well as in an emphasis on communication among knowledgeable humans. The paper provides a summary and overview of the two strands of knowledge and expertise sharing in CSCW, which, from an analytical standpoint, roughly represent `generations' of research: an `object-centric' and a `people-centric' view. We also survey the challenges and opportunities ahead.},
  keywords = {CSCW, collective intelligence, collective memory, expert finder, expertise finding, expertise location, expertise sharing, knowledge management, knowledge sharing, organizational memory, sociotechnical},
  owner = {magsilva},
  timestamp = {2014.05.19}
}

@INPROCEEDINGS{Adams:2009,
  author = {Adams, Joel},
  title = {Test-driven data structures: revitalizing {CS2}},
  crossref = {proceedings:sigcse:2009},
  pages = {143--147},
  doi = {10.1145/1508865.1508920},
  abstract = {Software testing is an increasingly important topic in engineering reliable software systems, and test-driven development is an increasingly popular methodology for building reliable systems. However, most software engineering instructors' courses are already very full, so that increasing coverage of testing in those courses can only occur at the expense of another topic. In this paper, we argue that testing should be introduced early in the CS curriculum, that the Data Structures (CS2) course is an especially natural place to emphasize unit testing and test-driven development, and that doing is a way to revitalize the CS2 course.},
  keywords = {agile methods, cs2, data structures, pedagogy, test-driven development, unit testing}
}

@INPROCEEDINGS{Afonso:2013,
  author = {Afonso, Adriano},
  title = {The {LibreOffice} {Portuguese} Community: A Researcher's View},
  crossref = {proceedings:osdoc:2013},
  pages = {35--37},
  doi = {10.1145/2503848.2503855},
  abstract = {The success of Open Source Software (OSS), along with the importance that their communities have created around their project's and products (Ubuntu, LibreOffice, Android and CyanogenMod, etc) has recently attracted the attention of researchers and commercial companies. While the first ones are learning lessons from the success of OSS and applying some of them, the second ones are also acquiring knowledge. They are now more open minded and import the apprenticeship to develop their systems, implement it to their structure and even help to make them compatible with their products (like HTC, Motorola, Samsung and Sony Ericsson do with CyanogenMod). These OSS communities are normally called communities of practice and they are a group of people who are informally bounded by their common interest and practice in a specific domain. The LibreOffice Portuguese Community has been in great growth and trying to answer the "The Document Foundation" (TDF) requests. The "real time" translations of the package and recently the development of the IT and LibreOffice Open Manual are examples. The author feels that it is time to make a short scientific analysis, through a reading of the creative processes and production, based on international scientific developments and conclusions. The objective of this paper is to make the first step of a study of how LibreOffice is contributing to the sustainable development in Portugal.},
  keywords = {LibreOffice, LibreOffice Portuguese community, OSS community, open source},
  owner = {magsilva},
  timestamp = {2014.05.22}
}

@ARTICLE{Aggarwal-Subbian:2014,
  author = {Aggarwal, Charu and Subbian, Karthik},
  title = {Evolutionary Network Analysis: A Survey},
  crossref = {journal:acm:csur},
  volume = {47},
  number = {1},
  month = may,
  year = {2014},
  pages = {10:1--10:36},
  doi = {10.1145/2601412},
  abstract = {Evolutionary network analysis has found an increasing interest in the literature because of the importance of different kinds of dynamic social networks, email networks, biological networks, and social streams. When a network evolves, the results of data mining algorithms such as community detection need to be correspondingly updated. Furthermore, the specific kinds of changes to the structure of the network, such as the impact on community structure or the impact on network structural parameters, such as node degrees, also needs to be analyzed. Some dynamic networks have a much faster rate of edge arrival and are referred to as network streams or graph streams. The analysis of such networks is especially challenging, because it needs to be performed with an online approach, under the one-pass constraint of data streams. The incorporation of content can add further complexity to the evolution analysis process. This survey provides an overview of the vast literature on graph evolution analysis and the numerous applications that arise in different contexts.},
  keywords = {Network analysis, dynamic graphs, temporal graphs}
}

@ARTICLE{Agrawal-etal:2012,
  author = {Agrawal, Rakesh and Gollapudi, Sreenivas and Kannan, Anitha and Kenthapadi, Krishnaram},
  title = {Data mining for improving textbooks},
  crossref = {journal:acm:sigkdd},
  volume = {13},
  number = {2},
  month = may,
  year = {2012},
  pages = {7--19},
  doi = {10.1145/2207243.2207246},
  abstract = {We present our early explorations into developing a data mining based approach for enhancing the quality of textbooks. We describe a diagnostic tool to algorithmically identify deficient sections in textbooks. We also discuss techniques for algorithmically augmenting textbook sections with links to selective content mined from the Web. Our evaluation, employing widely-used textbooks from India, indicates that developing technological approaches to help improve textbooks holds promise.}
}

@ARTICLE{Ahonen-Savolainen:2010,
  author = {Jarmo J. Ahonen and Paula Savolainen},
  title = {Software engineering projects may fail before they are started: Post-mortem analysis of five cancelled projects },
  crossref = {journal:elsevier:jss},
  volume = {83},
  number = {11},
  month = nov,
  year = {2010},
  pages = {2175--2187},
  doi = {10.1016/j.jss.2010.06.023},
  abstract = {Context Software project cancellations are often caused by mistakes made during the project, and such cancellations make a strong economic impact. We analyzed five cancelled software engineering projects. One case was an internal product development project of a company that sells products to its customers. The other four cases were different software engineering projects, and outcomes of these projects were planned to be delivered to external customers. Objective This study reports a post-mortem analysis of five software engineering projects with the aim of providing more knowledge about the reasons for cancellation decisions and the causes behind those reasons. Methods The research method is case study. A method for a document-based post-mortem analysis was developed and post-mortem analysis was performed. All project documentation was available for analysis. Results The reasons for the cancellation decisions were well-known ones. In four cases of five, the outcome of the project was to be delivered to an external customer, but in these cases the causes of the cancellation reasons were not found from the normal project documentation. In these cases the cause of the cancellation originated in a phase before the start of the project and therefore the project was doomed before it was started. Conclusion It is reasonable to suggest that a remarkable portion of project cancellations are due to mistakes made before the project is started in the case of contract-based software engineering projects. },
  keywords = {Software engineering, Project cancellation, Project failure, Post-mortem analysis, Customer, Supplier},
  owner = {magsilva},
  timestamp = {2014.09.13}
}

@INPROCEEDINGS{Ahoniemi-Karavirta:2009,
  author = {Ahoniemi, Tuukka and Karavirta, Ville},
  title = {Analyzing the use of a rubric-based grading tool},
  crossref = {proceedings:itcse:2009},
  pages = {333--337},
  doi = {10.1145/1562877.1562977},
  abstract = {Over the years, a lot of research has focused on how to assess programming courses. For programming courses, semiautomatic assessment combining automatic and manual feedback has been shown to be a good solution. In this paper, we will focus on the manual assessment part and analyze the use of a rubrics-based grading tool on larger courses with multiple graders. Our results show that the use of such tools can support objective grading with high-quality feedback with reasonable time usage. Finally, we will give some pointers for teachers intending to adopt such tools on their courses.},
  keywords = {assessment, grading, mass courses, programming, rubrics},
  timestamp = {2013-08-23}
}

@INBOOK{aiken:1990,
  chapter = {Hypermedia-based Requirements Engineering},
  title = {Advanced Technology for Command and Control Systems Engineering},
  publisher = {AFCEA International Press},
  year = {1990},
  author = {Peter Aiken},
  booktitle = {Advanced Technology for Command and Control Systems Engineering},
  crossref = {andriole:1990},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@ARTICLE{Ainsworth-etal:2008b,
  author = {Ainsworth, A. Barbara and Sheard, Judithe and Avram, Chris},
  title = {The {Monash} museum of computing history: part 2},
  crossref = {journal:acm:inroads},
  volume = {40},
  number = {4},
  month = nov,
  year = {2008},
  pages = {31--34},
  doi = {10.1145/1473195.1473214},
  abstract = {Introduction to the Monash Museum of Computing History, Monash University, Victoria, Australia. Part I of this series described the development of the Museum. This article gives a description of the current holdings of the Museum and the permanent display.},
  keywords = {Ferranti Sirius, Monash University, computer history, computer museum}
}

@ARTICLE{AlarioHoyos-etal:2013,
  author = {Carlos Alario-Hoyos and Miguel L. Bote-Lorenzo and Eduardo Gómez-Sánchez and Juan I. Asensio-Pérez and Guillermo Vega-Gorgojo and Adolfo Ruiz-Calleja},
  title = {{GLUE!}: An architecture for the integration of external tools in Virtual Learning Environments},
  crossref = {journal:elsevier:ce},
  volume = {60},
  number = {1},
  month = jan,
  year = {2013},
  pages = {122--137},
  doi = {10.1016/j.compedu.2012.08.010},
  abstract = {The integration of external tools in Virtual Learning Environments (VLEs) aims at enriching the learning activities that educational practitioners may design and enact. This paper presents GLUE!, an architecture that enables the lightweight integration of multiple existing external tools in multiple existing VLEs. GLUE! fosters this integration by imposing few restrictions on VLE and tool providers, as well as by requiring an attainable effort from developers, unlike other integration works. Besides, GLUE! facilitates the instantiation and enactment of collaborative activities within VLEs, leveraging the VLEs distinctive features for the management of users and groups. GLUE! has been evaluated using three authentic collaborative learning situations, instantiated and enacted by real practitioners at university level. The results of this evaluation show that GLUE! reduces the burden of educators when instantiating collaborative activities that require the integration of external tools, while facilitates students the realization of these activities in collaboration. Interestingly, the development effort required by the integration software is similar to that in other lightweight generic approaches that offer a lower degree of functionality.},
  keywords = {Cooperative/collaborative learning; Architectures for educational technology system; Distributed learning environments}
}

@INPROCEEDINGS{Alencar-etal:2012,
  author = {Alencar, Aretha B. and Börner, Katy and Paulovich, Fernando V. and Oliveira, Maria Cristina Ferreira de},
  title = {Time-aware Visualization of Document Collections},
  crossref = {proceedings:sac:2012},
  pages = {997--1004},
  doi = {10.1145/2245276.2245469},
  abstract = {Scientific articles are the major mechanism for researchers to report their results, and a collection of papers on a discipline can reveal a lot about its evolution, such as the emergence of new topics. Nonetheless, given a broad collection of papers it is typically very difficult to grasp important information that could help readers to globally interpret, navigate and then focus on the relevant items for their task. Content-based document maps are visual representations created from evaluating the (dis)similarity amongst the documents, and have been shown to support exploratory tasks in this scenario. Documents are represented by visual markers placed in the 2D space so that documents close share similar content. Albeit the maps allow visually identifying groups of related documents and frontiers between groups, they do not explicitly convey the temporal evolution of a collection. We propose a technique for creating content-based similarity maps of document collections that highlight temporal changes along time. Our solution constructs a sequence of maps from time-stamped sub-sets of the data. It adopts a cumulative backwards strategy to preserve user context across successive time-stamps, i.e., maps do not change drastically from one time stamp to the next, favouring user perception of changes.},
  keywords = {information visualization, multidimensional projections, text and document data, time-varying data},
  owner = {magsilva},
  timestamp = {2014.06.04}
}

@INPROCEEDINGS{Alexandre-etal:2010,
  author = {Rodrigo Silveira Alexandre and Rodrigo Costa Mesquita Santos and Thiago Alencar Gomes and Carlos de Salles Soares Neto},
  title = {Geração de Comandos de Edição na Autoria Textual de Documentos {NCL}},
  crossref = {proceedings:fisl:2010},
  pages = {1-6},
  abstract = {Este artigo apresenta métodos de autoria para o suporte à edição textual de documentos NCL (Nested Context Language) que podem ser aplicados para a geração de comandos de edição em tempo de exibição (ao vivo). NCL é a linguagem declarativa padrão do Sistema Brasileiro de TV Digital (SBTVD). Por meio da proposta deste artigo é possível oferecer mais facilmente a autores de aplicações interativas para TV digital o recurso de edição ao vivo, disponível no middleware Ginga-NCL, tornando suas aplicações passíveis de serem alteradas pela emissora durante a exibição. A proposta deste artigo foi integrada ao NCL Eclipse, ferramenta de autoria textual para NCL.}
}

@INPROCEEDINGS{Alfaro-etal:2014,
  author = {Alfaro, Luca de and Shavlovsky, Michael},
  title = {{CrowdGrader}: A Tool for Crowdsourcing the Evaluation of Homework Assignments},
  crossref = {proceedings:sigcse:2014},
  pages = {415--420},
  doi = {10.1145/2538862.2538900},
  abstract = {CrowdGrader is a system that lets students submit and collaboratively review and grade homework. We describe the techniques and ideas used in CrowdGrader, and report on the experience of using CrowdGrader in disciplines ranging from Computer Science to Economics, Writing, and Technology. In CrowdGrader, students receive an overall crowd-grade that reflects both the quality of their homework, and the quality of their work as reviewers. This creates an incentive for students to provide accurate grades and helpful reviews of other students' work. Instructors can use the crowd-grades as final grades, or fine-tune the grades according to their wishes. Our results on seven classes show that students actively participate in the grading and write reviews that are generally helpful to the submissions' authors. The results also show that grades computed by CrowdGrader are sufficiently precise to be used as the homework component of class grades. Students report that the main benefits in using CrowdGrader are the quality of the reviews they receive, and the ability to learn from reviewing their peers' work. Instructors can leverage peer learning in their classes, and easily handle homework evaluation in large classes.},
  keywords = {crowdsourcing, grading, peer evaluation}
}

@ARTICLE{Ali-etal:2010,
  author = {Muhammad Sarmad Ali and Muhammad Ali Babar and Lianping Chen and Klaas-Jan Stol},
  title = {A systematic review of comparative evidence of aspect-oriented programming},
  crossref = {journal:elsevier:ist},
  volume = {52},
  number = {9},
  year = {2010},
  pages = {871--887},
  doi = {10.1016/j.infsof.2010.05.003},
  abstract = {Context Aspect-oriented programming (AOP) promises to improve many facets of software quality by providing better modularization and separation of concerns, which may have system wide affect. There have been numerous claims in favor and against AOP compared with traditional programming languages such as Objective Oriented and Structured Programming Languages. However, there has been no attempt to systematically review and report the available evidence in the literature to support the claims made in favor or against AOP compared with non-AOP approaches.Objective This research aimed to systematically identify, analyze, and report the evidence published in the literature to support the claims made in favor or against AOP compared with non-AOP approaches.Method We performed a systematic literature review of empirical studies of AOP based development, published in major software engineering journals and conference proceedings.Results Our search strategy identified 3307 papers, of which 22 were identified as reporting empirical studies comparing AOP with non-AOP approaches. Based on the analysis of the data extracted from those 22 papers, our findings show that for performance, code size, modularity, and evolution related characteristics, a majority of the studies reported positive effects, a few studies reported insignificant effects, and no study reported negative effects; however, for cognition and language mechanism, negative effects were reported.Conclusion AOP is likely to have positive effect on performance, code size, modularity, and evolution. However its effect on cognition and language mechanism is less likely to be positive. Care should be taken using AOP outside the context in which it has been validated.},
  keywords = {Evidence-based software engineering},
  lang = {en}
}

@ARTICLE{Ali-etal:2014,
  author = {Nauman Bin Ali and Kai Petersen and Claes Wohlin},
  title = {A systematic literature review on the industrial use of software process simulation },
  crossref = {journal:elsevier:jss},
  volume = {97},
  month = nov,
  year = {2014},
  pages = {65--85},
  doi = {10.1016/j.jss.2014.06.059},
  abstract = {AbstractContext Software process simulation modelling (SPSM) captures the dynamic behaviour and uncertainty in the software process. Existing literature has conflicting claims about its practical usefulness: SPSM is useful and has an industrial impact; SPSM is useful and has no industrial impact yet; SPSM is not useful and has little potential for industry. Objective To assess the conflicting standpoints on the usefulness of SPSM. Method A systematic literature review was performed to identify, assess and aggregate empirical evidence on the usefulness of SPSM. Results In the primary studies, to date, the persistent trend is that of proof-of-concept applications of software process simulation for various purposes (e.g. estimation, training, process improvement, etc.). They score poorly on the stated quality criteria. Also only a few studies report some initial evaluation of the simulation models for the intended purposes. Conclusion There is a lack of conclusive evidence to substantiate the claimed usefulness of SPSM for any of the intended purposes. A few studies that report the cost of applying simulation do not support the claim that it is an inexpensive method. Furthermore, there is a paramount need for improvement in conducting and reporting simulation studies with an emphasis on evaluation against the intended purpose.},
  keywords = {Software process simulation, Systematic literature review, Evidence based software engineering},
  owner = {magsilva},
  timestamp = {2014.09.25}
}

@ARTICLE{AlKhanjari-etal:2010,
  author = {Al-Khanjari, Z. A. and Fiaidhi, J. A. and Al-Hinai, R. A. and Kutti, N. S.},
  title = {{PlagDetect}: a Java programming plagiarism detection tool},
  crossref = {journal:acm:inroads},
  volume = {1},
  number = {4},
  month = dec,
  year = {2010},
  pages = {66--71},
  doi = {10.1145/1869746.1869766},
  abstract = {Practical computing courses that involve significant amount of programming assessment tasks suffer from e-Plagiarism. A pragmatic solution for this problem could be by discouraging plagiarism particularly among the beginners in programming. One way to address this is to automate the detection of plagiarized work during the marking phase. Our research in this context involves at first examining various metrics used in plagiarism detection in program codes and secondly selecting an appropriate statistical measure using attribute counting metrics (ATMs) for detecting plagiarism in Java programming assignments. The goal of this investigation is to study the effectiveness of ATMs for detecting plagiarism among assignment submissions of introductory programming courses.},
  keywords = {ATMs, correlation coefficient ratio, equivalent ration, structured metrics},
  lang = {en}
}

@INPROCEEDINGS{Alphonce-Ventura:2002,
  author = {Alphonce, Carl and Ventura, Phil},
  title = {Object orientation in {CS1-CS2} by design},
  crossref = {proceedings:itcse:2002},
  pages = {70--74},
  doi = {10.1145/544414.544437},
  abstract = {This paper argues for a design driven approach to an object-oriented CS1-CS2 sequence in which object-orientation is thematic. Our approach integrates several components: (i) a strong object-oriented approach, (ii) design using UML, (iii) design patterns to manage complexity, and (iv) complex examples and projects to motivate the use of object-orientation and to motivate students by solving non-trivial problems. While this is a "programming-first" approach to CS1-CS2, it addresses several disadvantages of programming-first approaches noted in CC2001 [7]. The approach focuses on design rather than syntax, so students do not lose sight of the forest for the trees. We use (relatively speaking) large and complex examples, especially in the CS2 course, which allows us to address in a meaningful way issues of programming in the large. Because the approach is design driven and heavily object oriented, the course is not biased against novices in favor of students with prior programming experience, since CS1 students with prior programming experience typically have no design experience and only procedural programming experience.},
  keywords = {CS1, CS2, UML, design, object-orientation, pedagogical approaches}
}

@INPROCEEDINGS{AlQutaish:2009,
  author = {Al-Qutaish, R. E.},
  title = {An Investigation of the Weaknesses of the {ISO 9126} International Standard},
  crossref = {journal:iccee:2009},
  pages = {275--279},
  doi = {10.1109/ICCEE.2009.83},
  abstract = {Since 2005 and up-to-date, the International Organization for Standardization (ISO) is ongoing to update the current ISO 9126 international standard on software product quality measurement. However, this current standard will be replaced by the quality measurement division (ISO 25020, ISO 25021, ISO 25022, ISO 25023, and ISO 25024) of the upcoming ISO 25000 series of international standards on software quality requirements and evaluation (SQuaRE). This paper presents an investigation of the weaknesses of the current ISO 9126 by collecting various viewpoints of interested researchers and practitioners. Furthermore, this investigation will tackle the potential solutions of such weaknesses to be taken into account when preparing the new quality measurement division of the ISO 25000 series of international standards.},
  keywords = {ISO 25000 , ISO 9126 , software product , software quality}
}

@INPROCEEDINGS{Alshahwan-Harman:2014,
  author = {Alshahwan, Nadia and Harman, Mark},
  title = {Coverage and Fault Detection of the Output-uniqueness Test Selection Criteria},
  crossref = {proceedings:issta:2014},
  pages = {181--192},
  doi = {10.1145/2610384.2610413},
  abstract = {This paper studies the whitebox coverage and fault detection achieved by Output Uniqueness, a newly proposed blackbox test criterion, using 6 web applications. We find that output uniqueness exhibits average correlation coefficients of 0.85, 0.83 and 0.97 with statement, branch and path coverage respectively. More interestingly, output uniqueness finds 92% of the real faults found by branch coverage (and a further 47% that remained undetected by such whitebox techniques). These results suggest that output uniqueness may provide a useful surrogate when whitebox techniques are inapplicable and an effective complement where they are.},
  keywords = {Blackbox testing, Software Testing, Web applications, Whitebox testing},
  owner = {magsilva},
  timestamp = {2014.07.21}
}

@ARTICLE{Alshayeb:2013,
  author = {Mohammad Alshayeb},
  title = {On the relationship of class stability and maintainability},
  crossref = {journal:iet:software},
  volume = {7},
  number = {6},
  month = dec,
  year = {2013},
  pages = {339--347},
  doi = {10.1049/iet-sen.2013.0030},
  abstract = {Maintainability is an essential software quality attribute as software maintenance is a costly process. ISO 9126 characterised maintainability with five sub-characteristics, one of which is stability. Unstable software may lead to high maintenance cost and effort. Classes in object-oriented systems form the basic elements of the software architecture; hence, stable classes may contribute to reducing the software maintenance cost and effort. In this study, the author conducts an empirical study to evaluate the relationship between class stability and maintainability. The author correlates class stability with maintainability effort measured by the number of hours spent on maintenance activities and by the line of code changes. Results show that classes with higher values of stability measured by the class stability metric (CSM) are associated with a lower value of perfective maintenance effort measured by hours. CSM also correlated with all types of maintenance (corrective, adaptive and perfective) if measured for the cumulatively combined system classes in all iterations rather than per iteration. The author also found that none of the stability metrics show a relationship with maintainability when measured by number of line of code changes.}
}

@ARTICLE{Alshayeb-etal:2011,
  author = {Alshayeb, M. and Naji, M. and Elish, M.O. and Al-Ghamdi, J.},
  title = {Towards measuring object-oriented class stability},
  crossref = {journal:iet:software},
  volume = {5},
  number = {4},
  month = aug,
  year = {2011},
  pages = {415--424},
  doi = {10.1049/iet-sen.2010.0050},
  abstract = {Stable software, the capability of software to evolve while preserving its design, is an important software feature that software engineers strive for. Stable software tends to reduce maintenance cost and effort. Object-oriented (OO) classes form the basic components of the software systems; hence, stable OO classes may contribute to reducing the maintenance and effort cost. The authors identified factors that affect class stability and then used these factors to propose new class stability metric (CSM). Also, the authors theoretically and empirically validated CSM. The results show that the proposed CSM is negatively correlated with the maintenance effort.}
}

@INPROCEEDINGS{Alvarado-Dodds:2010,
  author = {Alvarado, Christine and Dodds, Zachary},
  title = {Women in {CS}: An Evaluation of Three Promising Practices},
  crossref = {proceedings:sigcse:2010},
  pages = {57--61},
  doi = {10.1145/1734263.1734281},
  abstract = {Historically, Harvey Mudd College (HMC) has had very little success attracting women to the study of computer science: women have chosen CS less than any other field of study. In 2006 HMC began three practices in order to increase the number of women studying and majoring in CS; these practices have now been in place for 3 years. With this paper we describe these practices and present a thorough evaluation of the quantitative and qualitative differences that have accompanied them. In sum, these efforts have rebalanced our department by significantly increasing women's participation in our computer science program.},
  keywords = {cs1, gender, promising practices, women in cs}
}

@INPROCEEDINGS{Alves-Benitti:2006,
  author = {Adriana G. Alves and Fabiane B. V. Benitti},
  title = {Processo de Desenvolvimento Integrando Disciplinas de Engenharia de Software},
  crossref = {proceedings:wei:2006},
  pages = {206--215},
  address = {Campo Grande, MS},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{Alves-etal:2006,
  author = {Luiz Gustavo Pacola Alves and Raoni Kulesza and Fábio Santos da Silva and Paulyne Jucá and Graça Bressan},
  title = {Análise Comparativa de Metadados em {TV} Digital},
  crossref = {proceedings:wtvd:2006},
  pages = {1--12},
  abstract = {Este artigo tem por objetivo realizar uma análise comparativa entre os padrões de metadados emergentes da TV Digital (MPEG-7, MPEG-21 e TV-Anytime) segundo alguns parâmetros de comparação. O artigo aborda a necessidade e a importância do uso de metadados na descrição de serviços e conteúdos multimídia no contexto da TV Digital. É apresentada também uma visão geral de alguns padrões de metadados, além de discutir como eles se complementam para compor uma solução viável.},
  abstract-en = {This paper has for purpose to realize a comparative analysis between Digital TV emerging metadata standards (MPEG-7, MPEG-21 and TV-Anytime) according to some parameters of comparison. The paper approaches the necessity and the importance of the metadata use in the services description and multimedia contents in the context of the Digital TV. An overview of some metadata standards is also presented, besides arguing as they complement themselves to compose a viable solution.}
}

@INPROCEEDINGS{Alves-etal:2008,
  author = {Alves, Luiz Gustavo Pacola and da Silva, Fábio Santos and Bressan, Graça},
  title = {{CollaboraTVware}: uma proposta de infra-estrutura ciente de contexto para suporte a participa\çao colaborativa no cenário da {TV} digital interativa},
  crossref = {proceedings:webmedia:2008},
  pages = {218--225},
  doi = {10.1145/1666091.1666128},
  abstract = {The growing of the number and diversity of programs available to users, as well as the interactive services provided, resulting from the emergence of the Interactive Digital TV increases the difficulty of selecting relevant content. In this scenario, it is important the user participation in a collaborative. Thus, this paper presents a software infrastructure in an Interactive Digital Television environment - entitled CollaboraTVware - to guide, in a transparent way, users in the choice of programs and interactive services through the collaborative participation of other users with similar profile and context. The classification task, from the theory of data mining, is the approach adopted in the infrastructure design. To demonstrate the functionalities in a use scenario was developed an application (collaborative EPG) as a case study which uses the CollaboraTVware.},
  keywords = {classification task, context-awareness, data mining, interactive digital TV, metadata, social TV}
}

@INPROCEEDINGS{Amelink-Scales:2011,
  author = {Catherine T. Amelink and Glenda Scales},
  title = {Work in Progress -- A Framework for Assessing the Impact of Instructional Technology on the Nature of Teaching and Learning},
  crossref = {proceedings:fie:2011},
  pages = {T2E-1 -- T2E-3},
  abstract = {If innovative approaches in educational environments are going to be considered for more widespread adoption, assessment methods need to be employed that demonstrate the efficacy of those approaches related to student learning. Various forms of instructional technology have been utilized within the undergraduate curriculum to enhance educational environments and as that technology rapidly advances, it is necessary to consider in what ways that technology brings about desired changes in the pedagogy employed and student engagement with course content. This paper describes the assessment methods currently being employed at a Research I university that are designed to examine the effectiveness of an undergraduate Tablet PC laptop requirement as it relates to systematic change in the nature of undergraduate teaching and learning.},
  keywords = {assessment, innovation, instructional technology, Tablet PC}
}

@INPROCEEDINGS{Amelung-etal:2008,
  author = {Amelung, Mario and Forbrig, Peter and Rösner, Dietmar},
  title = {Towards generic and flexible web services for e-assessment},
  crossref = {proceedings:itcse:2008},
  pages = {219--224},
  doi = {10.1145/1384271.1384330},
  abstract = {In computer science education, lectures are typically accompanied by exercise courses and/or lab practices are essential for the learning effect since they provide opportunities for students to apply their theoretical knowledge to practical problems. The automatic testing and assessment of assignments in a Web-based environment offers students more learning possibilities (e.g., time and location-independent) with immediate feedback and helps teachers to reduce their workload so they can concentrate on issues regarding content and didactics. In this paper we present a generic, flexible, and reusable Web-based system architecture and its implementation for automatic testing of programming assignments and assignments in other formal systems. We also describe our practical experience gathered with this approach in computer science courses at two different universities.},
  keywords = {computer-assisted assessment, cs1/2, e-assessment, e-learning, web services, web-based systems},
  timestamp = {2013-08-23}
}

@ARTICLE{Ananiadou-etal:2009,
  author = {Ananiadou, Sophia and Rea, Brian and Okazaki, Naoaki and Procter, Rob and Thomas, James},
  title = {Supporting Systematic Reviews Using Text Mining},
  crossref = {journal:sage:sscr},
  volume = {27},
  number = {4},
  month = nov,
  year = {2009},
  pages = {509--523},
  doi = {10.1177/0894439309332293},
  abstract = {In this article, we describe how we are using text mining solutions to enhance the production of systematic reviews. The aims of this collaborative project are the development of a text mining framework to support systematic reviews and the provision of a service exemplar serving as a test bed for deriving requirements for the development of more generally applicable text mining tools and services.},
  keywords = {document classification, summarisation, systematic reviews, terminology, text mining}
}

@ARTICLE{Anderson:2013,
  author = {Anderson, David},
  title = {{Max Newman}: forgotten man of early {British} computing},
  crossref = {journal:acm:communications},
  volume = {56},
  number = {5},
  month = may,
  year = {2013},
  pages = {29--31},
  doi = {10.1145/2447976.2447986},
  abstract = {Reflections on a significant, yet often overlooked, computing pioneer.}
}

@ARTICLE{Anderson-Jeffries:1985,
  author = {Anderson, John R. and Jeffries, Robin},
  title = {Novice {LISP} errors: undetected losses of information from working memory},
  crossref = {journal:erlbaum:hci},
  volume = {1},
  number = {2},
  month = jun,
  year = {1985},
  pages = {107--131},
  doi = {10.1207/s15327051hci0102_2},
  abstract = {Four experiments study the errors students make using LISP functions. The first two experiments show that frequency of errors is increased by increasing the complexity of irrelevant aspects of the problem. The experiments also show that the distribution of errors is largely random and that subjects' errors seem to result from slips rather than from misconceptions. Experiment 3 shows that subjects' errors tend to involve loss of parentheses in answers when the resulting errors are well-formed LISP expressions. Experiment 4 asks subjects, who knew no LISP, to judge the reasonableness of the answers to various LISP function calls. Subjects could detect many errors on the basis of general criteria of what a reasonable answer should look like. On the basis of these four experiments, we conclude that errors occur when there is a loss of information in the working memory representation of the problem and when the resulting answer still looks reasonable.}
}

@ARTICLE{Andres-etal:2013,
  author = {César Andrés and Carlos Camacho and Luis Llana},
  title = {A formal framework for software product lines },
  crossref = {journal:elsevier:ist},
  volume = {55},
  number = {11},
  month = nov,
  year = {2013},
  pages = {1925--1947},
  doi = {10.1016/j.infsof.2013.05.005},
  abstract = {A Software Product Line is a set of software systems that are built from a common set of features. These systems are developed in a prescribed way and they can be adapted to fit the needs of customers. Feature models specify the properties of the systems that are meaningful to customers. A semantics that models the feature level has the potential to support the automatic analysis of entire software product lines. The objective of this paper is to define a formal framework for Software Product Lines. This framework needs to be general enough to provide a formal semantics for existing frameworks like FODA (Feature Oriented Domain Analysis), but also to be easily adaptable to new problems. We define an algebraic language, called SPLA, to describe Software Product Lines. We provide the semantics for the algebra in three different ways. The approach followed to give the semantics is inspired by the semantics of process algebras. First we define an operational semantics, next a denotational semantics, and finally an axiomatic semantics. We also have defined a representation of the algebra into propositional logic. We prove that the three semantics are equivalent. We also show how FODA diagrams can be automatically translated into SPLA. Furthermore, we have developed our tool, called AT, that implements the formal framework presented in this paper. This tool uses a SAT-solver to check the satisfiability of an SPL. This paper defines a general formal framework for software product lines. We have defined three different semantics that are equivalent; this means that depending on the context we can choose the most convenient approach: operational, denotational or axiomatic. The framework is flexible enough because it is closely related to process algebras. Process algebras are a well-known paradigm for which many extensions have been defined.},
  keywords = {Formal methods, Software product lines, Feature models},
  timestamp = {2013-09-08}
}

@ARTICLE{Andrews-etal:2003,
  author = {Andrews, Anneliese and France, Robert and Ghosh, Sudipto and Craig, Gerald},
  title = {Test adequacy criteria for {UML} design models},
  crossref = {journal:wiley:stvr},
  volume = {13},
  number = {2},
  month = apr # {--} # jun,
  year = {2003},
  pages = {95--127},
  doi = {10.1002/stvr.270},
  abstract = {Systematic design testing, in which executable models of behaviours are tested using inputs that exercise scenarios, can help reveal flaws in designs before they are implemented in code. In this paper a technique for testing executable forms of UML (Unified Modelling Language) models is described and test adequacy criteria based on UML model elements are proposed. The criteria can be used to define test objectives for UML designs. The UML design test criteria are based on the same premise underlying code test criteria: coverage of relevant building blocks of models is highly likely to uncover faults. The test adequacy criteria proposed in this paper are based on building blocks for UML class and interaction diagrams. Class diagram criteria are used to determine the object configurations on which tests are run, while interaction diagram criteria are used to determine the sequences of messages that should be tested.},
  keywords = {design reviews, software testing, test adequacy criteria, UML, class diagram, collaboration diagram, category partitioning}
}

@INPROCEEDINGS{Aniche:2012,
  author = {Mauricio Finavaro Aniche and Thiago Miranda Ferreira and Marco Aurélio Gerosa},
  title = {What Concerns Beginner Test-Driven Development Practitioners: A Qualitative Analysis of Opinions in an Agile Conference},
  crossref = {proceedings:wbma:2011},
  pages = {1--12},
  abstract = {Test-Driven Development (TDD) is an important practice among ag-ile practitioners. Many studies in the literature, well-known authors, and devel-opers claim that TDD simplifies code, improves software design, and increases productivity. This paper reports a qualitative analysis on beginners' opinions about TDD, captured in an agile conference. All participants had at most 3 years of experience in TDD, but different levels of experience in software devel-opment, which allowed a rich discussion about the effects of the practice in the real world. Based on the participants' answers, beginners consider TDD as pri-marily a design technique. They also agree that TDD does not solve problems by itself, and programmers should have a deep knowledge about design and OO principles. However, baby steps, productivity, and difficulty in learning are a polemic topic among them.},
  owner = {magsilva},
  timestamp = {2014.10.14}
}

@ARTICLE{Anjaneyulu:1994,
  author = {Anjaneyulu, K. S. R.},
  title = {Bug analysis of {Pascal} programs},
  crossref = {journal:acm:sigplan},
  volume = {29},
  number = {4},
  month = apr,
  year = {1994},
  pages = {15--22},
  doi = {10.1145/181761.181762},
  abstract = {The paper first looks at issues related to the teaching of programming. Solutions to two programming problems written by participants new to the Pascal programming language are analyzed. The types of bugs which were detected in these programs are then described. Results of such analyses could perhaps help in improving the way programming is taught.}
}

@INPROCEEDINGS{Antoniol-etal:2008,
  author = {Antoniol, Giuliano and Ayari, Kamel and Di Penta, Massimiliano and Khomh, Foutse and Guéhéneuc, Yann-Gaël},
  title = {Is It a Bug or an Enhancement?: A Text-based Approach to Classify Change Requests},
  crossref = {proceedings:cascon:2008},
  pages = {23:304--23:318},
  doi = {10.1145/1463788.1463819},
  abstract = {Bug tracking systems are valuable assets for managing maintenance activities. They are widely used in open-source projects as well as in the software industry. They collect many different kinds of issues: requests for defect fixing, enhancements, refactoring/restructuring activities and organizational issues. These different kinds of issues are simply labeled as "bug" for lack of a better classification support or of knowledge about the possible kinds. This paper investigates whether the text of the issues posted in bug tracking systems is enough to classify them into corrective maintenance and other kinds of activities. We show that alternating decision trees, naive Bayes classifiers, and logistic regression can be used to accurately distinguish bugs from other kinds of issues. Results from empirical studies performed on issues for Mozilla, Eclipse, and JBoss indicate that issues can be classified with between 77% and 82% of correct decisions.}
}

@ARTICLE{Araujo-etal:2011,
  author = {J. E. M. Araujo and S. Souza and M. T. Valente},
  title = {Study on the relevance of the warnings reported by {Java} bug-finding tools},
  crossref = {journal:iet:software},
  volume = {5},
  number = {4},
  month = aug,
  year = {2011},
  pages = {366--374},
  doi = {10.1049/iet-sen.2009.0083},
  abstract = {Several bug-finding tools have been proposed to detect software defects by means of static analysis techniques. However, there is still no consensus on the effective role that such tools should play in software development. Particularly, there is still no concluding answer to the following question usually formulated by software developers and software quality managers: how relevant are the warnings reported by bug finding tools? The authors first report an in-depth study involving the application of two bug-finding tools (FindBugs and PMD) in five stable versions of the Eclipse platform. Next, in order to check whether the initial conclusions are supported by other systems, the authors describe an extended case study with 12 systems. In the end, it has been concluded that rates of relevance superior to 50% can be achieved when FindBugs is configured in a proper way. On the other hand, in the best scenario considered in the research, only 10% of the warnings reported by PMD have been classified as relevant.}
}

@INPROCEEDINGS{Araujo-etal:2011:icsea,
  author = {Rodrigo Fraxino Araujo and José Carlos Maldonado and Márcio Eduardo Delamaro and Auri Marcelo Rizzo Vincenzi and François Delebecque},
  title = {Devising Mutant Operators for Dynamic Systems Models by Applying the {HAZOP} Study},
  crossref = {proceedings:icsea:2011},
  pages = {58--64},
  abstract = {Embedded systems are increasingly present in many electronic devices. Therefore, it is necessary to use rigorous testing techniques aimed at ensuring that these systems behave as expected. Our contribution is the definition of mutant operators for the context of embedded systems models. We focus on dynamic systems models, specifically on Simulink and Scicos models, which are considered standards in many industrial application domains, such as avionics and automotive control. The HAZOP study was applied to investigate and analyze all the main features of such models, in order that the resulting mutant operators could be systematically generated. We developed a testing environment to support the mutation testing for dynamic system models, which was used to employ the defined mutant operators in a sample application.},
  keywords = {Simulink, Scicos, HAZOP, mutation testing}
}

@INPROCEEDINGS{Araujo-etal:2004,
  author = {Araujo, R. M. and Santoro, F. M. and Borges, M.},
  title = {The {CSCW} lab ontology for groupware evaluation},
  crossref = {proceedings:cscwd:2004},
  pages = {148--153},
  doi = {10.1109/CACWD.2004.1349175},
  abstract = {One of the main difficulties faced by a research group is how to accomplish the evaluation of groupware tools and prototypes in order to verify if they answer the hypotheses outlined at the beginning of the investigation. The CSCW Lab is an approach for applying evaluation methodologies in the context of a groupware research group. In this paper, we present an ontology for groupware evaluation where we establish the main concepts related to the evaluation processes and to the major dimensions of groupware evaluation.}
}

@ARTICLE{Ardis-Hunderson:2011,
  author = {Ardis, Mark A. and Henderson, Peter B.},
  title = {Software engineering education (SEEd) -- Guidelines for Software Engineering Education},
  crossref = {journal:software-engineering-notes},
  volume = {36},
  month = aug,
  year = {2011},
  pages = {6--7},
  doi = {10.1145/1988997.1989000},
  acmid = {1989000},
  address = {New York, NY, USA},
  issn = {0163-5948},
  journal = {SIGSOFT Software Engineering Notes},
  publisher = {ACM}
}

@ARTICLE{Arias-etal:2014,
  author = {Arias, M. and Pando, P. and Rodriguez, A. and Miaja, P. F. and Vazquez, A. and Fernandez, M. and Lamar, D. G.},
  title = {The Master's Thesis: An Opportunity for Fostering Presentation Skills},
  crossref = {journal:ieee:te},
  volume = {57},
  number = {1},
  month = feb,
  year = {2014},
  pages = {61-68},
  doi = {10.1109/TE.2013.2267094},
  abstract = {Presentation skills, such as oral expression and public speaking, have normally been relegated to the background in engineering degree programs. In recent years, however, the labor market has specifically demanded these kinds of skills in engineers. Accordingly, new engineering degrees, adapted to the goals of the Bologna Declaration or ABET criteria, consider presentation skills as being fundamental transferable skills. In practice, however, many engineering degree programs do not specifically foster these skills even though they are included in the syllabus. This paper proposes a presentation-skills training that uses the Master's thesis as an opportunity for fostering presentation-related skills. This activity has students deliver a scheduled series of rehearsals, in front of their classmates and tutors, for their officially assessed presentation of their Master's thesis work. The paper also presents a Web tool specifically designed for uploading recordings of the rehearsal presentations for feedback online as a complementary method for fostering presentation-related skills. Finally, the results of carrying out the proposed resource over a 4-year period from 2009 to 2013 are discussed; they show that students following the proposed methodology had higher than average marks, all receiving an A+, and 82% of them receiving an A+ with distinction.},
  keywords = {Master's thesis;Web tool;oral expression;presentation skills;transferable skills}
}

@INPROCEEDINGS{Arimoto-Barbosa:2012:icce,
  author = {Arimoto, M, M. and Barbosa, E. F.},
  title = {A Systematic Review of Methods for Developing Open Educational Resources},
  crossref = {proceedings:icce:2012},
  pages = {1--8},
  abstract = {Educational resources, such as learning objects, have been more and more used in education and training scenarios. The free and open distribution of these resources contributes to the dissemination of knowledge and facilitates access to information. Following this trend, Open Educational Resources (OER's) have emerged to assist in the teaching and learning processes in general. Motivated by this scenario, the purpose of this paper is to characterize the state-of-the-art regarding the development, delivery and reuse of OER's. A systematic literature review was conducted and some initiatives were identified and investigated. Additionally, a preliminary set of characteristics to be considered in the development of OER's was also established. In general, we noticed a lack of systematic methods for the appropriate creation and adoption of OER's. In this sense, this work provides guidance for new research and development in the area.},
  keywords = {Open educational resources, development methods, systematic review}
}

@INPROCEEDINGS{Arimoto-Barbosa:2012:wrea,
  author = {Maurício Massaru Arimoto and Ellen Francine Barbosa},
  title = {Um Conjunto Preliminar de Práticas para o Desenvolvimento Ágil de Recursos Educacionais Abertos},
  crossref = {proceedings:cbie:wrea:2012},
  pages = {1--10},
  abstract = {REAs (Recursos Educacionais Abertos) têm emergido como um mecanismo de disseminação de conhecimento e de democratização do acesso à educação. Entretanto, iniciativas que propiciem o desenvolvimento e a disponibilização de REAs de qualidade, de forma ágil e com custos reduzidos, ainda se mostram incipientes. Diante dessa perspectiva, este trabalho propõe um conjunto preliminar de práticas para o desenvolvimento flexível, colaborativo e ágil de REAs. As práticas foram definidas a partir da condução de uma revisão sistemática no domínio de REAs e da comparação e análise de alguns dos principais métodos ágeis utilizados no desenvolvimento de software. A médio prazo, a ideia é que o conjunto de práticas proposto sirva como base para o estabelecimento de um método ágil para o desenvolvimento de REAs.},
  owner = {magsilva},
  timestamp = {2014.08.01}
}

@ARTICLE{Armoni-BenAri:2009,
  author = {Armoni, Michal and Ben-Ari, Mordechai},
  title = {The concept of nondeterminism: its development and implications for teaching},
  crossref = {journal:acm:inroads},
  volume = {41},
  number = {2},
  month = jun,
  year = {2009},
  pages = {141--160},
  doi = {10.1145/1595453.1595495},
  abstract = {Nondeterminism is a fundamental concept in computer science that appears in various contexts such as automata theory, algorithms and concurrent computation. We present a taxonomy of the different ways that nondeterminism can be defined and used; the categories of the taxonomy are domain, nature, implementation, consistency, execution and semantics. An historical survey shows how the concept was developed from its inception by Rabin & Scott, Floyd and Dijkstra, as well the interplay between nondeterminism and concurrency. Computer science textbooks and pedagogical software are surveyed to determine how they present the concept; the results show that the treatment of nondeterminism is generally fragmentary and unsystematic. We conclude that the teaching of nondeterminism must be integrated through the computer science curriculum so that students learn to see nondeterminism both in terms of abstract mathematical entities and in terms of machines whose execution is unpredictable.},
  keywords = {abstraction, algorithms, automata, concurrency, formal methods, nondeterminism, specification}
}

@ARTICLE{Armour:2014,
  author = {Armour, Phillip G.},
  title = {The Business of Software Vendor: Vidi, Vici},
  crossref = {journal:acm:cacm},
  volume = {57},
  number = {10},
  month = sep,
  year = {2014},
  pages = {30--31},
  doi = {10.1145/2661053},
  abstract = {Some hidden costs of outsourcing.},
  owner = {magsilva},
  timestamp = {2014.10.14}
}

@ARTICLE{Armour:2011,
  author = {Armour, Phillip G.},
  title = {Testing: failing to succeed},
  crossref = {journal:cacm},
  volume = {54},
  number = {10},
  month = oct,
  year = {2011},
  pages = {30--31},
  doi = {10.1145/2001269.2001280},
  acmid = {2001280},
  address = {New York, NY, USA},
  issn = {0001-0782},
  issue = {10},
  issue_date = {October 2011},
  journal = {Communications of the ACM},
  numpages = {2},
  publisher = {ACM}
}

@ARTICLE{Armstrong:2006,
  author = {Armstrong, Deborah J.},
  title = {The Quarks of Object-oriented Development},
  crossref = {journal:acm:cacm},
  volume = {49},
  number = {2},
  month = feb,
  year = {2006},
  pages = {123--128},
  doi = {10.1145/1113034.1113040},
  abstract = {A two-construct taxonomy is used to define the essential elements of object orientation through analysis of existing literature.},
  owner = {magsilva},
  timestamp = {2014.07.17}
}

@ARTICLE{Arruda-etal:2009,
  author = {Arruda, Denis and Bezerra, Fábio and Neris, Vânia Almeida and Rocha De Toro, Patricia and Wainera, Jacques},
  title = {{Brazilian} computer science research: Gender and regional distributions},
  crossref = {journal:springer:jbcs},
  volume = {79},
  number = {3},
  month = jun,
  year = {2009},
  pages = {651--665},
  doi = {10.1007/s11192-007-1944-0},
  abstract = {This paper analysis the distribution of some characteristics of computer scientists in Brazil according to regions and gender. Computer scientist is defined as the faculty of a graduate level computer science department. Under this definition, there were 886 computer scientists in Brazil in November 2006.}
}

@INPROCEEDINGS{Arruda-etal:2002,
  author = {Carlos Roberto Esperança {Arruda Jr.} and Maria da Graça C. Pimentel and Claudia Akemi Izeki},
  title = {{CoTeia}: Uma Ferramenta Colaborativa de Edição Baseada na Web},
  crossref = {proceedings:sbmidia:2002},
  pages = {371-374},
  abstract = {CoTeia é uma ferramenta hipermídia que suporta a autoria colaborativa assíncrona de páginas Web em repositórios denominados Swikis. As principais características da CoTeia são: (a) simplicidade de uso, (b) ausência de estrutura pré-definida das páginas, fazendo com que a CoTeia tenha usos variados e (c) adição de funcionalidades como anotações, chat e mapa de swiki que facilitam o desenvolvimento colaborativo de informações entre os usuários.},
  abstract-en = {CoTeia is a hypermedia tool that supports the collaborative asynchronous authoring of Web hyperdocuments into repositories called Swikis. The main characteristics of CoTeia are: (a) use simplicity, (b) absence of pre-defined structure of the pages, increasing the uses of the CoTeia and (c) addition of functionalities as annotations, chat and swiki map that facilitate the collaborative development of information among the users.},
  address = {Fortaleza, Brasil},
  booktitle = {Workshop de Ferramentas e Aplicações do VIII SBMIDIA},
  lang = {pt},
  month = oct,
  owner = {magsilva},
  timestamp = {2008.07.30},
  year = {2002}
}

@ARTICLE{Asadi-etal:2014,
  author = {Mohsen Asadi and Bardia Mohabbati and Gerd Gröner and Dragan Gasevic},
  title = {Development and validation of customized process models},
  crossref = {journal:elsevier:jss},
  volume = {96},
  month = oct,
  year = {2014},
  pages = {73--92},
  doi = {10.1016/j.jss.2014.05.063},
  abstract = {Abstract Configurable reference process models encompass common and variable processes of organizations from different business domains. These reference process models are designed and reused to guide and derive customized business processes according to the requirements of stakeholders. The customization process is generally initiated by a configuration step, selecting a subset of the reference process model. Configuration is followed by a customization step, which assumes adapting or extending the configured business process based on the specific or unforeseen requirements. Hence, it is crucial to validate the correctness and compliance of the final customized business process with respect to the patterns and business constraints that are specified in the reference model. In this paper, we firstly introduce a technique to develop a customized process model and then present a set of identified inconsistency patterns that may happen during the configuration of a reference model and the customization of configured process models. Furthermore, we describe our proposed approach including formal representations and algorithms that provide logical reasoning and enable automatic inconsistency detection by leveraging description logic. In order to explore the scalability of the approach, we designed the experiments with various process models sizes and inconsistency distributions. The results of the experiments revealed the scalability of our approach with large size process models (500 activities).},
  keywords = {Reference process models; Feature models; Description logics},
  owner = {magsilva},
  timestamp = {2014.08.28}
}

@ARTICLE{Astrachan-Briggs:2012,
  author = {Astrachan, Owen and Briggs, Amy},
  title = {The {CS} principles project},
  crossref = {journal:acm:inroads},
  volume = {3},
  number = {2},
  month = jun,
  year = {2012},
  pages = {38--42},
  doi = {10.1145/2189835.2189849},
  keywords = {CS 10K, CS principles, computational thinking, computer science education}
}

@INPROCEEDINGS{Auer-etal:2002,
  author = {Auer, Ken and Jeffries, Ron and Canna, Jeff and Alleman, Glen B. and Crispin, Lisa and Gregory, Janet},
  title = {Are Testers eXtinct? How Can Testers Contribute to {XP} Teams?},
  crossref = {proceedings:xp:2002},
  pages = {287--287},
  doi = {10.1007/3-540-45672-4_50},
  abstract = {There are lots of success stories for XP teams where testers made a significant contribution. There are lots of success stories for XP teams that didn't have an official tester. There are some horror stories of so-called XP teams who didn't have testers and didn't do a scrap of acceptance testing. As more organizations try XP, there are a lot of teams out there wondering if they need testers, and a lot of testers who are suddenly members of XP teams wondering what the heck they are supposed to do. This is relevant to anyone on an XP team, any QA / test professionals who are interested in doing XP, anyone in a software development role who is considering using XP. The current Extreme Programming publications don't really define how an XP tester can contribute to the project. What should testers do? When should they do it? How should they do it? Is there even a place for testing and quality assurance professionals on XP teams? Can any tester be an XP tester? See http://www.testers.org for more information.},
  owner = {magsilva},
  timestamp = {2014.10.21}
}

@ARTICLE{Avgeriou-etal:2013,
  author = {Avgeriou, Paris and Stal, Michael and Hilliard, Rich},
  title = {Architecture Sustainability},
  crossref = {journal:ieee:software},
  volume = {30},
  number = {6},
  month = nov # {--} # dec,
  year = {2013},
  pages = {40--44},
  doi = {10.1109/MS.2013.120},
  abstract = {Software architecture is the foundation of software system development, encompassing a system's architects' and stakeholders' strategic decisions. A special issue of IEEE Software is intended to raise awareness of architecture sustainability issues and increase interest and work in the area. The first Web extra at http://youtu.be/wUGHvocfix0 is an audio interview in which Davide Falessi speaks with guest editors Paris Avgeriou and Rich Hilliard about the importance of architecture sustainability including the three types of approaches they distinguish for handling change systematically, listed in an order of increasing severity: refactoring, renovating, and rearchitecting. The second Web extra at http://youtu.be/T-neSlUhAv0 is an audio interview in which Brian Brannon speaks with guest editor Michael Stal about his experiences with architecture sustainability as a principal engineer at Siemens AG's Corporate Research and Technology division.},
  quotes = {One of the primary goals of systematic architecting is to increase architecture sustainability -- that is, the architecture capacity to endure different types of change through efficient maintenance and orderly evolution over its entire life cycle. Consequently, we can't limit systematic architecting to initial architecture creation but must observe it throughout software architecture evolution and improvement to encourage architecture sustainability during changes. Among the causes of change, several are particularly significant for architecture sustainability: new requirements emerge while older requirements change, interdependence between requirements and architecture, changes in business strategies and goals, environment changes, architecture erosion or drift, accidental complexity, technology changes, deferred decisions to meet near-term goals, to err is human. We distinguish three types of approaches for handling change systematically, listed in an order of increasing severity: refactoring, renovating, and rearchitecting.},
  owner = {magsilva},
  quality = {1},
  timestamp = {2014.01.14}
}

@INPROCEEDINGS{Avila-Zorzo:2009,
  author = {Ávila, Paulo Muniz and Zorzo, Sérgio Donizetti},
  title = {A personalized {TV} guide system compliant with {Ginga}},
  crossref = {proceedings:webmedia:2009},
  pages = {1--8},
  doi = {10.1145/1858477.1858482},
  abstract = {In this paper we present a personalized recommendation system, the RecommenderTV consistent with the reference implementation of the middleware Ginga. The implementation of the system RecommenderTV demanded the inclusion of new features to the middleware Ginga-NCL none exists in the implementation of reference. The service providers (in the analog system, broadcasters) and its importance to the system RecommenderTV are discussed in this work. The results obtained with three different mining algorithms running in a set-top box using real data provide by IBOPE Midia are presented. Finally, we are reported the results obtained from the experiments with the system of recommendation implemented.},
  keywords = {digital TV, middleware Ginga, multimedia, personalization, profiling, recommendation system}
}

@ARTICLE{Avison-etal:1994,
  author = {Avison, D. E. and Shah, H. U. and Wilson, D. N.},
  title = {Software quality standards in practice: the limitations of using {ISO-9001} to support software development},
  crossref = {journal:springer:sqj},
  volume = {3},
  number = {2},
  month = jun,
  year = {1994},
  pages = {105--111},
  doi = {10.1007/BF00213633},
  abstract = {Quality management standard BS5740/ISO9001 is a key technology for UK and Europe in the 1990s. This paper shows that the relevance of BS5750/ISO9001 is limited and suggests that standards bodies must develop and endorse new standards to ensure that software quality improvement programmes continue to be adopted by the information technology industry.},
  keywords = {software quality assurance; BS5750/ISO9001}
}

@INPROCEEDINGS{Azevedo-etal:2011,
  author = {Azevedo, Roberto Gerson Albuquerque and Soares Neto, Carlos de Salles and Teixeira, Mario Meireles and Santos, Rodrigo Costa Mesquita and Gomes, Thiago Alencar},
  title = {Textual authoring of interactive digital {TV} applications},
  crossref = {proceedings:euroitv:2011},
  pages = {235--244},
  doi = {10.1145/2000119.2000169},
  abstract = {Authoring tools for hypermedia languages usually provide visual abstractions, which hide the source code from the author aiming to simplify and accelerate the development process. Among other drawbacks, these abstractions modify or even break the communication process between the author and the language designer, since these languages were designed to be readable and understandable by its target audience. This paper presents a textual approach to hypermedia authoring that does not have these inconveniences, but rather uses typographical accessories, such as program visualization, hypertextual navigation, and semi-automatic error correction. The proposed approach exploits concepts known to the author and does not imply in extra cognitive overload. A use case is presented, namely the NCL Eclipse authoring environment, for Nested Context Language, the Brazilian Digital TV and ITU-T standard.},
  keywords = {ginga-ncl, hypermedia authoring, ncl eclipse, nested context language, textual authoring}
}

@ARTICLE{Balter-Bailey:2010,
  author = {B\"{a}lter, Olle and Bailey, Duane A.},
  title = {Enjoying Python, processing, and Java in CS1},
  crossref = {journal:acm:inroads},
  volume = {1},
  number = {4},
  month = dec,
  year = {2010},
  pages = {28--32},
  doi = {10.1145/1869746.1869758},
  abstract = {Here we describe an introductory course in computer science where we combined Python, Processing, and core Java. The main reason for this structure was to make the initial contact with programming as gentle, enjoyable, and understandable as possible, while still having the power of graphics and sufficient Java knowledge for more advanced courses in computer science. This course was designed with a few informal pedagogical principles that facilitated the students' abilities to learn how to learn on their own. Informal results suggest that students may be interested in a greater diversity of programming assignments.},
  keywords = {Java, Processing, Python, introductory course, student projects},
  acmid = {1869758},
  issue = {4},
  issue_date = {December 2010},
  lang = {en},
  numpages = {5}
}

@ARTICLE{Mourad-etal:2013,
  author = {Badri, Mourad and Badri, Linda and Flageol, William},
  title = {On the Relationship Between Use Cases and Test Suites Size: An Exploratory Study},
  crossref = {journal:acm:sen},
  volume = {38},
  number = {4},
  month = jul,
  year = {2013},
  pages = {1--5},
  doi = {10.1145/2492248.2492261},
  abstract = {Software testing, which plays a crucial role in software quality assurance, is a time and resource consuming process. It is, therefore, necessary to estimate as soon as possible the effort required to test software, so that activities can be planned and resources can be optimally allocated. Unfortunately, little is known about the prediction of the testing effort. In this paper, we address the testing effort from the perspective of test suites size. The study presented aims at exploring empirically the relationships between use cases and the size of test suites in object-oriented systems. We introduce four metrics to characterize the size and complexity of use cases. The size of test suites is measured in terms of lines of test code. We performed an experimental study using data collected from five cases studies. Results provide evidence that there is a significant relationship between use case metrics and the size of test suites.},
  keywords = {estimation, metrics, relationship, size, software testability, software testing, test suite, use cases},
  owner = {magsilva},
  timestamp = {2014.01.27}
}

@ARTICLE{Baggen-etal:2012,
  author = {Baggen, Robert and Correia, José Pedro and Schill, Katrin and Visser, Joost},
  title = {Standardized code quality benchmarking for improving software maintainability},
  crossref = {journal:springer:sqj},
  volume = {20},
  number = {2},
  month = jun,
  year = {2012},
  pages = {287--307},
  doi = {10.1007/s11219-011-9144-9},
  abstract = {We provide an overview of the approach developed by the Software Improvement Group for code analysis and quality consulting focused on software maintainability. The approach uses a standardized measurement model based on the ISO/IEC 9126 definition of maintainability and source code metrics. Procedural standardization in evaluation projects further enhances the comparability of results. Individual assessments are stored in a repository that allows any system at hand to be compared to the industry-wide state of the art in code quality and maintainability. When a minimum level of software maintainability is reached, the certification body of TÜV Informationstechnik GmbH issues a Trusted Product Maintainability certificate for the software product.},
  keywords = {Software product quality; Benchmarking; Certification; Standardization}
}

@ARTICLE{Bahsoon-etal:2013,
  author = {Rami Bahsoon and Ivan Mistrík and Nour Ali and T.S. Mohan and Nenad Medvidovic},
  title = {The future of software engineering {IN} and {FOR} the cloud},
  crossref = {journal:elsevier:jss},
  volume = {86},
  number = {9},
  month = sep,
  year = {2013},
  pages = {2221--2224},
  doi = {10.1016/j.jss.2013.05.061},
  keywords = {Cloud software engineering },
  timestamp = {2013-09-05}
}

@ARTICLE{Bakar:2011,
  author = {Bakar, Ahmad Zaki Abu},
  title = {The forgotten majority of computing have-nots},
  crossref = {journal:acm:inroads},
  volume = {2},
  number = {2},
  month = jun,
  year = {2011},
  pages = {4--10},
  doi = {10.1145/1963533.1963534},
  abstract = {People have falsely regarded the computing working environment as dedicated to the confines of a building with availability of electricity, high-speed info-structure, and the latest computer technology. In reality, there are many computing have-nots in the real world living in challenged computing environments. Current computing curricula are designed to prepare graduates for more urban and best-case business scenarios where learning takes place within campus boundaries. To prepare computing graduates better to survive in harsh environments and to contribute meaningfully to society, their learning should also take place out of the classroom and into challenged computing environments where active and experiential learning could take place. Confronted with the harsh realities of life, students learn quickly to adapt themselves for survival and for their future career. Many generic skills can be reinforced here to make computing graduates more versatile, entrepreneurial, effective, and ever ready to face the real world.},
  keywords = {Digital disparity, curriculum design, experiential learning},
  acmid = {1963534},
  issue = {2},
  issue_date = {June 2011},
  lang = {en},
  numpages = {7}
}

@ARTICLE{Baker:2006,
  author = {Keith D. Baker},
  title = {Learning Objects and Process Interoperability},
  crossref = {journal:ijel},
  volume = {5},
  number = {1},
  year = {2006},
  pages = {167--172},
  abstract = {There has been considerable emphasis on the availability and reuse of learning content in recent years. Since 2000, the ADL initiative has refined the recommendations contained in the SCORM documents through progressive stages represented in the SCORM 1.0, 1.1, 1.2 and 1.3 documents. Fundamental to SCORM is the notion of the Shareable Content Object (SCO) and the Learning Object Metadata (LOM). There is an expectation that the Learning Experience can be designed using a set of Learning Objects or SCOs drawn from repositories of learning materials.},
  url = {http://go.editlib.org/p/21762}
}

@ARTICLE{Baker-Habli:2012,
  author = {Richard Baker and Ibrahim Habli},
  title = {An Empirical Evaluation of Mutation Testing For Improving the Test Quality of Safety-Critical Software},
  crossref = {journal:ieee:tse},
  volume = {99},
  number = {PrePrints},
  year = {2012},
  pages = {1},
  doi = {10.1109/TSE.2012.56},
  abstract = {Testing provides a primary means for assuring software in safety-critical systems. To demonstrate, particularly to a certification authority, that sufficient testing has been performed, it is necessary to achieve the test coverage levels recommended or mandated by safety standards and industry guidelines. Mutation testing provides an alternative or complementary method of measuring test sufficiency, but has not been widely adopted in the safety-critical industry. In this study, we provide an empirical evaluation of the application of mutation testing to airborne software systems which have already satisfied the coverage requirements for certification. Specifically, we apply mutation testing to safety-critical software developed using high-integrity subsets of C and Ada, identify the most effective mutant types, and analyse the root causes of failures in test cases. Our findings show how mutation testing could be effective where traditional structural coverage analysis and manual peer review have failed. They also show that several testing issues have origins beyond the test activity, and this suggests improvements to the requirements definition and coding process. Our study also examines the relationship between program characteristics and mutation survival and considers how program size can provide a means for targeting test areas most likely to have dormant faults.}
}

@INPROCEEDINGS{Baker-etal:1999,
  author = {Baker, Ryan S. and Boilen, Michael and Goodrich, Michael T. and Tamassia, Roberto and Stibel, B. Aaron},
  title = {Testers and visualizers for teaching data structures},
  crossref = {proceedings:sigcse:1999},
  pages = {261--265},
  doi = {10.1145/299649.299779},
  abstract = {We present two tools to support the teaching of data structures and algorithms: Visualizers, which provide interactive visualizations of user-written data structures, and Testers, which check the functionality of user-written data structures. We outline a prototype implementation of visualizers and testers for data structures written in Java, and report on classroom use of testers and visualizers in an introductory Data Structures and Algorithms (CS2) course.}
}

@ARTICLE{Baldassarre-etal:2012,
  author = {Baldassarre, MariaTeresa and Caivano, Danilo and Pino, FranciscoJ. and Piattini, Mario and Visaggio, Giuseppe},
  title = {Harmonization of {ISO/IEC 9001:2000} and {CMMI-DEV}: from a theoretical comparison to a real case application},
  crossref = {journal:springer:sqj},
  volume = {20},
  number = {2},
  month = jun,
  year = {2012},
  pages = {309--335},
  doi = {10.1007/s11219-011-9154-7},
  abstract = {In the past years, both industrial and research communities in Software Engineering have shown special interest in Software Process Improvement --- SPI. This is evidenced by the growing number of publications on the topic. The literature offers numerous quality frameworks for addressing SPI practices, which may be classified into two groups: ones that describe what should be done (ISO 9001, CMMI) and ones that describe how it should be done (Six Sigma, Goal Question Metrics-GQM). When organizations decide to adopt improvement initiatives, many models may be implied, each leveraging the best practices provided, in the quest to address the improvement challenges as well as possible. This may at the same time, however, generate confusion and overlapping activities, as well as extra effort and cost. That, in turn, risks generating a series of inefficiencies and redundancies that end up leading to losses rather than to effective process improvement. Consequently, it is important to move toward a harmonization of quality frameworks, aiming to identify intersections and overlapping parts, as well as to create a multi-model improvement solution. Our aim in this work is twofold: first of all, we propose a theoretical harmonization process that supports organizations interested in introducing quality management and software development practices or concerned about improving those they already have. This is done with specific reference to CMMI-DEV and ISO 9001 models in the direction ISO to CMMI-DEV, showing how GQM is used to define operational goals that address ISO 9001 statements, reusable in CMMI appraisals. Secondly, we apply the theoretical comparison process to a real case, i.e., a Small Enterprise certified ISO 9001.},
  keywords = {Harmonization; Mapping; SPI; Multi-model; CMMI-DEV; ISO 9001; GQM}
}

@INPROCEEDINGS{Balog-etal:2006,
  author = {Balog, Krisztian and Azzopardi, Leif and de Rijke, Maarten},
  title = {Formal Models for Expert Finding in Enterprise Corpora},
  crossref = {proceedings:sigir:2006},
  pages = {43--50},
  doi = {10.1145/1148170.1148181},
  abstract = {Searching an organization's document repositories for experts provides a cost effective solution for the task of expert finding. We present two general strategies to expert searching given a document collection which are formalized using generative probabilistic models. The first of these directly models an expert's knowledge based on the documents that they are associated with, whilst the second locates documents on topic, and then finds the associated expert. Forming reliable associations is crucial to the performance of expert finding systems. Consequently, in our evaluation we compare the different approaches, exploring a variety of associations along with other operational parameters (such as topicality). Using the TREC Enterprise corpora, we show that the second strategy consistently outperforms the first. A comparison against other unsupervised techniques, reveals that our second model delivers excellent performance.},
  keywords = {enterprise search, expert finding},
  owner = {magsilva},
  timestamp = {2014.05.18}
}

@INPROCEEDINGS{Balzer:1991,
  author = {Robert Balzer},
  title = {Tolerating Inconsistency},
  crossref = {proceedings:icse:1991},
  pages = {158--165}
}

@INPROCEEDINGS{Banerjee-Murthy:2011,
  author = {Banerjee, G. and Murthy, S.},
  title = {Model for Rapid, Large-Scale Development of Learning Objects in Multiple Domains},
  crossref = {proceedings:t4e:2011},
  pages = {163--170},
  doi = {10.1109/T4E.2011.33},
  abstract = {Over the past few years, learning object (LO) repositories have become valuable educational resources in a variety of instructional settings. However, there is a lack of detailed documentation about the actual process to be adopted under different conditions to create such a repository. The commonly established process adopts a synchronous model in which there is continuous face-to-face communication between the various members of the team - the subject matter experts, the instructional designers, the code developers and the reviewers. The synchronous process has resulted in the production of good quality LOs but in restricted domains and in small numbers. This model is not suitable to scale the LO production process up along numbers and across multiple domains without compromising on quality. In this paper we propose an asynchronous model for rapid, large-scale development of LOs in multiple science and engineering domains at the tertiary level of education. We document the problems encountered in adopting a synchronous model of LO production, present a comparative analysis of different asynchronous models, and detail out the methodology for the successful asynchronous model that we adopted.}
}

@ARTICLE{Banerjee-etal:2013,
  author = {Ishan Banerjee and Bao Nguyen and Vahid Garousi and Atif Memon},
  title = {Graphical user interface (GUI) testing: Systematic mapping and repository },
  crossref = {journal:elsevier:ist},
  volume = {55},
  number = {10},
  month = oct,
  year = {2013},
  pages = {1679--1694},
  doi = {10.1016/j.infsof.2013.03.004},
  abstract = {AbstractContext \{GUI\} testing is system testing of a software that has a graphical-user interface (GUI) front-end. Because system testing entails that the entire software system, including the user interface, be tested as a whole, during \{GUI\} testing, test cases-modeled as sequences of user input events-are developed and executed on the software by exercising the GUI's widgets (e.g., text boxes and clickable buttons). More than 230 articles have appeared in the area of \{GUI\} testing since 1991. Objective In this paper, we study this existing body of knowledge using a systematic mapping (SM). Method The \{SM\} is conducted using the guidelines proposed by Petersen et al. We pose three sets of research questions. We define selection and exclusion criteria. From the initial pool of 230 articles, published in years 1991-2011, our final pool consisted of 136 articles. We systematically develop a classification scheme and map the selected articles to this scheme. Results We present two types of results. First, we report the demographics and bibliometrics trends in this domain, including: top-cited articles, active researchers, top venues, and active countries in this research area. Moreover, we derive the trends, for instance, in terms of types of articles, sources of information to derive test cases, types of evaluations used in articles, etc. Our second major result is a publicly-accessible repository that contains all our mapping data. We plan to update this repository on a regular basis, making it a live resource for all researchers. Conclusion Our \{SM\} provides an overview of existing \{GUI\} testing approaches and helps spot areas in the field that require more attention from the research community. For example, much work is needed to connect academic model-based techniques with commercially available tools. To this end, studies are needed to compare the state-of-the-art in \{GUI\} testing in academic techniques and industrial tools. },
  keywords = {Systematic mapping; GUI application; Testing; Paper repository; Bibliometrics }
}

@INPROCEEDINGS{Barber:2012:CCU:2330601.2330664,
  author = {Barber, Rebecca and Sharkey, Mike},
  title = {Course correction: using analytics to predict course success},
  crossref = {proceedings:lak:2012},
  pages = {259--262},
  doi = {10.1145/2330601.2330664},
  abstract = {Predictive analytics techniques applied to a broad swath of student data can aid in timely intervention strategies to help prevent students from failing a course. This paper discusses a predictive analytic model that was created for the University of Phoenix. The purpose of the model is to identify students who are in danger of failing the course in which they are currently enrolled. Within the model's architecture, data from the learning management system (LMS), financial aid system, and student system are combined to calculate a likelihood of any given student failing the current course. The output can be used to prioritize students for intervention and referral to additional resources. The paper includes a discussion of the predictor and statistical tests used, validation procedures, and plans for implementation.},
  keywords = {higher education, learning analytics, predictive analytics, predictive modeling, retention}
}

@INPROCEEDINGS{Barbosa-etal:2000:icece,
  author = {E. F. Barbosa and C. M. Adriano and J. C. Maldonado and I. L. M. Ricarte and M. Jino},
  title = {Fostering Theoretical, Empirical and Tool Specific Knowledge in a Software Testing Learning Scenario},
  crossref = {proceedings:icece:2000},
  abstract = {Teaching subjects such as Computer Science concerns the support for a learning process involving the cooperation of theoretical and empirical knowledge with related software tools. The underlying hypothesis is that there is a lack of appropriate support, to students and instructors, for the apprenticeship of specific theories and skills. The current research aims at a more specific learning scenario -- Software Testing -- addressing these specific theories and skills. A Software Testing Lab requires three cooperating types of knowledge -- theoretical, empirical and tool specific, composing the learning and evaluation process. In order to investigate the above hypothesis, a specific learning scenario is implemented within an on-line learning environment, CALM, comprising a unit testing activity supported by an integrated testing tool, Poke-Tool. This scenario raises additional guidelines to be integrated into CALM and provides an experience that is extensible to other Software Engineering courses.},
  keywords = {Software Testing Lab, Testing Tool, Educational/Training Environment, Learning Scenario},
  url = {http://www.dca.fee.unicamp.br/projects/sapiens/Papers/Icece/fostering.pdf}
}

@ARTICLE{Barbosa-Maldonado:2011:JBCS,
  author = {Barbosa, Ellen Francine and Maldonado, José Carlos},
  title = {{IMA-CID:} an integrated modeling approach for developing educational modules},
  crossref = {journal:springer:jbcs},
  volume = {17},
  number = {4},
  month = nov,
  year = {2011},
  pages = {207-239},
  doi = {10.1007/s13173-011-0043-5},
  abstract = {Educational modules -- concise units of study, composed of theoretical and practical content, which can be delivered to learners by using technological and computational resources -- are relevant mechanisms to improve the learning processes. Similar to software products, educational modules require the establishment and integration of innovative methods, tools and procedures into well-defined processes aiming at producing flexible, adaptable and high-quality products. In this sense, content modeling activity plays a fundamental role in the development of educational modules, providing a way to structure the relevant parts of the learning content. Motivated by this scenario, we propose an approach for modeling learning content, capable of addressing conceptual, instructional and didactic issues altogether, in an integrated way. By means of a set of models, helps the author in determining the relevant parts of the learning content, providing a systematic way to structure the concepts and related information. It also explores the idea of open specifications , providing support for the definition of dynamic contexts of learning. Besides that, the translation of models into machine-readable specifications, automatically or by hand, makes possible interoperability and promotes reusability. It has been applied in the development of educational modules for different domains. The resulting modules have been evaluated in terms of the authors' and learners' perspectives. The results obtained provide preliminary evidence of the learning effectiveness, quality and flexibility achieved by the educational modules produced.}
}

@ARTICLE{Barbosa-etal:2001:stvr,
  author = {E. F. Barbosa and J. C. Maldonado and A. M. R. Vincenzi},
  title = {Towards the Determination of Sufficient Mutant Operators for {C}},
  crossref = {journal:wiley:stvr},
  volume = {11},
  number = {2},
  month = jun,
  year = {2001},
  pages = {113--136},
  doi = {10.1002/stvr.226},
  abstract = {Mutation testing (MT) has been found to be effective at revealing faults. However, its high cost of application, due to the high number of mutants created and the effort to determine the equivalent ones, has motivated the proposition of alternative approaches for its application. One of them, named 'selective mutation', aims to reduce the number of generated mutants through a reduction in the number of mutant operators. A previous relevant study resulted in the proposition of a sufficient mutant operators set for FORTRAN, indicating that it is possible to have a large cost reduction in MT application, whilst preserving a high MT score. This work investigates procedures for the determination of a sufficient mutant operators set for C programs with the perspective of contributing to the establishment of low-cost, effective mutation-based testing strategies.},
  keywords = {software testing; mutation testing; sufficient mutant operators},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{Barbosa-etal:2008:FIE,
  author = {Ellen Francine Barbosa and Marco Aurélio Graciotto Silva and Camila Kozlowski Della Corte and José Carlos Maldonado},
  title = {Integrated Teaching of Programming Foundations and Software Testing},
  crossref = {proceedings:fie:2008},
  pages = {S1H-5 -- S1H-10},
  doi = {10.1109/FIE.2008.4720597},
  abstract = {The importance of software testing is widely recognized, but usually only a small portion of the computer science (CS) curriculum is allocated for teaching it. Some experiences have suggested that the teaching of software testing should begin as early as possible so an adequate culture of testing could be created. One way to achieve this is addressing testing practices in conjunction with programming concepts in introductory CS courses. In this paper we explore such idea, working on the integration between the teaching of software testing along with the teaching of programming foundations. We discuss the development of an educational module, and its related learning materials, for integrating such knowledge domains. Besides that, we propose PROGTEST -- a Web-based environment for the submission and automatic evaluation of practical programming assignments based on testing activities, aiming at providing an adequate feedback to evaluate the learnerspsila performance concerning programming and testing.},
  keywords = {Educational modules , Programming foundations , Software testing , Supporting tools}
}

@INPROCEEDINGS{Baresi-Ghezzi:2010,
  author = {Baresi, Luciano and Ghezzi, Carlo},
  title = {The disappearing boundary between development-time and run-time},
  crossref = {proceedings:foser:2010},
  pages = {17--22},
  doi = {10.1145/1882362.1882367},
  abstract = {Modern software systems are increasingly embedded in an open world that is constantly evolving, because of changes in the requirements, in the surrounding environment, and in the way people interact with them. The platform itself on which software runs may change over time, as we move towards cloud computing. These changes are difficult to predict and anticipate, and their occurrence is out of control of the application developers. Because of these changes, the applications themselves need to change. Often, changes in the applications cannot be handled off-line, but require the software to self-react by adapting its behavior dynamically, to continue to ensure the desired quality of service. The big challenge in front of us is how to achieve the necessary degrees of flexibility and dynamism required by software without compromising the necessary dependability. This paper advocates that future software engineering research should focus on providing intelligent support to software at run-time, breaking today's rigid boundary between development-time and run-time. Models need to continue to live at run-time and evolve as changes occur while the software is running. To ensure dependability, analysis that the updated system models continue to satisfy the goals must be performed by continuous verification. If verification fails, suitable adjustment policies, supported by model-driven re-derivation of parts of the system, must be activated to keep the system aligned with its expected requirements. The paper presents the background that motivates this research focus, the main existing research directions, and an agenda for future work.},
  keywords = {runtime support, self-adaptation, service-oriented systems}
}

@ARTICLE{Barnes:2012,
  author = {Barnes, Tiffany},
  title = {{CS} principles pilot at University of North Carolina at Charlotte},
  crossref = {journal:acm:inroads},
  volume = {3},
  number = {2},
  month = jun,
  year = {2012},
  pages = {64--66},
  doi = {10.1145/2189835.2189855}
}

@ARTICLE{Barr-Stephenson:2011,
  author = {Barr, Valerie and Stephenson, Chris},
  title = {Bringing computational thinking to K-12: what is Involved and what is the role of the computer science education community?},
  crossref = {journal:acm:inroads},
  volume = {2},
  number = {1},
  month = mar,
  year = {2011},
  pages = {48--54},
  doi = {10.1145/1929887.1929905},
  abstract = {The process of increasing student exposure to computational thinking in K-12 is complex, requiring systemic change, teacher engagement, and development of signifi cant resources. Collaboration with the computer science education community is vital to this effort.},
  keywords = {K-12 CS Education, K-12 curriculum, computational thinking, cross-disciplinary computing}
}

@INPROCEEDINGS{Barrere-etal:2008,
  author = {Eduardo Barrére and João Benedito dos Santos Jr. and Leandro Morais Bueno},
  title = {Adaptação das Funcionalidades de um AVA para um Ambiente de TVDi},
  crossref = {proceedings:sbie:2008},
  pages = {1-3},
  abstract = {Este artigo aborda um estudo sobre as principais funcionalidades encontradas num Ambiente Virtual de Aprendizagem (AVA) e sua adaptação a um ambiente de Televisão Digital Interativa. O estudo traça um paralelo entre essas funcionalidades e quais recursos de interatividade são exigidos de um Set-Top Box para que o usuário possa fazer uso de um T-Learning.}
}

@INCOLLECTION{Barreto:2009,
  author = {Hugo Barreto},
  title = {Aprendizagem por televisão},
  chapter = {60},
  pages = {449--454},
  crossref = {Litto-Formiga:2009},
  timestamp = {2012.01.30}
}

@ARTICLE{Barriocanal-etal:2002,
  author = {Barriocanal, Elena García and Urbán, Miguel-Ángel Sicilia and Cuevas, Ignacio Aedo and Pérez, Paloma Díaz},
  title = {An experience in integrating automated unit testing practices in an introductory programming course},
  crossref = {journal:acm:sigcse-bulletin},
  volume = {34},
  number = {4},
  month = dec,
  year = {2002},
  pages = {125--128},
  doi = {10.1145/820127.820183},
  abstract = {Unit testing is one of the core practices in the Extreme Programming lightweight software development method, and it is usually carried out with the help of software frameworks that ease the construction of test cases as an integral part of programming tasks. This work describes our first results in studying the integration of automated unit testing practices in conventional 'introduction to programming' laboratories. Since the work used a classical procedural language in the course's assignments, we had to design a specific testing framework called tpUnit. The results of the experiment points out that a straightforward approach for the integration of unit testing in first-semester courses do not result in the expected outcomes in terms of student's engagement in the practice.}
}

@INPROCEEDINGS{Baruque-etal:2003,
  author = {Lúcia Blondet B. Baruque and Fábio Porto and Rubens Nascimento Melo},
  title = {Towards an Instructional Design Methodology Based on Learning Objects},
  crossref = {proceedings:cate:2003},
  pages = {243--246},
  abstract = {Instructional System Development (ISD) is a set of procedures for systematically designing and developing instruction. The development of contents for e-Learning can well benefit from the ISD approach. However, we need to revisit the traditional ISD in order to incorporate the Learning Object (LO) paradigm. LOs are self contained chunks of online content, which can be reusable and interoperable. In this work, we propose a methodology to design e-learning contents based on the ISD and LO technologies. We also suggest the use of principles of learning theories in the chunking and sequencing of LOs in e-Learning modules. The methodology is currently being tested by K-12 teachers from public schools as well as instructional designers from private companies in Brazil.},
  keywords = {WBE; Instructional Design; Learning Object; Instructional System Design; ADDIE},
  abstract-pt = {Instructional System Development (ISD) é um conjunto de procedimentos para estruturar e desenvolver sistematicamente o ensino. O desenvolvimento de conteúdos para e-learning pode se beneficiar da abordagem ISD. Entretanto, é preciso revisitar a abordagem ISD tradicional de forma a poder se incorporar o paradigma de Learning Object (LO). LOs são porções de conteúdo online autocontidas, que são reusáveis e interoperáveis. Neste trabalho nós propomos uma metodologia para projetar conteúdos de e-learning com base nas tecnologias de ISD e LO. Nós também sugerimos o uso de princípois de teorias de aprendizado no particionamento e sequenciamento de LOs e módulos e-learning. A metodologia está atualimente sendo testada por professores de ensino médio e fundamental de escolas públicas bem como projetistas instrucionais de empresas privadas brasileiras.},
  booktitle = {International Conference on Computers and Advanced Technology in Education},
  keywords-pt = {Educação baseada na web, objeto de aprendizado, Projeto de Sistemas Instrucionais, ADDIE},
  month = jun,
  owner = {magsilva},
  timestamp = {2008.07.31},
  url = {http://www.actapress.com/Abstract.aspx?paperId=14865},
  year = {2003}
}

@ARTICLE{Basili-Turner:1975,
  author = {Basili, V.R. and Turner, A.J.},
  title = {Iterative enhancement: A practical technique for software development},
  crossref = {journal:ieee:tse},
  volume = {SE-1},
  number = {4},
  month = dec,
  year = {1975},
  pages = {390--396},
  doi = {10.1109/TSE.1975.6312870},
  abstract = {This paper recommends the iterative enhancement' technique as a practical means of using a top-down, stepwise refinement approach to software development. This technique begins with a simple initial implementation of a property chosen (skeletal) subproject which is followed by the gradual enhancement of successive implementations in order to build the full implementation. The development and quantitative analysis of a production compiler for the language SIMPL-T is used to demonstrate that the application of iterative enhancement to software development is practical and efficient, encourages the generation of an easily modifiable product, and facilities reliability.},
  keywords = {iterative enhancement, SIMPL, software analysis, software development, software evaluation mesaures, top-down design},
  owner = {magsilva},
  timestamp = {2014.10.23}
}

@INPROCEEDINGS{Basili:1996,
  author = {Basili, Victor R.},
  title = {The Role of Experimentation in Software Engineering: Past, Current, and Future},
  crossref = {proceedings:icse:1996},
  pages = {442--449},
  doi = {10.1109/ICSE.1996.10002},
  abstract = {Software engineering needs to follow the model of other physical sciences and develop an experimental paradigm for the field. This paper proposes teh approach towards developing an experimental component fo such a paradigm. The approach is based upon a quality improvement paradigm that addresses the role of experimentation and process improvement in the context of industrial development. The paper outlines a classification scheme for characterizing such experiments.}
}

@INPROCEEDINGS{Basili:2006,
  author = {Basili, Victor R.},
  title = {The role of controlled experiments in software engineering research},
  crossref = {proceedings:dagstuhl:2006},
  pages = {33--37}
}

@INPROCEEDINGS{Basili:1992:EF,
  author = {Victor R. Basili},
  title = {The Experimental Paradigm in Software Engineering},
  crossref = {proceedings:iwdc:2006},
  pages = {3--12},
  series = {Lecture Notes in Computer Science},
  address = {London, UK},
  booktitle = {International Workshop on Experimental Software Engineering Issues: Critical Assessment and Future Directions},
  owner = {magsilva},
  publisher = {Springer-Verlag},
  timestamp = {2010.08.11},
  year = {1992}
}

@INPROCEEDINGS{Basili-Rombach:1987,
  author = {Basili, V. R. and Rombach, H. D.},
  title = {Tailoring the Software Process to Project Goals and Environments},
  crossref = {proceedings:icse:1987},
  pages = {345--357},
  abstract = {This paper presents a methodology for improving the software process by tailoring it to the specific project goals and environment. This improvement process is aimed at the global software process model as well as methods and tools supporting that model. The basic idea is to use defect profiles to help characterize the environment and evaluate the project goals and the effectiveness of methods and tools in a quantitative way. The improvement process is implemented iteratively by setting project improvement goals, characterizing those goals and the environment, in part, via defect profiles in a quantitative way, choosing methods and tools fitting those characteristics, evaluating the actual behavior of the chosen set of methods and tools, and refining the project goals based on the evaluation results. All these activities require analysis of large amounts of data and, therefore, support by an automated tool. Such a tool -- TAME (Tailoring A Measurement Environment) -- is currently being developed.},
  owner = {magsilva},
  timestamp = {2014.09.11}
}

@INPROCEEDINGS{Bates:2003,
  author = {Peter J. Bates},
  title = {Learning through {iDTV} - results of t-learning study},
  crossref = {proceedings:euroitv:2003},
  pages = {137--138},
  abstract = {This paper describes initial conclusions and recommendations of a major global study into the potential use of the various interactive TV solutions for increasing learning opportunities in the home. It describes why it is increasingly important for policy and decision makers to consider the role that interactive TV might have for learning -- if they are to meet targets for widening participation in learning. The final report due to be completed by the end of March 2003 will also help educationalists, IDTV developers and service providers understand which aspects of interactive TV are likely to be of most value for increasing learning opportunities in the home. Initial findings suggest the developments towards personalized TV are likely to be of more value than service offerings through broadcast/scheduled TV.},
  keywords = {elearning strategy, interactive TV, personalized TV, educational broadcasting}
}

@INPROCEEDINGS{Batista-etal:2010,
  author = {Carlos Eduardo C. F. Batista and Luiz Fernando Gomes Soares and Guido Lemos de Souza Filho.},
  title = {Estendendo o Uso das Classes de Dispositivos {Ginga-NCL}},
  crossref = {proceedings:webmedia:2010},
  pages = {27--34},
  abstract = {Aplicações de TV Digital podem utilizar recursos disponibilizados por dispositivos em redes domésticas (conhecidas como HAN - Home Area Network). Funcionalidades avançadas são trazidas para o ambiente de TV, visto que tais dispositivos podem oferecer recursos de visualização de objetos de mídia, múltiplos mecanismos de interação, entre outras funcionalidades. A linguagem NCL (Nested Context Language), que é a linguagem núcleo do middleware Ginga-NCL, possui mecanismos para a reprodução distribuída de suas aplicações, de forma que aplicações multiusuário possam ser desenvolvidas, eliminando assim o legado monousuário imposto pelo controle remoto. Através de um modelo hierárquico para distribuição de partes de uma aplicação e uma abstração para agrupar os dispositivos (as chamadas classes de dispositivos), é possível orquestrar a utilização de recursos providos pelos dispositivos conectados. Esse trabalho visa estender o modelo original proposto para o middleware Ginga-NCL, de forma a compatibilizá-lo com tecnologias usadas para integração dedispositivos, tais como UPnP e OSGi.},
  keywords = {NCL, Ginga, TV Digital, múltiplos dispositivos, HAN},
  abstract-en = {Digital TV applications are able to use the resources made available by the devices connected to the Digital TV receiver through a Home Area Network (HAN). That brings advanced features to the Digital TV environment, since such devices may offer media display resources, multiple interaction mechanisms, amongst other features. NCL (Nested Context Language), which is the core language of Ginga-NCL Digital TV middleware, is provided with mechanisms for the distributed reproduction of its applications, so that multiuser applications can be developed, redefining the single user/remote control relationship. Using a hierarchical model for the application distribution and an abstraction for grouping devices (called device classes), it is possible to orchestrate the usage of the resources provided by the connected devices. This work aims to extend the original model proposed for the Ginga-NCL middleware, so that it can be made compatible with the different technologies used for device integration, such as UPnP and OSGi.}
}

@ARTICLE{Battistella-Wangenheim:2011,
  author = {Paulo Eduardo Battistella and Aldo von Wangenheim},
  title = {Avaliação de Ferramentas de Autoria Gratuitas para produção de Objetos de Aprendizagem no padrão SCORM},
  crossref = {journal:rbie},
  volume = {19},
  number = {3},
  year = {2011},
  pages = {16-28},
  doi = {10.5753/RBIE.2011.19.03.16},
  abstract = {Este artigo apresenta a avaliação de um conjunto de seis ferramentas de autoria para produção de objetos de aprendizagem no padrão SCORM. As ferramentas são avaliadas de acordo com dois critérios: usabilidade e efetividade. A usabilidade é medida através da aplicação de dois métodos de avaliação heurística a cada uma das ferramentas após a produção de um objeto de aprendizagem com conteúdo pré-definido. A efetividade é medida através da avaliação da qualidade dos objetos de aprendizagem produzidos com cada ferramenta através da aplicação de uma terceira avaliação heurística específica. Para possibilitar uma avaliação comparativa tanto das ferramentas como dos objetos de aprendizagem produzidos, foi tomado um objeto de aprendizagem de referência, produzido profissionalmente no contexto de uma grande iniciativa de ensino à distância, que foi reproduzido o mais fielmente possível com cada uma das ferramentas. As ferramentas de autoria foram previamente sistematicamente selecionadas a partir de um universo de 14 ferramentas gratuitas.},
  keywords = {Ferramentas de Autoria, Objetos de Aprendizagem; Usabilidade; Efetividade},
  lang = {pt}
}

@INPROCEEDINGS{Baumstark-Rudolph:2013,
  author = {Baumstark, Lewis and Rudolph, Edwin},
  title = {Automated online grading for virtual machine-based systems administration courses},
  crossref = {proceedings:sigcse:2013},
  pages = {477--482},
  doi = {10.1145/2445196.2445340},
  abstract = {We present a system for automatically and iteratively grading student work in a Systems Administration course. This system can grade and give feedback regarding live (running) virtual machines the students have configured. It is appropriate for both face-to-face and online course offerings.},
  keywords = {automated grading, networking, online grading, systems administration, virtual machines}
}

@ARTICLE{Bazzan-Argenta:2011,
  author = {Bazzan, Ana L. C. and Argenta, V. F.},
  title = {Network of collaboration among {PC} members of {Brazilian} computer science conferences},
  crossref = {journal:springer:jbcs},
  volume = {17},
  number = {2},
  month = jun,
  year = {2011},
  pages = {133--139},
  doi = {10.1007/s13173-011-0033-7},
  abstract = {The structure, dynamics, and importance of the social network of collaboration among scientists has been already studied, sometimes yielding counter-intuitive conclusions. In this paper we investigate the role played by people who served as PC (Program Committee) members in the network formed by members of the Brazilian computer science community and their co-authors. Some characteristics of such network are compared with those reported in similar studies involving other scientific collaboration networks. As a result, we show that apart from the evidence of Milgram's phenomenon (six degrees of separation), there is no other community with completely similar patterns (among those used for comparison). This is probably due to the unique characteristics of the target network. For instance, their members do not necessarily interact with each other in terms of co-authorship since they belong to different sub-areas of computer science. There are strong evidences that the clusters in this network are connected by non-Brazilian members. Moreover, nodes with high degrees have little connection to Brazilian authors.},
  keywords = {Complex networks; Social networks}
}

@INPROCEEDINGS{Beaver-etal:2009,
  author = {Beaver, Justin M. and Cui, Xiaohui and St Charles, Jesse L. and Potok, Thomas E.},
  title = {Modeling success in {FLOSS} project groups},
  crossref = {proceedings:promise:2009},
  pages = {16:1--16:8},
  doi = {10.1145/1540438.1540461},
  abstract = {A significant challenge in software engineering is accurately modeling projects in order to correctly forecast success or failure. The primary difficulty is that software development efforts are complex in terms of both the technical and social aspects of the engineering environment. This is compounded by the lack of real data that captures both the measures of success in performing a process, and the measures that reflect a group's social dynamics. This research focuses on the development of a model for predicting software project success that leverages the wealth of available open source project data in order to accurately forecast the behavior of those software engineering groups. The model accounts for both the technical elements of software engineering and the social elements that drive the decisions of individual developers. Agent-based simulations are used to represent the complexity of the group interactions, and the behavior of each agent is based on the acquired open source software engineering data. For four of the five project success measures, the results indicate that the developed model represents the underlying data well and provides accurate predictions of open source project success indicators.},
  keywords = {Bayesian belief networks, FLOSS, agent-based simulation, data-based models, software engineering}
}

@ARTICLE{Kent:2001,
  author = {Beck, K.},
  title = {Aim, fire},
  crossref = {journal:ieee:software},
  volume = {18},
  number = {5},
  month = sep # {--} # oct,
  year = {2001},
  pages = {87--89},
  doi = {10.1109/52.951502},
  abstract = {The author argues that test-first coding is not testing. Test-first coding is not new. It is nearly as old as programming. It is an analysis technique. We decide what we are programming and what we are not programming, and we decide what answers we expect. Test-first is also a design technique}
}

@INPROCEEDINGS{Beck-Cunningham:1989,
  author = {Beck, K. and Cunningham, W.},
  title = {A laboratory for teaching object oriented thinking},
  crossref = {proceedings:oopsla:1989},
  pages = {1--6},
  doi = {10.1145/74877.74879},
  abstract = {It is difficult to introduce both novice and experienced procedural programmers to the anthropomorphic perspective necessary for object-oriented design. We introduce CRC cards, which characterize objects by class name, responsibilities, and collaborators, as a way of giving learners a direct experience of objects. We have found this approach successful in teaching novice programmers the concepts of objects, and in introducing experienced programmers to complicated existing designs.}
}

@INPROCEEDINGS{Becker-etal:2011,
  author = {Henrique Becker and Vitor Malaggi and Adriano C. Teixeira and Marco Antônio S. Trentin},
  title = {Projeto {Guri}: software de autoria colaborativa de materiais educacionais hipermídia para a TV Digital},
  crossref = {proceedings:sbie:2011},
  pages = {848--851},
  abstract = {O presente artigo tem como objetivo descrever o processo de desenvolvimento de um software de autoria colaborativa que proporcione aos professores, alunos e demais seres sociais envolvidos nos processos de ensino-aprendizagem escolares a possibilidade de produção de materiais educativos hipermídia para a TV Digital. Por meio da descrição dos aspectos técnicos e educacionais, os quais partem da relação interdisciplinar entre as áreas da Informática, Comunicação e Educação, torna-se possível delinear o progresso atual da pesquisa em torno do desenvolvimento deste software, denominado Guri.},
  abstract-en = {The present article aims to describe the development process of a collaborative authorship software, which provides to teachers, students and other social beings involved in the school teaching-learning process the possibility of hypermedia educational content production to the Digital TV. By describing the technical and educational aspects, which initiate at the interdisciplinary relation among the Computing, Communication and Education areas, it becomes possible to delineate the present research progress around the development of this software, named Guri.}
}

@INPROCEEDINGS{Becker-etal:2006,
  author = {Valdecir Becker and Augusto Fornari and Günter H. Herweg Filho and Carlos Montez},
  title = {Recomendações de Usabilidade para TV Digital Interativa},
  crossref = {proceedings:wtvd:2006},
  pages = {1--12},
  abstract = {O presente trabalho apresenta estudos teóricos sobre usabilidade, efetuados pelo Núcleo de Redes de Alta Velocidade e Computação de Alto Desempenho (Nurcad). Além de apresentar propostas concretas para implementação de aplicações interativas para televisão digital, traz-se também um acompanhamento do que já foi feito de mais relevante sobre o tema e um Portal de Usabilidade, onde são demonstrados os conceitos utilizados.},
  abstract-en = {This work presents theoretical studies about usability developed on the Núcleo de Redes de Alta Velocidade e Computação de Alto Desempenho (Nurcad). Presents too some proposes for develop interactive applications for digital TV. Three is showed too some examples of what already is done in this area and one Usability Portal, where de used concepts are presented.}
}

@INPROCEEDINGS{Beecher-etal:2007,
  author = {Karl Beecher and Cornelia Boldyreff and Andrea Capiluppi and Stephen Rank},
  title = {Evolutionary Success of Open Source Software: an Investigation into Exogenous Drivers},
  crossref = {proceedings:ess:2007},
  pages = {1--14},
  abstract = {The success of a Free/Libre/Open Source Software (FLOSS) project has often been evaluated through the number of commits made to its configuration management system, number of developers and number of users. Based on SourceForge, most studies have concluded that the vast majority of projects are failures. This paper argues that the relative success of a FLOSS project can depend also on the chosen forge and distribution. Given a random sample of 50 projects contained within a popular FLOSS forge (Debian, which is the basis of the successful Debian distribution), we compare these with a similar sample from SourceForge, using product and process metrics, such as size achieved and number of developers involved. The results show firstly that, depending on the forge of FLOSS projects, researchers can draw different conclusions regarding what constitutes a successful FLOSS project. Secondly, the projects included in the Debian distribution benefit, on average, from more evolutionary activity and more developers than the comparable projects on SourceForge. Finally, the Debian projects start to benefit from more activity and more developers from the point at which they join this distribution.},
  keywords = {FLOSS, repositories, metrics, success, evolvability},
  volume = {8},
  owner = {magsilva},
  timestamp = {2014.05.29}
}

@ARTICLE{Begel-etal:2013,
  author = {Begel, A. and Bosch, J. and Storey, Margareth A.},
  title = {Social Networking Meets Software Development: Perspectives from GitHub, MSDN, Stack Exchange, and TopCoder},
  crossref = {journal:ieee:software},
  volume = {30},
  number = {1},
  month = jan # {--} # feb,
  year = {2013},
  pages = {52--66},
  doi = {10.1109/MS.2013.13},
  abstract = {Many successful software companies use social networking as a way to improve the services or products they provide. To gain an understanding of the role social networking plays in today's software development world, the guest editors of the January/February 2013 issue conducted semistructured interviews with leaders from four successful companies: Brian Doll, an engineer who manages GitHub's marketing; Doug Laundry, a principal group program manager at Microsoft; David Fullerton, vice president of engineering at Stack Exchange; and Robert Hughes, the president and chief operating officer of TopCoder. The first Web extra at http://try.github.com is a video of Joel Spolsky discussing the structure, software, technology, and culture of Stack Exchange. The second Web extra at http://blip.tv/play/gvUBgqLbRgI.html is a video of Matthew McCullough and Tim Berglund demonstrating how Git not only incorporates the best features of existing source control systems but also includes unique distributed capabilities that make version control commands available without connectivity, allowing you to choose when to interact with a network. The third Web extra at http://blip.tv/play/gvUBgqLbRgI.html is a video of Matthew McCullough and Tim Berglund demonstrating how to leverage Git's powerful yet underused advanced features. The last Web extra at http://youtu.be/SK6TBI1bNLI is a video of Thomas Baden, Chief Information Officer, State of Minnesota, Department of Human Services, describing the experience of working on the TopCoder Platform and with the members of the TopCoder Community.},
  keywords = {Github , Microsoft , Stack Exchange , TopCoder , community , social networking , software}
}

@INPROCEEDINGS{6142852,
  author = {Begosso, L.R. and Begosso, L.C. and de Souza Poletto, A.S.R. and de Lima, F.C. and Sanches da Cunha, D.},
  title = {Work in progress -- Software residency: A contribution for professional maturity},
  crossref = {proceedings:fie:2011},
  pages = {S4B-1-S4B-2},
  doi = {10.1109/FIE.2011.6142852},
  abstract = {Preparing and qualifying the Computer Science students to meet the software industry needs is a growing challenge for academia. This task is about maturing the future professional with good practices of software development, increasingly demanded by software industry. This work aims to present the process of implementing a software residency program for undergraduate Computer Science course, which we call ``Software Residency Program'', and is being implemented since the beginning of the academic year 2010. This program provides an environment for undergraduate students to experience real software development, following standards and rules established by the software industry. We describe the methodology adopted to implement the process and some initial results we have collected from the students who are in the program. Currently, the Software Residency Program has entered its final phase, and is scheduled to be completed in the month of May 2011, finishing the process of Software Residency, when results will be evaluated by all the stakeholders.},
  keywords = {professional maturity, software engineering, software residency, undergraduate course}
}

@ARTICLE{Benediktsson-etal:2006,
  author = {Benediktsson, O. and Dalcher, D. and Thorbergsson, H.},
  title = {Comparison of software development life cycles: a multiproject experiment},
  crossref = {journal:ieee:proceedings},
  volume = {153},
  number = {3},
  month = jun,
  year = {2006},
  pages = {87-101},
  abstract = {A variety of life cycle models for software development are generally available. Many of the variations were composed to overcome problems in the classic waterfall model. However, it is generally difficult to compare and contrast the methods and very little literature is available to guide developers and managers in making choices. Moreover, in order to make informed decisions, developers require access to real data that compares the different models and the results associated with the adoption of each model. An experiment in which 15 software teams developed comparable software products, using four different development approaches (V-model, incremental model, evolutionary model, and extreme programming), is described. Extensive measurements were taken to assess the time, quality, size, and development efficiency of each product. The experimental data collected and the conclusions related to the choice of method, its impact on the project and the quality of the results, are presented.},
  issn = {1462-5970},
  journal = {Software, IEE Proceedings -},
  owner = {magsilva},
  timestamp = {2014.10.23}
}

@INPROCEEDINGS{Beni-etal:2011,
  author = {Leandro Baldacim Beni and Thiago Bianchi and Jose Carlos Maldonado and Elisa Yumi Nakagawa},
  title = {Memória Virtual: Definição e Implementação da Arquitetura},
  crossref = {proceedings:siicusp:2011},
  pages = {1--1}
}

@INPROCEEDINGS{Benington:1987,
  author = {Benington, Herbert D.},
  title = {Production of Large Computer Programs},
  crossref = {proceedings:icse:1987},
  pages = {299--310},
  abstract = {The paper is adapted from a presentation at a symposium on advanced programming methods for digital computers sponsored by the Navy Mathematical Computing Advisory Panel and the Office of Naval Research in June 1956. The author describes the techniques used to produce the programs for the Semi-Automatic Ground Environment (SAGE) system.},
  owner = {magsilva},
  reprint-of = {Benington:1983},
  timestamp = {2014.10.21}
}

@ARTICLE{Benington:1983,
  author = {Benington, Herbert D.},
  title = {Production of Large Computer Programs},
  crossref = {proceedings:ieee:history-computing},
  volume = {5},
  number = {4},
  month = oct,
  year = {1983},
  pages = {350--361},
  doi = {10.1109/MAHC.1983.10102},
  abstract = {The paper is adapted from a presentation at a symposium on advanced programming methods for digital computers sponsored by the Navy Mathematical Computing Advisory Panel and the Office of Naval Research in June 1956. The author describes the techniques used to produce the programs for the Semi-Automatic Ground Environment (SAGE) system.},
  keywords = {design, management, Lincoln Laboratory, SAGE, software, systems},
  owner = {magsilva},
  timestamp = {2014.10.21}
}

@ARTICLE{Berliner-Ruparelia:2010,
  author = {Berliner, Brian and Ruparelia, Nayan B.},
  title = {Early days of {CVS}},
  crossref = {journal:acm:sen},
  volume = {35},
  number = {5},
  month = oct,
  year = {2010},
  pages = {5--6},
  doi = {10.1145/1838687.1838689},
  abstract = {The topic of this article is to discuss the early days of CVS, from the late 1980s to the mid 1990s. First, a timeline depicting key milestones for those early days is discussed and this is followed by an interview with Brian Berliner, the creator of CVS in C. This article concludes with a reading list on CVS for further study.},
  keywords = {CVS, SEN, history column, subversion}
}

@ARTICLE{Bernhaupt-etal:2007,
  author = {Bernhaupt, Regina and Obrist, Marianna and Tscheligi, Manfred},
  title = {Usability and usage of {iTV} services: lessons learned in an {Austrian} field trial},
  crossref = {journal:acm:cie},
  volume = {5},
  number = {2},
  month = apr,
  year = {2007},
  pages = {1--14},
  doi = {10.1145/1279540.1279546},
  abstract = {How users experience interactive TV (iTV) is determined by various factors; usability is a major one. In industry, usability is often seen as the key element that determines acceptance of new technologies by users. We present some of the results of an MHP-based (Multimedia Home Platform) iTV field trial in Salzburg, Austria concerning usability issues and iTV usage. We give an introduction to the field trial and an overview of its methods to ensure usability of iTV services and to measure their use. We present results from a usability test, give design recommendations, and discuss whether using iTV is an active or a passive user experience.},
  keywords = {MHP, iTV services, interactivity, usability issues}
}

@ARTICLE{bertolino-etal:2011,
  author = {Antonia Bertolino and Guglielmo De Angelis and Alessio Di Sandro and Antonino Sabetta},
  title = {Is my model right? Let me ask the expert},
  crossref = {journal:elsevier:jss},
  volume = {84},
  number = {7},
  year = {2011},
  pages = {1089--1099},
  doi = {10.1016/j.jss.2011.01.054},
  abstract = {Defining a domain model is a costly and error-prone process. It requires that the knowledge possessed by domain experts be suitably captured by modeling experts. Eliciting what is in the domain expert's mind and expressing it using a modeling language involve substantial human effort. In the process, conceptual errors may be introduced that are hard to detect without a suitable validation methodology. This paper proposes an approach to support such validation, by reducing the knowledge gap that separates modeling experts and domain experts. While our methodology still requires the domain expert's judgement, it partially automates the validation process by generating a set of yes/no questions from the model. Answers differing from expected ones point to elements in the model which require further consideration and can be used to guide the dialogue between domain experts and modeling experts. Our methodology was implemented as a tool and was applied to a real case study, within the IPERMOB project.},
  keywords = {Model validation}
}

@ARTICLE{Bettenburg-Hassan:2013,
  author = {Bettenburg, Nicolas and Hassan, Ahmed E.},
  title = {Studying the impact of social interactions on software quality},
  crossref = {journal:springer:ese},
  volume = {18},
  number = {2},
  month = apr,
  year = {2013},
  pages = {375-431},
  doi = {10.1007/s10664-012-9205-0},
  abstract = {Correcting software defects accounts for a significant amount of resources in a software project. To make best use of testing efforts, researchers have studied statistical models to predict in which parts of a software system future defects are likely to occur. By studying the mathematical relations between predictor variables used in these models, researchers can form an increased understanding of the important connections between development activities and software quality. Predictor variables used in past top-performing models are largely based on source code-oriented metrics, such as lines of code or number of changes. However, source code is the end product of numerous interlaced and collaborative activities carried out by developers. Traces of such activities can be found in the various repositories used to manage development efforts. In this paper, we develop statistical models to study the impact of social interactions in a software project on software quality. These models use predictor variables based on social information mined from the issue tracking and version control repositories of two large open-source software projects. The results of our case studies demonstrate the impact of metrics from four different dimensions of social interaction on post-release defects. Our findings show that statistical models based on social information have a similar degree of explanatory power as traditional models. Furthermore, our results demonstrate that social information does not substitute, but rather augments traditional source code-based metrics used in defect prediction models.},
  keywords = {Human factors; Software evolution; Metrics/measurement; Software quality assurance}
}

@ARTICLE{Bettio-etal:2013,
  author = {Raphael Winckler de Bettio and Denilson Alves Pereira and Ronei Ximenes Martins and Tales Heimfarth},
  title = {The Experience of Using the {Scrum} Process in the Production of Learning Objects for Blended Learning},
  crossref = {journal:imi:ie},
  volume = {12},
  number = {1},
  year = {2013},
  pages = {29--41},
  abstract = {The technological resources used for pedagogical innovation in the form of distance education have increasingly been incorporated into face-to-face education. This article describes the experience of the Federal University of Lavras - Brazil - with new ways to apply technology in face-to-face undergraduate courses. This paper presents (i) the strategy for the selection of course content, which was premised on the diversification of areas of knowledge and on promoting the permanent incorporation of the resources developed in the teaching-learning process, (ii) the organization of the production process of Learning Objects based on the Scrum method, (iii) the set of best practices, inspired by the management of agile software development, as well as the contextual motivation of its use.},
  keywords = {learning objects, digital educational production, scrum},
  timestamp = {2014-01-02}
}

@INPROCEEDINGS{Beydeda-Gruhn:2001,
  author = {Beydeda, Sami and Gruhn, Volker},
  title = {An integrated testing technique for component-based software},
  crossref = {proceedings:iccsa:2001},
  pages = {328-334},
  doi = {10.1109/AICCSA.2001.934006},
  abstract = {The main idea of component-based development is to use existing components for building software. The resulting software often has features which complicate testing, such a feature is, for example, the absence of component source code. This article proposes an approach for testing, which explicitly takes into account testing-relevant features of component-based software and thus allows more rigorous testing. The basic constituent of the approach is a graphical representation combining black- and white-box information from specification and implementation, respectively. This graphical representation can then be used for test case identification based on well-known structural techniques},
  timestamp = {2013-09-14}
}

@INPROCEEDINGS{Bezerra-etal:2012,
  author = {Bezerra, Diogo Henrique Duarte and Sousa, Denio Mariz Tim\'{o}teo and Filho, Guido Lemos de Souza and Burlamaqui, Aquiles Medeiros Filgueira and Silva, Igor Rosberg Medeiros},
  title = {Luar: a language for agile development of {NCL} templates and documents},
  crossref = {proceedings:webmedia:2012},
  pages = {395--402},
  doi = {10.1145/2382636.2382718},
  abstract = {In the application's development described in NCL language, we have observed the reuse of some models and document structures, which is possible by repetition of common codes on applications. Thus, we do visualize the need to generalize this kind of development described in NCL. This need has been observed by other developers who are aiming at the possibility of the reuse of structure from some documents. This paper introduces Luar, an authoring language for NCL templates. The Luar language has been conceived through analysis of the applications' behavior for iDTV. Luar has a templates's processor developed with the Lua language and library to maintain and to aggregating template collections, sharing them among developers. The entire template system aims to facilitate the design and development of interactive applications described in NCL using the technique of reuse.},
  keywords = {ITU-T H.761, hypermedia authoring, luar, nested context language, reuse, template engine}
}

@INPROCEEDINGS{biddle-etal:2002,
  author = {Biddle, Robert and Noble, James and Tempero, Ewan},
  title = {Reflections on {CRC} cards and {OO} design},
  crossref = {proceedings:crpit:2002},
  pages = {201--205},
  abstract = {We recently had the opportunity to introduce object-oriented design to a number of teams, and used CRC cards as one of the key techniques. The team members had varied backgrounds, and we had the opportunity to observe many teams tackle the same design exercises. This allowed us the opportunity to observe the effectiveness of the CRC cards, and reflect on the strengths and weaknesses. This paper documents our observations and reflections, and presents our advice on the strengths of the technique, and strategies we found useful for addressing the weaknesses.},
  timestamp = {2013-08-01}
}

@INPROCEEDINGS{Biddle-etal:2002,
  author = {Biddle, Robert and Noble, James and Tempero, Ewan},
  title = {Essential use cases and responsibility in object-oriented development},
  crossref = {proceedings:acsc:2002},
  pages = {7--16},
  doi = {10.1145/563857.563803},
  abstract = {Essential use cases are abstract, lightweight, technology-free dialogues of user intention and system responsibility that effectively capture requirements for user interface design. We describe how essential use cases can also drive object-oriented development directly, without any intervening translation, and allowing user interface development and object-oriented development to proceed in parallel. Working with essential use cases yields some unexpected further benefits: the crucial common vocabulary of responsibilities lets designers trace directly from the essential use cases to the objects in their design.},
  keywords = {object-oriented analysis, object-oriented design, traceability, use cases},
  timestamp = {2013-08-01}
}

@ARTICLE{Biewald:2010,
  author = {Biewald, Lukas},
  title = {Massive multiplayer human computation for fun, money, and survival},
  crossref = {journal:acm:xrds},
  volume = {17},
  number = {2},
  month = dec,
  year = {2010},
  pages = {10--15},
  doi = {10.1145/1869086.1869093},
  abstract = {Labor-on-demand---it's like cloud computing but with human workers.}
}

@ARTICLE{Biolchini-etal:2007,
  author = {Biolchini, Jorge Calmon de Almeida and Mian, Paula Gomes and Natali, Ana Candida Cruz and Conte, Tayana Uchôa and Travassos, Guilherme Horta},
  title = {Scientific research ontology to support systematic review in software engineering},
  crossref = {journal:elsevier:aei},
  volume = {21},
  number = {2},
  month = apr,
  year = {2007},
  pages = {133--151},
  doi = {10.1016/j.aei.2006.11.006},
  abstract = {The term systematic review is used to refer to a specific methodology of research, developed in order to gather and evaluate the available evidence pertaining to a focused topic. It represents a secondary study that depends on primary study results to be accomplished. Several primary studies have been conducted in the field of Software Engineering in the last years, determining an increasing improvement in methodology. However, in most cases software is built with technologies and processes for which developers have insufficient evidence to confirm their suitability, limits, qualities, costs, and inherent risks. Conducting systematic reviews in Software Engineering consists in a major methodological tool to scientifically improve the validity of assertions that can be made in the field and, as a consequence, the reliability degree of the methods that are employed for developing software technologies and supporting software processes. This paper aims at discussing the significance of experimental studies, particularly systematic reviews, and their use in supporting software processes. A template designed to support systematic reviews in Software Engineering is presented, and the development of ontologies to describe knowledge regarding such experimental studies is also introduced.},
  keywords = {Experimental software engineering; Systematic review; Experimental study; Ontology; Scientific method}
}

@INPROCEEDINGS{Bird:2011,
  author = {Bird, Christian},
  title = {Sociotechnical coordination and collaboration in open source software},
  crossref = {proceedings:icsm:2011},
  pages = {568--573},
  doi = {10.1109/ICSM.2011.6080832},
  abstract = {In the mid 90s, a new style of software development, termed open source software (OSS) has emerged and has originated large, mature, stable, and widely used software projects. As software continues to grow in size and complexity, so do development teams. Consequently, coordination and communication within these teams play larger roles in productivity and software quality. My dissertation focuses on the relationships between developers in large open source projects and how software affects and is affected by these relationships. Fortunately, source code repository histories, mailing list archives, and bug databases from OSS projects contain latent data from which we can reconstruct a rich view of a project over time and analyze these sociotechnical relationships. We present methods of obtaining and analyzing this data as well as the results of empirical studies whose goal is to answer questions that can help stakeholders understand and make decisions about their own teams. We answer questions such as "Do large OSS project really have a disorganized bazaar-like structure?" "What is the relationship between social and development behavior in OSS?" "How does one progress from a project newcomer to a full-fledged, core developer?" and others in an attempt to understand how large, successful OSS projects work and also to contrast them with projects in commercial settings.}
}

@INPROCEEDINGS{Bird-etal:2006,
  author = {Bird, Christian and Gourley, Alex and Devanbu, Prem and Gertz, Michael and Swaminathan, Anand},
  title = {Mining email social networks},
  crossref = {proceedings:msr:2006},
  pages = {137--143},
  doi = {10.1145/1137983.1138016},
  abstract = {Communication & Co-ordination activities are central to large software projects, but are difficult to observe and study in traditional (closed-source, commercial) settings because of the prevalence of informal, direct communication modes. OSS projects, on the other hand, use the internet as the communication medium,and typically conduct discussions in an open, public manner. As a result, the email archives of OSS projects provide a useful trace of the communication and co-ordination activities of the participants. However, there are various challenges that must be addressed before this data can be effectively mined. Once this is done, we can construct social networks of email correspondents, and begin to address some interesting questions. These include questions relating to participation in the email; the social status of different types of OSS participants; the relationship of email activity and commit activity (in the CVS repositories) and the relationship of social status with commit activity. In this paper, we begin with a discussion of our infrastructure (including a novel use of Scientific Workflow software) and then discuss our approach to mining the email archives; and finally we present some preliminary results from our data analysis.},
  keywords = {open source, social networks}
}

@INPROCEEDINGS{Bird-etal2009,
  author = {Bird, Christian and Rigby, Peter C. and Barr, Earl T. and Hamilton, David J. and German, Daniel M. and Devanbu, Prem},
  title = {The promises and perils of mining git},
  crossref = {proceedings:msr:2009},
  pages = {1--10},
  doi = {10.1109/MSR.2009.5069475},
  abstract = {We are now witnessing the rapid growth of decentralized source code management (DSCM) systems, in which every developer has her own repository. DSCMs facilitate a style of collaboration in which work output can flow sideways (and privately) between collaborators, rather than always up and down (and publicly) via a central repository. Decentralization comes with both the promise of new data and the peril of its misinterpretation. We focus on git, a very popular DSCM used in high-profile projects. Decentralization, and other features of git, such as automatically recorded contributor attribution, lead to richer content histories, giving rise to new questions such as 'How do contributions flow between developers to the official project repository?' However, there are pitfalls. Commits may be reordered, deleted, or edited as they move between repositories. The semantics of terms common to SCMs and DSCMs sometimes differ markedly, potentially creating confusion. For example, a commit is immediately visible to all developers in centralized SCMs, but not in DSCMs. Our goal is to help researchers interested in DSCMs avoid these and other perils when mining and analyzing git data.}
}

@ARTICLE{Blahut-etal:1995,
  author = {Blahut, Donald E. and Nichols, Texas E. and Schell, William M. and Story, Guy A. and Szurkowski, Edward S.},
  title = {Interactive television},
  crossref = {journal:ieee:proceedings},
  volume = {83},
  number = {7},
  month = jul,
  year = {1995},
  pages = {1071--1085},
  doi = {10.1109/5.390124},
  abstract = {Interactive television (ITV) is a new form of residential consumer video service that gives viewers far greater control over the contents of programs than is possible with conventional television. There are substantial technical challenges to offering a ITV service on a large scale, both in content creation and delivery. The paper discusses those challenges and presents a new system architecture for offering ITV, along with a broad range of other interactive video services, to consumers in their homes. A new suite of tools to simplify the creation of compelling interactive programming is also described.}
}

@ARTICLE{Blair-etal:2011,
  author = {Blair, Gordon and Kon, Fabio and Cirne, Walfredo and Milojicic, Dejan and Ramakrishnan, Raghu and Reed, Dan and Silva, Dilma},
  title = {Perspectives on cloud computing: interviews with five leading scientists from the cloud community},
  crossref = {journal:springer:jisa},
  volume = {2},
  number = {1},
  month = jul,
  year = {2011},
  pages = {3--9},
  doi = {10.1007/s13174-011-0023-1},
  abstract = {Abstract Cloud computing is currently one of the major topics in distributed systems, with large numbers of papers being written on the topic, with major players in the industry releasing a range of software platforms offering novel Internet-based services and, most importantly, evidence of real impact on end user communities in terms of approaches to provisioning software services. Cloud computing though is at a formative stage, with a lot of hype surrounding the area, and this makes it difficult to see the true contribution and impact of the topic. Cloud computing is a central topic for the Journal of Internet Services and Applications (JISA) and indeed the most downloaded paper from the first year of JISA is concerned with the state-of-the-art and research challenges related to cloud computing. The Editors-in-Chief, Fabio Kon and Gordon Blair, therefore felt it was timely to seek clarification on the key issues around cloud computing and hence invited five leading scientists from industrial organizations central to cloud computing to answer a series of questions on the topic.}
}

@INCOLLECTION{Blum:2006,
  author = {Bruce Blum},
  title = {Torn between Fun and Tedium},
  chapter = {9.1},
  pages = {298--303},
  crossref = {Glass:2006}
}

@ARTICLE{Blum:1967,
  author = {Blum, Manuel},
  title = {A Machine-Independent Theory of the Complexity of Recursive Functions},
  crossref = {journal:acm},
  volume = {14},
  number = {2},
  month = apr,
  year = {1967},
  pages = {322--336},
  doi = {10.1145/321386.321395},
  abstract = {The number of steps required to compute a function depends, in general, on the type of computer that is used, on the choice of computer program, and on the input-output code. Nevertheless, the results obtained in this paper are so general as to be nearly independent of these considerations. A function is exhibited that requires an enormous number of steps to be computed, yet has a 'nearly quickest' program: Any other program for this function, no matter how ingeniously designed it may be, takes practically as many steps as this nearly quickest program. A different function is exhibited with the property that no matter how fast a program may be for computing this function another program exists for computing the function very much faster.},
  acmid = {321395},
  issue = {2},
  numpages = {15}
}

@ARTICLE{BobericKrsticev-Tesendic:2013,
  author = {Danijela Boberic-Krsticev and Danijela Tesendic},
  title = {Experience in Teaching {OOAD} to Various Students},
  crossref = {journal:imi:ie},
  volume = {12},
  number = {1},
  year = {2013},
  pages = {43--58},
  abstract = {The paper elaborates on experiences and lessons learned from the course on object-oriented analyses and design at the Faculty of Sciences, Novi Sad. The course on OOAD is taught to students of computer science and to the students of mathematical programme. Conclusions made in this paper are based on results of students' assignments as well as results of conducted survey. In the paper we identify a set of issues concerning teaching modelling and UML. It is noticed that difficulties in mastering OOAD arise primarily from the absence of appropriate real case studies from the field of designing information systems. In order to overcome this problem, students worked on their own homework projects which include all phases of software development. Concerning the results of survey it is noticed that OOAD course should be taught in different manners regarding previous knowledge of students. Suggestions how to teach OOAD to students of computer science and to students of other programmes are given in this paper.},
  keywords = {OOAD, UML, teaching, modelling},
  timestamp = {2014-01-02}
}

@INPROCEEDINGS{Boehm:2006:ICSE,
  author = {Boehm, Barry},
  title = {A view of 20th and 21st century software engineering},
  crossref = {proceedings:icse:2006},
  pages = {12--29},
  doi = {10.1145/1134285.1134288},
  abstract = {George Santayana's statement, ``Those who cannot remember the past are condemned to repeat it,'' is only half true. The past also includes successful histories. If you haven't been made aware of them, you're often condemned not to repeat their successes.In a rapidly expanding field such as software engineering, this happens a lot. Extensive studies of many software projects such as the Standish Reports offer convincing evidence that many projects fail to repeat past successes.This paper tries to identify at least some of the major past software experiences that were well worth repeating, and some that were not. It also tries to identify underlying phenomena influencing the evolution of software engineering practices that have at least helped the author appreciate how our field has gotten to where it has been and where it is.A counterpart Santayana-like statement about the past and future might say, "In an era of rapid change, those who repeat the past are condemned to a bleak future." (Think about the dinosaurs, and think carefully about software engineering maturity models that emphasize repeatability.)This paper also tries to identify some of the major sources of change that will affect software engineering practices in the next couple of decades, and identifies some strategies for assessing and adapting to these sources of change. It also makes some first steps towards distinguishing relatively timeless software engineering principles that are risky not to repeat, and conditions of change under which aging practices will become increasingly risky to repeat.},
  keywords = {software engineering, software futures, software history}
}

@ARTICLE{Boehm:2006:SYS,
  author = {Boehm, Barry},
  title = {Some Future Trends and Implications for Systems and Software Engineering Processes},
  crossref = {journal:wiley:sys},
  volume = {9},
  number = {1},
  month = jan,
  year = {2006},
  pages = {1--19},
  doi = {10.1002/sys.v9:1},
  abstract = {In response to the increasing criticality of software within systems and the increasing demands being put onto 21st century systems, systems and software engineering processes will evolve significantly over the next two decades. This paper identifies eight relatively surprise-free trends -- the increasing interaction of software engineering and systems engineering; increased emphasis on users and end value; increased emphasis on systems and software dependability; increasingly rapid change; increasing global connectivity and need for systems to interoperate; increasingly complex systems of systems; increasing needs for COTS, reuse, and legacy systems and software integration; and computational plenty. It also identifies two wild card trends: increasing software autonomy and combinations of biology and computing. It then discusses the likely influences of these trends on systems and software engineering processes between now and 2025, and presents an emerging scalable spiral process model for coping with the resulting challenges and opportunities of developing 21st century software-intensive systems and systems of systems.},
  keywords = {future trends, human systems integration, software engineering, spiral model, systems acquisition, systems architecting, systems engineering, systems of systems, value-based processes},
  owner = {magsilva},
  timestamp = {2014.09.25}
}

@ARTICLE{Boehm:1996,
  author = {Boehm, Barry},
  title = {Anchoring the Software Process},
  crossref = {journal:ieee:software},
  volume = {13},
  number = {4},
  month = jul,
  year = {1996},
  pages = {73--82},
  doi = {10.1109/52.526834},
  abstract = {For a few golden moments in the mid-'70s, it appeared that the software field had found a sequence of milestones around which people couldplan, organize, monitor, and control their projects. These were the milestones in the waterfall model. They typically included the completion of system requirements, software requirements, preliminary design, detailed design, code, unit test, software acceptance test, and system acceptance test.Unfortunately, just as the waterfall model was becoming fully elaborated, people were finding that its milestones did not fit an increasing number of project situations. The risk-driven content of the three milestones proposed in this article let you tailor them to specific software situations, and at the same time they remain general enough to apply to most software projects.}
}

@ARTICLE{Boehm:1987,
  author = {Barry Boehm},
  title = {Improving Software Productivity},
  crossref = {journal:ieee:computer},
  volume = {20},
  number = {9},
  month = sep,
  year = {1987},
  pages = {43--57},
  doi = {10.1109/MC.1987.1663694},
  owner = {magsilva},
  timestamp = {2009.07.08}
}

@INPROCEEDINGS{Boehm-Lane:2010,
  author = {Boehm, Barry and Lane, Jo Ann},
  title = {New Processes for New Horizons: The Incremental Commitment Model},
  crossref = {proceedings:icse:2010},
  pages = {501--502},
  doi = {10.1145/1810295.1810450},
  abstract = {The wide variety of software-intensive systems needed to support the new horizons of evolving technology, system and software complexity, high dependability, global interoperability, emergent requirements, and adaptability to rapid change make traditional and current one-size-fits-all process models infeasible. This tutorial presents the process framework, principles, practices, and case studies for a new model developed and being used to address these challenges. It has a series of risk-driven decision points that enable projects to converge on whatever combination of agile, plan-driven, formal, legacy-oriented, reuse-oriented, or adaptive processes that best fit a project's situation. The tutorial discusses the decision table for common special cases; exit ramps for terminating non-viable projects; support of concurrent engineering of requirements, solutions and plans; and evidence-based commitment milestones for synchronizing the concurrent engineering. The tutorial will include case studies and exercises for participants' practice and discussion.},
  keywords = {feasibility evidence, hardware-software-human factors integration, incremental commitment model, risk management},
  series = {ICSE '10},
  acmid = {1810450},
  address = {New York, NY, USA},
  booktitle = {Proceedings of the 32Nd ACM/IEEE International Conference on Software Engineering - Volume 2},
  isbn = {978-1-60558-719-6},
  location = {Cape Town, South Africa},
  numpages = {2},
  owner = {magsilva},
  publisher = {ACM},
  timestamp = {2014.10.23},
  url = {http://doi.acm.org/10.1145/1810295.1810450},
  year = {2010}
}

@ARTICLE{Boehm:1988,
  author = {Boehm, B. W.},
  title = {A spiral model of software development and enhancement},
  crossref = {journal:ieee:computer},
  volume = {21},
  number = {5},
  month = may,
  year = {1988},
  pages = {61--72},
  doi = {10.1109/2.59},
  abstract = {A short description is given of software process models and the issues they address. An outline is given of the process steps involved in the spiral model, an evolving risk-driven approach that provides a framework for guiding the software process, and its application to a software project is shown. A summary is given of the primary advantages and implications involved in using the spiral model and the primary difficulties in using it at its current incomplete level of elaboration.},
  keywords = {enhancement;risk-driven approach;software development;software process models;spiral model;software engineering}
}

@ARTICLE{Boehm:1986,
  author = {Boehm, Barry W.},
  title = {A spiral model of software development and enhancement},
  crossref = {journal:acm:sen},
  volume = {11},
  number = {4},
  month = aug,
  year = {1986},
  pages = {14--24},
  doi = {10.1145/12944.12948}
}

@ARTICLE{Boehm:1976,
  author = {Boehm, B. W.},
  title = {Software Engineering},
  crossref = {journal:ieee:tc},
  volume = {C-25},
  number = {12},
  month = dec,
  year = {1976},
  pages = {1226--1241},
  doi = {10.1109/TC.1976.1674590},
  abstract = {This paper provides a definition of the term "software engineering" and a survey of the current state of the art and likely future trends in the field. The survey covers the technology available in the various phases of the software life cycle -- requirements engineering, design, coding, test, and maintenance -- and in the overall area of software management and integrated technology-management approaches. It is oriented primarily toward discussing the domain of applicability of techniques (where and when they work), rather than how they work in detail. To cover the latter, an extensive set of 104 references is provided.},
  keywords = {Computer software, data systems, information systems, research and development, software development, software engineering, software management},
  issn = {0018-9340},
  owner = {magsilva},
  timestamp = {2014.10.23}
}

@INPROCEEDINGS{Boehm-Sullivan:2000,
  author = {Boehm, Barry W. and Sullivan, Kevin J.},
  title = {Software Economics: A Roadmap},
  crossref = {proceedings:icse:2000},
  pages = {319--343},
  doi = {10.1145/336512.336584},
  abstract = {The fundamental goal of all good design and engineering is to create maximal value added for any given investment. There are many dimensions in which value can be assessed, from monetary profit to the solution of social problems. The benefits sought are often domain-specific, yet the logic is the same: design is an investment activity. Software economics is the field that seeks to enable significant improvements in software design and engineering through economic reasoning about product, process, program, and portfolio and policy issues. We summarize the state of the art and identify shortfalls in existing knowledge. Past work focuses largely on costs, not on benefits, thus not on value added; nor are current technical software design criteria linked clearly to value creation. We present a roadmap for research emphasizing the need for a strategic investment approach to software engineering. We discuss how software economics can lead to fundamental improvements in software design and engineering, in theory and practice.},
  owner = {magsilva},
  timestamp = {2014.09.11}
}

@ARTICLE{Boehm-Adve:2012,
  author = {Boehm, Hans-J. and Adve, Sarita V.},
  title = {You don't know jack about shared variables or memory models},
  crossref = {journal:acm:cacm},
  volume = {55},
  number = {2},
  month = feb,
  year = {2012},
  pages = {48--54},
  doi = {10.1145/2076450.2076465},
  abstract = {Data races are evil.}
}

@ARTICLE{Bohm-Jacopini:1966,
  author = {Böhm, Corrado and Jacopini, Giuseppe},
  title = {Flow diagrams, {Turing} machines and languages with only two formation rules},
  crossref = {journal:acm:cacm},
  volume = {9},
  number = {5},
  month = may,
  year = {1966},
  pages = {366--371},
  doi = {10.1145/355592.365646},
  abstract = {In the first part of the paper, flow diagrams are introduced to represent inter ah mappings of a set into itself. Although not every diagram is decomposable into a finite numbm of given base diagrams, this becomes hue at a semantical level due to a suitable extension of the given set and of the basic mappings defined in it. Two normalization methods of flow diagrams are given. The first has |hree base diagrams; the second, only two. In the second part of the paper, the second method is applied to 'lhe theory of Turing machines. With every Turing maching provided with a two-way half-tape, ihere is associated a similar machine, doing essentially 'lhe same job, but working on a tape obtained from the first one by interspersing alternate blank squares. The new machine belongs to the family, elsewhere introduced, generated by composition and iteration from the two machines X and R. That family is a proper subfamily of the whole family of Turing machines.}
}

@INPROCEEDINGS{Boland-Clifton:2009,
  author = {Boland, Michael G. and Clifton, Curtis},
  title = {Introducing PyLighter: dynamic code highlighter},
  crossref = {proceedings:sigcse:2009},
  pages = {489--493},
  doi = {10.1145/1508865.1509037},
  abstract = {Like a screenplay, a program is both a static artifact and instructions for a dynamic performance. This duality can keep laypeople from appreciating the complexity of software systems and can be a stumbling block for novice programmers. PyLighter lets laypeople and novice programmers perceive the relationship between static Python code and its execution. PyLighter works with everything from simple console applications to arcade-style games, and because PyLighter is easy to adopt and use, instructors can integrate it into any Python-based introductory course without changing the rest of their syllabus.},
  keywords = {cs1, presentation tools, pylighter, python, software visualization}
}

@ARTICLE{Boling-etal:2012,
  author = {E.C. Boling and M. Hough and H. Krinsky and H. Saleem and M. Stevens},
  title = {Cutting the distance in distance education: Perspectives on what promotes positive, online learning experiences},
  crossref = {journal:elsevier:ihe},
  volume = {15},
  number = {2},
  month = mar,
  year = {2012},
  pages = {118--126},
  doi = {10.1016/j.iheduc.2011.11.006},
  abstract = {This qualitative research study was designed to inform the development and implementation of effective online learning environments by exploring, from both teacher and student perspectives, what constitute effective online learning experiences. The study examined course content, tasks, and pedagogical approaches, as identified by students and instructors, which contributed to or hindered positive online learning experiences. Researchers interviewed 6 online course instructors and 10 adult students to understand their experiences in undergraduate and graduate level online degree programs. Using a Cognitive Apprenticeship Model to inform the analysis of data, findings revealed an emphasis on text-based content and lecture; instruction that led to disconnect between students, teachers, and course content and goals; and one innovative program that links real-world experiences with online classroom learning. Given the growing number of online programs, the study provides insight for course development and pedagogy as well as offers possibilities for additional research.},
  keywords = {Technology; Distance education; Online learning}
}

@INPROCEEDINGS{Bollin-etal:2012a,
  author = {Andreas Bollin and Elke Hochmüller and Roland Mittermeir and Ladislav Samuelis},
  title = {Experiences with Integrating Simulation into a Software Engineering Curriculum},
  crossref = {proceedings:cseet:2012},
  pages = {62--71},
  doi = {10.1109/CSEET.2012.18},
  abstract = {Software Engineering education must account for a broad spectrum of knowledge and skills software engineers will be required to apply throughout their professional life. Covering all the topics in depth within a university setting is infeasible due to curricular constraints as well as due to the inherent differences between educational institutions and the actual workplaces of individual graduates. This paper shows how a flexible simulation environment can link the various topic areas of software engineering in the same way they are interwoven in the daily work of practitioners. The authors report their experience gained in using such an environment in their courses at their different institutions, each one having a very distinct focus. Customization of the environment and respective didactical changes can address students with different maturity levels, educational aims, and backgrounds.}
}

@INPROCEEDINGS{Bollin-etal:2012b,
  author = {Bollin, A. and Hochmuller, E. and Samuelis, L.},
  title = {Teaching Software Project Management using Simulations -- The {AMEISE} Environment: from Concepts to Class Room Experience},
  crossref = {proceedings:sbsc:2012},
  pages = {85--86},
  doi = {10.1109/CSEET.2012.33},
  abstract = {The AMEISE (A Media Education Initiative for Software Engineering) approach focuses on the simulation of software project management processes. Based on Stuttgart University's SESAM (Software Engineering Simulation by Animated Models), the AMEISE tool-set allows for repeatedly experiencing the complexity of software project management within a game-like simulation environment.},
  booktitle = {Software Engineering Education and Training (CSEE T), 2012 IEEE 25th Conference on},
  issn = {1093-0175},
  year = {2012}
}

@ARTICLE{Bolloju-Leung:2006,
  author = {Bolloju, Narasimha and Leung, Felix S. K.},
  title = {Assisting novice analysts in developing quality conceptual models with {UML}},
  crossref = {journal:acm:cacm},
  volume = {49},
  number = {7},
  month = jul,
  year = {2006},
  pages = {108--112},
  doi = {10.1145/1139922.1139926},
  abstract = {Knowing the kinds of modeling errors they are most likely to produce helps prepare novice analysts for developing quality conceptual models.}
}

@ARTICLE{Bolloju-Sun:2012,
  author = {Narasimha Bolloju and Sherry X. Y. Sun},
  title = {Benefits of supplementing use case narratives with activity diagrams -- An exploratory study},
  crossref = {journal:springer:jss},
  volume = {85},
  number = {9},
  month = sep,
  year = {2012},
  pages = {2182--2191},
  doi = {10.1016/j.jss.2012.04.076},
  abstract = {Use case narratives modeling the complex functionality of a given system often extend for several pages due to the need to include numerous alternative scenario specifications. In such situations, it is difficult to ensure the completeness and validity of the process logic embedded in such lengthy text narratives. This exploratory study investigates the benefits of supplementing each complex and lengthy use case narrative with an activity diagram for analysts and clients during requirements gathering and analysis. Our findings indicate that the process logic in corresponding activity diagrams is more complete and offers a greater degree of validity than that used in use case narratives. In addition, the quality of the process logic in these artifacts is not negatively affected by a use case narrative's length or complexity when they are used together to capture system requirements. Our research provides empirical evidence of beneficial improvements in the quality of these widely used artifacts that subsequently help eliminate or minimize inconsistencies among the requirements specified in different artifacts.},
  keywords = {Use case narratives, Activity diagrams, Process logic, Quality improvement, Unified Modeling Language}
}

@ARTICLE{Bonar-Soloway:1985,
  author = {Bonar, Jeffrey and Soloway, Elliot},
  title = {Preprogramming knowledge: a major source of misconceptions in novice programmers},
  crossref = {journal:erlbaum:hci},
  volume = {1},
  number = {2},
  month = jun,
  year = {1985},
  pages = {133--161},
  doi = {10.1207/s15327051hci0102_3},
  abstract = {We present a process model to explain bugs produced by novices early in a programming course. The model was motivated by interviews with novice programmers solving simple programming problems. Our key idea is that many programming bugs can be explained by novices inappropriately using their knowledge of step-by-step procedural specifications in natural language. We view programming bugs as patches generated in response to an impasse reached by the novice while developing a program. We call such patching strategies bug generators. Several of our bug generators describe how natural language preprogramming knowledge is used by novices to create patches. Other kinds of bug generators are also discussed. We describe a representation both for novice natural language preprogramming knowledge and novice fragmentary programming knowledge. Using these representations and the bug generators, we evaluate the model by analyzing four interviews with novice programmers.}
}

@INPROCEEDINGS{Booch-etal:1996,
  author = {Booch, Grady and Fraser, Steven and Martin, Robert C. and Mellor, Steven J. and Lee, Michael and Garone, Steven and Fowler, Martin and Schmidt, Douglas C. and Lenzi, Marie},
  title = {Translation: Myth or Reality? (Panel)},
  crossref = {proceedings:oopsla:1996},
  pages = {441--443},
  doi = {10.1145/236337.236384},
  abstract = {In the realm of OO methodologies there are two major schools of thought. Both schools claim to define mechanisms whereby software applications can be created that are reusable, maintainable, and robust. Moreover, both schools claim to use abstraction as a key mechanism for achieving these benefits. At issue is whether or not these two schools are fundamentally different, or just variations on an object-oriented theme.Shlaer and Mellor have dubbed one of these schools "Translational". In the translational approach, two models are created. One is an abstract model of the application domain which is devoid of any design dependencies. The other model is an abstract model of the design which is devoid of any application dependencies. These two models are composed automatically to yield the code for the system.The other school - supported by Booch, Rumbaugh, Jacobson, and Martin - views the architecture of a system from several different perspectives of abstraction, e.g. logical, physical. These abstractions typically form a layer; abstractions in the logical sense manifest themselves as individual classes as well as collaborations of classes. There may be one layered model, at different layers of abstraction, or, especially given the Objectory view point, there may be multiple models, with an analysis model that's nearly independent from the design model.The panel will explore:&bull; Is there a seamless transition between analysis and design?&bull; Should there be a single model or should there be two - one for the analysis and one for the design?&bull; If there are two models, how are they "bridged"?&bull; What, if any, are the differences in process between the two schools?&bull; How does architecture manifest itself!&bull; Is there, in fact, a real difference between the two schools of thought?As a result of this exploration, we hope to answer the question: Is translation a myth or is it a reality?}
}

@INPROCEEDINGS{Borges-etal:2008,
  author = {Karen S. Borges and Maria Lúcia K. Barbosa and Fernando Varella and Valter Roesler},
  title = {Educação através da {TV} Digital utilizando Metadados},
  crossref = {proceedings:sbie:2008},
  pages = {1-10},
  abstract = {Uma das novas tecnologias de educação disponíveis atualmente no Brasil é a educação através da TV Digital, que vai permitir acesso a 98% da população brasileira. Este artigo apresenta um estudo sobre a viabilidade da utilização de metadados para agregar informações à programação tradicional, impulsionando o aprendizado da população. Para isso, efetuou-se um estudo dos padrões de metadados utilizados em TV Digital, além do desenvolvimento e implementação de um estudo de caso de uma campanha sobre saúde, especificamente na prevenção da Dengue. Adicionalmente, o artigo propõe cenários integrando Educação com TV Digital. Os resultados mostram claramente o grande potencial dos metadados e da televisão digital como ferramenta educacional.},
  abstract-en = {One of the new educational technology nowadays in Brazil is Digital TV, which will reach up to 98% of Brazilian people. This paper presents a study about the possibility of metadata use to aggregate information to traditional TV transmission, leveraging the televiewer learning. To validate this, the authors studied the digital TV metadata standards and developed a digital TV application, specifically a Dengue prevention campaign. Additionally, this paper proposes innovators sceneries integrating Digital TV and Education. The results show clearly the great educational potential of metadata and Digital TV as an educational tool.},
  lang = {pt},
  url = {http://www.br-ie.org/pub/index.php/sbie/article/view/709}
}

@ARTICLE{turine-etal:1999,
  author = {Borges Paulo, F. and Masiero, P.C. and Ferreira de Oliveira, M.C.},
  title = {Hypercharts: extended statecharts to support hypermedia specification},
  crossref = {journal:ieee:tse},
  volume = {25},
  number = {1},
  month = jan # {--} # feb,
  year = {1999},
  pages = {33 -49},
  doi = {10.1109/32.748917},
  abstract = {Introduces hypercharts, a novel and effective notation that extends the well-known statechart formalism to make it suitable for the specification of temporal and information synchronization requirements of hypermedia applications. Three new definitions are added: timed history, timed transitions, and a set of synchronization mechanisms. The proposed extensions are based on the major characteristics of some Petri net-based multimedia models, and have their semantics described in terms of conventional statechart models. Therefore, any hyperchart construction can be transformed into a statechart that exhibits the desired behavior, giving hyperchart models the same semantic behavior as statecharts. The new constructs are illustrated using a case study based on a hypermedia-modeling example},
  keywords = {Petri net-based multimedia models;case study;hypercharts;hypermedia specification;information synchronization;requirements specification;semantic behavior;statecharts;synchronization mechanisms;temporal synchronization;timed history;timed transitions;Petri nets;finite state machines;formal specification;hypermedia;synchronisation;}
}

@INPROCEEDINGS{Borstler:2005,
  author = {Börstler, Jürgen},
  title = {Improving {CRC}-card role-play with role-play diagrams},
  crossref = {proceedings:oopsla:2005},
  pages = {356--364},
  doi = {10.1145/1094855.1094973},
  abstract = {CRC-cards are a lightweight approach to collaborative object-oriented modeling. They have been adopted by many educators and trainers to teach early object-oriented design. Reports in the literature are generally positive. So is our own experience. However, over the years, we have noticed many subtle problems and issues that have largely gone unnoticed in the literature.In this paper, we discuss the problems and issues we experienced when teaching CRC-cards to novices. Two major sources of problems can be traced back to the CRC-card role-play. One is the usage of CRC-cards as substitutes for actual objects during the scenario role-play and the other the difficulty to document or trace the scenario role-play ``on the fly". We propose a new type of diagram to support the role-play activities and to overcome these problems. Our experience so far is quite positive. Novices have fewer problems with role-play activities when using these diagrams. Teaching and learning the new type of diagram adds only little overhead to the overall CRC-approach.We also provide general guidelines for CRC-card usage. Although our improvements are aimed at novices, we believe that the proposed diagram is useful even for professional software development.},
  keywords = {introductory programming, scenario role-play},
  timestamp = {2013-08-01}
}

@ARTICLE{Bosch:2012,
  author = {Jan Bosch},
  title = {Software ecosystems: Taking software development beyond the boundaries of the organization},
  crossref = {journal:elsevier:ist},
  volume = {85},
  number = {7},
  month = jul,
  year = {2012},
  pages = {1453--1454},
  doi = {10.1016/j.jss.2012.03.039},
  owner = {magsilva},
  timestamp = {2014.09.13}
}

@BOOK{Bossuet:1985,
  title = {O computador na escola: o sistema {LOGO}},
  publisher = {Artes Médicas},
  year = {1985},
  author = {Gerárd Bossuet},
  translator = {Leda Mariza Vieira Fischer and Léa da Cruz Fagundes},
  pages = {182},
  address = {Porto Alegre, RS, } # Brazil,
  edition = {1},
  booktitle = {O computador na escola: o sistema {LOGO}},
  crossref = {Bossuet:1982},
  lang = {pt}
}

@ARTICLE{Bosu-etal:2014,
  author = {Amiangshu Bosu and Jeffrey Carver and Rosanna Guadagno and Blake Bassett and Debra McCallum and Lorin Hochstein},
  title = {Peer Impressions in Open Source Organizations: A Survey},
  crossref = {journal:elsevier:ist},
  year = {2014},
  pages = {-},
  doi = {10.1016/j.jss.2014.03.061},
  abstract = {In virtual organizations, such as Open Source Software (OSS) communities, we expect that the impressions members have about each other play an important role in fostering effective collaboration. However, there is little empirical evidence about how peer impressions form and change in virtual organizations. This paper reports the results from a survey designed to understand the peer impression formation process among OSS participants in terms of perceived expertise, trustworthiness, productivity, experiences collaborating, and other factors that make collaboration easy or difficult. While the majority of survey respondents reported positive experiences, a non-trivial fraction had negative experiences. In particular, volunteer participants were more likely to report negative experiences than participants who were paid. The results showed that factors related to a person's project contribution (e.g., quality and understandability of committed codes, important design related decisions, and critical fixes made) were more important than factors related to work style or personal traits. Although OSS participants are very task focused, the respondents believed that meeting their peers in person is beneficial for forming peer impressions. Having an appropriate impression of one's OSS peers is crucial, but the impression formation process is complicated and different from the process in traditional organizations.},
  keywords = {Open source software; FLOSS; Impression formation; virtual teams}
}

@INPROCEEDINGS{Botelho-Pires:2008,
  author = {Botelho, Rodrigo Pereira and Pires, Daniel Facciolo},
  title = {Uso de ontologias para a representação semântica de objetos de aprendizagem},
  crossref = {proceedings:webmedia:2008},
  pages = {158--160},
  doi = {10.1145/1809980.1810025},
  keywords = {IEEE LOM, objetos de aprendizagem, web semântica},
  series = {WebMedia '08},
  abstract-en = {Learning Objects (LOs) retrieval and sharing are important tasks on a Web based educational system, because it allows LOs provided by different sources to be found and reused by heterogeneous systems. This enables, among others, costs reduction during the LO production proccess, as educational content development is a time consuming task. Therefore, a formal and standardized representation, like IEEE Learning Objects Metadata (LOM), is needed to describe the LOs to make the aforementioned scenario possible. However, semantic operations like LOs relationship demand an ontological representation as metadata semantics is not well defined. To this end, this paper presents an ontology that uses the IEEE LOM standard to semantically represent LOs.},
  address = {New York, NY, USA},
  booktitle = {Companion Proceedings of the XIV Brazilian Symposium on Multimedia and the Web},
  isbn = {978-85-7669-199-0},
  location = {Vila Velha, Espírito Santo, Brazil},
  publisher = {ACM},
  year = {2008}
}

@INPROCEEDINGS{Botturi-etal:2006,
  author = {Luca Botturi and Michael Derntl and Eddy Boot and Kathrin Figl},
  title = {A Classification Framework for Educational Modeling Languages in Instructional Design},
  crossref = {proceedings:icalt:2006},
  pages = {1216-1220},
  abstract = {The integration of advanced learning technologies in education has made the design and development of instructional units and courses a complex task. Instructional design languages are proposed as a conceptual tool to achieve more creative design solutions and to enhance communication in design teams. This paper reviews the state of the art in the development, application, and research concerning the use of design languages in education and e-learning. The review reports on relevant literature and on both theoretical and empirical studies. As basis for further research, the authors propose a taxonomy of design languages and a framework for possible application of design languages in instructional design and e-learning practices.},
  address = {Kerkrade, Netherlands},
  booktitle = {International Conference on Advanced Learning Technologies},
  month = jul,
  owner = {magsilva},
  publisher = {IEEE},
  url = {http://www.ask4research.info/icalt/2006/files/82_Bot.pdf},
  year = {2006}
}

@ARTICLE{Boute:2009,
  author = {Boute, Raymond},
  title = {Teaching and practicing computer science at the university level},
  crossref = {journal:acm:inroads},
  volume = {41},
  number = {2},
  month = jun,
  year = {2009},
  pages = {24--30},
  doi = {10.1145/1595453.1595458},
  abstract = {Universities offering Computing Science curricula should do so at the university level. Taking pragmatic shortcuts causes stagnation in professional practice. The essential element is the pervasive presence throughout the curriculum of mathematical modelling, which is the role of Formal Methods in its original sense. Mathematical fundamentals and concepts are crucial, software tools are auxiliary and even misleading without the former. Recommendations are given for curriculum structure, specific key courses and attitudes to instil in students and educators. Comparison with other approaches is made. A conclusion is that CS curricula should break outside the limitations caused by conservative policy makers but also self-imposed ones.},
  keywords = {computing curricula, formal methods, mathematical modelling, professional practice}
}

@INPROCEEDINGS{Bowring:2008,
  author = {Bowring, James F.},
  title = {A new paradigm for programming competitions},
  crossref = {proceedings:sigcse:2008},
  pages = {87--91},
  doi = {10.1145/1352135.1352166},
  abstract = {The annual ACM International Collegiate Programming Contest produces a competitive paradigm that is at odds with the pedagogical goals of modern computer science and software engineering degree programs. This paradigm stresses the fast completion of a programming task and evaluates the results solely with black-box testing specified by the judges. In contrast, the pedagogical goals of contemporary college degree programs in computing emphasize the quality of processes inherent in software development and implementation. In 2007, the College of Charleston student chapter of the ACM hosted its annual high school programming competition by turning the conventional programming paradigm on its head to focus on quality-of-process rather than time-to-complete. The judging criteria included both technical and artistic merit. The implementation of the competition emphasized success by giving students working skeleton solution programs. This paper presents the motivation for the new paradigm, the details of its implementation for the 2007 competition, and the details of the new techniques for judging technical and artistic merit.},
  keywords = {acm programming contest, competition paradigm, quality-of-process}
}

@ARTICLE{Bozzo-Franceschet:2013,
  author = {Enrico Bozzo and Massimo Franceschet},
  title = {Resistance distance, closeness, and betweenness },
  crossref = {journal:elsevier:sn},
  volume = {35},
  number = {3},
  month = jul,
  year = {2013},
  pages = {460--469},
  doi = {10.1016/j.socnet.2013.05.003},
  abstract = {Abstract In a seminal paper Stephenson and Zelen (1989) rethought centrality in networks proposing an information-theoretic distance measure among nodes in a network. The suggested information distance diverges from the classical geodesic metric since it is sensible to all paths (not just to the shortest ones) and it diminishes as soon as there are more routes between a pair of nodes. Interestingly, information distance has a clear interpretation in electrical network theory that was missed by the proposing authors. When a fixed resistor is imagined on each edge of the graph, information distance, known as resistance distance in this context, corresponds to the effective resistance between two nodes when a battery is connected across them. Here, we review resistance distance, showing once again, with a simple proof, that it matches information distance. Hence, we interpret both current-flow closeness and current-flow betweenness centrality in terms of resistance distance. We show that this interpretation has semantic, theoretical, and computational benefits.},
  keywords = {Information, Resistance distance, Geodesic distance, Closeness centrality, Betweenness centrality }
}

@ARTICLE{Bravo-etal:2013,
  author = {Crescencio Bravo and Rafael Duque and Jesús Gallardo},
  title = {A groupware system to support collaborative programming: Design and experiences },
  crossref = {journal:elsevier:jss},
  volume = {86},
  number = {7},
  month = jul,
  year = {2013},
  pages = {1759--1771},
  doi = {10.1016/j.jss.2012.08.039},
  abstract = {The advances in network and collaboration technologies enable the creation of powerful environments for collaborative programming. One such environment is COLLECE, a groupware system to support collaborative edition, compilation and execution of programs in a synchronous distributed fashion, which includes advanced tools for communication, coordination and workspace awareness. The article analyses firstly some usability and design issues, discussing strengths and weaknesses of the system as a basis for the development of groupware tools to support collaborative programming. Then, the focus is on a number of experimental activities carried out. COLLECE was used to conduct a set of experimental activities about work productivity and program quality when comparing the activity of pair and solo programmers, and to analyse potential associations between ways of working and collaborating, and specific characteristics of the programs produced.},
  keywords = {Collaborative programming, Distributed pair programming, Collaboration and interaction analysis, Collaborative learning environments}
}

@INPROCEEDINGS{Brennan:2010,
  author = {Brennan, Padraig},
  title = {Transitioning a Large Organisation: Adopting {TDD}},
  crossref = {proceedings:xp:2010},
  pages = {261--268},
  doi = {10.1007/978-3-642-13054-0_28},
  abstract = {Test-Driven Development (TDD) is promoted as a powerful technique for combining software design, testing, and coding to increase reliability and productivity. However the transition to TDD is not always easy. Is it worth the effort and what can really be gained from it? This report describes a useful transition strategy based on different TDD styles and identifies some key elements required for each style. It then identifies the main differences found on the code and designs that developed using these TDD styles. The differences are striking in their consistency and provide a strong indication that TDD is well worth the effort.},
  keywords = {Agile; Test-Driven Development; Code Complexity; Case Study; TDD style},
  owner = {magsilva},
  timestamp = {2014.10.20}
}

@ARTICLE{Brereton:2011,
  author = {Brereton, P.},
  title = {A Study of Computing Undergraduates Undertaking a Systematic Literature Review},
  crossref = {journal:ieee:te},
  volume = {54},
  number = {4},
  month = nov,
  year = {2011},
  pages = {558-563},
  doi = {10.1109/TE.2010.2090662},
  abstract = {Teaching computing students about the importance of evidence and about the use of empirical methods for evaluating computing technologies can be difficult, especially within dual honors undergraduate degree programs. The aims of this study were to explore the effectiveness of second-year undergraduate computing students in carrying out a systematic literature review and to identify the elements of the process that the students found most difficult. A multicase case study of students carrying out an assignment to perform a systematic literature review (SLR) was undertaken. Students worked in groups and were studying across a range of computing programs. Data was collected from three sources: student grades, the comments made by the teaching staff on the submitted reports, and a debriefing questionnaire. All of the groups successfully completed the assignment. Results on which parts of the process were the most difficult were mixed, although much of the evidence suggests that the students found the conduct phase more problematic than the planning phase. It can be concluded that undergraduates can do SLRs, but the task is clearly quite challenging and time-consuming. SLRs are well suited to being undertaken by groups.},
  keywords = {conduct phase;dual honors undergraduate degree programs;evidence-based software engineering;planning phase;second-year undergraduate computing students;systematic literature review;computer science education;further education;reviews;software engineering;teaching;},
  lang = {en}
}

@INPROCEEDINGS{Brereton-etal:2008,
  author = {Pearl Brereton and Barbara Kitchenham and David Budgen and Zhi Li},
  title = {Using a Protocol Template for Case Study Planning},
  crossref = {proceedings:ease:2008},
  pages = {41--48},
  abstract = {In order to undertake a series of case studies aimed at investigating systematic literature reviews, we have developed a case study protocol template. This paper introduces the template and discusses our experiences of using the template and the resulting case study protocol. We suggest that using our template to prepare a protocol and using the protocol for case study planning can improve the rigour of software engineering case studies.},
  keywords = {case study, template, protocol},
  url = {http://www.bcs.org/content/conWebDoc/19535}
}

@ARTICLE{Briggs-Snyder:2012,
  author = {Briggs, Amy and Snyder, Lawrence},
  title = {Computer science principles and the {CS 10K} initiative},
  crossref = {journal:acm:inroads},
  volume = {3},
  number = {2},
  month = jun,
  year = {2012},
  pages = {29--31},
  doi = {10.1145/2189835.2189847}
}

@ARTICLE{Briggs-Girard:2007,
  author = {Briggs, Tom and Girard, C. Dudley},
  title = {Tools and techniques for test-driven learning in CS1},
  crossref = {journal:ccsc:jcsc},
  volume = {22},
  number = {3},
  month = jan,
  year = {2007},
  pages = {37--43},
  abstract = {Test-Driven Development is a design strategy where a set of tests over a class is defined prior to the implementation of that class. The goal is to use the tests to exercise the class being developed, to provide immediate feedback of the overall quality of the code, and to identify and correct bugs as they are written. Testing is usually performed with automated testing tools, such as JUnit, which give clear feedback about the status of the tests1. The test-first approach requires students to think about the problem, identify corner cases, analyze ways their code may fail, and evaluate the goodness of their design. This paper presents a tool for teaching CS1 using a "Test-First" approach that will allow students to construct their tests using a simple GUI interface. The goal is to give CS1 students the ability to do test-driven development independently.}
}

@INPROCEEDINGS{Brinkman:2009,
  author = {Brinkman, Bo},
  title = {The heart of a whistle-blower: a corporate decision-making game for computer ethics classes},
  crossref = {proceedings:sigcse:2009},
  pages = {316--320},
  doi = {10.1145/1508865.1508979},
  abstract = {I describe a simple game for use in starting a class discussion about corporate decision-making and whistle-blowing. The game allows students to experience the power of managers to influence (for good or bad) the decisions of their underlings, and the counter-balancing powers held by workers.},
  keywords = {business, education, ethics, games, management, whistle-blowing}
}

@INPROCEEDINGS{Brito-etal:2010,
  author = {Maria A. S. Brito and João L. Rossi and Simone R. S. de Souza and Rosana T. V. Braga.},
  title = {Reuso de conjuntos de teste no ensino de disciplinas introdutórias de programação},
  crossref = {proceedings:eselaw:2010},
  abstract = {Este artigo descreve uma proposta de reuso de conjuntos de teste no ensino de disciplinas introdutórias de programação como alternativa para aumento na qualidade dos programas gerados pelos alunos. Para reforçar a validade da proposta foi realizado um estudo experimental com o objetivo de investigar o reuso de conjuntos de teste como contribuição ao aumento da qualidade dos programas implementados por alunos. O estudo foi realizado no domínio de manipulação de vetores e de matrizes. Foram gerados conjuntos de casos de teste funcional com base em programas de referência. Os conjuntos de teste foram reutilizados pelos alunos para o teste de programas equivalentes aos programas de referência. Evidências indicam que o reuso de conjuntos de teste pode contribuir para o aumentona qualidade dos programas equivalentes gerados pelos alunos.}
}

@ARTICLE{Broman-etal:2012,
  author = {Broman, D. and Sandahl, K. and Abu Baker, M.},
  title = {The Company Approach to Software Engineering Project Courses},
  crossref = {journal:ieee:te},
  volume = {55},
  number = {4},
  month = nov,
  year = {2012},
  pages = {445--452},
  doi = {10.1109/TE.2012.2187208},
  abstract = {Teaching larger software engineering project courses at the end of a computing curriculum is a way for students to learn some aspects of real-world jobs in industry. Such courses, often referred to as capstone courses, are effective for learning how to apply the skills they have acquired in, for example, design, test, and configuration management. However, these courses are typically performed in small teams, giving only a limited realistic perspective of problems faced when working in real companies. This paper describes an alternative approach to classic capstone projects, with the aim of being more realistic from an organizational, process, and communication perspective. This methodology, called the company approach, is described by intended learning outcomes, teaching/learning activities, and assessment tasks. The approach is implemented and evaluated in a larger Master's student course.},
  keywords = {Capstone projects, company approach, constructive alignment, software engineering (SE)}
}

@INPROCEEDINGS{Brown-etal:2012,
  author = {Brown, Christopher and Pastel, Robert and Siever, Bill and Earnest, John},
  title = {{JUG}: a {JUnit} generation, time complexity analysis and reporting tool to streamline grading},
  crossref = {proceedings:itcse:2012},
  pages = {99--104},
  doi = {10.1145/2325296.2325323},
  abstract = {The JUnit Generation (JUG) system provides fast, semi-automated feedback to students. It uses a Java-like script to generate unit tests and time complexity tests, then runs those tests to generate reports. The goals for JUG are improved feedback for students, and decreased preparation and grading time for instructors and grading assistants.},
  keywords = {automated testing, evaluation, generative programming}
}

@ARTICLE{Brown-Adler:2008,
  author = {John Seely Brown and Richard P. Adler},
  title = {Minds ond Fire: Open Education, the Long Tail, and Learning 2.0},
  crossref = {journal:educause:educause-review},
  volume = {43},
  number = {1},
  month = jan # {/} # feb,
  year = {2008},
  pages = {16--32}
}

@ARTICLE{Brun-etal:2011,
  author = {Armelle Brun and Sylvain Castagnos and Anne Boyer},
  title = {From Community Detection to Mentor Selection in Rating-Free Collaborative Filtering},
  crossref = {journal:hindawi:am},
  month = nov,
  year = {2011},
  doi = {10.1155/2011/852518},
  abstract = {The number of items that users can now access when navigating on the Web is so huge that these might feel lost. Recommender systems are a way to cope with this profusion of data by suggesting items that fit the users needs. One of the most popular techniques for recommender systems is the collaborative filtering approach that relies on the preferences of items expressed by users, usually under the form of ratings. In the absence of ratings, classical collaborative filtering techniques cannot be applied. Fortunately, the behavior of users, such as their consultations, can be collected. In this paper, we present a new approach to perform collaborative filtering when no rating is available but when user consultations are known. We propose to take inspiration from local community detection algorithms to form communities of users and deduce the set of mentors of a given user. We adapt one state-of-the-art algorithm so as to fit the characteristics of collaborative filtering. Experiments conducted show that the precision achieved is higher then the baseline that does not perform any mentor selection. In addition, our model almost offsets the absence of ratings by exploiting a reduced set of mentors.},
  timestamp = {2013-09-24}
}

@INPROCEEDINGS{Brusilovsky-etal:2008,
  author = {Brusilovsky, Peter and Sosnovsky, Sergey and Lee, Danielle H. and Yudelson, Michael and Zadorozhny, Vladimir and Zhou, Xin},
  title = {An open integrated {Exploratorium} for database courses},
  crossref = {proceedings:itcse:2008},
  pages = {22--26},
  doi = {10.1145/1384271.1384280},
  abstract = {In this paper, we present an open architecture that combines different SQL learning tools in an integrated Exploratorium for database courses. The integrated Exploratorium provides a unique learning environment that allows database students to take complimentary advantages of multiple advanced learning tools.},
  keywords = {e-learning, integration, learning environment, problem-solving, sql}
}

@ARTICLE{Brusilovsky-etal:2010,
  author = {Brusilovsky, Peter and Sosnovsky, Sergey and Yudelson, Michael V. and Lee, Danielle H. and Zadorozhny, Vladimir and Zhou, Xin},
  title = {Learning {SQL} Programming with Interactive Tools: From Integration to Personalization},
  crossref = {journal:acm:tce},
  volume = {9},
  number = {4},
  month = jan,
  year = {2010},
  pages = {19:1--19:15},
  doi = {10.1145.1656255.1656257},
  abstract = {Rich, interactive eLearning tools receive a lot of attention nowadays from both practitioners and researchers. However, broader dissemination of these tools is hindered by the technical difficulties of their integration into existing platforms. This article explores the technical and conceptual problems of using several interactive educational tools in the context of a single course. It presents an integrated Exploratorium for database courses, an experimental platform, which provides personalized access to several types of interactive learning activities. Several classroom studies of the Exploratorium have demonstrated its value in both the integration of several tools and the provision of personalized access.},
  keywords = {Adaptive educational system, SQL, adaptive hypermedia, integrated learning environment}
}

@ARTICLE{Bryce:2011,
  author = {Bryce, Renee},
  title = {{Bug Wars}: a competitive exercise to find bugs in code},
  crossref = {journal:ccsc:jcsc},
  volume = {27},
  number = {2},
  month = dec,
  year = {2011},
  pages = {43--50},
  abstract = {Software bugs are a common problem that students encounter in any Computer Science program. "Bug Wars" is a fun and competitive class exercise for student teams to identify bugs in code. To prepare for the competition, the instructor provides several code examples that contain bugs. Each student team also develops code that has a bug. All of the code examples are placed on a table in the classroom at the beginning of class. The competition then begins by each team taking one problem to solve and checking with the author of the respective code to ask whether they correctly identified the bug. If they solve the bug, we update the score and they swap the problem that they solved for a new problem. The team that identifies the most bugs wins the competition. The majority of students reported that this activity increased their interest in software testing and made them more aware of bugs that they should avoid on future assignments.}
}

@INPROCEEDINGS{Bryce-etal:2013,
  author = {Bryce, Renee and Mayo, Quentin and Andrews, Aaron and Bokser, Daniel and Burton, Michael and Day, Chelynn and Gonzolez, Jessica and Noble, Tara},
  title = {{Bug Catcher}: A System for Software Testing Competitions},
  crossref = {proceedings:sigcse:2013},
  pages = {513--518},
  doi = {10.1145/2445196.2445348},
  abstract = {Bug Catcher is a web-based system for running software testing competitions. While programming competitions are a way to engage students, they require students to have coding experience. On the other hand, software testing competitions may reach high school students that do not have access to a programming course. In this paper, we present the Bug Catcher system and the results from four sessions of a competition that include a total of 94 high school students. Bug Catcher provides students with requirements, buggy code, and input fields to enter test cases. We observed that most students began entering test cases based on requirements, but then many took an interest in the code as time went on. Our results show that 90% of students would recommend this activity in the future and 72% of students report that the activity increased their interest in Computer Science. Students also provided feedback on the system from the perspective of students without background in Computer Science, allowing us to create and modify features for future use.},
  keywords = {computer science outreach, software testing competition},
  owner = {magsilva},
  timestamp = {2014.08.31}
}

@ARTICLE{Budgen-etal:2011,
  author = {Budgen, D. and Burn, A. J. and Brereton, O. P. and Kitchenham, B. A. and Pretorius, R.},
  title = {Empirical evidence about the {UML}: a systematic literature review},
  crossref = {journal:wiley:spe},
  volume = {41},
  number = {4},
  year = {2011},
  pages = {363--392},
  doi = {10.1002/spe.1009},
  abstract = {Abstract The Unified Modeling Language (UML) was created on the basis of expert opinion and has now become accepted as the 'standard' object-oriented modelling notation. Our objectives were to determine how widely the notations of the UML, and their usefulness, have been studied empirically, and to identify which aspects of it have been studied in most detail. We undertook a mapping study of the literature to identify relevant empirical studies and to classify them in terms of the aspects of the UML that they studied. We then conducted a systematic literature review, covering empirical studies published up to the end of 2008, based on the main categories identified. We identified 49 relevant publications, and report the aggregated results for those categories for which we had enough papers -- metrics, comprehension, model quality, methods and tools and adoption. Despite indications that a number of problems exist with UML models, researchers tend to use the UML as a 'given' and seem reluctant to ask questions that might help to make it more effective.},
  keywords = {UML, systematic literature review}
}

@INPROCEEDINGS{Buechley-etal:2008,
  author = {Buechley, Leah and Eisenberg, Mike and Catchen, Jaime and Crockett, Ali},
  title = {The {LilyPad} Arduino: Using Computational Textiles to Investigate Engagement, Aesthetics, and Diversity in Computer Science Education},
  crossref = {proceedings:chi:2008},
  pages = {423--432},
  doi = {10.1145/1357054.1357123},
  abstract = {The advent of novel materials (such as conductive fibers) combined with accessible embedded computing platforms have made it possible to re-imagine the landscapes of fabric and electronic crafts--extending these landscapes with the creative range of electronic/computational textiles or e-textiles. This paper describes the LilyPad Arduino, a fabric-based construction kit that enables novices to design and build their own soft wearables and other textile artifacts. The kit consists of a microcontroller and an assortment of sensors and actuators in stitch-able packages; these elements can be sewn to cloth substrates and each other with conductive thread to build e-textiles. This paper will introduce the latest version of the kit; reflect on its affordances; present the results of our most recent user studies; and discuss possible directions for future work in the area of personalized e-textile design and its relation to technology education.},
  keywords = {computational textiles, construction kits., e-textiles, electronic textiles, lilypad arduino, smart textiles, wearable computing}
}

@INPROCEEDINGS{Buechley-Hill:2010,
  author = {Buechley, Leah and Hill, Benjamin Mako},
  title = {{LilyPad} in the Wild: How Hardware's Long Tail is Supporting New Engineering and Design Communities},
  crossref = {proceedings:dis:2010},
  pages = {199--207},
  doi = {10.1145/1858171.1858206},
  abstract = {This paper examines the distribution, adoption, and evolution of an open-source toolkit we developed called the LilyPad Arduino. We track the two-year history of the kit and its user community from the time the kit was commercially introduced, in October of 2007, to November of 2009. Using sales data, publicly available project documentation and surveys, we explore the relationship between the LilyPad and its adopters. We investigate the community of developers who has adopted the kit---paying special attention to gender---explore what people are building with it, describe how user feedback impacted the development of the kit and examine how and why people are contributing their own LilyPad-inspired tools back to the community. What emerges is a portrait of a new technology and a new engineering/design community in co-evolution.},
  keywords = {Arduino, LilyPad, e-textiles, electronic textiles, long tail, open-source hardware, wearable computing}
}

@INPROCEEDINGS{Buffardi:2012,
  author = {Buffardi, Kevin},
  title = {Understanding and Persuading Adherence to Test-driven Development},
  crossref = {proceedings:icer:2012},
  pages = {155--156},
  doi = {10.1145/2361276.2361308},
  abstract = {In computing education, students must learn techniques practiced in relevant professions. Test-Driven Development (TDD) is one such technique popular in the software industry. Preliminary reports suggest that TDD helps produce higher-quality code. However, motivating novice programmers to adopt TDD is also recognized as a distinct challenge. My studies and proposed work address this challenge with the following objectives: measuring adherence to TDD and its consequential outcomes; understanding students' reasons for non-adherence; and influencing students' attitudes and behavior via pedagogical interventions.},
  keywords = {adherence, affect, automated grading, software engineering, test-driven development (tdd)},
  owner = {magsilva},
  timestamp = {2014.08.31}
}

@INPROCEEDINGS{Buffardi-Edwards:2013:icer,
  author = {Buffardi, Kevin and Edwards, Stephen H.},
  title = {Effective and Ineffective Software Testing Behaviors by Novice Programmers},
  crossref = {proceedings:icer:2013},
  pages = {83--90},
  doi = {10.1145/2493394.2493406},
  abstract = {This data-driven paper quantitatively evaluates software testing behaviors that students exhibited in introductory computer science courses. The evaluation includes data collected over five years (10 semesters) from 49,980 programming assignment submissions by 883 different students. To examine the effectiveness of software testing behaviors, we investigate the quality of their testing at different stages of their development. We partition testing behaviors into four groups according to when in their development they first achieve substantial (at least 85%) test coverage. The study reveals significant results regarding effective and ineffective testing behaviors. A within-subjects comparison finds that higher coverage in early development is associated with higher quality code and with completing work earlier. Post-hoc analysis also suggests that the relationship between early testing and positive outcomes is independent of time management and effects of individuals' abilities. However, roughly 76% of students exhibit different testing behaviors on different assignments, demonstrating an opportunity to foster better, more consistent testing habits among computer science students.},
  keywords = {software development, software testing, test-driven development},
  owner = {magsilva},
  timestamp = {2014.08.31}
}

@INPROCEEDINGS{Buffardi-Edwards:2013:sigcse,
  author = {Buffardi, Kevin and Edwards, Stephen H.},
  title = {Impacts of adaptive feedback on teaching test-driven development},
  crossref = {proceedings:sigcse:2013},
  pages = {293--298},
  doi = {10.1145/2445196.2445287},
  abstract = {Studies have found that following Test-Driven Development (TDD) can improve code and testing quality. However, a preliminary investigation was consistent with concerns raised by other educators about programmers resisting TDD. In this paper, we describe an adaptive, pedagogical system for tracking and encouraging students' adherence to TDD. Along with an empirical evaluation of the system, we discuss challenges and opportunities for persuading student behavior through adaptive technology.},
  keywords = {adherence, automated testing, instructional technology, test-driven development (TDD), test-first, unit testing, web-cat}
}

@INPROCEEDINGS{Buffardi-Edwards:2014:itcse,
  author = {Buffardi, Kevin and Edwards, Stephen H.},
  title = {Responses to Adaptive Feedback for Software Testing},
  crossref = {proceedings:itcse:2014},
  pages = {165--170},
  doi = {10.1145/2591708.2591756},
  abstract = {As students learn to program they also learn basic software development methods and techniques, but educators do not often directly assess students' development processes or evaluate their adherence to specific techniques. However, automated grading systems provide opportunities to evaluate students' programming and provide feedback while the student is still in the process of developing. Consequently, automated adaptive feedback may help reinforce effective techniques and processes. This paper describes an adaptive feedback system that uses strategic reinforcement techniques to reward and encourage incremental software testing. By analyzing changes in students' code after they receive the system's reinforcement, we investigated students' responses to the presence and absence of rewards. We found that after receiving rewards, students respond with more test code in their subsequent submission.},
  keywords = {adaptive feedback, automated assessment, behavioral change, instructional technolgy, operant conditioning, punishment, reinforcement, test-driven development (tdd)},
  owner = {magsilva},
  timestamp = {2014.08.31}
}

@INPROCEEDINGS{Buffardi-Edwards:2014:sigcse,
  author = {Buffardi, Kevin and Edwards, Stephen H.},
  title = {A Formative Study of Influences on Student Testing Behaviors},
  crossref = {proceedings:sigcse:2014},
  pages = {597--602},
  doi = {10.1145/2538862.2538982},
  abstract = {While Computer Science curricula teach students strategic software development processes, assessment is often product-instead of process-oriented. Test-Driven Development (TDD) has gained popularity in computing education, but evaluating students' adherence to TDD requires analyzing their development processes instead of only their final product. Consequently, we designed an adaptive feedback system for reinforcing incremental testing behaviors. In this paper, we compare the results of the system with different reinforcement schedules and with- or without- visually salient testing goals. We analyzed snapshots of students' programming projects gathered during development and interviewed students at the end of the academic term. From our findings, we identify potential for influencing student development behaviors and suggest future direction for designing adaptive reinforcement.},
  keywords = {adaptive feedback, automated testing, instructional technology, software development process, test-driven development, test-first, unit testing, web-cat},
  owner = {magsilva},
  timestamp = {2014.08.31}
}

@INPROCEEDINGS{Buffardi-Edwards:itcse:2012,
  author = {Buffardi, Kevin and Edwards, Stephen H.},
  title = {Exploring influences on student adherence to test-driven development},
  crossref = {proceedings:itcse:2012},
  pages = {105--110},
  doi = {10.1145/2325296.2325324},
  abstract = {Test-Driven Development (TDD) is a software development process with a test-first approach that shows promise for improving code quality. Our research addresses concerns raised in both academia and industry about a lack of motivation or acceptance in adopting TDD. In a CS2 class, we used an automated testing tool and post-class surveys to observe patterns of behavior in testing as well as changes in attitudes. We found significant positive outcomes for students following TDD. We also identified obstacles deterring students from adhering to TDD and discuss reasons and possible remedies.},
  keywords = {adherence, affect, agile, automated testing, extreme programming, junit, procrastination, software engineering, test-driven development (tdd), web-cat}
}

@ARTICLE{Buffardi-Edwards:2012,
  author = {Kevin Buffardi and Stephen H. Edwards},
  title = {Impacts of Teaching Test-Driven Development to Novice Programmers},
  crossref = {journal:sepc:ijics},
  volume = {6},
  number = {1},
  month = sep,
  year = {2012},
  pages = {135--143},
  abstract = {Due to the popularity of Test-Driven Development (TDD) among software professionals, some schools have integrated it into their computing curricula. Through exposure to TDD, students gain practical experience while future employers benefit from their familiarity with the technique. However, it is important to investigate empirically whether the use of TDD in the classroom affects student performance or improves the quality of their code. This paper describes an investigation into results from multiple years of teaching TDD in introductory computer science classes. Directly analyzing the code and tests written by students provides insight into their work habits and consequential outcomes. We explain methods, tools, and metrics for determining students' adherence to TDD with unprecedented detail. Our study establishes correlations between students' software development processes and their quality of work and identifies significantly different outcomes based on their adherence to TDD. As a result, we provide empirical support for TDD and identify areas for improving its instruction.},
  keywords = {Test-Driven Development (TDD); Unit Testing; Software Metrics; Automated Grading; Adherence; Compute}
}

@INCOLLECTION{Bulcao:2009,
  author = {Renato Bulcão},
  title = {Aprendizagem por m-learning},
  chapter = {12},
  pages = {81-86},
  crossref = {Litto-Formiga:2009}
}

@ARTICLE{Bull-Whittle:2014,
  author = {Bull, C. N. and Whittle, J.},
  title = {Supporting Reflective Practice in Software Engineering Education through a Studio-Based Approach},
  crossref = {journal:ieee:software},
  volume = {31},
  number = {4},
  month = jul # {--} # aug,
  year = {2014},
  pages = {44--50},
  doi = {10.1109/MS.2014.52},
  abstract = {Learning is a lifelong process, especially in the fast-paced software industry. In addition to formal training courses, good software developers continually learn by reflecting on what they've done in the past. However, reflective practice is rarely taught explicitly in university software engineering education. One way to teach reflective techniques from the start is through studio-based learning.},
  owner = {magsilva},
  timestamp = {2014.09.13}
}

@ARTICLE{Bulterman:2004,
  author = {Bulterman, D. C. A.},
  title = {Is it time for a moratorium on metadata?},
  crossref = {journal:ieee:multimedia},
  volume = {11},
  number = {4},
  month = oct # {--} # dec,
  year = {2004},
  pages = {10--17},
  doi = {10.1109/MMUL.2004.29},
  abstract = {This work discusses the author suggestion for locating content in mixed-media for context-sensitive queries. Also provides examples of nontextual approach, a system for organizing digital photographs in which all of the instances of a particular person can be found based on face recognition rather than keyword matching, and compared with a conventional metadata effort that uses predictive labelling of objects in the base data set.}
}

@ARTICLE{Burgstahler:2011,
  author = {Burgstahler, Sheryl},
  title = {Universal Design: Implications for Computing Education},
  crossref = {journal:acm:tce},
  volume = {11},
  number = {3},
  month = oct,
  year = {2011},
  pages = {1-17},
  doi = {10.1145/2037276.2037283},
  abstract = {Universal design (UD), a concept that grew from the field of architecture, has recently emerged as a paradigm for designing instructional methods, curriculum, and assessments that are welcoming and accessible to students with a wide range of characteristics, including those related to race, ethnicity, native language, gender, age, and disability. This proactive approach holds promise for more fully including underrepresented groups in computing studies and for decreasing the need, and thus costs, for academic accommodations for students with disabilities. This article summarizes the history and development of UD, references research and practices that support the UD approach, provides examples of the strategies that apply UD to instruction and assessment, and recommends topics for future research. Although the application of UD to teaching and learning is in its infancy, the potential of UD to improve computing instruction should not be ignored. Further research could test the efficacy of specific UD practices in promoting learning in computing fields.},
  keywords = {Disability, accessibility, assessment, instruction, teaching, universal design}
}

@ARTICLE{Burgstahler-etal:2012,
  author = {Burgstahler, Sheryl and Ladner, Richard E. and Bellman, Scott},
  title = {Strategies for increasing the participation in computing of students with disabilities},
  crossref = {journal:acm:inroads},
  volume = {3},
  number = {4},
  month = dec,
  year = {2012},
  pages = {42--48},
  doi = {10.1145/2381083.2381098},
  abstract = {It is predicted that the demand for workers in computing fields will continue to be high for years to come. However, some groups of people continue to be underrepresented in academic programs and careers in computing. People with disabilities form one such group of untapped talent. This article addresses the unique challenges faced by individuals with disabilities, and shares practices of a nationwide alliance, AccessComputing, that show promise for attracting qualified individuals with disabilities to computing fields.},
  keywords = {accessibility, assistive technology, disability, diversity, universal design}
}

@ARTICLE{Burke:2002,
  author = {Burke, Robin},
  title = {Hybrid Recommender Systems: Survey and Experiments},
  crossref = {journal:kluwer:umuai},
  volume = {12},
  number = {4},
  month = nov,
  year = {2002},
  pages = {331--370},
  doi = {10.1023/A:1021240730564},
  abstract = {Recommender systems represent user preferences for the purpose of suggesting items to purchase or examine. They have become fundamental applications in electronic commerce and information access, providing suggestions that effectively prune large information spaces so that users are directed toward those items that best meet their needs and preferences. A variety of techniques have been proposed for performing recommendation, including content-based, collaborative, knowledge-based and other techniques. To improve performance, these methods have sometimes been combined in hybrid recommenders. This paper surveys the landscape of actual and possible hybrid recommenders, and introduces a novel hybrid, EntreeC, a system that combines knowledge-based recommendation and collaborative filtering to recommend restaurants. Further, we show that semantic ratings obtained from the knowledge-based part of the system enhance the effectiveness of collaborative filtering.},
  keywords = {case-based reasoning, collaborative filtering, recommender systems},
  timestamp = {2013-09-24}
}

@INPROCEEDINGS{Burton:2008,
  author = {Burton, Benjamin A.},
  title = {Informatics Olympiads: Challenges in Programming and Algorithm Design},
  crossref = {proceedings:acsc:2008},
  pages = {9--13},
  abstract = {The International Olympiad in Informatics is a world-wide contest for high school students, with a strong focus on creativity and ingenuity in algorithm design. Here we describe the activities in Australia that support and complement this contest, including a range of programming competitions, more accessible pen-and-paper competitions, and other enrichment and training activities. Sample problems are included, along with suggestions for becoming involved.},
  owner = {magsilva},
  timestamp = {2014.08.30}
}

@INPROCEEDINGS{Bush:1990,
  author = {Bush, M.},
  title = {Improving software quality: the use of formal inspections at the {JPL}},
  crossref = {proceedings:icse:1990},
  pages = {196--199},
  abstract = {Finding and fixing defects early in the software deve1opmentlifecyc1eismuchcheaperthanfinding andfixing the samedefectslateron. After surveying detection practices in the best of industry, JPL Software Product Assurancedecided that the most cost-effective early defect detection technique was the Fagan Inspection procedure. This paper will describe this technique, how it was introduced to JPL, some of the difficulties invo1ved in transfering technology and the first provisional setof results.}
}

@ARTICLE{Cabot-etal:2014,
  author = {J. Cabot and R. Clarisó and D. Riera},
  title = {On the Verification of UML/OCL Class Diagrams using Constraint Programming},
  crossref = {journal:elsevier:jss},
  year = {2014},
  pages = {-},
  doi = {10.1016/j.jss.2014.03.023},
  abstract = {Assessment of the correctness of software models is a key issue to ensure the quality of the final application. To this end, this paper presents an automatic method for the verification of UML class diagrams extended with OCL constraints. Our method checks compliance of the diagram with respect to several correctness properties including weak and strong satisfiability or absence of constraint redundancies among others. The method works by translating the UML/OCL model into a Constraint Satisfaction Problem (CSP) that is evaluated using state-of-the-art constraint solvers to determine the correctness of the initial model. Our approach is particularly relevant to current MDA and MDD methods where software models are the primary artifacts of the development process and the basis for the (semi-)automatic code-generation of the final application.},
  keywords = {UML, OCL, MDD, Model Verification, Constraint Programming, Constraint Satisfaction Problem}
}

@ARTICLE{cacmstaff:2013,
  author = {{CACM Staff}},
  title = {No place for old educational flaws in new online media},
  crossref = {journal:acm:cacm},
  volume = {56},
  number = {3},
  month = mar,
  year = {2013},
  pages = {8--9},
  doi = {10.1145/2428556.2428559}
}

@ARTICLE{CACMStaff:2012:,
  author = {{CACM Staff}},
  title = {Credit non-anonymous reviewers with a name},
  crossref = {journal:acm:cacm},
  volume = {55},
  number = {2},
  month = feb,
  year = {2012},
  pages = {6--7},
  doi = {10.1145/2076450.2076452},
  issue_date = {February 2012},
  lang = {en}
}

@INCOLLECTION{CaeiroRodrigues:2008,
  author = {Manuel Caeiro-Rodríguez},
  title = {{PoEML}: A separation-of-concerns proposal to instructional design},
  publisher = {IGI Global},
  year = {2008},
  pages = {183--207},
  abstract = {This chapter introduces a new visual Educational Modeling Language (EML) based on a separation-of-concerns approach, PoEML: Perspective-oriented EML. EMLs were proposed to support the modeling of educational units. These languages are related to ID, as they are intended to represent models of educational units. This chapter introduces the PoEML separation of concerns and its graphic constructs. The main idea underlying PoEML is to break down the modeling of educational units into separate parts that can be specified independently. PoEML is mainly focused on supporting the computational execution of educational unit models. In addition, the separation of concerns allows us to approach the modeling of educational units in an incremental way, offering advantages in expressiveness, formality, adaptability and flexibility.},
  crossref = {Botturi-Stubbs:2008},
  doi = {10.4018/978-1-59904-729-4.ch010},
  owner = {magsilva}
}

@INCOLLECTION{CaeiroRodrigues:2007,
  author = {Manuel Caeiro-Rodríguez},
  title = {Learning Objects and Instructional Design: From Contents to Activities},
  year = {2007},
  chapter = {8},
  pages = {219-251},
  crossref = {Koohang-Harman:2007}
}

@INPROCEEDINGS{Caglayan-etal:2013,
  author = {Caglayan, B. and Bener, A.B. and Miranskyy, A.},
  title = {Emergence of developer teams in the collaboration network},
  crossref = {proceedings:chase:2013},
  pages = {33-40},
  doi = {10.1109/CHASE.2013.6614729},
  abstract = {Developer teams may naturally emerge independent of managerial decisions, organizational structure, or work locations in large software. Such self organized collaboration teams of developers can be traced from the source code repositories. In this paper, we identify the developer teams in the collaboration network in order to present the work team evolution and the factors that affect team stability for a large, globally developed, commercial software. Our findings indicate that: a) Number of collaboration teams do not change over time, b) Size of the collaboration teams increases over time, c) Team activity is not related with team size, d) Factors related to team size, location and activity affect the stability of teams over time.}
}

@ARTICLE{Calders-Pechenizkiy:2012,
  author = {Calders, Toon and Pechenizkiy, Mykola},
  title = {Introduction to the special section on educational data mining},
  crossref = {journal:acm:sigkdd},
  volume = {13},
  number = {2},
  month = may,
  year = {2012},
  pages = {3--6},
  doi = {10.1145/2207243.2207245},
  abstract = {Educational Data Mining (EDM) is an emerging multidisciplinary research area, in which methods and techniques for exploring data originating from various educational information systems have been developed. EDM is both a learning science, as well as a rich application area for data mining, due to the growing availability of educational data. EDM contributes to the study of how students learn, and the settings in which they learn. It enables data-driven decision making for improving the current educational practice and learning material. We present a brief overview of EDM and introduce four selected EDM papers representing a crosscut of different application areas for data mining in education.}
}

@INPROCEEDINGS{camacho-guerrero:2002,
  author = {J. A. Camacho-Guerrero and A. A. Macedo and R. P. M. Fortes},
  title = {Uma infra-estrutura configurável para serviços web de criação automática de ligações},
  crossref = {proceedings:sbmidia:2002},
  pages = {298-305},
  address = {Fortaleza, CE},
  booktitle = {VIII Brazilian Symposium on Multimedia and Hypermedia Systems (SBMIDIA'2002)},
  month = oct,
  owner = {magsilva},
  timestamp = {2008.07.30},
  year = {2002}
}

@INPROCEEDINGS{Campanha-etal:2009,
  author = {Diogo Nascimento Campanha and Simone do Rocio Senger Souza and Otávio Augusto Lazzarini Lemos and Ellen Francine Barbosa and José Carlos Maldonado.},
  title = {Reutilização de Conjuntos de Teste: Um Estudo no Domínio de Algoritmos de Ordenação},
  crossref = {proceedings:eselaw:2009},
  abstract = {De acordo com resultados anteriores, um conjunto de teste (T) adequado para o critério Análise de Mutantes (AM) - AM-adequado - para um programa P não é adequado para um programa Q, equivalente a P. Por outro lado, apesar de T não ser 100% adequado para o teste de Q, é possível que na prática ele seja próximo ao adequado, motivando sua reutilização. Neste artigo apresenta-se um experimento que busca avaliar o nível de adequação de Ts AM-adequados para programas de referência em outros programas equivalentes. O estudo é realizado no domínio de algoritmos de ordenação. Foram construídos Ts AM-adequados para 6 algoritmos diferentes de ordenação, conjuntos estes que foram executados contra 22 implementações diferentes construídas por alunos de graduação. Para verificar a similaridade das médias das coberturas atingidas pelos diferentes Ts, foram realizados testes estatísticos de análise de variância. Resultados indicam que não há diferença significativa entre as coberturas atingidas pelos diferentes Ts, o que motiva a sua reutilização. Além disso um segundo teste indicou que essas coberturas são superiores às obtidas por um T aleatório.}
}

@INPROCEEDINGS{Campbell-etal:2014,
  author = {Campbell, Jennifer and Horton, Diane and Craig, Michelle and Gries, Paul},
  title = {Evaluating an Inverted {CS1}},
  crossref = {proceedings:sigcse:2014},
  pages = {307--312},
  doi = {10.1145/2538862.2538943},
  abstract = {This case study explores an inverted classroom offering of an introductory programming course (CS1). Students prepared for lecture by watching short lecture videos and completing required in-video quiz questions. During lecture, the students worked through exercises with the support of the instructor and teaching assistants. We describe the course implementation and its assessment, including pre- and post-course surveys. We also discuss lessons learned, modifications that we plan to make for the next offering, and recommendations for others teaching inverted courses.},
  keywords = {CS1, case study, flipped classroom, inverted classroom, novice programming}
}

@INPROCEEDINGS{Campos-Ferreira:2004,
  author = {Campos, Cassio P. de and Carlos E. Ferreira},
  title = {{BOCA}: um sistema de apoio a competições de programação},
  crossref = {proceedings:wei:2004},
  pages = {1--11},
  abstract = {Neste artigo apresentamos o BOCA, um sistema de apoio a competições de programação desenvolvido para ser usado na Maratona de Programação da Sociedade Brasileira de Computação. O sistema pode ser usado também no apoio a disciplinas em que se faça uso de submissão e correcão de trabalhos durante as aulas.},
  abstract-en = {In this article we describe BOCA, a software for supporting programming contests developed to be used in the Maratona de Programação of the Brazilian Computing Society. The system can also be used for supporting disciplines that make evaluation of student assignments during the classes.},
  title-en = {{BOCA}: A Support System for Programming Contests}
}

@INCOLLECTION{Canas-Novak:2008,
  author = {Alberto J. Canas and Joseph D. Novak},
  title = {Concept Mapping Using {CmapTools} to Enhance Meaningful Learning},
  series = {Advanced Information and Knowledge Processing},
  chapter = {2},
  pages = {25--46},
  edition = {1},
  abstract = {Concept maps are graphical tools that have been used in all facets of education and training for organizing and representing knowledge. When learners build concept maps, meaningful learning is facilitated. Computer-based concept mapping software such as CmapTools have further extended the use of concept mapping and greatly enhanced the potential of the tool, facilitating the implementation of a concept map-centered learning environment. In this chapter, we briefly present concept mapping and its theoretical foundation, and illustrate how it can lead to an improved learning environment when it is combined with CmapTools and the Internet. We present the nationwide "Proyecto Conéctate al Conocimiento" in Panama as an example of how concept mapping, together with technology, can be adopted by hundreds of schools as a means to enhance meaningful learning.},
  crossref = {Okada-etal:2008},
  lang = {en}
}

@ARTICLE{CaneteValdeon:2013,
  author = {Cañete-Valdeón, José Miguel},
  title = {How Influential Has Academic and Industrial Research Been in Current Software Life Cycles? A Retrospective Analysis of Four Mainstream Activities},
  crossref = {journal:elsevier:ist},
  volume = {55},
  number = {2},
  month = feb,
  year = {2013},
  pages = {226--240},
  doi = {10.1016/j.infsof.2012.07.019},
  abstract = {Context: Knowledge transfer is an important responsibility of universities and research institutes as part of their contribution to society. In the field of software engineering, several studies have been performed to show the influence of research in popular technologies such as middleware systems. However, there is no scholarly analysis of the influence that research has had in mainstream activities of current software life cycles. Objective: We analyse how methodological research has influenced activities of widespread use in current software life cycles. To keep this goal into manageable bounds, we focus on four very successful trends of current practice: iterative development, architecture-centric development, requirements-driven development, and coherent method integration. Method: We follow different forms of evidence backwards in time. As signs of influence we admit the following categories: citations included in papers and standards, interviews, historical essays, people movement, and acquisitions of companies. Results: For each one of the mentioned activities, we obtain a trace diagram showing the indirect influence that pieces of research have had in the selected activities of software life cycles. Conclusions: Our results support the following claims: (1) mainstream dissemination of the analysed methodological research has taken on the order of 20-40 years; (2) interdisciplinarity has been important in the research that influenced some very popular activities of current software life cycles; (3) research on life cycles is more influential when it originates from large development projects; and (4) probably the best results can be obtained if industrial research goes hand in hand with academic research.},
  keywords = {History of computing, Knowledge transfer, Practice of software development, Standardisation},
  url = {http://dx.doi.org/10.1016/j.infsof.2012.07.019},
  acmid = {2400999},
  address = {Newton, MA, USA},
  issn = {0950-5849},
  issue_date = {February, 2013},
  journal = {Inf. Softw. Technol.},
  numpages = {15},
  owner = {magsilva},
  publisher = {Butterworth-Heinemann},
  timestamp = {2014.10.23}
}

@INPROCEEDINGS{Canfora-etal:2012,
  author = {Canfora, Gerardo and Di Penta, Massimiliano and Oliveto, Rocco and Panichella, Sebastiano},
  title = {Who is going to mentor newcomers in open source projects?},
  crossref = {proceedings:fse:2012},
  pages = {44:1--44:11},
  doi = {10.1145/2393596.2393647},
  abstract = {When newcomers join a software project, they need to be properly trained to understand the technical and organizational aspects of the project. Inadequate training could likely lead to project delay or failure. In this paper we propose an approach, named Yoda (Young and newcOmer Developer Assistant) aimed at identifying and recommending mentors in software projects by mining data from mailing lists and versioning systems. Candidate mentors are identified among experienced developers who actively interact with newcomers. Then, when a newcomer joins the project, Yoda recommends her a mentor that, among the available ones, has already discussed topics relevant for the newcomer. Yoda has been evaluated on software repositories of five open source projects. We have also surveyed some developers of these projects to understand whether mentoring was actually performed in their projects, and asked them to evaluate the mentoring relations Yoda identified. Results indicate that top committers are not always the most appropriate mentors, and show the potential usefulness of Yoda as a recommendation system to aid project managers in supporting newcomers joining a software project.},
  keywords = {developer mentoring, empirical studies, mining software repositories}
}

@INPROCEEDINGS{Cardozo-etal:2010,
  author = {Cardozo, Eliza S. F. and Neto, J. Benito F. Araújo and Barza, Alexandre and França, A. César C. and da Silva, Fabio Q. B.},
  title = {{SCRUM} and productivity in software projects: a systematic literature review},
  crossref = {proceedings:ease:2010},
  pages = {131--134},
  abstract = {Background: Agile methods have increasingly attracted interest in the Software Industry. SCRUM is currently one of the most studied agile method, because of both its novelty and the assumption that SCRUM is able to improve project productivity. Objective/Method: This article describes a systematic literature review, which aims to find scientific evidence of the correlation between the use of SCRUM and productivity in Software Projects. Results/Conclusion: Among 274 primary studies, this research selected 28 papers presenting strong evidence on the research questions. According to these results, the relation between SCRUM and productivity may be positive.},
  keywords = {SCRUM, agile methods, productivity, software project, systematic literature review}
}

@ARTICLE{Carjaval-etal:2013,
  author = {Carjaval, L. and Moreno, A. and Sanchez-Segura, M. and Seffah, A.},
  title = {Usability through Software Design},
  crossref = {journal:ieee:tse},
  volume = {Pre-Print},
  number = {99},
  year = {2013},
  pages = {1--15},
  doi = {10.1109/TSE.2013.29},
  abstract = {Over the past two decades the HCI community has proposed specific features that software applications should include to overcome some of the most common usability problems. However, incorporating such usability features into software applications may not be a straightforward process for software developers who have not been trained in usability (i.e., determining when, how, and why usability features should been considered). We have defined a set of usability guidelines for software development to help software engineers incorporate particular usability features into their applications. In this paper we focus on the software design artifacts provided by the guidelines. We detail the structure of the proposed design artifacts and how they should be used according to the software development process and software architecture used in each application. We have tested our guidelines in an academic setting. Preliminary validation shows that the use of the guidelines reduces development time, improves the quality of the resulting designs and significantly decreases the perceived complexity of the usability features from the developers' perspective.},
  keywords = {Design;General;Software Engineering;Software/Software Engineering}
}

@INPROCEEDINGS{carlisle:2010,
  author = {Carlisle, Martin C.},
  title = {Using You Tube to enhance student class preparation in an introductory Java course},
  crossref = {proceedings:sigcse:2010},
  pages = {470--474},
  doi = {10.1145/1734263.1734419},
  abstract = {We provided 21 short YouTube videos for an Introduction to Programming in Java course. Students were surveyed on how often they watched the videos and did the readings, and how much these activites contributed to their learning. When professors reduced lecture time and increased lab time, students watched videos and read significantly more. Their test scores were at least as high and they indicated they would prefer to not have more lecture. The YouTube videos also provided a source of outreach for the university, drawing a large number of views, including the 13-17 year-old demographic.},
  keywords = {java, videos, youtube}
}

@INPROCEEDINGS{Carter-etal:2011,
  author = {Carter, Janet and Bouvier, Dennis and Cardell-Oliver, Rachel and Hamilton, Margaret and Kurkovsky, Stanislav and Markham, Stefanie and McClung, O. William and McDermott, Roger and Riedesel, Charles and Shi, Jian and White, Su},
  title = {Motivating all our students?},
  crossref = {proceedings:itcse-wgr:2011},
  pages = {1--18},
  doi = {10.1145/2078856.2078858},
  abstract = {Academics expend a large amount of time and effort to sustain and enhance the motivation of undergraduate students. Typically based on a desire to ensure that all students achieve their full potential, approaches are based on an understanding that students who are highly motivated will learn more. Furthermore, institutional rewards accrue from effective use of academics' time, along with financial benefits associated with high levels of retention and progression. This working group report, based on practice in Europe, Australasia and North America, builds on previous work. It provides an updated and revised literature review, analyses a larger collection of survey data and has sought to triangulate earlier findings with qualitative data from practitioner interviews. The report covers established approaches in teaching, support and extra-curricular activities. It tracks emerging practice such as streamed and differentiated teaching, and research based and authentic learning. It also considers contemporary innovations in student activities. Finally it reports on a repository of tips and techniques which has been established to support faculty wishing to change or review current methods.},
  keywords = {differentiation in the classroom, learning programming, otivation}
}

@ARTICLE{Carter-etal:2008,
  author = {Janet Carter and Nick Efford and Stephan Jamieson and Tony Jenkins and Su White},
  title = {Taxing our Best Students},
  crossref = {journal:hea-ics;italics},
  volume = {7},
  number = {1},
  month = feb,
  year = {2008},
  pages = {120--127},
  abstract = {A significant challenge that faces any teacher of introductory programming is the diversity of the class. At one extreme there will be students who have never programmed before, while at the other there will be students who have many years experience of programming. Handling this diversity is difficult. The temptation for the instructor is often to focus on the novice group and to assume that the others will get by with minimal supervision. This is understandable, but it can be risky. There is a very real risk that the neglected group of experienced programmers become bored and disengage from the course. At the worst, they can lose motivation and fail or drop out altogether. This paper describes and presents the outcomes of a project aimed at challenging the more experienced programmers in four introductory programming classes at four different UK institutions. The project took the form of a competition in which students were asked to devise and solve a series of programming challenges.},
  keywords = {programming, competition, diversity, retention, motivation},
  url = {http://eprints.soton.ac.uk/265379/}
}

@ARTICLE{Carterette:2012:,
  author = {Carterette, Benjamin A.},
  title = {Multiple testing in statistical analysis of systems-based information retrieval experiments},
  crossref = {journal:acm:tois},
  volume = {30},
  number = {1},
  month = mar,
  year = {2012},
  pages = {4:1--4:34},
  doi = {10.1145/2094072.2094076},
  abstract = {High-quality reusable test collections and formal statistical hypothesis testing together support a rigorous experimental environment for information retrieval research. But as Armstrong et al. [2009b] recently argued, global analysis of experiments suggests that there has actually been little real improvement in ad hoc retrieval effectiveness over time. We investigate this phenomenon in the context of simultaneous testing of many hypotheses using a fixed set of data. We argue that the most common approaches to significance testing ignore a great deal of information about the world. Taking into account even a fairly small amount of this information can lead to very different conclusions about systems than those that have appeared in published literature. We demonstrate how to model a set of IR experiments for analysis both mathematically and practically, and show that doing so can cause p-values from statistical hypothesis tests to increase by orders of magnitude. This has major consequences on the interpretation of experimental results using reusable test collections: it is very difficult to conclude that anything is significant once we have modeled many of the sources of randomness in experimental design and analysis.},
  keywords = {Information retrieval, effectiveness evaluation, experimental design, statistical analysis, test collections}
}

@ARTICLE{Carvalho-etal:2007,
  author = {Eduardo Rodrigues de Carvalho and Gil Garcia de Barros and Laisa Caroline de Paula Costa and Regis Rossi Alves Faria and Rogério Pernas Nunes and Roseli de Deus Lopes and Marcelo Knörich Zuffo},
  title = {The Brazilian Digital Television System Access Device Architecture},
  crossref = {journal:sbc:jbcs},
  volume = {13},
  number = {1},
  year = {2007},
  pages = {95-113},
  abstract = {In early 2003, the Brazilian government accelerated the decision process on analog to digital transition of terrestrial TV broadcast infrastructure, naming this initiative The Brazilian Digital Television System (SBTVD). This paper describes the access device architecture we have proposed for the SBTVD, as well as related issues. We focused on several requirements among which: flexibility to support the social economical diversity enabling market implementations that can vary on cost, complexity and applications; digital inclusion targeting a minimal cost architecture providing a simple access device to information and services by convergent broadcast and point-to-point telecommunication means; and scalability targets incorporating state-of-the-art technology, considering emerging services and the current legacy analog TV infrastructure available in Brazil. We cover the following specific topics: an architecture overview considering scalability, interoperability and regional and international requirements, operating system and middleware interfaces, audio and video coding formats and associate standards, technical and economical analysis, usability and user interface consistency. Finally two prototypes for the outlined access device architecture are reported.},
  keywords = {interactive Digital TV (iDTV), The Brazilian Digital Television System (SBTVD), Access Device Architecture, digital broadcasting, digital television (DTV), high definition TV (HDTV), Digital Television Services, audio and video coding},
  journal = {Journal of the Brazilian Computer Society},
  publisher = {SBC},
  timestamp = {2012.02.04}
}

@INPROCEEDINGS{Carvalho-Macedo:2010,
  author = {Lucas Carvalho and Hendrik Macedo.},
  title = {Estendendo a {NCL} para Promover Interatividade Vocal em Aplicações {Ginga} na {TVDi} Brasileira},
  crossref = {proceedings:webmedia:2010},
  pages = {227--234},
  abstract-en = {Vocal access to TVDi content can promote social and digital inclusion. Actually, vocal interface enhances accessibility since it enables TVDi usage by physical-impaired people and blind community. In the scientific literature, however, TVDi voice-driven interactivity is not often considered. There are just few works concerning architecture proposals, but none of them is actually properly validated. We consider the integration of VoiceXML voice gateways and the middleware Ginga a promising hypothesis for architecture definition. In this paper, we describe such an integration proposal and perform validation by means of two different case studies, two different TVDi applications. The proposal key element is the syntax extension we provide to NCL in order to incorporate some native VoiceXML elements. Results show that the vocal interactivity mecanism has achieved similar functionality to that of the remote control.},
  keywords-en = {Ginga, NCL, Vocal interaction, Accessibility}
}

@INPROCEEDINGS{Carver-etal:2003,
  author = {Carver, J. and Jaccheri, L. and Morasca, S. and Shull, F.},
  title = {Issues in using students in empirical studies in software engineering education},
  crossref = {proceedings:metrics:2003},
  pages = {239--249},
  doi = {10.1109/METRIC.2003.1232471},
  abstract = { Several empirical studies have been carried out with college students as subjects in the last few years. Researchers often use these studies to pilot experiments before they are carried out in industrial environments. Reports on these studies usually focus on the results obtained and issues such as their external validity. However, the effects and value of empirical studies with students may go beyond the contribution to scientific literature. For instance, the pedagogical challenges and value of these studies is hardly ever stressed. We identify four primary actors that are involved in these empirical studies, i.e., researchers, students, instructors, and industry. We discuss the costs and benefits of empirical studies with students for these actors, which are different because of the actors' different goals, expectations, and constraints, which must be recognized to fully exploit empirical studies with students. We also provide some advice on how to carry out empirical studies with students based on our experiences.},
  keywords = {Empirical Studies, Pilot Studies, Software Engineering Education}
}

@ARTICLE{Carver-etal:2010,
  author = {Carver, Jeffrey C. and Jaccheri, Letizia and Morasca, Sandro and Shull, Forrest},
  title = {A checklist for integrating student empirical studies with research and teaching goals},
  crossref = {journal:springer:ese},
  volume = {15},
  number = {1},
  month = feb,
  year = {2010},
  pages = {35--59},
  doi = {10.1007/s10664-009-9109-9},
  abstract = {The use of empirical studies with students in software engineering helps researchers gain insight into new or existing techniques and methods. However, due mainly to concerns of external validity, questions have been raised about the value of these types of studies. The authors of this paper draw on their experiences of conducting a large number of empirical studies in university courses in three countries (Italy, Norway, and the United States) to address this important issue. This paper first identifies the requirements that research and pedagogy place on a valid empirical study with students. This information is then used as the basis for a checklist that provides guidance for researchers and educators when planning and conducting studies in university courses. The goal of this checklist is to help ensure that these studies have as much research and pedagogical value as possible. Finally, an example application of the checklist is provided to illustrate its use.},
  keywords = {Empirical studies, Software engineering education}
}

@ARTICLE{Caso-etal:2012,
  author = {Caso, Guido de and Garbervetsky, Diego and Gorín, Daniel},
  title = {Integrated program verification tools in education},
  crossref = {journal:wiley:spe},
  year = {2012},
  pages = {n/a--n/a},
  doi = {10.1002/spe.2143},
  abstract = {Automated software verification is an active field of research, which has made enormous progress both in theoretical and practical aspects. Even if not ready for large-scale industrial adoption, the technology behind automated program verifiers is now mature enough to gracefully handle the kind of programs that arise in introductory programming courses. This opens exciting new opportunities in teaching the basics of reasoning about program correctness to novice students. However, for these tools to be effective, command-line-style user-interfaces need to be replaced. In this paper, we report on our experience using the verifying compiler for PEST in an introductory programming course as well as in a more advanced course on program analysis. PEST is an extremely basic programming language, but with expressive annotations capabilities and semantics amenable to verification. In particular, we comment on the crucial role played by the integration of this verifying compiler with the Eclipse integrated development environment.},
  keywords = {education, formal methods, automated program verification, Eclipse plug-in}
}

@ARTICLE{Castelluccia-Visaggio:2013,
  author = {Castelluccia, Daniela and Visaggio, Giuseppe},
  title = {Teaching Evidence-based Software Engineering: Learning by a Collaborative Mapping Study of Open Source Software},
  crossref = {journal:acm:sen},
  volume = {38},
  number = {6},
  month = nov,
  year = {2013},
  pages = {1--4},
  doi = {10.1145/2532780.2532803},
  abstract = {In this paper, we share our experiences about teaching evidence-based software engineering to students of a Master degree program in Computer Science. We provided a semester-long course, composed of lessons about empirical and experimental methods. It also included a collaborative project concerning a systematic mapping study of the challenges in the adoption of open source software in a business context. All students collaborated on the project by analyzing emerging results in the scientific literature. They evaluated the proposals in terms of level of novelty and evidence and delivered a complete report, which summarized the risk factors in the adoption of open source software and offers technical knowledge about evolutionary patterns and development community support, with practical implications. As a side effect, this problem-based learning approach provides a positive impact in terms of students' participation, teamwork attitude, professional interest in open source software, and exam passing.},
  keywords = {decision making, education, empirical methods, evidence-based software engineering, mapping study, open source software, software engineering, systematic, systematic literature study}
}

@BOOK{Catania:1999,
  title = {Aprendizagem: Comportamento, Linguagem e Cognição},
  publisher = {Artes Médicas},
  year = {1999},
  author = {A. Charles Catania},
  isbn = {85-7307-553-8},
  pages = {467},
  address = {Porto Alegre, RS, } # Brazil,
  edition = {4},
  note = {Traduçao por Deisy das Graças de Souza e outros.},
  crossref = {Catania:1998}
}

@INPROCEEDINGS{Cauevic-etal:2013,
  author = {Cauevic, A. and Punnekkat, S. and Sundmark, D.},
  title = {{TDD^{HQ}}: Achieving higher quality testing in test driven development},
  crossref = {proceedings:euromicro-seaa:2013},
  pages = {33--36},
  doi = {10.1109/SEAA.2013.47},
  abstract = {Test driven development (TDD) appears not to be immune to positive test bias effects, as we observed in several empirical studies. In these studies, developers created a significantly larger set of positive tests, but at the same time the number of defects detected with negative tests is significantly higher than those detected by positive ones. In this paper we propose the concept of TDDHQ which is aimed at achieving higher quality of testing in TDD by augmenting the standard TDD with suitable test design techniques. To exemplify this concept, we present combining equivalence partitioning test design technique together with the TDD, for the purpose of improving design of test cases. Initial evaluation of this approach showed a noticeable improvement in the quality of test cases created by developers utilising TDDHQ approach. © 2013 IEEE.},
  keywords = {Bias effects; Empirical studies; Improving designs; Quality testing; Test case; Test designs; Test driven development, Design; Software engineering; Testing, Computer programming},
  owner = {magsilva},
  references = {Beck, K., (2000) Extreme Programming Explained: Embrace Change, , Boston, MA, USA: Addison-Wesley Longman Publishing Co., Inc; Causevic, A., Sundmark, D., Punnekkat, S., Factors limiting industrial adoption of test driven development: A systematic review (2011) Software Testing, Verification and Validation (ICST), 2011 IEEE Fourth International Conference on, pp. 337-346. , march; Causevic, A., Sundmark, D., Punnekkat, S., Impact of test design technique knowledge on test driven development: A controlled experiment (2012) XP, Ser. Lecture Notes in Business Information Processing, 111, pp. 138-152. , , C. Wohlin, Ed.Springer; Leventhal, L.M., Teasley, B., Rohlman, D.S., Instone, K., Positive test bias in software testing among professionals: A review (1993) Selected Papers from the Third International Conference on Human-Computer Interaction, pp. 210-218. , London, UK: Springer-Verlag; Causevic, A., Punnekkat, S., Sundmark, D., Quality of testing in test driven development (2012) Quality of Information and Communications Technology (QUATIC), 2012 Eight International Conference on the, , September; Causevic, A., Shukla, R., Punnekkat, S., Sundmark, D., Effects of negative testing on tdd: An industrial experiment (2013) XP, Ser. Lecture Notes in Business Information Processing, 149. , , H. Baumeister and B. Weber, Eds.Springer, (to be presented); Megen, R., Meyerhoff, D., Costs and benefits of early defect detection: Experiences from developing client server and host applications (1995) Software Quality Journal, 4 (4), pp. 247-256; Madeyski, L., The impact of Test-First programming on branch coverage and mutation score indicator of unit tests: An experiment (2010) Inf. Softw. Technol., 52, pp. 169-184. , February; Shelton, W., Li, N., Ammann, P., Offutt, J., Adding criteria-based tests to test driven development (2012) Proceedings of the 2012 IEEE Fifth International Conference on Software Testing, Verification and Validation, Ser. ICST '12, pp. 878-886. , Washington, DC, USA: IEEE Computer Society},
  timestamp = {2014.08.19}
}

@INPROCEEDINGS{Causevic-etal:2012:quatic,
  author = {Causevic, A. and Punnekkat, S. and Sundmark, D.},
  title = {Quality of testing in test driven development},
  crossref = {proceedings:quatic:2012},
  pages = {266--271},
  doi = {10.1109/QUATIC.2012.49},
  abstract = {Test-driven development is an essential part of Extreme Programming approach with the preference of being followed in other Agile methods as well. For several years, researchers are performing empirical investigations to evaluate quality improvements in the resulting code when test-driven development is being used. However, very little had been reported into investigating the quality of the testing performed in conjunction with test-driven development. In this paper we present results from an experiment specifically designed to evaluate the quality of test cases created by developers who used the test-first and the traditional test-last approaches. On an average, the quality of testing in test-driven development was almost the same as the quality of testing using test-last approach. However, detailed analysis of test cases, created by test-driven development group, revealed that 29% of test cases were "negative" test cases (based on non-specified requirements) but contributing as much as 65% to the overall tests quality score of test-first developers. We are currently investigating the possibility of extending testdriven development to facilitate non-specified requirements to a higher extent and thus minimise the impact of a potentially inherent effect of positive test bias. © 2012 IEEE.},
  keywords = {experiment; software testing; test case quality; test driven development},
  owner = {magsilva},
  references = {Beck, K., (2000) Extreme Programming Explained: Embrace Change, , Boston, MA, USA: Addison-Wesley Longman Publishing Co., Inc; Koskela, L., (2007) Test Driven: Practical Tdd and Acceptance Tdd for Java Developers, , Greenwich, CT, USA: Manning Publications Co; Causevic, A., Sundmark, D., Punnekkat, S., An Industrial Survey on Contemporary Aspects of Software Testing Proceedings of the 3rd International Conference on Software Testing, Verification and Validation (ICST), 2010, pp. 393-401; George, B., Williams, L., A structured experiment of test-driven development (2003) Information and Software Technology, 46 (5), pp. 337-342; Erdogmus, H., Morisio, M., Torchiano, M., On the Effectiveness of the Test-First Approach to Programming (2005) IEEE Transactions on Software Engineering, 31, pp. 226-237; Janzen, D.S., Saiedian, H., On the Influence of Test-Driven Development on Software Design (2006) Software Engineering Education and Training, Conference on, pp. 141-148. , vol. 0; Gupta, A., Jalote, P., An Experimental Evaluation of the Effectiveness and Efficiency of the Test Driven Development (2007) ESEM '07, pp. 285-294. , Proceedings of the First International Symposium on Empirical Software Engineering and Measurement, ser. Washington, DC, USA: IEEE Computer Society; Vu, J.H., Frojd, N., Shenkel-Therolf, C., Janzen, D.S., Evaluating Test-Driven Development in an Industry-Sponsored Capstone Project (2009) Proceedings of the 2009 Sixth International Conference on Information Technology: New Generations, pp. 229-234. , Washington, DC, USA: IEEE Computer Society; Causevic, A., Sundmark, D., Punnekkat, S., Factors Limiting Industrial Adoption of Test Driven Development: A Systematic Review Proceedings of the 4th International Conference on Software Testing, Verification and Validation (ICST), 2011; Madeyski, L., The impact of Test-First programming on branch coverage and mutation score indicator of unit tests: An experiment (2010) Inf. Softw. Technol., 52, pp. 169-184. , February; Causevic, A., Sundmark, D., Punnekkat, S., Test Case Quality in Test Driven Development: A Study Design and a Pilot Experiment International Conference on Evaluation & Assessment in Software Engineering (EASE 2012), May 2012; Kollanus, S., Isomöttönen, V., Understanding TDD in academic environment: Experiences from two experiments (2008) Koli '08, pp. 25-31. , Proceedings of the 8th International Conference on Computing Education Research, ser. New York, NY, USA: ACM; http://www.eclipse.orgjUnit Framework, , http://www.junit.org; Flohr, T., Schneider, T., Lessons Learned from an XP Experiment with Students: Test-First Needs More Teachings (2006) Lecture Notes in Computer Science, 4034, pp. 305-318. , Product-Focused Software Process Improvement, ser. J. Mnch and M. Vierimaa, Eds. Springer Berlin / Heidelberg; EclEmma - Java Code Coverage for Eclipse, , http://www.eclemma.org; Judy - Java Mutation Tester, , http://www.java.mu; Causevic, A., Sundmark, D., Punnekkat, S., Impact of Test Design Technique Knowledge on Test Driven Development: A Controlled Experiment (2012) Lecture Notes in Business Information Processing, , Agile Processes in Software Engineering and Extreme Programming - 13th International Conference, XP 2012, Malmö, Sweden, May 20-25, 2012. Proceedings, ser. Springer, to appear; Teasley, B.E., Leventhal, L.M., Mynatt, C.R., Rohlman, D.S., Why Software Testing Is Sometimes Ineffective: Two Applied Studies of Positive Test Strategy (1994) Journal of Applied Psychology, 79 (1), pp. 142-155; Leventhal, L.M., Teasley, B., Rohlman, D.S., Instone, K., Positive Test Bias in Software Testing Among Professionals: A Review (1993) Selected Papers from the Third International Conference on Human-Computer Interaction, pp. 210-218. , London, UK: Springer-Verlag},
  timestamp = {2014.08.19}
}

@INPROCEEDINGS{Causevic-etal:2013:cesi,
  author = {Causevic, A. and Shukla, R. and Punnekkat, S.},
  title = {Industrial study on test driven development: Challenges and experience},
  crossref = {proceedings:cesi:2013},
  pages = {15--20},
  doi = {10.1109/CESI.2013.6618464},
  abstract = {Conducting empirical studies in industry always presents a major challenge for many researchers. Being a graduate student does not make things any easier. Often due to the lack of experience, credibility or just very limited networking, graduate students do not receive many opportunities to directly collaborate with industry and experiment their theoretical models in a realistic environment. On the other hand, empirical research conducted in an academic settings is often criticised for using students as subjects and working with a small sample size, thus creating major validity threat of the published results. In this paper we are presenting an experience report from an industrial empirical study conducted at Infosys Ltd., India with the support of their global internship program for graduate students, InStep. Focus of the paper is to present several challenges arisen before, during, and after the study, requiring an immediate attention in order to have a successful experiment completion. We also discuss and elaborate the data analysis results and its implication to our current research activities. © 2013 IEEE.},
  keywords = {Industrial experiment; Test Driven Development; Test Efficiency},
  owner = {magsilva},
  references = {Causevic, A., Sundmark, D., Punnekkat, S., Impact of test design technique knowledge on test driven development: A controlled experiment (2012) XP, Ser. Lecture Notes in Business Information Processing, 111, pp. 138-152. , C. Wohlin, Ed. Springer; Teasley, B.E., Leventhal, L.M., Mynatt, C.R., Rohlman, D.S., Why software testing is sometimes ineffective: Two applied studies of positive test strategy (1994) Journal of Applied Psychology, 79 (1), pp. 142-155; Leventhal, L.M., Teasley, B., Rohlman, D.S., Instone, K., Positive test bias in software testing among professionals: A review (1993) Selected Papers from the Third International Conference on HumanComputer Interaction, pp. 210-218. , London, UK: Springer-Verlag; Beck, K., (2000) Extreme Programming Explained: Embrace Change, , Boston, MA, USA: Addison-Wesley Longman Publishing Co., Inc; Causevic, A., Sundmark, D., Punnekkat, S., Test case quality in test driven development: A study design and a pilot experiment (2012) Evaluation Assessment in Software Engineering (EASE 2012), pp. 223-227. , 16th International Conference on, may; http://www.eclipse.orghttp://www.junit.orgKollanus, S., Isomöttönen, V., Understanding tdd in academic environment: Experiences from two experiments (2008) Proceedings of the 8th International Conference on Computing Education Research, pp. 25-31. , ser. Koli '08. New York, NY, USA: ACM; Flohr, T., Schneider, T., Lessons learned from an xp experiment with students: Test-first needs more teachings (2006) Product-Focused Software Process Improvement, 4034, pp. 305-318. , ser. Lecture Notes in Computer Science, J. Münch and M. Vierimaa, Eds. Springer Berlin / Heidelberg; Bergersen, G.R., Sjøberg, D.I.K., Evaluating methods and technologies in software engineering with respect to developers' skill level (2012) International Conference on Evaluation & Assessment in Software Engineering, , EASE},
  timestamp = {2014.08.19}
}

@INPROCEEDINGS{Causevic-etal:2013:xp,
  author = {Causevic, Adnan and Shukla, Rakesh and Punnekkat, Sasikumar and Sundmark, Daniel},
  title = {Effects of Negative Testing on {TDD}: An Industrial Experiment},
  crossref = {proceedings:xp:2013},
  pages = {91--105},
  doi = {10.1007/978-3-642-38314-4_7},
  abstract = {In our recent academic experiments, an existence of positive test bias, that is lack of negative test cases, was identified when a test driven development approach was used. At the same time, when defect detecting ability of individual test cases was calculated, it was noted that the probability of a negative test case to detect a defect was substantially higher than that of a positive test case. The goal of this study is to investigate the existence of positive test bias in test driven development within an industrial context, and measure defect detecting ability of both positive and negative test cases. An industrial experiment was conducted at Infosys Ltd. India, whose employees voluntarily signed up to participate in the study and were randomly assigned to groups utilizing test driven development, test driven development with negative testing, and test last development. Source code and test cases created by each participant during the study were collected and analysed. The collected data indicate a statistically significant difference between the number of positive and negative test cases created by industrial participants, confirming the existence of positive test bias. The difference in defect detecting ability of positive and negative test cases is also statistically significant. As a result, similarly to our previous academic study, 29% of all test cases were negative, contributing by revealing as much as 71% of all the defects found by all test cases. With this industrial experiment, we confirmed the existence of a positive test bias in an industrial context, as well as significantly higher defect detecting ability of negative test cases.},
  keywords = {Test-driven Development; Industrial Experiment; Quality of Testing},
  owner = {magsilva},
  timestamp = {2014.10.20}
}

@INPROCEEDINGS{Causevic-etal:2012:xp,
  author = {Causevic, A. and Sundmark, D. and Punnekkat, S.},
  title = {Impact of test design technique knowledge on test driven development: A controlled experiment},
  crossref = {proceedings:xp:2012},
  pages = {138--152},
  doi = {10.1007/978-3-642-30350-0_10},
  abstract = {Agile development approaches are increasingly being followed and favored by the industry. Test Driven Development (TDD) is a key agile practice and recent research results suggest that the successful adoption of TDD depends on different limiting factors, one of them being insufficient developer testing skills. The goal of this paper is to investigate if developers who are educated on general testing knowledge will be able to utilize TDD more effectively. We conducted a controlled experiment with master students during the course on Software Verification & Validation (V&V) where source code and test cases created by each participant during the labs as well as their answers on a survey questionnaire were collected and analyzed. Descriptive statistics indicate improvements in statement coverage. However, no statistically significant differences could be established between the pre- and post-course groups of students. By qualitative analysis of students' tests, we noticed a lack of test cases for non-stated requirements ("negative"tests) resulting in a non-detection of bugs. Students did show preference towards TDD in surveys. Although further research is required to fully establish this, we believe that identifying specific testing knowledge which is complementary to the testing skills of a new TDD developer would enable developers to perform their tasks in a more efficient manner. © 2012 Springer-Verlag Berlin Heidelberg.},
  keywords = {controlled experiment; software testing; test driven development},
  owner = {magsilva},
  references = {Beck, K., Extreme programming explained: Embrace change (2000) Addison-wesley Longman, , Publishing Co., Inc., Boston; Causevic, A., Sundmark, D., Punnekkat, S., An industrial survey on contemporary aspects of software testing (2010) Proceedings of the 3rd IEEE International Conference on Software Testing, Verification and Validation, ICST, pp. 393-401; Causevic, A., Sundmark, D., Punnekkat, S., Factors limiting industrial adoption of test driven development: A systematic review (2011) Proceedings of the 4th IEEE International Conference on Software Testing, Verification and Validation, ICST, pp. 337-346; Wohlin, C., Runesson, P., Höst, M., Ohlsson, M.C., Regnell, B., Wesslén, A., (2000) Experimentation in Software Engineering - An Introduction, , Kluwer Academic Publishers; Jedlitschka, A., Pfahl, D., Reporting guidelines for controlled experiments in software engineering (2005) Proceedings of the 4th International Symposium on Empirical Software Engineering (ISESE 2005), pp. 94-104. , Jeffery, R., et al. (eds.) IEEE Computer Society; Sfetsos, P., Angelis, L., Stamelos, I., Investigating the extreme programming system - An empirical study (2006) Empirical Software Engineering, 11, pp. 269-301; Geras, A., Smith, M., Miller, J., A prototype empirical evaluation of test driven development (2004) Proceedings of the 10th International Symposium on Software Metrics, pp. 405-416. , IEEE Computer Society, Washington, DC, USA; Kollanus, S., Isomöttönen, V., Understanding tdd in academic environment: Experiences from two experiments (2008) Proceedings of the 8th International Conference on Computing Education Research, Koli 2008, pp. 25-31. , ACM, New York; Muller, M., Hagner, O., Experiment about test-first programming (2002) IEE Proceedings Software, 149, pp. 131-136; George, B., Williams, L., A structured experiment of test-driven development (2003) Information and Software Technology, 46 (5), pp. 337-342; Erdogmus, H., Morisio, M., Torchiano, M., On the effectiveness of the test-first approach to programming (2005) IEEE Transactions on Software Engineering, 31, pp. 226-237; Flohr, T., Schneider, T., Lessons learned from an XP experiment with students: Test-first needs more teachings (2006) PROFES 2006, 4034, pp. 305-318. , Münch, J., Vierimaa, M. (eds.) LNCS Springer, Heidelberg; Janzen, D.S., Saiedian, H., On the influence of test-driven development on software design (2006) Conference on Software Engineering Education and Training, pp. 141-148; Müller, M., Höfer, A., The effect of experience on the test-driven development process (2007) Empirical Software Engineering, 12, pp. 593-615; Janzen, D.S., Turner, C.S., Saiedian, H., Empirical software engineering in industry short courses (2007) Conference on Software Engineering Education and Training, pp. 89-96; Gupta, A., Jalote, P., An experimental evaluation of the effectiveness and efficiency of the test driven development (2007) Proceedings of the First International Symposium on Empirical Software Engineering and Measurement, ESEM 2007, pp. 285-294. , IEEE Computer Society, Washington, DC, USA; Höfer, A., Philipp, M., An empirical study on the TDD conformance of novice and expert pair programmers (2009) XP 2009, 31, pp. 33-42. , Abrahamsson, P., Marchesi, M., Maurer, F. (eds.) LNBIP Springer, Heidelberg; Huang, L., Holcombe, M., Empirical investigation towards the effectiveness of test first programming (2009) Inf. Softw. Technol., 51, pp. 182-194; Vu, J.H., Frojd, N., Shenkel-Therolf, C., Janzen, D.S., Evaluating test-driven development in an industry-sponsored capstone project (2009) Proceedings of the 2009 Sixth International Conference on Information Technology: New Generations, pp. 229-234. , IEEE Computer Society, Washington, DC, USA; Madeyski, L., The impact of test-first programming on branch coverage and mutation score indicator of unit tests: An experiment (2010) Inf. Softw. Technol., 52, pp. 169-184; The International Software Testing Qualifications Board, , http://www.istqb.org; Ammann, P., Offutt, J., (2008) Introduction to Software Testing, , Cambridge University Press, Cambridge ISBN 0-52188-038-1; http://www.eclipse.orghttp://www.junit.org},
  timestamp = {2014.08.19}
}

@INPROCEEDINGS{Causevic-etal:2012:ease,
  author = {Causevic, A. and Sundmark, D. and Punnekkat, S.},
  title = {Test case quality in test driven development: A study design and a pilot experiment},
  crossref = {proceedings:ease:2012},
  pages = {223--227},
  doi = {10.1049/ic.2012.0029},
  abstract = {Background: Test driven development, as a side-effect of developing software, will produce a set of accompanied test cases which can protect implemented features during code refactoring. However, recent research results point out that successful adoption of test driven development might be limited by the testing skills of developers using it. Aim: Main goal of this paper is to investigate if there is a difference between the quality of test cases created while using test-first and test-last approaches. Additional goal of this paper is to measure the code quality produced using test-first and test-last approaches. Method: A pilot study was conducted during the master level course on Software Verification & Validation at Malardalen University. Students were working individually on the problem implementation by being randomly assigned to a test-first or a test-last (control) group. Source code and test cases created by each participant during the study, as well as their answers on a survey questionnaire after the study, were collected and analysed. The quality of the test cases is analysed from three perspectives: (i) code coverage, (ii) mutation score and (iii) the total number of failing assertions. Results: The total number of test cases with failing assertions (test cases revealing an error in the code) was nearly the same for both test-first and test-last groups. This can be interpreted as "test cases created by test-first developers were as good as (or as bad as) test cases created by test-last developers". On the contrary, solutions created by test-first developers had, on average, 27% less failing assertions when compared to solutions created by the test-last group. Conclusions: Though the study provided some interesting observations, it needs to be conducted as a fully controlled experiment with a higher number of participants in order to validate statistical significance of the presented results.},
  keywords = {controlled experiment; software testing; test case efficiency; test driven development},
  owner = {magsilva},
  references = {Beck, K., (2000) Extreme Programming Explained: Embrace Change, , Boston, MA, USA: Addison-Wesley Longman Publishing Co., Inc; Causevic, A., Sundmark, D., Punnekkat, S., An industrial survey on contemporary aspects of software testing Proceedings of the 3rd International Conference on Software Testing, Verification and Validation (ICST), 2010, pp. 393-401; George, B., Williams, L., A structured experiment of test-driven development (2003) Information and Software Technology, 46 (5), pp. 337-342; Erdogmus, H., Morisio, M., Torchiano, M., On the effectiveness of the test-first approach to programming (2005) IEEE Transactions on Software Engineering, 31, pp. 226-237; Janzen, D.S., Saiedian, H., On the influence of test-driven development on software design (2006) Software Engineering Education and Training, Conference on, pp. 141-148. , vol. 0; Gupta, A., Jalote, P., An experimental evaluation of the effectiveness and efficiency of the test driven development (2007) ESEM '07, pp. 285-294. , Proceedings of the First International Symposium on Empirical Software Engineering and Measurement, ser. Washington, DC, USA: IEEE Computer Society; Vu, J.H., Frojd, N., Shenkel-Therolf, C., Janzen, D.S., Evaluating test-driven development in an industry-sponsored capstone project (2009) Proceedings of the 2009 Sixth International Conference on Information Technology: New Generations, pp. 229-234. , Washington, DC, USA: IEEE Computer Society; Causevic, A., Sundmark, D., Punnekkat, S., Factors Limiting Industrial Adoption of Test Driven Development: A Systematic Review Proceedings of the 4th International Conference on Software Testing, Verification and Validation (ICST), 2011; Jedlitschka, A., Pfahl, D., Reporting guidelines for controlled experiments in software engineering (2005) Proceedings of the 4th International Symposium on Empirical Software Engineering (ISESE 2005), pp. 94-104. , R. J. et al., Ed. IEEE Computer Society; Madeyski, L., The impact of test-first programming on branch coverage and mutation score indicator of unit tests: An experiment (2010) Inf. Softw. Technol., 52, pp. 169-184. , February; Causevic, A., Sundmark, D., Punnekkat, S., Impact of Test Design Technique Knowledge on Test Driven Development: A Controlled Experiment (2012) Lecture Notes in Business Information Processing, , Agile Processes in Software Engineering and Extreme Programming - 13th International Conference, XP 2012, Malmö, Sweden, May 20-25, 2012. Proceedings, ser. Springer, (to appear); Teasley, B.E., Leventhal, L.M., Mynatt, C.R., Rohlman, D.S., Why Software Testing Is Sometimes Ineffective: Two Applied Studies of Positive Test Strategy (1994) Journal of Applied Psychology, 79 (1), pp. 142-155; Leventhal, L.M., Teasley, B., Rohlman, D.S., Instone, K., Positive Test Bias in Software Testing among Professionals: A Review (1993) Selected Papers from the Third International Conference on Human- Computer Interaction, pp. 210-218. , London, UK: Springer- Verlag; EclEmma - Java Code Coverage for Eclipse, , http://www.eclemma.org; Judy - Java Mutation Tester, , http://www.java.mu; http://www.eclipse.orghttp://www.junit.orgKollanus, S., Isomöttönen, V., Understanding tdd in academic environment: Experiences from two experiments (2008) Koli '08, pp. 25-31. , Proceedings of the 8th International Conference on Computing Education Research, ser. New York, NY, USA: ACM; Flohr, T., Schneider, T., Lessons learned from an xp experiment with students: Test-first needs more teachings (2006) Lecture Notes in Computer Science, 4034, pp. 305-318. , Product-Focused Software Process Improvement, ser. J. Mnch and M. Vierimaa, Eds. Springer Berlin / Heidelberg},
  timestamp = {2014.08.19},
  year = {2012}
}

@INPROCEEDINGS{Cavender-etal:2009,
  author = {Cavender, Anna C. and Ladner, Richard E. and Roth, Robert I.},
  title = {The summer academy for advancing deaf and hard of hearing in computing},
  crossref = {proceedings:sigcse:2009},
  pages = {514--518},
  doi = {10.1145/1508865.1509043},
  abstract = {Deaf and hard of hearing students are an underrepresented group in computing and face extra challenges in university-level computing courses. This paper describes a 9-week Summer Academy for Advancing Deaf and Hard of Hearing in Computing that jump-starts the academic careers of deaf and hard of hearing students and strengthens their interest in computing. Students take introductory computing and animation in a fun, supportive, accessible environment. We report on some of the problems students face and lessons we have learned about helping them overcome those problems. Through the academy, they meet other successful deaf and hard of hearing technology professionals, tour top computing companies, and display their own work to the local deaf and hard of hearing community. Students gain leadership, independent learning skills, and complete the program better prepared for a college major in computing.},
  keywords = {animation, cs 0.5, cs 1, deaf and hard of hearing students}
}

@ARTICLE{Ceret-etal:2013,
  author = {Eric Céret and Sophie Dupuy-Chessa and Gaëlle Calvary and Agnès Front and Dominique Rieu},
  title = {A taxonomy of design methods process models },
  crossref = {journal:elsevier:ist},
  volume = {55},
  number = {5},
  month = may,
  year = {2013},
  pages = {795 - 821},
  doi = {10.1016/j.infsof.2012.11.002},
  abstract = {Context Designers and developers are increasingly expected to deliver high quality systems, i.e. systems that are usable, robust, consistent as well as evolutionary, and that fulfill users' needs. To produce such systems, Design Methods suggest many approaches. However, the important number of existing approaches makes the choice of a method among the others particularly difficult. In addition to this, and because of the time required for understanding (and then operationalizing) new methods, designers tend to use already known methods, even though those which sometimes may not really be adapted to their needs. Objective This paper proposes a classification of characteristics of design methods process models. In other terms, it proposes a taxonomy that aims to facilitate the discovery and the choice of methods for designers and developers. Method From a study of process models of several design methods, we identify six main axes, namely Cycle, Collaboration, Artifacts, Recommended Use, Maturity and Flexibility, which are in turn divided into 34 characteristics. Results This paper provides a deep theorical insight. For each characteristic identified from relevant literature, a definition and a gradation, illustrated using examples, are given. Moreover, it presents a web site that offers various tools for exploring the axes of our taxonomy. This web site provides an overview of process models as well as means for comparing them, textually or graphically. Finally, the paper relates the first evaluation conducted in order to estimate designers' adhesion to the taxonomy in terms of easiness of learning, completeness and intention to use. Conclusion We show, based on evaluation results, that our taxonomy of process models facilitates the discovery of new methods and helps designers in choosing suitable methods, really adapted to their needs. Therefore, it enhances chances to conduct high quality projects.},
  keywords = {Process models, Taxonomy, Design methods, Characterization }
}

@ARTICLE{Cerpa-Verner:2009,
  author = {Cerpa, Narciso and Verner, June M.},
  title = {Why Did Your Project Fail?},
  crossref = {journal:acm:cacm},
  volume = {52},
  number = {12},
  month = dec,
  year = {2009},
  pages = {130--134},
  doi = {10.1145/1610252.1610286},
  owner = {magsilva},
  timestamp = {2014.09.13}
}

@INPROCEEDINGS{Cesar-etal:2008:doceng,
  author = {Cesar, Pablo and Vaishnavi, Ishan and Kernchen, Ralf and Meissner, Stefan and Hesselman, Cristian and Boussard, Matthieu and Spedalieri, Antonietta and Bulterman, Dick C.A. and Gao, Bo},
  title = {Multimedia adaptation in ubiquitous environments: benefits of structured multimedia documents},
  crossref = {proceedings:doceng:2008},
  pages = {275--284},
  doi = {10.1145/1410140.1410201},
  abstract = {This paper demonstrates the advantages of using structured multimedia documents for session management and media distribution in ubiquitous environments. We show how document manipulations can be used to perform powerful operations such as content to context adaptation and presentation continuity. When consuming media in ubiquitous environments, where the set of devices surrounding a user may change, dynamic media adaptation and session transfer become primary requirements. This paper presents a working system, based on a representative scenario, in which multimedia content is distributed and adapted to a movable user to best suit his/her contextual situation. The implemented scenario includes the following scenes: content selection using a personal mobile phone, content distribution to the most suitable device according to the user's context, and presentation continuity when the user moves to another location. This paper introduces the underlying document manipulations that turn the scenario into a working system.},
  keywords = {SMIL, multimedia adaptation, session continuity, structured multimedia documents},
  series = {DocEng '08},
  acmid = {1410201},
  address = {New York, NY, USA},
  isbn = {978-1-60558-081-4},
  numpages = {10}
}

@INPROCEEDINGS{Chagas-Ferraz:2012,
  author = {Chagas, Amirton Bezerra and Ferraz, Carlos André Guimarães},
  title = {{ConnecTV}: an environment to develop and run component-based customized {idTV} applications},
  crossref = {proceedings:webmedia:2012},
  pages = {83--90},
  doi = {10.1145/2382636.2382657},
  abstract = {Designing Interactive Digital TV (iDTV) applications is a challenging activity, due to the restrictions of having the remote control as the main and in most cases the only input device for those applications. Users of iDTV applications are used to an environment where constant concentration and intervention is not needed, so applications requiring much interaction are unfamiliar to them. Personalized applications, which behave accordingly to the context of their execution, including user's habits and preferences, tends to require less interaction. Developing such applications is however burdensome, due to the lack of tools for designing and developing the personalized behavior using contextual information. ConnecTV fills this void by combining a component-based approach to develop such applications and a runtime environment to run and give additional support to their execution.},
  keywords = {component-based software engineering, composition, context-awareness, ginga-j, interactive digital TV applications}
}

@ARTICLE{Chakraborty-etal:2011,
  author = {Chakraborty, Pinaki and Saxena, P. C. and Katti, C. P.},
  title = {Fifty years of automata simulation: a review},
  crossref = {journal:acm:inroads},
  volume = {2},
  number = {4},
  month = dec,
  year = {2011},
  pages = {59--70},
  doi = {10.1145/2038876.2038893},
  abstract = {Automata theory is an important subject in computer science and quite consequently, simulation of automata for pedagogical purposes is an important topic in computer science education research. This article reviews the major initiatives in the field of simulation of automata in the last five decades with emphasis on those automata simulators actually used at universities for teaching. A classification of the automata simulators on the basis of their design paradigms has been developed where they have been classified broadly into language based automata simulators and visualization centric automata simulators. Some salient trends in the research on simulation of automata are also identified. The article concludes with an advocacy for continuing research on simulation of automata and integration of automata simulators in teaching.},
  keywords = {automata simulator, pedagogical tool},
  lang = {en}
}

@INPROCEEDINGS{Chaves-etal:2013,
  author = {José Osvaldo Chaves and Angélica Castro and Rommel Lima and Marcos Vinicius Lima and Karl Ferreira},
  title = {{MOJO}: uma ferramenta para auxiliar o professor em disciplinas de programação},
  crossref = {proceedings:esud:2013},
  pages = {1--11},
  abstract = {Disciplinas de programação são essenciais em cursos de computação, e exigem um grande envolvimento por parte do professor que, muitas vezes, não consegue realizar o devido acompanhamento de seus alunos. A longa espera do aluno para tirar dúvidas ou para apresentar seus resultados são elementos que acabam contribuindo para a desmotivação, e em alguns casos até desistência do curso. Isso pode ser ainda mais grave quando a modalidade de ensino é a distância, onde é mínimo ou inexistente o contato pessoal entre professor e aluno. Com a sobrecarga de atividades, o professor tem como alternativa a utilização de ferramentas automatizadas que sirvam de auxílio para a realização de suas tarefas. Diante deste cenário, e visando contribuir com a melhoria do ensino e aprendizagem em disciplinas de programação, este artigo apresenta uma ferramenta para a automatização do processo de elaboração, submissão e avaliação de atividades práticas de programação, com base em um processo semelhante ao adotado em maratonas de programação. O ambiente apresentado é integrado ao Moodle e apoia o ensino quer seja na modalidade presencial ou na modalidade de ensino à distância.},
  keywords = {disciplinas de programação, professor, aluno, ensino à distância},
  timestamp = {2013-09-22}
}

@ARTICLE{Chen-Lynch:1992,
  author = {Chen, H. and Lynch, K. J.},
  title = {Automatic construction of networks of concepts characterizing document databases},
  crossref = {journal:ieee:tcmc},
  volume = {22},
  number = {5},
  month = sep # {--} # oct,
  year = {1992},
  pages = {885--902},
  doi = {10.1109/21.179830},
  abstract = {Two East-bloc computing knowledge bases, both based on a semantic network structure, were created automatically from large, operational textual databases using two statistical algorithms. The knowledge bases were evaluated in detail in a concept-association experiment based on recall and recognition tests. In the experiment, one of the knowledge bases, which exhibited the asymmetric link property, outperformed four experts in recalling relevant concepts in East-bloc computing. The knowledge base, which contained 20000 concepts (nodes) and 280000 weighted relationships (links), was incorporated as a thesaurus-like component in an intelligent retrieval system. The system allowed users to perform semantics-based information management and information retrieval via interactive, conceptual relevance feedback},
  keywords = {Artificial intelligence;Computer networks;Data mining;Feedback;Information management;Information retrieval;Intelligent systems;Large-scale systems;Relational databases;Testing;full-text databases;information retrieval systems;knowledge based systems;thesauri;East-bloc computing knowledge bases;document databases;information management;information retrieval;intelligent retrieval system;semantic network structure;textual databases;}
}

@ARTICLE{Chen-Konstan:2010,
  author = {Chen, Jilin and Konstan, Joseph A.},
  title = {Conference paper selectivity and impact},
  crossref = {journal:acm:cacm},
  volume = {53},
  number = {6},
  month = jun,
  year = {2010},
  pages = {79--83},
  doi = {10.1145/1743546.1743569},
  abstract = {Conference acceptance rate signals future impact of published conference papers.}
}

@INPROCEEDINGS{Chen-etal:2007,
  author = {Chen, Kai-Hsiung and Hung, Hao-Ping and Chen, Ming-Syan},
  title = {Designing a Resource-Reusable {T-Learning} System},
  crossref = {proceedings:ccnc:2007},
  pages = {681--685},
  doi = {10.1109/CCNC.2007.139},
  abstract = {E-Learning standard (SCORM) has been extensively developed in recent years. It provides the direction of extending distance education to other mediums. Multimedia Home Platform (MHP) is a promising interactive digital TV standard. In order to extend the re-use of the resource database in SCORM, this paper devises a new platform, which allows the use of SCORM resource to provide educational services on the MHP platform, i.e., T-Learning. Explicitly, we develop a SCORM compatible T-Learning system architecture named Resource-Reuseable T-Learning (RTL), which is capable of reusing the SCORM resource package. Moreover, to enhance the efficiency of parsing the T-Learning documents, we also propose a two-phase parsing algorithm, denoted by TPP. Our system architecture and the parsing algorithm makes the DVB platform flexible, extensible, and easy to be integrated with the existing E-Learning SCORM materials. We demonstrate the prototype of RTL architecture in this paper and show the efficiency of the TPP algorithm via our experimental results.}
}

@INPROCEEDINGS{Chen:2011,
  author = {Chen, Ning},
  title = {{GATE}: game-based testing environment},
  crossref = {proceedings:icse:2011},
  pages = {1078--1081},
  doi = {10.1145/1985793.1986000},
  abstract = {In this paper, we propose a game-based public testing mechanism called GATE. The purpose of GATE is to make use of the rich human resource on the Internet to help increase effectiveness in software testing and improve test adequacy. GATE facilitates public testing in three main steps: 1) decompose the test criterion satisfaction problem into many smaller sub-model satisfaction problems; 2) construct games for each individual sub-models and presenting the games to the public through web servers; 3) collect and convert public users' action sequence data into real test cases which guarantee to cover not adequately tested elements. A preliminary study on apache-commons-math library shows that 44% of the branches have not been adequately tested by state of the art automatic test generation techniques. Among these branches, at least 42% are decomposable by GATE into smaller sub-problems. These elements naturally become the potential targets of GATE for public game-based testing.},
  keywords = {code coverage, human computation, testing}
}

@INPROCEEDINGS{Chen-Kim:2012,
  author = {Chen, Ning and Kim, Sunghun},
  title = {Puzzle-based automatic testing: bringing humans into the loop by solving puzzles},
  crossref = {proceedings:ase:2012},
  pages = {140--149},
  doi = {10.1145/2351676.2351697},
  abstract = {Recently, many automatic test generation techniques have been proposed, such as Randoop, Pex and jCUTE. However, usually test coverage of these techniques has been around 50-60% only, due to several challenges, such as 1) the object mutation problem, where test generators cannot create and/or modify test inputs to desired object states; and 2) the constraint solving problem, where test generators fail to solve path conditions to cover certain branches. By analyzing branches not covered by state-of-the-art techniques, we noticed that these challenges might not be so difficult for humans. To verify this hypothesis, we propose a Puzzle-based Automatic Testing environment (PAT) which decomposes object mutation and complex constraint solving problems into small puzzles for humans to solve. We generated PAT puzzles for two open source projects and asked different groups of people to solve these puzzles. It was shown that they could be effectively solved by humans: 231 out of 400 puzzles were solved by humans at an average speed of one minute per puzzle. The 231 puzzle solutions helped cover 534 and 308 additional branches (7.0% and 5.8% coverage improvement) in the two open source projects, on top of the saturated branch coverages achieved by the two state-of-the-art test generation techniques.},
  keywords = {Code Coverage, Human Computation, Testing}
}

@ARTICLE{Chhillar-Nisha:2011,
  author = {Chhillar, Rajender Singh and Nisha},
  title = {Empirical analysis of object-oriented design metrics for predicting high, medium and low severity faults using mallows Cp},
  crossref = {journal:acm:signotes},
  volume = {36},
  number = {6},
  month = nov,
  pages = {1--9},
  doi = {10.1145/2047414.2047423},
  abstract = {An object-oriented approach has become a commonly-used method in software-related activities. Many design metrics for object-oriented systems have been proposed and also employed for predicting and managing the quality of processes and products. To enhance the practical utility of object-oriented metrics in software industry, various researchers have tried to find relations between these metrics and fault proneness, but very few focus on relating them with the number-offaults in different levels as per their severity rating. In this study, empirical validation is carried out on object-oriented design metrics (i.e. Chidamber and Kemerer CK-metrics suite and source lines of codes) for predicting number-of-faults in different severity levels. Different statistical methods are used to analyze the data, including correlation.},
  keywords = {cp function, fault prediction, fault-severity, mallows, object-oriented design metrics}
}

@ARTICLE{Chidamber-Kemerer:1994,
  author = {Shyam R. Chidamber and Chris F. Kemerer},
  title = {A Metrics Suite for Object Oriented Design},
  crossref = {journal:ieee:tse},
  volume = {20},
  number = {6},
  month = jun,
  year = {1994},
  pages = {476-493},
  doi = {10.1109/32.295895},
  abstract = {Given the central role that software development plays in the delivery and application of information technology, managers are increasingly focusing on process improvement in the software development area. This demand has spurred the provision of a number of new and/or improved approaches to software development, with perhaps the most prominent being object-orientation (OO). In addition, the focus on process improvement has increased the demand for software measures, or metrics with which to manage the process. The need for such metrics is particularly acute when an organization is adopting a new technology for which established practices have yet to be developed. This research addresses these needs through the development and implementation of a new suite of metrics for OO design. Metrics developed in previous research, while contributing to the field's understanding of software development processes, have generally been subject to serious criticisms, including the lack of a theoretical base. Following Wand and Weber (1989), the theoretical base chosen for the metrics was the ontology of Bunge (1977). Six design metrics are developed, and then analytically evaluated against Weyuker's (1988) proposed set of measurement principles. An automated data collection tool was then developed and implemented to collect an empirical sample of these metrics at two field sites in order to demonstrate their feasibility and suggest ways in which managers may use these metrics for process improvement},
  keywords = {class, complexity, design, management, measurement, metrics, object orientation, performance},
  timestamp = {2013.09.14}
}

@ARTICLE{Chirouze-etal:2005,
  author = {Olivier Chirouze and David Cleary and George G. Mitchell},
  title = {A software methodology for applied research: eXtreme Researching},
  crossref = {journal:wiley:spe},
  volume = {35},
  number = {15},
  month = dec,
  year = {2005},
  pages = {1441--1454},
  doi = {10.1002/spe.677},
  abstract = {Applied research is, by necessity, a distributed, collaborative process. To be useful, research methodologies must not only be applicable in such an environment, but must also be adaptive to the needs of human resources and specific research area requirements. This paper introduces eXtreme Researching (XR), an adaptation of eXtreme Programming (XP) by Ericsson, to support distributed telecommunications research and development. XR builds on XP and tailors it to meet the needs of applied industrial research. It adopts and extends the most useful elements of XP: collective ownership, planning game, continuous integration and metaphor and shows how they are applicable in multi-site, research projects. XPWeb is developed as a tool to facilitate XR in a distributed research environment. XPWeb and XR are actively used by Ericsson Applied Research and have been shown to significantly increase output and efficiencies in multi disciplinary research projects.},
  keywords = {eXtreme Programming; agile processes; process engineering; telecommunications},
  owner = {magsilva},
  timestamp = {2014.01.16}
}

@ARTICLE{Chorianopoulos-Spinellis:2004,
  author = {Chorianopoulos, Konstantinos and Spinellis, Diomidis},
  title = {Affective usability evaluation for an interactive music television channel},
  crossref = {journal:acm:cie},
  volume = {2},
  number = {3},
  month = jul,
  year = {2004},
  pages = {1--11},
  doi = {10.1145/1027154.1027177},
  abstract = {Computer-mediated television brings new requirements for user interface design and evaluation, since interactive television applications are deployed in a relaxed domestic setting and aim to gratify the need for entertainment. Digital video recorders, the generation of custom computer graphics on each digital set-top box, and the introduction of new advertising formats are important issues for research and practice. We explore the employment of an animated character and the dynamic insertion of advertising in the design of an intuitive user interface for interactive music-video television. We found that the animated character and the skippable videoclip feature seamlessly enhanced consumer satisfaction, as shown by affective usability questionnaires.},
  keywords = {TiVo, affective usability, animated character, interactive television, music video, set-top box, user interface}
}

@INPROCEEDINGS{Christensen:2003,
  author = {Christensen, Henrik Baerbak},
  title = {Systematic testing should not be a topic in the computer science curriculum!},
  crossref = {proceedings:itcse:2003},
  pages = {7--10},
  doi = {10.1145/961511.961517},
  abstract = {In this paper we argue that treating "testing" as an isolated topic is a wrong approach in computer science and software engineering teaching. Instead testing should pervade practical topics and exercises in the computer science curriculum to teach students the importance of producing software of high quality. We point out that we, as teachers, are partly to blame that many software products are of low quality. We describe a set of teaching guidelines that conveys our main pedagogical point to the students: that systematic testing is important, rewarding, and fun, and that testing should be an integrated part of any software development process.},
  keywords = {CS curriculum, Systematic Testing, systematic testing}
}

@ARTICLE{Chrysafiadi-Virvou:2013,
  author = {Chrysafiadi, K. and Virvou, M.},
  title = {Dynamically Personalized E-Training in Computer Programming and the Language {C}},
  crossref = {journal:ieee:te},
  volume = {56},
  number = {4},
  month = nov,
  year = {2013},
  pages = {385--392},
  doi = {10.1109/TE.2013.2243914},
  abstract = {This paper describes ELaC, a fully implemented and evaluated novel integrated environment for personalized e-training in programming and the language C. Software development relies on many different programming languages and tools, ranging from procedural to object-oriented and query languages; an individual learning a new language may already know a range of other languages, or may know no other languages at all. Given the variety of backgrounds of prospective learners of programming, developing learning environments for all of them is not easy. In the light of these problems, this work has focused on the development of an original integrated e-training environment for programming and the language C, incorporating a student model responsible for identifying and updating the student's knowledge level, which takes into account each individual user's pace of learning. The system can adapt dynamically to each individual learner's needs by scheduling the sequence of learning lessons on the fly. This personalization allows each learner to complete the e-training course on at their own pace and according to their ability.},
  keywords = {adaptivity, concept interdependency, domain knowledge representation, student model, teaching programming},
  owner = {magsilva},
  timestamp = {2014.01.15}
}

@INPROCEEDINGS{Cirilo-etal:2010a,
  author = {Cirilo, Carlos E. and do Prado, Antonio F. and de Souza, Wanderley L. and Zaina, Luciana A. M.},
  title = {Model driven RichUbi: a model driven process for building rich interfaces of context-sensitive ubiquitous applications},
  crossref = {proceedings:sigdoc:2010},
  pages = {207--214},
  doi = {10.1145/1878450.1878485},
  abstract = {The demand for software in Ubiquitous Computing, in which access to applications occurs anywhere, anytime and from different devices, has raised new challenges for Software Engineering. One of these challenges is related to the adaptation of the contents of an application to the numerous devices that can access it in distinct contexts. Another challenge is related to the building of rich interfaces with multimedia content, asynchronous communication and other features that characterize Rich Internet Applications (RIAs). Searching for solutions focused on these challenges, a model-driven process for building rich interfaces of context-sensitive ubiquitous applications has been developed. The process, which is based on the conceptions of Domain-Specific Modeling (DSM), emphasizes the modeling reuse from a rich interface components metamodel. This metamodel provides a generic infrastructure for developing rich interfaces of applications, focusing on model-level reuse and on code generation for different Ubiquitous Computing platforms. In addition, the metamodel allows that the interface models are built by using the terms of rich interface domain, which facilitates the communication between users and developers.s},
  keywords = {communication, context-sensitive ubiquitous applications, domain specific modeling, rich interfaces, software process},
  series = {SIGDOC '10},
  acmid = {1878485},
  address = {New York, NY, USA},
  isbn = {978-1-4503-0403-0},
  numpages = {8}
}

@INPROCEEDINGS{Clarke-etal:2010,
  author = {Clarke, Peter J. and Allen, Andrew A. and King, Tariq M. and Jones, Edward L. and Natesan, Prathiba},
  title = {Using a web-based repository to integrate testing tools into programming courses},
  crossref = {proceedings:splash:2010},
  pages = {193--200},
  doi = {10.1145/1869542.1869573},
  abstract = {Improving the quality of software developed in the 21st century is one of the major challenges in the software industry. Addressing this problem will require that academic institutions play a key role in training developers to produce high quality software. Unfortunately, students and instructors continue to be frustrated by the lack of support provided when selecting appropriate testing tools and program analyzers to verify programs under development. In this paper we present an approach that integrates the use of software testing tools into programming and software engineering courses. The approach consists of three phases, developing an online repository with learning resources, training instructors in the area of testing techniques and tools, and integrating the use of testing tools into various programming courses. We also present the results of the first instructors' workshop and studies on integrating testing tools into two courses, CS2 and Software Engineering (SE).},
  keywords = {computer science education, programming courses, software testing, unit testing}
}

@INPROCEEDINGS{Clarke-etal:2012,
  author = {Clarke, Peter J. and Pava, Jairo and Davis, Debra and Hernandez, Frank and King, Tariq M.},
  title = {Using {WReSTT} in {SE} courses: an empirical study},
  crossref = {proceedings:sigcse:2012},
  pages = {307--312},
  doi = {10.1145/2157136.2157227},
  abstract = {There continues to be a lack of adequate training for students in software testing techniques and tools at most academic institutions. Several educators and researchers have investigated innovative approaches that integrate testing into programming and software engineering (SE) courses with some success. The main problems are getting other educators to adopt their approaches and ensuring students continue to use the techniques they learned in previous courses. In this paper we present a study that evaluates a non-intrusive approach to integrating software testing techniques and tools in SE courses. The study uses a Web-Based Repository of Software Testing Tools (WReSTT) that contains tutorials on software testing concepts and tools. The results of the study show that (1) students who use WReSTT in the classroom can improve their understanding and use of testing techniques and tools, (2) students find WReSTT a useful learning resource, and (3) the collaborative learning environment motivates students to complete assignments.},
  keywords = {collaborative learning, repository, software testing, unit testing}
}

@INPROCEEDINGS{Clarke-etal:2011,
  author = {Clarke, Peter J. and Pava, Jairo and Wu, Yali and King, Tariq M.},
  title = {Collaborative web-based learning of testing tools in {SE} courses},
  crossref = {proceedings:sigcse:2011},
  pages = {147--152},
  doi = {10.1145/1953163.1953208},
  abstract = {One of the main concerns in the software industry continues to be the development of high quality software. This concern will be exacerbated as software systems become more complex. The training of software developers continues to grow in academia since more institutions are offering software engineering (SE) courses. However, the list of topics that are expected to be covered in this course leaves little or no time for topics that focus on developing quality software, such as software testing and the use of testing tools. In this paper we describe an approach that non-intrusively integrates the use of software testing tools in SE courses. The cornerstone of our approach is the interaction students have with a Web-Based Repository of Software Testing Tools (WReSTT) that contains tutorials on testing concepts and testing tools. WReSTT employs both collaborative learning and social networking features that are attractive to students. We present the results of preliminary study performed in two SE courses that show how using the resources in WReSTT can potentially impact the students' understanding of software testing and the use of testing tools.},
  keywords = {collaborative learning, repository, software testing, unit testing}
}

@ARTICLE{Clear:2012,
  author = {Clear, Tony},
  title = {Systematic literature reviews and undergraduate research},
  crossref = {journal:acm:inroads},
  volume = {3},
  number = {4},
  month = dec,
  year = {2012},
  pages = {10--11},
  doi = {10.1145/2381083.2381087}
}

@ARTICLE{Clear:2011,
  author = {Clear, Tony},
  title = {Affective dimensions of computing education: an 'education as drama' approach?},
  crossref = {journal:acm:inroads},
  volume = {2},
  number = {4},
  month = dec,
  year = {2011},
  pages = {12--13},
  doi = {10.1145/2038876.2038878}
}

@ARTICLE{Clear:2010,
  author = {Clear, Tony},
  title = {Diagnosing your teaching style: how interactive are you?},
  crossref = {journal:acm:inroads},
  volume = {1},
  number = {2},
  month = jun,
  year = {2010},
  pages = {34--41},
  doi = {10.1145/1805724.1805737},
  abstract = {In the higher education context within which computing educators now teach, an increasing range of forces are conspiring against innovative teaching practice. Pressures of academic workload, pressures from consumerist students and regular course evaluations, pressures from increasingly managerial policies and practices, from so-called 'quality assurance systems', pressures to continually expand research output, all lead towards stifling conformity and a natural conservatism in teaching practice. The increasing focus on consistency in a mass production model of teaching militates heavily against innovation. This paper presents an instrument used by the author to diagnose the student perceptions of the pedagogy of his course, by mapping it against Reeve's fourteen dimensions of an interactive learning system [12]. The outcomes demonstrated significant differences in style between this course and the overall programme within which it was situated. It enabled the author to gain insight into how the course differed and issues about it that had discomfited students. This enabled constructive dialogue with the students and an explicit discussion of the underlying collaborative mode of pedagogy. The tool is presented here for others to adopt in order to diagnose or make explicit to students the style of their own courses, and hopefully encourage innovative teaching practice.},
  keywords = {CS education research, IS education research, interactive learning systems, pedagogy}
}

@INPROCEEDINGS{Clements-Janzen:2010,
  author = {Clements, John and Janzen, David},
  title = {Overcoming Obstacles to Test-Driven Learning on Day One},
  crossref = {proceedings:icstw:2010},
  pages = {448--453},
  doi = {10.1109/ICSTW.2010.33},
  abstract = {We describe the preliminary construction of a web-based tool for test-driven learning in the first weeks of programming. We discuss obstacles to test-driven learning--both pragmatic and ideological--and describe the ways that we believe our tool overcomes these obstacles.},
  keywords = {test-driven-learning, test-driven-development, pedagogy, online-training}
}

@INPROCEEDINGS{Codocedo-Astudillo:2008,
  author = {Codocedo, Víctor and Astudillo, Hernán},
  title = {No mining, no meaning: relating documents across repositories with ontology-driven information extraction},
  crossref = {proceedings:doceng:2008},
  pages = {110--118},
  doi = {10.1145/1410140.1410164},
  abstract = {Far from eliminating documents as some expected, the Internet has lead to a proliferation of digital documents, without a centralized control or indexing. Thus, identifying relevant documents becomes simultaneously more important and much harder, since what users require may be dispersed across many documents and many repositories. This paper describes Ontologic Anchoring, a technique to relate documents in domain ontologies, using named entity recognition (a natural-language processing approach) and semantic annotation to relate individual documents to elements in ontologies. This approach allows document retrieval using domain-level inferences, and integration of repositories with heterogeneous media, languages and structure. Ontological anchoring is a two-way street: ontologies allow semantic indexing of documents, and simultaneously new documents enrich ontologies. The approach is illustrated with an initial deployment for heritage documents in Spanish.},
  keywords = {NLP, human-in-the-loop, information extraction, metadata creation, ontological anchoring, ontology},
  series = {DocEng '08},
  acmid = {1410164},
  address = {New York, NY, USA},
  isbn = {978-1-60558-081-4},
  numpages = {9}
}

@ARTICLE{Coles-etal:2011,
  author = {Coles, Drue and Jones, Curt and Wynters, Erik},
  title = {Programming contests for assessing problem-solving ability},
  crossref = {journal:ccsc:jcsc},
  volume = {26},
  number = {3},
  month = jan,
  year = {2011},
  pages = {28--35},
  abstract = {Computer science is one of the largest curricular areas among college and university programs seeking accreditation, a peer-review process designed to certify that a program meets professional standards of quality. Our program is accredited by ABET, the largest accrediting body in the U.S. for computer science. One of the ABET requirements (following ACM curriculum standards) is that a program teaches students how to "analyze a problem, and identify and define the computing requirements appropriate to its solution"; moreover, one of our own stated program objectives is to develop students' general problem-solving ability. Much of the work in sustaining accreditation involves identifying and collecting data for measuring the extent to which educational goals are being realized, but we find that quantifying problem-solving ability, or even simply defining it, is a significant challenge. This article describes one of the assessment mechanisms that we have developed to meet this challenge.}
}

@ARTICLE{Colwell:2002,
  author = {Colwell, Bob},
  title = {Engineering, science, and quantum mechanics},
  crossref = {journal:ieee:computer},
  volume = {35},
  number = {3},
  month = mar,
  year = {2002},
  pages = {8--10},
  doi = {10.1109/MC.2002.989920}
}

@ARTICLE{Conaldi-Lomi:2013,
  author = {Guido Conaldi and Alessandro Lomi},
  title = {The dual network structure of organizational problem solving: A case study on open source software development },
  crossref = {journal:elsevier:sn},
  volume = {35},
  number = {2},
  month = may,
  year = {2013},
  pages = {237--250},
  doi = {10.1016/j.socnet.2012.12.003},
  abstract = {We reconstruct the dual network structure generated by the association between 72 contributors and 737 software bugs engaged during a full development cycle of the free/open source software project Epiphany. Estimates of structural parameters of Exponential Random Graph Models for two-mode networks reveal the structural logics shaping activities of collaborative problem solving. After controlling for contributor-specific and software bug-specific characteristics, we find that contributors (problem solvers) tend to distribute their activity over multiple software bugs. At the same time, however, we find that software bugs (problems) tend not to share multiple contributors. This dual tendency toward de-specialization and exclusivity is sustained by specific local network dependencies revealed by our analysis which also suggests possible organizational mechanisms that may be underlying the puzzling macro-structural regularities frequently observed, but rarely explained, in the production of open source software. By combining these mechanisms with the influence of contributors characterized by different levels of involvement in the project, we provide micro-level evidence of structural interdependence between core and peripheral members identified exclusively on the basis of their individual level of contribution to the project.},
  keywords = {Two-mode networks, Exponential Random Graphs, Free/open source software, Organizational problem solving }
}

@INPROCEEDINGS{Condori-Fernandez-etal:2009,
  author = {Condori-Fernandez, Nelly and Daneva, Maya and Sikkel, Klaas and Wieringa, Roel and Dieste, Oscar and Pastor, Oscar},
  title = {A systematic mapping study on empirical evaluation of software requirements specifications techniques},
  crossref = {proceedings:esem:2009},
  pages = {502--505},
  doi = {10.1109/ESEM.2009.5314232},
  abstract = {This paper describes an empirical mapping study, which was designed to identify what aspects of Software Requirement Specifications (SRS) are empirically evaluated, in which context, and by using which research method. On the basis of 46 identified and categorized primary studies, we found that understandability is the most commonly evaluated aspect of SRS, experiments are the most commonly used research method, and the academic environment is where most empirical evaluation takes place.}
}

@ARTICLE{Conlon:2005,
  author = {Conlon, Michael P.},
  title = {{RockTest}: A Programming Contest Management System},
  crossref = {journal:ccsc:jcsc},
  volume = {20},
  number = {5},
  month = may,
  year = {2005},
  pages = {27--35},
  abstract = {RockTest is a software system to facilitate the activities of contestants and judges in computer programming competitions. RockTest was developed out of experience running programming competitions for high school students as a recruiting tool for the Computer Science Department. It has been proven reliable and has received enthusiastic reviews from the competitors, judges, and contest administrators at two universities who have used it.}
}

@INPROCEEDINGS{Cook:1971,
  author = {Cook, Stephen A.},
  title = {The Complexity of Theorem-proving Procedures},
  crossref = {proceedings:stoc:1971},
  pages = {151--158},
  doi = {10.1145/800157.805047},
  abstract = {It is shown that any recognition problem solved by a polynomial time-bounded nondeterministic Turing machine can be reduced to the problem of determining whether a given propositional formula is a tautology. Here reduced means, roughly speaking, that the first problem can be solved deterministically in polynomial time provided an oracle is available for solving the second. From this notion of reducible, polynomial degrees of difficulty are defined, and it is shown that the problem of determining tautologyhood has the same polynomial degree as the problem of determining whether the first of two given graphs is isomorphic to a subgraph of the second. Other examples are discussed. A method of measuring the complexity of proof procedures for the predicate calculus is introduced and discussed.}
}

@ARTICLE{Cooper-Cunningham:2010,
  author = {Cooper, Steve and Cunningham, Steve},
  title = {Teaching Computer Science in Context},
  crossref = {journal:acm:inroads},
  volume = {1},
  number = {1},
  month = mar,
  year = {2010},
  pages = {5--8},
  doi = {10.1145/1721933.1721934},
  abstract = {Do we need another editorial about engaging students in learning computer science so they will stay in the field and prepare for a career or further study? We wish it were not so, but in spite of some progress, there is little evidence that our students complete courses or stay in their degree programs at better rates than a few years ago. There are bright spots in the picture and some promising results here and there, but an overall pattern of change and improvement is not yet evident.},
  keywords = {computational thinking, computer science education, context, engagement, motivation}
}

@ARTICLE{Cormack:2006,
  author = {Cormack, Gordon},
  title = {Random Factors in {IOI} 2005 Test Case Scoring},
  crossref = {journal:imi:ie},
  volume = {5},
  number = {1},
  month = jan,
  year = {2006},
  pages = {5--14},
  abstract = {We examine the precision with which the cumulative score from a suite of test cases ranks participants in the International Olympiad in Informatics (IOI). Our concern is the ability of these scores to reflect achievement at all levels, as opposed to reflecting chance or arbitrary factors involved in composing the test suite. Test cases are assumed to be drawn from an infinite population of similar cases; variance in standardized rank is estimated by the bootstrap method and used to compute confidence intervals which contain the hypothetical true ranking with 95% probability. We examine the relative contribution of easy (so-called fifty-percent rule) cases and hard cases to the overall ranking. Empirical results based on IOI 2005 suggest that easy and hard cases are both material to the ranking, but the proportion of each is unimportant.},
  keywords = {classical test theory, informatics olympiad, programming contest},
  owner = {magsilva},
  timestamp = {2014.08.30}
}

@ARTICLE{Cormack-etal:2006,
  author = {Cormack, Gordon and Munro, Ian and Vasiga, Troy and Kemkes, Graeme},
  title = {Structure, scoring and purpose of computing competitions},
  crossref = {journal:imi:ie},
  volume = {5},
  number = {1},
  month = jan,
  year = {2006},
  pages = {15--36},
  abstract = {We identify aspects of computing competition formats as they relate to the purpose of these competitions, both stated and tacit. We consider the major international competitions - the International Olympiad for Informatics, the ACM International Collegiate Programming Contest, and top coder - and related contests whose format merits consideration. We consider the operational impact and possible outcomes of incorporating several of these aspects into scholastic competitions. We advocate, in particular, that contests be designed so as to provide a rewarding experience and opportunity for achievement for all competitors; not just the winners. Specific contest elements that should be considered are: (1) real-time scoring and feedback, (2) rewards for testing and test case creation, (3) tasks with graduated difficulty, (4) collaborative tasks, (5) practice contests and entry-level contests for novices, and (6) inclusion of spectators.},
  keywords = {algorithm contest, informatics olympiad, programming contest},
  url = {http://www.mii.lt/informatics_in_education/pdf/infe071.pdf}
}

@ARTICLE{Cornwell:2012,
  author = {Cornwell, Michael},
  title = {Anatomy of a solid-state drive},
  crossref = {journal:acm:cacm},
  volume = {55},
  number = {12},
  month = dec,
  year = {2012},
  pages = {59--63},
  doi = {10.1145/2380656.2380672},
  abstract = {While the ubiquitous SSD shares many features with the hard-disk drive, under the surface they are completely different.}
}

@INPROCEEDINGS{Corte-etal:2006:WEI,
  author = {Corte, C. K. D. and Barbosa, E. F. and Maldonado, José Carlos},
  title = {Estabelecimento de Mecanismos de Apoio ao Ensino Integrado de Fundamentos de Programação e Teste de Software},
  crossref = {proceedings:wei:2006},
  pages = {98 -- 107},
  abstract = {Tanto programação como teste de software não são disciplinas trivia de serem ensinadas e, nesse sentido, várias iniciativas têm sido investigadas a fim de amenizar os problemas associados. Neste artigo propõe-se o ensino conjunto de conceitos básicos de programação OO e de teste de software em disciplinas introdutórias dos cursos de Ciências da Computação. Para isso, discute-se a elaboração de um módulo educacional integrado de fundamentos de programação OO e teste de software, com ênfase em aspectos de modelagem conceitual. Propõe-se, ainda, um ambiente para submissão e avaliação automática de trabalhos práticos baseado em atividades de teste -- ProgTest --, utilizado como mecanismo de apoio ao processo de ensino e aprendizado.},
  abstract-en = {Programming and software testing are not trivial courses to be taught. In this sense, many initiatives have been explored in order to reduce the associated problems. This paper investigates the integrated teaching of basic concepts of OO programming and software testing in introductory courses of Computer Science. We discuss the creation of an integrated educational module of fundamentals of OO programming and software testing, with focus in conceptual modeling aspects. Also, we present the development of an environment for the submission and evaluation of practical assignments based on testing activities -- ProgTest --, used as a supporting mechanism to the learning processes.},
  lang = {pt},
  owner = {magsilva},
  timestamp = {2007.10.10}
}

@INPROCEEDINGS{Costa-Vicente:2008,
  author = {Costa, Juliano and de Lucena, Vicente},
  title = {An Educational Component-Based Digital TV Middleware for the Brazilian's System},
  crossref = {proceedings:edutainment:2008},
  pages = {41-51},
  doi = {10.1007/978-3-540-69736-7_5},
  abstract = {One of the major problems faced by the Brazilian population is the low level of the fundamental schools. Television is the most popular source of entertainment and information of the Brazilian population being present in approximately 54 million families all over the country. These families watch television for more than 8 hours daily. Moreover, at this moment, the Brazilian TV system is moving from analog to digital. That means not only that image and sound will be delivered with much better quality but also that it will be possible to send interactive multimedia programs, creating a brand new way of watching TV. That is in fact the main novelty of the digital system it will be possible to offer personal interactive services such as banking, games and most importantly educational programs. This work introduces a software framework called ``Extended Middleware for Digital TV (EMTV)'' which is suitable for the generation of interactive applications executed over digital television systems. Its concept was developed focusing on the Brazilian technological options for Digital TV. Technically, EMTV is a procedural GEM compliant application which, from the programmer's point of view, acts as a declarative middleware extension. The framework was developed to be component-based in order to minimize the need for programming knowledge to deploy the digital TV applications using EMTV. The main goal of the platform is to facilitate the construction of interactive multimedia educational applications, a crucial field for the Brazilian population. The concept is tested and validated by the construction of a Quiz application presented at the end of the paper.},
  volume = {5093},
  series = {Lecture Notes in Computer Science},
  affiliation = {Genius Institute of Technology Av. Dr. F. Coelho 64 São Paulo SP Brazil 05423-911},
  booktitle = {International Conference on Edutainment},
  editor = {Pan, Zhigeng and Zhang, Xiaopeng and El Rhalibi, Abdennour and Woo, Woontack and Li, Yi},
  isbn = {978-3-540-69734-3},
  keyword = {Computer Science},
  location = {Nanjing, China},
  month = jun,
  publisher = {Springer},
  year = {2008}
}

@INPROCEEDINGS{Costa-etal:2009:criwg,
  author = {Costa, Jean M. R. and Santana, Francisco W. and De Souza, Cleidson R. B.},
  title = {Understanding open source developers' evolution using TransFlow},
  crossref = {proceedings:criwg:2009},
  pages = {65--78},
  doi = {10.1007/978-3-642-04216-4_6},
  abstract = {Due to the success of many Open Source Software projects, both the industry and the academic community are interested in understanding how such software is produced. Particularly, there is interest in understanding how these communities are organized, maintained, and also how the contributors join and evolve their roles in these projects. However, few studies have been conducted around the evolution of the developers in the communities, i.e., how they reach roles of greater importance, and how the software changes over time through this evolution. This paper describes TransFlow, a tool aimed to support the integrated study of the evolution of both: the software itself and the developers' participation in open source projects. This integrated study is a requirement since the software architecture may support or hinder developers' participation in the project. We describe the rationale for building TransFlow and illustrate how its features can be used to study open source projects.},
  keywords = {developers evolution, open source, role migration, software evolution}
}

@INPROCEEDINGS{Costa-Lucena:2008,
  author = {Costa, Juliano Rodrigues and de Lucena, Vicente Ferreira de},
  title = {{EMTV} -- A Component-Based {DTV} Middleware Extension for Educational Purposes},
  crossref = {proceedings:euroitv:2008},
  pages = {219--228},
  doi = {10.1007/978-3-540-69478-6_30},
  abstract = {This work introduces a software framework called ``Extended Middleware for Digital TV (EMTV)'' which is suitable for the generation of interactive applications executed over digital television systems. Its concept was developed focusing on the Brazilian technological options for Digital TV. Technically, EMTV is a procedural GEM compliant application which, from the programmer's point of view, acts as a declarative middleware extension. The framework was developed to be component-based in order to minimize the need for programming knowledge to deploy the digital TV applications using EMTV. The main goal of the platform is to facilitate the construction of interactive educational applications, a crucial field for the Brazilian population. The concept is tested and validated by the construction of a Quiz application presented at the end of the paper.}
}

@INPROCEEDINGS{Costa-etal:2008,
  author = {Costa, Romualdo Monteiro de Resende and Moreno, Marcelo Ferreira and Gomes Soares, Luiz Fernando},
  title = {Intermedia synchronization management in {DTV} systems},
  crossref = {proceedings:doceng:2008},
  pages = {289--297},
  doi = {10.1145/1410140.1410203},
  abstract = {Intermedia synchronization is related with spatial and temporal relationships among media objects that compound a DTV application. From the server side (usually a broadcaster's server or a Web Server) to receivers, end-to-end intermedia synchronization support must be provided. Based on application specifications, several abstract data structures should be created to guide all synchronization control processes. A special data structure, a labeled digraph called HTG (Hypermedia Temporal Graph) is proposed in this paper as the basis of all other data structures. From HTG, receivers derive a presentation plan to orchestrate media content presentations that make up a DTV application. From this plan other data structures are derived to estimate when media players should be instantiated and when data contents should be retrieved from a DSM-CC carousel or from a return channel. If the return channel provides QoS support, another data structure is derived from the presentation plan, in order to determine when resource reservation should take place. For content pushed by broadcasters, HTG is used in the server side as the basis for building the carousel plan, a data structure that guides the order and frequency that media objects should be broadcasted. The paper's proposals were partially put into practice in the current open source reference implementation of the standard middleware of the Brazilian Terrestrial Digital TV System. However, this reference implementation is used just as a proof of concept. The ideas presented can be extended to any multimedia document presentation player (user agent) and content distribution server.},
  keywords = {NCL, digital TV, intermedia synchronization, middleware, temporal graph},
  series = {DocEng '08},
  acmid = {1410203},
  address = {New York, NY, USA},
  isbn = {978-1-60558-081-4},
  numpages = {9}
}

@INPROCEEDINGS{Costa-etal:2009:webmedia,
  author = {Costa, Romualdo Monteiro de Resende and Moreno, Marcio Ferreira and Soares, Luiz Fernando Gomes},
  title = {{Ginga-NCL}: supporting multiple devices},
  crossref = {proceedings:webmedia:2009},
  pages = {1--8},
  doi = {10.1145/1858477.1858483},
  abstract = {Multimedia applications for DTV systems can take profit of multiple exhibition devices to enrich the set of supported interactive applications. New applications in which viewers can cooperate besides being able to have its own navigation space without disturbing their neighbors in a common environment will now be possible. The NCL language allows developing such applications following a hierarchical model supported by its presentation environment called Ginga-NCL, by using a set of components in charge of orchestrating the several devices used in the presentation. This paper presents the mentioned support provided by the reference implementation of the Ginga-NCL middleware, stressing its architecture and illustrating the new possibilities opened by the multi-device applications.},
  keywords = {Ginga, NCL, TV digital, múltiplos dispositivos, middleware TVD, sincronização}
}

@ARTICLE{Costabile-etal:2010,
  author = {Costabile, Maria Francesca and Ardito, Carmelo and Lanzilotti, Rosa},
  title = {Enjoying cultural heritage thanks to mobile technology},
  crossref = {journal:acm:interactions},
  volume = {17},
  number = {3},
  month = may,
  year = {2010},
  pages = {30--33},
  doi = {10.1145/1744161.1744169}
}

@INPROCEEDINGS{Souza-etal:2011:OER,
  author = {Costa de Souza, Maria de Fátima and Rossana Maria de Castro Andrade and José Aires de Castro Filho},
  title = {Guided customization for learning objects},
  crossref = {proceedings:oer:2011},
  pages = {105--126},
  abstract = {In recent years, the idea of open software has expanded and involved several new types of applications with the intention of democratizing information and knowledge. In the educational context, this idea has been evolved and called open educational resources (OER). One of the characteristics of OER is that users (i.e., teachers and students) can adapt the educational software to their needs. This adaptation is only feasible if users have access to software codes and expertise to perform the adaptation. However, adjustments for the OER community are quite specific and require the direct intervention of a teacher who usually does not have skills to perform technical changes. This work then describes a strategy for adapting learning objects (LO), called guided customization. This strategy proposes that, at the design step, the LO development team states precisely what resources can be adapted. Similarly, users of these resources will be associated with profiles indicating which level of adaptation, depending on their qualification, can be accomplished without, however, compromising the pedagogical content of the resource. Thus, resources can be customized by users at execution time, making the real benefits of OER become evident in practice.}
}

@ARTICLE{Courtois:1985,
  author = {Courtois, P. J.},
  title = {On time and space decomposition of complex structures},
  crossref = {journal:acm:cacm},
  volume = {28},
  number = {6},
  month = jun,
  year = {1985},
  pages = {590--603},
  doi = {10.1145/3812.3814},
  abstract = {Models of large and complex systems can often be reduced to smaller sub-models, for easier analysis, by a process known as decomposition. Certain criteria for successful decompositions can be established.}
}

@ARTICLE{Couto-etal:2014,
  author = {Couto, Cesar and Valente, Marco and Pires, Pedro and Hora, Andre and Anquetil, Nicolas and Bigonha, Roberto},
  title = {{BugMaps-Granger}: a tool for visualizing and predicting bugs using {Granger} causality tests},
  crossref = {journal:springer:jserd},
  volume = {2},
  number = {1},
  month = mar,
  year = {2014},
  pages = {1--12},
  doi = {10.1186/2195-1721-2-1},
  abstract = {BACKGROUND:Despite the increasing number of bug analysis tools for exploring bugs in software systems, there are no tools supporting the investigation of causality relationships between internal quality metrics and bugs. In this paper, we propose an extension of the BugMaps tool called BugMaps-Granger that allows the analysis of source code properties that are more likely to cause bugs. For this purpose, we relied on the Granger Causality Test to evaluate whether past changes to a given time series of source code metrics can be used to forecast changes in a time series of defects. Our tool extracts source code versions from version control platforms, calculates source code metrics and defects time series, computes Granger Test results, and provides interactive visualizations for causal analysis of bugs.RESULTS:We provide an example of use of BugMaps-Granger involving data from the Equinox Framework and Eclipse JDT Core systems collected during three years. For these systems, the tool was able to identify the modules with more bugs, the average lifetime and complexity of the bugs, and the source code properties that are more likely to cause bugs.CONCLUSIONS:With the results provided by the tool in hand, a maintainer can perform at least two main software quality assurance activities: (a) refactoring the source code properties that Granger-caused bugs and (b) improving unit tests coverage in classes with more bugs.}
}

@ARTICLE{Coward:1988,
  author = {P. David Coward},
  title = {A review of software testing},
  crossref = {journal:elsevier:ist},
  volume = {30},
  number = {3},
  month = apr,
  year = {1988},
  pages = {189--198},
  doi = {10.1016/0950-5849(88)90065-1},
  abstract = {Despite advances in formal methods of specification and improved software creation tools, there is no guarantee that the software produced meets its functional requirements. There is a need for some form of software testing. The paper introduces the aims of software testing. This is followed by a description of static and dynamic analysis, and, functional and structural testing strategies. These ideas are used to provide a taxonomy of testing techniques. Each technique is briefly described.},
  keywords = {software development; software testing; formal methods},
  lang = {en}
}

@ARTICLE{Box:1984,
  author = {Cox, B. J.},
  title = {Message/Object Programming: An Evolutionary Change in Programming Technology},
  crossref = {journal:ieee:software},
  volume = {1},
  number = {1},
  month = jan,
  year = {1984},
  pages = {50--61},
  doi = {10.1109/MS.1984.233398},
  abstract = {Could a marriage of the message/object model, a la Smalltalk-80, and the operator/operand model, a la Unix, improve the lot of both users and programmers? Stay tuned...}
}

@ARTICLE{Creswell-Miller:2000,
  author = {John W. Creswell and Dana L. Miller},
  title = {Determining Validity in Qualitative Inquiry},
  crossref = {journal:routledge:tip},
  volume = {39},
  number = {3},
  year = {2000},
  pages = {124--130},
  doi = {10.1207/s15430421tip3903_2}
}

@INPROCEEDINGS{Crispin:2002,
  author = {Crispin, Lisa},
  title = {Test Drive for Testers: What, When, and How Testers Do for {XP} Teams},
  crossref = {proceedings:xp:2002},
  pages = {277--278},
  doi = {10.1007/3-540-45672-4_43},
  abstract = {This tutorial shows testers, or anyone wearing the tester hat on an XP team, how testers contribute to the project, including what testers should do, when they should do it, and how they should do it. You'll do exercises that show you how to either work on an XP team as a tester yourself, or work productively with a tester on your team.},
  owner = {magsilva},
  timestamp = {2014.10.21}
}

@INPROCEEDINGS{Crowston-etal:2004,
  author = {K. Crowston and H. Annabi and J. Howison and C. Masango, C.},
  title = {Towards A Portfolio of {FLOSS} Project Success Measures},
  crossref = {proceedings:icse:2004},
  pages = {1--5},
  abstract = {Project success is one of the most widely used dependent variables in information systems research. However, conventional measures of project success are difficult to apply to Free/Libre Open Source Software projects. In this paper, we present an analysis of four measures of success applied to SourceForge projects: number of members of the extended development community, project activity, bug fixing time and number of downloads. We argue that these four measures provide different insights into the collaboration and control mechanisms of the projects.},
  address = {Edinburgh, Scotland},
  booktitle = {4th Workshop on Open Source Software Engineering},
  owner = {magsilva},
  timestamp = {2008.07.30},
  year = {2004}
}

@INCOLLECTION{Cruz:2009,
  author = {Dulce Márcia Cruz},
  title = {Aprendizagem por videoconferência},
  chapter = {13},
  pages = {87-93},
  crossref = {Litto-Formiga:2009}
}

@INPROCEEDINGS{Cruz-etal:2008,
  author = {Cruz, Vítor Medina and Moreno, Marcio Ferreira and Soares, Luiz Fernando Gomes},
  title = {{Ginga-NCL}: implementaçao de referência para dispositivos portáteis},
  crossref = {proceedings:webmedia:2008},
  pages = {67--74},
  doi = {10.1145/1666091.1666105},
  abstract = {This paper aims to present the first reference implementation of Ginga-NCL for portable receivers. Although based on a particular platform, the implementation not only works as a concept proof, but also raised several issues that should be taken into account when embedding this system. Ginga is the standard middleware of the Brazilian Digital TV System and Ginga-NCL is the unique required environment for portable devices.},
  keywords = {Ginga-NCL, NCL, declarative middleware, hypermedia systems, interactive DTV, mobile iTV, multimedia systems}
}

@ARTICLE{Cruzes-Dyba:2011,
  author = {Daniela S. Cruzes and Tore Dybå},
  title = {Research synthesis in software engineering: A tertiary study},
  crossref = {journal:elsevier:ist},
  volume = {53},
  number = {5},
  year = {2011},
  pages = {440 - 455},
  doi = {10.1016/j.infsof.2011.01.004},
  abstract = {Context: Comparing and contrasting evidence from multiple studies is necessary to build knowledge and reach conclusions about the empirical support for a phenomenon. Therefore, research synthesis is at the center of the scientific enterprise in the software engineering discipline. Objective: The objective of this article is to contribute to a better understanding of the challenges in synthesizing software engineering research and their implications for the progress of research and practice. Method: A tertiary study of journal articles and full proceedings papers from the inception of evidence-based software engineering was performed to assess the types and methods of research synthesis in systematic reviews in software engineering. Results: As many as half of the 49 reviews included in the study did not contain any synthesis. Of the studies that did contain synthesis, two thirds performed a narrative or a thematic synthesis. Only a few studies adequately demonstrated a robust, academic approach to research synthesis. Conclusion: We concluded that, despite the focus on systematic reviews, there is limited attention paid to research synthesis in software engineering. This trend needs to change and a repertoire of synthesis methods needs to be an integral part of systematic reviews to increase their significance and utility for research and practice.},
  keywords = {Evidence-based software engineering, Empirical software engineering, Systematic review, Qualitative methods, Mixed-methods},
  lang = {en}
}

@INBOOK{cruzlemus-etal:2005,
  chapter = {7},
  pages = {237-272},
  title = {Metrics for UML Statechart Diagrams},
  publisher = {Imperial College Press},
  year = {2005},
  editor = {Marcela Genero and Mario Piattini and Coral Calero},
  author = {José Antonio Cruz-Lemus and Marcela Genero and Mario Piattini},
  address = {London, UK},
  edition = {1},
  crossref = {genero-etal:2005}
}

@INPROCEEDINGS{Cubranic-Murphy:2003,
  author = {Cubranic, D. and Murphy, G.C.},
  title = {{Hipikat}: recommending pertinent software development artifacts},
  crossref = {proceedings:icse:2003},
  pages = {408--418},
  doi = {10.1109/ICSE.2003.1201219},
  abstract = {A newcomer to a software project must typically come up-to-speed on a large, varied amount of information about the project before becoming productive. Assimilating this information in the open-source context is difficult because a newcomer cannot rely on the mentoring approach that is commonly used in traditional software developments. To help a newcomer to an open-source project become productive faster, we propose Hipikat, a tool that forms an implicit group memory from the information stored in a project's archives, and that recommends artifacts from the archives that are relevant to a task that a newcomer is trying to perform. To investigate this approach, we have instantiated the Hipikat tool for the Eclipse open-source project. In this paper we describe the Hipikat tool, we report on a qualitative study conducted with a Hipikat mock-up on a medium-sized in-house project, and we report on a case study in which Hipikat recommendations were evaluated for a task on Eclipse.}
}

@ARTICLE{Cubranic-etal:2005,
  author = {Cubranic, D. and Murphy, G. C. and Singer, J. and Booth, K. S.},
  title = {Hipikat: a project memory for software development},
  crossref = {journal:ieee:tse},
  volume = {31},
  number = {6},
  month = jun,
  year = {2005},
  pages = {446--465},
  doi = {10.1109/TSE.2005.71},
  abstract = {Sociological and technical difficulties, such as a lack of informal encounters, can make it difficult for new members of noncollocated software development teams to learn from their more experienced colleagues. To address this situation, we have developed a tool, named Hipikat that provides developers with efficient and effective access to the group memory for a software development project that is implicitly formed by all of the artifacts produced during the development. This project memory is built automatically with little or no change to existing work practices. After describing the Hipikat tool, we present two studies investigating Hipikat's usefulness in software modification tasks. One study evaluated the usefulness of Hipikat's recommendations on a sample of 20 modification tasks performed on the Eclipse Java IDE during the development of release 2.1 of the Eclipse software. We describe the study, present quantitative measures of Hipikat's performance, and describe in detail three cases that illustrate a range of issues that we have identified in the results. In the other study, we evaluated whether software developers who are new to a project can benefit from the artifacts that Hipikat recommends from the project memory. We describe the study, present qualitative observations, and suggest implications of using project memory as a learning aid for project newcomers.},
  keywords = {Software development teams; project memory; recommender system; software artifacts; user studies.}
}

@INPROCEEDINGS{Cubranic-etal:2002,
  author = {Cubranic, Gail C. Murphy and Booth},
  title = {Hipikat: A Developer's Recommender},
  crossref = {proceedings:oopsla:2002}
}

@ARTICLE{Curtis-etal:1992,
  author = {Curtis, Bill and Kellner, Marc I. and Over, Jim},
  title = {Process modeling},
  crossref = {journal:acm:cacm},
  volume = {35},
  number = {9},
  month = sep,
  year = {1992},
  pages = {75--90},
  doi = {10.1145/130994.130998},
  keywords = {analysis, modeling}
}

@INPROCEEDINGS{Dagenais-etal:2010,
  author = {Dagenais, Barthélémy and Ossher, Harold and Bellamy, Rachel K. E. and Robillard, Martin P. and de Vries, Jacqueline P.},
  title = {Moving into a new software project landscape},
  crossref = {proceedings:icse:2010},
  pages = {275--284},
  doi = {10.1145/1806799.1806842},
  abstract = {When developers join a software development project, they find themselves in a project landscape, and they must become familiar with the various landscape features. To better understand the nature of project landscapes and the integration process, with a view to improving the experience of both newcomers and the people responsible for orienting them, we performed a grounded theory study with 18 newcomers across 18 projects. We identified the main features that characterize a project landscape, together with key orientation aids and obstacles, and we theorize that there are three primary factors that impact the integration experience of newcomers: early experimentation, internalizing structures and cultures, and progress validation.}
}

@INPROCEEDINGS{Dagiene:2010,
  author = {Dagiene, Valentina},
  title = {Sustaining Informatics Education by Contests},
  crossref = {proceedings:issep:2010},
  pages = {1--12},
  doi = {10.1007/978-3-642-11376-5_1},
  abstract = {Three decades ago high school computing was highly consistent with academic and professional world. This consistency was destroyed when school curricula began to emphasize information and communication technology skills at the expense of computer science. Recently many countries began to think how to re-establish informatics education in schools and how to attract pupils to choose optional modules related to computer science. Although informatics is not taught as a discipline in many countries, pupils are invited to participate in different contests on informatics organized all over the world. When pupils get interested in programming contests, they are looking for training and gain some informatics education. Contests are exceptionally valuable for motivating and involving pupils in computer science. The current paper discusses the contests and olympiads in informatics arranged internationally and continuously. The main attention is paid to the model of International Olympiad in Informatics and International Contest on Informatics and Computer Fluency (named Bebras in Lithuanian, or Beaver in English).},
  keywords = {Teaching informatics, computer science education, contest on informatics, olympiad in informatics, teaching programming},
  owner = {magsilva},
  timestamp = {2014.08.30}
}

@INPROCEEDINGS{Dagiene-etal:2014,
  author = {Dagiene, Valentina and Mannila, Linda and Poranen, Timo and Rolandsson, Lennart and Söderhjelm, Pär},
  title = {Students' Performance on Programming-related Tasks in an Informatics Contest in {Finland}, {Sweden} and {Lithuania}},
  crossref = {proceedings:itcse:2014},
  pages = {153--158},
  doi = {10.1145/2591708.2591760},
  abstract = {The ways in which informatics is covered in K-12 education vary among European countries. In Finland and Sweden, informatics is not included in the core curriculum, whereas, for example, in Lithuania, all students are exposed to some informatics concepts starting in the fifth grade. Bebras is an annually arranged international informatics contest for K-12 level, resulting in a large collection of data about contestants and their results. In this paper, we analyse contest data from the Finnish, Swedish and Lithuanian 2013 con- tests, focusing on students' performance on tasks related to algorithmic thinking. Our findings suggest that despite coming from different educational systems, students perform rather similarly on the tasks. The same tasks are difficult and the thinking behind picking an incorrect answer seems rather similar throughout the countries. The analysis also points out that there is a lack of easy questions -- this needs to be fixed in order to not risk scaring students away.},
  keywords = {algorithmic thinking, contests, data structures, informatics education, programming},
  owner = {magsilva},
  timestamp = {2014.08.30}
}

@ARTICLE{Dallal:2013,
  author = {Jehad Al Dallal},
  title = {Object-oriented class maintainability prediction using internal quality attributes},
  crossref = {journal:elsevier:ist},
  volume = {55},
  number = {11},
  month = nov,
  year = {2013},
  pages = {2028--2048},
  doi = {10.1016/j.infsof.2013.07.005},
  abstract = {Context Class maintainability is the likelihood that a class can be easily modified. Before releasing an object-oriented software system, it is impossible to know with certainty when, where, how, and how often a class will be modified. At that stage, this likelihood can be estimated using the internal quality attributes of a class, which include cohesion, coupling, and size. To reduce the future class maintenance efforts and cost, developers are encouraged to carefully test and well document low maintainability classes before releasing the object-oriented system. We empirically study the relationship between internal class quality attributes (size, cohesion, and coupling) and an external quality attribute (class maintainability). Using statistical techniques, we also construct models based on the selected internal attributes to predict class maintainability. We consider classes of three open-source systems. For each class, we account for two actual maintainability indicators, the number of revised lines of code and the number of revisions in which the class was involved. Using 19 internal quality measures, we empirically explore the impact of size, cohesion, and coupling on class maintainability. We also empirically investigate the abilities of the measures, considered both individually and combined, to estimate class maintainability. Statistically based prediction models are constructed and validated. Our results demonstrate that classes with better qualities (i.e., higher cohesion values and lower size and coupling values) have better maintainability (i.e., are more likely to be easily modified) than those of worse qualities. Most of the considered measures are shown to be predictors of the considered maintainability indicators to some degree. The abilities of the considered internal quality measures to predict class maintainability are improved when the measures are combined using optimized multivariate statistical models. The prediction models can help software engineers locate classes with low maintainability. These classes must be carefully tested and well documented.},
  keywords = {Internal and external quality attributes, Quality measures, Class cohesion, Class coupling, Class size, Class maintainability },
  timestamp = {2013-09-08}
}

@INPROCEEDINGS{Damasceno-etal:2010,
  author = {Ribeiro Damasceno and Joel A. Ferreira dos Santos and Débora C. Muchaluat Saade.},
  title = {{EDITEC}: Editor Gráfico de Templates de Composição para Facilitar a Autoria de Programas para {TV} Digital Interativa},
  crossref = {proceedings:webmedia:2010},
  pages = {211--218},
  abstract = {Este artigo apresenta o EDITEC, um editor gráfico de templates de composição hipermídia baseado na linguagem XTemplate 3.0. O EDITEC foi projetado para a criação de templates usando uma abordagem gráfica visual de fácil uso e aprendizado. Ele fornece diversas opções para representar estruturas de iteração e uma interface gráfica para a criação de expressões XPath básicas. O sistema provê um ambiente amigável com múltiplas visões, dando ao autor um completo controle do template de composição durante o processo de autoria. Templates de composição podem ser usados em programas NCL para embutir semântica espaçotemporal em contextos NCL e facilitar a produção de conteúdo interativo para o Sistema Brasileiro de TV Digital.},
  keywords = {EDITEC, NCL, XTemplate, XPath, templates, editor gráfico, templates de composição},
  abstract-en = {This paper presents EDITEC, a graphical editor for hypermedia composite templates based on the XTemplate 3.0 language. EDITEC was designed for the creation of templates using a user-friendly visual graphical approach. It provides several options for representing iteration structures and a graphical interface for creating basic XPath expressions. The system provides a friendly environment with multiple views, giving the user a complete control of the composite template during the authoring process. Composite templates can be used in NCL programs for embedding spatio-temporal semantics into NCL contexts and making the production of interactive content easier for the Brazilian Digital TV System.}
}

@INPROCEEDINGS{Damasio:2003,
  author = {Manuel José Damásio},
  title = {Uses of Interactive Television on Educational Settings: Evaluating the Media Impact},
  crossref = {proceedings:euroitv:2003},
  pages = {117 -- 119},
  abstract = {VEMiTV project involves the establishing of t-learning potential on a specific educational setting: elementary schools. This document describes the working hypothesis and the usability and cognitive procedures being followed in that project, while at the same time discusses t-learning potential as a formal or informal learning strategy.},
  keywords = {t-learning, cognitive evaluation, iTV applications}
}

@INCOLLECTION{Daniel-Mackintosh:2003,
  author = {John Daniel and Wayne Mackintosh},
  title = {Leading {ODL} Futures in the Eternal Triangle: The Mega-University Response to the Greatest Moral Challenge of Our Age},
  chapter = {54},
  pages = {811--827},
  crossref = {Moore-Anderson:2003}
}

@INPROCEEDINGS{Dannelly-Garrison:2008,
  author = {Dannelly, R. Stephen and Garrison, Chlotia P.},
  title = {Development of a Graduate Software Project Management Degree},
  crossref = {proceedings:acm-se:2008},
  pages = {446--449},
  doi = {10.1145/1593105.1593222},
  abstract = {The shortcomings of the software development industry are well documented and familiar to all computer science faculty members. Many software projects fail to deliver products with adequate functionality or are completed over budget and well past the original expected delivery date. The causes of these problems are also well documented and well known. Most often the causes of software project failure are not related to incompetency among the software developers, but inadequate skills among the project managers. Recently, several universities have begun offering management degree programs in their engineering colleges. Most graduate software engineering programs now include at least some coursework in project management. Our university has taken a different approach to producing graduate software project managers. We have developed a Software Project Management option within our College of Business's MBA program. This paper describes the skills we believe necessary for software project managers and how we cover these skills through a combination of computer science and business courses. We hope this paper will be helpful to educators developing new degree programs and promote discussion about the value of bridging the gap between the two distant academic worlds of engineering and business.},
  keywords = {computer science education, graduate curriculum, project management},
  owner = {magsilva},
  timestamp = {2014.09.13}
}

@INCOLLECTION{Dave:1968,
  author = {Ravindrakumar H. Dave},
  title = {Psychomotor levels},
  pages = {33-34},
  crossref = {Armstrong-etal:1968}
}

@ARTICLE{Davis-etal:1988,
  author = {Davis, A.M. and Bersoff, E.H. and Comer, E.R.},
  title = {A strategy for comparing alternative software development life cycle models},
  crossref = {journal:ieee:tse},
  volume = {14},
  number = {10},
  month = oct,
  year = {1988},
  pages = {1453--1461},
  doi = {10.1109/32.6190},
  abstract = {It is difficult to compare and contrast models of software development because their proponents often use different terminology, and the mdels often have little in common except their beginnings (marked by a recognition that a problem exists) and ends (marked by the existence of a software solution). A framework is provided that can serve: as a basis for analyzing the similarities and differences among alternate life-cycle models; as a tool for software engineering researchers to help describe the probable impacts of a life-cycle mode; and as a means to help software practitioners decide on an appropriate life-cycle model to utilize on a particular project or in a particular application area},
  keywords = {software development life cycle models;software engineering;software engineering;}
}

@ARTICLE{Davis-etal:1988,
  author = {Davis, A. M. and Bersoff, E. H. and Comer, E. R.},
  title = {A strategy for comparing alternative software development life cycle models},
  crossref = {journal:ieee:tse},
  volume = {14},
  number = {10},
  month = oct,
  year = {1988},
  pages = {1453--1461},
  doi = {10.1109/32.6190},
  abstract = {It is difficult to compare and contrast models of software development because their proponents often use different terminology, and the models often have little in common except their beginnings (marked by a recognition that a problem exists) and ends (marked by the existence of a software solution). A framework is provided that can serve: as a basis for analyzing the similarities and differences among alternate life-cycle models; as a tool for software engineering researchers to help describe the probable impacts of a life-cycle mode; and as a means to help software practitioners decide on an appropriate life-cycle model to utilize on a particular project or in a particular application area.<>},
  keywords = {reusable software, software development life cycles, software prototyping, software synthesis, waterfall model},
  issn = {0098-5589},
  journal = {Software Engineering, IEEE Transactions on},
  owner = {magsilva},
  timestamp = {2014.10.23}
}

@ARTICLE{Daylight:2014,
  author = {Daylight, Edgar G.},
  title = {A Turing Tale},
  crossref = {journal:acm:cacm},
  volume = {57},
  number = {10},
  month = sep,
  year = {2014},
  pages = {36--38},
  doi = {10.1145/2629499},
  abstract = {Assessing the accuracy of popular descriptions of Alan Turing's influences and legacy.},
  owner = {magsilva},
  timestamp = {2014.10.14}
}

@ARTICLE{Debroy-Wong:2014,
  author = {Vidroha Debroy and W. Eric Wong},
  title = {Combining mutation and fault localization for automated program debugging },
  crossref = {journal:elsevier:jss},
  volume = {90},
  number = {0},
  month = apr,
  year = {2014},
  pages = {45-60},
  doi = {10.1016/j.jss.2013.10.042},
  abstract = {This paper proposes a strategy for automatically fixing faults in a program by combining the ideas of mutation and fault localization. Statements ranked in order of their likelihood of containing faults are mutated in the same order to produce potential fixes for the faulty program. The proposed strategy is evaluated using 8 mutant operators against 19 programs each with multiple faulty versions. Our results indicate that 20.70% of the faults are fixed using selected mutant operators, suggesting that the strategy holds merit for automatically fixing faults. The impact of fault localization on efficiency of the overall fault-fixing process is investigated by experimenting with two different techniques, Tarantula and Ochiai, the latter of which has been reported to be better at fault localization than Tarantula, and also proves to be better in the context of fault-fixing using our proposed strategy. Further experiments are also presented to evaluate stopping criteria with respect to the mutant examination process and reveal that a significant fraction of the (fixable) faults can be fixed by examining a small percentage of the program code. We also report on the relative fault-fixing capabilities of mutant operators used and present discussions on future work.},
  keywords = {Program debugging, Mutation, Fault localization, Fault-fixing, Software testing}
}

@ARTICLE{DeClue-etal:2012,
  author = {DeClue, Tim and Kimball, Jeff and Cain, James},
  title = {Learning theory in {Computer Science 1}: an experiment supporting the use of multiple languages},
  crossref = {journal:ccsc:jcsc},
  volume = {27},
  number = {5},
  month = may,
  year = {2012},
  pages = {198--204},
  abstract = {A great deal of time and effort have been focused on answering the question of what approach is "best" for teaching Computer Science 1 (CS1). Clearly, the question has significance due to the consequences of teaching the course poorly-losing talented students, lowered levels of learning, less diversity among CS majors, even the possibility of losing faculty who dislike teaching a poorly designed course. This paper presents an innovative approach based in human learning theory which uses multiple languages (Java and Python) to teach fundamental concepts of writing algorithms to novices. An experiment was designed and conducted to judge the effectiveness of the approach, and the results are discussed.}
}

@INPROCEEDINGS{Defude-Farhat:2005,
  author = {Defude, Bruno and Farhat, Ramzi},
  title = {A Framework to Design Quality-Based Learning Objects},
  crossref = {proceedings:icalt:2005},
  pages = {23--27},
  doi = {10.1109/ICALT.2005.7},
  abstract = {Nowadays there are lots of learning objects stored on numerous repositories. They are described by meta-data allowing users (either authors or learners) to search and reuse these learning objects. The process of reuse is not so simple and requires some attention during the design phase. In our opinion, it seems clear that semantic metadata are required to allow a real reusing and assembling of learning objects. Following this principle we have defined a system based on three semantic models used to describe the domain, learners and learning objects. In this paper we investigate how to improve the design process of resources described using our proposal. For this, we propose two kinds of approaches: metrics and types. Using metrics, authors may have information about several aspects of quality of their existing resources. Types allow constraining the authoring process by defining constraints to be enforced by new learning objects.},
  isbn = {0-7695-2338-2},
  lang = {en}
}

@INPROCEEDINGS{Deissenboeck-etal:2011,
  author = {Deissenboeck, F. and Heinemann, L. and Herrmannsdoerfer, M. and Lochmann, K. and Wagner, S.},
  title = {The {Quamoco} Tool Chain for Quality Modeling and Assessment},
  crossref = {proceedings:icse:2011},
  pages = {1007--1009},
  doi = {10.1145/1985793.1985977},
  abstract = {Continuous quality assessment is crucial for the long-term success of evolving software. On the one hand, code analysis tools automatically supply quality indicators, but do not provide a complete overview of software quality. On the other hand, quality models define abstract characteristics that influence quality, but are not operationalized. Currently, no tool chain exists that integrates code analysis tools with quality models. To alleviate this, the Quamoco project provides a tool chain to both define and assess software quality. The tool chain consists of a quality model editor and an integration with the quality assessment toolkit ConQAT. Using the editor, we can define quality models ranging from abstract characteristics down to operationalized measures. From the quality model, a ConQAT configuration can be generated that can be used to automatically assess the quality of a software system.},
  keywords = {quality assessment , quality modeling , tool chain}
}

@INPROCEEDINGS{Delamaro-Maldonado:1996,
  author = {Márcio E. Delamaro and José Carlos Maldonado},
  title = {Proteum -- A Tool for the Assessment of Test Adequacy for {C} Programs},
  crossref = {proceedings:pcs:1996},
  pages = {79--95},
  abstract = {The quality and productivity of the test activity is dependent on the test criterion used as well as on related supporting tool. We present a testing tool that supports the application of mutation testing to C programs, named Proteum, developed at Universidade de São Paulo (USP), Brazil. Proteum can be run either by using a graphical interface or by using scripts, both ways are described and illustrated. Proteum has been used for teaching and research at USP and at Purdue University, as well as in other universities. The most critical aspect of implementing such a tool is briefly discussed.},
  owner = {magsilva}
}

@INPROCEEDINGS{Delamaro-etal:1996,
  author = {M. E. Delamaro and J. C. Maldonado and A. P. Mathur},
  title = {Integration Testing Using Interface Mutation},
  crossref = {proceedings:issre:1996},
  pages = {112--121},
  doi = {10.1109/ISSRE.1996.558719},
  abstract = {A criterion for assessing the adequacy of test sets during integration testing is proposed. The criterion is based on a testing technique named Interface Mutation. The technique itself is designed to be scalable with the size of the software under test; the size being measured in the number of subsystems integrated. Using Interface Mutation it is possible to assess the adequacy of tests incrementally while integrating various subsystems. Also reported are results from a pilot experiment conducted to study the cost and error defection effectiveness of Interface Mutation},
  keywords = {integration testing; test adequacy; mutation testing; PROTEUM}
}

@ARTICLE{Delamaro-etal:2001:TSE,
  author = {M. E. Delamaro and J. C. Maldonado and A. P. Mathur},
  title = {Interface Mutation: An Approach for Integration Testing},
  crossref = {journal:ieee:tse},
  volume = {27},
  number = {3},
  month = mar,
  year = {2001},
  pages = {228--247},
  doi = {10.1109/32.910859},
  abstract = {The need for test adequacy criteria is widely recognized. Several criteria have been proposed for the assessment of adequacy of tests at the unit level. However, there remains a lack of criteria for the assessment of the adequacy of tests generated during integration testing. We present a mutation based interprocedural criterion, named Interface Mutation (IM), suitable for use during integration testing. A case study to evaluate the proposed criterion is reported. In the study, the UNIX sort utility was seeded with errors and Interface Mutation evaluated by measuring the cost of its application and its error revealing effectiveness. Alternative IM criteria using different sets of Interface Mutation operators were also evaluated. While comparing the error revealing effectiveness of these Interface Mutation-based test sets with same size randomly generated test sets, we observed that in most cases Interface Mutation based test sets are superior. The results suggest that Interface Mutation offers a viable test adequacy criteria for use at the integration level.},
  keywords = {test adequacy criteria; mutation testing; mutation analysis; integration testing; testing tool}
}

@ARTICLE{Delamaro-etal:2001:ESE,
  author = {M. E. Delamaro and J. C. Maldonado and Alberto Pasquini and Aditya P. Mathur},
  title = {Interface Mutation Test Adequacy Criterion: An Empirical Evaluation},
  crossref = {proceedings:springer:ese},
  volume = {6},
  number = {2},
  month = jun,
  year = {2001},
  pages = {111-142},
  doi = {10.1023/A:1011429104252},
  abstract = {An experiment was conducted to evaluate an inter-procedural test adequacy criterion named Interface Mutation. Program SPACE, developed for the European Space Agency (ESA), was used in this experiment. The development record available for this program was used to find the faults uncovered during its development. Using this information the test process was reproduced starting with a version of SPACE containing several faults and then applying Interface Mutation. Thus we could evaluate the fault revealing effectiveness of Interface Mutation. Results from the experiment suggest that (a) the application of Interface Mutation favors the selection of fault revealing test cases when they exist and (b) Interface Mutation tends to select fault revealing test cases more efficiently than in the case where random selection is used.},
  keywords = {mutation testing; interface mutation; test adequacy criteria; software testing}
}

@INPROCEEDINGS{Delamaro-etal:2000,
  author = {Márcio Eduardo Delamaro and José Carlos Maldonado and Auri Marcelo Rizzo Vincenzi},
  title = {{Proteum/IM 2.0}: An Integrated Mutation Testing Environment},
  crossref = {proceedings:mutation:2000},
  pages = {91--101},
  abstract = {Mutation testing has been used mostly at the unit level. To support its application few tools have been developed and used, mainly in the academic envrionment. Interface Mutation has been proposed aiming at applying mutation at the integration level. A tool named Proteum/IM was implemented to support such criterion. With the definition of the Interface Mutation criterion the tester has the possibility of applying mutation testing concepts throughout the software development. It seens mandatory to have a single, integrated environment that would support mutation-based unit and integration testing. Such environment, which provides facilities to investigate low-cost and incremental testing strategies, is the focus of this paper.},
  keywords = {software testing; mutation testing; interface mutation; testing tool; Proteum/IM 2.0},
  address = {San Jose, CA},
  booktitle = {Mutation 2000 Symposium},
  month = oct,
  owner = {magsilva},
  publisher = {Kluwer Academic Publishers},
  timestamp = {2008.07.31},
  year = {2000}
}

@ARTICLE{Dellarocas-VanAlstyne:2013,
  author = {Dellarocas, Chrysanthos and Van Alstyne, Marshall},
  title = {Money models for MOOCs},
  crossref = {journal:acm:cacm},
  volume = {56},
  number = {8},
  month = aug,
  year = {2013},
  pages = {25--28},
  doi = {10.1145/2492007.2492017},
  abstract = {Considering new business models for massive open online courses.}
}

@ARTICLE{Denning:2013,
  author = {Denning, Peter J.},
  title = {The science in computer science},
  crossref = {journal:acm:communications},
  volume = {56},
  number = {5},
  month = may,
  year = {2013},
  pages = {35--38},
  doi = {10.1145/2447976.2447988},
  abstract = {Computer science is in a period of renaissance as it rediscovers its science roots.}
}

@ARTICLE{Denning:1992,
  author = {Denning, Peter J.},
  title = {Educating a new engineer},
  crossref = {journal:acm:cacm},
  volume = {35},
  number = {12},
  month = dec,
  year = {1992},
  pages = {82--97},
  doi = {10.1145/138859.138870}
}

@ARTICLE{Denning:1968,
  author = {Denning, Peter J.},
  title = {The working set model for program behavior},
  crossref = {journal:acm:cacm},
  volume = {11},
  number = {5},
  month = may,
  year = {1968},
  pages = {323--333},
  doi = {10.1145/363095.363141},
  keywords = {general operating system concepts, multiprocessing, multiprogramming, operating systems, program behavior, program models, resource allocation, scheduling, storage allocation}
}

@INPROCEEDINGS{Denny-etal:2008,
  author = {Denny, Paul and Luxton-Reilly, Andrew and Hamer, John},
  title = {Student use of the {PeerWise} system},
  crossref = {proceedings:itcse:2008},
  pages = {73--77},
  doi = {10.1145/1384271.1384293},
  abstract = {PeerWise is a web-based system that supports the creation of student-generated test banks of multiple choice questions. Students contribute question stems and answers, provide explanations, answer questions contributed by other students, rate questions for difficulty and quality, and participate in on-line discussions of all these activities. In 2007, the system was used in four computing classes that varied in level, instructors, and student reward. We present results that show common patterns of response from students, and outline some initial investigations into the impact of the system on student performance. Our main findings are: external motivators are needed only for question generation; exam performance is correlated with participation in on-line discussions; and, despite student enthusiasm, drill-and-practice use does not contribute to exam success.},
  keywords = {MCQ, PeerWise, automated, peer assessment, question test bank}
}

@INPROCEEDINGS{Denny-etal:2012,
  author = {Denny, Paul and Luxton-Reilly, Andrew and Tempero, Ewan},
  title = {All syntax errors are not equal},
  crossref = {proceedings:itcse:2012},
  pages = {75--80},
  doi = {10.1145/2325296.2325318},
  abstract = {Identifying and correcting syntax errors is a challenge all novice programmers confront. As educators, the more we understand about the nature of these errors and how students respond to them, the more effective our teaching can be. It is well known that just a few types of errors are far more frequently encountered by students learning to program than most. In this paper, we examine how long students spend resolving the most common syntax errors, and discover that certain types of errors are not solved any more quickly by the higher ability students. Moreover, we note that these errors consume a large amount of student time, suggesting that targeted teaching interventions may yield a significant payoff in terms of increasing student productivity.},
  keywords = {assessment, codewrite, drill and practice, java, syntax errors}
}

@INPROCEEDINGS{Denny-etal:2011:itcse,
  author = {Denny, Paul and Luxton-Reilly, Andrew and Tempero, Ewan and Hendrickx, Jacob},
  title = {Understanding the syntax barrier for novices},
  crossref = {proceedings:itcse:2011},
  pages = {208--212},
  doi = {10.1145/1999747.1999807},
  abstract = {Mastering syntax is one of the earliest challenges facing the novice programmer. Problem solving and algorithms are the focus of many first year programming classes, leaving students to learn syntax on their own while they practice writing code. In this paper we investigate the frequency with which students encounter syntax errors during a drill and practice activity. We find that students struggle with syntax to a greater extent than we anticipated, even when writing short fragments of code.},
  keywords = {assessment, codewrite, constructive evaluation, drill and practice, java, student-generated exercises, syntax}
}

@INPROCEEDINGS{Denny-etal:2011:sigce,
  author = {Denny, Paul and Luxton-Reilly, Andrew and Tempero, Ewan and Hendrickx, Jacob},
  title = {{CodeWrite}: supporting student-driven practice of {Java}},
  crossref = {proceedings:sigcse:2011},
  pages = {471--476},
  doi = {10.1145/1953163.1953299},
  abstract = {Drill and practice exercises enable students to master skills needed for more sophisticated programming. A barrier to providing such activities is the effort required to set up the programming environment. Testing is an important component to writing good software, but it is difficult to motivate students to write tests. In this paper we describe and evaluate CodeWrite, a web-based tool that provides drill and practice support for Java programming, and for which testing plays a central role in its use. We describe how we have used CodeWrite in a CS1 course, and demonstrate its effectiveness in providing good coverage of the language features presented in the course.},
  keywords = {CodeWrite, assessment, constructive evaluation, contributing student pedagogy, online, student-generated content}
}

@ARTICLE{Derntl-MotschnigPitrik:2005,
  author = {Michael Derntl and Renate Motschnig-Pitrik},
  title = {The role of structure, patterns, and people in blended learning},
  crossref = {journal:elsevier:ihe},
  volume = {8},
  number = {2},
  month = mar # {-} # apr,
  year = {2005},
  pages = {111--130},
  doi = {10.1016/j.iheduc.2005.03.002},
  abstract = {Recently, much e-learning research has been devoted to producing e-content, describing it with metadata, and to constructing e-learning systems. Considerably less attention has been paid to integrating technology to improve the learning process in terms of depth and scope. In this paper, that gap is filled by considering learning support from a technological as well as from a socio-psychological perspective. Didactically, well-proven educational principles from the Person-Centered Approach are adopted to drive educational processes. Technically, a layered framework for deriving Web-based support from these educational principles is proposed. The study focuses on the contribution of visual modeling of blended learning scenarios, on their semi-formal description as patterns, and on the use of patterns as sources for user-centered Web support modules. The experiences and evaluations of one major academic course on Web Engineering indicate that blended learning has added value only when facilitated by educators with high interpersonal skills, and accompanied by reliable, easy-to-use technology.},
  keywords = {Blended learning; Person-Centered e-Learning (PCeL); Learning design; Design patterns; Learning technology; Evaluation}
}

@INCOLLECTION{Derntl-MotshnigPitrik:2008,
  author = {Michael Derntl and Renate Motshnig-Pitrik},
  title = {{coUML}: A Visual Language for Modeling Cooperative Environments},
  chapter = {9},
  pages = {154-182},
  abstract = {In this chapter we present coUML, a visual modeling language for cooperative environments. As modern instructional environments have a highly cooperative nature, coUML is proposed as a powerful and effective language for modeling instructional designs in such environments. Being based on UML, it was conceived and refined through application and experience over multiple years, primarily in a cooperative blended learning environment. We present relevant requirements and applications that contributed to the development of coUML, as well as a detailed specification of model elements, characteristics and features that describe its current state.},
  crossref = {Botturi-Stubbs:2008},
  doi = {10.4018/978-1-59904-729-4.ch009},
  lang = {en},
  timestamp = {2012.01.26}
}

@ARTICLE{Derntl-etal:2012,
  author = {Derntl, M. and Neumann, S. and Griffiths, D. and Oberhuemer, P.},
  title = {The Conceptual Structure of {IMS Learning Design} Does Not Impede Its Use for Authoring},
  crossref = {journal:ieee:tlt},
  volume = {5},
  number = {1},
  month = jan # {--} # mar,
  year = {2012},
  pages = {74--86},
  doi = {10.1109/TLT.2011.25},
  abstract = {IMS Learning Design (LD) is the only available interoperability specification in the area of technology enhanced learning that allows the definition and orchestration of complex activity flows and resource environments in a multirole setting. IMS LD has been available since 2003, and yet it has not been widely adopted either by practitioners or by institutions. Much current IMS LD research seems to accept the assumption that a key barrier to adoption is the specification's conceptual complexity impeding the authoring process. This paper presents an empirical study to test this assumption. Study participants were asked to transform a given textual design description into an IMS LD unit of learning using 1) paper snippets representing IMS LD elements and 2) authoring software. The results show that teachers with little or no previous IMS LD knowledge were able to solve a design task that required the use of all IMS LD elements at levels A and B. An additional finding is that the authoring software did not facilitate people in producing better solutions than those who used paper snippets. This evidence suggests that conceptual complexity does not impede effective IMS LD authoring, so the barriers to adoption appear to lie elsewhere.},
  keywords = {E-learning standards, IMS Learning Design, authoring tools, computer-managed instruction}
}

@ARTICLE{Desai-etal:2008,
  author = {Desai, Chetan and Janzen, David and Savage, Kyle},
  title = {A Survey of Evidence for Test-driven Development in Academia},
  crossref = {journal:acm:sigcse-bulletin},
  volume = {40},
  number = {2},
  month = jun,
  year = {2008},
  pages = {97--101},
  doi = {10.1145/1383602.1383644},
  abstract = {University professors traditionally struggle to incorporate software testing into their course curriculum. Worries include double-grading for correctness of both source and test code and finding time to teach testing as a topic. Test-driven development (TDD) has been suggested as a possible solution to improve student software testing skills and to realize the benefits of testing. According to most existing studies, TDD improves software quality and student productivity. This paper surveys the current state of TDD experiments conducted exclusively at universities. Similar surveys compare experiments in both the classroom and industry, but none have focused strictly on academia.},
  keywords = {empirical survey, pedagogy, test-driven development},
  owner = {magsilva},
  timestamp = {2014.08.30}
}

@ARTICLE{Desai-etal:2009,
  author = {Desai, Chetan and Janzen, David S. and Clements, John},
  title = {Implications of integrating test-driven development into {CS1/CS2} curricula},
  crossref = {proceedings:sigcse:2009},
  volume = {41},
  number = {1},
  month = mar,
  pages = {148--152},
  doi = {10.1145/1539024.1508921},
  abstract = {Many academic and industry professionals have called for more testing in computer science curricula. Test-driven development (TDD) has been proposed as a solution to improve testing in academia. This paper demonstrates how TDD can be integrated into existing course materials without reducing topic coverage. Two controlled experiments were conducted in a CS1/CS2 course in Winter 2008. Following a test-driven learning approach, unit testing was introduced at the beginning of the course and reinforced through example. Results indicate that while student work loads may increase with the incorporation of TDD, students are able to successfully develop unit tests while learning to program.},
  keywords = {cs1, cs2, test-driven development, test-driven learning}
}

@ARTICLE{Desharnais-etal:2011,
  author = {Desharnais, Jean-Marc and Abran, Alain and Suryn, Witold},
  title = {Identification and analysis of attributes and base measures within {ISO 9126}},
  crossref = {journal:springer:sqj},
  volume = {19},
  number = {2},
  month = jun,
  year = {2011},
  pages = {447--460},
  doi = {10.1007/s11219-010-9124-5},
  abstract = {The ISO 9126 quality model is a 4-part suite of documents presenting 10 characteristics of the quality of software products, 27 subcharacteristics, and an inventory of more than 250 derived measures proposed to quantify these quality characteristics and subcharacteristics. However, these measures are presented only at a fairly abstract level as formulae composed from a set of 80 base measures. As the base measures themselves lack detailed descriptions, including the attributes they are attempting to measure, they are highly susceptible to individual interpretation. Improving the design of the 80 base measures is a daunting task. The ISO 9126 standard is currently under revision by an ISO working group (ISO/IEC JTC1/SC7 WG6), and this paper proposes a process to determine which of these base measures should be improved in the timeliest fashion.},
  keywords = {ISO 9126; Base measures; Attributes}
}

@MISC{Devanbu:2009,
  author = {Prem Devanbu},
  title = {Study the Social Side of Software Engineering},
  howpublished = {Statement at \cite{Nagappan-etal:2009}},
  crossref = {Nagappan-etal:2009}
}

@INPROCEEDINGS{Dickson-etal:2008,
  author = {Dickson, Paul E. and Adrion, W. Richards and Hanson, Allen R.},
  title = {Automatic creation of indexed presentations from classroom lectures},
  crossref = {proceedings:itcse:2008},
  pages = {12--16},
  doi = {10.1145/1384271.1384277},
  abstract = {This paper describes a system designed to automatically capture classroom events as videos and images. This content is delivered in several ways, most commonly as indexed multimedia presentations but also in real time as notes of classroom events. This content creation system identifies when significant events occur, e.g., material presented by computer and projected on a screen or written on a standard whiteboard, and saves these events as enhanced images. In parallel with the whiteboard capture, a digitally-zoomed video of the speaker is created. The significant event images (from cameras and computers) are used to create an index into the video and the images, video and index are complied into a Flash presentation. These presentations are used by on-campus or distance students. The event images can also be stored and exported to a Ubiquitous Presenter-style server that provides students with real-time, in-class access. The event images and video are recorded transparently to the lecturer. The lecturer need not make any modifications to teaching style or modality (whiteboard, computer-based presentation, or a combination). The primary focus of this paper is on event image and video capture techniques. The lecture capture system has great benefits for education and we report some initial experience using it in support of computer science curricula.},
  keywords = {automatic capture, image processing, indexing, lecture recording, video creation}
}

@ARTICLE{Dieste-etal:2009,
  author = {Dieste, Oscar and Grimán, Anna and Juristo, Natalia},
  title = {Developing Search Strategies for Detecting Relevant Experiments},
  crossref = {journal:springer:ese},
  volume = {14},
  number = {5},
  month = oct,
  year = {2009},
  pages = {513--539},
  doi = {10.1007/s10664-008-9091-7},
  abstract = {Our goal is to analyze the optimality of search strategies for use in systematic reviews of software engineering experiments. Studies retrieval is an important problem in any evidence-based discipline. This question has not been examined for evidence-based software engineering as yet. We have run several searches exercising different terms denoting experiments to evaluate their recall and precision. Based on our evaluation, we propose using a high recall strategy when there are plenty of resources or the results need to be exhaustive. For any other case, we propose optimal, or even acceptable, search strategies. As a secondary goal, we have analysed trends and weaknesses in terminology used in articles reporting software engineering experiments. We have found that it is impossible for a search strategy to retrieve 100% of the experiments of interest (as happens in other experimental disciplines), because of the shortage of reporting standards in the community.},
  keywords = {Controlled experiment, Evidence-based software engineering, Systematic review}
}

@INPROCEEDINGS{Dieste-Padua:2007,
  author = {Dieste, O. and Padua, O. A. G.},
  title = {Developing Search Strategies for Detecting Relevant Experiments for Systematic Reviews},
  crossref = {proceedings:esem:2007},
  pages = {215--224},
  doi = {10.1109/ESEM.2007.19},
  abstract = {Information retrieval is an important problem in any evidence-based discipline. Although evidence- based software engineering (EBSE) is not immune to this fact, this question has not been examined at length. The goal of this paper is to analyse the optimality of search strategies for use in systematic reviews. We tried out 29 search strategies using different terms and combinations of terms. We evaluated their sensitivity and precision with a view to finding an optimum strategy. From this study of search strategies we were able to analyse trends and weaknesses in terminology use in articles reporting experiments.}
}

@INPROCEEDINGS{DiIorio-etal:2008,
  author = {Di Iorio, Angelo and Furini, Luca and Vitali, Fabio and Lumley, John and Wiley, Tony},
  title = {Higher-level layout through topological abstraction},
  crossref = {proceedings:doceng:2008},
  pages = {90--99},
  doi = {10.1145/1410140.1410157},
  abstract = {Existing layout languages provide support for geometric properties allowing - and in a sense forcing - users to give a complete geometric description of the desired output: if the characteristics of the output medium change, the layout of the whole document has to be reworked completely, as the properties set by the user are no longer appropriate for the modified context. In this paper we propose a different paradigm which allows users to produce layouts by describing their topological and abstract properties, rather than geometric ones. We first define and detail topological properties as abstract relationships between the document components, independent from the output characteristics, and then describe an XML-based layout language based on these concepts, called TALL. A running engine able to transform topological layouts into actual PDF files, based on XSLT and the DDF framework, is presented as well.},
  keywords = {DDF, TALL, XSLT, automatic layouts, topological layouts}
}

@INPROCEEDINGS{Dijk-Wijknands:2007,
  author = {van Dijk, Ingmar and Wijnands, Ruud},
  title = {Test Driving the Wrong Car},
  crossref = {proceedings:xp:2007},
  pages = {250--252},
  doi = {10.1007/978-3-540-73101-6_47},
  abstract = {Test-Driven Development (TDD) is a practice that can be applied in almost all software development projects. It is a great tool to write working code and end up with clean designs. When writing code we make choices about the technologies we use and the underlying architecture. Sometimes the consequences of unfortunate choices do not show up for a while. TDD does not prevent us from making big mistakes. This paper is about such an unfortunate choice, the process of writing code based on this choice and the result. Finally, we discuss the lessons learned that can help us to avoid making big mistakes or to get a quick indication of such a mistake.},
  keywords = {Test-Driven Development; mistakes; non-functional tests; feedback},
  owner = {magsilva},
  timestamp = {2014.10.20}
}

@INCOLLECTION{Dijkstra:1982:447,
  author = {Edsger W. Dijkstra},
  title = {{EWD 447}: On the role of scientific thought},
  pages = {60--66},
  crossref = {Dijkstra:1982}
}

@INCOLLECTION{Dijkstra:2002,
  author = {Edsger W. Dijkstra},
  title = {{EWD 1308}: What let to "{Notes} on Structured Programming"},
  chapter = {10},
  pages = {341--346},
  crossref = {Broy-Denert:2002}
}

@ARTICLE{Dingsoyr-etal:2012,
  author = {Torgeir Dingsøyr and Sridhar Nerur and VenuGopal Balijepally and Nils Brede Moe},
  title = {A decade of agile methodologies: Towards explaining agile software development},
  crossref = {journal:springer:jss},
  volume = {85},
  number = {6},
  month = jun,
  year = {2012},
  pages = {1213 -- 1221},
  doi = {10.1016/j.jss.2012.02.033},
  abstract = {Ever since the agile manifesto was created in 2001, the research community has devoted a great deal of attention to agile software development. This article examines publications and citations to illustrate how the research on agile has progressed in the 10 years following the articulation of the manifesto. Specifically, we delineate the conceptual structure underlying agile scholarship by performing an analysis of authors who have made notable contributions to the field. Further, we summarize prior research and introduce contributions in this special issue on agile software development. We conclude by discussing directions for future research and urging agile researchers to embrace a theory-based approach in their scholarship.},
  keywords = {Agile software development; Theory; Software engineering; Information systems; eXtreme programming, XP; Scrum; Lean software development; Crystal method; Feature-driven development},
  issn = {0164-1212},
  journal = {Journal of Systems and Software}
}

@ARTICLE{DiRuscio-etal:2012,
  author = {Di Ruscio, Davide and Iovino, Ludovico and Pierantonio, Alfonso},
  title = {Coupled Evolution in Model-Driven Engineering},
  crossref = {journal:ieee:software},
  volume = {29},
  number = {6},
  month = nov # {--} # dec,
  year = {2012},
  pages = {78--84},
  doi = {10.1109/MS.2012.153},
  abstract = {Model-driven engineering bases a wide range of artifacts on metamodels. When such metamodels evolve, such as a new version of Unified Modeling Language or Business Process Execution Notation or a company-specific metamodel, underlying artifacts often become invalid. In this article, the authors provide an overview of coupled evolution methods and tools to handle such dependencies. I look forward to hearing from both readers and prospective authors about this column and the technologies you want to know more about.}
}

@INPROCEEDINGS{Distante-Shihong:2007,
  author = {Distante, D. and Shihong Huang},
  title = {Challenges and Lessons Learned in Teaching Software Engineering and Programming to Hearing-Impaired Students},
  crossref = {proceedings:cseet:2007},
  pages = {344 -354},
  doi = {10.1109/CSEET.2007.13},
  abstract = {Teaching academic courses to students with disabilities is a challenging task, particularly for academics who are presented with the teaching requirements and needs that this implies, for the first time. Courses in the field of engineering and computer science, by requiring a lot of handson practices and teamwork, further exacerbate the situation as how to provide an effective learning experience for these disabled students. This situation requires a higher-level commitment than normal, from both the teachers and students. This paper presents the experience gained from teaching courses that involved hearing-impaired students of an undergraduate software engineering and a programming language course in two different universities. Some of the challenges faced by both instructors and the students are identified and some possible solutions are described.},
  keywords = {software engineering education, programming languages, hearing-impaired students}
}

@ARTICLE{Distaso:1980,
  author = {Distaso, J. R.},
  title = {Software management -- A survey of the practice in 1980},
  crossref = {journal:ieee:proceedings},
  volume = {68},
  number = {9},
  month = sep,
  year = {1980},
  pages = {1103-1119},
  doi = {10.1109/PROC.1980.11810},
  abstract = {The primary thrust of this paper is to explore many of the problems currently plaguing software development activities and to propose how some of the recently developed management practices may be employed in dealing with them. The practices described range from people organizations (e.g., chief programmer teams) to fully automated engineering tools (e.g., software requirements engineering methodology). A number of techniques are presented. These include methods for coping with communications problems in the requirements definition activity, for evolving a facility which will help increase the productivity of software designers and proggammers, and for maintaining a high degree of visibility during the elusive unit design code and test phase of a project. A very practical view of the management problems and suggested approaches is presented. Key principles, potentials "pitfalls," and unresolved concerns are addressed from a viewpoint of where the state of the art is today and where the industry appears to be heading in the mid-1980's.},
  owner = {magsilva},
  timestamp = {2014.10.23}
}

@ARTICLE{Dittrich:2014,
  author = {Yvonne Dittrich},
  title = {Software engineering beyond the project -- Sustaining software ecosystems},
  crossref = {journal:elsevier:ist},
  volume = {56},
  number = {11},
  month = nov,
  year = {2014},
  pages = {1436--1456},
  doi = {10.1016/j.infsof.2014.02.012},
  abstract = {AbstractContext The main part of software engineering methods, tools and technologies has developed around projects as the central organisational form of software development. A project organisation depends on clear bounds regarding scope, participants, development effort and lead-time. What happens when these conditions are not given? The article claims that this is the case for software product specific ecosystems. As software is increasingly developed, adopted and deployed in the form of customisable and configurable products, software engineering as a discipline needs to take on the challenge to support software ecosystems. Objective The article provides a holistic understanding of the observed and reported practices as a starting point to device specific support for the development in software ecosystems. Method A qualitative interview study was designed based on previous long-term ethnographical inspired research. Results The analysis results in a set of common features of product development and evolution despite differences in size, kind of software and business models. Design is distributed and needs to be coordinated across heterogeneous design constituencies that, together with the software, build a product specific socio-technical ecosystem. The technical design has to support the deference of part of the development not only to 3rd-party developers but also to local designers tailoring the software in the use organisation. The technical interfaces that separate the work of different design constituencies are contested and need to be maintained permanently. Development takes place as cycles within cycles -- overlaying development cycles with different rhythms to accommodate different evolution drivers. Conclusion The reported practices challenge some of the very core assumptions of traditional software engineering, but makes perfect sense, considering that the frame of reference for product development is not a project but continuous innovation across the respective ecosystem. The article provides a number of concrete points for further research.},
  keywords = {Software ecosystems, Software product development, Qualitative empirical research },
  owner = {magsilva},
  timestamp = {2014.09.13}
}

@INPROCEEDINGS{Dohrn-Riehle:2013,
  author = {Hannes Dohrn and Dirk Riehle},
  title = {Design and Implementation of Wiki Content Transformations and Refactorings},
  crossref = {proceedings:wikisym-opensym:2013},
  abstract = {The organic growth of wikis requires constant attention by contributors who are willing to patrol the wiki and improve its content structure. However, most wikis still only offer textual editing and even wikis which offer WYSIWYG editing do not assist the user in restructuring the wiki. Therefore, ``gardening'' a wiki is a tedious and error-prone task. One of the main obstacles to assisted restructuring of wikis is the underlying content model which prohibits automatic transformations of the content. Most wikis use either a purely textual representation of content or rely on the representational HTML format. To allow rigorous definitions of transformations we use and extend a Wiki Object Model. With the Wiki Object Model installed we present a catalog of transformations and refactorings that helps users to easily and consistently evolve the content and structure of a wiki. Furthermore we propose XSLT as language for transformation specification and provide working examples of selected transformations to demonstrate that the Wiki Object Model and the transformation framework are well designed. We believe that our contribution significantly simplifies wiki ``gardening'' by introducing the means of effortless restructuring of articles and groups of articles. It furthermore provides an easily extensible foundation for wiki content transformations.},
  keywords = {Wiki, Wiki Markup, WM, Wiki Object Model, WOM, Transformation, Refactoring, XML, XSLT, Sweble},
  timestamp = {2013-08-09}
}

@ARTICLE{Dolado-etal:2014,
  author = {Dolado, JoséJavier and Otero, MariCarmen and Harman, Mark},
  title = {Equivalence hypothesis testing in experimental software engineering},
  crossref = {journal:springer:sqj},
  volume = {22},
  number = {2},
  month = jun,
  year = {2014},
  pages = {215--238},
  doi = {10.1007/s11219-013-9196-0},
  abstract = {This article introduces the application of equivalence hypothesis testing (EHT) into the Empirical Software Engineering field. Equivalence (also known as bioequivalence in pharmacological studies) is a statistical approach that answers the question 'is product T equivalent to some other reference product R within some range delta?.' The approach of 'null hypothesis significance test' used traditionally in Empirical Software Engineering seeks to assess evidence for differences between T and R, not equivalence. In this paper, we explain how EHT can be applied in Software Engineering, thereby extending it from its current application within pharmacological studies, to Empirical Software Engineering. We illustrate the application of EHT to Empirical Software Engineering, by re-examining the behavior of experts and novices when handling code with side effects compared to side-effect free code; a study previously investigated using traditional statistical testing. We also review two other previous published data of software engineering experiments: a dataset compared the comprehension of UML and OML specifications, and the last dataset studied the differences between the specification methods UML-B and B. The application of EHT allows us to extract additional conclusions to the previous results. EHT has an important application in Empirical Software Engineering, which motivate its wider adoption and use: EHT can be used to assess the statistical confidence with which we can claim that two software engineering methods, algorithms of techniques, are equivalent.},
  keywords = {Equivalence hypothesis testing; Bioequivalence analysis; Program comprehension; Side-effect free programs; Crossover design; Experimental software engineering}
}

@INPROCEEDINGS{Dolstra-etal:2008,
  author = {Dolstra, Eelco and Hage, Jurriaan and Heeren, Bastiaan and Holdermans, Stefan and Jeuring, Johan and Löh, Andres and Löh, Clara and Middelkoop, Arie and Rodriguez, Alexey and van Schie, John},
  title = {Report on the tenth {ICFP} programming contest},
  crossref = {proceedings:icfp:2008},
  pages = {397--408},
  doi = {10.1145/1411204.1411259},
  abstract = {The ICFP programming contest is a 72-hour contest, which attracts thousands of contestants from all over the world. In this report we describe what it takes to organise this contest, the main ideas behind the contest we organised, the task, how to solve it, how we created it, and how well the contestants did. This year's task was to reverse engineer the DNA of a stranded alien life form to enable it to survive on our planet. The alien's DNA had to be modified by means of a prefix that modified its meaning so that the alien's phenotype would approximate a given "ideal" outcome, increasing its probability of survival. About 357 teams from 39 countries solved at least part of the contest. The language of choice for discriminating hackers turned out to be C++.},
  keywords = {programming contest, reverse engineering}
}

@ARTICLE{Dominguez-etal:2012,
  author = {Eladio Domínguez and Beatriz Pérez and Ángel L. Rubio and María A. Zapata},
  title = {A systematic review of code generation proposals from state machine specifications},
  crossref = {journal:elsevier:ist},
  volume = {54},
  number = {10},
  month = oct,
  year = {2012},
  pages = {1045--1066},
  doi = {10.1016/j.infsof.2012.04.008},
  abstract = {Model Driven Development (MDD) encourages the use of models for developing complex software systems. Following a MDD approach, modelling languages are used to diagrammatically model the structure and behaviour of object-oriented software, among which state-based languages (including UML state machines, finite state machines and Harel statecharts) constitute the most widely used to specify the dynamic behaviour of a system. However, generating code from state machine models as part of the final system constitutes one of the most challenging tasks due to its dynamic nature and because many state machine concepts are not supported by the object-oriented programming languages. Therefore, it is not surprising that such code generation has received great attention over the years. The overall objective of this paper is to plot the landscape of published proposals in the field of object oriented code generation from state machine specifications, restricting the search neither to a specific context nor to a particular programming language. We perform a systematic, accurate literature review of published studies focusing on the object oriented implementation of state machine specifications. The systematic review is based on a comprehensive set of 53 resources in all, which we have classified into two groups: pattern-based and not pattern-based. For each proposal, we have analysed both the state machine specification elements they support and the means the authors propose for their implementation. Additionally, the review investigates which proposals take into account desirable features to be considered in software development such as maintenance or reusability. One of the conclusions drawn from the review is that most of the analysed works are based on a software design pattern. Another key finding is that many papers neither support several of the main components of the expressive richness of state machine specifications nor provide an implementation strategy that considers relevant qualitative aspects in software development.},
  keywords = {UML state machines; Finite state machines; Statecharts; Code generation; Systematic review}
}

@ARTICLE{DominguezJimenez-etal:2011,
  author = {J. J. Domínguez-Jiménez and A. Estero-Botaro and A. García-Domínguez and I. Medina-Bulo},
  title = {Evolutionary mutation testing},
  crossref = {journal:information-software-technology},
  volume = {53},
  number = {10},
  month = oct,
  year = {2011},
  pages = {1108 - 1123},
  doi = {10.1016/j.infsof.2011.03.008},
  abstract = {Mutation testing is a testing technique that has been applied successfully to several programming languages. However, it is often regarded as computationally expensive, so several refinements have been proposed to reduce its cost. Moreover, WS-BPEL compositions are being widely adopted by developers, but present new challenges for testing, since they can take much longer to run than traditional programs of the same size. Therefore, it is interesting to reduce the number of mutants required. We present Evolutionary Mutation Testing (EMT), a novel mutant reduction technique for finding mutants that help derive new test cases that improve the quality of the initial test suite. It uses evolutionary algorithms to reduce the number of mutants that are generated and executed with respect to the exhaustive execution of all possible mutants, keeping as many difficult to kill and potentially equivalent mutants (strong mutants) as possible in the reduced set. To evaluate EMT we have developed GAmera, a mutation testing system powered by a co-evolutive genetic algorithm. We have applied this system to three WS-BPEL compositions to estimate its effectiveness, comparing it with random selection. The results obtained experimentally show that EMT can select all strong mutants generating 15% less mutants than random selection in over 20% less time for complex compositions. When generating a percentage of all mutants, EMT finds on average more strong mutants than random selection. This has been confirmed to be statistically significant within a 99.9% confidence interval. EMT has reduced for the three tested compositions the number of mutants required to select those which are useful to derive new test cases that improve the quality of the test suite. The directed search performed by EMT makes it more effective than random selection, especially as compositions become more complex and the search space widens.},
  keywords = {Mutation testing, Evolutionary algorithm, Genetic algorithm, Web Service, WS-BPEL},
  lang = {en}
}

@ARTICLE{Douce-etal:2005,
  author = {Douce, Christopher and Livingstone, David and Orwell, James},
  title = {Automatic test-based assessment of programming: A review},
  crossref = {journal:acm:jeric},
  volume = {5},
  number = {3},
  month = sep,
  year = {2005},
  pages = {1--13},
  doi = {10.1145/1163405.1163409},
  abstract = {Systems that automatically assess student programming assignments have been designed and used for over forty years. Systems that objectively test and mark student programming work were developed simultaneously with programming assessment in the computer science curriculum. This article reviews a number of influential automatic assessment systems, including descriptions of the earliest systems, and presents some of the most recent developments. The final sections explore a number of directions automated assessment systems may take, presenting current developments alongside a number of important emerging e-learning specifications.},
  keywords = {Education, computer-based training, learning, programming assessment}
}

@ARTICLE{Doukakis-etal:2013,
  author = {Spyros Doukakis and Michail N. Giannakos and Christos Koilias and Panayiotis Vlamos},
  title = {Measuring Students' Acceptance and Confidence on Algorithms and Programming: The Impact of the Engagement with {CS} on Secondary Education},
  crossref = {journal:imi:ie},
  volume = {12},
  number = {2},
  year = {2013},
  pages = {207--219},
  abstract = {This paper presents results of a questionnaire focused on investigating students' confidence and behavioral intention in the area of programming, particularly that of structures, problem solving, and programming commands (Conditional - Loop). Responses from 116 1st year students regarding informatics were used. The results indicate that the engagement with programming logic yields a positive impact on students' confidence and acceptance. In addition, all the measured factors are related relatively strongly. Our findings demonstrate that students' prior direction (at Lyceum) has a significant impact on their Confidence for using Programming Commands (CPC) and Confidence for using Data Structures (CDS); however, prior direction does not have any impact on learners Problem Solving Confidence (PSC) and Behavioral Intention (BI) for programming. In the conclusion, several issues regarding the courses of programming are discussed.},
  keywords = {adoption, algorithms, curriculum, data structures, Greece, programming, problem solving},
  timestamp = {2014-01-02}
}

@ARTICLE{Dromey:1995,
  author = {R. G. Dromey},
  title = {A Model for Software Product Quality},
  crossref = {journal:ieee:tse},
  volume = {21},
  number = {2},
  month = feb,
  year = {1995},
  pages = {146--162},
  doi = {10.1109/32.345830},
  abstract = {A model for software product quality is defined, it has been formulated by associating a set of quality-carrying properties with each of the structural forms that are used to define the statements and statement components of a programming language. These quality-carrying properties are in turn linked to the high-level quality attributes of the International Standard for Software Product Evaluation ISO-9126. The model supports building quality into software, definition of language-specific coding standards, systematically classifying quality defects, and the development of automated code auditors for detecting defects in software.},
  keywords = {software quality, product evaluation, ISO-9126, code auditing, quality defect classification, quality model, quality attributes, software characteristics, maintainability, quality-carrying properties},
  owner = {magsilva},
  timestamp = {2006.09.12}
}

@INPROCEEDINGS{Duim-etal:2007,
  author = {Duim, Louwarnoud van der and Andersson, Jesper and Sinnema, Marco},
  title = {Good Practices for Educational Software Engineering Projects},
  crossref = {proceedings:icse:2007},
  pages = {698--707},
  doi = {10.1109/ICSE.2007.40},
  abstract = {Recent publications indicate the importance of software engineering in the computer science curriculum. In this paper, we present the final part of software engineering education at University of Groningen in the Netherlands and Växjö University in Sweden, where student teams perform an industrial software development project. It furthermore presents the main educational problems encountered in such real-life projects and explains how this international course addresses these problems. The main contribution of this paper is a set of seven good practices for project based software engineering education.}
}

@INCOLLECTION{Duitama-etal:2007,
  author = {John Freddy Duitama and Bruno Defude and Claire Lecocq and Amel Bouzeghoub},
  title = {An Educational Component Model for Learning Objects},
  chapter = {9},
  pages = {239-285},
  crossref = {Harman-Koohang:2007}
}

@INCOLLECTION{Dunning-etal:2007,
  author = {Jeremy Dunning and Sunand Bhattacharya and Abtar Kaur and Mansor Fadzil and Ansary Ahmed and Repin Ibrahim},
  title = {The Role of Learning Object Architecture in the Instructional Design of Successful Online Courses},
  chapter = {5},
  pages = {137-155},
  crossref = {Harman-Koohang:2007}
}

@INPROCEEDINGS{Duque-Bravo:2007,
  author = {Duque, Rafael and Bravo, Crescencio},
  title = {A Method to Classify Collaboration in {CSCL} Systems},
  crossref = {proceedings:icannga:2007},
  pages = {649--656},
  doi = {10.1007/978-3-540-71618-1_72},
  abstract = {One of the most important challenges of collaborative learning systems is to offer mechanisms to facilitate the study of the relationships between the collaboration process and the characteristics of the solution (product) built by the learners in this work process. In this article, a machine learning algorithm that generates a set of rules to classify the different forms of collaboration within a group of learners with respect to the quality of the solution built is presented. The algorithm, based on a fuzzy model, is put into practice using data registered in a collaborative learning environment.}
}

@ARTICLE{Durelli-etal:2013,
  author = {Vinicius Humberto Serapilha Durelli and Rodrigo Fraxino Araujo and Marco Aurelio Graciotto Silva and Rafael Alves Paes de Oliveira and Jose Carlos Maldonado and Marcio Eduardo Delamaro},
  title = {A scoping study on the 25 years of research into software testing in {Brazil} and an outlook on the future of the area},
  crossref = {journal:elsevier:jss},
  volume = {86},
  number = {4},
  month = apr,
  year = {2013},
  pages = {934--950},
  doi = {10.1016/j.jss.2012.10.012},
  abstract = {Over the past 25 years the Brazilian Symposium on Software Engineering (SBES) has evolved to become the most important event on software engineering in Brazil. Throughout these years, SBES has gathered a large body of studies in software testing. Aimed at providing an insightful understanding of what has already been published in such event, we have synthesized its 25-year history of research on software testing. Using information drawn from this overview we highlighted which software testing topics have been the most extensively surveyed in SBES literature. We have also devised a co-authorship network to depict the most prolific research groups and researchers. Moreover, by performing a citation analysis of the selected studies we have tried to ascertain the importance of SBES in a wider scenario. Finally, using the information extracted from the studies, we have shed light on the state-of-the-art of software testing in Brazil and provided an outlook on its foreseeable future.},
  keywords = {Software testing, Systematic mapping, Brazilian research}
}

@INPROCEEDINGS{Durelli-etal:2012,
  author = {Durelli, Vinicius H. S. and Endo, Andre T. and Simao, Adenilso and Delamaro, Marcio E.},
  title = {Towards Envisaging Software Testing in a Pervasive Computing World},
  crossref = {proceedings:sbes:2012},
  pages = {201--205},
  doi = {10.1109/SBES.2012.21},
  abstract = {Pervasive computing has been increasingly finding its way into mainstream. Such paradigm has been fostering the development of systems that transparently interact with users, push context awareness further, and are able to deal with aspects of the user's day-to-day experience. Pervasive systems have been constantly and invisibly introduced in our everyday lives, moving us towards a pervasive computing world. Therefore, in this paper we argue that there is a need to prepare for the challenges that such paradigm will bring about. As dependability is a key feature in pervasive environments, we highlight some of these challenges in the light of software testing, which will play an important role on a plausible pervasive computing world. We address this topic by (i) illustrating challenges for testing pervasive software in an example scenario, (ii) describing our outlook on how the tool support for testing pervasive systems will interact with testers and practitioners alike, and (iii) outlining what research thrusts we need to emphasize in order to prepare for this change.}
}

@INPROCEEDINGS{duval-hodgins:2003,
  author = {Erik Duval and Wayne Hodgins},
  title = {A LOM Research Agenda},
  crossref = {proceedings:www:2003},
  pages = {1-10},
  abstract = {This paper presents a research agenda on Learning Objects. The main intent is to elaborate on what the authors consider important issues for research on learning objects and their use in education and training. The paper focuses somewhat on metadata related issues, but does not restrict itself to only those aspects that have a direct relationship with metadata.},
  keywords = {metadata, learning, training, education, knowledge management, eLearning, library and information science, information management, content management, adaptive hypermedia, learning technology standardization},
  year = {2003}
}

@INPROCEEDINGS{Dvornik-etal:2011,
  author = {Dvornik, Thomas and Janzen, David S. and Clements, John and Dekhtyar, Olga},
  title = {Supporting introductory test-driven labs with {WebIDE}},
  crossref = {proceedings:cseet:2011},
  pages = {51--60},
  doi = {10.1109/CSEET.2011.5876137},
  abstract = {WebIDE is a new web-based development environment for entry-level programmers with two primary goals: minimize tool barriers to writing computer programs and introduce software engineering best practices early in a student's educational career. Currently, WebIDE focuses on Test-Driven Learning (TDL) by using small iterative examples and introducing lock-step labs, which prevent the student from moving forward until they finish the current step. However, WebIDE does not require that labs follow TDL. Instructors can write their own labs for WebIDE using any software engineering or pedagogical approach. Likewise, instructors can build custom evaluators--written in any language--to support their approach and provide detailed error messages to students. We report on a pilot study in a CS0 course where students were split into two groups, one that used WebIDE and one that didn't. The WebIDE group showed a significant improvement in performance when writing a simple Android application. Additionally, among students with some programming experience, the WebIDE group was more proficient in writing unit tests.}
}

@ARTICLE{Dyba-Dingsoyr:2008,
  author = {Dyb{\aa}, Tore and Dings{\o}yr, Torgeir},
  title = {Empirical studies of agile software development: A systematic review},
  crossref = {journal:elsevier:ist},
  volume = {50},
  number = {9-10},
  month = aug,
  year = {2008},
  pages = {833--859},
  doi = {10.1016/j.infsof.2008.01.006},
  abstract = {Agile software development represents a major departure from traditional, plan-based approaches to software engineering. A systematic review of empirical studies of agile software development up to and including 2005 was conducted. The search strategy identified 1996 studies, of which 36 were identified as empirical studies. The studies were grouped into four themes: introduction and adoption, human and social factors, perceptions on agile methods, and comparative studies. The review investigates what is currently known about the benefits and limitations of, and the strength of evidence for, agile methods. Implications for research and practice are presented. The main implication for research is a need for more and better empirical studies of agile software development within a common research agenda. For the industrial readership, the review provides a map of findings, according to topic, that can be compared for relevance to their own settings and situations.},
  keywords = {Agile software development, Empirical software engineering, Evidence-based software engineering, Extreme programming, Research synthesis, Scrum, Systematic review, XP},
  lang = {en}
}

@ARTICLE{Dyba:2013,
  author = {Dyba, T.},
  title = {Contextualizing Empirical Evidence},
  crossref = {journal:ieee:software},
  volume = {30},
  number = {1},
  month = jan # {--} # feb,
  year = {2013},
  pages = {81 -83},
  doi = {10.1109/MS.2013.4},
  abstract = {What works for whom, where, when, and why is the ultimate question of evidence-based software engineering. Still, the empirical research seems mostly concerned with identifying universal relationships that are independent of how work settings and other contexts interact with the processes important to software practice. Questions of #x201C;What is best? #x201D; seem to prevail. For example, #x201C;Which is better: pair or solo programming? test-first or test-last? #x201D; However, just as the question of whether a helicopter is better than a bicycle is meaningless, so are these questions because the answers depend on the settings and goals of the projects studied. Practice settings are rarely, if ever, the same. For example, the environments of software organizations differ, as do their sizes, customer types, countries or geography, and history. All these factors influence engineering practices in unique ways. Additionally, the human factors underlying the organizational culture differ from one organization to the next and also influence the way software is developed. We know these issues and the ways they interrelate are important for the successful uptake of research into practice. However, the nature of these relationships is poorly understood. Consequently, we can't a priori assume that the results of a particular study apply outside the specific context in which it was run. Here, I offer an overview of how context affects empirical research and how to better contextualize empirical evidence so that others can better understand what works for whom, where, when, and why.},
  keywords = {empirical software engineering , software engineering}
}

@ARTICLE{Dyba-etal:2006,
  author = {Tore Dybå and Vigdis By Kampenes and Dag I.K. Sjøberg},
  title = {A systematic review of statistical power in software engineering experiments},
  crossref = {journal:elsevier:ist},
  volume = {48},
  number = {8},
  month = aug,
  year = {2006},
  pages = {745--755},
  doi = {10.1016/j.infsof.2005.08.009},
  abstract = {Statistical power is an inherent part of empirical studies that employ significance testing and is essential for the planning of studies, for the interpretation of study results, and for the validity of study conclusions. This paper reports a quantitative assessment of the statistical power of empirical software engineering research based on the 103 papers on controlled experiments (of a total of 5,453 papers) published in nine major software engineering journals and three conference proceedings in the decade 1993-2002. The results show that the statistical power of software engineering experiments falls substantially below accepted norms as well as the levels found in the related discipline of information systems research. Given this study's findings, additional attention must be directed to the adequacy of sample sizes and research designs to ensure acceptable levels of statistical power. Furthermore, the current reporting of significance tests should be enhanced by also reporting effect sizes and confidence intervals.},
  keywords = {Empirical software engineering},
  lang = {en}
}

@ARTICLE{Dyer:2010,
  author = {Dyer, Jason},
  title = {Mathematics for the masses},
  crossref = {journal:acm:xrds},
  volume = {17},
  number = {2},
  month = dec,
  year = {2010},
  pages = {32--33},
  doi = {10.1145/1869086.1869097},
  abstract = {Can human computation bring together people from diverse backgrounds to solve age-old math problems?}
}

@INPROCEEDINGS{Eagle-Barnes:2008,
  author = {Eagle, Michael and Barnes, Tiffany},
  title = {Wu's castle: teaching arrays and loops in a game},
  crossref = {proceedings:itcse:2008},
  pages = {245--249},
  doi = {10.1145/1384271.1384337},
  abstract = {We are developing games to teach introductory computer science concepts to increase student motivation and engagement in learning to program. Wu's Castle is a two-dimensional role playing game that teaches loops and arrays in an interactive, visual way. In this game, the player interactively programs magical creatures to create armies of snowmen. The game provides immediate feedback and helps students visualize the execution of their code in a safe environment. We tested the game in a CS1 course, where students could earn extra credit to play Wu's Castle. Our results show learning gains for game players, compared both through pre- and post-tests differences and improved performance on relevant final exam questions when compared to students who did not play the game. The results of this study suggest that Wu's Castle implements good practices for teaching programming within a game.},
  keywords = {CS1 education, Game2Learn, arrays, games, iteration}
}

@ARTICLE{Easterbrook-Nuseibeh:1996,
  author = {Steve Easterbrook and Bashar Nuseibeh},
  title = {Using ViewPoints for Inconsistency Management},
  crossref = {journal:ieee:sej},
  volume = {11},
  number = {1},
  month = jan,
  year = {1996},
  pages = {31--43},
  abstract = {Large-scale software development is an evolutionary process. In an evolving specification, multiple development participants often hold multiple inconsistent views on the system being developed, and considerable effort is spent handling recurrent inconsistencies. Detecting and resolving inconsistencies is only part of the problem; a resolved inconsistency might not stay resolved as a specification evolves. Frameworks in which inconsistency is tolerated help by allowing resolution to be delayed. However, the evolution of a specification may affect both resolved and unresolved inconsistencies. A framework is presented and elaborated in which software development knowledge is partitioned into multiple views called ViewPoints. Inconsistencies between ViewPoints are managed by explicitly representing relationships between them, and recording both resolved and unresolved inconsistencies. It is assumed that ViewPoints will often be inconsistent, and so a complete work record is kept, detailing any inconsistencies that have been detected and what actions, if any, have been taken to resolve them. The work record is then used to reason about the effects of subsequent changes to ViewPoints, without constraining the development process. The paper demonstrates how inconsistency management is used as a tool for requirements elicitation and how ViewPoints provide a vehicle for achieving this. Inconsistency is used as a stimulus for eliciting missing information and capturing user-defined relationships that arise between elements of an evolving specification},
  timestamp = {2008.07.30}
}

@ARTICLE{Ebert-Brinkkemper:2014,
  author = {Christof Ebert and Sjaak Brinkkemper},
  title = {Software product management -- An industry evaluation},
  crossref = {journal:elsevier:2014},
  volume = {95},
  month = sep,
  year = {2014},
  pages = {10--18},
  doi = {10.1016/j.jss.2013.12.042},
  abstract = {Abstract Product management is a key success factor for software products as it spans the entire life-cycle and thus ensures both a technical and business perspective. With its many interfaces to various business processes and stakeholders across the life-cycle, it is a primary driver for requirements engineering in its focus on value-orientation and consistency across releases. This article provides an overview on product management in software and IT. It summarizes experiences with introducing, improving and deploying the role of a product manager. In order to get a profound industry overview we performed a field study with interviews and concrete insight across fifteen different organizations world-wide on the role of the product manager and its success factors. As a technical solution we present four success factors identified from the research and show how they address the challenges we identified in practice. The novel part of this research and technical study is the industry survey and evaluation of resulting solution proposals. We found that with increasing institutionalization of a consistent and empowered product management role, the success rate of projects in terms of schedule predictability, quality and project duration improves.},
  keywords = {Product management, Software business, Industry survey },
  owner = {magsilva},
  timestamp = {2014.09.13}
}

@INCOLLECTION{Edwards-etal:2007,
  author = {Dianne Edwards and Shri Rai and Rob Phillips and Lance C. C. Fung},
  title = {A Framework for Interoperable Learning Objects for E-Learning},
  chapter = {14},
  pages = {437-469},
  crossref = {Koohang-Harman:2007}
}

@INPROCEEDINGS{Edwards:2004,
  author = {Stephen H. Edwards},
  title = {Using Software Testing to Move Students from Trial-and-Error to Reflection-in-Action},
  crossref = {proceedings:sigcse:2004},
  pages = {26--30},
  doi = {10.1145/971300.971312},
  abstract = {Introductory computer science students rely on a trial and error approach to fixing errors and debugging for too long. Moving to a reflection in action strategy can help students become more successful. Traditional programming assignments are usually assessed in a way that ignores the skills needed for reflection in action, but software testing promotes the hypothesis-forming and experimental validation that are central to this mode of learning. By changing the way assignments are assessed--where students are responsible for demonstrating correctness through testing, and then assessed on how well they achieve this goal--it is possible to reinforce desired skills. Automated feedback can also play a valuable role in encouraging students while also showing them where they can improve.},
  keywords = {CS1, automated grading, extreme programming, pedagogy, test-driven development}
}

@INPROCEEDINGS{Edwards:2013,
  author = {Edwards, S. H.},
  title = {Adding software testing to programming assignments},
  crossref = {proceedings:cseet:2013},
  pages = {371--373},
  doi = {10.1109/CSEET.2013.6595283},
  abstract = {This tutorial provides a practical introduction to how one can incorporate software testing activities as a regular part of programming assignments, supported by live demonstrations, with a special focus on early introduction in CS1 and/or CS2 courses. It presents five different models for how one can incorporate testing into assignments, provides examples of each technique, and discusses the corresponding advantages and disadvantages. The focus is on unit testing, test-driven development, and incremental testing, all of which work well in a classroom environment. Examples will use Java, although participant discussion regarding support in other languages such as Python and C++ is welcome. Approaches to assessment- using testing to assess student code, assessing tests that students write, and automated grading-are all discussed. A live demonstration of automatic assignment grading based on student-written tests is included. Advice for writing testable assignments is given. Participant discussions are encouraged.},
  owner = {magsilva},
  timestamp = {2014.09.12},
  url = {http://web-cat.org/cseet2013/}
}

@INPROCEEDINGS{Edwards:2014:WPG:2556325.2567888,
  author = {Edwards, Stephen H.},
  title = {Work-in-progress: Program Grading and Feedback Generation with {Web-CAT}},
  crossref = {proceedings:las:2014},
  pages = {215--216},
  doi = {10.1145/2556325.2567888},
  abstract = {Web-CAT, the Web-based Center for Automated Testing, is the most widely used open-source automated grading system for programming assignments in the world. Web-CAT is customizable and extensible, allowing it to support a wide variety of programming languages and assessment strategies. Web-CAT is most well known as the system that "grades students on how well they test their own code," with experimental evidence that it offers greater learning benefits than more traditional output-comparison grading. This work-in-progress demonstration will show how Web-CAT can be used to automatically grade student work, assess conformance with coding style guidelines, provide students with feedback on how well they have tested their own code, and allow instructors to provide directed hints to students on where to focus their attention for improvements.},
  keywords = {automated grading, automated marking, programming assignments, software testing, static analysis, test-driven development},
  owner = {magsilva},
  timestamp = {2014.05.18}
}

@INPROCEEDINGS{Edwards:EISTA:2003,
  author = {Stephen H. Edwards},
  title = {Using test-driven development in the classroom: Providing students with concrete feedback on performance},
  crossref = {proceedings:eista:2003},
  pages = {421--426},
  abstract = {There is a need for better ways to teach software testing skills to computer science undergraduates, who are routinely underprepared in this area. This paper proposes the use of test-driven development in the classroom, requiring students to test their own code in programming assignments. In addition, an automated grading approach is used to assess student-written code and student-written tests together. Students receive clear, immediate feedback on the effectiveness and validity of their testing. This approach has been piloted in an undergraduate computer science class. Results indicate that students scored higher on their program assignments while producing code with 45% fewer defects per thousand lines of code.},
  keywords = {Computer Science, software testing, test-first coding, programming assignments, automated grading}
}

@INPROCEEDINGS{Edwards:OOPLSA:2003,
  author = {Edwards, Stephen H.},
  title = {Rethinking computer science education from a test-first perspective},
  crossref = {proceedings:oopsla:2003},
  pages = {148--155},
  doi = {10.1145/949344.949390},
  abstract = {Despite our best efforts and intentions as educators, student programmers continue to struggle in acquiring comprehension and analysis skills. Students believe that once a program runs on sample data, it is correct; most programming errors are reported by the compiler; when a program misbehaves, shuffling statements and tweaking expressions to see what happens is the best debugging approach. This paper presents a new vision for computer science education centered around the use of test-driven development in all programming assignments, from the beginning of CS1. A key element to the strategy is comprehensive, automated evaluation of student work, in terms of correctness, the thoroughness and validity of the student's tests, and an automatic coding style assessment performed using industrial-strength tools. By systematically applying the strategy across the curriculum as part of a student's regular programming activities, and by providing rapid, concrete, useful feedback that students find valuable, it is possible to induce a cultural shift in how students behave.},
  keywords = {CS1, extreme programming, laboratory-based teaching, pedagogy, test-driven development}
}

@ARTICLE{Edwards:JERIC:2003,
  author = {Edwards, Stephen H.},
  title = {Improving student performance by evaluating how well students test their own programs},
  crossref = {journal:acm:jeric},
  volume = {3},
  number = {3},
  month = sep,
  year = {2003},
  pages = {1:1--1:24},
  doi = {10.1145/1029994.1029995},
  abstract = {Students need to learn more software testing skills. This paper presents an approach to teaching software testing in a way that will encourage students to practice testing skills in many classes and give them concrete feedback on their testing performance, without requiring a new course, any new faculty resources, or a significant number of lecture hours in each course where testing will be practiced. The strategy is to give students basic exposure to test-driven development, and then provide an automated tool that will assess student submissions on-demand and provide feedback for improvement. This approach has been demonstrated in an undergraduate programming languages course using a prototype tool. The results have been positive, with students expressing appreciation for the practical benefits of test-driven development on programming assignments. Experimental analysis of student programs shows a 28% reduction in defects per thousand lines of code.},
  keywords = {agile methods, extreme programming, teaching software testing, test-driven development, test-first coding}
}

@ARTICLE{Edwards-etal:2008,
  author = {Edwards, Stephen H. and Börstler, Jürgen and Cassel, Lillian N. and Hall, Mark S. and Hollingsworth, Joseph},
  title = {Developing a common format for sharing programming assignments},
  crossref = {journal:acm:inroads},
  volume = {40},
  number = {4},
  month = nov,
  year = {2008},
  pages = {167--182},
  doi = {10.1145/1473195.1473240},
  abstract = {Computer science educators spend a lot of effort designing programming assignments, and many are willing to share the results of this investment. However, sharing of programming assignments occurs primarily in an ad hoc manner through informal channels. There are no widely used mechanisms that support instructors in finding and sharing such resources. Often, the additional work required to prepare and self-publish assignment resources in a way that others can then adapt or reuse is a significant inhibitor. Also, other instructors may have to spend an inordinate amount of time and effort to reshape a potential assignment into something that can be used in their own courses. This working group report proposes a common format for packaging assignments for sharing. This format is easy for instructors to create (requiring no specialized tools), is extensible and flexible enough to handle assignments written for any programming language at any level of proficiency, supports appropriate metadata, and is easily manipulated by software tools. As more and more instructors use automated grading tools to process student submissions, it is our hope that such an interchange format can lead to a community practice of sharing resources in a way that overcomes existing barriers to such reuse.},
  keywords = {automated grading, interchange, programming assignment, reuse}
}

@INPROCEEDINGS{Edwards-Shams:2014,
  author = {Edwards, Stephen H. and Shams, Zalia},
  title = {Do Student Programmers All Tend to Write the Same Software Tests?},
  crossref = {proceedings:itcse:2014},
  pages = {171--176},
  doi = {10.1145/2591708.2591757},
  abstract = {While many educators have added software testing practices to their programming assignments, assessing the effectiveness of student-written tests using statement coverage or branch coverage has limitations. While researchers have begun investigating alternative approaches to assessing student-written tests, this paper reports on an investigation of the quality of student written tests in terms of the number of authentic, human-written defects those tests can detect. An experiment was conducted using 101 programs written for a CS2 data structures assignment where students implemented a queue two ways, using both an array-based and a link-based representation. Students were required to write their own software tests and graded in part on the branch coverage they achieved. Using techniques from prior work, we were able to approximate the number of bugs present in the collection of student solutions, and identify which of these were detected by each student-written test suite. The results indicate that, while students achieved an average branch coverage of 95.4% on their own solutions, their test suites were only able to detect an average of 13.6% of the faults present in the entire program population. Further, there was a high degree of similarity among 90% of the student test suites. Analysis of the suites suggest that students were following naïve, "happy path" testing, writing basic test cases covering mainstream expected behavior rather than writing tests designed to detect hidden bugs. These results suggest that educators should strive to reinforce test design techniques intended to find bugs, rather than simply confirming that features work as expected.},
  keywords = {automated assessment, automated grading, happy path, mutation testing, program assignments, software testing, test coverage, test quality},
  owner = {magsilva},
  timestamp = {2014.08.31}
}

@INPROCEEDINGS{Stephen-Shams:2014,
  author = {Edwards, Stephen H. and Shams, Zalia},
  title = {Comparing Test Quality Measures for Assessing Student-written Tests},
  crossref = {proceedings:icse:seet:2014},
  pages = {354--363},
  doi = {10.1145/2591062.2591164},
  abstract = {Many educators now include software testing activities in programming assignments, so there is a growing demand for appropriate methods of assessing the quality of student-written software tests. While tests can be hand-graded, some educators also use objective performance metrics to assess software tests. The most common measures used at present are code coverage measures -- tracking how much of the student's code (in terms of statements, branches, or some combination) is exercised by the corresponding software tests. Code coverage has limitations, however, and sometimes it overestimates the true quality of the tests. Some researchers have suggested that mutation analysis may provide a better indication of test quality, while some educators have experimented with simply running every student's test suite against every other student's program -- an all-pairs strategy that gives a bit more insight into the quality of the tests. However, it is still unknown which one of these measures is more accurate, in terms of most closely predicting the true bug revealing capability of a given test suite. This paper directly compares all three methods of measuring test quality in terms of how well they predict the observed bug revealing capabilities of student-written tests when run against a naturally occurring collection of student-produced defects. Experimental results show that all-pairs testing -- running each student's tests against every other student's solution -- is the most effective predictor of the underlying bug revealing capability of a test suite. Further, no strong correlation was found between bug revealing capability and either code coverage or mutation analysis scores.},
  keywords = {Software testing, automated assessment, automated grading, mutation testing, programming assignments, test coverage, test metrics, test quality},
  owner = {magsilva},
  timestamp = {2014.08.31}
}

@INPROCEEDINGS{Edwards-etal:2012,
  author = {Edwards, Stephen H. and Shams, Zalia and Cogswell, Michael and Senkbeil, Robert C.},
  title = {Running students' software tests against each others' code: new life for an old ``gimmick''},
  crossref = {proceedings:sigcse:2012},
  pages = {221--226},
  doi = {10.1145/2157136.2157202},
  abstract = {At SIGCSE 2002, Michael Goldwasser suggested a strategy for adding software testing practices to programming courses by requiring students to turn in tests along with their solutions, and then running every student's tests against every other student's program. This approach provides a much more robust environment for assessing the quality of student-written tests, and also provides more thorough testing of student solutions. Although software testing is included as a regular part of many more programming courses today, the all-pairs model of executing tests is still a rarity. This is because student-written tests, such as JUnit tests written for Java programs, are now more commonly written in the form of program code themselves, and they may depend on virtually any aspect of their author's own solution. These dependencies may keep one student's tests from even compiling against another student's program. This paper discusses the problem and presents a novel solution for Java that uses bytecode rewriting to transform a student's tests into a form that uses reflection to run against any other solution, regardless of any compile-time dependencies that may have been present in the original tests. Results of applying this technique to two assignments, encompassing 147 student programs and 240,158 individual test case runs, shows the feasibility of the approach and provides some insight into the quality of both student tests and student programs. An analysis of these results is presented.},
  keywords = {automated assessment, bytecode transformation, programming assignments, reflection, software testing, test coverage, test-driven development}
}

@INPROCEEDINGS{Edwards-etal:2014,
  author = {Edwards, Stephen H. and Shams, Zalia and Estep, Craig},
  title = {Adaptively Identifying Non-terminating Code when Testing Student Programs},
  crossref = {proceedings:sigcse:2014},
  pages = {15--20},
  doi = {10.1145/2538862.2538926},
  abstract = {Infinite looping problems that keep student programs from termi-nating may occur in many kinds of programming assignments. While non-terminating code is easier to diagnose interactively, it poses different concerns when software tests are being run auto-matically in batch. The common strategy of using a timeout to preemptively kill test runs that execute for too long has limita-tions, however. When one test case gets stuck in an infinite loop, forcible termination prevents any later test cases from running. Worse, when test results are buffered inside a test execution framework, forcible termination may prevent any information from being produced. Further, overly generous timeouts can de-lay the availability of results, and when tests are executed on a shared server, one non-terminating program can delay results for many people. This paper describes an alternative strategy that uses a fine-grained timeout on the execution of each individual test case in a test suite, and that adaptively adjusts this timeout dynamically based on the termination behavior of test cases completed so far. By avoiding forcible termination of test runs, this approach allows all test cases an opportunity to run and produce results, even when infinite looping behaviors occur. Such fine-grained timeouts also result in faster completion of entire test runs when non-terminating code is present. Experimental results from applying this strategy to 4,214 student-written programs are dis-cussed, along with experiences from live deployment in the class-room where 8,926 non-termination events were detected over the course of one academic year.},
  keywords = {automated assessment, automated grading, infinite loop, junit, programming assignments, software testing, timeout}
}

@ARTICLE{Egan:2010,
  author = {Egan, Mary Anne L.},
  title = {Recruitment of {CS} majors through a non-programmer's programming contest},
  crossref = {journal:ccsc:jcsc},
  volume = {25},
  number = {6},
  month = jun,
  year = {2010},
  pages = {198--204},
  abstract = {Declining enrollments in computer science are a cause of great concern. There has been a 30% decline in enrollments in computer science bachelor programs over this decade and more than a 50% decline in the enrollment of women in computer science. This paper describes a unique way of attracting excellent students to the major by inviting students and their teachers to a day of exploration and competition hosted by our college. The program has demonstrated an increased awareness of computer science among the students and faculty who attend the day-long event. By including teachers and guidance counselors in the day's events, we hope to give them a better understanding of computer science curricula and careers to bring back to their high schools.}
}

@INPROCEEDINGS{Ehrig-etal:1997,
  author = {Ehrig, Hartmut and Geisler, Robert and Klar, Marcus and Padberg, Julia},
  title = {Horizontal and Vertical Structuring Techniques for Statecharts},
  crossref = {proceedings:icct:1997},
  pages = {181--195},
  abstract = {In this paper we present an algebraic approach to statecharts as they are used in the Statemate tool in the style of "Petri-Nets are Monoids" for place-transition nets developed by Meseguer and Montanari. We apply the framework of high-level-replacement systems, a categorical generalization of graph transformation systems, in order to define union as horizontal as well as transformation and refinement as vertical structuring techniques for statecharts. The first main result shows compatibility of union and transformation in a suitable category of statecharts. We present an algorithm for the computation of all transitions enabled within one step. The second main result shows the correctness of this algorithm. We define refinement morphisms for statecharts, which allow refinement of arbitrary states, in contrast to concepts in the literature where only basic and root states are subject of refinement. The third main result shows that refinement morphisms are compatible with the behavior of statecharts as defined in the formal semantics.}
}

@INPROCEEDINGS{Elbaum-etal:2007,
  author = {Elbaum, Sebastian and Person, Suzette and Dokulil, Jon and Jorde, Matt},
  title = {Bug Hunt: Making Early Software Testing Lessons Engaging and Affordable},
  crossref = {proceedings:icse:2007},
  pages = {688--697},
  doi = {10.1109/ICSE.2007.23},
  abstract = {Software testing efforts account for a large part of software development costs. However, as educators, we struggle to properly prepare students to perform software testing activities. This struggle is caused by multiple factors: 1) it is challenging to effectively incorporate software testing into an already over-packed curriculum, 2) ad-hoc efforts to teach testing generally happen too late in the students' career, after bad habits have already been developed, and 3) these efforts lack the necessary institutional consistency and support to be effective. To address these challenges we created Bug Hunt, a web-based tutorial to engage students in learning software testing strategies. In this paper we describe the most interesting aspects of the tutorial including the lessons and feedback mechanisms, and the facilities for instructors to configure the tutorial and obtain automatic student assessment. We also present the lessons learned after two years of deployment.},
  keywords = {Software Testing Education, Web-based Tutorial}
}

@ARTICLE{Elberzhager-etal:2012,
  author = {Frank Elberzhager and Alla Rosbach and Jürgen Münch and Robert Eschbach},
  title = {Reducing test effort: A systematic mapping study on existing approaches},
  crossref = {journal:elsevier:ist},
  volume = {54},
  number = {10},
  month = oct,
  year = {2012},
  pages = {1092--1106},
  doi = {10.1016/j.infsof.2012.04.007},
  abstract = {Quality assurance effort, especially testing effort, is often a major cost factor during software development, which sometimes consumes more than 50% of the overall development effort. Consequently, one major goal is often to reduce testing effort. The main goal of the systematic mapping study is the identification of existing approaches that are able to reduce testing effort. Therefore, an overview should be presented both for researchers and practitioners in order to identify, on the one hand, future research directions and, on the other hand, potential for improvements in practical environments. Two researchers performed a systematic mapping study, focusing on four databases with an initial result set of 4020 articles. In total, we selected and categorized 144 articles. Five different areas were identified that exploit different ways to reduce testing effort: approaches that predict defect-prone parts or defect content, automation, test input reduction approaches, quality assurance techniques applied before testing, and test strategy approaches. The results reflect an increased interest in this topic in recent years. A lot of different approaches have been developed, refined, and evaluated in different environments. The highest attention was found with respect to automation and prediction approaches. In addition, some input reduction approaches were found. However, in terms of combining early quality assurance activities with testing to reduce test effort, only a small number of approaches were found. Due to the continuous challenge of reducing test effort, future research in this area is expected.},
  keywords = {Efficiency improvement; Mapping study; Quality assurance; Software testing; Test effort reduction},
  journal = {Information and Software Technology}
}

@INPROCEEDINGS{Eler-etal:2009,
  author = {Eler, M.M. and Endo, A.T. and Masiero, P.C. and Delamaro, M.E. and Maldonado, J.C. and Vincenzi, A.M.R. and Chaim, M.L. and Beder, D.M.},
  title = {JaBUTiService: A Web Service for Structural Testing of Java Programs},
  crossref = {proceedings:sew:2009},
  pages = {69--76},
  doi = {10.1109/SEW.2009.10},
  abstract = {Web services are an emerging Service-Oriented Architecture technology to integrate applications using open standards based on XML. Software Engineering tools integration is a promising area since companies adopt different software processes and need different tools on each activity. Software engineers could take advantage of software engineering tools available as web services and create their own workflow for integrating the required tools. In this paper, we propose the development of testing tools designed as web services and discuss the pros and cons of this idea. We developed a web service for structural testing of Java programs called JaBUTiService, which is based on the stand-alone tool JaBUTi. We also present an usage example of this service with the support of a desktop front-end and pre prepared scripts. A set of 62 classes of the library Apache-Commons-BeanUtils was used for this test and the results are discussed.},
  booktitle = {33rd Annual IEEE Software Engineering Workshop},
  issn = {1550-6215},
  location = {Skövde, #Sweden#},
  month = oct,
  year = {2009}
}

@INPROCEEDINGS{Eler-etal:2011,
  author = {Eler, Marcelo Medeiros and Bertolino, Antonia and Masiero, Paulo Cesar},
  title = {More testable service compositions by test metadata},
  crossref = {proceedings:sose:2011},
  pages = {204--213},
  doi = {10.1109/SOSE.2011.6139109},
  abstract = {In previous work we proposed testable services as a solution to provide third-party testers with structural coverage information after a test session, yet without revealing their internal details. However, service testers, e.g., integrators that use testable services into their compositions, do not have enough information to improve their test set when they get a low coverage measure because they do not know which test requirements have not been covered. This paper proposes an approach in which testable services are provided along with test metadata that will help their testers to get a higher coverage. We show the approach on a case study of a real system that uses orchestrations and testable services.}
}

@INPROCEEDINGS{Eler-etal:2010,
  author = {Eler, Marcelo Medeiros and Delamaro, Marcio Eduardo and Maldonado, Jose Carlos and Masiero, Paulo Cesar},
  title = {Built-In Structural Testing of Web Services},
  crossref = {proceedings:sbes:2010},
  pages = {70--79},
  doi = {10.1109/SBES.2010.15},
  abstract = {Testing Service Oriented Architecture applications is a challenging task due to the high dynamism, the low coupling and the low testability of services. Web services, a popular implementation of services, are usually provided as black box and using testing techniques based on implementation is limited. This paper presents an approach to support the use of the structural testing technique on web service testing. The approach improves web service testability by developing web services with built-in structural testing capabilities. Testers can run test cases against such web services and obtain a coverage analysis on structural testing criteria. A set of metadata provided with the testable web service helps testers to evaluate the coverage reached and the quality of their test cases. An implementation of the approach is presented using a service called JaBUTiWS that performs instrumentation and coverage analysis of Java web services. We also present a usage scenario of the approach.}
}

@ARTICLE{Ellis-etal:1991,
  author = {C. A. Ellis and S. J. Gibbs and G. L. Rein},
  title = {Groupware: Some Issues and Experiences},
  crossref = {journal:acm:cacm},
  volume = {34},
  number = {1},
  month = jan,
  year = {1991},
  pages = {38--58},
  doi = {10.1145/99977.99987},
  abstract = {Groupware reflects a change in emphasis from using the computer to solve problemas to using the computer to facilitate human interaction. This article describes categories and examples of groupware and discusses some underlying research and development issues. GROVE, a novel group editor, is explained in some detail as a salient groupware example.},
  tags = {collaborative systems, groupware, groupware taxonomy},
  timestamp = {2008.07.30}
}

@INPROCEEDINGS{Ellis-etal:SIGCSE:2011,
  author = {Ellis, Heidi J.C. and Chua, Mel and Jadud, Matthew C. and Hislop, Gregory W.},
  title = {Learning through open source participation},
  crossref = {proceedings:sigcse:2011},
  pages = {83--84},
  doi = {10.1145/1953163.1953191},
  abstract = {Free and Open Source Software (FOSS) and documentation projects provide excellent learning opportunities for students. In the context of active learning, FOSS is particularly interesting in providing transparent meritocracies that allow students to observe and contribute as part of their learning. This panel will present four different perspectives on student involvement in Free and Open Source Software (FOSS) projects. These perspectives will cover: (a) different ways that students can contribute to FOSS projects beyond coding, (b) an industry perspective on student involvement in FOSS projects, (c) how Humanitarian FOSS can provide a welcoming environment for student learning, and (d) barriers to faculty involvement and how such barriers can be overcome.},
  keywords = {education, faculty development, open source software}
}

@INPROCEEDINGS{Ellis-etal:FIE:2011,
  author = {Ellis, H. J. C. and Hislop, G. W. and Chua, M. and Dziallas, S.},
  title = {How to involve students in {FOSS} projects},
  crossref = {proceedings:fie:2011},
  pages = {T1H-1--T1H-6},
  doi = {10.1109/FIE.2011.6142994},
  abstract = {Software projects are frequently used to provide software engineering students with an understanding of the complexities of real-world software development. Free and Open Source Software projects provide a unique opportunity for student learning as projects are open and accessible and students are able to interact with an established professional community. However, many faculty members have little or no experience participating in an open source software project. In addition, faculty members may be reluctant to approach student learning within such a project due to concerns over time requirements, learning curve, the unpredictability of working with a "live" community, and more. This paper provides guidance to instructors desiring to involve students in open source projects.},
  keywords = {Free and open source software, Teaching open source, Software development, Humanitarian software}
}

@INPROCEEDINGS{Ellis-etal:2012,
  author = {Ellis, Heidi J. C. and Purcell, Michelle and Hislop, Gregory W.},
  title = {An approach for evaluating {FOSS} projects for student participation},
  crossref = {proceedings:sigcse:2012},
  pages = {415--420},
  doi = {10.1145/2157136.2157260},
  abstract = {Free and Open Source Software (FOSS) offers a transparent development environment and community in which to involve students. Students can learn much about software development and professionalism by contributing to an on-going project. However, the number of FOSS projects is very large and there is a wide range of size, complexity, domains, and communities, making selection of an ideal project for students difficult. This paper addresses the need for guidance when selecting a FOSS project for student involvement by presenting an approach for FOSS project selection based on clearly identified criteria. The approach is based on several years of experience involving students in FOSS projects.},
  keywords = {computing education, free and open source software, student projects}
}

@INPROCEEDINGS{Elvesaeter-etal:2013,
  author = {Elves{\ae}ter, Brian and Benguria, Gorka and Ilieva, Sylvia},
  title = {A Comparison of the {Essence} 1.0 and {SPEM} 2.0 Specifications for Software Engineering Methods},
  crossref = {proceedings:pmde:2013},
  pages = {2:1--2:10},
  doi = {10.1145/2489833.2489835},
  abstract = {In this paper we present a comparison of the draft Essence 1.0 and SPEM 2.0 specifications for software engineering methods. The comparison is based on results from the REMICS research project where we are defining an agile methodology for model-driven modernization of legacy applications to service clouds.},
  keywords = {Essence, SPEM, method, method engineering, practice, software engineering},
  owner = {magsilva},
  timestamp = {2014.02.23}
}

@ARTICLE{Endo-Simao:2013,
  author = {Andre Takeshi Endo and Adenilso da Silva Simao},
  title = {Evaluating Test Suite Characteristics, Cost, and Effectiveness of FSM-based Testing Methods},
  crossref = {journal:elsevier:ist},
  year = {2013},
  doi = {10.1016/j.infsof.2013.01.001},
  abstract = {Testing from finite state machines has been investigated due to its well-founded and sound theory as well as its practical application. There has been a recurrent interest in developing methods capable of generating test suites that detect all faults in a given fault domain. However, the proposal of new methods motivates the comparison with traditional methods. We compare the methods that generate complete test suites from finite states machines. The test suites produced by the W, HSI, H, SPY, and P methods are analyzed in different configurations. Complete and partial machines were randomly generated varying numbers of states, inputs, outputs, and transitions. These different configurations were used to compare test suite characteristics (number of resets, test case length) and the test suite length (i.e., the sum of the length of its test cases). The fault detection ratio was evaluated using mutation testing to produce faulty implementations with an extra state. On average, the recent methods (H, SPY, and P) produced longer test cases but smaller test suites than the traditional methods (W, HSI). The recent methods generated test suites of similar length, though P produced slightly smaller test suites. The SPY and P methods had the highest fault detection ratios and HSI had the lowest. For all methods, there was a positive correlation between the number of resets and the test suite length and between the test case length and the fault detection ratio. The recent methods rely on fewer and longer test cases to reduce the overall test suite length, while the traditional methods produce more and shorter test cases. Longer test cases are correlated to fault detection ratio which favored SPY, though all methods have a ratio of over 92%.},
  keywords = {Model based testing, Test automation, Experiments, Test case generation method, Mutation testing, Conformance testing}
}

@INPROCEEDINGS{6142931,
  author = {Enstrom, E. and Kreitz, G. and Niemela, F. and Soderman, P. and Kann, V.},
  title = {Five years with {Kattis} -- Using an automated assessment system in teaching},
  crossref = {proceedings:fie:2011},
  pages = {T3J-1-T3J-6},
  doi = {10.1109/FIE.2011.6142931},
  abstract = {Automated assessment systems have been employed in computer science (CS) courses at a number of different universities. Such systems are especially applicable in teaching algorithmic problem solving since they can automatically test if an algorithm has been correctly implemented, i.e., that it performs its specified function on a set of inputs. Being able to implement algorithms that work correctly is a crucial skill for CS students in their professional role, but it can be difficult to convey the importance of this in a classroom situation. Programming and problem solving education supported by automated grading has been used since 2002 at our department. We study, using action research methodology, different strategies for deploying automated assessment systems in CS courses. Towards this end, we have developed an automated assessment system and both introduced it into existing courses and constructed new courses structured around it. Our primary data sources for evaluation consists of course evaluations, statistics on students' submitted solutions, and experience teaching the courses. Authors of this paper have been participating in teaching all of the courses mentioned here.},
  keywords = {computer science education;educational administrative data processing;educational courses;teaching;CS courses;action research methodology;automated assessment system;automated grading;computer science courses;course evaluations;course experience teaching;problem solving education;programming education;student submitted solution statistics;teaching algorithmic problem solving;Conferences;Education;Electronic mail;Problem-solving;Programming profession;Testing;Algorithms;Automated assessment;Computer Science Education;Programming},
  timestamp = {2013-08-23}
}

@ARTICLE{Erdogmus:2009,
  author = {Hakan Erdogmus},
  title = {Cloud Computing: Does Nirvana Hide behind the Nebula?},
  crossref = {journa:ieee:software},
  volume = {26},
  number = {2},
  month = mar # {--} # apr,
  year = {2009},
  pages = {4-6},
  doi = {10.1109/MS.2009.31},
  abstract = {At the core of cloud computing is a simple concept: software as a service, or SaaS. Whether the underlying software is an application, application component, platform, framework, environment, or some other soft infrastructure for composing applications to be delivered as a service on the Web, it's all software in the end. But the simplicity ends there. Just a step away from that core, a complex concoction of paradigms, concepts, and technologies envelop cloud computing.}
}

@INPROCEEDINGS{Erdogmus-etal:2002,
  author = {Erdogmus, Hakan and Boehm, Barry W. and Harrison, Warren and Reifer, Don J. and Sullivan, Kevin J.},
  title = {Software Engineering Economics: Background, Current Practices, and Future Directions},
  crossref = {proceedings:icse:2002},
  pages = {683--684},
  doi = {10.1145/581339.581444},
  abstract = {The field of software economics seeks to develop technical theories, guidelines, and practices of software development based on sound, established, and emerging models of value and value-creation---adapted to the domain of software development as necessary. The premise of the field is that software development is an ongoing investment activity---in which developers and managers continually make investment decisions requiring the expenditure of valuable resources, such as time, talent, and money. The overriding aim of this activity is to maximize the value added subject to an equitable distribution among the participating stakeholders. The goal of the tutorial is to expose the audience to this line of thinking and introduce the tools pertinent to its pursuit. The tutorial is designed to be self-contained and will cover concepts from introductory to advanced. Both practitioners and researchers with an interest in the impact of value considerations in software decision-making will benefit from attending it.This tutorial is offered in conjunction with the Fourth International Workshop on Economics-Driven Software Engineering Research (EDSER-4). The tutorial is meant in part to enable those who would like to participate in the workshop, but who might not possess the requisite background, to come up to speed.},
  owner = {magsilva},
  timestamp = {2014.09.11}
}

@ARTICLE{Wong-etal:2010,
  author = {Eric Wong, W. and Debroy, Vidroha and Choi, Byoungju},
  title = {A family of code coverage-based heuristics for effective fault localization},
  crossref = {journal:elsevier:jss},
  volume = {83},
  number = {2},
  month = feb,
  year = {2010},
  pages = {188--208},
  doi = {10.1016/j.jss.2009.09.037},
  abstract = {Locating faults in a program can be very time-consuming and arduous, and therefore, there is an increased demand for automated techniques that can assist in the fault localization process. In this paper a code coverage-based method with a family of heuristics is proposed in order to prioritize suspicious code according to its likelihood of containing program bugs. Highly suspicious code (i.e., code that is more likely to contain a bug) should be examined before code that is relatively less suspicious; and in this manner programmers can identify and repair faulty code more efficiently and effectively. We also address two important issues: first, how can each additional failed test case aid in locating program faults; and second, how can each additional successful test case help in locating program faults. We propose that with respect to a piece of code, the contribution of the first failed test case that executes it in computing its likelihood of containing a bug is larger than or equal to that of the second failed test case that executes it, which in turn is larger than or equal to that of the third failed test case that executes it, and so on. This principle is also applied to the contribution provided by successful test cases that execute the piece of code. A tool, @gDebug, was implemented to automate the computation of the suspiciousness of the code and the subsequent prioritization of suspicious code for locating program faults. To validate our method case studies were performed on six sets of programs: Siemens suite, Unix suite, space, grep, gzip, and make. Data collected from the studies are supportive of the above claim and also suggest Heuristics III(a), (b) and (c) of our method can effectively reduce the effort spent on fault localization.},
  keywords = {Code coverage, Failed tests, Fault localization, Heuristics, Program debugging, Successful tests, Suspiciousness of code},
  timestamp = {2013-09-14}
}

@INPROCEEDINGS{Eronen:2003,
  author = {Leena Eronen},
  title = {User Centered Research for Interactive Television},
  crossref = {proceedings:euroitv:2003},
  pages = {5--12},
  abstract = {This paper presents results from a qualitative user study. The aim of research was to include the future users of a new technology in the product design of interactive television programs. During the study, the study participants were interviewed. They were asked to answer questions about their television use and to comment on artist's drawings presenting the possible future setup and equipment at home. The study resulted in users' stories and innovations of interactive applications for the future.},
  keywords = {User centered research, interactive television, users' stories}
}

@INPROCEEDINGS{Eshuis-Wieringa:2000,
  author = {Eshuis, Rik and Wieringa, Roel},
  title = {Requirements-level semantics for UML statecharts},
  crossref = {proceedings:fmoods:2000},
  pages = {121--140},
  keywords = {UML, formal semantics, statecharts}
}

@INPROCEEDINGS{Espiritu-etal:2006,
  author = {Cleo Espiritu and Eleni Stroulia and Tapanee Tirapad},
  title = {{ENWiC}: Visualizing Wiki Semantics as Topic Maps},
  crossref = {proceedings:iceis:2006},
  pages = {35--42},
  abstract = {In this paper, we present ENWiC (EduNuggets Wiki Crawler), a framework for intelligent visualization of Wikis. In recent years, e-learning has emerged as an appealing alternative to traditional teaching. The effectiveness of e-Learning is depended upon the sharing of information on the web, which makes the web a vast library of information that students and instructors can utilize for educational purposes. Wiki's collaborative authoring nature makes it a very attractive tool to use for e-Learning purposes; however, its text-based navigational structure becomes insufficient as the Wiki grows in size, and this backlash can hinder students from taking full advantage of the information available. ENWiC's goal is to provide student with an intelligent interface for navigating Wikis and other similar large-scale websites. ENWiC make use of graphic organizers to visualize the relationships between content pages so that students can gain a cognitional understanding of the content as they navigating through the Wiki pages. We describe ENWiC's automated visualization process, and its user interfaces for students to view and navigate the Wiki in a meaningful manner, and for instructors to further enhance the visualization. We also discuss our usability study for evaluating ENWiC's effectiveness as a Wiki Interface.},
  keywords = {Novel E-learning interfaces and interactions, Web-based education software, Intelligent information and knowledge management systems, Intelligent visualization tools}
}

@ARTICLE{Evangelist-Pellegrin:1986,
  author = {Evangelist, M and Pellegrin, J},
  title = {Foundational problems in software process research},
  crossref = {journal:acm:sen},
  volume = {11},
  number = {4},
  month = aug,
  year = {1986},
  pages = {12--13},
  doi = {10.1145/12944.12947}
}

@INPROCEEDINGS{Evey:1963,
  author = {Evey, R. James},
  title = {Application of Pushdown-store Machines},
  crossref = {proceedings:afips:1963},
  pages = {215--227},
  doi = {10.1145/1463822.1463848},
  abstract = {Scientific knowledge has always been advanced through the combined efforts of those who experiment and those who theorize. This is as true of the field in which the effective processing of languages by computers is considered as any other.},
  owner = {magsilva},
  timestamp = {2014.07.15}
}

@ARTICLE{Fabbri-etal:2013,
  author = {Sandra Camargo Pinto Ferraz Fabbri and Katia Romero Felizardo and Fabiano Cutigi Ferrari and Elis Cristina Montoro Hernandes and Fábio Roberto Octaviano and Elisa Yumi Nakagawa and José Carlos Maldonado},
  title = {Externalising tacit knowledge of the systematic review process},
  crossref = {journal:iet:software},
  volume = {7},
  number = {6},
  month = dec,
  year = {2013},
  pages = {298--307},
  doi = {10.1049/iet-sen.2013.0029},
  abstract = {Systematic Reviews (SRs) have recently intensified in Software Engineering. However, there is a lack of work that makes explicit how the process to perform SR is in practice. The goal of this paper is externalising the process that reflects how SRs are currently performed, transforming tacit knowledge into explicit knowledge. We describe the phases and activities that compose the process and the relationship among them, and explore the iterative characteristic of this process, focusing on intra- and inter-phase iterations that are necessary to conduct the process appropriately. To achieve the proposed goal, we devised the process based on practical experience acquired for several years by research groups in Software Engineering, which include graduate students and researchers who have applied SR. The process has been applied in several SRs and seems to be effective in keeping the focus of the review at all phases. Moreover, the externalisation of the process has been useful to help researchers improving the process execution quality. As the process reflects the practice and is explained in details, it can be used as a guide to better understand the SR process and its details. This shall contribute to improve all SR process phases, and hence the quality of SR results.}
}

@INPROCEEDINGS{Fabbri-etal:1994:WQS,
  author = {S. C. P. F. Fabbri and J. C. Maldonado and P. C. Masiero and M. E. Delamaro},
  title = {Aplicação da análise de mutantes na validação de especificações baseadas em {Redes de Petri}},
  crossref = {proceedings:wqs:1994},
  pages = {423--437},
  abstract = {A atividade de Teste é uma das atividades fundamentais do ciclo de desenvolvimento de software. Para Sistemas Reativos, as atividades de validação de seu aspecto comportamental é ainda mais relevante, uma vez que falha nesses sistemas, em geral, provocam grandes perdas econômicas e sociais. O objetivo deste artigo é explorar a aplicação do critério de teste Análise de Mutantes para validar especificações baseadas em Redes de Petri. Apresentam-se o projeto dos operadores de mutação para Redes de Petri, ponto chave para aplicação do critério Análise de Mutantes, e os resultados obtidos da aplicação manual desse critério em uma especificação de um protocolo. A viabilidade de automatização da aplicação do critério Análise de Mutantes para Redes de Petri é brevemente discutida, com base na ferramenta Proteum/FSM, especificada para apoiar o uso desse critério na validação de especificações baseadas em MEF.},
  keywords = {Redes de Petri; análise de mutantes; teste; validação},
  abstract-en = {Testing is one of the fundamental software development life cycle activities. Considering Reactive Systems, this activity becomes more relevant as errors in these systems can promote severe economical and social losses. The objective of this work is to evaluate the adequacy of applying the Mutant Analysis criterion to validate Petri Net based specifications. A set of mutation operators for Petri Nets, a key point for using Mutation Analysis, as well as the results of applying manually these operators for Petri Nets modeling a level 3 protocol are presented. Taking as reference the software tool Proteum/FSM, that has been developed to support Mutation Analysis use for validating Finite State Machine based specifications, it is briefly discussed that implementing a tool to support the validation of a Petri Net based specification constitutes a feasible task.}
}

@INPROCEEDINGS{Fabbri-etal:1995:FORTE,
  author = {Sandra Camargo Pinto Ferraz Fabbri and José Carlos Maldonado and Paulo Cesar Masiero and Márcio Eduardo Delamaro and W. Eric Wong},
  title = {Mutation Testing Applied to Validate Specifications Based on Petri Nets},
  crossref = {proceedings:forte:1995},
  pages = {329--337},
  abstract = {Testing is one of the fundamental software developmnet life cycle activities. Considering Reactive Systems such as:metro control, patient hospital monitoring and communication protocols, the testing activity becomes more relevant as errors in these systems can promote severe economical and social losses. The objective of this work is to evaluate the adequacy of applying the Mutation Analysis criterion to validate Petri Net based specifications. A set of mutation operators for Petri Nets, a key point for using Mutation Analysis, as well as the results of applying manually these operators to a Petri net modeling a level 3 protocol are presented. We also examine the ideas of constrained and randomly selected mutation in this context.},
  keywords = {Petri nets; mutation analysis, test and validation}
}

@ARTICLE{Fabbri-Maldonado:1996,
  author = {SandraC. Pinto Ferraz Fabbri and José Carlos Maldonado},
  title = {{Proteum/FSM}: Uma Ferramenta de Teste Baseada na Análise de Mutantes para apoiar a Validação de Especificações em Máquinas de Estado Finito},
  crossref = {journal:unicep:multiciencia},
  volume = {1},
  number = {1},
  month = nov,
  year = {1996},
  pages = {66--77},
  abstract = {Máquinas de Estados Finitos é uma técnica bastante utilizada na especificação do aspecto comportamental de Sistemas Reativos, os quais, muitas vezes, controlam atividades que envolvem grandes riscos à vida humana e/ou grandes perdas ao patrimônio, exigindo um maior rigor na atividade de desenvolvimento e de validação dos mesmos. O apoio automatizado à atividade de teste em geral é de fundamental importância para aumentar a qualidade e produtividade no desenvolvimento de software e, conseqüentemente, aumentar a confiabilidade no produto liberado. O objetivo deste artigo é apresentar uma ferramenta de teste, denominada Proteum/FSM, que apóia a aplicação do critério de teste Análise de Mutantes na atividade de teste e validação do aspecto comportamental de Sistemas Reativos, especificado pela técnica Máquina de Estados Finitos.},
  keywords = {análise de mutantes; máquinas de estados finitos; sistemas reativos; teste e validação; ferramentas de teste},
  abstract-en = {Finite State Machine is one of the most used technique for the specification of the behavioral aspectives of Reactive Systems, which control activities that usually envolve risks to the human being as well as economical losses, therefore, requiring rigor and systematic in the development and validation activities. The availability of software tools to support the testing activity is fundamental to increase quality and productiviy in software development, contributing in this way to achieve higher reliability software products. A software testing tool, named Proteum/FSM, that supports the use of Mutation Analysis Criterion to test and validate the behavioral aspects of Reactive Systems specified by Finite State Machines is presented.},
  keywords-en = {mutation analysis criterion; finite state machines; reactive systems},
  title-en = {Proteum/FSM: a mutation analysis testing tool to support the validation of finite state machine based specifications}
}

@INPROCEEDINGS{Fabri-etal:2010,
  author = {Fabri, J. A. and L'Erario, A. and Begosso, L. R. C. and Begosso, L. R. and de Lima, F. C.},
  title = {Implementation of Software Residency at a graduation course},
  crossref = {proceedings:fie:2010},
  pages = {F1H-1-F1H-6},
  doi = {10.1109/FIE.2010.5673498},
  abstract = {This paper presents the implementation of Software Residency at a graduation course focused in Software Development and Management in a Software Factory. Software Residency follows the same line of medical residency, at a medicine course. In this case, software residency has the objective to promote experience for students, inside a software development real environment, with well defined quality policies and with the goal to promote the dissemination of software quality, project management and production process concepts. In this course, the student actively participates on a software development project at a standard software factory (located in the university) or at some company previously selected by the university. We will present the qualitative and quantitative results of the experience we had conducting the graduation course focused in Software Development and Management in a Software Factory. The course was taken in 2008 and 2009 at a Brazilian public university. The objective of the course was to provide complementary knowledge to the students in the areas of Information Technology, Software Engineering and Project Management, focusing on software residency inside a software factory environment.},
  keywords = {Graduation Course; Professional Maturity; Software Engineering; Software Residency}
}

@ARTICLE{Falessi-etal:2014,
  author = {Falessi, Davide and Shaw, Michele and Mullen, Kathleen},
  title = {Achieving and Maintaining CMMI Maturity Level 5 in a Small Organization},
  crossref = {journal:ieee:software},
  volume = {31},
  number = {5},
  month = sep,
  year = {2014},
  pages = {80--86},
  doi = {10.1109/MS.2014.17},
  abstract = {CMMI (Capability Maturity Model Integration) models are collections of best practices that help organizations improve their processes. This article reports on the authors' experience in achieving and maintaining CMMI Maturity Level 5 in a small organization. Economic achievements, success factors, and lessons learned are reported by using real-life examples from almost 10 years of improvement process. This article could be a valuable and unique reference for practitioners intending to pursue high-maturity CMMI level, particularly in small organization settings. The importance of this topic and lack of similar experience reports make it a valuable contribution to the state of the practice. The first Web extra at http://youtu.be/HMbgNSFxkpE is an audio recording in which IEEE Software Multimedia Editor Davide Falessi speaks with Shane Oleson and Shannon Taylor of Keymind about how the organization achieved and maintained CMMI Maturity Level 5. The second Web extra at http://youtu.be/RKpKBo7roZI is an audio recording in which author Kathy Mullen introduces a custom Web-based tool called the Keymind Measurement Reporting Tool.},
  owner = {magsilva},
  timestamp = {2014.09.25}
}

@INPROCEEDINGS{Falkner-etal:2014,
  author = {Falkner, Nickolas and Vivian, Rebecca and Piper, David and Falkner, Katrina},
  title = {Increasing the Effectiveness of Automated Assessment by Increasing Marking Granularity and Feedback Units},
  crossref = {proceedings:sigcse:2014},
  pages = {9--14},
  doi = {10.1145/2538862.2538896},
  abstract = {Computer-based assessment is a useful tool for handling large-scale classes and is extensively used in the automated assessment of student programming assignments in Computer Science. The forms that this assessment takes, however, can vary widely from simple acknowledgement to a detailed analysis of output, structure and code. This study focusses on output analysis of submitted student assignment code and the degree to which changes in automated feedback influence student marks and persistence in submission. Data was collected over a four year period, over 22 courses but we focus on one course for this paper. Assignments were grouped by the number of different units of automated feedback that were delivered per assignment to investigate if students changed their submission behaviour or performance as the possible set of marks, that a student could achieve, changed. We discovered that pre-deadline results improved as the number of feedback units increase and that post-deadline activity was also improved as more feedback units were available.},
  keywords = {automated assessment, feedback, student performance}
}

@ARTICLE{Fan-Bifet:2013,
  author = {Fan, Wei and Bifet, Albert},
  title = {Mining big data: current status, and forecast to the future},
  crossref = {journal:acm:sigkdd},
  volume = {14},
  number = {2},
  month = apr,
  year = {2013},
  pages = {1--5},
  doi = {10.1145/2481244.2481246},
  abstract = {Big Data is a new term used to identify datasets that we can not manage with current methodologies or data mining software tools due to their large size and complexity. Big Data mining is the capability of extracting useful information from these large datasets or streams of data. New mining techniques are necessary due to the volume, variability, and velocity, of such data. The Big Data challenge is becoming one of the most exciting opportunities for the years to come. We present in this issue, a broad overview of the topic, its current status, controversy, and a forecast to the future. We introduce four articles, written by influential scientists in the field, covering the most interesting and state-of-the-art topics on Big Data mining.}
}

@INPROCEEDINGS{Fanciulli:2008,
  author = {Fanciulli, Marco},
  title = {Principles of entertainment in inhabited television},
  crossref = {proceedings:avi:2008},
  pages = {5--12},
  doi = {10.1145/1385569.1385573},
  abstract = {Inhabited TV paradigms have been around since a while and several experimental implementations have been delivered around the world. The basic model of these experiments involves the deployment of collaborative virtual environments so that users can take part in TV shows from within these virtual, shared environments. Unfortunately, this approach although cheap and easily implemen-table, doesn't add up too much to engagement, pace gap between real/virtual world, camera control techniques and most important, adequate TV Formats. The talk presents a new paradigm of basic principles for entertaining a virtually deployed audience allowing for itneraction and maintaining the entertainment sensation.},
  keywords = {inhabited TV, social design, virtual life},
  series = {AVI '08},
  acmid = {1385573},
  address = {New York, NY, USA},
  booktitle = {Working Conference on Advanced Visual Interfaces},
  isbn = {978-1-60558-141-5},
  location = {Napoli, Italy},
  numpages = {8},
  publisher = {ACM},
  year = {2008}
}

@INCOLLECTION{Farrel-Carr:2007,
  author = {Katy Farrel and Allie Emigh Carr},
  title = {A Blended Model of Instructional Design for Learning Objects},
  chapter = {12},
  pages = {359-405},
  crossref = {Koohang-Harman:2007}
}

@ARTICLE{Souza-etal:2011:MEEM,
  author = {Maria de Fátima Costa de Souza and Jose Aires Castro-Filho and Rossana Maria de Castro Andrade},
  title = {Applying Model-Driven Development for Building Customizable Learning Objects},
  crossref = {journal:ieee:meem},
  volume = {6},
  number = {1},
  month = mar,
  year = {2011},
  pages = {22-30},
  abstract = {Learning Objects (LO) are digital resources developed to help teachers present concepts to students. However, the way these resources are produced does not allow them to be easily adaptable to different contexts. Thus, this work proposes the use of a model-driven development strategy for building customizable LO and improving communication between the whole team. We also present an authoring tool to be used in the design phase as a way to ease the development of the LO. With our proposal, teachers will be able to make adjustments to LO and thus achieve more autonomy in the use of these resources.},
  url = {http://www.ewh.ieee.org/soc/e/sac/meem/index.php/meem/article/view/135/156},
  owner = {magsilva}
}

@ARTICLE{Fayyad-etal:1996,
  author = {Usama Fayyad and Gregory Piatetsky-shapiro and Padhraic Smyth},
  title = {From Data Mining to Knowledge Discovery in Databases},
  crossref = {journal:aaai:ai},
  volume = {17},
  number = {3},
  month = sep # {--} # nov,
  year = {1996},
  pages = {37--54},
  abstract = {Data mining and knowledge discovery in databases have been attracting a significant amount of research, industry, and media attention of late. What is all the excitement about? This article provides an overview of this emerging field, clarifying how data mining and knowledge discovery in databases are related both to each other and to related fields, such as machine learning, statistics, and databases. The article mentions particular real-world applications, specific data-mining techniques, challenges involved in real-world applications of knowledge discovery, and current and future research directions in the field.}
}

@INPROCEEDINGS{Feitelson-etal:2006,
  author = {Feitelson, D. G. and Heller, G. Z. and Schach, S. R.},
  title = {An empirically-based criterion for determining the success of an open-source project},
  crossref = {proceedings:aswec:2006},
  pages = {1--6},
  doi = {10.1109/ASWEC.2006.12},
  abstract = {In order to determine a success criterion for open-source software projects, we analyzed 122,205 projects in the SourceForge database. There were 80,597 projects with no downloads at all. We restricted our analysis to the 41,608 projects that together were downloaded 704,897,520 times. Contrary to what we had expected, the distribution of the number of downloads of each project is not Zipf-like; only a portion of the log-log plot of the number of downloads and their rank appears to be a straight line. We performed least-squares analysis (utilizing the Bayesian information criterion) to divide the plot into three segments. On the basis of the shapes of the corresponding curves and the locations of their boundary points, we categorized the projects as follows: 85 superprojects (highly successful projects with more than 1.1 million downloads); just over 10,000 successful projects (with more than 1680 downloads each); and struggling projects (with 1680 downloads or fewer). In terms of our criterion, only a quarter of the projects that have one or more downloads can be deemed to be successful.},
  owner = {magsilva},
  timestamp = {2014.05.29}
}

@INPROCEEDINGS{Felizardo-etal:2009,
  author = {Katia R. Felizardo and Gabriel F. Andery and José Carlos Maldonado and Rosane Minghim},
  title = {Uma Abordagem Visual para Auxiliar a Revisão da Seleção de Estudos Primários na Revisão Sistemática},
  crossref = {proceedings:eselaw:2009},
  pages = {83--92},
  abstract = {This paper presents an approach that uses Visual Text Mining (VTM) techniques and associated tool to support the reliability of inclusion and exclusion decisions in the conduction stage of a systematic review. The approach has been applied to real systematic reviews and the results showed that the use of visualization is an additional component and it can assist the reviewer to decide that relevant studies were not deleted.},
  abstract-native = {Este artigo apresenta uma abordagem que faz uso de técnicas de Mineração Visual de Texto (Visual Text Mining - VTM) e ferramenta associada para apoiar a revisão da seleção de estudos primários na etapa de Execução da revisão sistemática. A abordagem foi aplicada em revisões sistemáticas reais e os resultados mostraram que o uso da visualização é um componente adicional e pode auxiliar o revisor na decisão de garantir que estudos relevantes não foram eliminados.}
}

@ARTICLE{Felizardo-etal:2012:IST,
  author = {Katia R. Felizardo and Gabriel F. Andery and Fernando V. Paulovich and Rosane Minghim and José C. Maldonado},
  title = {A visual analysis approach to validate the selection review of primary studies in systematic reviews},
  crossref = {journal:elsevier:ist},
  volume = {54},
  number = {10},
  month = oct,
  year = {2012},
  pages = {1079--1091},
  doi = {10.1016/j.infsof.2012.04.003},
  abstract = {Systematic Literature Reviews (SLRs) are an important component to identify and aggregate research evidence from different empirical studies. Despite its relevance, most of the process is conducted manually, implying additional effort when the Selection Review task is performed and leading to reading all studies under analysis more than once. We propose an approach based on Visual Text Mining (VTM) techniques to assist the Selection Review task in SLR. It is implemented into a VTM tool (Revis), which is freely available for use. We have selected and implemented appropriate visualization techniques into our approach and validated and demonstrated its usefulness in performing real SLRs. The results have shown that employment of VTM techniques can successfully assist in the Selection Review task, speeding up the entire SLR process in comparison to the conventional approach. VTM techniques are valuable tools to be used in the context of selecting studies in the SLR process, prone to speed up some stages of SLRs.},
  keywords = {Systematic Literature Review (SLR); Visual Text Mining (VTM); Information visualization; Content document map; Citation document map}
}

@ARTICLE{Felizardo-etal:2012:JSW,
  author = {Katia R. Felizardo and Stephen G. MacDonell and Emília Mendes and José Carlos Maldonado},
  title = {A Systematic Mapping on the use of Visual Data Mining to Support the Conduct of Systematic Literature Reviews},
  crossref = {journal:academy:js},
  volume = {7},
  number = {2},
  month = feb,
  year = {2012},
  pages = {450--461},
  doi = {10.4304/jsw.7.2.450-461},
  abstract = {A systematic literature review (SLR) is a methodology used to find and aggregate all relevant existing evidence about a specific research question of interest. Important decisions need to be made at several points in the review process, relating to search of the literature, selection of relevant primary studies and use of methods of synthesis. Visualization can support tasks that involve large collections of data, such as the studies collected, evaluated and summarized in an SLR. The objective of this paper is to present the results of a systematic mapping study (SM) conducted to collect and evaluate evidence on the use of a specific visualization technique, visual data mining (VDM), to support the SLR process. We reviewed 20 papers and our results indicate a scarcity of research on the use of VDM to help with conducting SLRs in the software engineering domain. However, most of the studies (16 of the 20 studies included in our mapping) have been conducted in the field of medicine and they revealed that the activities of data extraction and data synthesis, related to conducting the review phase of an SLR process, have more VDM support than other activities. In contrast, according to our SM, previous studies using VDM techniques with SLRs have not employed such techniques during the SLR's planning and reporting phases.},
  keywords = {Systematic Mapping; Systematic Literature Review; Visual Data Mining}
}

@INPROCEEDINGS{Felizardo-etal:2010,
  author = {Katia Romera Felizardo and Elisa Yumi Nakagawa and Daniel Feitosa and Rosane Minghim and José Carlos Maldonado},
  title = {An Approach Based on Visual Text Mining to Support Categorization and Classification in the Systematic Mapping},
  crossref = {proceedings:ease:2010},
  pages = {34--43},
  abstract = {Systematic mapping provides an overview of a research area to assess the quantity of evidence existing on a topic of interest. In spite of its relevance, the establishment of consistent categories and classification of primary studies in these categories are manually conducted. Objective: We propose an approach, named SM-VTM (Systematic Mapping based on Visual Text Mining), to support categorization and classification stages in the systematic mapping using Visual Text Mining (VTM), aiming at reducing time and effort required in this process. Method: We established SM-VTM, selected a VTM tool and conducted a case study comparing results of two systematic mappings: one performed manually and another using our approach. Results: The results of both systematic mappings were very similar, showing the viability of SM-VTM. Furthermore, since our approach was applied using a tool, reduction of time and effort can be achieved. Conclusions: The application of VTM seems to be very relevant in the context of systematic mapping.},
  keywords = {Systematic Mapping, Information Visualization, Visual Text Mining},
  url = {http://www.bcs.org/content/conWebDoc/34783}
}

@INPROCEEDINGS{Felizardo-etal:2014,
  author = {Felizardo, Katia Romero and Nakagawa, Elisa Yumi and MacDonell, Stephen G. and Maldonado, José Carlos},
  title = {A Visual Analysis Approach to Update Systematic Reviews},
  crossref = {proceedings:ease:2014},
  pages = {4:1--4:10},
  doi = {10.1145/2601248.2601252},
  abstract = {Context: In order to preserve the value of Systematic Reviews (SRs), they should be frequently updated considering new evidence that has been produced since the completion of the previous version of the reviews. However, the update of an SR is a time consuming, manual task. Thus, many SRs have not been updated as they should be and, therefore, they are currently outdated. Objective: The main contribution of this paper is to support the update of SRs. Method: We propose USR-VTM, an approach based on Visual Text Mining (VTM) techniques, to support selection of new evidence in the form of primary studies. We then present a tool, named Revis, which supports our approach. Finally, we evaluate our approach through a comparison of outcomes achieved using USR-VTM versus the traditional (manual) approach. Results: Our results show that USR-VTM increases the number of studies correctly included compared to the traditional approach. Conclusions: USR-VTM effectively supports the update of SRs.},
  keywords = {VTM, systematic literature review, systematic review, visual text mining},
  owner = {magsilva},
  timestamp = {2014.09.13}
}

@INPROCEEDINGS{Felizardo-etal:2013,
  author = {Felizardo, K. R. and Riaz, Mehwish and Sulayman, M. and Mendes, E. and MacDonell, S. G. and Maldonado, J. C.},
  title = {Analysing the Use of Graphs to Represent the Results of Systematic Reviews in Software Engineering},
  crossref = {proceedings:sbes:2011},
  pages = {174--183},
  doi = {10.1109/SBES.2011.9},
  abstract = {The presentation of results from Systematic Literature Reviews (SLRs) is generally done using tables. Prior research suggests that results summarized in tables are often difficult for readers to understand. One alternative to improve results' comprehensibility is to use graphical representations. The aim of this work is twofold: first, to investigate whether graph representations result is better comprehensibility than tables when presenting SLR results; second, to investigate whether interpretation using graphs impacts on performance, as measured by the time consumed to analyse and understand the data. We selected an SLR published in the literature and used two different formats to represent its results - tables and graphs, in three different combinations: (i) table format only; (ii) graph format only; and (iii) a mixture of tables and graphs. We conducted an experiment that compared the performance and capability of experts in SLR, as well as doctoral and masters students, in analysing and understanding the results of the SLR, as presented in one of the three different forms. We were interested in examining whether there is difference between the performance of participants using tables and graphs. The graphical representation of SLR data led to a reduction in the time taken for its analysis, without any loss in data comprehensibility. For our sample the analysis of graphical data proved to be faster than the analysis of tabular data. However, we found no evidence of a difference in comprehensibility whether using tables, graphical format or a combination. Overall we argue that graphs are a suitable alternative to tables when it comes to representing the results of an SLR.}
}

@INPROCEEDINGS{Felizardo-etal:2011,
  author = {Felizardo, K. R. and Salleh, N. and Martins, R. M. and Mendes, E. and Macdonell, S.G. and Maldonado, J. C.},
  title = {Using visual text mining to support the study selection activity in systematic literature reviews},
  crossref = {proceedings:esem:2011},
  pages = {77--86},
  doi = {10.1109/ESEM.2011.16},
  abstract = {Background: A systematic literature review (SLR) is a methodology used to aggregate all relevant existing evidence to answer a research question of interest. Although crucial, the process used to select primary studies can be arduous, time consuming, and must often be conducted manually. Objective: We propose a novel approach, known as 'Systematic Literature Review based on Visual Text Mining' or simply SLR-VTM, to support the primary study selection activity using visual text mining (VTM) techniques. Method: We conducted a case study to compare the performance and effectiveness of four doctoral students in selecting primary studies manually and using the SLR-VTM approach. To enable the comparison, we also developed a VTM tool that implemented our approach. We hypothesized that students using SLR-VTM would present improved selection performance and effectiveness. Results: Our results show that incorporating VTM in the SLR study selection activity reduced the time spent in this activity and also increased the number of studies correctly included. Conclusions: Our pilot case study presents promising results suggesting that the use of VTM may indeed be beneficial during the study selection activity when performing an SLR.},
  keywords = {Evidence-based software engineering (EBSE); Study selection activity; Systematic literature review (SLR); Visual text mining (VTM)}
}

@ARTICLE{Fernandes-Ferreira:2011,
  author = {Geraldo Wellington Fernandes and Carlos Alberto Ferreira},
  title = {Dificuldades durante a produção de e-Conteúdos para formação em Ciência e Tecnologia: quais são e como solucioná-las?},
  crossref = {journal:rbie},
  volume = {19},
  number = {3},
  year = {2011},
  pages = {3-15},
  doi = {10.5753/RBIE.2011.19.03.03},
  abstract = {O e-Learning, como um método de ensino-aprendizagem, tem se desenvolvido em Portugal no que se refere a formação profissional e universitária, principalmente em Ciência e Tecnologia. Neste processo, as empresas e universidades que oferecem o e-Learning procuram superar os seus problemas principalmente em relação a qualidade do ensino e qualidade dos conteúdos, assim, este artigo tem como objetivo apresentar as principais dificuldades e soluções encontradas pelas instituições portuguesas que produzem e-Conteúdos, mas voltada para formação em Ciência e Tecnologia. A abordagem de investigação é do tipo quantitativo e qualitativo. Utilizou-se como instrumentos de coleta de dados questionários, entrevistas semiestruturadas e a análise de documentos. O nosso estudo permitiu-nos verificar que as principais dificuldades estão em aspetos relacionados com a reutilização dos conteúdos, geração de metadados, tempo de produção e aspetos referentes ao contrato para a produção do conteúdo.},
  keywords = {e-Learning, e-Conteúdos, ciência e tecnologia, objetos de aprendizagem, dificuldades e soluções},
  lang = {pt}
}

@ARTICLE{FernandezAleman:2011,
  author = {Fernandez Aleman, J. L.},
  title = {Automated Assessment in a Programming Tools Course},
  crossref = {journal:ieee:te},
  volume = {54},
  number = {4},
  month = nov,
  year = {2011},
  pages = {576 -581},
  doi = {10.1109/TE.2010.2098442},
  abstract = {Automated assessment systems can be useful for both students and instructors. Ranking and immediate feedback can have a strongly positive effect on student learning. This paper presents an experience using automatic assessment in a programming tools course. The proposal aims at extending the traditional use of an online judging system with a series of assignments related to programming tools. Some empirical results on how students use an automated assessment system in a CS2 course are presented. Research suggested that automated assessment systems promoted the students' interest and produced statistically significant differences in the scores between experimental and control groups.},
  keywords = {automated assessment systems;immediate feedback;online judging system;programming tools course;ranking;student learning;computer science education;courseware;feedback;software tools;},
  lang = {en}
}

@INPROCEEDINGS{Ferrari-etal:2008,
  author = {Ferrari, F.C. and Maldonado, J.C. and Rashid, A.},
  title = {Mutation Testing for Aspect-Oriented Programs},
  crossref = {proceedings:icst:2008},
  pages = {52--61},
  doi = {10.1109/ICST.2008.37},
  abstract = {Mutation testing has been shown to be one of the strongest testing criteria for the evaluation of both programs and test suites. Comprehensive sets of mutants require strong test sets to achieve acceptable testing coverage. Moreover, mutation operators are valuable for the evaluation of other testing approaches. Although its importance has been highlighted for aspect-oriented (AO) programs, there is still a need for a suitable set of mutation operators for AO languages. The quality of the mutation testing itself relies on the quality of such operators. This paper presents the design of a set of mutation operators for AspectJ-based programs. These operators model instances of fault types identified in an extensive survey. The fault types and respective operators are grouped according to the related language features. We also discuss the generalisation of the fault types to AO approaches other than AspectJ and the coverage that may be achieved with the application of the proposed operators. In addition, a cost analysis based on two case studies involving real-world applications has provided us feedback on the most expensive operators, which will support the definition of further testing strategies.}
}

@INPROCEEDINGS{Ferrari-Maldonado:2008,
  author = {Fabiano Cutigi Ferrari and José Carlos Maldonado},
  title = {Experimenting with a Multi-Iteration Systematic Review in Software Engineering},
  crossref = {proceedings:eselaw:2008},
  pages = {1-10},
  abstract = {Context: Systematic reviews promise to become a common practice within the Software Engineering (SE) domain, having the replicability as an important requirement that allows for result contrasting and updates. Objectives: To provide background in systematic review updating process by reporting our experience in performing a multi-iteration systematic review within the SE domain. Method: We updated the original review twice based on an adapted three-phase process for systematic reviews. We discuss the main issues and present the lessons learned. Results: Following the adapted process led us to update the original review successfully, even considering the lack of background in review updates and the limited supporting mechanisms. Conclusions: Replicability of systematic reviews is feasible specially thanks to the rigorous planning process.},
  owner = {magsilva},
  timestamp = {2010.09.13},
  year = {2008}
}

@INPROCEEDINGS{Ferrari-etal:2011,
  author = {Ferrari, Fabiano Cutigi and Nakagawa, Elisa Yumi and Maldonado, José Carlos and Rashid, Awais},
  title = {{Proteum/AJ}: a mutation system for {AspectJ} programs},
  crossref = {proceedings:aosd:2011},
  pages = {73--74},
  doi = {10.1145/1960314.1960340},
  abstract = {Aspect-Oriented Programming (AOP) has introduced a complementary set of mechanisms which enhance the modularisation of crosscutting concerns. However, such mechanisms represent new potential sources of faults that may be systematically tackled with mutation testing. In this demonstration we present a tool, named Proteum/AJ, which automates the mutation testing of AspectJ programs. Proteum/AJ supports the main steps of this testing approach and realises a set of requirements for mutation-based testing tools like mutant handling, test case handling and mutant analysis. Our experience in using the tool provided us with evidence on the feasibility of performing mutation testing of AO programs. In this demonstration we are going to share some of this experience with the audience.},
  keywords = {AspectJ, aspect-oriented programming, mutation testing, test automation, testing tools}
}

@INPROCEEDINGS{Ferreira-etal:2010,
  author = {Guilherme Daher Ferreira and Guilherme Nogueira and Giovanni Comarela and Fábio Fabris and Magnos Martinello and José Gonçalves P. Filho},
  title = {{Ginga-NCL} em Dispositivos Portáteis: Uma Implementação para a Plataforma {Android}},
  crossref = {proceedings:webmedia:2010},
  pages = {43--50},
  abstract = {Hoje já existem no Brasil aparelhos que permitem a recepção do sinal de TV digital. No entanto, estes dispositivos não estão equipados com o Ginga, middleware adotado pelo Sistema Brasileiro de Televisão Digital - SBTVD, o que inviabiliza a execução de conteúdo multimídia interativo. Este trabalho descreve uma implementação do Ginga-NCL para dispositivos portáteis baseados no sistema operacional Android. Como meio de validar a implementação, foram conduzidos experimentos para analisar a execução de aplicações NCL, bem como o uso de recursos do dispositivo portátil. Além disso, o ambiente desenvolvido permite avaliar a transmissão e recepção de aplicações NCL por meio do protocolo padronizado DSM-CC sobre IP.},
  keywords = {Ginga, Middleware, SBTVD, Android OS, TV Digital, DTV},
  abstract-en = {Recently, there has been in Brazil a few number of devices capable of receiving the digital television signal. However, these devices lack the Brazilian Digital Television System's middleware, named Ginga, and therefore they do not allow the execution of interactive multimedia content. This paper reports an implementation of Ginga-NCL for Google's Android platform. In order to validate the implementation, experiments were conducted to analyze the execution of NCL applications, as well as the usage of devices resources. Moreover, the developed environment allows to evaluate the transmission and reception of NCL applications through the standardized DSM-CC over IP protocol.}
}

@INPROCEEDINGS{FerreiraSantos-MuchaluatSaade:2009,
  author = {Ferreira dos Santos, Joel André and Muchaluat Saade, Débora Christina},
  title = {Linguagem {XTemplate} 3.0: Facilitando a Autoria de Programas {NCL} para {TV} Digital Interativa},
  crossref = {proceedings:webmedia:2009},
  pages = {1--8},
  doi = {10.1145/1858477.1858494},
  abstract = {Este artigo apresenta a linguagem XTemplate 3.0 como solução para a definição de templates de composição para documentos NCL 3.0, facilitando assim a autoria de documentos hipermídia usados na criação de conteúdo interativo no sistema brasileiro de TV digital. Templates de composição hipermídia definem estruturas de nós e elos que podem ser reutilizadas em diferentes contextos de documentos NCL 3.0. A especificação da linguagem XTemplate 3.0 foi feita usando uma abordagem modular em XML Schema de acordo com o padrão W3C. Com essa abordagem modular, a especificação ganha uma maior simplicidade de manutenção e flexibilidade de implementação, além da possibilidade de criação de perfis de XTemplate. XTemplate 3.0 estende as versões anteriores de XTemplate, incorporando novas funcionalidades a linguagem.},
  keywords = {Ginga, NCL, TV digital interativa, reuso, templates de composição},
  abstract-en = {This paper presents the XTemplate 3.0 language as a solution for defining composite templates to NCL 3.0 documents. Hypermedia composite templates define nodes and links structures that can be reused in different NCL 3.0 document contexts, facilitating the authoring of hypermedia documents used in the Brazilian digital TV system interactive content creation. The XTemplate 3.0 language specification was made using a modular approach in XML Schema according to the W3C standard. With this modular approach, the specification becomes simpler to maintain and more flexible to implement, besides the possibility to create XTemplate 3.0 profiles. XTemplate 3.0 extends the previous XTemplate versions, incorporating new features to the language.},
  lang = {pt},
  title-en = {{XTemPlate} 3.0 language: easing the authoring of {NCL} programs for interactive digital {TV}}
}

@INPROCEEDINGS{Feuerstack-Pizzolato:2012,
  author = {Feuerstack, Sebastian and Pizzolato, Ednaldo Brigante},
  title = {Engineering device-spanning, multimodal web applications using a model-based design approach},
  crossref = {proceedings:webmedia:2012},
  pages = {29--38},
  doi = {10.1145/2382636.2382646},
  abstract = {Nowadays the web is an ubiquitously available source of information that can be accessed through a broad range of devices, such as smart phones, tablets and notebooks. Although web applications can be used through several devices, they are controlled and designed for a one-to-one connection type of interaction, which prevents device-spanning multi-modal interactions. We propose a model-based run-time framework to design and execute multi-modal interfaces for the web. Different to a model-based design that implements reification, a process to derive concrete models from abstract ones by transformation, we design interactors that keep all design models alive at run-time. Interactors are based on finite state machines that can be inspected and manipulated at run-time and are synchronized over different devices and modalities using mappings. We show the expressiveness of state charts for modeling interactions, interaction resources, and interaction paradigms. We proof our approach by checking its conformance against common requirements for multimodal frameworks, classify it based on characteristics identified by others, and present initial results of a performance analysis.},
  keywords = {HCI, model-based user interfaces, multimodal interfaces, web application development}
}

@INCOLLECTION{Filatro:2009,
  author = {Andrea Filatro},
  title = {As teorias pedagógicas fundamentais em {EAD}},
  chapter = {14},
  pages = {96-104},
  crossref = {Litto-Formiga:2009}
}

@ARTICLE{Finlay-etal:2013,
  author = {Jacqui Finlay and Russel Pears and Andy M. Connor},
  title = {Data stream mining for predicting software build outcomes using source code metrics },
  crossref = {journal:elsevier:ist},
  number = {0},
  year = {2013},
  pages = {--},
  doi = {10.1016/j.infsof.2013.09.001},
  abstract = {AbstractContext Software development projects involve the use of a wide range of tools to produce a software artifact. Software repositories such as source control systems have become a focus for emergent research because they are a source of rich information regarding software development projects. The mining of such repositories is becoming increasingly common with a view to gaining a deeper understanding of the development process. Objective This paper explores the concepts of representing a software development project as a process that results in the creation of a data stream. It also describes the extraction of metrics from the Jazz repository and the application of data stream mining techniques to identify useful metrics for predicting build success or failure. Method This research is a systematic study using the Hoeffding Tree classification method used in conjunction with the Adaptive Sliding Window (ADWIN) method for detecting concept drift by applying the Massive Online Analysis (MOA) tool. Results The results indicate that only a relatively small number of the available measures considered have any significance for predicting the outcome of a build over time. These significant measures are identified and the implication of the results discussed, particularly the relative difficulty of being able to predict failed builds. The Hoeffding Tree approach is shown to produce a more stable and robust model than traditional data mining approaches. Conclusion Overall prediction accuracies of 75% have been achieved through the use of the Hoeffding Tree classification method. Despite this high overall accuracy, there is greater difficulty in predicting failure than success. The emergence of a stable classification tree is limited by the lack of data but overall the approach shows promise in terms of informing software development activities in order to minimize the chance of failure. },
  keywords = {Data Stream Mining, Concept Drift Detection, Hoeffding Tree, Jazz, Software Metrics, Software Repositories },
  url = {http://www.sciencedirect.com/science/article/pii/S0950584913001766},
  issn = {0950-5849},
  journal = {Information and Software Technology },
  timestamp = {2013-09-16}
}

@INPROCEEDINGS{Fischer:2007,
  author = {Gerhard Fischer},
  title = {Meta-Design: Expanding Boundaries and Redistributing Control in Design},
  crossref = {proceedings:interact:2007},
  pages = {1--14},
  abstract = {Meta-design is an emerging conceptual framework aimed at defining and creating socio-technical environments as living entities. It extends existing design methodologies focused on the development of a system at design time by allowing users to become co-designers at use time. Meta-design is grounded in the basic assumption that future uses and problems cannot be completely anticipated at design time, when a system is developed. Users, at use time, will discover mismatches between their needs and the support that an existing system can provide for them. Meta-design extends boundaries by supporting users as active contributors who can transcend the functionality and content of existing systems. By facilitating these possibilities, control is distributed among all stakeholders in the design process. This paper characterizes different design methodologies and identifies the unique challenges and opportunities for meta-design. It illustrates this approach with two examples: (a) Web2Gether (enriching the organizational practices and community building of assistive technology teachers), and (b) the Memory Aiding Prompting System (MAPS) (addressing the needs of people with cognitive disabilities and their caregivers). Assessments of our developments are used to identify some future implications and challenges for meta-design and its role in socially responsible design.},
  keywords = {design, design methodologies, meta-design, socio-technical environments, boundaries, control, seeding / evolutionary growth / reseeding model, Web2Gether, Memory Aiding Prompting System (MAPS), application areas for meta-design, socially responsible design}
}

@INPROCEEDINGS{Fischer:1963,
  author = {Fischer, Patrick C.},
  title = {On computability by certain classes of restricted turing machines},
  crossref = {proceedings:swct:1963},
  pages = {23--32},
  doi = {10.1109/SWCT.1963.10},
  abstract = {The theory of abstract machines has been well developed for the finite automaton [RS] and the Turing machine [D]. More recently, machines intermediate in computing power between the above two classes of machines have been investigated. These machines have some form of unbounded memory, thus giving them more potential computing ability than the finite automata, but the access to the unbounded memory is restricted in some way so that they do not have the full power of a Turing machine. The two forms of restricted unbounded memory we shall consider here are the counter and the pushdown store.},
  keywords = {Automata;Counting circuits;Transducers;Turing machines},
  owner = {magsilva},
  timestamp = {2014.07.15}
}

@ARTICLE{Patrick,
  author = {Patrick C. Fischer},
  title = {On Formalisms for Turing Machines},
  crossref = {journal:acm:jacm},
  volume = {12},
  number = {4},
  pages = {570--580},
  doi = {10.1145/321296.321308}
}

@ARTICLE{Fischer:2001,
  author = {Fischer, Stephan},
  title = {Course and exercise sequencing using metadata in adaptive hypermedia learning systems},
  crossref = {journal:acm:jeric},
  volume = {1},
  number = {1},
  month = mar,
  year = {2001},
  pages = {1-21},
  doi = {10.1145/376697.376700},
  abstract = {In the last few years the (semi-) automatic sequencing of course material has become an important research issue, particularly the standardization of metadata for educational resources. Sequencing can help to generate hypermedia documents which, at their best match the learner's needs. To perform (semi-) automatic course sequencing, a knowledge library as well as modular resources can be used. Both must be described by metadata. First, metadata standards (IEEE Learning Objects Metadata, Instructional Mangement Systems Global Learning Consortium, Dublin Core) are analyzed with regard to course sequencing. As an application example, Multibook, an adaptive hypermedia system used to teach multimedia technology, is described. Multibook uses metadata to create course sequences semi-automatically. In this article we explain how a knowledge library can be used to create exercises automatically. We give an example of how courses can be sequenced in general by analyzing the creation of exercises. An evaluation of our system shows the advantages and drawbacks of the automatic sequencing approach. are analyzed with regard to course sequencing. As an application example, Multibook uses metadata to create course sequences semi-automatically. In this article we explain how a knowledge library can be used to create automatically. We give an example of how courses can be sequenced in general by analyzing the creation of exercises. An evaluation of our system shows the advantages and drawbacks of the automatic course sequencing approach.},
  keywords = {adaptive hypermedia systems, hypermedia learning, knowledge engineering, sequencing of course material}
}

@ARTICLE{Fisher-Margolis:2002,
  author = {Fisher, Allan and Margolis, Jane},
  title = {Unlocking the Clubhouse: The Carnegie Mellon Experience},
  crossref = {journal:acm:sigcse},
  volume = {34},
  number = {2},
  month = jun,
  year = {2002},
  pages = {79--83},
  doi = {10.1145/543812.543836},
  abstract = {In the fall of 1995, just seven of 95 students entering the undergraduate program in computer science at Carnegie Mellon University were women. In 2000, 54 of 130, or 42%, were women. What happened? This article presents a brief history of the transformation at Carnegie Mellon's School of Computer Science, and the research project that lay behind it. A fuller discussion, set in an analysis of gender issues in computing from childhood through college, is found in our book, Unlocking the Clubhouse: Women in Computing [2].The story begins with a research study designed specifically to diagnose and find remedies for the gender gap in Carnegie Mellon's undergraduate computer science program. Female enrollment had hovered below 10% for a number of years, and the fraction of women leaving the program was approximately twice that for men. In 1995, the Alfred P. Sloan Foundation funded our proposal for a two-year program, which was followed up two years later with a two-year extension. The goal was to understand the experiences and choices of both men and women with respect to studying computer science, and to design interventions that would involve more women.}
}

@ARTICLE{Fisher-Cox:2006,
  author = {Fisher, Maryanne and Cox, Anthony},
  title = {Gender and programming contests: mitigating exclusionary practices},
  crossref = {journal:imi:ie},
  volume = {5},
  number = {1},
  month = jan,
  year = {2006},
  pages = {47--62},
  abstract = {Individuals vary across many dimensions due to the effects of gender-based, personality, and cultural differences. Consequently, programming contests with a limited and restrictive structure (e.g., scoring system, questioning style) are most favourable and attractive to a specific set of individuals with the characteristics that best match this structure. We suggest that a more inclusive and flexible structure will allow contests to be more appealing to a wider range of participants by being less biased towards specific traits. As well, by making contests more broadly appealing, they become better post secondary recruiting tools that can potentially be used to attract under-represented populations to the discipline of computer science. In this paper, we focus on gender-based differences and the effect of a competition's structure on female participants.},
  keywords = {gender bias, programming contests, scoring systems}
}

@INPROCEEDINGS{Flores-etal:2010,
  author = {Flores, Luciano and Miletto, Evandro and Pimenta, Marcelo and Miranda, Eduardo and Keller, Damián},
  title = {Musical interaction patterns: communicating computer music knowledge in a multidisciplinary project},
  crossref = {proceedings:sigdoc:2010},
  pages = {199--206},
  doi = {10.1145/1878450.1878484},
  abstract = {The growing popularity of mobile devices gave birth to a still emergent research field, called Mobile Music, and concerning the development of musical applications for use in these devices. Our particular research investigates interaction design within this field, taking into account relations hips with ubiquitous computing contexts, and applying knowledge from several disciplines, mainly Computer Music and Human-Computer Interaction. In this paper we propose using the concept of patterns in such multidisciplinary design context. Design patterns are, essentially, common solutions for specific design problems, which have been systematically collected and documented. Since they help designers, allowing them to reuse proven solutions within a certain domain, we argue that they can aid multidisciplinary design, facilitating communication and allowing knowledge transfer among team members of diverse fields. We illustrate our point by describing a set of musical interaction patterns that came out of our investigation so far, showing how they encapsulate Computer Music knowledge and how this was helpful in our own design process.},
  keywords = {computer music, interaction design patterns, mobile music, multidisciplinary design, ubiquitous computing},
  series = {SIGDOC '10},
  acmid = {1878484},
  address = {New York, NY, USA},
  isbn = {978-1-4503-0403-0},
  numpages = {8}
}

@ARTICLE{Fomin-Kaski:2013,
  author = {Fomin, Fedor V. and Kaski, Petteri},
  title = {Exact exponential algorithms},
  crossref = {journal:acm:cacm},
  volume = {56},
  number = {3},
  month = mar,
  year = {2013},
  pages = {80--88},
  doi = {10.1145/2428556.2428575},
  abstract = {Discovering surprises in the face of intractability.}
}

@ARTICLE{Fong:2009,
  author = {Fong, Philip W.L.},
  title = {Reading a computer science research paper},
  crossref = {journal:acm:inroads},
  volume = {41},
  number = {2},
  month = jun,
  year = {2009},
  pages = {138--140},
  doi = {10.1145/1595453.1595493},
  abstract = {This tutorial article highlights some points that a graduate or senior undergraduate student should bear in mind when reading a computer science research paper. Specifically, the reading process is divided into three tasks: comprehension, evaluation and synthesis. The genre of paper review is then introduced as a vehicle for critical reading of research papers. Lastly, guidelines on how to be initiated into the trade of conference and/or journal paper review are given. Designed to be used in a graduate course setting, this tutorial comes with a suggested marking scheme for grading paper reviews with a summary-critique-synthesis structure.},
  keywords = {graduate education, paper review, reading research papers}
}

@ARTICLE{Fontana-etal:2014,
  author = {Rafaela Mantovani Fontana and Isabela Mantovani Fontana and Paula Andrea da Rosa Garbuio and Sheila Reinehr and Andreia Malucelli},
  title = {Processes versus people: How should agile software development maturity be defined? },
  crossref = {journal:elsevier:ist},
  volume = {97},
  year = {2014},
  pages = {140--155},
  doi = {10.1016/j.jss.2014.07.030},
  abstract = {Abstract Maturity in software development is currently defined by models such as CMMI-DEV and ISO/IEC 15504, which emphasize the need to manage, establish, measure and optimize processes. Teams that develop software using these models are guided by defined, detailed processes. However, an increasing number of teams have been implementing agile software development methods that focus on people rather than processes. What, then, is maturity for these agile teams that focus less on detailed, defined processes? This is the question we sought to answer in this study. To this end, we asked agile practitioners about their perception of the maturity level of a number of practices and how they defined maturity in agile software development. We used cluster analysis to analyze quantitative data and triangulated the results with content analysis of the qualitative data. We then proposed a new definition for agile software development maturity. The findings show that practitioners do not see maturity in agile software development as process definition or quantitative management capabilities. Rather, agile maturity means fostering more subjective capabilities, such as collaboration, communication, commitment, care, sharing and self-organization. },
  keywords = {Maturity, Agile software development, Software process improvement },
  url = {http://www.sciencedirect.com/science/article/pii/S0164121214001587},
  issn = {0164-1212},
  journal = {Journal of Systems and Software },
  owner = {magsilva},
  timestamp = {2014.09.25}
}

@INPROCEEDINGS{Forisek:2010,
  author = {Forisek, Michal},
  title = {The Difficulty of Programming Contests Increases},
  crossref = {proceedings:issep:2010},
  pages = {72--85},
  doi = {10.1007/978-3-642-11376-5_8},
  abstract = {In this paper we give a detailed quantitative and qualitative analysis of the difficulty of programming contests in past years. We analyze task topics in past competition tasks, and also analyze an entire problem set in terms of required algorithm efficiency. We provide both subjective and objective data on how contestants are getting better over the years and how the tasks are getting harder. We use an exact, formal method based on Item Response Theory to analyze past contest results.},
  owner = {magsilva},
  timestamp = {2014.08.30}
}

@ARTICLE{Forisek:2006,
  author = {Forisek, Michal},
  title = {On the Suitability of Programming Tasks for Automated Evaluation},
  crossref = {journal:imi:ie},
  volume = {5},
  number = {1},
  month = jan,
  year = {2006},
  pages = {63--76},
  abstract = {For many programming tasks we would be glad to have some kind of automatic evaluation process. As an example, most of the programming contests use an automatic evaluation of the contestants' submissions. While this approach is clearly highly efficient, it also has some drawbacks. Often it is the case that the test inputs are not able to "break" all flawed submissions. In this article we show that the situation is not pleasant at all - for some programming tasks it is impossible to design good test inputs. Moreover, we discuss some ways how to recognize such tasks, and discuss other possibilities for doing the evaluation. The discussion is focused on programming contests, but the results can be applied for any programming tasks, e.g., assignments in school.},
  keywords = {IOI, automated testing, black-box testing, programming contests, programming task, task analysis},
  owner = {magsilva},
  timestamp = {2014.08.30}
}

@INPROCEEDINGS{Forte-Bruckman:2007,
  author = {Forte, Andrea and Bruckman, Amy},
  title = {Constructing text: Wiki as a toolkit for (collaborative?) learning},
  crossref = {proceedings:wikysym-opensym:2013},
  pages = {31--42},
  doi = {10.1145/1296951.1296955},
  abstract = {Writing a book from which others can learn is itself a powerful learning experience. Based on this proposition, we have launched Science Online, a wiki to support learning in high school science classrooms through the collaborative production of an online science resource. Our approach to designing educational uses of technology is based on an approach to education called constructionism, which advocates learning by working on personally meaningful projects. Our research examines the ways that constructionism connects to collective models of knowledge production and learning such as Knowledge Building. In this paper, we explore ways that collaboration using wiki tools fits into the constructionist approach, we examine learning goals for youth growing up in a read-write culture, and we discuss preliminary findings in an ongoing year-long study of Science Online in the classroom. Despite the radically open collaboration afforded by wiki, we observe that many factors conspired to stymie collaborative writing on the site. We expected to find cultural barriers to wiki adoption in schools. Unexpectedly, we are also finding that the design of the wiki tool itself contributed barriers to collaborative writing in the classroom.},
  keywords = {collaboration, constructionism, education, knowledge building, open content, wiki}
}

@INPROCEEDINGS{Fortes-etal:2004a,
  author = {Fortes, Renata Pontin de Mattos and Marco Aurélio Graciotto Silva and André Pimenta Freire and Daniel Cárnio Junqueira},
  title = {{SAFE} -- Software Engineering Available for Everyone},
  crossref = {proceedings:wsl:2004},
  pages = {203-206},
  abstract = {The SAFE project aims the elaboration of a software development framework sufficiently simple to attract the collaboration of free software's developers with different levels of software process's familiarity. This framework will help the automation of free software processes, through the integration of free software tools that support software engineering activities.},
  abstract-en = {The SAFE project aims the elaboration of a software development framework sufficiently simple to attract the collaboration of free software's developers with different levels of software process's familiarity. This framework will help the automation of free software processes, through the integration of free software tools that support software engineering activities.},
  abstract-pt = {O projeto SAFE visa elaborar uma infra-estrutura para desenvolvimento de software que seja simples o suficiente para atrair a colaboração de desenvolvedores nos diversos níveis de familiaridade com o processo de software livre. A infra-estrutura será na forma de um suporte automatizado ao processo de software livre, por meio da integração de ferramentas de software livre de apoio às atividades de engenharia de software.},
  address = {Porto Alegre, Brasil},
  booktitle = {V Workshop sobre Software Livre (WSL 2004), parte do V Fórum Internacional de Software Livre (FISL 2004)},
  lang = {pt},
  owner = {magsilva},
  timestamp = {2006.09.28},
  title-en = {SAFE -- Software Engineering Available for Everyone},
  title-pt = {SAFE -- Software Engineering Available for Everyone},
  year = {2004}
}

@ARTICLE{Fortnow:2009,
  author = {Fortnow, Lance},
  title = {The status of the {P} versus {NP} problem},
  crossref = {journal:acm:cacm},
  volume = {52},
  number = {9},
  month = sep,
  year = {2009},
  pages = {78--86},
  doi = {10.1145/1562164.1562186},
  abstract = {It's one of the fundamental mathematical problems of our time, and its importance grows with the rise of powerful computers.}
}

@ARTICLE{Forward-etal:2012,
  author = {Forward, Andrew and Badreddin, Omar and Lethbridge, Timothy C. and Solano, Julian},
  title = {Model-driven rapid prototyping with {Umple}},
  crossref = {journal:springer:spe},
  volume = {42},
  number = {7},
  month = jul,
  year = {2012},
  pages = {781--797},
  doi = {10.1002/spe.1155},
  abstract = {The emergence of model-driven software development brings new opportunities and challenges for rapid prototyping. On the one hand, the modeling process is inherently abstract, removing the prototyper from details, and letting him or her focus on exploring design alternatives for various aspects of the system. On the other hand, the most popular modeling languages and tools entirely omit the modeling and generating of user interfaces. As a result, the benefit of user interface prototypes as a medium for interaction with the user and customer is lost. This paper presents a model-oriented technology called Umple that can be used for prototyping and also supporting model driven engineering. Umple allows end users to quickly create class and state machine models and to incrementally embed implementation artifacts. At any point in the modeling process, users can quickly generate a fully functional prototype that exposes modeling implications on the user interface, and allows stakeholders to get a feel of how the full system will behave.},
  keywords = {modeling, prototyping, UML, Umple, model-driven development}
}

@ARTICLE{Fotheringham:1961,
  author = {Fotheringham, John},
  title = {Dynamic storage allocation in the {Atlas} computer, including an automatic use of a backing store},
  crossref = {journal:acm:cacm},
  volume = {4},
  number = {10},
  month = oct,
  year = {1961},
  pages = {435--436},
  doi = {10.1145/366786.366800}
}

@ARTICLE{Frailey:2011,
  author = {Frailey, Dennis J.},
  title = {Computing: a perspective from industry},
  crossref = {journal:acm:inroads},
  volume = {2},
  number = {4},
  month = dec,
  year = {2011},
  pages = {4--8},
  doi = {10.1145/2038876.2038877},
  abstract = {In recent months, there has been considerable discussion about the value of computing as an academic discipline and the value of computing studies in furthering one's career. Kevin Carey (2010) recently wrote an article showing how a student who took only a few computing courses and then changed majors was able to exploit the knowledge and discipline he learned to solve some serious problems in other domains. Carey's paper focused on the knowledge gained from learning how to program, but what about the other knowledge that is fundamental to our field? Should people outside of computing learn about computing fundamentals because they are as important as, say, basic science or math? This prompted me to examine the role of computing in my own career, and to make some observations on computing jobs in industry and how we might better appreciate and promulgate what we know.},
  acmid = {2038877},
  issue_date = {December 2011},
  lang = {en},
  numpages = {5}
}

@INPROCEEDINGS{France-Rumpe:2007,
  author = {France, Robert and Rumpe, Bernhard},
  title = {Model-driven Development of Complex Software: A Research Roadmap},
  crossref = {proceedings:fose:2007},
  pages = {37--54},
  doi = {10.1109/FOSE.2007.14},
  abstract = {The term Model-Driven Engineering (MDE) is typically used to describe software development approaches in which abstract models of software systems are created and systematically transformed to concrete implementations. In this paper we give an overview of current research in MDE and discuss some of the major challenges that must be tackled in order to realize the MDE vision of software development. We argue that full realizations of the MDE vision may not be possible in the near to medium-term primarily because of the wicked problems involved. On the other hand, attempting to realize the vision will provide insights that can be used to significantly reduce the gap between evolving software complexity and the technologies used to manage complexity.}
}

@ARTICLE{Frankl-Weyuker:1988,
  author = {Phyllis G. Frankl and Elaine J. Weyuker},
  title = {An Applicable Family of Data Flow Testing Criteria},
  crossref = {journal:ieee:tse},
  volume = {14},
  number = {10},
  month = oct,
  year = {1988},
  pages = {1483--1498},
  doi = {10.1109/32.6194},
  abstract = {The authors extend the definitions of the previously introduced family of data flow testing criteria to apply to programs written in a large subset of Pascal. They then define a family of adequacy criteria called feasible data flow testing criteria, which are derived from the data-flow testing criteria. The feasible data flow testing criteria circumvent the problem of nonapplicability of the data flow testing criteria by requiring the test data to exercise only those definition-use associations which are executable. It is shown that there are significant differences between the relationships among the data flow testing criteria and the relationships among the feasible data flow testing criteria. The authors discuss a generalized notion of the executability of a path through a program unit. A script of a testing session using their data flow testing tool, ASSET, is included.},
  lang = {en}
}

@INPROCEEDINGS{Frantzi-etal:2004,
  author = {Frantzi, M. and Moumoutzis, N. and Christodoulakis, S.},
  title = {A methodology for the integration of {SCORM} with {TV-Anytime} for achieving interoperable digital {TV} and e-learning applications},
  crossref = {proceedings:icalt:2004},
  pages = {636--638},
  doi = {10.1109/ICALT.2004.1357493},
  abstract = { The term t-learning refers to interactive access of video-rich learning materials, primarily within the home, through a digital TV set-top box. The effective development of t-learning systems and applications should be based on existing standardization efforts in the fields of digital TV and e-learning. In this paper we examine the compatibility between the international standard for digital TV (TV-Anytime) and the international standard for e-learning (SCORM). The purpose is to provide a methodology for interoperability between educational applications in digital TV environments and to facilitate the creation of educational metadata for digital TV programs. The approach is also applicable in audiovisual digital libraries providing educational services to their users. We also describe an implementation of the mapping between the two standards. The implementation allows the transformation of TV-Anytime metadata to SCO metadata for the creation of SCORM compatible courses that utilize educational material from TV programs.},
  address = {Joensuu, } # Finland,
  booktitle = {IEEE International Conference on Advanced Learning Technologies},
  month = aug # {-} # sep,
  publisher = {IEEE},
  year = {2004}
}

@ARTICLE{Fraser-Zeller:2012,
  author = {Fraser, G. and Zeller, A.},
  title = {Mutation-Driven Generation of Unit Tests and Oracles},
  crossref = {journal:ieee:tse},
  volume = {38},
  number = {2},
  month = mar # {--} # apr,
  year = {2012},
  pages = {278--292},
  doi = {10.1109/TSE.2011.93},
  abstract = {To assess the quality of test suites, mutation analysis seeds artificial defects (mutations) into programs; a nondetected mutation indicates a weakness in the test suite. We present an automated approach to generate unit tests that detect these mutations for object-oriented classes. This has two advantages: First, the resulting test suite is optimized toward finding defects modeled by mutation operators rather than covering code. Second, the state change caused by mutations induces oracles that precisely detect the mutants. Evaluated on 10 open source libraries, our #x03BC;test prototype generates test suites that find significantly more seeded defects than the original manually written test suites.},
  keywords = {Mutation analysis, test case generation, unit testing, test oracles, assertions, search-based testing}
}

@INPROCEEDINGS{Fraser-etal:2003,
  author = {Fraser, Steven and Beck, Kent and Caputo, Bill and Mackinnon, Tim and Newkirk, James and Poole, Charlie},
  title = {Test Driven Development (TDD)},
  crossref = {proceedings:xp:2003},
  pages = {459--462},
  doi = {10.1007/3-540-44870-5_84},
  abstract = {This panel brings together practitioners with extensive experience in agile/XP methodologies to discuss the approaches and benefits of applying TDD. The goal of test driven development (TDD) is clean code that works. The mantra of TDD is: write a test; make it run; and make it right. Open questions exist, for example -- how can TDD approaches be applied to databases, GUIs, and distributed systems? What are the quantitative benchmarks that can demonstrate the value of TDD, and what are the best approaches to solve the ubiquitous issues of scalability?},
  owner = {magsilva},
  timestamp = {2014.10.21}
}

@ARTICLE{Brooks:1987,
  author = {Frederick P. Brooks, Jr},
  title = {No Silver Bullet -- Essence and Accidents of Software Engineering},
  crossref = {proceedings:ieee:computer},
  volume = {20},
  number = {4},
  month = apr,
  year = {1987},
  pages = {10--19},
  doi = {10.1109/MC.1987.1663532}
}

@INPROCEEDINGS{Freeman-etal:1976,
  author = {Peter Freeman and Anthony I. Wasserman and Richard E. Fairley},
  title = {Essential Elements of Software Engineering Education},
  crossref = {proceedings:icse:1976},
  pages = {116--122},
  abstract = {Software engineering involves the application of principles of computer science, management science, and other fields to the design and construction of software systems. Education in software engineering is fundamentally different from education in computer science, management science, or other constituent fields, even though it shares a large common area of concern. As we move toward the development of coordinated software engineering curricula, it is mandatory that we identify principles, not just random collections of techniques, on which to build them. Our research, teaching, and practical experience leads us to argue for five essential elements of any software engineering curriculum: computer science, management science, communication skills, problem solving, and design methodology. This paper will discuss these areas, illustrate their current application in courses, and indicate their implications for curriculum development.}
}

@ARTICLE{Freire-Figueiredo:2011,
  author = {Freire, Vinícius P. and Figueiredo, Daniel R.},
  title = {Ranking in collaboration networks using a group based metric},
  crossref = {journal:springer:jbcs},
  volume = {17},
  number = {4},
  month = nov,
  year = {2011},
  pages = {255--266},
  doi = {10.1007/s13173-011-0041-7},
  abstract = {Collaboration networks are social networks in which relationships represent some kind of professional collaboration. The study of collaboration networks can help identify individuals or groups that are important or influential within a given community. We start this work by characterizing the structural properties of the scientific collaboration network in the area of Computer Science. In particular, we consider the global network (all individuals) and the Brazilian network (individuals affiliated with Brazilian institutions) and establish a direct comparison between them. Our empirical results indicate that despite exhibiting features found in most social networks, these two networks also have some interesting differences. We then present a novel approach to rank individuals within a group in the network (as opposed to ranking all individuals) using solely their relationships. Intuitively, the importance assigned to an individual by our metric is proportional to the intensity of its relationship to the outside of the group. We use the proposed approach and other classical metrics to rank individuals of the Brazilian network and compare the results with the ranking of the Research Fellowship Program of CNPq (an agency of the Brazilian Ministry of Science and Technology). The direct comparison indicates the effectiveness of the proposed approach in identifying influential researchers, in particular when considering top ranked individuals. We then extend the proposed approach to rank small groups of individuals (as opposed to single individuals). We apply this and other classical metrics to rank graduate programs in Computer Science in Brazil and compare the results with the ranking of graduate programs provided by CAPES (an agency of the Brazilian Ministry of Education). Our results indicate that the proposed method can effectively identify influential groups such as well-established graduate programs in Brazil.},
  keywords = {Collaboration networks; Network structure; Node ranking}
}

@ARTICLE{Frenkel:1990,
  author = {Frenkel, Karen A.},
  title = {Women and computing},
  crossref = {journal:acm:cacm},
  volume = {33},
  number = {11},
  month = nov,
  year = {1990},
  pages = {34--46},
  doi = {10.1145/92755.92756}
}

@INPROCEEDINGS{Frieze-Quesenberry:2013,
  author = {Frieze, Carol and Quesenberry, Jeria L.},
  title = {From Difference to Diversity: Including Women in the Changing Face of Computing},
  crossref = {proceedings:sigcse:2013},
  pages = {445--450},
  doi = {10.1145/2445196.2445327},
  abstract = {In this paper we argue that gender difference thinking, with regards to attitudes towards computing, can work against diversity in the field of computing. Indeed, gender difference approaches to the participation of women in computing have not provided adequate explanations for women's declining interest in computer science (CS) and related technical fields. As yet "The Changing Face of Computing" has not led to significant changes in the levels of women's participation. Indeed, the number of computer science degrees awarded to women has steadily declined since 1984. Our objective in this paper is to present a critique on why gender difference approaches may be problematic and propose that a cultural approach offers a more effective framework for investigating and increasing women's participation in CS. We support our findings and recommendations from the most recent research in a series of studies carried out at Carnegie Mellon University (CMU) over the past 10 years. In brief, we found the Women-CS fit at CMU continues to present a positive and encouraging story. Our findings demonstrate that under certain conditions women, alongside their male peers, can fit successfully into a CS environment and help shape that environment and computing culture, for the benefit of everyone, without accommodating presumed gender differences or any compromises to academic integrity.},
  keywords = {computer science education, culture, diversity, gender differences, gender similarities, retention, women, women-cs fit}
}

@ARTICLE{Floyd-etal:2013,
  author = {Froyd, J.E. and Borrego, M. and Cutler, S. and Henderson, C. and Prince, M.J.},
  title = {Estimates of Use of Research-Based Instructional Strategies in Core Electrical or Computer Engineering Courses},
  crossref = {journal:ieee:te},
  volume = {56},
  number = {4},
  month = nov,
  year = {2013},
  pages = {393--399},
  doi = {10.1109/TE.2013.2244602},
  abstract = {Many research-based instruction strategies (RBISs) have been developed; their superior efficacy with respect to student learning has been demonstrated in many studies. Collecting and interpreting evidence about: 1) the extent to which electrical and computer engineering (ECE) faculty members are using RBISs in core, required engineering science courses, and 2) concerns that they express about using them, are important aspects of understanding how engineering education is evolving. The authors surveyed ECE faculty members, asking about their awareness and use of selected RBISs. The survey also asked what concerns ECE faculty members had about using RBISs. Respondent data showed that awareness of RBISs was very high, but estimates of use of RBISs, based on survey data, varied from 10% to 70%, depending on characteristics of the strategy. The most significant concern was the amount of class time that using an RBIS might take; efforts to increase use of RBISs must address this.},
  keywords = {Change in engineering education, diffusion of innovations, faculty adoption, faculty awareness, research-based instructional strategies (RBISs), teaching}
}

@ARTICLE{Froyd-etal:2012,
  author = {Froyd, J. E. and Wankat, P. C. and Smith, K. A.},
  title = {Five Major Shifts in 100 Years of Engineering Education},
  crossref = {journal:ieee:proceedings},
  volume = {100},
  number = {Special Centennial Issue},
  month = {13},
  year = {2012},
  pages = {1344--1360},
  doi = {10.1109/JPROC.2012.2190167},
  abstract = {In this paper, five major shifts in engineering education are identified. During the engineering science revolution, curricula moved from hands-on practice to mathematical modeling and scientific analyses. The first shift was initiated by engineering faculty members from Europe; accelerated during World War II, when physicists contributed multiple engineering breakthroughs; codified in the Grinter report; and kick-started by Sputnik. Did accreditation hinder curricular innovations? Were engineering graduates ready for practice? Spurred by these questions, the Accreditation Board for Engineering and Technology (ABET) required engineering programs to formulate outcomes, systematically assess achievement, and continuously improve student learning. The last three shifts are in progress. Since the engineering science revolution may have marginalized design, a distinctive feature of engineering, faculty members refocused attention on capstone and first-year engineering design courses. However, this third shift has not affected the two years in between. Fourth, research on learning and education continues to influence engineering education. Examples include learning outcomes and teaching approaches, such as cooperative learning and inquiry that increase student engagement. In shift five, technologies (e.g., the Internet, intelligent tutors, personal computers, and simulations) have been predicted to transform education for over 50 years; however, broad transformation has not yet been observed. Together, these five shifts characterize changes in engineering education over the past 100 years.}
}

@INPROCEEDINGS{Fucci:2014,
  author = {Fucci, Davide},
  title = {Understanding the Dynamics of Test-driven Development},
  crossref = {proceedings:icse-doctoral:2014},
  pages = {690--693},
  doi = {10.1145/2591062.2591086},
  abstract = {Test-driven development (TDD) has been the subject of several software engineering experiments. However the controversial results about its effects still need to be contextualized. This doctoral research will show how TDD could be better assessed by studying to what extent developers follow its cycle and for what kind of development tasks. This knowledge is foreseen to be beneficial for software industries willing to adopt or adapt TDD.},
  keywords = {Process conformance, Test-driven development, development task},
  owner = {magsilva},
  timestamp = {2014.08.24}
}

@INPROCEEDINGS{Fucci-Turhan:2013,
  author = {Fucci, D. and Turhan, B.},
  title = {A replicated experiment on the effectiveness of test-first development},
  crossref = {proceedings:esem:2013},
  pages = {103-112},
  doi = {10.1109/ESEM.2013.15},
  abstract = {Background: Test-first development (TF) is regarded as a development practice that can lead to better quality of software products, as well as improved developer productivity. By implementing unit tests before the corresponding production code, the tests themselves are the main driver to such improvements. The role of tests on the effectiveness of TF has been studied in a controlled experiment by Erdogmus et al. (i.e. original study). Aim: Our goal is to examine the impact of test-first (TF) development on product quality and developer productivity, specifically the role that tests play in it. Method: We replicated the original study's controlled experiment by comparing an experimental group applying TF to a control group applying a test-last approach. We then carried out a correlation study in order to understand whether the number of tests is a good predictor for external quality and/or productivity. Results: Mann-Whitney tests did not show any significant difference between the two groups in terms of number of tests written (W=114.5, p=0.38), developers' productivity (W=90, p=0.82) and external quality (W=81.55, p=0.53). In addition, while a significant correlation exists between the number of tests and productivity (Spearman's ? = 0.57, p © 2013 IEEE.},
  keywords = {experiment replication; productivity; software quality; test-driven development},
  owner = {magsilva},
  references = {Beck, K., Test-driven development: By example, ser (2003) The Addison-Wesley Signature Series, , Addison-Wesley; Astels, D., (2003) Test Driven Development: A Practical Guide, , Prentice Hall Professional Technical Reference; Shull, F., Melnik, G., Turhan, B., Layman, L., Diep, M., Erdogmus, H., What do we know about test-driven development (2010) Software, IEEE, 27 (6), pp. 16-19; Siniaalto, M., Abrahamsson, P., Does test-driven development improve the program code? Alarming results from a comparative case study (2008) Balancing Agility and Formalism in Software Engineering, pp. 143-156; Erdogmus, H., Morisio, M., Torchiano, M., On the effectiveness of the test-first approach to programming (2005) IEEE Transactions on Software Engineering, 31 (3), pp. 226-237; Juristo, N., Vegas, S., Using differences among replications of software engineering experiments to gain knowledge (2009) Proceedings of the 2009 3rd International Symposium on Empirical Software Engineering and Measurement, Ser. ESEM '09. Washington, DC, USA: IEEE Computer Society, pp. 356-366. , http://dx.doi.org/10.1109/ESEM.2009.5314236; Shull, F., Carver, J., Vegas, S., Juristo, N., The role of replications in empirical software engineering (2008) Empirical Software Engineering, 13 (2), pp. 211-218; Turhan, B., Layman, L., Diep, M., Erdogmus, H., Shull, F., (2010) How Effective Is Test Driven Development, , O'Reilly Media; Rafique, Y., Misic, V., (2012) The Effects of Test-driven Development on External Quality and Productivity: A Meta-Analysis; Xu, L.T.S., Evaluation of test-driven development: An academic case study (2009) Studies in Computational Intelligence, 253, pp. 229-238; Bhadauria, V., (2009) To Test before or to Test After-An Experimental Investigation of the Impact of Test Driven Development, , Ph.D. dissertation, The University of Texas at Arlington; Yenduri, S., Perkins, L., Impact of using test-driven development: A case study (2006) Software Engineering Research and Practice, pp. 126-129; George, B., (2002) Analysis and Quantification of Test Driven Development Approach; Canfora, G., Cimitile, A., Garcia, F., Piattini, M., Visaggio, C.A., Evaluating advantages of test driven development: A controlled experiment with professionals (2006) Proceedings of the 2006 ACM/IEEE International Symposium on Empirical Software Engineering. ACM, pp. 364-371; George, B., Williams, L., A structured experiment of test-driven development (2004) Information and Software Technology, 46 (5), pp. 337-342; Madeyski, L., (2009) Test-driven Development: An Empirical Evaluation of Agile Practice, , Springer; Huang, L., (2007) Analysis and Quantification of Test First Programming, , Ph.D. dissertation, The University of Sheffield, Aug; Pancur, M., Ciglaric, M., Impact of test-driven development on productivity, code and tests: A controlled experiment (2011) INFORMATION and SOFTWARE TECHNOLOGY, 53 (6), pp. 557-573. , Jun; Maximilien, E.M., Williams, L., Assessing test-driven development at ibm (2003) Software Engineering, 2003. Proceedings. 25th International Conference On. IEEE, pp. 564-569; Bhat, T., Nagappan, N., Evaluating the efficacy of test-driven development: Industrial case studies (2006) Proceedings of the 2006 ACM/IEEE International Symposium on Empirical Software Engineering. ACM, pp. 356-363; Melnik, G., Maurer, F., A cross-program investigation of students' perceptions of agile methods (2005) Software Engineering, 2005. ICSE 2005. Proceedings. 27th International Conference On. IEEE, pp. 481-488; Janzen, D.S., Saiedian, H., A leveled examination of test-driven development acceptance (2007) Software Engineering, 2007. ICSE 2007. 29th International Conference On. IEEE, pp. 719-722; Flohr, T., Schneider, T., Lessons learned from an xp experiment with students: Test-first needs more teachings (2006) Product-Focused Software Process Improvement, pp. 305-318; Carver, J.C., Towards reporting guidelines for experimental replications: A proposal (2010) RESER2010: Proceedings of the 1st International Workshop on Replication in Empirical Software Engineering Research, Cape Town, South Africa, 4; Wohlin, C., (2000) Experimentation in Software Engineering: An Introduction, 6. , Springer; Sato, D.T., Corbucci, H., Bravo, M.V., Coding dojo: An environment for learning and sharing agile practices (2008) Agile, 2008. AGILE'08. Conference. IEEE, pp. 459-464; Lilliefors, H.W., On the kolmogorov-smirnov test for normality with mean and variance unknown (1967) Journal of the American Statistical Association, 62 (318), pp. 399-402; Mann, H.B., Whitney, D.R., On a test of whether one of two random variables is stochastically larger than the other (1947) The Annals of Mathematical Statistics, 18 (1), pp. 50-60; Fritz, C.O., Morris, J.J., Richler, P.E., Effect size estimates: Current use, calculations, and interpretation (2012) Journal of Experimental Psychology: General, 141, pp. 2-18; Kampenes, V.B., Dyba, T., Hannay, J.E., Sjøberg, D.I., A systematic review of effect size in software engineering experiments (2007) Information and Software Technology, 49 (11), pp. 1073-1086; Howell, D.C., (2012) Statistical Methods for Psychology, , Wadsworth Publishing Company; Pena, E.A., Slate, E.H., Global validation of linear model assumptions (2006) Journal of the American Statistical Association, 101 (473), pp. 341-354; Cook, T.D., Campbell, D.T., Day, A., (1979) Quasi-experimentation: Design &Analysis Issues for Field Settings, , Houghton Mifflin Boston; Adair, J.G., The hawthorne effect: A reconsideration of the methodological artifact (1984) Journal of Applied Psychology, 69 (2), p. 334; Fay, M.P., Proschan, M.A., Wilcoxon-mann-whitney or t-test? on assumptions for hypothesis tests and multiple interpretations of decision rules (2010) Statistics Surveys, 4, p. 1; Muller, M., Hofer, A., The effect of experience on the test-driven development process (2007) Empirical Software Engineering, 12 (6), pp. 593-615; Philipp, M., (2009) Comparison of the Test-Driven Development Processes of Novice and Expert Programmer Pairs; Maxwell, S.E., Delaney, H.D., (2004) Designing Experiments and Analyzing Data; Madeyski, L., The impact of test-first programming on branch coverage and mutation score indicator of unit tests: An experiment (2010) Inf. Softw. Technol., 52 (2), pp. 169-184. , http://dx.doi.org/10.1016/j.infsof.2009.08.007, Feb; Causevic, A., Sundmark, D., Punnekkat, S., Test case quality in test driven development: A study design and a pilot experiment (2012) Evaluation Assessment in Software Engineering (EASE 2012), 16th International Conference on, pp. 223-227; Johnson, P., Kou, H., Automated recognition of test-driven development with zorro (2007) AGILE 2007. IEEE, pp. 15-25},
  timestamp = {2014.08.19}
}

@ARTICLE{Fucci-Turhan:2014,
  author = {Fucci, Davide and Turhan, Burak},
  title = {On the Role of Tests in Test-driven Development: A Differentiated and Partial Replication},
  crossref = {journal:springer:ese},
  volume = {19},
  number = {2},
  month = apr,
  year = {2014},
  pages = {277--302},
  doi = {10.1007/s10664-013-9259-7},
  abstract = {Background: Test-Driven Development (TDD) is claimed to have positive effects on external code quality and programmers' productivity. The main driver for these possible improvements is the tests enforced by the test-first nature of TDD as previously investigated in a controlled experiment (i.e. the original study). Aim: Our goal is to examine the nature of the relationship between tests and external code quality as well as programmers' productivity in order to verify/ refute the results of the original study. Method: We conducted a differentiated and partial replication of the original setting and the related analyses, with a focus on the role of tests. Specifically, while the original study compared test-first vs. test-last, our replication employed the test-first treatment only. The replication involved 30 students, working in pairs or as individuals, in the context of a graduate course, and resulted in 16 software artifacts developed. We performed linear regression to test the original study's hypotheses, and analyses of covariance to test the additional hypotheses imposed by the changes in the replication settings. Results: We found significant correlation (Spearman coefficient = 0.66, with p-value = 0.004) between the number of tests and productivity, and a positive regression coefficient (p-value = 0.011). We found no significant correlation (Spearman coefficient = 0.41 with p-value = 0.11) between the number of tests and external code quality (regression coefficient p-value = 0.0513). For both cases we observed no statistically significant interaction caused by the subject units being individuals or pairs. Further, our results are consistent with the original study although there were changes in the timing constraints for finishing the task and the enforced development processes. Conclusions: This replication study confirms the results of the original study concerning the relationship between the number of tests vs. external code quality and programmer productivity. Moreover, this replication allows us to identify additional context variables, for which the original results still hold; namely the subject unit, timing constraint and isolation of test-first process. Based on our findings, we recommend practitioners to implement as many tests as possible in order to achieve higher baselines for quality and productivity.},
  keywords = {Productivity, Replication, Software quality, Software testing, Test-driven development},
  owner = {magsilva},
  timestamp = {2014.08.31}
}

@INPROCEEDINGS{Fucci-etal:2014,
  author = {Fucci, D. and Turhan, B. and Oivo, M.},
  title = {Conformance factor in test-driven development: Initial results from an enhanced replication},
  crossref = {proceedings:ease:2014},
  doi = {10.1145/2601248.2601272},
  abstract = {Test-driven development (TDD) is an iterative software development technique where unit-tests are defined before production code. The proponents of TDD claim that it improves both external quality and developers' productivity. In particular, Erdogmus et al. (i.e., original study) proposed a two-stage model to investigate these claims regarding TDD's effects. Our aim is to enhance the model proposed in the original study by investigating an additional factor: TDD process conformance. We conducted a close, external replication of the original study accompanied by a correlation analysis to check whether process conformance is related to improvements for the subjects using TDD. We partially confirmed the results of the original study. Moreover, we observed a correlation between process conformance and quality, but not productivity. We found no evidence to support the claim that external quality and productivity are improved by the adoption of TDD compared to test-last development. Finally, conformance to TDD process improves the quality and does not affect productivity. We conclude that the role of process conformance is relevant in studying the quality and productivity-related effects of TDD. Copyright 2014 ACM.},
  keywords = {Process conformance; Test-driven development},
  owner = {magsilva},
  references = {Beck, K., (2003) Test-driven Development: By Example, , Addison-Wesley; Erdogmus, H., Morisio, M., Torchiano, M., On the effectiveness of the test-first approach to programming (2005) IEEE Transactions on Software Engineering, 31 (3), pp. 226-237; Fucci, D., Turhan, B., A replicated experiment on the effectiveness of test-first development (2013) 2013 ACM/IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM), pp. 103-112. , IEEE; Fucci, D., Turhan, B., On the role of tests in test-driven development: A differentiated and partial replication (2013) Empirical Software Engineering, pp. 1-26; Johnson, P.M., Kou, H., Automated recognition of test-driven development with zorro (2007) AGILE 2007, pp. 15-25. , IEEE; Juristo, N., Vegas, S., Using differences among replications of software engineering experiments to gain knowledge Proceedings of the 2009 3rd International Symposium on Empirical Software Engineering and Measurement, 2009, pp. 356-366. , Washington, DC, USA. IEEE Computer Society; Madeyski, L., (2009) Test-driven Development: An Empirical Evaluation of Agile Practice, , Springer; Müller, M.M., Höfer, A., The effect of experience on the test-driven development process (2007) Empirical Software Engineering, 12 (6), pp. 593-615; Philipp, M., (2009) Comparison of the Test-Driven Development Processes of Novice and Expert Programmer Pairs; Rafique, Y., Misic, V., (2013) The Effects of Test-driven Development on External Quality and Productivity: A Meta-analysis; Siniaalto, M., Abrahamsson, P., Does test-driven development improve the program code? Alarming results from a comparative case study (2008) Balancing Agility and Formalism in Software Engineering; Sørumgård, S., (1997) Verification of Process Conformance in Empirical Studies of Software Development, , Department of Computer and Information Science The Norwegian University of Science and Technology; Turhan, B., Layman, L., Diep, M., Erdogmus, H., Shull, F., (2010) How Effective Is Test Driven Development?, , O'Reilly Media; Wang, Y., Erdogmus, H., The role of process measurement in test-driven development (2004) 4th Conference on Extreme Programming and Agile Methods},
  timestamp = {2014.08.19},
  year = {2014}
}

@ARTICLE{Fuggetta:2003,
  author = {Alfonso Fuggetta},
  title = {Open source software -- an evaluation},
  crossref = {journal:elsevier:jss},
  volume = {66},
  number = {1},
  month = apr,
  year = {2003},
  pages = {77--90},
  doi = {10.1016/S0164-1212(02)00065-1},
  abstract = {The success of Linux and Apache has strengthened the opinion that the open source paradigm is one of the most promising strategies to enhance the maturity, quality, and efficiency of software development activities. This observation, however, has not been discussed in much detail and critically addressed by the software engineering community. Most of the claims associated with open source appear to be weakly motivated and articulated. For this reason, this paper proposes some qualitative reflections and observations on the nature of open source software and on the most popular and important claims associated with the open source approach. The ultimate goal of the paper is to identify the concepts and intuitions that are really peculiar to open source, and to distinguish them from features and aspects that can be equally applied to or found in proprietary software.},
  owner = {magsilva},
  review = {Paper with several definitions of open source software. There are some blunt mistakes (such as relevancy regarding IBM's contribution towards Apache -- Win32 port, nothing related to its hardware business), but, overall, it's a good paper.},
  timestamp = {2013.10.11}
}

@INPROCEEDINGS{Fuggetta:2000,
  author = {Fuggetta, Alfonso},
  title = {Software Process: A Roadmap},
  crossref = {proceedings:icse:2000},
  pages = {25--34},
  doi = {10.1145/336512.336521},
  series = {ICSE '00},
  acmid = {336521},
  address = {New York, NY, USA},
  booktitle = {Proceedings of the Conference on The Future of Software Engineering},
  isbn = {1-58113-253-0},
  location = {Limerick, Ireland},
  numpages = {10},
  owner = {magsilva},
  publisher = {ACM},
  timestamp = {2014.10.23},
  url = {http://doi.acm.org/10.1145/336512.336521},
  year = {2000}
}

@ARTICLE{Fuller-etal:2006,
  author = {Fuller, Ursula and Pears, Arnold and Amillo, June and Avram, Chris and Mannila, Linda},
  title = {A computing perspective on the Bologna process},
  crossref = {journal:acm:sigcse-bulletin},
  volume = {38},
  number = {4},
  month = jun,
  pages = {115--131},
  doi = {10.1145/1189136.1189181},
  abstract = {The Bologna process is intended to culminate in the formation of the European Higher Education Area (EHEA) by 2010. Its aim is to facilitate the mobility of people, the transparency and recognition of qualifications, quality and development of a European dimension to higher education, and the attractiveness of European institutions for third country students.This paper provides an overview of progress towards implementation in EHEA member states using official documents and interview data from faculty teaching computing in countries represented at the ITiCSE 2006 meeting. The key areas where the structures established by the Bologna process are problematic for computing education arise from the rapidly changing nature of the curriculum. It seems that the maturity and capability criteria, as well as the manner in which learning outcomes are specified, being developed within the Bologna process are too general. This endangers the properties of transparency and mobility that the process intends to promote.Progression and prerequisite knowledge in computing degrees can be very specific. For instance, generic learning outcomes for an introductory programming course quite rightly will not specify the programming language, or languages, used to implement algorithms. However, suppose a student intends to study an advanced algorithms and data structures course in which Java is the language of implementation which has an introductory course in programming as a prerequisite. If the introductory course language was Standard ML it is not clear that the prerequisite course actually provides the student with a suitable background. These types of complexities are typical of computing, where early subject curricula are not standardised nationally or internationally, and create significant hurdles for realising the Bologna objectives.},
  keywords = {Europe, bologna declaration, computer science education, standardization and curriculum issues}
}

@ARTICLE{Garcia-etal:2012,
  author = {Garcia, Daniel D. and Harvey, Brian and Segars, Luke},
  title = {{CS} principles pilot at University of California, Berkeley},
  crossref = {journal:acm:inroads},
  volume = {3},
  number = {2},
  month = jun,
  year = {2012},
  pages = {58--60},
  doi = {10.1145/2189835.2189853}
}

@ARTICLE{GarciaBorgonon-etal:2014,
  author = {L. García-Borgoñón and M. A. Barcelona and J. A. García-García and M. Alba and M. J. Escalona},
  title = {Software process modeling languages: A systematic literature review},
  crossref = {journal:ist:2014},
  volume = {56},
  number = {2},
  month = feb,
  pages = {103--116},
  doi = {10.1016/j.infsof.2013.10.001},
  abstract = {Organizations working in software development are aware that processes are very important assets as well as they are very conscious of the need to deploy well-defined processes with the goal of improving software product development and, particularly, quality. Software process modeling languages are an important support for describing and managing software processes in software-intensive organizations. This paper seeks to identify what software process modeling languages have been defined in last decade, the relationships and dependencies among them and, starting from the current state, to define directions for future research. A systematic literature review was developed. 1929 papers were retrieved by a manual search in 9 databases and 46 primary studies were finally included. Since 2000 more than 40 languages have been first reported, each of which with a concrete purpose. We show that different base technologies have been used to define software process modeling languages. We provide a scheme where each language is registered together with the year it was created, the base technology used to define it and whether it is considered a starting point for later languages. This scheme is used to illustrate the trend in software process modeling languages. Finally, we present directions for future research. This review presents the different software process modeling languages that have been developed in the last ten years, showing the relevant fact that model-based SPMLs (Software Process Modeling Languages) are being considered as a current trend. Each one of these languages has been designed with a particular motivation, to solve problems which had been detected. However, there are still several problems to face, which have become evident in this review. This let us provide researchers with some guidelines for future research on this topic. },
  keywords = {Software process modeling, Software process language, Systematic literature review}
}

@ARTICLE{GarciaBorgonon-etal:2013,
  author = {L. García-Borgoñón and M. A. Barcelona and J. A. García-García and M. Alba and M. J. Escalona},
  title = {Software Process Modeling Languages: a Systematic Literature Review},
  crossref = {journal:elsevier:ist},
  year = {2013},
  doi = {10.1016/j.infsof.2013.10.001},
  abstract = {Organizations working in software development are aware that processes are very important assets as well as they are very conscious of the need to deploy well-defined processes with the goal of improving software product development and, particularly, quality. Software process modeling languages are an important support for describing and managing software processes in software-intensive organizations. This paper seeks to identify what software process modeling languages have been defined in last decade, the relationships and dependencies among them and, starting from the current state, to define directions for future research. A Systematic Literature Review was developed. 1929 papers were retrieved by a manual search in 9 databases and 46 primary studies were finally included. Since 2000 more than 40 languages have been first reported, each of which with a concrete purpose. We show that different base technologies have been used to define software process modeling languages. We provide a scheme where each language is registered together with the year it was created, the base technology used to define it and whether it is considered a starting point for later languages. This scheme is used to illustrate the trend in software process modeling languages. Finally, we present directions for future research. Conclusion: This review presents the different software process modeling languages that have been developed in the last ten years, showing the relevant fact that model-based SPMLs (Software Process Modelling Languages) are being considered as a current trend. Each one of these languages has been designed with a particular motivation, to solve problems which had been detected. However, there are still several problems to face, which have become evident in this review. This let us provide researchers with some guidelines for future research on this topic.},
  keywords = {Software Process Modeling, Software Process Language, Systematic Literature Review }
}

@ARTICLE{Guzman-etal:2012,
  author = {García Guzmán, Javier and Martín, Diego and Urbano, Julián and Amescua, Antonio},
  title = {Practical experiences in modelling software engineering practices: The project patterns approach},
  crossref = {journal:springer:sqj},
  month = jul,
  year = {2012},
  pages = {1--30},
  doi = {10.1007/s11219-012-9177-8},
  abstract = {Software process improvement in software development organisations is a complex task that can be solved using knowledge management strategies. In this area, the definition and use of process patterns are a proven approach to apply knowledge management strategies in software engineering organisations. One of the main problems for the effective application of process patterns in the software industry is the difficulty of formalising the knowledge about the development process using these approaches. This study presents a framework to manage software project patterns. This framework (which is composed of a metamodel and a platform for patterns modelling and reuse) is able to formalise the knowledge on software development projects including software engineers' previous experience, development methodologies, references frameworks and lessons learnt. The authors carried out an empirical study at Carlos III University of Madrid, where junior software engineers used the project patterns defined in this research work. The evidences and findings obtained during the empirical study execution indicates that correctness of the pattern depends on relevance of the bibliographic references used to create it, implementation of a knowledge sharing strategy among the personnel involved and previous experience in the business areas related to the information systems being developed. The results obtained from the empirical study also envisage that the usefulness of an sdPP (Software Development Project Pattern) depends on the ease of identifying when and how to apply a specific sdPP in a software project.},
  keywords = {Software process improvement; Knowledge management; Process patterns; Process modelling; Empirical study},
  note = accepted
}

@INPROCEEDINGS{GarciaMateos-FernandezAleman:2009,
  author = {Gárcia-Mateos, Ginés and Fernández-Alemán, José Luis},
  title = {A course on algorithms and data structures using on-line judging},
  crossref = {proceedings:itcse:2009},
  pages = {45--49},
  doi = {10.1145/1562877.1562897},
  abstract = {High dropout rates are commonly the main problem we must face in Computer Science degrees. There are two main causes of dropout: the implicit complexity of the matter, and a lack of motivation among students. The second-year programming course of our university suffered dropout rates of over 70% of the more than three hundred enrolled students. In order to overcome this problem, we have adopted a new teaching methodology based on two key ideas: replacing the traditional final exam with a series of activities in a continuous evaluation context; and making those activities more appealing to the students. In particular, most of the activities are designed as on-line programming competitions; they are carried out by using a web-based automatic evaluation system, the on-line judge. Experimental results show the high effectiveness of the proposed approach. On average, the dropout rate decreased to 45% while the pass rate doubled. Some strategies are used to ensure the authorship of the programs and to detect source code plagiarism.},
  keywords = {active learning, experience report, on-line judging}
}

@ARTICLE{Garousi-Zhi:2013,
  author = {Vahid Garousi and Junji Zhi},
  title = {A Survey of Software Testing Practices in Canada},
  crossref = {journal:sciencedirect:jss},
  year = {2013},
  doi = {10.1016/j.jss.2012.12.051},
  abstract = {Software testing is an important activity in the software development life-cycle. In an earlier study in 2009, we reported the results of a regional survey of software testing practices among practitioners in the Canadian province of Alberta. To get a larger nationwide view on this topic (across Canada), we conducted a newer survey with a revised list of questions in 2010. Compared to our previous Alberta-wide survey (53 software practitioners), the nation-wide survey had largernumber of participants (246 practitioners). We report the survey design, execution and results in this article. The survey results reveal important and interesting findings about software testing practices in Canada. Whenever possible, we also compare the results of this survey to other similar studies, such as the ones conducted in the US, Sweden and Australia, and also two previous Alberta-wide surveys, including our 2009 survey. The results of our survey will be of interest to testing professionals both in Canada and world-wide. It will also benefit researchers in observing the latest trends in software testing industry identifying the areas of strength and weakness, which would then hopefully encourage further industry-academia collaborations in this area. Among the findings are the followings: (1)The importance of testing-related training is increasing, (2) Functional and unit testing are two common test types that receive the most attentionand efforts spent on them, (3) Usage of the mutation testing approach is getting attention among Canadian firms, (4)Traditional Test-last Development (TLD) style is still dominating and a few companies are attempting the new development approachessuch asTest-Driven Development (TDD), and Behavior-Driven Development (BDD), (5) in terms of the most popular test tools, NUnit and Web application testing tools overtook JUnit and IBM Rational tools, (6)Most Canadian companies use a combination of two coverage metrics: decision (branch) and condition coverage, (7) Number of passing user acceptance tests and number of defects found per day (week or month) are regarded asthe most important quality assurance metrics and decision factors to release,(8) In most Canadian companies, testers are out-numbered by developers, with ratios ranging from 1:2 to 1:5, (9) The majority of Canadian firms spent less than 40% of their efforts (budget and time) on testing during development,and (10) More than 70% of respondents participated in online discussion forums related to testing on a regular basis.},
  keywords = {Survey, software testing, industry practices, Canada}
}

@INPROCEEDINGS{garrido-gea:2002,
  author = {Garrido, José Luis and Gea, Miguel},
  title = {A Coloured Petri Net Formalisation for a UML-Based Notation Applied to Cooperative System Modelling},
  crossref = {proceedings:dsvis:2002},
  pages = {16--28},
  abstract = {New approaches are currently being adopted to address the development of cooperative systems, although not many standards exist that can be used to develop this type of interactive system. We apply the standard Unified Modelling Language (UML) notation within a methodology aimed at the analysis and design of such systems, and present a semantic formalisation of the UML notation used to model cooperative systems. The semantics and its application are described on the basis of translation schemes to Coloured Petri Nets and the benefits of formalisation are shown.},
  acmid = {680983},
  isbn = {3-540-00266-9},
  numpages = {13},
  year = {2002}
}

@ARTICLE{garrigos-etal:2010,
  author = {Irene Garrigós and Jaime Gomez and Geert-Jan Houben},
  title = {Specification of personalization in web application design},
  crossref = {journal:elsevier:ist},
  volume = {52},
  number = {9},
  year = {2010},
  pages = {991--1010},
  doi = {10.1016/j.infsof.2010.04.001},
  abstract = {Personalization of websites has become an important issue in Web modeling methods due to their big and heterogeneous audience. However, due to the existence of too many notations to represent the same design concepts in different methodologies, personalization specifications cannot be used out of the scope of a single tool or method. Moreover, in some cases, personalization is not defined as a separate aspect, being difficult to maintain and update. This paper tackles the aforementioned problems presenting a generic modeling technique to facilitate the specification of the personalization. Personalization specifications can be reused across different websites and different development environments.},
  keywords = {Personalization},
  lang = {en}
}

@ARTICLE{Garrison-Arbaugh:2007,
  author = {D. Randy Garrison and J. B. Arbaugh},
  title = {Researching the community of inquiry framework: Review, issues, and future directions},
  crossref = {journal:elsevier:ihe},
  volume = {10},
  number = {3},
  year = {2007},
  pages = {157 - 172},
  doi = {10.1016/j.iheduc.2007.04.001},
  abstract = {Since its publication in The Internet and Higher Education, Garrison, Anderson, and Archer's framework has generated substantial interest among online learning researchers. This literature review examines recent research pertaining to the overall framework as well as to specific studies on social, teaching, and cognitive presence. We then use the findings from this literature to identify potential future directions for research. Some of these research directions include the need for more quantitatively-oriented studies, the need for more cross-disciplinary studies, and the opportunities for identifying factors that moderate and/or extend the relationship between the framework's components and online course outcomes.},
  keywords = {Community of inquiry; Online learning research; Cognitive presence; Social presence; Teaching presence}
}

@INBOOK{Gavesic-etal:2006:13,
  chapter = {13},
  pages = {267-290},
  title = {Examples of Ontology},
  author = {Dragan Gasevic and Dragan Djuric and Vladan Devedzic},
  crossref = {Gavesic-etal:2006}
}

@INCOLLECTION{Gaspar:2002,
  author = {Alberto Gaspar},
  title = {A educação formal e a educação informal em ciências},
  pages = {171--183},
  crossref = {Massarani-etal:2002}
}

@INPROCEEDINGS{Gaspar-etal:2013,
  author = {Gaspar, Alessio and Langevin, Sarah and Boyer, Naomi and Tindell, Ralph},
  title = {A Preliminary Review of Undergraduate Programming Students' Perspectives on Writing Tests, Working with Others, \& Using Peer Testing},
  crossref = {proceedings:sigite:2013},
  pages = {109--114},
  doi = {10.1145/2512276.2512301},
  abstract = {Techniques such as Pair Programming, or allowing students to run their programs against a reference test harness, have demonstrated their effectiveness in improving grades or retention rates. This paper proposes to supplement the existing literature by investigating students' perceptions of the benefits of writing tests, working with other students and using Peer Testing. Responses to an online anonymous survey cast new light on the relation between testing and programming and confirm previously postulated limitations of collaborative approaches; i.e. the unbalanced nature of contributions and lack of didactic interactions in student groups. We then examine how Peer Testing is perceived and discuss its relation to both collaboration and test-based pedagogies.},
  keywords = {novice programmers, peer testing, programming pedagogy},
  owner = {magsilva},
  timestamp = {2014.08.31}
}

@INPROCEEDINGS{Gaudencio-etal:2014,
  author = {Gaudencio, Matheus and Dantas, Ayla and Guerrero, Dalton D.S.},
  title = {Can Computers Compare Student Code Solutions As Well As Teachers?},
  crossref = {proceedings:sigcse:2014},
  pages = {21--26},
  doi = {10.1145/2538862.2538973},
  abstract = {In introductory programming courses it is common to demand from students exercises based on the production of code. However, it is difficult for the teacher to give fast feedback to the students about the main solutions tried, the main errors and the drawbacks and advantages of certain solutions. If we could use automatic code comparison algorithms to build visualisation tools to support the teacher in analysing how each solution provided is similar or different from another, such information would be able to be rapidly obtained. However, can computers compare students code solutions as well as teachers? In this work we present an experiment in which we have requested teachers to compare different code solutions to the same problem. Then we have evaluated the level of agreement among each teacher comparison strategy and some algorithms generally used for plagiarism detection and automatic grading. We found out a maximum rate of 77% of agreement between one of the teachers and the algorithms, but a minimum agreement of 75%. However, for most of the teachers, the maximum agreement rate was over 90% for at least one of the automatic strategies to compare code. We have also detected that the level of agreement among teachers regarding their personal strategies to compare students solutions was between 62% and 95%, which shows that there may be more agreement between a teacher and an algorithm than between a teacher and one of her colleagues regarding their strategies to compare students' solutions. The results also seem to support that comparison of students' codes has significant potential to be automated to help teachers in their work.},
  keywords = {CS1, code comparison algorithms, programming}
}

@ARTICLE{Carrillo-etal:2012,
  author = {Juan M. Carrillo de Gea and Joaquín Nicolás and José L. Fernández Alemán and Ambrosio Toval and Christof Ebert and Aurora Vizcaíno},
  title = {Requirements engineering tools: Capabilities, survey and assessment},
  crossref = {journal:elsevier:ist},
  volume = {54},
  number = {10},
  month = oct,
  year = {2012},
  pages = {1142--1157},
  doi = {10.1016/j.infsof.2012.04.005},
  abstract = {There is a significant number of requirements engineering (RE) tools with different features and prices. However, existing RE tool lists do not provide detailed information about the features of the tools that they catalogue. It would therefore be interesting for both practitioners and tool developers to be aware of the state-of-the-art as regards RE tools. This paper presents the results of a survey answered by RE tool vendors. The purpose of the survey was to gain an insight into how current RE tools support the RE process by means of concrete capabilities, and to what degree. The ISO/IEC TR 24766:2009 is a framework for assessing RE tools' capabilities. A 146-item questionnaire based principally on the features covered by this international guideline was sent to major tool vendors worldwide. A descriptive statistical study was then carried out to provide comparability, and bivariate correlation tests were also applied to measure the association between different variables. A sample of the tools was subjected to neutral assessment and an interrater reliability analysis was performed to ensure the reliability of the results. The 38 participants sent back their answers. Most tools are delivered under a proprietary license, and their licenses are not free. A growing number of them facilitate Web access. Moreover, requirements elicitation exemplifies the best supported category of features in this study, whereas requirements modeling and management are the most badly supported categories. The RE process seems to be well covered by current RE tools, but there is still a certain margin for amelioration, principally with regard to requirements modeling, open data model and data integration features. These subjects represent areas for improvement for RE tool developers. Practitioners might also obtain useful ideas from the study to be taken into account when selecting an appropriate RE tool to be successfully applied to their work.},
  keywords = {Requirements engineering tools; Survey; ISO/IEC TR 24766:2009}
}

@ARTICLE{Genova-etal:2014,
  author = {Gonzalo Génova and Juan Llorens and Anabel Fraga},
  title = {Metamodeling generalization and other directed relationships in {UML}},
  crossref = {journal:elsevier:ist},
  volume = {56},
  number = {7},
  month = jul,
  year = {2014},
  pages = {718--726},
  doi = {10.1016/j.infsof.2014.01.010},
  abstract = {Context Generalization is a fundamental relationship in object orientation and in the UML (Unified Modeling Language). The generalization relationship is represented in the UML metamodel as a 'directed relationship'. Objective Being a directed relationship corresponds to the nature of generalization in the semantic domain of object orientation: a relationship that is directed from the subclass to the superclass. However, we claim that the particular form this relationship adopts in the metamodel is erroneous, which entails a series of inconveniencies for model manipulation tools that try to adhere to the UML specification. Moreover, we think that this error could be due to a misinterpretation of the relationships between metamodeling levels in the UML: represented reality (M0), model (M1) and metamodel (M2). This problem also affects other directed relationships: Dependency and its various subtypes, Include and Extend between use cases, and others. Method We analyze the features of the generalization relationship in various domains and how it has been metamodeled in UML. We examine the problems, both theoretical and technological, posed by the UML metamodel of generalization. We then compare it with the metamodel of other directed relationships. Results We arrive at the conclusion that the metamodel of all directed relationships could be improved. Namely, we claim that, at level M2, the metamodel should not contain any one-way meta-associations: all meta-associations should be two-way, both for practical and theoretical reasons. Conclusions The rationale for our main claim can be summarized as follows: connected graphical symbols do know each other, and the goal of a metamodel is to specify the syntactic properties of a language, ergo meta-associations must be two-way. This, of course, does not preclude at all the use of one-way associations at the user model level (M1).},
  keywords = {Unified Modeling Language, Model engineering, Metamodel, Generalization, Directed relationship },
  url = {http://www.sciencedirect.com/science/article/pii/S0950584914000214},
  issn = {0950-5849},
  journal = {Information and Software Technology }
}

@ARTICLE{Genuchten-Hatton:2013,
  author = {Genuchten, Michiel and Hatton, Les},
  title = {Metrics with Impact},
  crossref = {journal:ieee:software},
  volume = {30},
  number = {4},
  month = jul # {--} # aug,
  year = {2013},
  pages = {99--101},
  doi = {10.1109/MS.2013.81},
  abstract = {Over the past few years, metrics proposed in Impact columns such as Compound Average Growth Rate (CAGR) and software mileage have been applied in real life in organizations around the world. This issue's installment provides some examples and discusses the metrics' applicability and limitations.},
  keywords = {Performance evaluation;Software measurement;Software metrics;Software quality;compound annual growth rate;impact;metrics;software mileage}
}

@ARTICLE{George-Williams:2004,
  author = {Boby George and Laurie Williams},
  title = {A structured experiment of test-driven development },
  crossref = {journal:elsevier:ist},
  volume = {46},
  number = {5},
  month = apr,
  year = {2004},
  pages = {337--342},
  doi = {10.1016/j.infsof.2003.09.011},
  abstract = {Test Driven Development (TDD) is a software development practice in which unit test cases are incrementally written prior to code implementation. We ran a set of structured experiments with 24 professional pair programmers. One group developed a small Java program using TDD while the other (control group), used a waterfall-like approach. Experimental results, subject to external validity concerns, tend to indicate that TDD programmers produce higher quality code because they passed 18% more functional black-box test cases. However, the TDD programmers took 16% more time. Statistical analysis of the results showed that a moderate statistical correlation existed between time spent and the resulting quality. Lastly, the programmers in the control group often did not write the required automated test cases after completing their code. Hence it could be perceived that waterfall-like approaches do not encourage adequate testing. This intuitive observation supports the perception that TDD has the potential for increasing the level of unit testing in the software industry.},
  keywords = {Software engineering, Test driven development, Extreme programming, Agile methodologies }
}

@INPROCEEDINGS{Gerosa-etal:2007,
  author = {Marco Aurélio Gerosa and Celso Gomes Barreto and Hugo Fuks and Carlos José Pereira de Lucena},
  title = {Integração do AulaNet com a TV Digital},
  crossref = {proceedings:sbie:2007},
  pages = {1--4},
  abstract = {O Brasil vem se preparando para a adoção da TV digital. O potencial de disseminação desta tecnologia e a disponibilidade de conteúdos multimídia disponíveis oferecem uma abordagem promissora para o ensino- aprendizagem. O Ambiente AulaNet, utilizado para gerenciar conteúdos e para hospedar serviços colaborativos na Web, está sendo adaptado para oferecer suporte ao ensino-aprendizagem na TV digital. Neste artigo, é abordada a integração do ambiente com a infra-estrutura da TV digital.},
  abstract-en = {Brazil is getting ready for digital TV. The potential of dissemination of this technology and the availability multimedia content offer a promising approach for teaching-learning. The AulaNet environment, used to manage contents and to host collaborative services in the Web, is being adapted to offer support to teaching-learning using the digital TV. This article presents the integration of the environment with the infrastructure of the digital TV.},
  lang = {pt},
  url = {http://www.br-ie.org/pub/index.php/sbie/article/view/623}
}

@INPROCEEDINGS{Gersting:1994,
  author = {Gersting, Judith L.},
  title = {A software engineering ``frosting'' on a traditional {CS-1} course},
  crossref = {proceedings:sigcse:1994},
  pages = {233--237},
  doi = {10.1145/191029.191129}
}

@INCOLLECTION{Gibbons-etal:2001,
  author = {Andrew S. Gibbons and Jon Nelson and Robert Richards},
  title = {The Nature and Origin of Instructional Objects},
  chapter = {1.2},
  pages = {1--58},
  crossref = {Wiley:2001},
  lang = {en},
  url = {http://reusability.org/read/chapters/gibbons.doc}
}

@INBOOK{Gibbons-Rogers:2009,
  chapter = {14},
  pages = {305-326},
  title = {The Architecture of Instructional Theory},
  author = {Andrew S. Gibbons and P. Clint Rogers},
  crossref = {Reigeluth-CarrChellman:2009}
}

@ARTICLE{Gilb:1985,
  author = {Gilb, Tom},
  title = {Evolutionary Delivery Versus the ``Waterfall Model''},
  crossref = {journal:acm:sen},
  volume = {10},
  number = {3},
  month = jul,
  year = {1985},
  pages = {49--61},
  doi = {10.1145/1012483.1012490},
  abstract = {The conventional wisdom of planning software engineering projects, using the widely cited "waterfall model" is not the only useful software development process model. In fact, the "waterfall model" may be unrealistic, and dangerous to the primary objectives of any software project.The alternative model, which I choose to call "evolutionary delivery" is not widely taught or practiced yet. But there is already more than a decade of practical experience in using it. In various forms. It is quite clear from these experiences that evolutionary delivery is a powerful general tool for both software development and associated systems development.Almost all experienced software developers do make use of some of the ideas in evolutionary development at one time or another. But, this is often unplanned, informal and it is an incomplete exploitation of this powerful method. This paper will try to expose the theoretical and practical aspects of the method in a fuller perspective. We need to learn the theory fully, so that we can apply and learn it completely.},
  owner = {magsilva},
  timestamp = {2014.10.23}
}

@ARTICLE{Gilb:1981,
  author = {Gilb, Tom},
  title = {Evolutionary Development},
  crossref = {journal:acm:sen},
  volume = {6},
  number = {2},
  month = apr,
  year = {1981},
  pages = {17--17},
  doi = {10.1145/1010865.1010868},
  owner = {magsilva},
  timestamp = {2014.10.23}
}

@INPROCEEDINGS{Gimenes,
  author = {Gimenes, Itana M. S. and Barroca, Leonor and Barbosa, Ellen Francine},
  title = {The Future of Human Resources Qualifications in Software Engineering -- Meeting Demands from Industry and Benefiting from Educational and Technological Advances},
  crossref = {proceedings:sbes:2012},
  pages = {181--185},
  doi = {10.1109/SBES.2012.19},
  abstract = {The recent economic growth in Brazil has resulted in a strong demand for human resources qualification. Software Engineering education, in Brazil, offers qualifications at all levels: undergraduate, further education and postgraduate. However, current market demand indicates a mismatch between the academic provision and the industrial demand. To address this mismatch, it is important to take into account the large geographic distribution of Brazil and its regional inequalities. We suggest that innovative strategies in education including Distance Education, Open Education and Open Educational Resources will need to play an important role in the future of professional qualifications in Brazil. This raises opportunities and challenges that can only be addressed by a strong interdisciplinary research and political agenda. This paper discusses the scenario of the Software Engineering education in Brazil and presents research questions and political issues associated with the future of human resource qualification in this area.}
}

@INCOLLECTION{Gimenes-etal:2012,
  author = {Itana M. S. Gimenes and Leonor Barroca and Valéria D. Feltrim},
  title = {Tendências na Educação a Distância e Educação Aberta na Computação},
  chapter = {1},
  pages = {1--41},
  abstract = {Este curso apresenta as tendências da educação a distância e educação aberta na área de computação, considerando a evolução tecnológica e dos recursos e perspectivas da Web 2.0 (ex., redes sociais, twitters e blogs) neste contexto. O curso apresenta conceitos, a infraestrutura de apoio necessária e técnicas de projeto de aprendizagem. A educação a distância é ilustrada com experiências da Open University (Grã-Bretanha). Educação aberta e Recursos Educacionais Abertos (REAs) são apresentados como princípios distintos, mas relacionados, que compõem o cenário contemporâneo da educação aberta e a distância. Esses princípios são ilustrados com exemplos reais de cursos e REAs na área de computação. Uma seção final aponta para discussões e perspectivas atuais que influenciarão o futuro da educação. O curso busca motivar os alunos e a comunidade de computação em geral a se engajar na promoção da educação aberta e REAs, acompanhando o mesmo sucesso já obtido com a iniciativa de software livre.},
  abstract-en = {This course discusses trends in computing distance and open education. It considers recent technology developments, resources and perspectives brought about by the Web 2.0 (e.g. social networking, twitters and blogs). The course introduces concepts, the required support frameworks and learning design techniques. Distance education is illustrated with experiences from the Open University, UK. Open education and Open Education Resources (OER) are presented as distinct but interrelated principles that compose the contemporaneous scenario of distance and open education. The discussion is illustrated with real examples of courses and OERs in the area of computing. A final section highlights current debates and perspectives that will influence the future of education. The course aims to motivate students and the overall community to engage with the promotion of Open Education and OERs, as initiatives that run in parallel with the already successful Open Source movement.},
  crossref = {proceedings:csbc:2012},
  lang = {pt}
}

@ARTICLE{Ginat:2014,
  author = {Ginat, David},
  title = {Longest Sum Modulo-3},
  crossref = {journal:acm:inroads},
  volume = {5},
  number = {1},
  month = mar,
  year = {2014},
  pages = {37--38},
  doi = {10.1145/2568195.2568208},
  owner = {magsilva},
  timestamp = {2014.09.01}
}

@ARTICLE{Ginat:2012,
  author = {Ginat, David},
  title = {Rectangle cover},
  crossref = {journal:acm:inroads},
  volume = {3},
  number = {3},
  month = sep,
  year = {2012},
  pages = {34--35},
  doi = {10.1145/2339055.2339068}
}

@ARTICLE{Ginsburg-Greibah:1966,
  author = {Seymour Ginsburg and Sheila Greibach},
  title = {Deterministic context free languages },
  crossref = {journal:elsevier:ic},
  volume = {9},
  number = {6},
  month = dec,
  year = {1966},
  pages = {620--648},
  doi = {10.1016/S0019-9958(66)80019-0},
  abstract = {A number of results about deterministic languages (languages accepted by pushdown automata with no choice of moves) are established. In particular,o(1) each deterministic language is unambiguous. (2) the complement of each deterministic language is a deterministic language. (3) numerous operations which preserve deterministic languages (for example, intersection with a regular set) are obtained. (4) several problems are shown to be recursively unsolvable.},
  owner = {magsilva},
  timestamp = {2014.07.15}
}

@INBOOK{giraffa-etal:2010,
  chapter = {Ambiente Moodle: potencialidades e experiências},
  pages = {135-146},
  title = {Capacitação docente: um movimento que se faz compromisso},
  publisher = {EDIPUCRS},
  year = {2010},
  editor = {Ana Lúcia Souza de Freitas and Marlene Correro Grillo and Rosana Maria Gessinger and Valderez Marina do Rosário Lima},
  author = {Lúcia Maria Martins Giraffa and Márcia de Borba Campos and Elaine Turk Faria},
  address = {Porto Alegre, RS, Brazil},
  crossref = {freitas-etal:2010},
  owner = {magsilva},
  timestamp = {2010.08.04}
}

@ARTICLE{Giuffrida-Dittrich:2013,
  author = {Rosalba Giuffrida and Yvonne Dittrich},
  title = {Empirical studies on the use of social software in global software development -- A systematic mapping study},
  crossref = {journal:elsevier:ist},
  volume = {55},
  number = {7},
  month = jul,
  year = {2013},
  pages = {1143--1164},
  doi = {10.1016/j.infsof.2013.01.004},
  abstract = {AbstractBackground In Global Software Development (GSD), informal communication and knowledge sharing play an important role. Social Software (SoSo) has the potential to support and foster this key responsibility. Research on the use of SoSo in GSD is still at an early stage: although a number of empirical studies on the usage of SoSo are available in related fields, there exists no comprehensive overview of what has been investigated to date across them. Objective The aim of this review is to map empirical studies on the usage of SoSo in Software Engineering projects and in distributed teams, and to highlight the findings of research works which could prove to be beneficial for GSD researchers and practitioners. Method A Systematic Mapping Study is conducted using a broad search string that allows identifying a variety of studies which can be beneficial for GSD. Papers have been retrieved through a combination of automatic search and snowballing, hence a wide quantitative map of the research area is provided. Additionally, text extracts from the studies are qualitatively synthesised to investigate benefits and challenges of the use of SoSo. Results SoSo is reported as being chiefly used as a support for collaborative work, fostering awareness, knowledge management and coordination among team members. Contrary to the evident high importance of the social aspects offered by SoSo, socialisation is not the most important usage reported. Conclusions This review reports how SoSo is used in GSD and how it is capable of supporting GSD teams. Four emerging themes in global software engineering were identified: the appropriation and development of usage structures; understanding how an ecology of communication channels and tools are used by teams; the role played by SoSo either as a subtext or as an explicit goal; and finally, the surprising low percentage of observational studies.},
  keywords = {Systematic mapping study, Global software development, Distributed teams, Social media, Social software, Computer-supported cooperative work }
}

@ARTICLE{Glass:2007:softwarefun1,
  author = {Robert L. Glass},
  title = {Is Software Engineering Fun?},
  crossref = {journal:ieee:software},
  volume = {24},
  number = {1},
  month = jan,
  year = {2007},
  pages = {95--96},
  doi = {10.1109/MS.2007.18}
}

@ARTICLE{Glass:softwarefun2:2007,
  author = {Robert L. Glass},
  title = {Is Software Engineering Fun? Part 2},
  crossref = {journal:ieee:software},
  volume = {24},
  number = {2},
  month = mar # {--} # apr,
  year = {2007},
  pages = {103--104},
  doi = {10.1109/MS.2007.46},
  abstract = {The article examines 'software fun' from the viewpoint of the role of methodologies in software history. Historically, (1950s), programming was a small-scale, problem-solving activity. There were few firm requirements. Programmers worked with prototypes and used them to extend their knowledge as they created new products. In doing this, they maximized fun. The author concludes that the software process optimization approaches of the past had their place, and perhaps they still do. The methodologized approaches that today's gurus favor also had, and continue to have, their place. But there's a huge gap between "when tasks are small..." and "only valid for firm and stable requirements." The answer is a structured, object-oriented, knowledge-based prototyping paradigm based on formal specifications and proofs of correctness that combines the main features of composition and decomposition in a CASE environment using methodology-independent methods and visual programming in Ada}
}

@ARTICLE{Glass:2006,
  author = {Glass, Robert L.},
  title = {The Standish Report: Does It Really Describe a Software Crisis?},
  crossref = {journal:acm:cacm},
  volume = {49},
  number = {8},
  month = aug,
  year = {2006},
  pages = {15--16},
  doi = {10.1145/1145287.1145301},
  abstract = {Reconsidering the relevancy of a frequently cited report on software project failures.},
  owner = {magsilva},
  timestamp = {2014.09.13}
}

@ARTICLE{Glass:2004,
  author = {Glass, Robert L.},
  title = {Matching methodology to problem domain},
  crossref = {journal:acm:cacm},
  volume = {47},
  number = {5},
  month = may,
  year = {2004},
  pages = {19--21},
  doi = {10.1145/986213.986228},
  abstract = {Soliciting advice on choosing and applying appropriate software development methodologies.}
}

@ARTICLE{Glass-Vessey:2011,
  author = {Glass, Robert L. and Vessey, Iris},
  title = {Naïveté Squared: In Search of Two Taxonomies and a Mapping between Them},
  crossref = {journal:ieee-software},
  volume = {28},
  number = {5},
  month = sep # {-} # oct,
  year = {2011},
  pages = {14 -15},
  doi = {10.1109/MS.2011.89},
  abstract = {The authors describe an issue that they think is extremely important: the relationship between applications and solutions in the software engineering and information systems fields. In particular, they believe the fields desperately need a taxonomy of application domains, a taxonomy of solution approaches, and a mapping between the two. This article has a Web extra that offers an interview with one of the article's authors, Robert L. Glass, about the "dark side" of this topic.},
  issn = {0740-7459},
  journal = {Software, IEEE}
}

@INPROCEEDINGS{Gluga-etal:2012,
  author = {Gluga, Richard and Kay, Judy and Lister, Raymond and Kleitman, Sabina and Lever, Tim},
  title = {Over-confidence and confusion in using bloom for programming fundamentals assessment},
  crossref = {proceedings:sigcse:2012},
  pages = {147--152},
  doi = {10.1145/2157136.2157181},
  abstract = {A computer science student is required to progress from a novice programmer to a proficient developer through the programming fundamentals sequence of subjects. This paper deals with the capturing and representation of learning progression. The key contribution is a web-based interactive tutorial that enables computer science educators to practice applying the Bloom Taxonomy in classifying programming exam questions. The tutorial captures participant confidence and self-explanations for each Bloom classification exercise. The results of an evaluation with ten participants were analyzed for consistency and accuracy in the application of Bloom. The confidence and self-explanation measures were used to identify problem areas in the application of Bloom to programming fundamentals. The tutorial and findings are valuable contributions to future ACM/IEEE CS curriculum revisions, which are expected to have a continued emphasis on Bloom.},
  keywords = {CS1/2, assessment, bloom, competence, confidence, learning progression, maturity, pedagogy, programming}
}

@MISC{Godfrey:2009,
  author = {Michael W. Godfrey},
  title = {Anwser Commony Asked Project Questions},
  howpublished = {Statement published at IEEE Computer},
  month = jan # {--} # feb,
  year = {2009},
  crossref = {Nagappan-etal:2009}
}

@ARTICLE{Goeminne-Mens:2011,
  author = {Mathieu Goeminne and Tom Mens},
  title = {A comparison of identity merge algorithms for software repositories },
  crossref = {journal:elsevier:scp},
  doi = {10.1016/j.scico.2011.11.004},
  abstract = {Software repository mining research extracts and analyses data originating from multiple software repositories to understand the historical development of software systems, and to propose better ways to evolve such systems in the future. Of particular interest is the study of the activities and interactions between the persons involved in the software development process. The main challenge with such studies lies in the ability to determine the identities (e.g., logins or e-mail accounts) in software repositories that represent the same physical person. To achieve this, different identity merge algorithms have been proposed in the past. This article provides an objective comparison of identity merge algorithms, including some improvements over existing algorithms. The results are validated on a selection of large ongoing open source software projects. },
  keywords = {Software repository mining, Empirical software engineering, Identity merging, Open source, Software evolution, Comparison }
}

@ARTICLE{Goldberg:1991,
  author = {Goldberg, David},
  title = {What every computer scientist should know about floating-point arithmetic},
  crossref = {journal:acm:csur},
  volume = {23},
  number = {1},
  month = mar,
  year = {1991},
  pages = {5--48},
  doi = {10.1145/103162.103163},
  abstract = {Floating-point arithmetic is considered as esoteric subject by many people. This is rather surprising, because floating-point is ubiquitous in computer systems: Almost every language has a floating-point datatype; computers from PCs to supercomputers have floating-point accelerators; most compilers will be called upon to compile floating-point algorithms from time to time; and virtually every operating system must respond to floating-point exceptions such as overflow. This paper presents a tutorial on the aspects of floating-point that have a direct impact on designers of computer systems. It begins with background on floating-point representation and rounding error, continues with a discussion of the IEEE floating point standard, and concludes with examples of how computer system builders can better support floating point.},
  keywords = {NaN, denormalized number, exception, floating-point, floating-point standard, gradual underflow, guard digit, overflow, relative error, rounding error, rounding mode, ulp, underflow}
}

@ARTICLE{Goldman-etal:2010,
  author = {Goldman, Ken and Gross, Paul and Heeren, Cinda and Herman, Geoffrey L. and Kaczmarczyk, Lisa and Loui, Michael C. and Zilles, Craig},
  title = {Setting the Scope of Concept Inventories for Introductory Computing Subjects},
  crossref = {journal:acm:tce},
  volume = {10},
  number = {2},
  month = jun,
  year = {2010},
  pages = {5:1--5:29},
  doi = {10.1145/1789934.1789935},
  abstract = {A concept inventory is a standardized assessment tool intended to evaluate a student's understanding of the core concepts of a topic. In order to create a concept inventory it is necessary to accurately identify these core concepts. A Delphi process is a structured multi-step process that uses a group of experts to achieve a consensus opinion. We present the results of three Delphi processes to identify topics that are important and difficult in each of three introductory computing subjects: discrete mathematics, programming fundamentals, and logic design. The topic rankings can not only be used to guide the coverage of concept inventories, but can also be used by instructors to identify what topics merit special attention.},
  keywords = {Curriculum, concept inventory, delphi, discrete math, logic design, programming fundamentals}
}

@INPROCEEDINGS{Goldwasser:2002,
  author = {Michael H. Goldwasser},
  title = {A Gimmick to Integrate Software Testing Throughout the Curriculum},
  crossref = {proceedings:sigcse:2002},
  pages = {271--275},
  doi = {10.1145/563340.563446},
  abstract = {We discuss our experiences in which students of a programming course were asked to submit both an implementation as well as a test set. A portion of a student's grade was then devoted both to the validity of a student's program on others' test sets, as well as how that student's test set performed in uncovering flaws in others' programs. The advantages are many, as this introduces implicit principles of software testing together with a bit of fun competition. The major complication is that such an all-pairs execution of tests grows quadratically with the number of participants, necessitating a fully automated scoring system.}
}

@INPROCEEDINGS{Goldwasser:2009:GPF:1508865.1508945,
  author = {Goldwasser, Michael H. and Letscher, David},
  title = {A graphics package for the first day and beyond},
  crossref = {proceedings:sigcse:2009},
  pages = {206--210},
  doi = {10.1145/1508865.1508945},
  abstract = {We describe cs1graphics, a new Python drawing package designed with pedagogy in mind. The package is simple enough that students can sit down and make use of it from the first day of an introductory class. Yet it provides seamless support for intermediate and advanced lessons as students progress. In this paper, we discuss its versatility in the context of an introductory course. The package is available at www.cs1graphics.org.},
  keywords = {cs1, python}
}

@ARTICLE{Goldweber:2012,
  author = {Goldweber, Michael},
  title = {A day one computing for the social good activity},
  crossref = {journal:acm:inroads},
  volume = {3},
  number = {3},
  month = sep,
  year = {2012},
  pages = {46--49},
  doi = {10.1145/2339055.2339071},
  keywords = {in-class exercises, kinesthetic learning activities, socially relevant computing}
}

@ARTICLE{Goldweber:2011,
  author = {Goldweber, Michael},
  title = {TauRUs: a "Taulbee survey" for the rest of us},
  crossref = {journal:acm:inroads},
  volume = {2},
  number = {1},
  month = jun,
  year = {2011},
  pages = {38--42},
  doi = {10.1145/1963533.1963547},
  abstract = {The TauRUs survey (Taulbee For the Rest of Us) is an attempt to capture data regarding the state of computer science education at non-Ph.D. granting institutions. Annually, the Taulbee survey reports on the state of computer science programs at Ph.D. granting institutions. What this survey attempts to answer is how well does Taulbee data represent non-Ph.D. programs? If Taulbee is not representative, what are the differences between the three cohorts of programs: Ph.D. granting programs (which include Masters and undergraduate programs), Masters granting programs (which also include undergraduate programs), and undergraduate only programs.},
  keywords = {Computing, masters survey, undergraduate survey},
  acmid = {1963547},
  issue = {2},
  issue_date = {June 2011},
  lang = {en},
  numpages = {5}
}

@INPROCEEDINGS{Gomes-etal:2010,
  author = {Thiago Alencar Gomes and Rodrigo Costa Mesquita Santos and Roberto Gerson Albuquerque Azevedo and Carlos de Salles Soares Neto and Mario Meireles Teixeira},
  title = {Ferramenta de Autoria Textual para a Linguagem NCL},
  crossref = {proceedings:fisl:2010},
  pages = {1-6},
  abstract = {Este artigo apresenta a evolução da ferramenta de autoria textual NCL Eclipse, evidenciando também dados de sua utilização pela comunidade de desenvolvedores NCL, e os planos para o lançamento das futuras versões. O NCL Eclipse é um plug-in para a IDE Eclipse e proporciona um ambiente de desenvolvimento de aplicações interativas em Nested Context Language (NCL), linguagem declarativa adotada como padrão pelo Sistema Brasileiro de Televisão Digital Terrestre (SBTVD-T).}
}

@ARTICLE{Gomez-etal:2014,
  author = {Omar S. Gómez and Natalia Juristo and Sira Vegas},
  title = {Understanding Replication of Experiments in Software Engineering: A Classification},
  crossref = {journal:elsevier:ist},
  year = {2014},
  doi = {10.1016/j.infsof.2014.04.004},
  abstract = {Context Replication plays an important role in experimental disciplines. There are still many uncertainties about how to proceed with replications of SE experiments. Should replicators reuse the baseline experiment materials? How much liaison should there be among the original and replicating experimenters, if any? What elements of the experimental configuration can be changed for the experiment to be considered a replication rather than a new experiment? Objective To improve our understanding of SE experiment replication, in this work we propose a classification which is intend to provide experimenters with guidance about what types of replication they can perform. Method The research approach followed is structured according to the following activities: 1) a literature review of experiment replication in SE and in other disciplines, 2) identification of typical elements that compose an experimental configuration, 3) identification of different replications purposes and 4) development of a classification of experiment replications for SE. Results We propose a classification of replications which provides experimenters in SE with guidance about what changes can they make in a replication and, based on these, what verification purposes such a replication can serve. The proposed classification helped to accommodate opposing views within a broader framework, it is capable of accounting for less similar replications to more similar ones regarding the baseline experiment. Conclusion The aim of replication is to verify results, but different types of replication serve special verification purposes and afford different degrees of change. Each replication type helps to discover particular experimental conditions that might influence the results. The proposed classification can be used to identify changes in a replication and, based on these, understand the level of verification.},
  keywords = {Software Engineering, Experimental Software Engineering, Experimentation, Replication }
}

@ARTICLE{GonzalesBarahona-etal:2013,
  author = {Gonzalez-Barahona, Jesus M. and Izquierdo-Cortazar, Daniel and Maffulli, Stefano and Robles, Gregorio},
  title = {Understanding How Companies Interact with Free Software Communities},
  crossref = {journal:ieee:software},
  volume = {30},
  number = {5},
  month = sep # {--} # oct,
  year = {2013},
  pages = {38--45},
  doi = {10.1109/MS.2013.95},
  abstract = {Free, open source software development communities can become large and complex. They can also be a focus of interest for competing companies relying on their outcomes, with employees joining the development and maintenance effort. In those cases, it's especially important for both companies and communities to understand how this collaboration is working and how it matches their policies and expectations. This articles looks at two cases (OpenStack and WebKit) that the authors studied using analytics techniques. They conclude that such analytics can improve factual knowledge about how development communities are performing in aspects that are of interest to companies.},
  tags = {MSR, FLOSS project, company, contribution},
  timestamp = {2013-09-10}
}

@INPROCEEDINGS{Gopinath-etal:2014,
  author = {Gopinath, Rahul and Jensen, Carlos and Groce, Alex},
  title = {Code Coverage for Suite Evaluation by Developers},
  crossref = {proceedings:icse:2014},
  pages = {72--82},
  doi = {10.1145/2568225.2568278},
  abstract = {One of the key challenges of developers testing code is determining a test suite's quality -- its ability to find faults. The most common approach is to use code coverage as a measure for test suite quality, and diminishing returns in coverage or high absolute coverage as a stopping rule. In testing research, suite quality is often evaluated by a suite's ability to kill mutants (artificially seeded potential faults). Determining which criteria best predict mutation kills is critical to practical estimation of test suite quality. Previous work has only used small sets of programs, and usually compares multiple suites for a single program. Practitioners, however, seldom compare suites --- they evaluate one suite. Using suites (both manual and automatically generated) from a large set of real-world open-source projects shows that evaluation results differ from those for suite-comparison: statement (not block, branch, or path) coverage predicts mutation kills best.},
  keywords = {evaluation of coverage criteria, statistical analysis, test frameworks},
  owner = {magsilva},
  timestamp = {2014.05.22}
}

@ARTICLE{Gotel-ClelandHuang:2013,
  author = {Gotel, Olly and Cleland-Huang, Jane},
  title = {Requirements Engineering's Next Top Model},
  crossref = {journal:ieee:software},
  volume = {30},
  number = {6},
  month = nov # {--} # dec,
  year = {2013},
  pages = {24--29},
  doi = {10.1109/MS.2013.129},
  abstract = {A game-show environment let a panel competitively explore the use of various requirements modeling techniques for specifying a complex problem. Although plain old text and rich pictures emerged as the winners, real-world problems are best modeled using a variety of techniques. The Web extra at http://youtu.be/6vfIwSauj5o is an audio podcast of author Jane Cleland-Huang providing an audio recording of her Requirements column, in which she discusses how a game-show environment at the 2013 European Software Engineering Conference let a panel competitively explore the use of various requirements modeling techniques for specifying a complex problem.},
  annote = {Not quite a fair comparison, as i*, URN are requirement specification techniques and plain old text, UML, picture are just representation techniques.},
  quotes = {At the 2013 European Software Engineering Conference, Andrey Terekhov raised the question of whether any concrete empirical results determine whether text or visual models are more effective for specification purposes. First, we all agreed that it's an oversimplification of the issue that a single modeling technique is sufficient for all projects. We need to understand the nature of the problem and the skillset of the stakeholder to select appropriate techniques. Second, [...], a more effective solution on any single project will always inevitably involve a combination of techniques, at least one of which is likely to be text-based. What impedes this very obvious message is that as yet, we don't readily know which modeling approaches to use, for what purposes, at what times, and in what ways that would combine them seamlessly in support of requirements engineering activities. In practice, many projects default to the exclusive use of text in the form of "shall" statements or written scenarios simply because people aren't well versed in the use of a more diverse set of modeling techniques, and text is the common denominator.},
  owner = {magsilva},
  quality = {1},
  timestamp = {2014.01.14}
}

@INPROCEEDINGS{Gotel-etal:2008,
  author = {Gotel, Olly and Scharff, Christelle and Wildenberg, Andrew},
  title = {Teaching software quality assurance by encouraging student contributions to an open source web-based system for the assessment of programming assignments},
  crossref = {proceedings:itcse:2008},
  pages = {214--218},
  doi = {10.1145/1384271.1384329},
  abstract = {This paper presents a novel and innovative pedagogical approach for teaching software quality assurance in the undergraduate computer science curriculum. The approach is based on students contributing programming problems to an open source web-based system that is used for student practice and instructor assessment of assignments. WeBWorK, and some of the latest web-based systems, use a mechanism based on unit testing to account for variation in the way in which the same problem can be answered in an accurate manner, making such systems highly appealing for education. Tackling open-ended programming problems within WeBWorK therefore requires students to write a code fragment that is then checked for semantic correctness. Given that WeBWorK is open source, the teaching approach that we have evolved revolves around students creating their own problems for other students to practice with. This requires students to construct comprehensive unit tests that can assure both the usability and accuracy of their work prior to deployment. The paper describes this approach, gives examples of student work, presents findings from the experience of using the approach in the classroom, and discusses broader lessons and reasons for integrating software quality assurance practices into the computer science curriculum.},
  keywords = {automated assessment systems, java, junit, open source, peer review, programming, requirements, software quality assurance, unit testing, webwork}
}

@ARTICLE{Goth:2012,
  author = {Goth, Greg},
  title = {Next-Generation Wi-Fi: As Fast as We'll Need?},
  crossref = {journal:ieee:internet-computing},
  volume = {16},
  number = {6},
  month = nov # {--} # dec,
  year = {2012},
  pages = {7--9},
  doi = {10.1109/MIC.2012.136},
  abstract = {The latest generation of 802.11, 802.11ac, is slated to be officially approved by the end of 2013. It's expected to bring further diminution of wired infrastructure within areas such as manufacturing floors and campus uses. The faster 802.11ac technology will also likely boost aggregate performance of legacy Wi-Fi networks, and its wider channels could deliver more data to end devices.}
}

@INPROCEEDINGS{Gotlieb-Petit:2009,
  author = {Gotlieb, A. and Petit, M.},
  title = {Towards a Theory for Testing Non-terminating Programs},
  crossref = {proceedings:compsac:2009},
  pages = {160--165},
  doi = {10.1109/COMPSAC.2009.30},
  abstract = {Non-terminating programs are programs that legally perform unbounded computations. Though they are ubiquitous in real-world applications, testing these programs requires new theoretic developments as usual definitions of test data adequacy criteria ignore infinite paths.This paper develops a theory of program-based structural testing based on operational semantics. Reasoning at the program semantics level permits to cope with infinite paths (and non-feasible paths) when defining test data adequacy criteria. As a result, our criteria respect the first Weyuker's property on finite applicability, even for non-terminating programs. We discuss the consequences of this re-interpretation of test data adequacy criteria w.r.t. existing test coverage criteria.}
}

@ARTICLE{Gotterbarn:2012,
  author = {Gotterbarn, Don},
  title = {Professional trust and privacy: the dangers of silo thinking},
  crossref = {journal:acm:inroads},
  volume = {3},
  number = {2},
  month = jun,
  year = {2012},
  pages = {4--5},
  doi = {10.1145/2189835.2189836}
}

@ARTICLE{Gotterbarn:2009,
  author = {Gotterbarn, Don},
  title = {Thinking professionally: professional computer ethics: "i didn't do it" is not good enough},
  crossref = {journal:acm:inroads},
  volume = {41},
  number = {2},
  month = jun,
  year = {2009},
  pages = {65--66},
  doi = {10.1145/1595453.1595465}
}

@ARTICLE{Goulding:2013,
  author = {Goulding, Tom},
  title = {A first semester freshman project: the enigma encryption system in {C}},
  crossref = {journal:acm:inroads},
  volume = {4},
  number = {1},
  month = mar,
  year = {2013},
  pages = {43--46},
  doi = {10.1145/2432596.2432613},
  abstract = {This case study continues our effort to introduce complex systems development projects into the college curriculum at the earliest possible moment. In our previous work, we demonstrated that sophomores were quite capable of developing a complex encryption system in assembly language; we also discussed the success of second semester freshman developing multi-game, client-server casino systems in C#. Our next pedagogical challenge was to determine whether freshman could master the basics of C programming rapidly enough to complete the WWII German Encryption system during their first semester in college. In this article we describe how a project based learning pedagogy, combined with a Socratic-like method, once again led entering freshmen to success.},
  keywords = {encryption, game development, software engineering}
}

@INPROCEEDINGS{Gousios:2014:LGG:2597073.2597126,
  author = {Gousios, Georgios and Vasilescu, Bogdan and Serebrenik, Alexander and Zaidman, Andy},
  title = {Lean {GHTorrent}: {GitHub} Data on Demand},
  crossref = {proceedings:msr:2014},
  pages = {384--387},
  doi = {10.1145/2597073.2597126},
  abstract = {In recent years, GitHub has become the largest code host in the world, with more than 5M developers collaborating across 10M repositories. Numerous popular open source projects (such as Ruby on Rails, Homebrew, Bootstrap, Django or jQuery) have chosen GitHub as their host and have migrated their code base to it. GitHub offers a tremendous research potential. For instance, it is a flagship for current open source development, a place for developers to showcase their expertise to peers or potential recruiters, and the platform where social coding features or pull requests emerged. However, GitHub data is, to date, largely underexplored. To facilitate studies of GitHub, we have created GHTorrent, a scalable, queriable, offline mirror of the data offered through the GitHub REST API. In this paper we present a novel feature of GHTorrent designed to offer customisable data dumps on demand. The new GHTorrent data-on-demand service offers users the possibility to request via a web form up-to-date GHTorrent data dumps for any collection of GitHub repositories. We hope that by offering customisable GHTorrent data dumps we will not only lower the "barrier for entry" even further for researchers interested in mining GitHub data (thus encourage researchers to intensify their mining efforts), but also enhance the replicability of GitHub studies (since a snapshot of the data on which the results were obtained can now easily accompany each study).},
  keywords = {GitHub, data on demand, dataset},
  owner = {magsilva},
  timestamp = {2014.05.21}
}

@MASTERSTHESIS{GraciottoSilva:2005,
  author = {Graciotto Silva, Marco Aurélio},
  title = {Uma ferramenta {Web} colaborativa para apoiar a engenharia de requisitos em software livre},
  keywords = {Requirement engineering, free software, wiki},
  school = {Universidade de São Paulo},
  year = {2005},
  advisor = {Renata Pontin de Mattos Fortes},
  address = {São Carlos, SP, } # Brazil,
  month = {nov},
  url = {http://www.teses.usp.br/teses/disponiveis/55/55134/tde-28042006-080550/publico/dissertacao-v2.pdf},
  crossref = {proceedings:std:icmc:2006},
  owner = {magsilva},
  pages = {1-12},
  timestamp = {2006.09.28}
}

@INPROCEEDINGS{GraciottoSilva-etal:2011:FIE,
  author = {Graciotto Silva, Marco Aurélio and Ellen Francine Barbosa and José Carlos Maldonado},
  title = {Model-driven development of learning objects},
  crossref = {proceedings:fie:2011},
  pages = {F4E-1 -- F4E6},
  doi = {10.1109/FIE.2011.6143024},
  abstract = {The development of effective learning objects that explores blended learning, collaborative, and open development requires a laborious process. Information created and used at each phase of the process must be manually translated and augmented until achieving a proper product. The issue of systematic development of learning objects can be addressed using model-driven development. In fact, each phase in the development of learning objects requires a specific type of user/developer profile and generates different models. This article defines a model-driven approach for the open and collaborative development of learning objects. The approach herein described uses concept maps, represented as CXL documents, and statechart-based models, which are represented as UML models in XMI documents. Finally, the later model is used to generate learning objects, given a specific platform description. The current implementation supports the generation of slides in LaTeX/Beamer format. The feasibility of the approach is demonstrated using a course on software testing for undergraduate students, with learning objects generated for a context that comprises both traditional classroom and blended learning.},
  keywords = {concept map, learning object, model-driven development, Statecharts, UML profile}
}

@INPROCEEDINGS{Graham-Latulipe:2003,
  author = {Graham, Sandy and Latulipe, Celine},
  title = {{CS} girls rock: sparking interest in computer science and debunking the stereotypes},
  crossref = {proceedings:sigcse:2003},
  pages = {322--326},
  doi = {10.1145/611892.611998},
  abstract = {Declining female enrollment in undergraduate Computer Science programs is a serious problem. Part of the solution lies in retaining more of the female students currently enrolled; even more important, however, is increasing initial enrollment. Many believe lack of interest to be rooted in stereotypes of computer science formed early in high school: that it is a boring subject, devoid of interesting applications and stimulating only to 'geeks'. To attract high school females to CS, and to determine whether early exposure to the interesting breadth of CS and its applications might ameliorate such attitudes, a week-long Computer Science Seminar for Grade 9 and 10 girls was held at the University of Waterloo. The seminar consisted of lectures, labs and activities chosen to demonstrate the breadth of CS and to dispel the negative stereotypes. Pre- and post-seminar surveys indicate a substantial increase in interest, translating directly into increased desire to take high school CS courses.},
  keywords = {diversity, enrichment program, enrollment, gender, high school, stereotypes, women}
}

@INPROCEEDINGS{Greiler:2012:TCS:2337223.2337253,
  author = {Greiler, Michaela and Deursen, Arie van and Storey, Margaret-Anne},
  title = {Test confessions: a study of testing practices for plug-in systems},
  crossref = {proceedings:icse:2012},
  pages = {244--254},
  doi = {10.1109/ICSE.2012.6227189},
  abstract = {Testing plug-in based systems is challenging due to complex interactions among many different plug-ins, and variations in version and configuration. The objective of this paper is to find out how developers address this test challenge. To that end, we conduct a qualitative (grounded theory) study, in which we interview 25 senior practitioners about how they test plug-ins and applications built on top of the Eclipse plug-in framework. The outcome is an overview of the testing practices currently used, a set of identified barriers limiting the adoption of test practices, and an explanation of how limited testing is compensated by self-hosting of projects and by involving the community. These results are supported by a structured survey of more than 150 professionals. The study reveals that unit testing plays a key role, whereas plug-in specific integration problems are identified and resolved by the community. Based on our findings, we propose a series of recommendations and areas for future research.},
  keywords = {Eclipse; grounded theory; plug-in architectures; open source software development}
}

@ARTICLE{Griffiths-Steyvers:2004,
  author = {Griffiths, Thomas L. and Steyvers, Mark},
  title = {Finding scientific topics},
  crossref = {journal:nas:pnas},
  volume = {101},
  number = {Suppl. 1},
  month = apr,
  year = {2004},
  pages = {5228--5235},
  doi = {10.1073/pnas.0307752101},
  abstract = {A first step in identifying the content of a document is determining which topics that document addresses. We describe a generative model for documents, introduced by Blei, Ng, and Jordan [Blei, D. M., Ng, A. Y. & Jordan, M. I. (2003) J. Machine Learn. Res. 3, 993-1022], in which each document is generated by choosing a distribution over topics and then choosing each word in the document from a topic selected according to this distribution. We then present a Markov chain Monte Carlo algorithm for inference in this model. We use this algorithm to analyze abstracts from PNAS by using Bayesian model selection to establish the number of topics. We show that the extracted topics capture meaningful structure in the data, consistent with the class designations provided by the authors of the articles, and outline further applications of this analysis, including identifying hot topics by examining temporal dynamics and tagging abstracts to illustrate semantic content.}
}

@ARTICLE{Groce-etal:2014,
  author = {Groce, A. and Kulesza, T. and Zhang, C. and Shamasunder, S. and Burnett, M. and Wong, W.-K. and Stumpf, S. and Das, S. and Shinsel, A. and Bice, F. and McIntosh, K.},
  title = {You Are the Only Possible Oracle: Effective Test Selection for End Users of Interactive Machine Learning Systems},
  crossref = {journal:ieee:tse},
  volume = {40},
  number = {3},
  month = mar,
  year = {2014},
  pages = {307--323},
  doi = {10.1109/TSE.2013.59},
  abstract = {How do you test a program when only a single user, with no expertise in software testing, is able to determine if the program is performing correctly? Such programs are common today in the form of machine-learned classifiers. We consider the problem of testing this common kind of machine-generated program when the only oracle is an end user: e.g., only you can determine if your email is properly filed. We present test selection methods that provide very good failure rates even for small test suites, and show that these methods work in both large-scale random experiments using a gold standard and in studies with real users. Our methods are inexpensive and largely algorithm-independent. Key to our methods is an exploitation of properties of classifiers that is not possible in traditional software testing. Our results suggest that it is plausible for time-pressured end users to interactively detect failures -- even very hard-to-find failures -- without wading through a large number of successful (and thus less useful) tests. We additionally show that some methods are able to find the arguably most difficult-to-detect faults of classifiers: cases where machine learning algorithms have high confidence in an incorrect result.},
  keywords = {Machine learning, end-user testing, test suite size},
  owner = {magsilva},
  timestamp = {2014.04.07}
}

@ARTICLE{Gubbi-etal:2013,
  author = {Gubbi, Jayavardhana and Buyya, Rajkumar and Marusic, Slaven and Palaniswami, Marimuthu},
  title = {{Internet of Things} ({IoT}): A Vision, Architectural Elements, and Future Directions},
  crossref = {journal:elsevier:fgcs},
  volume = {29},
  number = {7},
  month = sep,
  year = {2013},
  pages = {1645--1660},
  doi = {10.1016/j.future.2013.01.010},
  abstract = {Ubiquitous sensing enabled by Wireless Sensor Network (WSN) technologies cuts across many areas of modern day living. This offers the ability to measure, infer and understand environmental indicators, from delicate ecologies and natural resources to urban environments. The proliferation of these devices in a communicating-actuating network creates the Internet of Things (IoT), wherein sensors and actuators blend seamlessly with the environment around us, and the information is shared across platforms in order to develop a common operating picture (COP). Fueled by the recent adaptation of a variety of enabling wireless technologies such as RFID tags and embedded sensor and actuator nodes, the IoT has stepped out of its infancy and is the next revolutionary technology in transforming the Internet into a fully integrated Future Internet. As we move from www (static pages web) to web2 (social networking web) to web3 (ubiquitous computing web), the need for data-on-demand using sophisticated intuitive queries increases significantly. This paper presents a Cloud centric vision for worldwide implementation of Internet of Things. The key enabling technologies and application domains that are likely to drive IoT research in the near future are discussed. A Cloud implementation using Aneka, which is based on interaction of private and public Clouds is presented. We conclude our IoT vision by expanding on the need for convergence of WSN, the Internet and distributed computing directed at technological research community.},
  keywords = {Cloud computing, Internet of Things, RFID, Smart environments, Ubiquitous sensing, Wireless sensor networks},
  owner = {magsilva},
  timestamp = {2014.09.04}
}

@ARTICLE{Guerra:2014,
  author = {Guerra, Eduardo},
  title = {Designing a Framework with Test-Driven Development: A Journey},
  crossref = {journal:ieee:software},
  volume = {31},
  number = {1},
  month = jan,
  year = {2014},
  pages = {9--14},
  doi = {10.1109/MS.2014.3},
  abstract = {Usually we read about agile development practices that seem like no more than hand waving. If that's how you feel, you'll enjoy traveling this detailed design journey and seeing up close how test-driven development (TDD) and refactoring are done in an agile environment. This article is especially insightful because of the collaborative shepherding by Rebecca Wirfs-Brock.}
}

@INPROCEEDINGS{Guimares-etal:2008,
  author = {Rodrigo Laiola Guimarães and Romualdo Monteiro de Resende Costa and Luiz Fernando Gomes Soares},
  title = {Composer: Authoring Tool for {iTV} Programs},
  crossref = {proceedings:euroitv:2008},
  pages = {61-71},
  doi = {10.1007/978-3-540-69478-6},
  abstract = {This paper presents Composer, an authoring tool to help creating interactive TV programs for the Brazilian Terrestrial Digital TV System. In Composer, several abstractions are defined creating different document views (structural, temporal, layout and textual). One of these views, the temporal view, preserves as much as possible the timeline paradigm, so popular in TV program editing. Using this view, authoring can be done by placing media objects on a time axis, however, preserving the relative relationships among them. Moreover, non-deterministic time events, like viewer interactions and content adaptations, can also be represented in the temporal view. In addition, the occurrence of these unpredictable events can be simulated, and the resulting TV program played, from any starting point. Besides other facilities provided by its four views, Composer also supports third-party views created as add-ons, and live program editing.},
  keywords = {Authoring tool, Digital TV, Interactivity, Temporal and spatial synchronization, Composer, NCL, SBTVD}
}

@ARTICLE{Gurko:2011,
  author = {Krista L. Gurko},
  title = {{CAPES}/{FIPSE} year one experience report: why begin with math learning objects?},
  crossref = {journal:educa:etd},
  volume = {12},
  number = {3},
  month = jan # {--} # apr,
  year = {2011},
  pages = {252--267},
  abstract = {This experience report describes one student's perspective about being a part of the first CAPES/FIPSE exchange session that brought her to study at Universidade Estadual de Campinas (UNICAMP) in Brazil from Utah State University (USU) in the United States. In June and July 2010, this student joined two other university students to present the CAPES/FIPSE project and the related math learning objects at four schools in Campinas. This article provides an overview of the project and offers this student's thoughts about possible reasons for the instructors' immediate responses and future plans with the digital learning objects.},
  keywords = {CAPES/FIPSE; International student exchange; Digital learning objects; Cultural affordances; Instructor education}
}

@ARTICLE{Gutierrez-Sanders:2009,
  author = {Gutiérrez, Juan M. and Sanders, Ian D.},
  title = {Computer science education in Peru: a new kind of monster?},
  crossref = {journal:acm:inroads},
  volume = {41},
  number = {2},
  month = jun,
  year = {2009},
  pages = {86--89},
  doi = {10.1145/1595453.1595481},
  abstract = {Peruvian law requires that prospective school teachers be graduates of institutions which focus on preparing them into the pedagogical aspects of teaching. Unfortunately in the area of computing we believe that the prospective teachers do not receive enough subject specific training. In addition, the legal requirement means that CS graduates, without teaching qualifications, are disadvantaged if they attempt to become teachers. The result is that computer science education in high schools has become sterile and uninteresting. We provide an analysis of the academic status of these future teachers, with recommendations geared towards academic and curricular change in this area.},
  keywords = {K-12 curriculum, computer science education, prospective teachers}
}

@ARTICLE{Guttag:1977,
  author = {Guttag, John},
  title = {Abstract data types and the development of data structures},
  crossref = {journal:acm:cacm},
  volume = {20},
  number = {6},
  month = jun,
  year = {1977},
  pages = {396--404},
  doi = {10.1145/359605.359618},
  abstract = {Abstract data types can play a significant role in the development of software that is reliable, efficient, and flexible. This paper presents and discusses the application of an algebraic technique for the specification of abstract data types. Among the examples presented is a top-down development of a symbol table for a block structured language; a discussion of the proof of its correctness is given. The paper also contains a brief discussion of the problems involved in constructing algebraic specifications that are both consistent and complete.},
  keywords = {abstract data type, correctness proof, data structure, data type, software specification, specification}
}

@INCOLLECTION{Guttag:2002,
  author = {John V. Guttag},
  title = {Abstract Data Types, Then and Now},
  chapter = {13},
  pages = {357--366},
  abstract = {Data abstraction has come to play an important role in software development. This paper presents one view of what data abstraction is, how it was viewed when it was introduced, and its long-term impact on programming.},
  crossref = {Broy-Denert:2002}
}

@INPROCEEDINGS{Guy-etal:2013,
  author = {Guy, Ido and Avraham, Uri and Carmel, David and Ur, Sigalit and Jacovi, Michal and Ronen, Inbal},
  title = {Mining Expertise and Interests from Social Media},
  crossref = {proceedings:www:2013},
  pages = {515--526},
  abstract = {The rising popularity of social media in the enterprise presents new opportunities for one of the organization's most important needs--expertise location. Social media data can be very useful for expertise mining due to the variety of existing applications, the rich metadata, and the diversity of user associations with content. In this work, we provide an extensive study that explores the use of social media to infer expertise within a large global organization. We examine eight different social media applications by evaluating the data they produce through a large user survey, with 670 enterprise social media users. We distinguish between two semantics that relate a user to a topic: expertise in the topic and interest in it and compare these two semantics across the different social media applications.},
  keywords = {enterprise, enterprise 2.0, expert finding, expert recommendation, expert search, expertise location, interest mining, people search, social business, social computing, social media, social software, web 2.0}
}

@INPROCEEDINGS{Guzdial:2013,
  author = {Guzdial, Mark},
  title = {Exploring Hypotheses About Media Computation},
  crossref = {proceedings:iter:2013},
  pages = {19--26},
  doi = {10.1145/2493394.2493397},
  abstract = {Research in computing education has been criticized as "Marco Polo," e.g., the researchers tried something and reported what happened. Our developing field needs more hypothesis-driven and theory-driven research. We will get there by making clear our goals and hypotheses, testing those goals and hypotheses explicitly, and critically reconsidering our results. My colleagues and I designed and evaluated a media-centric introductory computing approach ("Media Computation") over the last ten years. We started from a "Marco Polo" style and an explicit set of hypotheses. We have worked to test those hypotheses and to understand the outcomes. Our iterative effort has led us to explore deeper theory around motivation and learning. This paper serves as an example of a ten year research program that resulted in more hypotheses, a more elaborated theory, and a better understanding of the potential impacts of a computer science curriculum change.},
  keywords = {assessment, broadening participation, curriculum, education research, motivation, retention, under-represented minorities, women in computing}
}

@ARTICLE{Guzdial-Adams:2014,
  author = {Guzdial, Mark and Adams, Joel C.},
  title = {{MOOCs} Need More Work; So Do {CS} Graduates},
  crossref = {journal:acm:cacm},
  volume = {57},
  number = {1},
  month = jan,
  year = {2014},
  pages = {18--19},
  doi = {10.1145/2555813},
  abstract = {Mark Guzdial assesses the first full year of massive open online courses, while Joel C. Adams considers the employment outlook for CS grads.},
  owner = {magsilva},
  timestamp = {2014.05.22}
}

@ARTICLE{Hadar-Leron:2008,
  author = {Hadar, Irit and Leron, Uri},
  title = {How Intuitive is Object-oriented Design?},
  crossref = {journal:acm:cacm},
  volume = {51},
  number = {5},
  month = may,
  year = {2008},
  pages = {41--46},
  doi = {10.1145/1342327.1342336},
  abstract = {Intuition is a powerful tool that helps us navigate through life, but it can get in the way of more formal processes.},
  owner = {magsilva},
  timestamp = {2014.07.18}
}

@ARTICLE{Haigh:2014:,
  author = {Haigh, Thomas},
  title = {Actually, {Turing} Did Not Invent the Computer},
  crossref = {journal:acm:cacm},
  volume = {57},
  number = {1},
  month = jan,
  year = {2014},
  pages = {36--41},
  doi = {10.1145/2542504},
  abstract = {Separating the origins of computer science and technology.},
  owner = {magsilva},
  timestamp = {2014.05.22}
}

@ARTICLE{Halasz-Schwartz:1994,
  author = {Frank Halasz and Mayer Schwartz},
  title = {The {Dexter} hypertext reference model},
  crossref = {journal:acm:cacm},
  volume = {37},
  number = {2},
  month = feb,
  year = {1994},
  pages = {30-39},
  doi = {10.1145/175235.175237},
  lang = {en},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@ARTICLE{Hall-etal:2012,
  author = {Hall, Morgan and Laughter, Keri and Brown, Jessica and Day, Chelynn and Thatcher, Christopher and Bryce, Renee},
  title = {An empirical study of programming bugs in {CS1}, {CS2}, and {CS3} homework submissions},
  crossref = {journal:ccsc:jcsc},
  volume = {28},
  number = {2},
  month = dec,
  year = {2012},
  pages = {87--94},
  abstract = {In this work, we use the IEEE Standard for Software Anomalies to classify the types of bugs that CS1, CS2, and CS3 students submit on programming assignments over the course of one semester. We also classify the types of bugs that students bring to a Computer Science Tutor Lab so that we can compare the types of bugs that students seek help for in comparison to those in their homework submissions. Using nine high level categories, Logic problems are the most common type of problem brought to the tutor lab (58% of tutor visits) and also the most frequent as observed on homework submissions (30%). However, the frequency of Logic problems brought to the tutor lab was quite higher than those in homework submissions. Computational and Data problems accounted for much of this difference. These results are being used in our ongoing work that strives to help students to avoid the most common bugs that are brought to our tutor lab and submitted on assignments.}
}

@ARTICLE{Hamburgen-etal:2001,
  author = {Hamburgen, W.R. and Wallach, D.A. and Viredaz, M.A. and Brakmo, L.S. and Waldspurger, C.A. and Bartlett, J.F. and Mann, T. and Farkas, K.I.},
  title = {Itsy: stretching the bounds of mobile computing},
  crossref = {journal:ieee:computer},
  volume = {34},
  number = {4},
  month = apr,
  year = {2001},
  pages = {28--36},
  doi = {10.1109/2.917534},
  abstract = {The Compaq Itsy, a prototype pocket computer that has enough processing power and memory capacity to run cycle-hungry applications such as continuous-speech recognition and real-time MPEG-1 movie decoding, has proved to be a useful experimental tool for interesting applications, systems work and power studies}
}

@INPROCEEDINGS{Hammond-Umphress:2012,
  author = {Hammond, Susan and Umphress, David},
  title = {Test Driven Development: The State of the Practice},
  crossref = {proceedings:acm-se:2012},
  pages = {158--163},
  doi = {10.1145/2184512.2184550},
  abstract = {Test-Driven Development has been a practice used primarily in agile software development circles for a little more than a decade now. In software development circles, this is a relatively young and immature practice. How much acceptance has it gained it its short life span? What do we know about its effectiveness? This paper will explore these topics.},
  keywords = {agile software development, test-driven development},
  owner = {magsilva},
  timestamp = {2014.08.19}
}

@ARTICLE{HamouLhadj-Lethbridge:2012,
  author = {Hamou-Lhadj, Abdelwahab and Lethbridge, Timothy C.},
  title = {A metamodel for the compact but lossless exchange of execution traces},
  crossref = {journal:springer:sosym},
  volume = {11},
  number = {1},
  month = feb,
  year = {2012},
  pages = {77--98},
  doi = {10.1007/s10270-010-0180-x},
  abstract = {Understanding the behavioural aspects of a software system can be made easier if efficient tool support is provided. Lately, there has been an increase in the number of tools for analysing execution traces. These tools, however, have different formats for representing execution traces, which hinders interoperability and limits reuse and sharing of data. To allow for better synergies among trace analysis tools, it would be beneficial to develop a standard format for exchanging traces. In this paper, we present a graph-based format, called compact trace format (CTF), which we hope will lead the way towards such a standard. CTF can model traces generated from a variety of programming languages, including both object-oriented and procedural ones. CTF is built with scalability in mind to overcome the vast size of most interesting traces. Indeed, the design of CTF is based on the idea that call trees can be transformed into more compact ordered acyclic directed graphs by representing similar subtrees only once. CTF is also supported by our trace analysis tool SEAT (Software Exploration and Analysis Tool).},
  keywords = {Dynamic analysis, Exchange format, Execution traces, Metamodelling}
}

@INPROCEEDINGS{Han-Kramer:2009,
  author = {Peng Han and Bernd J. Krämer},
  title = {Generating Interactive Learning Objects from Configurable Samples},
  crossref = {proceedings:elml:2009},
  pages = {1-6},
  doi = {10.1109/eLmL.2009.9},
  abstract = {Pedagogically well-designed interactive learning objects (LOs) can help students to better understand complex concepts and processes. Such LOs can stimulate higher-level cognitive skills by involving students in interactive learning activities. The design and implementation of interactive LOs is, however, time-consuming and requires special skills. LOs are also often localized and tightly connected with particular educational scenarios, which strongly limits their reuse in different contexts. In this article, we present a methodology of developing and reusing interactive learning objects relying on a heuristic principle. It suggests keeping content and educational context separate at design time and connecting both facets of LOs only at reuse time. We illustrate this principle both for Java applets and for interactive Flash animations. Building on top of Adobe's Flex technology, we also suggest to separate the design of generic Flash animation templates from the pedagogically motivated interaction logics. Three simple examples illustrate our method.},
  owner = {magsilva},
  year = {2009}
}

@ARTICLE{Hanssen-etal:2014,
  author = {Geir K. Hanssen and Carina Frota Alves and Jan Bosch},
  title = {Special issue editorial: Understanding software ecosystems },
  crossref = {journal:elsevier:ist},
  volume = {56},
  number = {11},
  month = nov,
  year = {2014},
  pages = {1421--1422},
  doi = {10.1016/j.infsof.2014.06.013},
  owner = {magsilva},
  timestamp = {2014.09.13}
}

@ARTICLE{Harel-Gery:1997,
  author = {Harel, D. and Gery, E.},
  title = {Executable object modeling with statecharts},
  crossref = {journal:ieee:computer},
  volume = {30},
  number = {7},
  month = jul,
  year = {1997},
  pages = {31--42},
  doi = {10.1109/2.596624},
  abstract = {Statecharts, popular for modeling system behavior in the structural analysis paradigm, are part of a fully executable language set for modeling object-oriented systems. The languages form the core of the emerging Unified Modeling Language. The authors embarked on an effort to develop an integrated set of diagrammatic languages for object modeling, built around statecharts, and to construct a supporting tool that produces a fully executable model and allows automatic code synthesis. The language set includes two constructive modeling languages (languages containing the information needed to execute the model or translate it into executable code)},
  keywords = {Unified Modeling Language;automatic code synthesis;constructive modeling languages;executable object modeling;fully executable language set;fully executable model;integrated diagrammatic languages;object-oriented system modelling;statecharts;structural analysis paradigm;system behavior modeling;automatic programming;object-oriented languages;object-oriented methods;object-oriented programming;simulation languages;software tools;}
}

@ARTICLE{Harel-Kahana:1992,
  author = {Harel, David and Kahana, Chaim-arie},
  title = {On statecharts with overlapping},
  crossref = {journal:acm:tosem},
  volume = {1},
  number = {4},
  month = oct,
  year = {1992},
  pages = {399--421},
  doi = {10.1145/136586.136589},
  abstract = {The problem of extending the language of statecharts to include overlapping states is considered. The need for such an extension is motivated and the subtlety of the problem is illustrated by exhibiting the shortcomings of naive approaches. The syntax and formal semantics of our extension are then presented, showing in the process that the definitions for conventional statecharts constitute a special case. Our definitions are rather complex, a fact that we feel points to the inherent difficulty of such an extension. We thus prefer to leave open the question of whether or not it should be adopted in practice.},
  keywords = {higraphs, reactive systems, statecharts, visual language}
}

@ARTICLE{Harel-Naamad:1996,
  author = {D. Harel and A. Naamad},
  title = {The {STATEMATE} Semantics of Statecharts},
  crossref = {journal:acm:tosem},
  volume = {5},
  number = {4},
  month = oct,
  year = {1996},
  pages = {293--333},
  doi = {10.1145/235321.235322},
  abstract = {We describe the semantics of statecharts as implemented in the STATEMATE system. This was the first executable semantics defined for the language and has been in use for almost a decade. In terms of the controversy around whether changes made in a given step should take effect in the current step or in the next one, this semantics adopts the latter approach.},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@ARTICLE{Hasni-Lodhi:2011,
  author = {Hasni, Tahreem Fatima and Lodhi, Fakhar},
  title = {Teaching problem solving effectively},
  crossref = {journal:acm:inroads},
  volume = {2},
  number = {3},
  month = aug,
  year = {2011},
  pages = {58--62},
  doi = {10.1145/2003616.2003636},
  abstract = {To teach students problem solving effectively it is important to guide them properly through the process of problem solving. Most of the programming lab exercises lack emphasis on practicing the process of problem solving. Based on our experience, we have suggested a guideline to design lab exercises. In which we emphasize on defining detailed steps to guide students through the process of problem solving. We have proven through experiments that lab exercises designed with guidelines provided to solve the problem are very effective way of teaching problem solving skills.},
  keywords = {problem-solving process, programming laboratory course},
  acmid = {2003636},
  issue = {3},
  issue_date = {September 2011},
  lang = {en},
  numpages = {5}
}

@INPROCEEDINGS{Hassan,
  author = {Hassan, A.E. and Tao Xie},
  title = {Mining software engineering data},
  crossref = {proceedings:icse:2010},
  pages = {503--504},
  doi = {10.1145/1810295.1810451},
  abstract = {Software engineering data (such as code bases, execution traces, historical code changes, mailing lists, and bug databases) contains a wealth of information about a project's status, progress, and evolution. Using well-established data mining techniques, practitioners and researchers have started exploring the potential of this valuable data in order to better manage their projects and to produce higher quality software systems that are delivered on time and within budget. This tutorial presents the latest research in mining software engineering data, discusses challenges associated with mining software engineering data, highlights success stories of mining software engineering data, and outlines future research directions. Attendees will acquire the knowledge and skills needed to integrate the mining of software engineering data in their own research or practice. This tutorial builds on several successful offerings at ICSE since 2007.},
  keywords = {mining software engineering data; mining software repositories},
  volume = {2}
}

@INPROCEEDINGS{Hassan:2008,
  author = {Ahmed E. Hassan},
  title = {The road ahead for Mining Software Repositories},
  crossref = {proceedings:fosm:2008},
  pages = {48--57},
  doi = {10.1109/FOSM.2008.4659248},
  abstract = {Source control repositories, bug repositories, archived communications, deployment logs, and code repositories are examples of software repositories that are commonly available for most software projects. The mining software repositories (MSR) field analyzes and cross-links the rich data available in these repositories to uncover interesting and actionable information about software systems. By transforming these repositories from static record-keeping ones into active repositories, we can guide decision processes in modern software projects. For example, data in source control repositories, traditionally used to archive code, could be linked with data in bug repositories to help practitioners propagate complex changes and to warn them about risky code based on prior changes and bugs. In this paper, we present a brief history of the MSR field and discuss several recent achievements and results of using MSR techniques to support software research and practice. We then discuss the various opportunities and challenges that lie in the road ahead for this important and emerging field.}
}

@ARTICLE{Hassan-etal:2013,
  author = {Hassan, Ahmed E. and Hindle, Abram and Runeson, Per and Shepperd, Martin and Devanbu, Prem and Kim, Sunghun},
  title = {Roundtable: What's Next in Software Analytics},
  crossref = {journal:ieee:software},
  volume = {30},
  number = {4},
  month = jul # {--} # aug,
  year = {2013},
  pages = {53-56},
  doi = {10.1109/MS.2013.85},
  abstract = {For this special issue, the guest editors asked a panel of six established experts in software analytics to highlight what they thought were the most important, or overlooked, aspect of this field. They all pleaded for a much broader view of analytics than seen in current practice: software analytics should go beyond developers (Ahmed Hassan) and numbers (Per Runeson). Analytics should also prove its relevance to practitioners (Abram Hindle, Martin Shepperd). There are now opportunities for "natural" software analytics based on statistical natural language processing (Prem Devanbu). Lastly, software analytics needs information analysts and field agents like Chloe O'Brian and Jack Bauer in the TV show 24 (Sung Kim).},
  keywords = {decision support; information search and retrieval; management metrics; software/program verification; statistical methods; testing and debugging}
}

@ARTICLE{Hassan-etal:2005,
  author = {Ahmed E. Hassan and Audris Mockus and Richard C. Holt and Philip M. Johnson},
  title = {Guest Editor's Introduction: Special Issue on Mining Software Repositories},
  crossref = {journal:iee:tse},
  volume = {31},
  number = {6},
  month = jun,
  year = {2005},
  pages = {426--428},
  doi = {10.1109/TSE.2005.70}
}

@INPROCEEDINGS{Hassan-Xie:2010,
  author = {Hassan, Ahmed E. and Xie, Tao},
  title = {Software intelligence: the future of mining software engineering data},
  crossref = {proceedings:foser:2010},
  pages = {161--166},
  doi = {10.1145/1882362.1882397},
  abstract = {Mining software engineering data has emerged as a successful research direction over the past decade. In this position paper, we advocate Software Intelligence (SI) as the future of mining software engineering data, within modern software engineering research, practice, and education. We coin the name SI as an inspiration from the Business Intelligence (BI) field, which offers concepts and techniques to improve business decision making by using fact-based support systems. Similarly, SI offers software practitioners (not just developers) up-to-date and pertinent information to support their daily decision-making processes. SI should support decision-making processes throughout the lifetime of a software system not just during its development phase. The vision of SI has yet to become a reality that would enable software engineering research to have a strong impact on modern software practice. Nevertheless, recent advances in the Mining Software Repositories (MSR) field show great promise and provide strong support for realizing SI in the near future. This position paper summarizes the state of practice and research of SI, and lays out future research directions for mining software engineering data to enable SI.},
  keywords = {mining software engineering data, mining software repositories, software intelligence}
}

@ARTICLE{hastbacka-2011,
  author = {David Hästbacka and Timo Vepsäläinen and Seppo Kuikka},
  title = {Model-driven development of industrial process control applications},
  crossref = {journal:elsevier:jss},
  volume = {84},
  number = {7},
  year = {2011},
  pages = {1100 - 1113},
  doi = {10.1016/j.jss.2011.01.063},
  abstract = {This article presents model-driven development and domain-specific modeling applied to the development of industrial process control applications. The approach is based on established practices of the industrial automation and control domain, a compatible UML profile, and an integrated and standards based tool environment for modeling and transformation execution. The methods provide means for developing applications using domain-specific modeling concepts to increase productivity and enhance platform independent solution reuse. The approach has been implemented to support industrial practices and to be able to utilize existing control system platforms. During demonstrations and an assessment event with industry professionals the methods have been successfully applied to the development of small-scale process control applications. In this paper, attention is also paid on discussion of the practical applicability and benefits of the approach for engineering and development of industrial process control applications.},
  keywords = {Model-driven development}
}

@INPROCEEDINGS{Haungs-etal:2012,
  author = {Haungs, Michael and Clark, Christopher and Clements, John and Janzen, David},
  title = {Improving first-year success and retention through interest-based CS0 courses},
  crossref = {proceedings:sigcse:2012},
  pages = {589--594},
  doi = {10.1145/2157136.2157307},
  abstract = {Many computer science programs suffer from low student retention rates. At Cal Poly San Luis Obispo, academic performance and retention rates among first-year computer science students are among the lowest on campus. In order to remedy this, we have developed a new CS0 course featuring different "tracks" that students can choose from (e.g. robotics, gaming, music, mobile apps). This allows students to learn the basics of programming, teamwork, and college-level study in a domain that is of personal interest. In addition, the course relies on classic Project-based Learning (PBL) approaches as well as a focus on both academic and non-academic factors shown to increase student retention. Initial assessment demonstrates positive results in the form of increased academic performance in post CS0 courses and student retention.},
  keywords = {CS0, CS1, cornerstone, motivation, self-efficacy}
}

@ARTICLE{Hayashi-etal:2009,
  author = {Hayashi, Yusuke and Bourdeau, Jacqueline and Mizoguchi, Riichiro},
  title = {Using Ontological Engineering to Organize Learning/Instructional Theories and Build a Theory-Aware Authoring System},
  crossref = {journal:ios:ijaie},
  volume = {19},
  number = {2},
  month = apr,
  year = {2009},
  pages = {211--252},
  abstract = {This paper describes the achievements of an innovative eight-year research program first introduced in Mizoguchi and Bourdeau (2000), which was aimed at building a theory-aware authoring system by using ontological engineering. To date, we have proposed OMNIBUS, an ontology that comprehensively covers different learning/instructional theories and paradigms, and SMARTIES, a theory-aware and standards-compliant authoring system to create learning/instructional scenarios based on OMNIBUS. This approach was intended to bridge the gap between theory and practice in scientific and technological development, including learning/instruction support. The goals of this study included the following: that computers would (a) understand a variety of learning/instructional theories based on their organization, (b) utilize such understanding to help authors build learning/instructional scenarios, and (c) make such theoretically sound scenarios interoperable within the framework of technology standards. This paper suggests an ontological engineering solution to achieve these three goals and describes the implementation and feasibility demonstrations of the basic functions of SMARTIES, a solution that supports the design of learning/instructional scenarios based on multiple theories. Although the evaluation is far from complete in terms of practical use, we believe that the results of this study speak to high-level technical challenges of ITS authoring systems and the other areas of AIED, and therefore constitute a substantial contribution.},
  keywords = {instructional design, instructional theories, learning theories, ontology, standard technologies}
}

@INPROCEEDINGS{He-etal:2012,
  author = {He, Peng and Li, Bing and Huang, Yuan},
  title = {Applying Centrality Measures to the Behavior Analysis of Developers in Open Source Software Community},
  crossref = {proceedings:cgc:2012},
  pages = {418--423},
  doi = {10.1109/CGC.2012.50},
  abstract = {In this paper, we firstly create developer networks by affiliation between projects and developers, and then, with respect to social network analysis, take an approach to empirically study the new developers' behavior and the relationship with the centrality measures. We find that most of new developers choose to cooperate with each other initially, but more collaboration are established between new developers and existing developers, and more new collaboration are developed between existing developers who have never collaborated with each other than those have collaborated before. In addition we suggest that new developers prior to cooperate with high between ness centrality or degree centrality and then closeness centrality, discuss that centrality measures can use to guide the preferential collaboration of OSS community.},
  keywords = {OSS community; Developer networks; Centrality analysis; Longitudinal study}
}

@ARTICLE{Heer-Kandel:2012,
  author = {Heer, Jeffrey and Kandel, Sean},
  title = {Interactive analysis of big data},
  crossref = {journal:acm:xrds},
  volume = {19},
  number = {1},
  month = sep,
  year = {2012},
  pages = {50--54},
  doi = {10.1145/2331042.2331058},
  abstract = {New user interfaces can transform how we work with big data, and raise exciting research problems that span human-computer interaction, machine learning, and distributed systems.}
}

@INPROCEEDINGS{Hemmati-etal:2013,
  author = {Hemmati, Hadi and Nadi, Sarah and Baysal, Olga and Kononenko, Oleksii and Wang, Wei and Holmes, Reid and Godfrey, Michael W.},
  title = {The {MSR} Cookbook: Mining a Decade of Research},
  crossref = {proceedings:msr:2013},
  pages = {343--352},
  doi = {10.1109/MSR.2013.6624048},
  abstract = {The Mining Software Repositories (MSR) research community has grown significantly since the first MSR workshop was held in 2004. As the community continues to broaden its scope and deepens its expertise, it is worthwhile to reflect on the best practices that our community has developed over the past decade of research. We identify these best practices by surveying past MSR conferences and workshops. To that end, we review all 117 full papers published in the MSR proceedings between 2004 and 2012. We extract 268 comments from these papers, and categorize them using a grounded theory methodology. From this evaluation, four high-level themes were identified: data acquisition and preparation, synthesis, analysis, and sharing/replication. Within each theme we identify several common recommendations, and also examine how these recommendations have evolved over the past decade. In an effort to make this survey a living artifact, we also provide a public forum that contains the extracted recommendations in the hopes that the MSR community can engage in a continuing discussion on our evolving best practices.}
}

@ARTICLE{Hemmendinger:2010,
  author = {Hemmendinger, David},
  title = {A plea for modesty},
  crossref = {journal:acm:inroads},
  volume = {1},
  number = {2},
  month = jun,
  pages = {4--7},
  doi = {10.1145/1805724.1805725},
  abstract = {From time to time a movement arises that promises to save the world, or at least to make it vastly better. The extraordinary achievements of digital computing make it a locus of such movements today. Yet we should be wary; when movements fail they provoke backlash that rejects the more limited gains that they might have afforded. Today "computational thinking" has a considerable following, and I would like to discuss some problems with its discourse. It is too often presented in terms that could be interpreted as arrogant or that are overstated. Its descriptions too often lack appropriate examples, and perhaps as a result, it gets misunderstood in casual writing.},
  keywords = {computational thinking, computing and society}
}

@ARTICLE{Henderson:2009,
  author = {Henderson, Peter B.},
  title = {SIGCSE 2009 and CS unplugged},
  crossref = {journal:acm:inroads},
  volume = {41},
  number = {2},
  month = jun,
  year = {2009},
  pages = {81--82},
  doi = {10.1145/1595453.1595477}
}

@ARTICLE{Hendler-etal:1990,
  author = {James A. Hendler and Austin Tate and Mark Drummond},
  title = {{AI} Planning: Systems and Techniques},
  crossref = {journal:aaai:ai},
  volume = {11},
  number = {2},
  month = jun # {--} # sep,
  year = {1990},
  pages = {61--77},
  abstract = {This article reviews research in the development of plan generation systems. Our goal is to familiarize the reader with some of the important problems that have arisen in the design of planning systems and to discuss some of the many solutions that have been developed in the over 30 years of research in this area. In this article, we broadly cover the major ideas in the field of AI planning and show the direction in which some current research is going. We define some of the terms commonly used in the planning literature, describe some of the basic issues coming from the design of planning systems, and survey results in the area. Because such tasks are virtually never ending, and thus, any finite document must be incomplete, we provide references to connect each idea to the appropriate literature and allow readers access to the work most relevant to their own research or applications.},
  url = {http://aaaipress.org/ojs/index.php/aimagazine/article/view/833},
  owner = {magsilva},
  timestamp = {2014.01.16}
}

@ARTICLE{Herlocker-etal:2004,
  author = {Herlocker, Jonathan L. and Konstan, Joseph A. and Terveen, Loren G. and Riedl, John T.},
  title = {Evaluating Collaborative Filtering Recommender Systems},
  crossref = {journal:acm:tois},
  volume = {22},
  number = {1},
  month = jan,
  year = {2004},
  pages = {5--53},
  doi = {10.1145/963770.963772},
  abstract = {Recommender systems have been evaluated in many, often incomparable, ways. In this article, we review the key decisions in evaluating collaborative filtering recommender systems: the user tasks being evaluated, the types of analysis and datasets being used, the ways in which prediction quality is measured, the evaluation of prediction attributes other than quality, and the user-based evaluation of the system as a whole. In addition to reviewing the evaluation strategies used by prior researchers, we present empirical results from the analysis of various accuracy metrics on one content domain where all the tested metrics collapsed roughly into three equivalence classes. Metrics within each equivalency class were strongly correlated, while metrics from different equivalency classes were uncorrelated.},
  keywords = {Collaborative filtering, evaluation, metrics, recommender systems}
}

@INPROCEEDINGS{HernanLosada-etal:2008,
  author = {Hernan-Losada, I. and Pareja-Flores, C. and Velazquez-Iturbide, A.J.},
  title = {Testing-Based Automatic Grading: A Proposal from Bloom's Taxonomy},
  crossref = {proceedings:icalt:2008},
  pages = {847--849},
  doi = {10.1109/ICALT.2008.224},
  abstract = {The test-first approach has been repeatedly advocated to learn both programming and software engineering. Besides, automatic graders are broadly used, both in programming contests and in everyday teaching. The sort of problems stated in both situations is always placed at the application and higher levels of Bloompsilas taxonomy, and it demands some degree of mastery on students. In this paper we address the combined use of automatic grading and the test-driven approach from a pedagogical view. In particular, we address assessment at the levels of comprehension, application, analysis and synthesis in Bloompsilas taxonomy. We make a proposal, based on sorts of exercises and suggested examples. We also gather a set of features that exercises should include as metadata to facilitate its use from pedagogical criteria.}
}

@INPROCEEDINGS{Hickey:2004,
  author = {Timothy J. Hickey},
  title = {Scheme-based web programming as a basis for a {CS0} curriculum},
  crossref = {proceedings:sigcse:2004},
  pages = {353--357},
  doi = {10.1145/971300.971423},
  abstract = {The thesis of this paper is that Scheme-based web programming is a worthy organizing topic for CS0 computer literacy courses. We describe an approach to introducing non-science majors to Computer Science by teaching them to write webpages using HTML and CSS and to also write applets and servlets using Scheme. The programming component of our approach is completed in about nine weeks of a thirteen week course, leaving time for a treatment of more traditional CS0 topics such as intellectual property, privacy, artificial intelligence, the limits of computability, PC architecture, Operating Systems, CMOS and logic circuits. We argue that the use of a high level scripting language (like Scheme) is essential to the success of this approach. We also argue that wide scale success in teaching web programming to non-majors could enhance the students productivity when they enter the job market, and hence this approach deserves further study.},
  address = {Norfolk, Virginia, USA},
  booktitle = {35th SIGCSE Technical Symposium on Computer Science Education},
  year = {2004}
}

@ARTICLE{Hicks-Foster:2010,
  author = {Michael Hicks and Jeffrey S. Foster},
  title = {{SCORE}: Agile Research Group Management},
  crossref = {journal:acm:cacm},
  volume = {53},
  number = {10},
  month = oct,
  pages = {30--31},
  doi = {10.1145/1831407.1831421},
  abstract = {Adapting agile software development methodology toward more efficient management of academic research groups.},
  review = {SCORE tackles the problem of mentoring and fostering graduate students from a research group. Actually, it encourages the creation of a real research group, building up a close community of researchers, working on the same field. The encouragement comes from the frequently update of status, with proper (and real-time) release to every one, and, if so required, one-to-one meetings with the advisor/mentor. The process is kidda nifty. It simply exposes the problems every graduate students faces. As it exposes that to everyone, the feeling of 'working alone' or 'it is just me?' disappears: the student perceives the problems they face are common, and that the solutions are not difficult. The process also reduces the frustration of lengthy meetings (with no further good result): status reports are kept short and broadcast; meetings for a specific topic are scheduled an run with enough time. So, it works not only from the student side, but also from the advisor one (which is great). Nonetheless, the current process description lacks some metrics to help the identification of problems. Well, some metrics are actually provided: if a student does not report significant updates after several meetings, something is probably wrong. But, may be, some extra metrics can be provided based upon the what was done/what problems were found/what is planned reports: if a student is finding several problems (thus hampering/ruining its planning), may be it would be better to devise a new approach or provide a new technique to handle/avoid such issues.}
}

@INPROCEEDINGS{Higgins-Bligh:2006,
  author = {Higgins, Colin A. and Bligh, Brett},
  title = {Formative computer based assessment in diagram based domains},
  crossref = {proceedings:itcse:2006},
  pages = {98--102},
  doi = {10.1145/1140124.1140152},
  abstract = {This paper presents an approach to conducting formative assessment of student coursework within diagram-based domains using Computer Based Assessment (CBA) technology. Formative assessment is perceived as a resource-intensive assessment mode and its usage is in steep decline in higher education. CBA technology developed out of the desire to automate assessment due to the necessity of assessing students with decreasing unit-resource; it can overcome the decline in formative assessment by automating those processes which are considered resource-intensive.The system described is based upon the CourseMarker CBA system (formerly CourseMaster / Ceilidh) and the DATsys object-oriented framework for CBA-oriented diagram editors. This paper outlines requirements for obtaining good formative assessment using CBA software and documents a live system which assessed student Entity Relationship diagrams within an undergraduate Database Systems course. Results are presented and considerable extensions proposed.},
  keywords = {automatic assessment, education, formative assessment, testing},
  timestamp = {2013-08-23}
}

@ARTICLE{Hilburn:1997,
  author = {Thomas B. Hilburn},
  title = {Software Engineering Education: A Modest Proposal},
  crossref = {journal:ieee:software},
  volume = {14},
  number = {6},
  month = nov,
  year = {1997},
  pages = {44--48},
  doi = {10.1109/52.636650},
  abstract = {For our profession to advance, software engineering education must improve. The author proposes a conceptual model for achieving this that is founded on the triad of people, process, and technology. He then outlines a sample curriculum based on his model.}
}

@INPROCEEDINGS{Hill-Ciccarelli:2013,
  author = {Hill, Lawrence and Ciccarelli, Steven},
  title = {Using a Low-cost Open Source Hardware Development Platform in Teaching Young Students Programming Skills},
  crossref = {proceedings:sigite:2013},
  pages = {63--68},
  doi = {10.1145/2512276.2512289},
  abstract = {The teaching of programming skills to young students is often described by those educators involved as problematic at best. Student issues like mathematical maturity, readiness for complex thought, basic problem solving skills, short attention span especially related to the boredom of traditional programming teaching methodologies, and the lack of exciting problems and their solutions with respect to programming assignments contribute to the angst of many a programming instructor. A small fraction of students who "were just made for programming" always seem to succeed at whatever programming problem is given to them. However, a majority of students, especially precollege and college freshmen tend to have difficulty in overcoming these issues. It is with that observation that something new, in terms of programming pedagogy, needed to be investigated by this paper's authors. An ideal opportunity requiring successful programming instruction for 7-12 graders in the local metropolitan area presented itself in the winter of 2012. The students were involved in a statewide competition where groups of students self-selected into project options offered by various sponsoring institutions. Under the "Technology" choice heading of the state program, the student team and the instructor agreed to program a microprocessor to send messages in International Morse Code. The object of the exercise was to learn basic programming skills and to apply them to solving a problem. The hook was to do something brand new the students had never engaged in, keeping their attention on the end goal, and to see the immediate real-time results of some programming effort along the development cycle as the completed final program took form. The effort was a resounding success; the students learned in a few Saturday morning sessions more about programming than the authors have experienced over weeks of effort in traditional programming classes at the college freshman level.},
  keywords = {arduino, c programming, ide, international morse code, it education, open source, young students}
}

@INPROCEEDINGS{Hilton-Janzen:2012,
  author = {Hilton, Michael and Janzen, David S.},
  title = {On teaching arrays with test-driven learning in {WebIDE}},
  crossref = {proceedings:itcse:2012},
  pages = {93--98},
  doi = {10.1145/2325296.2325322},
  abstract = {Test-driven development (TDD) has been shown to reduce defects and to lead to better code, but can it help beginning students learn basic programming topics, specifically arrays? We performed a controlled experiment where we taught arrays to two CS0 classes, one using WebIDE, an intelligent tutoring system that enforced the use of Test-Driven Learning (TDL) methods, and one using more traditional static methods and a development environment that instructed, but did not enforce the use of TDD. Students who used the TDL approach with WebIDE performed significantly better in assessments and had significantly higher opinions of their experiences than students who used traditional methods and tools.},
  keywords = {CS0, CS1, computer science education, intelligent tutor}
}

@INPROCEEDINGS{Hislop-etal:2009,
  author = {Hislop, Gregory W. and Ellis, Heidi J. C. and Tucker, Allen B. and Dexter, Scott},
  title = {Using open source software to engage students in computer science education},
  crossref = {proceedings:sigcse:2009},
  pages = {134--135},
  doi = {10.1145/1508865.1508915},
  abstract = {This panel will discuss issues and methods for incorporating free and open source software (FOSS) in computer science education. The panelists are investigating approaches to student participation in FOSS that produce results that are contributed to the FOSS community and actually used by others.},
  keywords = {computing education, open source software, student motivation}
}

@ARTICLE{Hitz-Montazeri:1996,
  author = {Hitz, Martin and Montazeri, Behzad},
  title = {Chidamber and Kemerer's metrics suite: a measurement theory perspective},
  crossref = {journal:ieee:tse},
  volume = {22},
  number = {4},
  month = apr,
  year = {1996},
  pages = {267--271},
  doi = {10.1109/32.491650},
  abstract = {The metrics suite for object-oriented design put forward by Chidamber and Kemerer (1994) is partly evaluated by applying principles of measurement theory. Using the object coupling measure (CBO) as an example, it is shown that failing to establish a sound empirical relation system can lead to deficiencies of software metrics. Similarly, for the object-oriented cohesion measure (LCOM) it is pointed out that the issue of empirically testing the representation condition must not be ignored, even if other validation principles are carefully obeyed. As a by-product, an alternative formulation for LCOM is proposed},
  keywords = {software measurement, coupling metrics, cohesion metrics, object-orientation, validation},
  timestamp = {2013-09-14}
}

@INCOLLECTION{Hoare:1972,
  author = {Hoare, C. A. R.},
  title = {Notes on data structuring},
  chapter = {2},
  pages = {83--174},
  crossref = {Dahl-etal:1972}
}

@ARTICLE{Hoare:1974,
  author = {C. A. R. Hoare},
  title = {Monitors: an operating system structuring concept},
  crossref = {journal:acm:cacm},
  volume = {17},
  year = {1974}
}

@ARTICLE{Hoare:1965,
  author = {Hoare, C. A. R.},
  title = {Record Handling},
  crossref = {journal:chm:algol-bulletin},
  number = {21},
  month = nov,
  year = {1965},
  pages = {39--69},
  doi = {10.1145/1061032.1061041}
}

@INPROCEEDINGS{Hofer-Philipp:2009,
  author = {Höfer, Andreas and Philipp, Marc},
  title = {An Empirical Study on the {TDD} Conformance of Novice and Expert Pair Programmers},
  crossref = {proceedings:xp:2009},
  pages = {33--42},
  doi = {10.1007/978-3-642-01853-4_6},
  abstract = {We conducted a quasi-experiment comparing the confor- mance to the test-driven development (TDD) process of one expert and two novice groups of programmers working in pairs. Besides an insignificant tendency of the expert group toward a higher TDD conformance and instruction coverage, we found that the expert group had refactored their code to a larger extent than the two novice groups. More surprisingly though, the pairs in the expert group were significantly slower than the pairs in one of the novice groups.},
  keywords = {test-driven development; pair programming; experts and novices; quasi-experiment},
  owner = {magsilva},
  timestamp = {2014.10.20}
}

@INPROCEEDINGS{Hoffmann-etal:2008,
  author = {Hoffmann, Peter and Kochems, Tobias and Herczeg, Michael},
  title = {HyLive: Hypervideo-Authoring for Live Television},
  crossref = {proceedings:euroitv:2008},
  pages = {51-60},
  doi = {10.1007/978-3-540-69478-6_6},
  abstract = {In this paper we discuss the commonalities and differences of hypervideo and interactive television. We show that, even if the interaction and presentation of both are similar, there are strong differences in handling the content and the link structure of those media. The production and editorial process for live interactive television with hyperlinks and added value including production and editorial workflows is examined. The results led to a concept and a prototypical implementation for an editing tool and a web-based client player for interactive live television with hypervideo structures, called HyLive.}
}

@INPROCEEDINGS{Hofmann-Riehle:2009,
  author = {Hofmann, Philipp and Riehle, Dirk},
  title = {Estimating Commit Sizes Efficiently},
  crossref = {procedings:oss:2009},
  pages = {105--115},
  doi = {10.1007/978-3-642-02032-2_11},
  abstract = {The quantitative analysis of software projects can provide insights that let us better understand open source and other software development projects. An important variable used in the analysis of software projects is the amount of work being contributed, the commit size. Unfortunately, post-facto, the commit size can only be estimated, not measured. This paper presents several algorithms for estimating the commit size. Our performance evaluation shows that simple, straightforward heuristics are superior to the more complex text-analysis-based algorithms. Not only are the heuristics significantly faster to compute, they also deliver more accurate results when estimating commit sizes. Based on this experience, we design and present an algorithm that improves on the heuristics, can be computed equally fast, and is more accurate than any of the prior approaches.},
  owner = {magsilva},
  timestamp = {2014.05.29}
}

@ARTICLE{Hohpe-etal:2013,
  author = {Hohpe, Gregor and Allianz SE and Wirfs-Brock, Rebecca and Yoder, Joseph W. and Zimmermann, Olaf},
  title = {Twenty Years of Patterns' Impact},
  crossref = {journal:ieee:software},
  volume = {30},
  number = {6},
  month = nov # {--} # dec,
  year = {2013},
  pages = {84--88},
  doi = {10.1109/MS.2013.135},
  abstract = {This column celebrates 20 years of software patterns. IEEE Software advisory board members teamed up with members of the Hillside Group, a nonprofit organization that promotes the use of patterns and pattern languages, to reflect on the state of the practice and impact of patterns.},
  quotes = {The early hype around patterns has settled, and people realize that patterns neither replace skills nor solve all problems. Patterns present a reusable solution, provide information about its usefulness and trade-offs, and encapsulate knowledge about proven best practices.},
  owner = {magsilva},
  timestamp = {2014.01.14}
}

@INPROCEEDINGS{Holloway-Julien:2010,
  author = {Holloway, Seth and Julien, Christine},
  title = {The case for end-user programming of ubiquitous computing environments},
  crossref = {proceedings:foser:2010},
  pages = {167--172},
  doi = {10.1145/1882362.1882398},
  abstract = {Gone are the days that computers will be used by select users sitting at a desk with a mouse and keyboard. The next wave of computing, ubiquitous computing, is upon us. With smart phones, tablet computers, and embedded sensors/actuators flourishing, users are already interacting with dozens of computers per day. A large body of research has addressed many issues in hardware and software for the future, but few have focused on the users. We posit that the reason ubiquitous computing environments are still largely unrealized is because research is technology-centric, with inadequate focus on users. To bridge this gap between what technology can provide and what users need and want from ubiquitous computing, we motivate the need for end-user programming in ubiquitous computing environments and provide a vision for enabling end-user programming. We believe that the software engineering community must provide end-user programming capabilities in ubiquitous computing environments if this domain is to reach its full potential.},
  keywords = {end-user programming, software engineering, ubiquitous computing, vision}
}

@INPROCEEDINGS{Holohan-etal:2005,
  author = {Holohan, Edmond and Melia, Mark and McMullen, Declan and Pahl, Claus},
  title = {Adaptive E-learning content generation based on semantic web technology},
  crossref = {proceedings:sw-el:2005},
  pages = {1--8},
  abstract = {The efficient authoring of learning content is a central problem of courseware engineering. Courseware authors will appreciate the benefits of tools which automate various authoring tasks. We describe a system, OntAWare, which provides an environment comprising a set of software tools that support learning content authoring, management and delivery. This system exploits an opportunity provided by the emerging technologies of the Semantic Web movement, most notably knowledge-representation standards and knowledge-processing techniques. The system represents a combination of these newer developments with earlier work in areas such as artificial intelligence (AI) and intelligent tutoring systems (ITS). A key feature of the authoring environment is the semi-automatic generation of standard e-learning and other courseware elements (learning objects). Widely available standardised knowledge representations (ontologies) and ontology-structured content are used as source material. Standard courseware elements are produced by the application of graph transformations to these ontologies. The resulting products can be hosted by standards-compliant delivery environments. Adaptivity is an important characteristic of the system as a whole. Authors can select and customise new or existing subject ontologies and employ an appropriate teaching/learning strategy in the generation of learning objects. Instructors can configure the delivery environment either to offer strictly sequenced presentations to students, or to allow also varying degrees of free student navigation, based on the the runtime incorporation of domain ontologies. Students in turn can take the generated courses in the preconfigured delivery environment, and this delivery is dynamically customised to the individual student's preferences and constantly monitored learning track. The combination of the semi-automatic generation of learning objects with an adaptive delivery environment is a central feature of this new system.},
  keywords = {courseware generation; Semantic Web; ontology; learning object; adaptivity.},
  lang = {en},
  url = {http://doras.dcu.ie/15941/}
}

@ARTICLE{Hong:2013,
  author = {Hong, Jason},
  title = {{Ph.D.} students must break away from undergraduate mentality},
  crossref = {journal:acm:cacm},
  volume = {56},
  number = {7},
  month = jul,
  year = {2013},
  pages = {10--11},
  doi = {10.1145/2483852.2483857}
}

@INPROCEEDINGS{Hong-etal:2011,
  author = {Qiaona Hong and Sunghun Kim and Cheung, S. C. and Bird, C.},
  title = {Understanding a developer social network and its evolution},
  crossref = {proceedings:icsm:2011},
  pages = {323--332},
  doi = {10.1109/ICSM.2011.6080799},
  abstract = {With the growing number of large scale software projects, software development and maintenance demands the participation of larger groups. Having a thorough understanding of the group of developers is critical for improving development and maintenance quality and reducing cost. In contrast to most commercial software endeavors, developers in open source software (OSS) projects enjoy more freedom to organize and contribute to a project in their own working style. Their interactions through various means in the project generate a latent developer social network (DSN). We have observed that developers and their relationships in these DSNs change continually under the influence of differences in the set of active developers and their changing activities. Revealing and understanding the structure and evolution of these social networks as well as their similarities and differences from other more general social networks (GSNs) is of value to our software engineering community, as it allows us to begin building an understanding of how well the findings from other fields based on GSNs apply to DSN. In this paper, we compare DSNs with popular GSNs such as Facebook, Twitter, Cyworld (a large social network in South Korea), and the Amazon recommendation network. We found, for instance, that while most social networks exhibit power law degree distributions, our DSNs do not. In addition, we also examine how DSNs evolve over time, highlighting how events within a project (such as a release of new software or the departure of prominent developers) impact the makeup of the DSNs, and observe the evolution of topological properties such as modularity and the paths of communities within these networks.},
  keywords = {developer social network;community detection}
}

@ARTICLE{Hoonlor-etal:2013,
  author = {Apirak Hoonlor and Boleslaw K. Szymanski and Mohammed J. Zaki},
  title = {Trends in computer science research},
  crossref = {jounal:acm:cacm},
  volume = {56},
  number = {10},
  month = oct,
  year = {2013},
  pages = {74--83},
  doi = {10.1145/2500892},
  abstract = {Keywords in the ACM Digital Library and IEEE Xplore digital library and in NSF grants anticipate future CS research.},
  owner = {magsilva},
  timestamp = {2014.01.16}
}

@INCOLLECTION{Hoare:2002,
  author = {C. A. R. Hoore},
  title = {Assertions: A Personal Perspective},
  chapter = {11},
  pages = {357--366},
  abstract = {It was my early experience in industry that triggered my interest in assertions and their in-program proofs; and my subsequent research at university extended the idea into a methodology for the specification and design of programs. Now that I have returned to work in industry, I have looked into the current role of assertions in industrial program development. My personal perspective illustrates the complementary roles of pure research, aimed at academic ideals of excellence, and the unexpected ways in which the results of such research contribute to the gradual improvement of engineering practice.},
  crossref = {Broy-Denert:2002}
}

@ARTICLE{Horgan-eteal:1994,
  author = {Horgan, Joseph R. and London, Saul and Lyu, Michael R.},
  title = {Achieving Software Quality with Testing Coverage Measures},
  crossref = {journal:ieee:computer},
  volume = {27},
  number = {9},
  month = sep,
  year = {1994},
  pages = {60--69},
  doi = {10.1109/2.312032},
  abstract = {Coverage testing helps the tester create a thorough set of tests and gives a measure of test completeness. The concepts of coverage testing are well-described in the literature. However, there are few tools that actually implement these concepts for standard programming languages, and their realistic use on large-scale projects is rare. In this article, we describe the uses of a dataflow coverage-testing tool for C programs-called ATAC for Automatic Test Analysis for C/sup 3/-in measuring, controlling,and understanding the testing process. We present case studies of two real-world software projects using ATAC. The first study involves 12 program versions developed by a university/industry fault-tolerant software project for a critical automatic-flight-control system. The second study involves a Bellcore project of 33 program modules. These studies indicate that coverage analysis of programs during testing not only gives a clear measure of testing quality but also reveals important aspects of software structure. Understanding the structure of a program, as revealed in coverage testing, can be a significant component in confident assessment of overall software quality.},
  owner = {magsilva},
  timestamp = {2014.09.11}
}

@ARTICLE{Horswill:2012,
  author = {Horswill, Ian},
  title = {What is computation?},
  crossref = {journal:acm:xrds},
  volume = {18},
  number = {3},
  month = mar,
  year = {2012},
  pages = {8--14},
  doi = {10.1145/2090276.2090283}
}

@INPROCEEDINGS{Hovemeyer-etal:2013,
  author = {Hovemeyer, David and Hertz, Matthew and Denny, Paul and Spacco, Jaime and Papancea, Andrei and Stamper, John and Rivers, Kelly},
  title = {{CloudCoder}: building a community for creating, assigning, evaluating and sharing programming exercises},
  crossref = {proceedings:sigcse:2013},
  pages = {742--742},
  doi = {10.1145/2445196.2445451},
  abstract = {Automatically-tested online programming exercises can be useful in introductory programming courses as self-tests to accompany readings, for in-class assessment, for skills development, and to provide additional practice for students who need it. CloudCoder (http://cloudcoder.org) is an effort to build a community based on an open-source programming exercise system (currently supporting C, Java, and Python) tightly integrated with a repository of freely-redistributable programming exercises written and used by members of the community. The goal of the project is to make programming exercises easy and free to incorporate into any programming course.},
  keywords = {automated testing, cloudcoder, cs1}
}

@ARTICLE{Hovemeyer-Spacco:2013,
  author = {Hovemeyer, David and Spacco, Jaime},
  title = {{CloudCoder}: A Web-based Programming Exercise System},
  crossref = {journal:ccsc:jcsc},
  volume = {28},
  number = {3},
  month = jan,
  year = {2013},
  pages = {30--30},
  abstract = {CloudCoder is a web-based programming exercise system designed for introductory programming courses. Using CloudCoder, instructors can assign practice problems to reinforce concepts and assess mastery of skills. Students access their assigned problems using a web browser. A typical problem asks the student to write a function or complete program to perform a simple task such as classifying input or performing a computation on input data. When the student submits her solution to a problem, the server tests her code against a series of test cases designed by the instructor and reports which tests executed correctly. CloudCoder is inspired by existing systems such as Codingbat, but is designed to be installed and used widely. As such, CloudCoder is open source (https://github.com/daveho/CloudCoder) and supports programming exercises in multiple languages (currently C, Java, and Python).},
  owner = {magsilva},
  timestamp = {2014.01.26}
}

@ARTICLE{Howden:1986,
  author = {William E. Howden},
  title = {A Functional Approach to Program Testing and Analysis},
  crossref = {journal:ieee:tse},
  volume = {12},
  number = {10},
  month = oct,
  year = {1986},
  pages = {997--1005},
  doi = {10.1109/TSE.1986.6313016},
  abstract = {An integrated approach to testing is described which includes both static and dynamic analysis methods and which is based on theoretical results that prove both its effectiveness and efficiency. Programs are viewed as consisting of collections of functions that are joined together using elementary functional forms or complex functional structures. Functional testing is identified as the input-output analysis of functional forms. Classes of faults are defined for these forms, and results are presented which prove the fault-revealing effectiveness of well defined sets of tests. Functional analysis is identified as the analysis of the sequences of operators, functions, and data type transformations which occur in functional structures. Theoretical results are presented which prove that it is only necessary to look at interfaces between pairs of operators and data type transformations in order to detect the presence of operator or data type sequencing errors. The results depend on the definition of normal forms for operator and data type sequencing diagrams.},
  keywords = {analysis, dynamic analysis, functions, input-output, interfaces, operators, sequence analysis, testing, theory, validation},
  tags = {software testing, functional testing, software testing concepts}
}

@INPROCEEDINGS{Hristova-etal:2003,
  author = {Hristova, Maria and Misra, Ananya and Rutter, Megan and Mercuri, Rebecca},
  title = {Identifying and correcting {Java} programming errors for introductory computer science students},
  crossref = {proceedings:sigcse:2003},
  pages = {153--156},
  doi = {10.1145/611892.611956},
  abstract = {Programming in Java can be a daunting task for introductory students, one that is only compounded by the cryptic compiler error messages they see when they first start to write actual code. This article details a project conducted by faculty and advanced students in the creation of an educational tool for Java programming, called Expresso. This paper discusses some existing programming tools, explains their drawbacks, and describes why Expresso is different. We also include a detailed list of typical errors made by novice programmers, used in the construction of the Expresso tool.},
  keywords = {CS1, Java, logic, programming, semantics, syntax}
}

@ARTICLE{Hsu-etal:2012,
  author = {Yu-Chen Hsu and Hsin Ning Jessie Ho and Chin-Chung Tsai and Gwo-Jen Hwang and Hui-Chun Chu and Chin-Yeh Wang and Nian-Shing Chen},
  title = {Research Trends in Technology-based Learning from 2000 to 2009: A content Analysis of Publications in Selected Journals},
  crossref = {journal:ifets:ets},
  volume = {15},
  number = {2},
  month = apr,
  year = {2012},
  pages = {354--370},
  abstract = {This paper provides a content analysis of studies in technology-based learning (TBL) that were published in five Social Sciences Citation Index (SSCI) journals (i.e. the British Journal of Educational Technology, Computers & Education, Educational Technology Research & Development, Educational Technology & Society, the Journal of Computer Assisted Learning) from 2000 to 2009. A total of 2,976 articles were cross-analyzed by three categories including research topic, research sample group, and learning domain. It was found that 'Pedagogical design and theories' was the most popular research topic, 'Higher Education' was the most utilized sample group, and 'Non-specified' and 'Engineering/Computer sciences' were the most selected learning domains in the last decade. However, topics in 'Motivation, Perceptions and Attitudes' drew more attention in the latest five years, while the number of articles in 'Digital game and intelligent toy enhanced learning' and 'Mobile and Ubiquitous Learning' grew significantly between 2005 and 2009. Furthermore, the Chi-square analysis results showed that there were significant associations among these three categories. The results of the analysis provide insights for educators and researchers into research trends and patterns of technology-based learning.},
  keywords = {Research trends, Technology-based learning, Content analysis}
}

@ARTICLE{Huang:1978,
  author = {Huang, J. C.},
  title = {Program Instrumentation and Software Testing},
  crossref = {journal:ieee:tse},
  volume = {11},
  number = {4},
  month = apr,
  year = {1978},
  pages = {25--32},
  doi = {10.1109/C-M.1978.218134},
  abstract = {The program tester needs to know what goes on inside a program as it executes during a test Instrumentation methods permit collection of testing coverage data without modifying the logical properties of programs being tested.},
  issn = {0018-9162},
  journal = {Computer},
  owner = {magsilva},
  timestamp = {2014.09.12}
}

@INPROCEEDINGS{Hubwieser-Muhling:2011,
  author = {Hubwieser, Peter and Mühling, Andreas},
  title = {What students (should) know about object oriented programming},
  crossref = {proceedings:icer:2011},
  pages = {77--84},
  doi = {10.1145/2016911.2016929},
  abstract = {In order to explore and validate suitable methods for investigating learning processes, we are currently conducting a case study, exploring the mental models of novice students in the field of object oriented modeling and programming. After abstracting and systemizing the information that was presented to the students of our introductory CS 1 course for non-majors we have asked them to draw concept maps at four points in time. Additionally, we conducted a small midterm exam, where the students had to implement some of the most important concepts and a regular final exam. We found that learning progress can be observed in detail by evaluating the concept maps.},
  keywords = {concept maps, learning process, mental model, object-orientation, objects first}
}

@INCOLLECTION{Hudak:2007,
  author = {Christine A. Hudak},
  title = {Linking Instructional Theories and Instructional Design to Learning Objects: A Proposed Conceptual Framework},
  chapter = {1},
  pages = {1-38},
  crossref = {Koohang-Harman:2007}
}

@ARTICLE{Huff-Martin:1995,
  author = {Huff, Chuck and Martin, C. Dianne},
  title = {Computing consequences: a framework for teaching ethical computing},
  crossref = {journal:acm:cacm},
  volume = {38},
  number = {12},
  month = dec,
  year = {1995},
  pages = {75--84},
  doi = {10.1145/219663.219687},
  abstract = {How to prepare tomorrow's professionals for questions that can't always be answered with faster, better, or more technology.}
}

@INPROCEEDINGS{Hull:2011:IAG:1999747.1999841,
  author = {Hull, Michael J. and Powell, Daniel and Klein, Ewan},
  title = {Infandango: automated grading for student programming},
  crossref = {proceedings:itcse:2011},
  pages = {330--330},
  doi = {10.1145/1999747.1999841},
  abstract = {Infandango is an open source web-based system for automated grading of Java code submitted by students. Uploaded Java files are compiled and run against a set of unit tests on a central server, with results being stored in a database. Students gain near-instant feedback on the correctness of their code, and instructors are able to monitor the progress of students in the class.},
  keywords = {automatic grading, django, java, restructured-text, sphinx},
  timestamp = {2013-08-23}
}

@INPROCEEDINGS{Hundhausen-etal:2009,
  author = {Hundhausen, Christopher and Agrawal, Anukrati and Fairbrother, Dana and Trevisan, Michael},
  title = {Integrating pedagogical code reviews into a CS 1 course: an empirical study},
  crossref = {proceedings:sigcse:2009},
  pages = {291--295},
  doi = {10.1145/1508865.1508972},
  abstract = {Formal code inspections are employed by teams of professional software engineers to identify software defects and improve the quality of software. After reviewing a piece of code individually, members of an inspection team come together to log the issues they have found, and to find new ones. Within the scope of a multi-institutional research project to adapt, refine, and evaluate studio-based learning methods in computing education, we are developing an adaptation of the formal code inspection called the pedagogical code review for use in lower-division computer science courses. In a pedagogical code review, a group of three to four students, led by a trained moderator, (a) walk through segments of each other's programming assignments, (b) check the code against a list of best coding practices, and (c) discuss and log issues that arise. We implemented pedagogical code inspections in three lab sessions of a CS 1 course. Through an analysis of inspection logs and exit surveys, we compiled evidence that the reviews improved the quality of students' code, stimulated increasingly sophisticated discussions of programming issues and practices, and promoted a sense of community.},
  keywords = {code inspection, cs education research, cs1, pedagogical code review, studio-based learning and instruction}
}

@ARTICLE{Huq:2012,
  author = {Huq, Arefin},
  title = {An interview with {Robert Soare}},
  crossref = {journal:acm:xrds},
  volume = {18},
  number = {3},
  month = mar,
  pages = {15--17},
  doi = {10.1145/2090276.2090284},
  abstract = {University of Chicago's Robert Soare, the Paul Snowden Russell Distinguished Service Professor of Mathematics and Computer Science, offers his reflections on Alan Turing.}
}

@ARTICLE{Hyman:2012,
  author = {Hyman, Paul},
  title = {Stanford schooling -- gratis!},
  crossref = {journal:cacm},
  volume = {55},
  number = {3},
  month = mar,
  year = {2012},
  pages = {22--22},
  doi = {10.1145/2093548.2093556}
}

@ARTICLE{Hyman:2012:YDE:2380656.2380664,
  author = {Hyman, Paul},
  title = {In the year of disruptive education},
  crossref = {journal:acm:cacm},
  volume = {55},
  number = {12},
  month = dec,
  year = {2012},
  pages = {20--22},
  doi = {10.1145/2380656.2380664},
  abstract = {As college tuitions soar, various online models vie to educate college students worldwide -- at no cost.}
}

@ARTICLE{Ibanez-Sanchez:2009,
  author = {Ibáñez, Jesús and Sánchez, Ana},
  title = {Constructive reduction: understanding uncomputability through programming},
  crossref = {journal:acm:inroads},
  volume = {41},
  number = {2},
  month = jun,
  year = {2009},
  pages = {90--94},
  doi = {10.1145/1595453.1595482},
  abstract = {We present a programming approach to teach the reduction technique in a computing engineering degree's Computability Theory course. It is based in a computing formalism that allows the students to analyze, construct and transform programs as normal data in a simple way. Reduction can then be tackled in a constructive manner, so that the students benefit from their programming skills to prove uncomputability results without the help of the Parametrization (S-m-n) Theorem. Additionally the method is suitable to be applied to interesting problems that cannot be handled by diagonalization nor classical reduction.},
  keywords = {S-m-n theorem, programming approach, reduction in computability}
}

@INPROCEEDINGS{Ihantola-etal:2010,
  author = {Ihantola, Petri and Ahoniemi, Tuukka and Karavirta, Ville and Seppälä, Otto},
  title = {Review of recent systems for automatic assessment of programming assignments},
  crossref = {proceedings:koli-calling:2010},
  pages = {86--93},
  doi = {10.1145/1930464.1930480},
  abstract = {This paper presents a systematic literature review of the recent (2006 - 2010) development of automatic assessment tools for programming exercises. We discuss the major features that the tools support and the different approaches they are using both from the pedagogical and the technical point of view. Examples of these features are ways for the teacher to define tests, resubmission policies, security issues, and so forth. We have also identified a list of novel features, like assessing web software, that are likely to get more research attention in the future. As a conclusion, we state that too many new systems are developed, but also acknowledge the current reasons for the phenomenon. As one solution we encourage opening up the existing systems and joining efforts on developing those further. Selected systems from our survey are briefly described in Appendix A.}
}

@INPROCEEDINGS{Inozemtseva-Holmes:2014,
  author = {Inozemtseva, Laura and Holmes, Reid},
  title = {Coverage is Not Strongly Correlated with Test Suite Effectiveness},
  crossref = {proceedings:icse:2014},
  pages = {435--445},
  doi = {10.1145/2568225.2568271},
  abstract = {The coverage of a test suite is often used as a proxy for its ability to detect faults. However, previous studies that investigated the correlation between code coverage and test suite effectiveness have failed to reach a consensus about the nature and strength of the relationship between these test suite characteristics. Moreover, many of the studies were done with small or synthetic programs, making it unclear whether their results generalize to larger programs, and some of the studies did not account for the confounding influence of test suite size. In addition, most of the studies were done with adequate suites, which are are rare in practice, so the results may not generalize to typical test suites. We have extended these studies by evaluating the relationship between test suite size, coverage, and effectiveness for large Java programs. Our study is the largest to date in the literature: we generated 31,000 test suites for five systems consisting of up to 724,000 lines of source code. We measured the statement coverage, decision coverage, and modified condition coverage of these suites and used mutation testing to evaluate their fault detection effectiveness. We found that there is a low to moderate correlation between coverage and effectiveness when the number of test cases in the suite is controlled for. In addition, we found that stronger forms of coverage do not provide greater insight into the effectiveness of the suite. Our results suggest that coverage, while useful for identifying under-tested parts of a program, should not be used as a quality target because it is not a good indicator of test suite effectiveness.},
  keywords = {Coverage, test suite effectiveness, test suite quality},
  owner = {magsilva},
  timestamp = {2014.07.21}
}

@INPROCEEDINGS{Iqbal-Hausenblas:2012,
  author = {Iqbal, A. and Hausenblas, M.},
  title = {Integrating developer-related information across open source repositories},
  crossref = {proceedings:iri:2012},
  pages = {69--76},
  doi = {10.1109/IRI.2012.6302993},
  abstract = {Software developers use various software repositories in order to interact with each other or to solve software related problems. They are required to adopt an identity for each of the software repositories they wanted to use. Quite often developers are also found on different code forges developing open source projects. It is worth mentioning that the information relevant to the developers are distributed on the Web among different data sources each requires an ID and an authentication mechanism. In this paper, we propose to interlink the identities of a developer across different data sources on the Web. Further, we show the benefit of integrating developer-related information from different data sources using some real-world scenarios.}
}

@ARTICLE{Isakowitz-etal:1995,
  author = {Tomás Isakowitz and Edward A. Stohr and P. Balasubramanian},
  title = {{RMM}: A Methodology for Structured Hypermedia Design},
  crossref = {journal:acm:cacm},
  volume = {38},
  number = {8},
  month = aug,
  year = {1995},
  pages = {34 - 44},
  doi = {10.1145/208344.208346},
  lang = {en},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@ARTICLE{Isomottonen-Lappalainen:2012,
  author = {Isomöttönen, Ville and Lappalainen, Vesa},
  title = {{CSI} with games and an emphasis on {TDD} and unit testing: piling a trend upon a trend},
  crossref = {journal:acm:inroads},
  volume = {3},
  number = {3},
  month = sep,
  year = {2012},
  pages = {62--68},
  doi = {10.1145/2339055.2339073},
  keywords = {CS1, TDD, game programming}
}

@ARTICLE{Ivanovic-Pitnerl:2011,
  author = {Ivanovic, Mirjana and PitnerI, Tomáv},
  title = {Technology-enhanced learning for Java programming: Duo cum faciunt idem, non est idem},
  crossref = {journal:acm:inroads},
  volume = {2},
  number = {1},
  month = mar,
  year = {2011},
  pages = {55--63},
  doi = {10.1145/1929887.1929906},
  abstract = {Background pedagogical theories and methods underpinning technology-enhanced learning in introductory programming courses at a university level attract teachers' community and foster continuous research at least since the end of the nineties. However, it still has not led to a generally applicable way of teaching and learning that would guarantee the best possible success under the given circumstances. This rather pessimistic fi nding intrigued and inspired authors of this paper to analyze, present, and compare selected experiences gathered during nearly a decade of technology-enhanced approach in teaching an object-oriented programming languages with specifi c focus on Java at two large universities in two countries. In this paper we have examined a number of issues affecting its positioning in the curriculum, learning design, and quality at both institutions. Based on quantitative and qualitative analysis, the history and current state is evaluated and key recommendations for planning, designing, deployment, and evaluation of similar courses are provided. Different traditions and independent development at both institutions allow us to draw generally applicable conclusions not infl uenced by specifi c properties of one particular educational system.},
  keywords = {Java programming course, assessment, curriculum, person-centered approach, technology-enhanced learning}
}

@INPROCEEDINGS{izeki:2002,
  author = {C. A. Izeki and R. F. Bulcão Neto and M. G. C. Pimentel and A. M. M. Miotto and R. P. M. Fortes},
  title = {A Dual Open Hypermedia Service for the Semantic Web},
  crossref = {proceedings:sbmidia:2002},
  pages = {53-68},
  address = {Fortaleza, CE},
  booktitle = {VIII Brazilian Symposium on Multimedia and Hypermedia Systems (SBMIDIA'2002)},
  month = oct,
  owner = {magsilva},
  timestamp = {2008.07.30},
  year = {2002}
}

@ARTICLE{CanovasIzquierdo-etal:2012,
  author = {Javier Luis Cánovas Izquierdo and Frédéric Jouault and Jordi Cabot and Jesús García Molina},
  title = {{API2MoL}: Automating the building of bridges between APIs and Model-Driven Engineering},
  crossref = {journal:elsevier:ist},
  volume = {54},
  number = {3},
  year = {2012},
  pages = {257--273},
  doi = {10.1016/j.infsof.2011.09.006},
  abstract = {A software artefact typically makes its functionality available through a specialized Application Programming Interface (API) describing the set of services offered to client applications. In fact, building any software system usually involves managing a plethora of APIs, which complicates the development process. In Model-Driven Engineering (MDE), where models are the key elements of any software engineering activity, this API management should take place at the model level. Therefore, tools that facilitate the integration of APIs and MDE are clearly needed. Our goal is to automate the implementation of API-MDE bridges for supporting both the creation of models from API objects and the generation of such API objects from models. In this sense, this paper presents the API2MoL approach, which provides a declarative rule-based language to easily write mapping definitions to link API specifications and the metamodel that represents them. These definitions are then executed to convert API objects into model elements or vice versa. The approach also allows both the metamodel and the mapping to be automatically obtained from the API specification (bootstrap process). After implementing the API2MoL engine, its correctness was validated using several APIs. Since APIs are normally large, we then developed a tool to implement the bootstrap process, which was also validated. We provide a toolkit (language and bootstrap tool) for the creation of bridges between APIs and MDE. The current implementation focuses on Java APIs, although its adaptation to other statically typed object-oriented languages is straightforward. The correctness, expressiveness and completeness of the approach have been validated with the Swing, SWT and JTwitter APIs. Conclusion API2MoL frees developers from having to manually implement the tasks of obtaining models from API objects and generating such objects from models. This helps to manage API models in MDE-based solutions.},
  keywords = {Application Programming Interface; Model-Driven Engineering; Domain-Specific Languages},
  lang = {en}
}

@INPROCEEDINGS{Jaccheri-Osterlie:2007,
  author = {Jaccheri, L. and Osterlie, T.},
  title = {Open Source Software: A Source of Possibilities for Software Engineering Education and Empirical Software Engineering},
  crossref = {proceedings:floss:2007},
  pages = {1--5},
  doi = {10.1109/FLOSS.2007.12},
  abstract = {Open source projects are an interesting source for software engineering education and research. By participating in open source projects students can improve their programming and design capabilities. By reflecting on own participation by means of an established research method and plan, master's students can in addition contribute to increase knowledge concerning research questions. In this work we report on a concrete study in the context of the Net- beans open source project. The research method used is a modification of action research.},
  keywords = {Net-beans open source project;open source projects;open source software;software engineering education;computer science education;programming;public domain software;software engineering;}
}

@INPROCEEDINGS{Jackson-Usher:1997,
  author = {Jackson, David and Usher, Michelle},
  title = {Grading student programs using {ASSYST}},
  crossref = {proceedings:sigcse:1997},
  pages = {335--339},
  doi = {10.1145/268084.268210},
  abstract = {The task of grading solutions to student programming exercises is laborious and error-prone. We have developed a software tool called ASSYST that is designed to relieve a tutor of much of the burden of assessing such programs. ASSYST offers a graphical interface that can be used to direct all aspects of the grading process, and it considers a wide range of criteria in its automatic assessment. Experience with the system has been encouraging.}
}

@INPROCEEDINGS{Jackson-etal:2005,
  author = {Jackson, J. and Cobb, M. and Carver, C.},
  title = {Identifying Top {Java} Errors for Novice Programmers},
  crossref = {proceedings:fie:2005},
  pages = {T4C-24--T4C-27},
  doi = {10.1109/FIE.2005.1611967},
  abstract = {All freshmen at the United States Military Academy take an introductory programming course. We use a custom-built integrated development environment to help teach Java. During previous work, we implemented an integrated semantic and syntax error pre-processing system to help novice programmers decipher the otherwise cryptic compiler error messages in order for them to focus more on design issues than implementation issues. The syntactic errors that we checked were gathered by an informal survey of the current and former faculty members teaching the course. We noticed over the course of the year that there were discrepancies between the errors that the instructors had identified and the errors that the students were encountering. In response, we developed a real-time, automated error collection system that logged 100% of the Java errors in a central database that all users, students and faculty alike, encountered while using the integrated development environment over the course of a semester. This paper discusses the implementation and results of our system as well as the implications for novice programmers},
  keywords = {syntax errors; programming; information technology}
}

@ARTICLE{Jacobson-etal:1999:article,
  author = {Ivar Jacobson and Grady Booch and James Rumbaugh},
  title = {The Unified Process},
  crossref = {journal:ieee:software},
  volume = {16},
  number = {3},
  month = may # {-} # jun,
  year = {1999},
  pages = {96--102}
}

@ARTICLE{Jacobson-etal:2012,
  author = {Jacobson, Ivar and Ng, Pan-Wei and McMahon, Paul E. and Spence, Ian and Lidman, Svante},
  title = {The essence of software engineering: the {SEMAT} kernel},
  crossref = {journal:acm:cacm},
  volume = {55},
  number = {12},
  month = dec,
  year = {2012},
  pages = {42--49},
  doi = {10.1145/2380656.2380670},
  abstract = {A thinking framework in the form of an actionable kernel.}
}

@ARTICLE{Jacobson-etal:2013,
  author = {Jacobson, Ivar and Spence, Ian and Ng, Pan-Wei},
  title = {Agile and {SEMAT}: Perfect Partners},
  crossref = {journal:acm:cacm},
  volume = {56},
  number = {11},
  month = nov,
  year = {2013},
  pages = {53--59},
  doi = {10.1145/2524713.2524723},
  abstract = {Combining agile and SEMAT yields more advantages than either one alone.},
  owner = {magsilva},
  timestamp = {2014.01.30}
}

@INPROCEEDINGS{Jadud-etal:2006,
  author = {Jadud, Matthew C.},
  title = {Methods and tools for exploring novice compilation behaviour},
  crossref = {proceedings:icer:2006},
  pages = {73--84},
  doi = {10.1145/1151588.1151600},
  abstract = {Our research explores what we call compilation behaviour: the programming behaviour a student engages in while repeatedly editing and compiling their programs. This edit-compile cycle often represents students' attempts to make their programs syntactically, as opposed to semantically, correct. Over the course of two years, we have observed first-year university students learning to program in Java, collecting and studying thousands of snapshots of their programs from one compilation to the next. At the University of Kent, students are introduced to programming in an objects-first style using BlueJ, an environment intended for use by novice programmers.},
  keywords = {BlueJ, Java, behavior, compilation, compiler, novice}
}

@INPROCEEDINGS{Jalali-Wohlin:2012,
  author = {Jalali, Samireh and Wohlin, Claes},
  title = {Systematic literature studies: database searches vs. backward snowballing},
  crossref = {proceedings:esem:2012},
  pages = {29--38},
  doi = {10.1145/2372251.2372257},
  abstract = {Systematic studies of the literature can be done in different ways. In particular, different guidelines propose different first steps in their recommendations, e.g. start with search strings in different databases or start with the reference lists of a starting set of papers. In software engineering, the main recommended first step is using search strings in a number of databases, while in information systems, snowballing has been recommended as the first step. This paper compares the two different search approaches for conducting literature review studies. The comparison is conducted by searching for articles addressing "Agile practices in global software engineering". The focus of the paper is on evaluating the two different search approaches. Despite the differences in the included papers, the conclusions and the patterns found in both studies are quite similar. The strengths and weaknesses of each first step are discussed separately and in comparison with each other. It is concluded that none of the first steps is outperforming the other, and the choice of guideline to follow, and hence the first step, may be context-specific, i.e. depending on the area of study.},
  keywords = {agile practices, global software engineering, snowballing, systematic literature review}
}

@ARTICLE{Jamieson:2012,
  author = {Jamieson, L. H.},
  title = {Prolog to the Section on Engineering Education},
  crossref = {journal:ieee:proceedings},
  volume = {100},
  number = {Special Centennial Issue},
  month = {13},
  year = {2012},
  pages = {1342 -1343},
  doi = {10.1109/JPROC.2012.2189818}
}

@INPROCEEDINGS{Janeiro-etal:2010,
  author = {Janeiro, Jordan and Barbosa, Simone D. J. and Springer, Thomas and Schill, Alexander},
  title = {A flexible model for improving the reuse of user interface design patterns},
  crossref = {proceedings:sigdoc:2010},
  pages = {215--221},
  doi = {10.1145/1878450.1878486},
  abstract = {Despite being a set of proven, well-documented, contextualized recommendations for solving frequently occurring user interface design problems, user interface design patterns are still not widely used. We believe this is due to the lack of tools to help designers find patterns and identify how they can be combined to solve user interface design problems. This paper proposes a flexible model to represent UIDPs and their relationships. The flexibility of our model, based on RDF Statements, is to provide a structure to the representation of the UIDPs in order to allow the development of tools to automate their use.},
  keywords = {semantic relationships, user interface design patterns},
  series = {SIGDOC '10},
  acmid = {1878486},
  address = {New York, NY, USA},
  isbn = {978-1-4503-0403-0},
  numpages = {7}
}

@INPROCEEDINGS{Jansen-Bulterman:2008,
  author = {Jansen, Jack and Bulterman, Dick C.A.},
  title = {Enabling adaptive time-based web applications with {SMIL} state},
  crossref = {proceedings:doceng:2008},
  pages = {18--27},
  doi = {10.1145/1410140.1410146},
  abstract = {In this paper we examine adaptive time-based web applications (or presentations). These are interactive presentations where time dictates the major structure, and that require interactivity and other dynamic adaptation. We investigate the current technologies available to create such presentations and their shortcomings, and suggest a mechanism for addressing these shortcomings. This mechanism, SMIL State, can be used to add user-defined state to declarative time-based languages such as SMIL or SVG animation, thereby enabling the author to create control flows that are difficult to realize within the temporal containment model of the host languages. In addition, SMIL State can be used as a bridging mechanism between languages, enabling easy integration of external components into the web application.},
  keywords = {SMIL, declarative languages, delayed ad viewing, multimedia web applications},
  series = {DocEng '08},
  acmid = {1410146},
  address = {New York, NY, USA},
  isbn = {978-1-60558-081-4},
  numpages = {10}
}

@ARTICLE{Jansen:2014,
  author = {Slinger Jansen},
  title = {Measuring the health of open source software ecosystems: Beyond the scope of project health},
  crossref = {journal:elsevier:ist},
  year = {2014},
  doi = {10.1016/j.infsof.2014.04.006},
  abstract = {The livelihood of an open source ecosystem is important to different ecosystem participants: software developers, end-users, investors, and participants want to know whether their ecosystem is healthy and performing well. Currently, there exists no working operationalization available that can be used to determine the health of open source ecosystems. Health is typically looked at from a project scope, not from an ecosystem scope. With such an operationalization, stakeholders can make better decisions on whether to invest in an ecosystem: developers can select the healthiest ecosystem to join, keystone organizers can establish which governance techniques are effective, and end-users can select ecosystems that are robust, will live long, and prosper. Design research is used to create the health operationalization. The evaluation step is done using four ecosystem health projects from literature. The Open Source Ecosystem Health Operationalization is provided, which establishes the health of a complete software ecosystem, using the data from collections of open source projects that belong to the ecosystem. The groundwork is done, by providing a summary of research challenges, for more research in ecosystem health. With the operationalization in hand, researchers no longer need to start from scratch when researching open source ecosystems' health.},
  keywords = {Software ecosystem health, Open source ecosystems, Software repository mining },
  owner = {magsilva},
  timestamp = {2014.05.22}
}

@INBOOK{Janssen-Hermans:2005,
  chapter = {15},
  pages = {253-267},
  title = {How to Integrate Learning Design into Existing Practice},
  year = {2005},
  author = {José Janssen and Henry Hermans},
  crossref = {Koper-Tattersall:2005}
}

@INPROCEEDINGS{Janzen-Saiedian:2008,
  author = {Janzen, David and Saiedian, Hossein},
  title = {Test-driven learning in early programming courses},
  crossref = {proceedings:sigcse:2008},
  pages = {532--536},
  doi = {10.1145/1352135.1352315},
  abstract = {Coercing new programmers to adopt disciplined development practices such as thorough unit testing is a challenging endeavor. Test-driven development (TDD) has been proposed as a solution to improve both software design and testing. Test-driven learning (TDL) has been proposed as a pedagogical approach for teaching TDD without imposing significant additional instruction time. This research evaluates the effects of students using a test-first (TDD) versus test-last approach in early programming courses, and considers the use of TDL on a limited basis in CS1 and CS2. Software testing, programmer productivity, programmer performance, and programmer opinions are compared between test-first and test-last programming groups. Results from this research indicate that a test-first approach can increase student testing and programmer performance, but that early programmers are very reluctant to adopt a test-first approach, even after having positive experiences using TDD. Further, this research demonstrates that TDL can be applied in CS1/2, but suggests that a more pervasive implementation of TDL may be necessary to motivate and establish disciplined testing practice among early programmers.},
  keywords = {cs1, pedagogy, test-driven development, test-driven learning}
}

@ARTICLE{Janzen-Saiedian:2005,
  author = {Janzen, D. and Saiedian, H.},
  title = {Test-driven development concepts, taxonomy, and future direction},
  crossref = {journal:ieee:computer},
  volume = {38},
  number = {9},
  month = sep,
  year = {2005},
  pages = {43--50},
  doi = {10.1109/MC.2005.314},
  abstract = { Test-driven development creates software in very short iterations with minimal upfront design. This strategy requires writing automated tests prior to developing functional code in small, rapid iterations. Although developers have been applying TDD in various forms for several decades, this software development strategy has continued to gain increased attention as one of the core extreme programming practices.}
}

@INPROCEEDINGS{Janzen-etal:2013,
  author = {Janzen, David S. and Clements, John and Hilton, Michael},
  title = {An evaluation of interactive test-driven labs with {WebIDE} in {CS0}},
  crossref = {proceedings:icse:2013},
  pages = {1090--1098},
  abstract = {WebIDE is a framework that enables instructors to develop and deliver online lab content with interactive feedback. The ability to create lock-step labs enables the instructor to guide students through learning experiences, demonstrating mastery as they proceed. Feedback is provided through automated evaluators that vary from simple regular expression evaluation to syntactic parsers to applications that compile and run programs and unit tests. This paper describes WebIDE and its use in a CS0 course that taught introductory Java and Android programming using a test-driven learning approach. We report results from a controlled experiment that compared the use of dynamic WebIDE labs with more traditional static programming labs. Despite weaker performance on pre-study assessments, students who used WebIDE performed two to twelve percent better on all assessments than the students who used traditional labs. In addition, WebIDE students were consistently more positive about their experience in CS0.}
}

@INPROCEEDINGS{Janzen-Hossein:2006,
  author = {Janzen, David S. and Saiedian, Hossein},
  title = {Test-driven learning: intrinsic integration of testing into the {CS/SE} curriculum},
  crossref = {proceedings:sigcse:2006},
  pages = {254--258},
  doi = {10.1145/1121341.1121419},
  abstract = {Test-driven learning (TDL) is an approach to teaching computer programming that involves introducing and exploring new concepts through automated unit tests. TDL offers the potential of teaching testing for free, of improving programmer comprehension and ability, and of improving software quality both in terms of design quality and reduced defect density.This paper introduces test-driven learning as a pedagogical tool. It will provide examples of how TDL can be incorporated at multiple levels in computer science and software engineering curriculum for beginning through professional programmers. In addition, the relationships between TDL and test-driven development will be explored.Initial evidence indicates that TDL can improve student comprehension of new concepts while improving their testing skills with no additional instruction time. In addition, by learning to construct programs in a test-driven manner, students are expected to be more likely to develop their own code with a test-driven approach, likely resulting in improved software designs and quality.},
  keywords = {CS1, extreme programming, pedagogy, test-driven development, test-driven learning}
}

@INPROCEEDINGS{Janzen-Saiedian:2007,
  author = {Janzen, David S. and Saiedian, Hossein},
  title = {A Leveled Examination of Test-Driven Development Acceptance},
  crossref = {proceedings:icse:2007},
  pages = {719--722},
  doi = {10.1109/ICSE.2007.8},
  abstract = {Test-driven development (TDD) has garnered considerable attention in professional settings and has made some inroads into software engineering and computer science education. A series of leveled experiments were conducted with students in beginning undergraduate programming courses through upper-level undergraduate, graduate, and professional training courses. This paper reports that mature programmers who try TDD are more likely to choose TDD over a similar test-last approach. Additionally this research reveals differences in programmer acceptance of TDD between beginning programmers who were reluctant to adopt TDD and more mature programmers who were more willing to adopt TDD. Attention is given to confounding factors, and future studies aimed at resolving these factors are identified. Finally proposals are made to improve early programmer acceptance of TDD.}
}

@INPROCEEDINGS{Jensen:2008b,
  author = {Jensen, Jens F.},
  title = {Interactive Television -- A Brief Media History},
  crossref = {proceedings:euroitv:2008},
  pages = {1--10},
  doi = {10.1007/978-3-540-69478-6_1},
  abstract = {The paper is an attempt at tracing the history of interactive television. The lead that is followed is the various experimental attempts with and the commercial launches of interactive television that have been conducted, as well as the results that have been achieved. This will be done by identifying the various historical phases with different characteristic technological waves, business models, services and contents concepts.},
  keywords = {Interactive Television, interactive media, media history}
}

@INPROCEEDINGS{Jergensen-etal:2011,
  author = {Jergensen, Corey and Sarma, Anita and Wagstrom, Patrick},
  title = {The onion patch: migration in open source ecosystems},
  crossref = {proceedings:fse:2011},
  pages = {70--80},
  doi = {10.1145/2025113.2025127},
  abstract = {Past research established that individuals joining an Open Source community typically follow a socialization process called "the onion model": newcomers join a project by first contributing at the periphery through mailing list discussions and bug trackers and as they develop skill and reputation within the community they advance to central roles of contributing code and making design decisions. However, the modern Open Source landscape has fewer projects that operate independently and many projects under the umbrella of software ecosystems that bring together projects with common underlying components, technology, and social norms. Participants in such an ecosystems may be able to utilize a significant amount of transferrable knowledge when moving between projects in the ecosystem and, thereby, skip steps in the onion model. In this paper, we examine whether the onion model of joining and progressing in a standalone Open Source project still holds true in large project ecosystems and how the model might change in such settings.},
  keywords = {contribution model, open source software, project ecosystem}
}

@ARTICLE{Jia-Harman:2011,
  author = {Yue Jia and Harman, M.},
  title = {An Analysis and Survey of the Development of Mutation Testing},
  crossref = {journal:ieee:tse},
  volume = {37},
  number = {5},
  month = sep # {-} # oct,
  year = {2011},
  pages = {649--678},
  doi = {10.1109/TSE.2010.62},
  abstract = {Mutation Testing is a fault-based software testing technique that has been widely studied for over three decades. The literature on Mutation Testing has contributed a set of approaches, tools, developments, and empirical results. This paper provides a comprehensive analysis and survey of Mutation Testing. The paper also presents the results of several development trend analyses. These analyses provide evidence that Mutation Testing techniques and tools are reaching a state of maturity and applicability, while the topic of Mutation Testing itself is the subject of increasing interest.},
  keywords = {mutation testing; survey}
}

@ARTICLE{Jiang-etal:2013,
  author = {Bo Jiang and Ke Zhai and W.K. Chan and T.H. Tse and Zhenyu Zhang},
  title = {On the adoption of MC/DC and control-flow adequacy for a tight integration of program testing and statistical fault localization },
  crossref = {journal:elsevier:ist},
  volume = {55},
  number = {5},
  month = may,
  year = {2013},
  pages = {897--917},
  doi = {10.1016/j.infsof.2012.10.001},
  abstract = {Context Testing and debugging consume a significant portion of software development effort. Both processes are usually conducted independently despite their close relationship with each other. Test adequacy is vital for developers to assure that sufficient testing effort has been made, while finding all the faults in a program as soon as possible is equally important. A tight integration between testing and debugging activities is essential. Objective The paper aims at finding whether three factors, namely, the adequacy criterion to gauge a test suite, the size of a prioritized test suite, and the percentage of such a test suite used in fault localization, have significant impacts on integrating test case prioritization techniques with statistical fault localization techniques. Method We conduct a controlled experiment to investigate the effectiveness of applying adequate test suites to locate faults in a benchmark suite of seven Siemens programs and four real-life \{UNIX\} utility programs using three adequacy criteria, 16 test case prioritization techniques, and four statistical fault localization techniques. We measure the proportion of code needed to be examined in order to locate a fault as the effectiveness of statistical fault localization techniques. We also investigate the integration of test case prioritization and statistical fault localization with postmortem analysis. Result The main result shows that on average, it is more effective for a statistical fault localization technique to utilize the execution results of a MC/DC-adequate test suite than those of a branch-adequate test suite, and is in turn more effective to utilize the execution results of a branch-adequate test suite than those of a statement-adequate test suite. On the other hand, we find that none of the fault localization techniques studied can be sufficiently effective in suggesting fault-relevant statements that can fit easily into one debug window of a typical IDE. Conclusion We find that the adequacy criterion and the percentage of a prioritized test suite utilized are major factors affecting the effectiveness of statistical fault localization techniques. In our experiment, the adoption of a stronger adequacy criterion can lead to more effective integration of testing and debugging.},
  keywords = {Testing-debugging integration, Test case prioritization, Fault localization, Adequacy criterion, MC/DC }
}

@ARTICLE{Johnson-Miller:2002,
  author = {Johnson, Deborah G. and Miller, Keith W.},
  title = {Is diversity in computing a moral matter?},
  crossref = {journal:acm:sigcse},
  volume = {34},
  number = {2},
  month = jun,
  year = {2002},
  pages = {9--10},
  doi = {10.1145/543812.543814}
}

@INPROCEEDINGS{Johnson:2013,
  author = {Johnson, Julie L.},
  title = {Making programming contest practice worthy of academic credit},
  crossref = {proceedings:sigcse:2013},
  pages = {738--738},
  doi = {10.1145/2445196.2445437},
  abstract = {The ACM Intercollegiate Programming Contest is probably the most prestigious competition of its kind. Decomposing problems into familiar algorithms; making tradeoffs between efficiency and complexity; working on a team under pressure; not only are these skills needed to compete successfully in such a contest, but are also highly valued in industry. The focus of this poster is to describe a course recently added to the curriculum at Vanderbilt University that centers on programming contest skills and yet, somewhat surprisingly, encompasses several significant learning objectives. Because we already had a general idea of what the learning activities of a course like this would be, we were careful not to simply cobble together performance metrics and learning objectives to suit them. This common mistake leads to assessments that devolve into skills tests measuring basic knowledge instead of instruments that gauge a deeper understanding of the target learning objectives. To combat these pitfalls I broke down the learning activity by identifying the skills needed for success in such an exercise. I then classified each skill in two ways. (i) How could this ability play a part in the achievement of some broader, overarching concept and (ii) in what way might the learning and practice of this skill contribute to the deeper understanding of these larger concepts. Our goal is to inform faculty on how they might include a course like this in their programs and to demonstrate its value to the curriculum.},
  keywords = {course design, programming contest}
}

@INPROCEEDINGS{Johnson:2013:SWG:2486788.2487066,
  author = {Johnson, Pontus and Jacobson, Ivar and Goedicke, Michael and Kajko-Mattsson, Mira},
  title = {2nd SEMAT workshop on a general theory of software engineering (GTSE 2013)},
  crossref = {proceedings:icse:2013},
  pages = {1525--1526},
  abstract = {Most academic disciplines emphasize the importance of their general theories. Examples of well-known general theories include the Big Bang theory, Maxwell's equations, the theory of the cell, the theory of evolution, and the theory of demand and supply. Less known to the wider audience, but established within their respective fields, are theories with names such as the general theory of crime and the theory of marriage. Few general theories of software engineering have, however, been proposed, and none have achieved significant recognition. This workshop, organized by the SEMAT initiative, aims to provide a forum for discussing the concept of a general theory of software engineering. The topics considered include the benefits, the desired qualities, the core components and the form of a such a theory.}
}

@INPROCEEDINGS{Johnson:2010,
  author = {Johnson, Ralph E.},
  title = {Software development is program transformation},
  crossref = {proceedings:foser:2010},
  pages = {177--180},
  doi = {10.1145/1882362.1882400},
  abstract = {Since most programmers are working on software that they did not start, their view of programming is that it is the process of converting one version of software to the next. In other words, software development is program transformation. This paper describes some of the implications of this point of view.},
  keywords = {programming environment, refactoring}
}

@ARTICLE{Johnson-Elliot:1984,
  author = {Johnson, W. Lewis and Soloway, Elliot},
  title = {{PROUST}: Knowledge-based program understanding},
  crossref = {journal:ieee:tse},
  volume = {11},
  number = {3},
  month = mar,
  year = {1984},
  pages = {267--275},
  doi = {10.1109/TSE.1985.232210},
  abstract = {This paper describes a program called PROUST which does on-line analysis and understanding of Pascal written by novice programmers. PROUST takes as input a program and a nonalgorithmic description of the program requirements, and finds the most likely mapping between the requirements and the code. This mapping is in essence a reconstruction of the design and implementation steps that the programmer went through in writing the program. A knowledge base of programming plans and strategies, together with common bugs associated with them, is used in constructing this mapping. Bugs are discovered in the process of relating plans to the code; PROUST can therefore give deep explanations of program bugs by relating the buggy code to its underlying intentions.}
}

@ARTICLE{Jones:2004,
  author = {Jones, Christopher G.},
  title = {Test-driven development goes to school},
  crossref = {journal:ccsc:jcsc},
  volume = {20},
  number = {1},
  month = oct,
  year = {2004},
  pages = {220--231},
  abstract = {In industry experiments using test-driven development (TDD), some researchers report significantly increased code quality over traditional test-last approaches. Not surprisingly computing and information technology educators have begun to call for the introduction of TDD into the curriculum. This paper explores the pedagogical experience to date in using a test-first approach in the classroom. Selected studies include four experience reports, one conceptual paper, and three experiments comparing TDD against control groups. Issues in operationalizing TDD across the curriculum are examined, including programming language assertion mechanisms, the feasibility of employing test frameworks, and the automated verification of student test plans. Recommendations derived from the literature are presented.}
}

@INPROCEEDINGS{Jones:ACSE:2000,
  author = {Jones, Edward L.},
  title = {Software testing in the computer science curriculum -- a holistic approach},
  crossref = {proceedings:acse:2000},
  pages = {153--157},
  doi = {10.1145/359369.359392},
  abstract = {Although testing accounts for 50% of the cost of software, it receives little treatment in most curricula. This paper presents some approaches to giving all students multiple, incremental exposures to software testing throughout the curriculum. A unifying framework is presented which identifies a minimal set of test experiences, skills and concepts students should accumulate. The holistic approach combines common test experiences in core courses, an elective course in software testing, and volunteer participation in a test laboratory.}
}

@INPROCEEDINGS{Jones:FIE:2001,
  author = {Jones, Edward L.},
  title = {An experiential approach to incorporating software testing into the computer science curriculum},
  crossref = {proceedings:fie:2001},
  pages = {F3D-7--F3D-11},
  doi = {10.1109/FIE.2001.963741},
  abstract = {Testing accounts for about half of the cost of software, but testing receives little treatment in most curricula. This paper presents an approach to giving students experiences in software testing throughout the curriculum, rather than the usual approach of offering a separate course in testing. The centerpiece of the authors' approach is the Software TestLab, which exists to train selected students in the art and science of testing, and to transfer testing practice into core courses. TestLab students become agents of technology transfer. This paper describes the conceptual framework used to define the set of essential test experiences, and presents lessons learned, to date},
  keywords = {software testing, tester certification}
}

@INPROCEEDINGS{Jones:SIGCSE:2001,
  author = {Edward L. Jones},
  title = {Integrating testing into the curriculum -- arsenic in small doses},
  crossref = {proceedings:sigcse:2001},
  pages = {337--341},
  doi = {10.1145/364447.364617},
  abstract = {Testing accounts for 50% of the cost of software, yet it receives little treatment in most curricula. This paper presents some approaches to giving all students multiple, incremental exposures to software testing throughout the curriculum. A unifying framework is presented which identifies a minimal set of test experiences, skills and concepts students should accumulate. The integrated approach combines common test experiences in core courses, an elective course in software testing, and volunteer participation in a test laboratory.},
  keywords = {software testing, tester certification}
}

@ARTICLE{Jones:JCSC:2000,
  author = {Jones, Edward L.},
  title = {Grading student programs -- a software testing approach},
  crossref = {journal:ccsc:jcsc},
  volume = {16},
  number = {2},
  month = oct,
  year = {2000},
  pages = {185--192},
  abstract = {This paper describes an experience of automating the grading of student programs. A testing framework provides guidance for developing the assignment specification and the grading program. Automation saves time and improves grading consistency and feedback to students. After an adjustment period, student programs improved. Although the instructor invests more time writing a testable assignment specification and developing the grading program, these costs are expected to be amortized over multiple courses and assignments.}
}

@ARTICLE{Jouault200831,
  author = {Jouault, F.a , Allilaire, F.a , Bézivin, J.a , Kurtev, I.b },
  title = {ATL: A model transformation tool},
  crossref = {journal:elsevier:scp},
  volume = {72},
  number = {1--2},
  month = jun,
  year = {2008},
  pages = {31--39},
  doi = {10.1016/j.scico.2007.08.002},
  abstract = {In the context of Model Driven Engineering, models are the main development artifacts and model transformations are among the most important operations applied to models. A number of specialized languages have been proposed, aimed at specifying model transformations. Apart from the software engineering properties of transformation languages, the availability of high quality tool support is also of key importance for the industrial adoption and ultimate success of MDE. In this paper we present ATL: a model transformation language and its execution environment based on the Eclipse framework. ATL tools provide support for the major tasks involved in using a language: editing, compiling, executing, and debugging.},
  keywords = {M2M (model-to-model transformation); Model engineering; Model transformation},
  references = {A. Agrawal, G. Karsai, Z. Kalmar, S. Neema, F. Shi, A. Vizhanyo, The Design of a simple language for graph transformations, Journal in Software and System Modeling (2005) (submitted for publication)Bézivin, J., Jouault, F., Rosenthal, P., Valduriez, P., Modeling in the large and modeling in the small (2004) LNCS, 3599, pp. 33-46. , MDAFA'2004, Springer-Verlag; Budinsky, F., Steinberg, D., Raymond Ellersick, R., Ed Merks, E., Brodsky, S.A., Grose, T.J., (2003) Eclipse Modeling Framework, , Addison Wesley; D. Di Ruscio, F. Jouault, I. Kurtev, J. Bezivin, A. Piearantonio, Extending AMMA for supporting dynamic semantics specifications of DSLs. LINA Research Report number 06.02, University of Nantes, April, 2006Eclipse project, ATL Home Page. http://www.eclipse.org/m2m/atl/F. Jouault, I. Kurtev, On the architectural alignment of ATL and QVT, in: Proceedings of ACM Symposium on Applied Computing, SAC 06, Model Transformation Track, Dijon, Bourgogne, France, April 2006F. Jouault, I. Kurtev, Transforming models with ATL, in: Proceedings of the Model Transformations in Practice Workshop at MoDELS 2005, Montego Bay, Jamaica, 2005F. Jouault, J. Bézivin, KM3: A DSL for metamodel specification FMOODS 2006, Bologna, Italy, 14-16 June 2006Netbeans meta data repository (MDR). http://mdr.netbeans.orgOMG/MOF meta object facility (MOF) specification, OMG Document AD/97-08-14, September 1997. Available from: www.omg.orgOMG/RFP/QVT MOF 2.0 query/views/transformations RFP, OMG document ad/2002-04-10. Available from: www.omg.orgOMG. Object constraint language (OCL), OMG Document ptc/03-10-14, 2003Varró, D., Varró, G., Pataricza, A., Designing the automatic transformation of visual languages (2002) Journal of Science of Computer Programming, 44, pp. 205-227}
}

@INPROCEEDINGS{Juca-etal:2006,
  author = {Paulyne Jucá and Andrino Coêlho and Carlos Ferraz},
  title = {Desenvolvendo, Executando e Controlando Aplicações de Televisão Digital Interativa no SBTVD},
  crossref = {proceedings:wtvd:2006},
  pages = {1--9},
  abstract = {Este artigo descreve os componentes necessários para possibilitar a execução de aplicações de televisão digital em um middleware. Esses componentes são responsáveis por dar suporte ao desenvolvimento, à execução e ao controle do ciclo de vida dessas aplicações. Depois uma breve descrição desses componentes desenvolvidos para suportar a interatividade em um dos middlewares do sistema brasileiro de televisão digital (SBTVD) será fornecida.},
  abstract-en = {This paper describes the middleware components necessary to execute digital television applications. These components are responsible for support the development, execution a life cycle control of these applications. After that, a short description of those components developed to support interactivity in a brazilian digital television system (SBTVD) middleware will be shown.}
}

@INPROCEEDINGS{Junqueira-Fortes:2004,
  author = {D. C. Junqueira and R. P. M. Fortes},
  title = {{VersionWeb}: a Tool for Open Source Software Development Support},
  crossref = {proceedings:webmedia:2004},
  pages = {65--68},
  doi = {10.1109/WEBMED.2004.1348148},
  abstract = {The amount of communities dedicated to software development has grown up stimulated by the support provided by Internet. Although the Web freedom has its benefits, the communities face lack of organization and privacy when using versions control systems. This paper proposes functional increments in a tool that tackle the requirements of providing access control and different types of users and consequently gives support to groups of software developers.}
}

@INPROCEEDINGS{Just:2014,
  author = {Just, René},
  title = {The {Major} Mutation Framework: Efficient and Scalable Mutation Analysis for {Java}},
  crossref = {proceedings:issta:2014},
  pages = {433--436},
  doi = {10.1145/2610384.2628053},
  abstract = {Mutation analysis seeds artificial faults (mutants) into a pro- gram and evaluates testing techniques by measuring how well they detect those mutants. Mutation analysis is well- established in software engineering research but hardly used in practice due to inherent scalability problems and the lack of proper tool support. In response to those challenges, this paper presents Major, a framework for mutation analysis and fault seeding. Major provides a compiler-integrated mu- tator and a mutation analyzer for JUnit tests. Major implements a large set of optimizations to enable efficient and scalable mutation analysis of large software sys- tems. It has already been applied to programs with more than 200,000 lines of code and 150,000 mutants. Moreover, Major features its own domain specific language and is de- signed to be highly configurable to support fundamental re- search in software engineering. Due to its efficiency and flexibility, the Major mutation framework is suitable for the application of mutation analysis in research and practice. It is publicly available at http://mutation-testing.org.},
  keywords = {Mutation testing, compiler-integrated mutation, strong mutation, weak mu- tation},
  owner = {magsilva},
  timestamp = {2014.07.21}
}

@INPROCEEDINGS{Just-etal:2014,
  author = {Just, René and Ernst, Michael D. and Fraser, Gordon},
  title = {Efficient Mutation Analysis by Propagating and Partitioning Infected Execution States},
  crossref = {proceedings:issta:2014},
  pages = {315--326},
  doi = {10.1145/2610384.2610388},
  abstract = {Mutation analysis evaluates a testing technique by measur- ing how well it detects seeded faults (mutants). Mutation analysis is hampered by inherent scalability problems -- a test suite is executed for each of a large number of mutants. Despite numerous optimizations presented in the literature, this scalability issue remains, and this is one of the reasons why mutation analysis is hardly used in practice. Whereas most previous optimizations attempted to stati- cally reduce the number of executions or their computational overhead, this paper exploits information available only at run time to further reduce the number of executions. First, state infection conditions can reveal -- with a single test execution of the unmutated program -- which mutants would lead to a different state, thus avoiding unnecessary test executions. Second, determining whether an infected execution state propagates can further reduce the number of executions. Mutants that are embedded in compound expressions may infect the state locally without affecting the outcome of the compound expression. Third, those mutants that do infect the state can be partitioned based on the resulting infected state -- if two mutants lead to the same infected state, only one needs to be executed as the result of the other can be inferred. We have implemented these optimizations in the Major mu- tation framework and empirically evaluated them on 14 open source programs. The optimizations reduced the mutation analysis time by 40% on average.},
  keywords = {Mutation analysis, dynamic analysis, software testing},
  owner = {magsilva},
  timestamp = {2014.07.21}
}

@ARTICLE{Rene-Schweiggert:2011,
  author = {Just, René and Schweiggert, Franz},
  title = {Automating unit and integration testing with partial oracles},
  crossref = {journal:springer:sqj},
  volume = {19},
  number = {4},
  month = dec,
  year = {2011},
  pages = {753--769},
  doi = {10.1007/s11219-011-9151-x},
  abstract = {The oracle problem is an essential part in current research on automating software tests. Partial oracles seem to be a viable solution, but their suitability for different testing steps and general applicability for various systems remains still to be shown. This paper presents a study in which partial oracles are applied in order to automatically test a jpeg2000 encoder as an example for a modular software system with several integrated units and components. The effectiveness of the partial oracles is measured by means of mutation analysis to determine their adequacy for both unit and integration testing. Additionally, the paper presents possibilities of improving the effectiveness as well as the efficiency of the employed partial oracles. It shows how the knowledge of certain characteristics of the system to be tested, such as linearity or time-invariance, may lead to a better choice of partial oracles and thus to an improved effectiveness and efficiency.},
  keywords = {Test automation; Partial oracles; Metamorphic testing; Integration testing; Mutation analysis; Random testing}
}

@ARTICLE{Kaczmarczyk:2013,
  author = {Kaczmarczyk, Lisa C.},
  title = {{MOO CS!}},
  crossref = {journal:acm:inroads},
  volume = {4},
  number = {1},
  month = mar,
  year = {2013},
  pages = {19--20},
  doi = {10.1145/2432596.2432604}
}

@ARTICLE{Kaczmarczyk:2011a,
  author = {Lisa C. Kaczmarczyk},
  title = {Why I don't want to teach CS1 anymore},
  crossref = {journal:acm:inroads},
  volume = {2},
  number = {2},
  year = {2011},
  pages = {26-27},
  doi = {10.1145/1963533.1963542},
  lang = {en}
}

@ARTICLE{Kaczmarczyk:2011b,
  author = {Kaczmarczyk, Lisa C.},
  title = {Overwhelmed?: prioritize ruthlessly or be a mouse running on a wheel},
  crossref = {journal:acm:inroads},
  volume = {2},
  number = {3},
  month = aug,
  year = {2011},
  pages = {19--20},
  doi = {10.1145/2003616.2003624},
  acmid = {2003624},
  issue = {3},
  issue_date = {September 2011},
  lang = {en},
  numpages = {2}
}

@INPROCEEDINGS{Kaczmarczyk-etal:2010,
  author = {Kaczmarczyk, Lisa C. and Petrick, Elizabeth R. and East, J. Philip and Herman, Geoffrey L.},
  title = {Identifying student misconceptions of programming},
  crossref = {proceedings:sigcse:2010},
  pages = {107--111},
  doi = {10.1145/1734263.1734299},
  abstract = {Computing educators are often baffled by the misconceptions that their CS1 students hold. We need to understand these misconceptions more clearly in order to help students form correct conceptions. This paper describes one stage in the development of a concept inventory for Computing Fundamentals: investigation of student misconceptions in a series of core CS1 topics previously identified as both important and difficult. Formal interviews with students revealed four distinct themes, each containing many interesting misconceptions. Three of those misconceptions are detailed in this paper: two misconceptions about memory models, and data assignment when primitives are declared. Individual misconceptions are related, but vary widely, thus providing excellent material to use in the development of the CI. In addition, CS1 instructors are provided immediate usable material for helping their students understand some difficult introductory concepts.},
  keywords = {concept inventory, cs1, curriculum, misconceptions, pedagogy, programming}
}

@ARTICLE{Kadgi-etal:2007,
  author = {Kagdi, Huzefa and Collard, Michael L. and Maletic, Jonathan I.},
  title = {A survey and taxonomy of approaches for mining software repositories in the context of software evolution},
  crossref = {journal:wiley:jsep},
  volume = {19},
  number = {2},
  month = mar # {--} # apr,
  year = {2007},
  pages = {77--131},
  doi = {10.1002/smr.344},
  abstract = {A comprehensive literature survey on approaches for mining software repositories (MSR) in the context of software evolution is presented. In particular, this survey deals with those investigations that examine multiple versions of software artifacts or other temporal information. A taxonomy is derived from the analysis of this literature and presents the work via four dimensions: the type of software repositories mined (what), the purpose (why), the adopted/invented methodology used (how), and the evaluation method (quality). The taxonomy is demonstrated to be expressive (i.e., capable of representing a wide spectrum of MSR investigations) and effective (i.e., facilitates similarities and comparisons of MSR investigations). Lastly, a number of open research issues in MSR that require further investigation are identified.},
  keywords = {software evolution, mining software repositories, multi-version analysis}
}

@INPROCEEDINGS{Kalliamvakou-etal:2014,
  author = {Kalliamvakou, Eirini and Gousios, Georgios and Blincoe, Kelly and Singer, Leif and German, Daniel M. and Damian, Daniela},
  title = {The Promises and Perils of Mining {GitHub}},
  crossref = {proceedings:msr:2014},
  pages = {92--101},
  doi = {10.1145/2597073.2597074},
  abstract = {With over 10 million git repositories, GitHub is becoming one of the most important source of software artifacts on the Internet. Researchers are starting to mine the information stored in GitHub's event logs, trying to understand how its users employ the site to collaborate on software. However, so far there have been no studies describing the quality and properties of the data available from GitHub. We document the results of an empirical study aimed at understanding the characteristics of the repositories in GitHub and how users take advantage of GitHub's main features---namely commits, pull requests, and issues. Our results indicate that, while GitHub is a rich source of data on software development, mining GitHub for research purposes should take various potential perils into consideration. We show, for example, that the majority of the projects are personal and inactive; that GitHub is also being used for free storage and as a Web hosting service; and that almost 40% of all pull requests do not appear as merged, even though they were. We provide a set of recommendations for software engineering researchers on how to approach the data in GitHub.},
  keywords = {Mining software repositories, bias, code reviews, git, github}
}

@INPROCEEDINGS{Kamalrudin-etal:2010,
  author = {Kamalrudin, Massila and Grundy, John and Hosking, John},
  title = {Tool support for essential use cases to better capture software requirements},
  crossref = {proceedings:ase:2010},
  pages = {255--264},
  doi = {10.1145/1858996.1859047},
  abstract = {Capturing software requirements from clients often leads to error prone and vague requirements documents. To surmount this issue, requirements engineers often choose to use UML models to capture their requirements. In this paper we discuss the use of Essential Use Cases (EUCs) as an alternative, user-centric representation which was developed to ease the process of capturing and describing requirements. However, EUCs are not commonly used in practice because, to our knowledge, no suitable tool support has been developed. In addition, requirements engineers face difficulties in finding the correct "essential" requirements (abstract interactions) in a time efficient manner. In order to overcome these problems, we have developed a prototype tool for automated tracing of abstract interactions. We describe the tool and compare the performance and correctness of the results provided by it to that of manual essential use case extraction efforts by a group of requirements engineers. The results of an end user study of the tool's usefulness and ease of use are also discussed.},
  keywords = {automated tracing tool, essential use cases, requirements extraction},
  timestamp = {2013-08-01}
}

@INPROCEEDINGS{Kamalrudin-etal:2011,
  author = {Kamalrudin, Massila and Hosking, John and Grundy, John},
  title = {Improving requirements quality using essential use case interaction patterns},
  crossref = {proceedings:icse:2011},
  pages = {531--540},
  doi = {10.1145/1985793.1985866},
  abstract = {Requirements specifications need to be checked against the 3C's - Consistency, Completeness and Correctness - in order to achieve high quality. This is especially difficult when working with both natural language requirements and associated semi-formal modelling representations. We describe a technique and support tool that allows us to perform semi-automated checking of natural language and semi-formal requirements models, supporting both consistency management between representations but also correctness and completeness analysis. We use a concept of essential use case interaction patterns to perform the correctness and completeness analysis on the semi-formal representation. We highlight potential inconsistencies, incompleteness and incorrectness using visual differencing in our support tool. We have evaluated our approach via an end user study which focused on the tool's usefulness, ease of use, ease of learning and user satisfaction and provided data for cognitive dimensions of notations analysis of the tool.},
  keywords = {consistency management, essential use cases, requirements engineering, requirements patterns, tool support},
  timestamp = {2013-08-01}
}

@ARTICLE{Kaminski-etal:2011,
  author = {Garrett Kaminski and Upsorn Praphamontripong and Paul Ammann and Jeff Offutt},
  title = {A logic mutation approach to selective mutation for programs and queries},
  crossref = {journal:elsevier:ist},
  volume = {53},
  number = {10},
  month = oct,
  year = {2011},
  pages = {1137--1152},
  doi = {10.1016/j.infsof.2011.03.009},
  abstract = {Program mutation testing is a technique for measuring and generating high quality test data. However, traditional mutation operators are not necessarily efficient or effective. We address three specific issues. One, test data that kills all mutants generated by current mutation tools can still miss detection of some common logic faults because such tools lack appropriate logic mutation operators. Two, the number of mutants generated is often unnecessarily large. Three, many equivalent mutants can be generated and these can be difficult to eliminate. This paper explores the idea of addressing these issues by selectively generating only specially engineered subsuming higher order logic mutants. However, such an approach is only useful if a test set that kills all such mutants also kills a high percentage of general mutants. An empirical study was conducted using a tool that generates only subsuming higher order logic mutants and tools that generate general mutants. Both Java code and SQL were used as the source under test.Results and conclusions For both the software and queries, tests killing all the subsuming higher order mutants killed a high percentage of general mutants while reducing both the number of mutants and the number of equivalent mutants. The conclusion is that, for the test subjects studied, subsuming higher order logic mutation is an effective approach to selective mutation for programs and queries.},
  keywords = {Software logic testing, Mutation testing, Database query testing, Disjunctive Normal Form}
}

@ARTICLE{Kampenes-etal:2007,
  author = {Vigdis By Kampenes and Tore Dybå and Jo E. Hannay and Dag I.K. Sjøberg},
  title = {A systematic review of effect size in software engineering experiments},
  crossref = {journal:elsevier:ist},
  volume = {49},
  number = {11-12},
  year = {2007},
  pages = {1073--1086},
  doi = {10.1016/j.infsof.2007.02.015},
  abstract = {An effect size quantifies the effects of an experimental treatment. Conclusions drawn from hypothesis testing results might be erroneous if effect sizes are not judged in addition to statistical significance. This paper reports a systematic review of 92 controlled experiments published in 12 major software engineering journals and conference proceedings in the decade 1993-2002. The review investigates the practice of effect size reporting, summarizes standardized effect sizes detected in the experiments, discusses the results and gives advice for improvements. Standardized and/or unstandardized effect sizes were reported in 29% of the experiments. Interpretations of the effect sizes in terms of practical importance were not discussed beyond references to standard conventions. The standardized effect sizes computed from the reviewed experiments were equal to observations in psychology studies and slightly larger than standard conventions in behavioral science.},
  keywords = {Empirical software engineering, Controlled experiments, Effect size, Statistical significance, Practical importance},
  lang = {en}
}

@ARTICLE{Kang-Faloutsos:2013,
  author = {Kang, U. and Faloutsos, Christos},
  title = {Big graph mining: algorithms and discoveries},
  crossref = {journal:acm:sigkdd},
  volume = {14},
  number = {2},
  month = apr,
  year = {2013},
  pages = {29--36},
  doi = {10.1145/2481244.2481249},
  abstract = {How do we find patterns and anomalies in very large graphs with billions of nodes and edges? How to mine such big graphs efficiently? Big graphs are everywhere, ranging from social networks and mobile call networks to biological networks and the World Wide Web. Mining big graphs leads to many interesting applications including cyber security, fraud detection, Web search, recommendation, and many more. In this paper we describe Pegasus, a big graph mining system built on top of MapReduce, a modern distributed data processing platform. We introduce GIM-V, an important primitive that Pegasus uses for its algorithms to analyze structures of large graphs. We also introduce HEigen, a large scale eigensolver which is also a part of Pegasus. Both GIM-V and HEigen are highly optimized, achieving linear scale up on the number of machines and edges, and providing 9.2x and 76x faster performance than their naive counterparts, respectively. Using Pegasus, we analyze very large, real world graphs with billions of nodes and edges. Our findings include anomalous spikes in the connected component size distribution, the 7 degrees of separation in a Web graph, and anomalous adult advertisers in the who-follows-whom Twitter social network.}
}

@INPROCEEDINGS{Kaufmann-Janzen:2003,
  author = {Kaufmann, Reid and Janzen, David},
  title = {Implications of test-driven development: a pilot study},
  crossref = {proceedings:oopsla:2003},
  pages = {298--299},
  doi = {10.1145/949344.949421},
  abstract = {A Spring 2003 experiment examines the claims that test-driven development or test-first programming improves software quality and programmer confidence. The results indicate support for these claims and inform larger future experiments.},
  keywords = {agile development, software quality, test-driven development}
}

@INPROCEEDINGS{Kay-etal:1994,
  author = {Kay, David G. and Scott, Terry and Isaacson, Peter and Reek, Kenneth A.},
  title = {Automated grading assistance for student programs},
  crossref = {proceedings:sigcse:1994},
  pages = {381--382},
  doi = {10.1145/191029.191184}
}

@INPROCEEDINGS{Kearse-Hardnett:2008,
  author = {Kearse, Iretta B. and Hardnett, Charles R.},
  title = {Computer science olympiad: exploring computer science through competition},
  crossref = {proceedings:sigcse:2008},
  pages = {92--96},
  doi = {10.1145/1352135.1352167},
  abstract = {Generating interest in specialized areas of Computer Science (CS) is one of the goals of the department of Computer and Information Science at Spelman College as with most departments. Achieving this goal in a new, exciting, and innovative manner provided the inspiration to establish the Spelman College Computer Science Olympiad (SC CS Olympiad). The SC CS Olympiad is patterned after the Olympics athletic event. Students participate in the Olympiad as a part of a team as with the Olympics. In addition, there are several events for competition as there are in the Olympics. The events are designed to expose students to the interesting breadth of CS over several days. In this paper, the events are in the following categories: Cryptography, Robotics, Website Design, Hardware and Software Integration, and Programming. Teams use their CS knowledge and problem-solving skills to complete hands-on exercises in each area. Each teams receives points based on the quality of their results from the exercise. In this paper, we present the implementation, results, and future directions of the Spelman College Computer Science Olympiad.},
  keywords = {competition, computer programming, computer science education, hardware, olympiad, retention, robotics, software, world wide web}
}

@INPROCEEDINGS{Keefe-etal:2006,
  author = {Keefe, Karen and Sheard, Judithe and Dick, Martin},
  title = {Adopting {XP} practices for teaching object oriented programming},
  crossref = {proceedings:ace:2006},
  pages = {91--100},
  abstract = {This paper reports on an Action Research project that investigated the effect of introducing a number of Extreme Programming (XP) practices as teaching techniques to introductory programming students. The focus of the study was on using the XP practices to assist students in an introductory programming subject develop object oriented programming skills, problem solving skills and teach them to become more self-sufficient in their learning. The research is concerned with applying several of the XP practices as a means of value-adding to current pedagogical approaches. The results from this first exploratory cycle have been mixed, but there have been enough positive results to feed forward into the next action research cycle.},
  keywords = {action research, extreme programming, learning to program, pair programming, refactoring, simple design, test driven development}
}

@INPROCEEDINGS{Kelleher-etal:2007,
  author = {Kelleher, Caitlin and Pausch, Randy and Kiesler, Sara},
  title = {Storytelling Alice Motivates Middle School Girls to Learn Computer Programming},
  crossref = {proceedings:chi:2007},
  pages = {1455--1464},
  doi = {10.1145/1240624.1240844},
  abstract = {We describe Storytelling Alice, a programming environment that introduces middle school girls to computer programming as a means to the end of creating 3D animated stories. Storytelling Alice supports story creation by providing 1) a set of high-level animations, that support the use of social characters who can interact with one another, 2) a collection of 3D characters and scenery designed to spark story ideas, and 3) a tutorial that introduces users to writing Alice programs using story-based examples. In a study comparing girls' experiences learning to program using Storytelling Alice and a version of Alice without storytelling support (Generic Alice), we found that users of Storytelling Alice and Generic Alice were equally successful at learning basic programming constructs. Participants found Storytelling Alice and Generic Alice equally easy to use and entertaining. Users of Storytelling Alice were more motivated to program; they spent 42% more time programming, were more than 3 times as likely to sneak extra time to work on their programs, and expressed stronger interest in future use of Alice than users of Generic Alice.},
  keywords = {Alice, children, computer science education, gender, motivation, programming, programming environments}
}

@INPROCEEDINGS{Kelly-etal:2010,
  author = {Kelly, Ashley R. and Wallace, James R. and Cerar, Katie and Randall, Neil and McClelland, Phillip and Seto, Amanda Mindy},
  title = {Solar scramble: an educational children's game for collaborative multi-touch digital tabletops},
  crossref = {proceedings:sigdoc:2010},
  pages = {27--32},
  doi = {10.1145/1878450.1878455},
  abstract = {Our experience report describes the design and development of an educational game for interactive, multi-touch tabletop displays. The game has been designed for children aged 5-10 on the SMART Tabletop platform. This experience report describes the process, design and development of our application and the implications we have drawn from this work in the design of educational technologies for interactive multi-touch tabletops. To investigate the effectiveness of our design, and to identify potential issues in deploying our software, we conducted participant interviews. Based on our design and development process, as well as our participant feedback, we have identified several key issues regarding the development of educational software for K-5 aged (5-10 years old) children on digital tabletops. This research was conducted at the University of Waterloo jointly by the Collaborative Systems Laboratory and the Critical Media Lab.},
  keywords = {digital tabletops, educational games, interactive surfaces, tabletop displays},
  series = {SIGDOC '10},
  acmid = {1878455},
  address = {New York, NY, USA},
  isbn = {978-1-4503-0403-0},
  numpages = {6}
}

@ARTICLE{Kemerer:1987,
  author = {Kemerer, Chris F.},
  title = {An empirical validation of software cost estimation models},
  crossref = {journal:acm:cacm},
  volume = {30},
  number = {5},
  month = may,
  year = {1987},
  pages = {416--429},
  doi = {10.1145/22899.22906},
  abstract = {Practitioners have expressed concern over their inability to accurately estimate costs associated with software development. This concern has become even more pressing as costs associated with development continue to increase. As a result, considerable research attention is now directed at gaining a better understanding of the software-development process as well as constructing and evaluating software cost estimating tools. This paper evaluates four of the most popular algorithmic models used to estimate software costs (SLIM, COCOMO, Function Points, and ESTIMACS). Data on 15 large completed business data-processing projects were collected and used to test the accuracy of the models' ex post effort estimation. One important result was that Albrecht's Function Points effort estimation model was validated by the independent data provided in this study [3]. The models not developed in business data-processing environments showed significant need for calibration. As models of the software-development process, all of the models tested failed to sufficiently reflect the underlying factors affecting productivity. Further research will be required to develop understanding in this area.},
  tags = {software, cost model, metrics}
}

@INPROCEEDINGS{Kemkes-etal:2006,
  author = {Kemkes, Graeme and Vasiga, Troy and Cormack, Gordon},
  title = {Objective Scoring for Computing Competition Tasks},
  crossref = {proceedings:issep:2006},
  pages = {230--241},
  doi = {10.1007/11915355_22},
  abstract = {Computing competitions like the International Olympiad in Informatics (IOI) typically pose several problems that contestants are required to solve by writing a program. The program is tested automatically on several sets of input data to determine whether or not it computes the correct answer within specified time and memory limits. We consider the controversy of whether and how to award partial credit for programs that fail some of the tests. Using item response theory, we analyze the degree to which the scores from these automatic tests, separately and in various combinations, truly reflect the contestants' achievement.},
  owner = {magsilva},
  timestamp = {2014.08.30}
}

@ARTICLE{Khajenoori:1994,
  author = {Khajenoori, S.},
  title = {Process-oriented software education},
  crossref = {journal:ieee:software},
  volume = {11},
  number = {6},
  month = nov,
  year = {1994},
  pages = {99--101},
  doi = {10.1109/52.329412},
  abstract = {In the last few years, development organizations have come to recognize that software development has moved beyond the capabilities of individual programmers and is now an engineering activity performed by teams, and the quality of a software product is highly dependent on the quality of the process used to develop it. The process movement has had a visible effect on the software industry, but how should it influence educators? In this article, the author describes his institution's response. He presents some new views of mature ideas on software quality and productivity.<>},
  keywords = {process-oriented software education;software development;software industry;software productivity;software quality;DP industry;computer science education;software quality;}
}

@ARTICLE{Kick:2012,
  author = {Kick, Richard},
  title = {Computer science principles at {Newbury Park High School}},
  crossref = {journal:acm:inroads},
  volume = {3},
  number = {2},
  month = jun,
  year = {2012},
  pages = {75--77},
  doi = {10.1145/2189835.2189859},
  abstract = {Newbury Park high School in Southern California is one of 10 high schools participating in the 2011-12 pilot of Computer Science Principles. Teacher Richard Kick describes student activities from his course, shares some examples of student work, and reflects on student engagement with the material and the inspiration they draw from it.},
  keywords = {CS 10K, CS principles, computer science education, pedagogy}
}

@ARTICLE{Kilamo-etal:2012,
  author = {Terhi Kilamo and Imed Hammouda and Tommi Mikkonen and Timo Aaltonen},
  title = {From proprietary to open source -- Growing an open source ecosystem},
  crossref = {journal:elsevier:jss},
  volume = {85},
  number = {7},
  month = jul,
  year = {2012},
  pages = {1467--1478},
  doi = {10.1016/j.jss.2011.06.071},
  abstract = {In today's business and software arena, Free/Libre/Open Source Software has emerged as a promising platform for software ecosystems. Following this trend, more and more companies are releasing their proprietary software as open source, forming a software ecosystem of related development projects complemented with a social ecosystem of community members. Since the trend is relatively recent, there are few guidelines on how to create and maintain a sustainable open source ecosystem for a proprietary software. This paper studies the problem of building open source communities for industrial software that was originally developed as closed source. Supporting processes, guidelines and best practices are discussed and illustrated through an industrial case study. The research is paving the road for new directions in growing a thriving open source ecosystem.},
  keywords = {Open source; Software ecosystem; Opening proprietary software; Open source engineering}
}

@INPROCEEDINGS{Kinnunen-etal:2010,
  author = {Kinnunen, Päivi and Meisalo, Veijo and Malmi, Lauri},
  title = {Have we missed something?: identifying missing types of research in computing education},
  crossref = {proceedings:icer:2010},
  pages = {13--22},
  doi = {10.1145/1839594.1839598},
  abstract = {In this paper, we introduce a new way to categorise existing educational research making it possible to find new previously overlooked research topics. This novel categorisation system is based on the didactic foci of the research papers. Our categorisation scheme is not data driven as in previously published categorisation systems but is derived from the didactic triangle, which is a theoretical model describing the elements of a teaching-studying-learning processes. The didactic-focus-based categorisation system can be used to promote discussion about missing types of research foci within the computing education research (CER) community. In addition, the new categorisation system supports meta-level analysis of published research papers and thus contributes to the discussion of the goals and the present state of CER. We analyse previously existing categorisation systems and describe how our system differs. Finally, we give two examples how to apply the new theoretical categorisation system. First, we use research papers published in ICER conferences 2005-2009 as our source material to illustrate how to apply the new theoretical categorisation system for revealing a number of areas for novel research such that seem to have received little attention from the CER community. The second example highlights how the categorisation system can be used to find overlooked research topics on some specific research area (in our example students' success in CS1).},
  keywords = {classification criteria, computing education research, didactic focus, didactic triangle, literature}
}

@ARTICLE{Kirsch-etal:2012,
  author = {Kirsch, Adam and Mitzenmacher, Michael and Pietracaprina, Andrea and Pucci, Geppino and Upfal, Eli and Vandin, Fabio},
  title = {An Efficient Rigorous Approach for Identifying Statistically Significant Frequent Itemsets},
  crossref = {journal:acm:jacm},
  volume = {59},
  number = {3},
  month = jun,
  year = {2012},
  pages = {12:1--12:22},
  doi = {10.1145/2220357.2220359},
  abstract = {As advances in technology allow for the collection, storage, and analysis of vast amounts of data, the task of screening and assessing the significance of discovered patterns is becoming a major challenge in data mining applications. In this work, we address significance in the context of frequent itemset mining. Specifically, we develop a novel methodology to identify a meaningful support threshold s* for a dataset, such that the number of itemsets with support at least s* represents a substantial deviation from what would be expected in a random dataset with the same number of transactions and the same individual item frequencies. These itemsets can then be flagged as statistically significant with a small false discovery rate. We present extensive experimental results to substantiate the effectiveness of our methodology.},
  keywords = {Frequent itemset mining, Poisson approximation, false discovery rate, multi-hypothesis test, statistical significance}
}

@ARTICLE{Kitchenham:2010,
  author = {Barbara Kitchenham},
  title = {What's up with software metrics? -- A preliminary mapping study},
  crossref = {journal:elsevier:jss},
  volume = {83},
  number = {1},
  month = jan,
  year = {2010},
  pages = {37--51},
  doi = {10.1016/j.jss.2009.06.041},
  abstract = {Many papers are published on the topic of software metrics but it is difficult to assess the current status of metrics research. This paper aims to identify trends in influential software metrics papers and assess the possibility of using secondary studies to integrate research results. Search facilities in the SCOPUS tool were used to identify the most cited papers in the years 2000-2005 inclusive. Less cited papers were also selected from 2005. The selected papers were classified according factors such as to main topic, goal and type (empirical or theoretical or mixed). Papers classified as Evaluation studies were assessed to investigate the extent to which results could be synthesized. Compared with less cited papers, the most cited papers were more frequently journal papers, and empirical validation or data analysis studies. However, there were problems with some empirical validation studies. For example, they sometimes attempted to evaluate theoretically invalid metrics and fail to appreciate the importance of the context in which data are collected. This paper, together with other similar papers, confirms that there is a large body of research related to software metrics. However, software metrics researchers may need to refine their empirical methodology before they can answer useful empirical questions.},
  keywords = {Software metrics, Secondary study, Literature survey, Mapping study, Influential papers, Empirical evaluation problems }
}

@ARTICLE{Kitchenham-etal:2010:ese,
  author = {Kitchenham, Barbara A. and Brereton, Pearl and Turner, Mark and Niazi, Mahmood K. and Linkman, Stephen and Pretorius, Rialette and Budgen, David},
  title = {Refining the Systematic Literature Review Process -- two Participant-observer Case Studies},
  crossref = {journal:springer:ese},
  volume = {15},
  number = {6},
  month = dec,
  year = {2010},
  pages = {618--653},
  doi = {10.1007/s10664-010-9134-8},
  abstract = {Systematic literature reviews (SLRs) are a major tool for supporting evidence-based software engineering. Adapting the procedures involved in such a review to meet the needs of software engineering and its literature remains an ongoing process. As part of this process of refinement, we undertook two case studies which aimed 1) to compare the use of targeted manual searches with broad automated searches and 2) to compare different methods of reaching a consensus on quality. For Case 1, we compared a tertiary study of systematic literature reviews published between January 1, 2004 and June 30, 2007 which used a manual search of selected journals and conferences and a replication of that study based on a broad automated search. We found that broad automated searches find more studies than manual restricted searches, but they may be of poor quality. Researchers undertaking SLRs may be justified in using targeted manual searches if they intend to omit low quality papers, or they are assessing research trends in research methodologies. For Case 2, we analyzed the process used to evaluate the quality of SLRs. We conclude that if quality evaluation of primary studies is a critical component of a specific SLR, assessments should be based on three independent evaluators incorporating at least two rounds of discussion.},
  keywords = {Automated search, Broad search, Case study, Manual search, Mapping studies, Quality evaluation process, Systematic literature review, Targeted search},
  owner = {magsilva},
  timestamp = {2014.08.23}
}

@ARTICLE{Kitchenham-etal:2011,
  author = {Barbara A. Kitchenham and David Budgen and O. Pearl Brereton},
  title = {Using mapping studies as the basis for further research -- A participant-observer case study},
  crossref = {journal:elsevier:ist},
  volume = {53},
  number = {6},
  month = jun,
  year = {2011},
  pages = {638--651},
  doi = {10.1016/j.infsof.2010.12.011},
  abstract = {We are strong advocates of evidence-based software engineering (EBSE) in general and systematic literature reviews (SLRs) in particular. We believe it is essential that the SLR methodology is used constructively to support software engineering research. This study aims to assess the value of mapping studies which are a form of SLR that aims to identify and categorise the available research on a broad software engineering topic. We used a multi-case, participant-observer case study using five examples of studies that were based on preceding mapping studies. We also validated our results by contacting two other researchers who had undertaken studies based on preceding mapping studies and by assessing review comments related to our follow-on studies. Our original case study identified 11 unique benefits that can accrue from basing research on a preceding mapping study of which only two were case specific. We also identified nine problems associated with using preceding mapping studies of which two were case specific. These results were consistent with the information obtained from the validation activities. We did not find an example of an independent research group making use of a mapping study produced by other researchers. Mapping studies can save time and effort for researchers and provide baselines to assist new research efforts. However, they must be of high quality in terms of completeness and rigour if they are to be a reliable basis for follow-on research. },
  keywords = {Case study, Systematic literature review, Mapping studies, Software engineering }
}

@INPROCEEDINGS{Kitchenham-etal:2004,
  author = {Barbara A. Kitchenham and Tore Dyba and Magne Jorgensen},
  title = {Evidence-based Software Engineering},
  crossref = {proceedings:icse:2004},
  pages = {273--281},
  doi = {10.1109/ICSE.2004.1317449},
  abstract = {Our objective is to describe how software engineering might benefit from an evidence-based approach and to identify the potential difficulties associated with the approach. We compared the organisation and technical infrastructure supporting evidence-based medicine (EBM) with the situation in software engineering. We considered the impact that factors peculiar to software engineering (i.e. the skill factor and the lifecycle factor) would have on our ability to practice evidence-based software engineering (EBSE). EBSE promises a number of benefits by encouraging integration of research results with a view to supporting the needs of many different stakeholder groups. However, we do not currently have the infrastructure needed for widespread adoption of EBSE. The skill factor means software engineering experiments are vulnerable to subject and experimenter bias. The lifecycle factor means it is difficult to determine how technologies will behave once deployed. Software engineering would benefit from adopting what it can of the evidence approach provided that it deals with the specific problems that arise from the nature of software engineering.}
}

@ARTICLE{Kitchenham-Pfleeger:part2:2002,
  author = {Kitchenham, Barbara A. and Pfleeger, Shari Lawrence},
  title = {Principles of Survey Research Part 2: Designing a Survey},
  crossref = {journal:acm:sen},
  volume = {27},
  number = {1},
  month = jan,
  year = {2002},
  pages = {18--20},
  doi = {10.1145/566493.566495},
  abstract = {This second article of our series looks at the process of designing a survey. The design process begins with reviewing the objectives, examining the target population identified by the objectives, and deciding how best to obtain the information needed to address those objectives. However, we also need to consider factors such as determining the appropriate sample size and ensuring the largest possible response rate.To illustrate our ideas, we use the three surveys described in Part 1 of this series to suggest good and bad practice in software engineering survey research.}
}

@ARTICLE{Kitchenham-Pfleeger:part3:2002,
  author = {Kitchenham, Barbara A. and Pfleeger, Shari Lawrence},
  title = {Principles of Survey Research: Part 3: Constructing a Survey Instrument},
  crossref = {journal:acm:sen},
  volume = {27},
  number = {2},
  month = mar,
  year = {2002},
  pages = {20--24},
  doi = {10.1145/511152.511155},
  abstract = {In this article, we discuss how to construct a questionnaire. We point out the need to use any previous research results to reduce the overheads of survey construction. We identify a number of issues to consider when selecting questions, constructing questions, deciding on the type of question and finalizing the format of the questionnaire.},
  keywords = {question construction, question selection, question types, questionnaire format, survey construction}
}

@ARTICLE{Kitchenham-etal:2012,
  author = {Barbara Ann Kitchenham and Dag I.K. Sjøberg and Tore Dybå and Dietmar Pfahl and Pearl Brereton and David Budgen and Martin Höst and Per Runeson},
  title = {Three empirical studies on the agreement of reviewers about the quality of software engineering experiments},
  crossref = {journal:elsevier:ist},
  volume = {54},
  number = {8},
  month = aug,
  year = {2012},
  pages = {804--819},
  doi = {10.1016/j.infsof.2011.11.008},
  abstract = {During systematic literature reviews it is necessary to assess the quality of empirical papers. Current guidelines suggest that two researchers should independently apply a quality checklist and any disagreements must be resolved. However, there is little empirical evidence concerning the effectiveness of these guidelines. This paper investigates the three techniques that can be used to improve the reliability (i.e. the consensus among reviewers) of quality assessments, specifically, the number of reviewers, the use of a set of evaluation criteria and consultation among reviewers. We undertook a series of studies to investigate these factors. Two studies involved four research papers and eight reviewers using a quality checklist with nine questions. The first study was based on individual assessments, the second study on joint assessments with a period of inter-rater discussion. A third more formal randomised block experiment involved 48 reviewers assessing two of the papers used previously in teams of one, two and three persons to assess the impact of discussion among teams of different size using the evaluations of the teams of one person as a control. For the first two studies, the inter-rater reliability was poor for individual assessments, but better for joint evaluations. However, the results of the third study contradicted the results of Study 2. Inter-rater reliability was poor for all groups but worse for teams of two or three than for individuals. When performing quality assessments for systematic literature reviews, we recommend using three independent reviewers and adopting the median assessment. A quality checklist seems useful but it is difficult to ensure that the checklist is both appropriate and understood by reviewers. Furthermore, future experiments should ensure participants are given more time to understand the quality checklist and to evaluate the research papers.},
  keywords = {Quality evaluation; Empirical studies; Human-intensive experiments; Experimentation; Software engineering}
}

@ARTICLE{Kitchenham-etal:2009:ist,
  author = {Barbara Kitchenham and O. Pearl Brereton and David Budgen and Mark Turner and John Bailey and Stephen Linkman},
  title = {Systematic literature reviews in software engineering - A systematic literature review},
  crossref = {journal:elsevier:ist},
  volume = {51},
  number = {1},
  month = jan,
  year = {2009},
  pages = {7--15},
  doi = {10.1016/j.infsof.2008.09.009},
  abstract = {Background In 2004 the concept of evidence-based software engineering (EBSE) was introduced at the ICSE04 conference.Aims This study assesses the impact of systematic literature reviews (SLRs) which are the recommended EBSE method for aggregating evidence.Method We used the standard systematic literature review method employing a manual search of 10 journals and 4 conference proceedings.Results Of 20 relevant studies, eight addressed research trends rather than technique evaluation. Seven SLRs addressed cost estimation. The quality of SLRs was fair with only three scoring less than 2 out of 4.Conclusions Currently, the topic areas covered by SLRs are limited. European researchers, particularly those at the Simula Laboratory appear to be the leading exponents of systematic literature reviews. The series of cost estimation SLRs demonstrate the potential value of EBSE for synthesising evidence and making it available to practitioners.},
  keywords = {Systematic literature review},
  lang = {en}
}

@ARTICLE{Kitchenham-Brereton:2013,
  author = {Barbara Kitchenham and Pearl Brereton},
  title = {A systematic review of systematic review process research in software engineering},
  crossref = {journal:elsevier:ist},
  volume = {55},
  number = {12},
  month = dec,
  year = {2013},
  pages = {2049--2075},
  doi = {10.1016/j.infsof.2013.07.010},
  abstract = {Many researchers adopting systematic reviews (SRs) have also published papers discussing problems with the SR methodology and suggestions for improving it. Since guidelines for SRs in software engineering (SE) were last updated in 2007, we believe it is time to investigate whether the guidelines need to be amended in the light of recent research. To identify, evaluate and synthesize research published by software engineering researchers concerning their experiences of performing SRs and their proposals for improving the SR process. We undertook a systematic review of papers reporting experiences of undertaking SRs and/or discussing techniques that could be used to improve the SR process. Studies were classified with respect to the stage in the SR process they addressed, whether they related to education or problems faced by novices and whether they proposed the use of textual analysis tools. We identified 68 papers reporting 63 unique studies published in SE conferences and journals between 2005 and mid-2012. The most common criticisms of SRs were that they take a long time, that SE digital libraries are not appropriate for broad literature searches and that assessing the quality of empirical studies of different types is difficult. We recommend removing advice to use structured questions to construct search strings and including advice to use a quasi-gold standard based on a limited manual search to assist the construction of search stings and evaluation of the search process. Textual analysis tools are likely to be useful for inclusion/exclusion decisions and search string construction but require more stringent evaluation. SE researchers would benefit from tools to manage the SR process but existing tools need independent validation. Quality assessment of studies using a variety of empirical methods remains a major problem.},
  keywords = {Systematic review, Systematic literature review, Systematic review methodology, Mapping study},
  timestamp = {2013-10-06}
}

@ARTICLE{Kitchenham-etal:1997,
  author = {Kitchenham, Barbara and Linkman, Steve and Pasquini, Alberto and Nanni, Vincenzo},
  title = {The {SQUID} approach to defining a quality model},
  crossref = {journal:springer:sqj},
  volume = {6},
  number = {3},
  month = sep,
  year = {1997},
  pages = {211--233},
  doi = {10.1023/A:1018516103435},
  abstract = {This paper describes an attempt to use the approach developed by the SQUID project, which was part of the ESPRIT 3 programme, to define the software quality requirements of the Telescience project. The SQUID project developed its approach to quality modelling in parallel with ongoing feedback from testing that approach on the Telescience project, which was both large and software intensive. As part of this exercise we used the ISO software quality standard ISO 9126. It was an assessment of this and other existing quality models that caused us to re-assess what was meant by a quality model and led to a decomposition of existing 'quality models' into a composite model reflecting the different aspects of the model and its mapping onto a specific project or product. We break existing quality models into components which reflect the structure and content of the model. This composite model must then be customized for an individual product/project, we call this customized model a 'Product Quality Model'. Application of this approach to the Telescience project identified a number of practical problems that the SQUID project needed to address. It also indicated a number of problems inherent in the current version of ISO 9126.},
  keywords = {ISO 9126; modelling; evaluation}
}

@INPROCEEDINGS{Kitchenham-Mendes:2009,
  author = {Kitchenham, Barbara and Mendes, Emilia},
  title = {Why Comparative Effort Prediction Studies May Be Invalid},
  crossref = {proceedings:promise:2009},
  pages = {4:1--4:5},
  doi = {10.1145/1540438.1540444},
  abstract = {Background: Many cost estimation papers are based on finding a "new" estimation method, trying out the method on one or two past datasets and "proving" that the new method is better than linear regression. Aim: This paper aims to explain why this approach to model comparison is often invalid and to suggest that the PROMISE repository may be making things worse. Method: We identify some of the theoretical problems with studies that compare different estimation models. We review some of the commonly used datasets from the viewpoint of the reliability of the data and the validity of the proposed linear regression models. Discussion points: It is invalid to select one or two datasets to "prove" the validity of a new technique because we cannot be sure that, of the many published datasets, those chosen are the only ones that favour the new technique. When new models are compared with regression models, researchers need to understand how to use regression analysis appropriately. The use of linear regression presupposes: a linear relationship between dependent and independent variables, no significant outliers, no significant skewness, no relationship between the variance of the dependent variable and the magnitude of the variable. If all these conditions are not true, standard statistical practice is to use a robust regression or transform the data. The logarithmic transformation is appropriate in many cases, and for the Desharnais dataset gives better results than the regression model presented in the PROMISE repository. Conclusions: Simplistic studies comparing data intensive methods with linear regression will be scientifically valueless, if the regression techniques are applied incorrectly. They are also suspect if only a small number of datasets are used and the selection of those datasets is not scientifically justified.},
  keywords = {effort estimation, linear regression, model comparison, model construction},
  owner = {magsilva},
  timestamp = {2014.09.11}
}

@ARTICLE{Kitchenham-etal:2002,
  author = {Kitchenham, B.A. and Pfleeger, S.L. and Pickard, L.M. and Jones, P.W. and Hoaglin, D.C. and El Emam, K. and Rosenberg, J.},
  title = {Preliminary guidelines for empirical research in software engineering},
  crossref = {journal:ieee:tse},
  volume = {28},
  number = {8},
  month = aug,
  year = {2002},
  pages = {721 - 734},
  doi = {10.1109/TSE.2002.1027796},
  abstract = {Empirical software engineering research needs research guidelines to improve the research and reporting processes. We propose a preliminary set of research guidelines aimed at stimulating discussion among software researchers. They are based on a review of research guidelines developed for medical researchers and on our own experience in doing and reviewing software engineering research. The guidelines are intended to assist researchers, reviewers, and meta-analysts in designing, conducting, and evaluating empirical studies. Editorial boards of software engineering journals may wish to use our recommendations as a basis for developing guidelines for reviewers and for framing policies for dealing with the design, data collection, and analysis and reporting of empirical studies.},
  keywords = {software engineering; software researchers; software engineering;}
}

@ARTICLE{Kitchenham-Pfleeger:part6:2003,
  author = {Kitchenham, Barbara and Pfleeger, Shari Lawrence},
  title = {Principles of Survey Research Part 6: Data Analysis},
  crossref = {journal:acm:sen},
  volume = {28},
  number = {2},
  month = mar,
  year = {2003},
  pages = {24--27},
  doi = {10.1145/638750.638758},
  abstract = {This article is the last of our series of articles on survey research. In it, we discuss how to analyze survey data. We provide examples of correct and incorrect analysis techniques used in software engineering surveys.},
  keywords = {statistical analysis, survey methods}
}

@ARTICLE{Kitchenham-Pfleeger:2002,
  author = {Kitchenham, Barbara and Pfleeger, Shari Lawrence},
  title = {Principles of Survey Research Part 4: Questionnaire Evaluation},
  crossref = {journal:acm:sen},
  volume = {27},
  number = {3},
  month = may,
  year = {2002},
  pages = {20--23},
  doi = {10.1145/638574.638580},
  abstract = {This article discusses how to avoid biased questions in survey instruments, how to motivate people to complete instruments and how to evaluate instruments. In the context of survey evaluation, we discuss how to assess survey reliability i.e. how reproducible a survey's data is and survey validity i.e. how well a survey instrument measures what it sets out to measure.},
  keywords = {researcher bias, respondent motivation, survey reliability, survey validity}
}

@ARTICLE{Kitchenham-Pfleeger:part5:2002,
  author = {Kitchenham, Barbara and Pfleeger, Shari Lawrence},
  title = {Principles of Survey Research: Part 5: Populations and Samples},
  crossref = {journal:acm:sen},
  volume = {27},
  number = {5},
  month = sep,
  year = {2002},
  pages = {17--20},
  doi = {10.1145/571681.571686},
  abstract = {This article is the fifth installment of our series of articles on survey research. In it, we discuss what we mean by a population and a sample and the implications of each for survey research. We provide examples of correct and incorrect sampling techniques used in software engineering surveys.},
  keywords = {populations, sampling, survey methods}
}

@ARTICLE{Kitchenham-etal:2010:ist,
  author = {Barbara Kitchenham and Rialette Pretorius and David Budgen and O. Pearl Brereton and Mark Turner and Mahmood Niazi and Stephen Linkman},
  title = {Systematic literature reviews in software engineering -- A tertiary study},
  crossref = {journal:elsevier:ist},
  volume = {52},
  number = {8},
  month = aug,
  year = {2010},
  pages = {792--805},
  doi = {10.1016/j.infsof.2010.03.006},
  abstract = {In a previous study, we reported on a systematic literature review (SLR), based on a manual search of 13 journals and conferences undertaken in the period 1st January 2004 to 30th June 2007. The aim of this on-going research is to provide an annotated catalogue of SLRs available to software engineering researchers and practitioners. This study updates our previous study using a broad automated search. We performed a broad automated search to find SLRs published in the time period 1st January 2004 to 30th June 2008. We contrast the number, quality and source of these SLRs with SLRs found in the original study. Our broad search found an additional 35 SLRs corresponding to 33 unique studies. Of these papers, 17 appeared relevant to the undergraduate educational curriculum and 12 appeared of possible interest to practitioners. The number of SLRs being published is increasing. The quality of papers in conferences and workshops has improved as more researchers use SLR guidelines. SLRs appear to have gone past the stage of being used solely by innovators but cannot yet be considered a main stream software engineering research methodology. They are addressing a wide range of topics but still have limitations, such as often failing to assess primary study quality. },
  keywords = {Systematic literature review, Mapping study, Software engineering, Tertiary study}
}

@ARTICLE{Klau-etal:2010,
  author = {Klau, Gunnar W. and Lesh, Neal and Marks, Joe and Mitzenmacher, Michael},
  title = {Human-guided search},
  crossref = {journal:springer:jh},
  volume = {16},
  number = {3},
  month = jun,
  year = {2010},
  pages = {289--310},
  doi = {10.1007/s10732-009-9107-5},
  abstract = {We present a survey of techniques and results from the Human-Guided Search (HuGS) project, an effort to investigate interactive optimization. HuGS provides simple and general visual metaphors relating to local search operations that allow users to guide the exploration of the search space. These metaphors apply to a wide variety of problems and combinatorial optimization algorithms, which we demonstrate by describing the HuGS toolkit and as well as eight diverse applications we developed using it. User experiments show that human guidance can improve the performance of powerful heuristic search algorithms. HuGS is also a valuable development environment for understanding and improving optimization algorithms. Although HuGS was designed for human-computer interaction, for two different problems we have used the HuGS code base to develop completely automatic heuristic algorithms that produced at the time new best automatic results on benchmark problem instances.},
  keywords = {Human-computer interaction, Interactive optimization, Tabu search}
}

@INPROCEEDINGS{Kleinschmager-etal:2011,
  author = {Kleinschmager, Sebastian and Hanenberg, Stefan},
  title = {How to Rate Programming Skills in Programming Experiments?: A Preliminary, Exploratory, Study Based on University Marks, Pretests, and Self-estimation},
  crossref = {proceedings:plateau:2011},
  pages = {15--24},
  doi = {10.1145/2089155.2089161},
  abstract = {Rating of subjects is an important issue for empirical studies. First, it is desirable for studies that rely on comparisons between different groups to make sure that those groups are balanced, i.e. that subjects in different groups are comparable. Second, in order to understand to what extent the results of a study are generalizable it is necessary to understand whether the used subjects can be considered as representative. Third, for a deeper understanding of an experiment's results it is desirable to understand what different kinds of subjects achieved what results. This paper addresses this topic by a preliminary, exploratory study that analyzes three different possible criteria: university marks, self-estimation, and pretests. It turns out that neither university marks nor pretests yielded better results than self-estimation.},
  keywords = {experimentation, human subjects, programming}
}

@INPROCEEDINGS{Knobelsdorf-etal:2014,
  author = {Knobelsdorf, Maria and Kreitz, Christoph and Böhne, Sebastian},
  title = {Teaching Theoretical Computer Science Using a Cognitive Apprenticeship Approach},
  crossref = {proceedings:sigcse:2014},
  pages = {67--72},
  doi = {10.1145/2538862.2538944},
  abstract = {High failure rates in introductory courses on theoretical computer science are a common problem at universities in Germany, Europe, and North America, as students often have difficulties coping with the contents of such courses due to their abstract and theoretical nature. This paper describes modifications to the pedagogy of a theory course held at the University of Potsdam, Germany that are motivated by a cognitive apprenticeship approach and have led to a significant reduction of the course's failure rates. Since our approach is based on the typical infrastructure for teaching introductory computer science courses and does not require additional expenses or special resources, it can be replicated by other institutions. We believe that it is a serious contribution to better support teaching as well as student learning success in this field.},
  keywords = {cognitive apprenticeship, high failure rates, pedagogy, theoretical computer science, theory of computation}
}

@ARTICLE{Knuth:1965,
  author = {Donald E. Knuth},
  title = {On the translation of languages from left to right},
  crossref = {journal:elsevier:ic},
  volume = {8},
  number = {6},
  month = dec,
  year = {1965},
  pages = {607--639},
  doi = {10.1016/S0019-9958(65)90426-2},
  abstract = {There has been much recent interest in languages whose grammar is sufficiently simple that an efficient left-to-right parsing algorithm can be mechanically produced from the grammar. In this paper, we define LR(k) grammars, which are perhaps the most general ones of this type, and they provide the basis for understanding all of the special tricks which have been used in the construction of parsing algorithms for languages with simple structure, e.g. algebraic languages. We give algorithms for deciding if a given grammar satisfies the LR(k) condition, for given k, and also give methods for generating recognizes for LR(k) grammars. It is shown that the problem of whether or not a grammar is LR(k) for some k is undecidable, and the paper concludes by establishing various connections between LR(k) grammars and deterministic languages. In particular, the LR(k) condition is a natural analogue, for grammars, of the deterministic condition, for languages.},
  owner = {magsilva},
  timestamp = {2014.07.15}
}

@ARTICLE{Knutson-etal:2010,
  author = {Knutson, Charles D. and Krein, Jonathan L. and Prechelt, Lutz and Juristo, Natalia},
  title = {Report from the 1st international workshop on replication in empirical software engineering research ({RESER} 2010)},
  crossref = {journal:acm:sen},
  volume = {35},
  number = {5},
  month = oct,
  year = {2010},
  pages = {42--44},
  doi = {10.1145/1838687.1838698},
  abstract = {The RESER 2010 Workshop, held on May 4, 2010 in Cape Town, South Africa was co-located with the 32nd International Conference on Software Engineering (ICSE 2010). The workshop provided a venue in which empirical Software Engineering researchers could present and discuss the theoretical foundations and methods of replication, as well as the results of specific replicated studies.},
  keywords = {methods, replication, reporting, research, software engineering, validation, validity}
}

@INPROCEEDINGS{Ko-etal:2004,
  author = {Ko, A.J. and Myers, B.A. and Aung, H.H.},
  title = {Six Learning Barriers in End-User Programming Systems},
  crossref = {proceedings:vlhcc:2004},
  pages = {199--206},
  doi = {10.1109/VLHCC.2004.47},
  abstract = {As programming skills increase in demand and utility, the learnability of end-user programming systems is of utmost importance. However, research on learning barriers in programming systems has primarily focused on languages, overlooking potential barriers in the environment and accompanying libraries. To address this, a study of beginning programmers learning Visual Basic.NET was performed. This identified six types of barriers: design, selection, coordination, use, understanding, and information. These barriers inspire a new metaphor of computation, which provides a more learner-centric view of programming system design}
}

@ARTICLE{Kohavi-Longbotham:2011,
  author = {Kohavi, Ron and Longbotham, Roger},
  title = {Unexpected results in online controlled experiments},
  crossref = {journal:acm:sigkdd},
  volume = {12},
  number = {2},
  month = mar,
  year = {2011},
  pages = {31--35},
  doi = {10.1145/1964897.1964905},
  abstract = {Controlled experiments, also called randomized experiments and A/B tests, have had a profound influence on multiple fields, including medicine, agriculture, manufacturing, and advertising. Offline controlled experiments have been well studied and documented since Sir Ronald A. Fisher led the development of statistical experimental design while working at the Rothamsted Agricultural Experimental Station in England in the 1920s. With the growth of the world-wide-web and web services, online controlled experiments are being used frequently, utilizing software capabilities like ramp-up (exposure control) and running experiments on large server farms with millions of users. We share several real examples of unexpected results and lessons learned.},
  keywords = {A/B tests, controlled experiments, statistics, unexpected results}
}

@INPROCEEDINGS{Kolassa-etal:opensym:2013,
  author = {Carsten Kolassa and Dirk Riehle and Michel A. Salim},
  title = {The Empirical Commit Frequency Distribution of Open Source Projects},
  crossref = {proceedings:wikisym-opensym:2013},
  abstract = {A fundamental unit of work in programming is the code contribution (commit) that a developer makes to the code base of the project in work. An author's commit frequency describes how often that author commits. Knowing the distribution of all commit frequencies is a fundamental part of understanding software development processes. This paper presents a detailed quantitative analysis of commit frequencies in open-source software development. The analysis is based on a large sample of open source projects, and presents the overall distribution of commit frequencies. We analyze the data to show the differences between authors and projects by project size; we also includes a comparison of successful and non successful projects and we derive an activity indicator from these analyses. By measuring a fundamental dimension of programming we help improve software development tools and our understanding of software development. We also validate some fundamental assumptions about software development.},
  keywords = {Open source; open source metrics; commit frequency; commit interval; mean time between commits},
  review = {We also show that there is a correlation between activity and successfulness of a project. A project is active at a given point of time when the number of commits in the preceding 12 months is at least 60% of the number of commits in the 12 months before that. [Survivability] We define commit frequency as the number of commits in a time period. However, we actually derive this measure from the commit interval because the commit interval is not prone to timezone errors. The results show that the vast majority of committers works very regularly on open souce projects with 50% of the committers having a median commit interval of less than 13.88 hours. Popularity describes whether the project is used and liked by the open source community. We duse the ohloh popularity index [...] is equal to the number to the number of web pages linking to the project home page as determined by the Yahoo search engine API. To show that the commit frequency is an indicator for project activity, we calculate the median commit frequency in a project over the last 6 months and over the whole lifetime of the project and then we calculate the rtio of those two.},
  timestamp = {2013-08-08}
}

@INPROCEEDINGS{Kolassa-etal:sofsem:2013,
  author = {Kolassa, Carsten and Riehle, Dirk and Salim, Michel A.},
  title = {A Model of the Commit Size Distribution of Open Source},
  crossref = {proceedings:sofsem:2013},
  pages = {52--66},
  doi = {10.1007/978-3-642-35843-2_6},
  abstract = {A fundamental unit of work in programming is the code contribution (commit) that a developer makes to the code base of the project in work. We use statistical methods to derive a model of the probabilistic distribution of commit sizes in open source projects and we show that the model is applicable to different project sizes. We use both graphical as well as statistical methods to validate the goodness of fit of our model. By measuring and modeling a fundamental dimension of programming we help improve software development tools and our understanding of software development.},
  keywords = {Open source; commit sizes; commit size distribution; configuration management; code contributions},
  timestamp = {2013-08-08}
}

@INPROCEEDINGS{Kollanus:2010,
  author = {Kollanus, S.},
  title = {Test-Driven Development - Still a promising approach?},
  crossref = {proceedings:quatic:2010},
  pages = {403--408},
  doi = {10.1109/QUATIC.2010.73},
  abstract = {Test-Driven Development (TDD) has been regarded as a useful practice during the last decade as well in industry as in academia. It has been suggested to have several benefits in software development process. This paper is focused on the reported empirical research on TDD. A systematic literature review was conducted in order to analyze the current empirical evidence. Based on the review data, TDD may improve external code quality, but it also leads to increase in development time. However, there are a lot of contradictory results and it raises a question about the actual factors behind them. More systematic research, specifically controlled experiments and well reported case studies, is needed in order to better understand TDD. © 2010 IEEE.},
  keywords = {Controlled experiment; Development time; Empirical evidence; Empirical research; External code; Software development process; Systematic literature review; Systematic research; Test driven development, Information technology; Research, Software design},
  owner = {magsilva},
  references = {Iterative and incremental developments. A brief history (2003) Computer, 36 (6), pp. 47-56. , L. C. and B. V.R; Astels, D., (2003) Test Driven Development: A Practical Guide, , Upper Saddle River, New Jersey: Prentice Hall; Beck, K., (2003) Test-Driven Development, , By Example, ser. The Addison-Wesley Signature Series. Addison-Wesley; Erdogmus, H., Morisio, M., Torchiano, M., On the effectiveness of the test-first approach to programming (2005) Software Engineering, IEEE Transactions on, 31 (3), pp. 226-237. , March; Janzen, D.S., Saiedian, H., On the influence of test-driven development on software design (2006) CSEET '06: Proceedings of the 19th Conference on Software Engineering Education & Training, pp. 141-148. , Washington, DC, USA: IEEE Computer Society; Edwards, S.H., Using software testing to move students from trial-anderror to reflection-in-action (2004) SIGCSE '04: Proceedings of the 35th SIGCSE Technical Symposium on Computer Science Education, pp. 26-30. , New York, NY, USA: ACM; Nagappan, N., Maximilien, E.M., Bhat, T., Williams, L., Realizing quality improvement through test driven development: Results and experiences of four industrial teams (2008) Empirical Softw. Engg., 13 (3), pp. 289-302; Bhat, T., Nagappan, N., Evaluating the efficacy of test-driven development: Industrial case studies (2006) ISESE '06: Proceedings of the 2006 ACM/IEEE International Symposium on Empirical Software Engineering, pp. 356-363. , New York, NY, USA: ACM; Janzen, D., Saiedian, H., Does test-driven development really improve software design quality? (2008) IEEE Software, 25 (2), pp. 77-84; Kaufmann, R., Janzen, D., Implications of test-driven development: A pilot study (2003) OOPSLA '03: Companion of the 18th Annual ACM SIGPLAN Conference on Object-oriented Programming, Systems, Languages, and Applications, pp. 298-299. , New York, NY, USA: ACM; Steinberg, D.H., The effect of unit tests on entry points, coupling and cohesion in an introductory java programming course (2001) XP Universe Conference'01; Kitchenham, B., Charters, S., Guidelines for performing systematic literature reviews in software engineering (2007) Keele University and Durham University Joint Report, Tech. Rep. EBSE 2007-001, , http://www.dur.ac.uk/ebse/resources/Systematicreviews-5-8.pdf, [Online], Available; Laranjeiro, N., Vieira, M., Extending test-driven development for robust web services (2009) Dependability, 2009. DEPEND '09. Second International Conference on, pp. 122-127. , june; Delamare, R., Baudry, B., Ghosh, S., Traon, Y.L., A test-driven approach to developing pointcut descriptors in aspectj (2009) Software Testing Verification and Validation, 2009. ICST '09. International Conference on, pp. 376-385. , april; Thornton, M., Edwards, S.H., Tan, R.P., Pérez-Qui, M.A., Supporting student-written tests of gui programs (2008) SIGCSE '08: Proceedings of the 39th SIGCSE Technical Symposium on Computer Science Education, pp. 537-541. , New York, NY, USA: ACM; Kollanus, S., Isomöttönen, V., Test-driven development in education: Experiences with critical viewpoints (2008) Proceedings of the 13th Annual Conference on Innovation and Technology in Computer Science Education, pp. 124-127. , New York, NY, USA: ACM; George, B., Williams, L., A structured experiment of test-driven development (2004) Information and Software Technology, 46 (5), pp. 337-342; Gupta, A., Jalote, P., An experimental evaluation of the effectiveness and efficiency of the test driven development (2007) Empirical Software Engineering and Measurement, 2007. ESEM 2007. First International Symposium on, pp. 285-294. , sept; Huang, L., Holcombe, M., Empirical investigation towards the effectiveness of test first programming (2009) Information and Software Technology, 51 (1), pp. 182-194; Pancur, M., Ciglaric, M., Trampus, M., Vidmar, T., Towards empirical evaluation of test-driven development in a university environment (2003) EUROCON 2003. Computer as a Tool. The IEEE Region 8, 2, pp. 83-86. , Sept., vol.2; Muller, M., Hagner, O., Experiment about test-first programming (2002) Software, IEE Proceedings, 149 (5), pp. 131-136. , Oct; Madeyski, L., Preliminary analysis of the effects of pair programming and test-driven development on the external code quality (2005) Proceeding of the 2005 Conference on Software Engineering: Evolution and Emerging Technologies, pp. 113-123. , Amsterdam, The Netherlands, The Netherlands: IOS Press; Maximilien, E., Williams, L., Assessing test-driven development at ibm (2003) Software Engineering, 2003. Proceedings. 25th International Conference on, pp. 564-569. , May; Slyngstad, O.P.N., Li, J., Conradi, R., Rønneberg, H., Landre, E., Wesenberg, H., The impact of test driven development on the evolution of a reusable framework of components - An industrial case study (2008) ICSEA '08: Proceedings of the 2008 the Third International Conference on Software Engineering Advances, pp. 214-223. , Washington, DC, USA: IEEE Computer Society; Sanchez, J., Williams, L., Maximilien, E., On the sustained use of a test-driven development practice at ibm (2007) AGILE 2007, pp. 5-14. , aug; Williams, L., Maximilien, E., Vouk, M., Test-driven development as a defect-reduction practice (2003) Software Reliability Engineering, 2003. ISSRE 2003. 14th International Symposium on, pp. 34-45. , Nov; Damm, L.-O., Lundberg, L., Quality impact of introducing component-level test automation and test-driven development (2007) EuroSPI 2007, 4764, pp. 187-199. , ser. LNCS; Ynchausti, R., Integrating unit testing into a software development teams process (2001) Intl. Conf. EXtreme Programming and Flexible Processes in Software Engineering, pp. 79-83; Lui, K.M., Chan, K.C., Test driven development and software process improvement in China (2004) Extreme Programming and Agile Processes in Software Engineering, pp. 219-222; Madeyski, L., Szala, L., The impact of test-driven development on software development productivity - An empirical study (2007) EuroSPI 2007, 4764, pp. 200-211. , ser. LNCS; Edwards, S.H., Using test-driven development in the classroom: Providing students with automatic, concrete feedback on performance (2003) Proc. Int"l Conf. Education and Information Systems: Technologies and Applications (EISTA 03); Rahman, S., Applying the tbc method in introductory programming courses (2007) Frontiers in Education Conference - Global Engineering: Knowledge without Borders, Opportunities without Passports, 2007. FIE '07. 37th Annual, pp. T1E20-T1E21. , oct; Desai, C., Janzen, D.S., Clements, J., Implications of integrating test-driven development into cs1/cs2 curricula (2009) SIGCSE '09: Proceedings of the 40th ACM Technical Symposium on Computer Science Education, pp. 148-152. , New York, NY, USA: ACM; Xu, S., Li, T., Evaluation of test-driven development: An academic case study (2009) Software Engineering Research, Management and Applications 2009, 253, pp. 229-238. , ser. Studies in Computational Intelligence; Canfora, G., Cimitile, A., Garcia, F., Piattini, M., Visaggio, C.A., Productivity of test driven development: A controlled experiment with professionals (2006) Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics), 4034, pp. 383-388. , Product-Focused Software Process Improvement - 7th International Conference, PROFES 2006, Proceedings; Canfora, G., Cimitile, A., Garcia, F., Piattini, M., Visaggio, C.A., Evaluating advantages of test driven development: A controlled experiment with professionals (2006) ISCE'06 - Proceedings of the 5th ACM-IEEE International Symposium on Empirical Software Engineering, 2006, pp. 364-371. , DOI 10.1145/1159733.1159788, ISCE'06 - Proceedings of the 5th ACM-IEEE International Symposium on Empirical Software Engineering; Madeyski, L., The impact of pair programming and test-driven development on package dependencies in object-oriented design - an experiment (2006) Product-Focused Software Process Improvement, 4034, pp. 278-289. , ser. LNCS; Maeyski, L., The impact of test-first programming on branch coverage and mutation score indicator of unit tests: An experiment (2010) Inf. Softw. Technol., 52 (2), pp. 169-184; Flohr, T., Schneider, T., Lessons learned from an xp experiment with students: Test-first needs more teachings (2006) Intl Conf. Product Focused Software Process Improvement, 4034, p. 305318. , ser. LNCS; Rendell, A., Effective and pragmatic test driven development (2008) Agile, 2008. AGILE '08. Conference, pp. 298-303. , aug; Siniaalto, M., Abrahamsson, P., A comparative case study on the impact of test-driven development on program design and test coverage (2007) Empirical Software Engineering and Measurement, 2007. ESEM 2007. First International Symposium on, pp. 275-284. , sept; Siniaalto, M., Abahamsson, P., Does test-driven development improve the program code? alarming results from a comparative case study (2008) Balancing Agility and Formalism in Software Engineering: Second IFIP TC 2 Central and East European Conference on Software Engineering Techniques, CEE-SET 2007, pp. 143-156. , Berlin, Heidelberg; Geras, A., Smith, M., Miller, J., A prototype empirical evaluation of test driven development (2004) METRICS '04: Proceedings of the Software Metrics, 10th International Symposium, pp. 405-416. , Washington, DC, USA: IEEE Computer Society; Janzen, D., Turner, C., Saiedian, H., Empirical software engineering in industry short courses (2007) Software Engineering Education Training, 2007. CSEET '07. 20th Conference on, pp. 89-96. , july; Vu, J., Frojd, N., Shenkel-Therolf, C., Janzen, D., Evaluating test-driven development in an industry-sponsored capstone project (2009) Information Technology: New Generations, 2009. ITNG '09. Sixth International Conference on, pp. 229-234. , april; George, B., Williams, L., An initial investigation of test driven development in industry (2003) SAC '03: Proceedings of the 2003 ACM Symposium on Applied Computing, pp. 1135-1139. , New York, NY, USA: ACM; Zhang, L., Akifuji, S., Kawai, K., Morioka, T., Comparison between test driven development and waterfall development in a small-scale project (2006) Extreme Programming and Agile Processes in Software Engineering, 4044, pp. 211-212. , ser. LNCS},
  timestamp = {2014.08.19}
}

@INPROCEEDINGS{Kollanus:2011,
  author = {Kollanus, S.},
  title = {Critical issues on test-driven development},
  crossref = {proceedings:profes:2011},
  pages = {322-336},
  doi = {10.1007/978-3-642-21843-9_25},
  abstract = {During the last decade, Test-Driven Development (TDD) has been actively discussed in the software engineering community. It has been regarded as a useful and beneficial software development practice as well in industry as in academia. After a decade of active research, there is still very little critical discussion on TDD in the literature. This paper is based on a literature review and it is focused on identifying and introducing critical viewpoints on TDD. First, the current evidence on TDD's benefits is still weak and it includes several issues. Second, the paper presents a number of other possible issues and challenges with TDD that are referred in the literature. Finally, based on the findings, a list of concrete research questions for the future research is presented. © 2011 Springer-Verlag.},
  keywords = {Concrete research; Critical issues; Engineering community; Issues and challenges; Literature reviews; Software development practices; Test driven development, Research; Software testing, Software design},
  owner = {magsilva},
  references = {Abrahamsson, P., Hanhineva, A., Jäälinoja, J., Improving Business Agility Through Technical Solutions: A Case Study on Test-Driven Development in Mobile Software Development (2006) Business Agility and Information Technology Diffusion. IFIP International Federation for Information Processing, 180, pp. 227-243. , Springer, Boston; Ambler, S.W., Test-driven development of relational databases (2007) IEEE Software, 24 (3), p. 37; Astels, D., (2003) Test Driven Development: A Practical Guide, , Prentice Hall, Upper Saddle River; Beck, K., Aim, fire [test-first coding] (2001) IEEE Software, 18 (5), p. 87; Beck, K., (1999) Extreme Programming Explained: Embrace Change, p. 224. , 1st edn., Addison-Wesley Professional, Reading; Beck, K., Test-Driven Development: By Example (2003) The Addison-Wesley Signature Series, , Addison-Wesley, Reading; Bhat, T., Nagappan, N., Evaluating the efficacy of test-driven development: Industrial case studies (2006) ISESE 2006: Proceedings of the 2006 ACM/IEEE International Symposium on Empirical Software Engineering, pp. 356-363. , ACM, New York; Boehm, B., Turner, R., (2004) Balancing Agility and Discipline - A Guide for the Perplexed, , Addison-Wesley, Reading; Larman, C., Basili, V.R., Iterative and incremental developments. A brief history (2003) Computer, 36 (6), pp. 47-56; Canfora, G., Cimitile, A., Garcia, F., Piattini, M., Visaggio, C.A., Evaluating advantages of test driven development: A controlled experiment with professionals (2006) ISESE 2006: Proceedings of the 2006 ACM/IEEE International Symposium on Empirical Software Engineering, pp. 364-371. , ACM, New York; Canfora, G., Cimitile, A., García, F., Piattini, M., Visaggio, C.A., Productivity of test driven development: A controlled experiment with professionals (2006) LNCS, 4034, pp. 383-388. , Münch, J., Vierimaa, M. (eds.) PROFES 2006. Springer, Heidelberg; Crispin, L., Driving software quality: How test-driven development impacts software quality (2006) IEEE Software, 23 (6), pp. 70-71; Damm, L.-O., Lundberg, L., Quality impact of introducing component-level test automation and test-driven development (2007) LNCS, 4764, pp. 187-199. , Abrahamsson, P., Baddoo, N., Margaria, T., Messnarz, R. (eds.) EuroSPI 2007. Springer, Heidelberg; Desai, C., Janzen, D.S., Clements, J., Implications of integrating test-driven development into cs1/cs2 curricula (2009) SIGCSE 2009: Proceedings of the 40th ACM Technical Symposium on Computer Science Education, pp. 148-152. , ACM, New York; Van Deursen, A., Program comprehension risks and opportunities in extreme programming Proceedings of the Eighth Working Conference on Reverse Engineering (2001); Deursen, A.V., Moonen, L., Bergh, A., Kok, G., Refactoring test code (2001) Proceedings of the 2nd International Conference on Extreme Programming and Flexible Processes in Software Engineering (XP 2001), pp. 92-95; Dybå, T., Dingsøyr, T., Empirical studies of agile software development: A systematic review (2008) Inf. Softw. Technol., 50, pp. 833-859. , http://portal.acm.org/citation.cfm?id=1379905.1379989; Dybå, T., Dingsøyr, T., Strength of evidence in systematic reviews in software engineering (2008) Proceedings of the Second ACM-IEEE International Symposium on Empirical Software Engineering and Measurement, ESEM 2008, pp. 178-187. , http://doi.acm.org/10.1145/1414004.1414034, ACM, New York; Edwards, S.H., Using test-driven development in the classroom: Providing students with automatic, concrete feedback on performance (2003) Proc. Int''l Conf. Education and Information Systems: Technologies and Applications, EISTA 2003; Edwards, S.H., Using software testing to move students from trial-and-error to reflection-in-action (2004) SIGCSE 2004: Proceedings of the 35th SIGCSE Technical Symposium on Computer Science Education, pp. 26-30. , ACM, New York; Erdogmus, H., Morisio, M., Torchiano, M., On the effectiveness of the test-first approach to programming (2005) IEEE Transactions on Software Engineering, 31 (3), pp. 226-237. , doi:10.1109/TSE.2005.37; Flohr, T., Schneider, T., Lessons learned from an XP experiment with students: Test-first needs more teachings (2006) LNCS, 4034, pp. 305-318. , Münch, J., Vierimaa, M. (eds.) PROFES 2006. Springer, Heidelberg; George, B., Williams, L., An initial investigation of test driven development in industry (2004) SAC 2003: Proceedings of the 2003 ACM Symposium on Applied Computing, pp. 1135-1139. , ACM, New York; George, B., Williams, L., A structured experiment of test-driven development (2004) Information and Software Technology, 46 (5), pp. 337-342; Geras, A., Smith, M., Miller, J., A prototype empirical evaluation of test driven development (2004) METRICS 2004: Proceedings of the Software Metrics, 10th International Symposium, pp. 405-416. , IEEE Computer Society, Washington, DC, USA; Grenning, J., Applying test driven development to embedded software (2007) IEEE Instrumentation Measurement Magazine, 10 (6), pp. 20-25; Gupta, A., Jalote, P., An experimental evaluation of the effectiveness and efficiency of the test driven development (2007) First International Symposium on Empirical Software Engineering and Measurement, ESEM 2007, pp. 285-294. , September; Hamill, P., Alexander, D., Shasharina, S., Web service validation enabling test-driven development of service-oriented applications (2009) Proceedings of the 2009 Congress on Services - I, pp. 467-470. , http://portal.acm.org/citation.cfm?id=1590963.1591598, IEEE Computer Society, Washington, DC, USA; Hedin, G., Bendix, L., Magnusson, B., Teaching extreme programming to large groups of students (2005) Journal of Systems and Software, 74 (2), pp. 133-146; Huang, L., Holcombe, M., Empirical investigation towards the effectiveness of test first programming (2009) Information and Software Technology, 51 (1), pp. 182-194; Janzen, D., Saiedian, H., Does test-driven development really improve software design quality? (2008) IEEE Software, 25 (2), pp. 77-84; Janzen, D.S., Saiedian, H., On the influence of test-driven development on software design (2006) CSEET 2006: Proceedings of the 19th Conference on Software Engineering Education & Training, pp. 141-148. , IEEE Computer Society, Washington, DC, USA; Janzen, D.S., Saiedian, H., A leveled examination of test-driven development acceptance (2007) 29th International Conference on Software Engineering, ICSE 2007, pp. 719-722. , May; Janzen, D.S., Turner, C.S., Saiedian, H., Empirical software engineering in industry short courses (2007) 20th Conference on Software Engineering Education Training, CSEET 2007, pp. 89-96. , July; Kaufmann, R., Janzen, D., Implications of test-driven development: A pilot study (2003) OOPSLA 2003: Companion of the 18th Annual ACM SIGPLAN Conference on Object-Oriented Programming, Systems, Languages, and Applications, pp. 298-299. , ACM, New York doi:10.1145/949344.949421; Kitchenham, B., Charters, S., Guidelines for performing systematic literature reviews in software engineering (2007) Keele University and Durham University Joint Report, , http://www.dur.ac.uk/ebse/resources/Systematic-reviews-5-8.pdf, Tech. Rep. EBSE 2007-001; Kollanus, S., Test-driven development - Still a promising approach? (2010) Proceedings of the 7th International Conference on the Quality of Information and Communications Technology, pp. 403-408; Kollanus, S., Isomöttönen, V., Test-driven development in education: Experiences with critical viewpoints (2008) Proceedings of the 13th Annual Conference on Innovation and Technology in Computer Science Education, pp. 124-127. , ACM, New York; Kollanus, S., Isomöttönen, V., Understanding tdd in academic environment: Experiences from two experiments (2009) 8th International Conference on Computing Education Research, Koli Calling 2008, pp. 25-31. , Pears, A., Malmi, L. (eds.); Lui, K.M., Chan, K.C., Test driven development and software process improvement in china (2004) Extreme Programming and Agile Processes in Software Engineering, pp. 219-222; Madeyski, L., Preliminary analysis of the effects of pair programming and test-driven development on the external code quality (2005) Proceeding of the 2005 Conference on Software Engineering: Evolution and Emerging Technologies, pp. 113-123. , IOS Press, Amsterdam; Madeyski, L., The impact of pair programming and test-driven development on package dependencies in object-oriented design - An experiment (2006) LNCS, 4034, pp. 278-289. , Münch, J., Vierimaa, M. (eds.) PROFES 2006. Springer, Heidelberg; Madeyski, L., The impact of test-first programming on branch coverage and mutation score indicator of unit tests: An experiment (2010) Inf. Softw. Technol., 52 (2), pp. 169-184; Madeyski, L., Szata, T., The impact of test-driven development on software development productivity - An empirical study (2007) LNCS, 4764, pp. 200-211. , Abrahamsson, P., Baddoo, N., Margaria, T., Messnarz, R. (eds.) EuroSPI 2007. Springer, Heidelberg; Maximilien, E.M., Williams, L., Assessing test-driven development at ibm (2003) Proceedings of the 25th International Conference on Software Engineering, pp. 564-569. , May; Muller, M.M., Hagner, O., Experiment about test-first programming (2002) Software, IEE Proceedings, 149 (5), pp. 131-136; Nagappan, N., Maximilien, E.M., Bhat, T., Williams, L., Realizing quality improvement through test driven development: Results and experiences of four industrial teams (2008) Empirical Softw. Engg., 13 (3), pp. 289-302; Pancur, M., Ciglaric, M., Trampus, M., Vidmar, T., Towards empirical evaluation of test-driven development in a university environment (2003) The IEEE Region 8, 2, pp. 83-86. , EUROCON 2003. Computer As A Tool. September; Rahman, S.M., Applying the tbc method in introductory programming courses (2007) 37th Annual Frontiers in Education Conference - Global Engineering: Knowledge Without Borders, Opportunities Without Passports, FIE, pp. T1E20-T1E21. , October; Rasmussen, J., Introducing xp into greenfield projects: Lessons learned (2003) IEEE Software, 20 (3), pp. 21-28; Rendell, A., Effective and pragmatic test driven development (2008) Conference on AGILE 2008, pp. 298-303. , August; Sanchez, J.C., Williams, L., Maximilien, E.M., On the sustained use of a test-driven development practice at ibm (2007) AGILE 2007, pp. 5-14. , August; Sangwan, R.S., Laplante, P.A., Test-driven development in large projects (2006) IT Professional, 8 (5), pp. 25-29; Siniaalto, M., Abrahamsson, P., A comparative case study on the impact of test-driven development on program design and test coverage (2007) First International Symposium on Empirical Software Engineering and Measurement, ESEM 2007, pp. 275-284. , September; Siniaalto, M., Abrahamsson, P., Does test-driven development improve the program code? Alarming results from a comparative case study (2008) LNCS, 5082, pp. 143-156. , Meyer, B., Nawrocki, J.R., Walter, B. (eds.) CEE-SET 2007. Springer, Heidelberg; Slyngstad, O.P.N., Li, J., Conradi, R., Rønneberg, H., Landre, E., Wesenberg, H., The impact of test driven development on the evolution of a reusable framework of components - An industrial case study (2008) ICSEA 2008: Proceedings of the 2008 the Third International Conference on Software Engineering Advances, pp. 214-223. , IEEE Computer Society, Washington, DC, USA; Steinberg, D.H., The effect of unit tests on entry points, coupling and cohesion in an introductory java programming course (2001) XP Universe Conference 2001; Tinkham, A., Kaner, C., Experiences teaching a course in programmer testing (2005) ADC 2005: Proceedings of the Agile Development Conference, pp. 298-305. , IEEE Computer Society, Washington, DC, USA; Vodde, B., Koskela, L., Learning test-driven development by counting lines (2007) IEEE Software, 24 (3), pp. 74-79; Vu, J.H., Frojd, N., Shenkel-Therolf, C., Janzen, D.S., Evaluating test-driven development in an industry-sponsored capstone project (2009) Sixth International Conference on Information Technology: New Generations, ITNG 2009, pp. 229-234. , April; Williams, L., Maximilien, E.M., Vouk, M., Test-driven development as a defectreduction practice (2003) 14th International Symposium on Software Reliability Engineering, ISSRE 2003, pp. 34-45. , November; Xu, S., Li, T., Evaluation of test-driven development: An academic case study (2009) Software Engineering Research, Management and Applications 2009. Studies in Computational Intelligence, 253, pp. 229-238; Ynchausti, R.A., Integrating unit testing into a software development team's process (2001) Intl. Conf. EXtreme Programming and Flexible Processes in Software Engineering, pp. 79-83; Zhang, L., Akifuji, S., Kawai, K., Morioka, T., Comparison between test driven development and waterfall development in a small-scale project (2006) LNCS, 4044, pp. 211-212. , Abrahamsson, P., Marchesi, M., Succi, G. (eds.) XP 2006. Springer, Heidelberg},
  timestamp = {2014.08.19}
}

@INPROCEEDINGS{Kollanus-Isomottonen:2008,
  author = {Kollanus, Sami and Isomöttönen, Ville},
  title = {Test-driven development in education: experiences with critical viewpoints},
  crossref = {proceedings:itcse:2008},
  pages = {124--127},
  doi = {10.1145/1384271.1384306},
  abstract = {Test-Driven Development (TDD) was applied in educational setting right after it became well-known as a key practice of Extreme Programming (XP). Basically, there are many studies reporting positive experiences on TDD applied in different levels of a curriculum. In this paper, we discuss the role of TDD in education through the students' experiences. In our experiment, a challenging programming task was applied in order to see what kind of difficulties the students would encounter and discuss. The students' answers revealed several topics that require a careful treatment in teaching to avoid conceptual confusion. For example, the topics include the scalability of TDD, extent of single test, and discipline.},
  keywords = {TDD, education}
}

@INBOOK{Koper:2005,
  chapter = {1},
  pages = {3-20},
  title = {An Introduction to Learning Design},
  year = {2005},
  author = {Rob Koper},
  crossref = {Koper-Tattersall:2005},
  doi = {10.1007/3-540-27360-3_1}
}

@ARTICLE{Korel:1990,
  author = {Korel, Bogdan},
  title = {Automated software test data generation},
  crossref = {journal:ieee:tse},
  volume = {16},
  number = {8},
  month = aug,
  year = {1990},
  pages = {870--879},
  doi = {10.1109/32.57624},
  abstract = {An alternative approach to test-data generation based on actual execution of the program under test, function-minimization methods and dynamic data-flow analysis is presented. Test data are developed for the program using actual values of input variables. When the program is executed, the program execution flow is monitored. If during program execution an undesirable execution flow is observed then function-minimization search algorithms are used to automatically locate the values of input variables for which the selected path is traversed. In addition, dynamic data-flow analysis is used to determine those input variables responsible for the undesirable program behavior, significantly increasing the speed of the search process. The approach to generating test data is then extended to programs with dynamic data structures and a search method based on dynamic data-flow analysis and backtracking is presented. In the approach described, values of array indexes and pointers are known at each step of program execution; this information is used to overcome difficulties of array and pointer handling},
  keywords = {Automated test generation, dynamic data flow analysis, function minimization, software testing, symbolic evaluation},
  owner = {magsilva},
  timestamp = {2014.09.12}
}

@INPROCEEDINGS{Korenjak-Hopcroft:1966,
  author = {Korenjak, A. J. and Hopcroft, J. E.},
  title = {Simple Deterministic Languages},
  crossref = {proceedings:swat:1966},
  pages = {36--46},
  doi = {10.1109/SWAT.1966.22},
  abstract = {The s-languages are those languages recognized by a particular restricted form of deterministic pushdown automaton, called an s-machine. They are uniquely characterized by that subset of the standard-form grammars in which each rule has the form Z -> aY1...Yn, n>=0, and for which the pairs (Z, a) are distinct among the rules. It is shown that the s-languages have the prefix property, and that they include the regular sets with end-markers. Finally, their closure properties and decision problems are examined, and it is found that their equivalence problem is solvable. Since the solvability of the equivalence problem is not known for arbitrary deterministic languages, the s-languages are the most general class of languages for which this problem has been shown to be solvable.},
  owner = {magsilva},
  timestamp = {2014.07.15}
}

@ARTICLE{Koru-Liu:2007,
  author = {A. Günes Koru and Hongfang Liu},
  title = {Identifying and characterizing change-prone classes in two large-scale open-source products},
  crossref = {journal:elsevier:jss},
  volume = {80},
  number = {1},
  month = jan,
  year = {2007},
  pages = {63--73},
  doi = {10.1016/j.jss.2006.05.017},
  abstract = {Developing and maintaining open-source software has become an important source of profit for many companies. Change-prone classes in open-source products increase project costs by requiring developers to spend effort and time. Identifying and characterizing change-prone classes can enable developers to focus timely preventive actions, for example, peer-reviews and inspections, on the classes with similar characteristics in the future releases or products. In this study, we collected a set of static metrics and change data at class level from two open-source projects, KOffice and Mozilla. Using these data, we first tested and validated Pareto's Law which implies that a great majority (around 80%) of change is rooted in a small proportion (around 20%) of classes. Then, we identified and characterized the change-prone classes in the two products by producing tree-based models. In addition, using tree-based models, we suggested a prioritization strategy to use project resources for focused preventive actions in an efficient manner. Our empirical results showed that this strategy was effective for prioritization purposes. This study should provide useful guidance to practitioners involved in development and maintenance of large-scale open-source products.},
  keywords = {Static metrics; Open-source development; Object-oriented programming; Change-prone classes; Software maintenance},
  owner = {magsilva},
  timestamp = {2013.10.11}
}

@INPROCEEDINGS{Kouters-etal:2012,
  author = {Kouters, E. and Vasilescu, B. and Serebrenik, A. and Brand, M. G. J.},
  title = {Who's who in {Gnome}: Using {LSA} to merge software repository identities},
  crossref = {proceedings:icsm:2012},
  pages = {592--595},
  doi = {10.1109/ICSM.2012.6405329},
  abstract = {Understanding an individual's contribution to an ecosystem often necessitates integrating information from multiple repositories corresponding to different projects within the ecosystem or different kinds of repositories (e.g., mail archives and version control systems). However, recognising that different contributions belong to the same contributor is challenging, since developers may use different aliases. It is known that existing identity merging algorithms are sensitive to large discrepancies between the aliases used by the same individual: the noisier the data, the worse their performance. To assess the scale of the problem for a large software ecosystem, we study all Gnome Git repositories, classify the differences in aliases, and discuss robustness of existing algorithms with respect to these types of differences. We then propose a new identity merging algorithm based on Latent Semantic Analysis (LSA), designed to be robust against more types of differences in aliases, and evaluate it empirically by means of cross-validation on Gnome Git authors. Our results show a clear improvement over existing algorithms in terms of precision and recall on worst-case input data.},
  keywords = {identity merging; Gnome; latent semantic analysis}
}

@ARTICLE{Krathwohl:2002,
  author = {David R. Krathwohl},
  title = {A Revision of Bloom's Taxonomy: An Overview},
  crossref = {journal:routledge:tip},
  volume = {41},
  number = {4},
  month = oct # {--} # dec,
  year = {2002},
  pages = {212--218},
  doi = {10.1207/s15430421tip4104_2}
}

@ARTICLE{Krein-etal:2012,
  author = {Krein, Jonathan L. and Knutson, Charles D. and Prechelt, Lutz and Juristo, Natalia},
  title = {Report from the 2nd international workshop on replication in empirical software engineering research ({RESER} 2011)},
  crossref = {journal:acm:sen},
  volume = {37},
  number = {1},
  month = jan,
  year = {2012},
  pages = {27--30},
  doi = {10.1145/2088883.2088889},
  abstract = {The RESER workshop provides a venue in which empirical software engineering researchers can discuss the theoretical foundations and methods of replication, as well as present the results of specific replicated studies. In 2011, the workshop co-located with the International Symposium on Empirical Software Engineering and Measurement (ESEM) in Banff, Alberta, Canada. In addition to several outstanding paper sessions, highlights of the 2011 workshop included a keynote address by Dr. Victor R. Basili, in which he addressed the question, "What's so hard about replication of software engineering experiments?" The workshop also featured a joint replication panel session discussing the first cooperative joint replication ever conducted in empirical software engineering research and a planning session for next year's joint replication project addressing Conway's Law.},
  keywords = {experimentation, methods, replication, reporting, software engineering, validation, validity}
}

@ARTICLE{Krogh-etal:2003,
  author = {Georg von Krogh and Sebastian Spaeth and Karim R Lakhani},
  title = {Community, joining, and specialization in open source software innovation: a case study },
  crossref = {journal:elsevier:research-policy},
  volume = {32},
  number = {7},
  month = jul,
  year = {2003},
  pages = {1217--1241},
  doi = {10.1016/S0048-7333(03)00050-7},
  abstract = {This paper develops an inductive theory of the open source software (OSS) innovation process by focussing on the creation of Freenet, a project aimed at developing a decentralized and anonymous peer-to-peer electronic file sharing network. We are particularly interested in the strategies and processes by which new people join the existing community of software developers, and how they initially contribute code. Analyzing data from multiple sources on the Freenet software development process, we generate the constructs of joining script, specialization, contribution barriers, and feature gifts, and propose relationships among these. Implications for theory and research are discussed.},
  keywords = {Open source software, Innovation, Community, Collective action, Virtual teams },
  owner = {magsilva},
  timestamp = {2014.05.29}
}

@INPROCEEDINGS{Krogstie:2008,
  author = {Birgit R. Krogstie},
  title = {Power through brokering: open source community participation in software engineering student projects},
  crossref = {proceedings:icse:2008},
  pages = {791--800},
  doi = {10.1145/1368088.1368201},
  abstract = {Many software engineering projects use open source software tools or components. The project team's active participation in the open source community may be necessary for the team to use the technology. Based on an in-depth field study of industry software engineering project students interacting with an open source community, we find that participation in the community may affect the team's work and learning by strengthening the power of the broker between the team and the community. We outline pitfalls and benefits of having student teams acquire development-related knowledge from open source communities. The findings are relevant to the organization and supervision of software engineering student projects interacting with open source communities.},
  keywords = {communities of practice, computer science education, floss, open source, software engineering, software engineering education}
}

@ARTICLE{Kruchten-etal:2012,
  author = {Kruchten, Philippe and Nord, Robert L. and Ozkaya, Ipek},
  title = {Technical Debt: From Metaphor to Theory and Practice},
  crossref = {journal:ieee:software},
  volume = {29},
  number = {6},
  month = nov # {--} # dec,
  year = {2012},
  pages = {18--21},
  doi = {10.1109/MS.2012.167},
  abstract = {The metaphor of technical debt in software development was introduced two decades ago to explain to nontechnical stakeholders the need for what we call now refactoring. As the term is being used to describe a wide range of phenomena, this paper proposes an organization of the technical debt landscape, and introduces the papers on technical debt contained in the issue.},
  keywords = {evolvability , maintainability , refactoring , software quality , technical debt}
}

@ARTICLE{Kruchten-etal:2013,
  author = {Philippe Kruchten and Robert L. Nord and Ipek Ozkaya and Davide Falessi},
  title = {Technical debt: towards a crisper definition report on the 4th international workshop on managing technical debt},
  crossref = {journal:acm:sen},
  volume = {38},
  number = {5},
  month = sep,
  year = {2013},
  pages = {51--54},
  doi = {10.1145/2507288.2507326},
  abstract = {As the pace of software delivery increases and technology rapidly changes, organizations seek guidance on how to insure the sustainability of their software development effort. Over the past four years running the workshops on Managing Technical Debt, we have seen increased interest from the software industry to understanding and managing technical debt. A better understanding of the concept of technical debt, and how to approach it, both from a theoretical and a practical perspective is necessary to advance its state of the art and practice. In this paper, we highlight the current confusion in industry on the definition of technical debt, their contributions that have led to a deeper understanding of this concept and the limits of the metaphor, the criteria to discriminate what is technical debt and not, and areas of further investigation.},
  keywords = {technical debt; software economics; software quality; software evolution; state of the practice},
  owner = {magsilva},
  timestamp = {2014.01.16}
}

@INPROCEEDINGS{Krutz-etal:2014,
  author = {Krutz, Daniel E. and Malachowsky, Samuel A. and Reichlmayr, Thomas},
  title = {Using a Real World Project in a Software Testing Course},
  crossref = {proceedings:sigcse:2014},
  pages = {49--54},
  doi = {10.1145/2538862.2538955},
  abstract = {Although testing often accounts for 50% of the budget of a typical software project, the subject of software testing is often overlooked in computing curriculum. Students often view testing as a boring and unnecessary task, and education is usually focused on building software, not ensuring its quality. Previous works have focused on either making the subject of testing more exciting for students or on a more potent lecture-based learning process. At the Department of Software Engineering at the Rochester Institute of Technology, recent efforts have been focused on the project component of our Software Testing course as an area of innovation. Rather than previous methods such as a tightly controlled and repetitive testbed, our students are allowed to choose a real-world, open source project to test throughout the term. With the instructor as both counsel and client, students are expected to deliver a test plan, a final report, and several class-wide presentations. This project has achieved significant student praise; qualitative and quantitative feedback demonstrates both increased satisfaction and fulfilled curricular requirements. Students enjoy the real-world aspect of the project and the ability to work with relevant applications and technologies. This paper outlines the project details and educational goals.},
  keywords = {software engineering education, software project, software testing}
}

@INPROCEEDINGS{Kulesza-etal:2010,
  author = {Raoni Kulesza and Sindolfo M. Filho and Álan Lívio and Rafael R. M. Brandão and Jônatas P. C. Araujo and Guido L. S. Filho},
  title = {{Ginga-J}: Implementação de Referência do Ambiente Imperativo do Middleware {Ginga}},
  crossref = {proceedings:webmedia:2010},
  pages = {35--42},
  abstract = {Este artigo tem como objetivo apresentar a primeira implementação de referência do Ginga-J. Embora desenvolvida para uma plataforma particular, a implementação serviu não apenas como prova de conceito, mas também para levantar diversas questões e principais dificuldades sobre o projeto da arquitetura do software e propor estratégias de implementação que facilitassem a evolução e porte do middleware para outras plataformas. Ginga é o middleware padrão do Sistema Brasileiro de TV Digital e Ginga-J é o ambiente imperativo obrigatório para dispositivos fixos.},
  abstract-en = {This paper aims to present a Ginga-J's reference implementation. Although based on a particular platform, the implementation not only works as a proof of concept, but also raised several issues and difficulties on the software architecture project that should be taken into account to ease extensibility and porting to other platforms. Ginga is the standard middleware for the Brazilian DTV System and its imperative environment (Ginga-J) is mandatory for fixed terrestrial receptors.},
  keywords-en = {DTV middleware, Java, JavaDTV, Digital TV, Ginga, SBTVD}
}

@INPROCEEDINGS{Kulesza-etal:2012,
  author = {Kulesza, Raoni and Meira, Silvio Romero de Lemos and Ferreira, Thales Pordeus and Silva Neto, Vicente Ramos and Alexandre, Eduardo Freire de Santana and Souza Filho, Guido Lemos},
  title = {Towards a generative software development approach for rapid prototyping {iDTV} applications},
  crossref = {proceedings:webmedia:2012},
  pages = {91--98},
  doi = {10.1145/2382636.2382658},
  abstract = {This paper presents an approach for development Interactive Digital TV applications. Methodology seeks to explore concepts and techniques already established in the area of generative software development for rapid prototyping application source code from models. The main goal is to define a systematic method using notations of high level and platform-independent to allow integration of media objects and complex application logic in applications, for example the use of Web Services. In addition, the proposed solution takes care of generating a source compatible with existing authoring tools to allow a subsequent spatial and temporal design of applications. The work also describes a case study for iTV domain for illustration purpose and an experimental pilot study to evaluate the impact of the approach usage.},
  keywords = {authoring tool, digital tv, generative software developmet, model-driven development, multimedia application development}
}

@INPROCEEDINGS{Kumar-Gupta:2013,
  author = {Kumar, Amit and Gupta, Avdhesh},
  title = {Evolution of developer social network and its impact on bug fixing process},
  crossref = {proceedings:isec:2013},
  pages = {63--72},
  doi = {10.1145/2442754.2442764},
  abstract = {Universally accessible and publically archived nature of Bug Tracking System (BTS) of Open Source Software enables developers to follow the work of each other and contribute in bug fixing. The interaction of developers through comments on BTS of project leads to form a social network. The developers and their relationships change over the time resulting in evolution of Developers' social network (DSN). Prior studies (Hong et.al) have compared the evolution of DSN with evolution of general social networks like facebook, twitter etc., showing their resemblance and some differences with them. However these studies don't provide any insight how the evolution of DSN correlate with the effectiveness of bug fixing process over the time. Such insight is helpful as managers can reorganize the teams and issue the guidelines to the developers, accordingly, forcing the communication structure which results in to more effective bug fixing process. In this paper, we first study the evolution of DSN of Eclipse a java based IDE, partially replicating and enhancing the study done by Hong et. al. Then we show how the global social network properties of the DSN e.g. Average Path Length, Clustering Coefficient, modularity etc. has an impact on attributes characterizing effectiveness of bug fixing process like average fix time of the bugs, percentage of bugs fixed etc. We found good correlation between global social network properties and attributes characterizing the bug fixing process.},
  keywords = {Eclipse, bug fixing process, bug tracking system, developer social network, global social network properties, netbeans}
}

@ARTICLE{Kumar:2011,
  author = {Kumar, Deepak},
  title = {Top secret Rosies},
  crossref = {journal:acm:inroads},
  volume = {2},
  number = {1},
  month = mar,
  year = {2011},
  pages = {10--11},
  doi = {10.1145/1929887.1929890}
}

@ARTICLE{Kumar:2009,
  author = {Kumar, Deepak},
  title = {Rebuilding history\ldots again!},
  crossref = {journal:acm:inroads},
  volume = {41},
  number = {2},
  month = jun,
  year = {2009},
  pages = {67--69},
  doi = {10.1145/1595453.1595467}
}

@ARTICLE{Kumar:2008,
  author = {Kumar, Deepak},
  title = {Reflections: historical cheesecakes\ldots},
  crossref = {journal:acm:inroads},
  volume = {40},
  number = {4},
  month = nov,
  year = {2008},
  pages = {11--13},
  doi = {10.1145/1473195.1473200}
}

@INPROCEEDINGS{Kumar-Kannan:2008,
  author = {Kumar, Niraj and Srinathan, Kannan},
  title = {Automatic keyphrase extraction from scientific documents using N-gram filtration technique},
  crossref = {proceedings:doceng:2008},
  pages = {199--208},
  doi = {10.1145/1410140.1410180},
  abstract = {In this paper we present an automatic Keyphrase extraction technique for English documents of scientific domain. The devised algorithm uses n-gram filtration technique, which filters sophisticated n-grams {1dnd4} along with their weight from the words of input document. To develop n-gram filtration technique, we have used (1) LZ78 data compression based technique, (2) a simple refinement step, (3) A simple Pattern Filtration algorithm and, (4) a term weighting scheme. In term weighting scheme, we have introduced the importance of position of sentence (where given phrase occurs first) in document and position of phrase in sentence for documents of scientific domain (which is literally more organized than other domains). The entire system is based upon statistical observations, simple grammatical facts, heuristics, and lexical information of English language. We remark that the devised system does not require a learning phase. Our experimental results with publically available text dataset, shows that the devised system is comparable with other known algorithms.},
  keywords = {information extraction, information retrieval, keyphrase extraction, scientific domain}
}

@INPROCEEDINGS{Kummerfeld-Kay:2003,
  author = {Kummerfeld, Sarah K. and Kay, Judy},
  title = {The neglected battle fields of syntax errors},
  crossref = {proceedings:ace:2003},
  pages = {105--111},
  abstract = {Syntax error correction is an essential part of the debugging process. Yet there has been little research investigating how programmers approach syntax error correction and how to help beginner programmers learn to fix errors efficiently. This paper describes development and evaluation of a tool to support students learning how to correct syntax errors.We collected both quantitative and qualitative data for a small but varied group of students as they corrected syntax errors. This showed that even the more experienced students took significant time to correct some syntax errors. It also indicated that general and language specific programming experience provides both strategic skill in correcting errors and greater depth of understanding of the error messages themselves. At the same time, we observed that beginners can be almost as efficient as more expert users when they have access to our tool for explanations of the less intuitive compile error messages.}
}

@INCOLLECTION{Kurzel:2007,
  author = {Frank Kurzel},
  title = {A Model to Support Alternate Instruction within Learning Environments Delivering Learning Objects},
  chapter = {8},
  pages = {223-238},
  crossref = {Harman-Koohang:2007}
}

@INPROCEEDINGS{Lerario-etal:2012,
  author = {L'Erario, A. and Fabri, J. A. and Domingues, A. and Duarte, A. and Pal'cios, R. and de Paula Pessoa, M. S.},
  title = {A Distributed Software Development Environment Dynamics Model},
  crossref = {proceedings:icgse:2012},
  pages = {184--184},
  doi = {10.1109/ICGSE.2012.13},
  abstract = {This article presents a model of the distributed software envelopment environment. This work used the multiple case studies for create this model. The dynamics and the properties discussed in this work help as guide framework for the network managers. For the stakeholders who are in the strategy of the network, this mapping constitutes the understanding and positioning of the network as a whole and for the sites, represents the group of relationships among them.},
  keywords = {software distributed development, dsd environment dynamics}
}

@ARTICLE{Ladd-Harcourt:2005,
  author = {Ladd, Brian and Harcourt, Ed},
  title = {Student Competitions and Bots in an Introductory Programming Course},
  crossref = {journal:ccsc:jcsc},
  volume = {20},
  number = {5},
  month = may,
  year = {2005},
  pages = {274--284},
  abstract = {An introductory programming course that is both an introduction to the major and a university-wide distribution course can suffer from a large disparity of interest as well as ability. Motivating all students to participate improves outcomes. At St. Lawrence University we have found that competitions are fun and engaging for students while providing a vehicle for both individual and collaborative team projects. We use homegrown robot simulation software to draw students into the course with microworld interaction and animation; student competitions based on popular winter sporting events fit our northern clime and improve engagement.},
  owner = {magsilva},
  timestamp = {2014.08.30}
}

@INPROCEEDINGS{Laender-etal:2008:doceng,
  author = {Laender, Alberto H.F. and Gonçalves, Marcos André and Cota, Ricardo G. and Ferreira, Anderson A. and Santos, Rodrygo L. T. and Silva, Allan J. C.},
  title = {Keeping a digital library clean: new solutions to old problems},
  crossref = {proceedings:doceng:2008},
  pages = {257--262},
  doi = {10.1145/1410140.1410195},
  abstract = {Digital Libraries are complex information systems that involve rich sets of digital objects and their respective metadata, along with multiple organizational structures and services (e.g., searching, browsing, and personalization), and are normally built having a target community of users with specific interests. Central to the success of this type of system is the quality of their services and content. In the context of DLs of scientific literature, among the many problems faced to sustain their information quality, two specific ones, related to information consistency, have taken a lot of attention from the research community: name disambiguation and lack of information to access the full-text of cataloged documents. In this paper, we examine these two problems and describe the solutions we have proposed to solve them.},
  keywords = {citation management, digital libraries, full-text management, information quality, name disambiguation},
  series = {DocEng '08},
  acmid = {1410195},
  address = {New York, NY, USA},
  isbn = {978-1-60558-081-4},
  numpages = {6}
}

@INPROCEEDINGS{Lahtinen-etal:2005,
  author = {Essi. Lahtinen and Kirsti Ala-Mutka and Hannu-Matti Järvinen},
  title = {A study of the difficulties of novice programmers},
  crossref = {proceedings:itcse:2005},
  pages = {14--18},
  doi = {10.1145/1067445.1067453},
  abstract = {Programming is related to several fields of technology, and many university students are studying the basics of it. Unfortunately, they often face difficulties already on the basic courses. This work studies the difficulties in learning programming in order to support developing learning materials for basic programming courses. The difficulties have to be recognized to be able to aid learning and teaching in an effective way.An international survey of opinions was organized for more than 500 students and teachers. This paper analyses the results of the survey. The survey provides information of the difficulties experienced and perceived when learning and teaching programming. The survey results also provide basis for recommendations for developing learning materials and approaches.}
}

@ARTICLE{Lai-Wong:2009,
  author = {Lai, Yiu-chi and Wong, Tak-wah},
  title = {Developing creativity in computer lessons},
  crossref = {journal:acm:inroads},
  volume = {41},
  number = {2},
  month = jun,
  year = {2009},
  pages = {132--135},
  doi = {10.1145/1595453.1595491},
  abstract = {When we examine the recent official curriculum documents published by the Curriculum Development Council in Hong Kong, we can observe that generic skills such as Collaboration Skills, Communication Skills, Creativity, Critical Thinking Skills, Problem-solving Skills etc. are identified as fundamental in helping students to learn. As most people agree that creativity is an essential element in the computer world, we are going to discuss the ways to develop students' creative ability in computer lessons in this paper.},
  keywords = {ICT, creativity, curriculum, thinking strategy}
}

@INPROCEEDINGS{LaiolaGuimaraes-etal:2008,
  author = {Laiola Guimarães, Rodrigo and de Salles Soares Neto, Carlos and Gomes Soares, Luiz Fernando},
  title = {A visual approach for modeling spatiotemporal relations},
  crossref = {proceedings:doceng:2008},
  pages = {285--288},
  doi = {10.1145/1410140.1410202},
  abstract = {Textual programming languages have proven to be difficult to learn and to use effectively for many people. For this sake, visual tools can be useful to abstract the complexity of such textual languages, minimizing the specification efforts. In this paper we present a visual approach for high level specification of spatiotemporal relations. In order to accomplish this task, our visual representation provides an intuitive way to specify complex synchronization events amongst media. Finally, to validate our work, the visual specification is mapped to NCL (Nested Context Language), the standard declarative language of the Brazilian Terrestrial Digital TV System.},
  keywords = {NCL, SBTVD, connector, spatiotemporal relations, synchronization, visual representation, visual specification},
  series = {DocEng '08},
  acmid = {1410202},
  address = {New York, NY, USA},
  isbn = {978-1-60558-081-4},
  numpages = {4}
}

@INPROCEEDINGS{Lampasona-etal:2012,
  author = {Lampasona, Constanza and Heidrich, Jens and Basili, Victor R. and Ocampo, Alexis},
  title = {Software quality modeling experiences at an oil company},
  crossref = {proceedings:esem:2012},
  pages = {243--246},
  doi = {10.1145/2372251.2372296},
  abstract = {The concept of "software quality" is often hard to capture for an organization. Quality models aim at making the concept more operational by refining the "quality" of software development products and processes into sub-concepts down to the level of concrete metrics and indicators. In practice, it is difficult for an organization to come up with a reliable quality model because quality depends on numerous organizational context factors, and the model as well as the metrics and indicators need to be tailored to the specifics of the organization. This paper presents experiences in developing custom-tailored quality models for an organization, exemplified by Ecopetrol, a Colombian oil and gas company. The general approach taken is illustrated and excerpts from the initial model are presented.},
  keywords = {industrial experience, quality measurement and assurance}
}

@INPROCEEDINGS{Lange-Chaudron:2006,
  author = {Lange, Christian F. J. and Chaudron, Michel R. V.},
  title = {Effects of defects in {UML} models: an experimental investigation},
  crossref = {proceedings:icse:2006},
  pages = {401--411},
  doi = {10.1145/1134285.1134341},
  abstract = {The Unified Modeling Language (UML) is the de facto standard for designing and architecting software systems. UML offers a large number of diagram types that can be used with varying degree of rigour. As a result UML models may contain consistency defects. Previous research has shown that industrial UML models that are used as basis for implementation and maintenance contain large numbers of defects. This study investigates to what extent implementers detect defects and to what extent defects cause different interpretations by different readers. We performed two controlled experiments with a large group of students (111) and a group of industrial practitioners (48). The experiment's results show that defects often remain undetected and cause misinterpretations. We present a classification of defect types based on a ranking of detection rate and risk for misinterpretation. Additionally we observed effects of using domain knowledge to compensate defects. The results are generalizable to industrial UML users and can be used for improving quality assurance techniques for UML-based development.},
  keywords = {UML, completeness, consistency, defect detection}
}

@INPROCEEDINGS{Lappalainen-etal:2010,
  author = {Lappalainen, Vesa and Itkonen, Jonne and Isomöttönen, Ville and Kollanus, Sami},
  title = {{ComTest}: a tool to impart {TDD} and unit testing to introductory level programming},
  crossref = {proceedings:itcse:2010},
  pages = {63--67},
  doi = {10.1145/1822090.1822110},
  abstract = {Research has noticed that imparting TDD-like testing to an early computing curriculum is challenging because it increases technical and cognitive load for the students. This paper addresses the challenge with a software-based solution constructed to facilitate the process of writing tests. The solution allows using a compact while efficient syntax for formulating tests, writing tests into JavaDoc comments, thus close to the source code that implements intended functionalities, and automates the generation of actual test code. The constructed solution -- the ComTest tool -- has now been used in four introductory level programming course offerings. The paper presents the tool and concludes with initial lessons learned.},
  keywords = {TDD, education, tools, unit testing}
}

@ARTICLE{Larman-Basili:2003,
  author = {Larman, Craig and Basili, Victor R.},
  title = {Iterative and Incremental Development: A Brief History},
  crossref = {journal:ieee:computer},
  volume = {36},
  number = {6},
  month = jun,
  year = {2003},
  pages = {47--56},
  doi = {10.1109/MC.2003.1204375},
  abstract = {Although many view iterative and incremental development as a modern practice, its application dates as far back as the mid-1950s. Prominent software-engineering thought leaders from each succeeding decade supported IID practices, and many large projects used them successfully. These practices may have differed in their details, but all had a common theme-- to avoid a single-pass sequential, document-driven, gated-step approach.}
}

@ARTICLE{Laserson:2011,
  author = {Laserson, Jonathan},
  title = {From Neural Networks to Deep Learning: zeroing in on the human brain},
  crossref = {journal:acm:xrds},
  volume = {18},
  number = {1},
  month = sep,
  pages = {29--34},
  doi = {10.1145/2000775.2000787},
  abstract = {Pondering the brain with the help of machine learning expert Andrew Ng and researcher-turned-author-turned-entrepreneur Jeff Hawkins.}
}

@ARTICLE{Laski-Korel:1983,
  author = {J. W. Laski and B. Korel},
  title = {A Data Flow Oriented Program Testing Strategy},
  crossref = {journal:ieee:tse},
  volume = {9},
  number = {3},
  month = may,
  year = {1983},
  pages = {347--354},
  abstract = {Some properties of a program data flow can be used to guide program testing. The presented approach aims to exercise use-definition chains that appear in the program. Two such data oriented testing strategies are proposed; the first involves checking liveness of every definition of a variable at the point(s) of its possible use; the second deals with liveness of vectors of variables treated as arguments to an instruction or program block. Reliability of these strategies is discussed with respect to a program containing an error.},
  owner = {magsilva},
  timestamp = {2009.07.16}
}

@ARTICLE{Latorre:2013,
  author = {Latorre, R.},
  title = {Effects of developer experience on learning and applying Unit Test-Driven Development},
  crossref = {journal:ieee:tse},
  doi = {10.1109/TSE.2013.2295827},
  abstract = {Unit Test-Driven Development (UTDD) is a software development practice where unit test cases are specified iteratively and incrementally before production code. In the last years, researchers have conducted several studies within academia and industry on the effectiveness of this software development practice. They have investigated its utility as compared to other development techniques, focusing mainly on code quality and productivity. This quasi-experiment analyzes the influence of the developers' experience level on the ability to learn and apply UTDD. The ability to apply UTDD is measured in terms of process conformance and development time. From the research point of view, our goal is to evaluate how difficult is learning UTDD by professionals without any prior experience in this technique. From the industrial point of view, the goal is to evaluate the possibility of using this software development practice as an effective solution to take into account in real projects. Our results suggest that skilled developers are able to quickly learn the UTDD concepts and, after practicing them for a short while, become as effective in performing small programming tasks as compared to more traditional test-last development techniques. Junior programmers differ only in their ability to discover the best design, and this translates into a performance penalty since they need to revise their design choices more frequently than senior programmers.},
  keywords = {Process Conformance;Programmer Productivity;Software Construction;Software Engineering Process;Software Quality/SQA;Test-Driven Development;Test-First Design}
}

@ARTICLE{Latorre:2014,
  author = {R. Latorre},
  title = {A successful application of a Test-Driven Development strategy in the industrial environment},
  crossref = {journal:elsevier:ese},
  volume = {19},
  number = {3},
  month = jun,
  year = {2014},
  pages = {753--773},
  doi = {10.1007/s10664-013-9281-9},
  abstract = {Unit Test-Driven Development (UTDD) and Acceptance Test-Driven Development (ATDD) are software development techniques to incrementally develop software where the test cases, unit or acceptance tests respectively, are specified before the functional code. There are little empirical evidences supporting or refuting the utility of these techniques in an industrial context. Just a few case studies can be found in literature within the industrial environment and they show conflicting results (positive, negative and neutral). In this report, we present a successful application of UTDD in combination with ATDD in a commercial project. By successful we mean that the project goals are reached without an extra economic cost. All the UTDD and ATDD implementations are based on the same basic concepts, but they may differ in specific adaptations to each project or team. In the implementation presented here, the business requirements are specified by means of executable acceptance tests, which then are the input of a development process where the functional code is written in response to specific unit tests. Our goal is to share our successful experience in a specific project from an empirical point of view. We highlight the advantages and disadvantages of adopting UTDD and ATDD and identify some conditions that facilitate success. The main conclusions we draw from this project are that ATDD contributes to clearly capture and validate the business requirements, but it requires an extensive cooperation from the customer; and that UTDD has not a significant impact neither on productivity nor on software quality. These results cannot be generalized, but they point out that under some circumstances a test-driven development strategy can be a possible option to take into account by software professionals.},
  keywords = {Acceptance Test-Driven Development (ATDD); Experience report; Software construction; Software engineering process; Software quality/SQA; Test-first design; Unit Test-Driven Development (UTDD)},
  owner = {magsilva},
  timestamp = {2014.08.24}
}

@ARTICLE{Lavazza-etal:2013,
  author = {Luigi Lavazza and Sandro Morasca and Gabriela Robiolo},
  title = {Towards a simplified definition of Function Points },
  crossref = {journal:elsevier:ist},
  volume = {55},
  number = {10},
  month = oct,
  year = {2013},
  pages = {1796--1809},
  doi = {10.1016/j.infsof.2013.04.003},
  abstract = {AbstractBackground The measurement of Function Points is based on Base Functional Components. The process of identifying and weighting Base Functional Components is hardly automatable, due to the informality of both the Function Point method and the requirements documents being measured. So, Function Point measurement generally requires a lengthy and costly process. Objectives We investigate whether it is possible to take into account only subsets of Base Functional Components so as to obtain functional size measures that simplify Function Points with the same effort estimation accuracy as the original Function Points measure. Simplifying the definition of Function Points would imply a reduction of measurement costs and may help spread the adoption of this type of measurement practices. Specifically, we empirically investigate the following issues: whether available data provide evidence that simplified software functionality measures can be defined in a way that is consistent with Function Point Analysis; whether simplified functional size measures by themselves can be used without any appreciable loss in software development effort prediction accuracy; whether simplified functional size measures can be used as software development effort predictors in models that also use other software requirements measures. Method We analyze the relationships between Function Points and their Base Functional Components. We also analyze the relationships between Base Functional Components and development effort. Finally, we built effort prediction models that contain both the simplified functional measures and additional requirements measures. Results Significant statistical models correlate Function Points with Base Functional Components. Basic Functional Components can be used to build models of effort that are equivalent, in terms of accuracy, to those based on Function Points. Finally, simplified Function Points measures can be used as software development effort predictors in models that also use other requirements measures. Conclusion The definition and measurement processes of Function Points can be dramatically simplified by taking into account a subset of the Base Functional Components used in the original definition of the measure, thus allowing for substantial savings in measurement effort, without sacrificing the accuracy of software development effort estimates. },
  keywords = {Functional size measurement; Function Points; Effort prediction }
}

@ARTICLE{Leal-Silva:2003,
  author = {Leal, José Paulo and Silva, Fernando},
  title = {{Mooshak}: a {Web}-based multi-site programming contest system},
  crossref = {journal:wiley:spe},
  volume = {33},
  number = {6},
  month = may,
  year = {2003},
  pages = {567--581},
  doi = {10.1002/spe.522},
  abstract = {This paper presents a new Web-based system, Mooshak, to handle programming contests. The system acts as a full contest manager as well as an automatic judge for programming contests. Mooshak innovates in a number of aspects: it has a scalable architecture that can be used from small single server contests to complex multi-site contests with simultaneous public online contests and redundancy; it has a robust data management system favoring simple procedures for storing, replicating, backing up data and failure recovery using persistent objects; it has automatic judging capabilities to assist human judges in the evaluation of programs; it has built-in safety measures to prevent users from interfering with the normal progress of contests. Mooshak is an open system implemented on the Linux operating system using the Apache HTTP server and the Tcl scripting language.This paper starts by describing the main features of the system and its architecture with reference to the automated judging, data management based on the replication of persistent objects over a network. Finally, we describe our experience using this system for managing two official programming contests. Copyright © 2003 John Wiley & Sons, Ltd.},
  keywords = {Web application, contest management, program evaluation, automatic judging}
}

@INPROCEEDINGS{Leary-etal:2011,
  author = {Leary, Heather and Recker, Mimi and Walker, Andrew and Wetzler, Philipp and Sumner, Tamara and Martin, James},
  title = {Automating open educational resources assessments: a machine learning generalization study},
  crossref = {proceedings:JCDL:2011},
  pages = {283--286},
  doi = {10.1145/1998076.1998129},
  abstract = {Assessing the quality of online educational resources in a cost effective manner is a critical issue for educational digital libraries. This study reports on the approach for extending the Open Educational Resource Assessments (OPERA) algorithm from assessing vetted to peer-produced content. This article reports details of changes to the algorithm, comparisons between human raters and the algorithm, and the extent the algorithm can automate the review process.},
  keywords = {education digital library, machine learning, resource quality}
}

@INPROCEEDINGS{Leitao-etal:2008,
  author = {Leitao-Junior, Plinio S. and Vilela, Plinio R. S. and Jino, Mario},
  title = {Data Flow Testing of SQL-Based Active Database Applications},
  crossref = {proceedings:icsea:2008},
  pages = {230--236},
  doi = {10.1109/ICSEA.2008.57},
  abstract = {The relevance of reactive capabilities as a unifying paradigm for handling a number of database features and applications is well-established. Active database systems have been used to implement the persistent data requirements of applications on several knowledge domains. They extend passive ones by automatically performing predefined actions in response to events that they monitor. These reactive abilities are generally expressed with active rules defined within the database itself. We investigate the use of data flow-based testing to identify the presence of faults in active rules written in SQL. The goal is to improve reliability and overall quality in this realm. Our contribution is the definition of a family of adequacy criteria, which require the coverage of inter-rule persistent data flow associations, and its effectiveness in various data flow analysis precisions. Both theoretical and empirical investigations show that the criteria have strong fault detecting ability at a polynomial complexity cost.},
  keywords = {Active database applications, testing adequacy criteria, SQL-based applications, Data flow testing}
}

@INPROCEEDINGS{Leite-etal:2006,
  author = {Leite, Luiz Eduardo Cunha and de Souza Filho, Guido Lemos and de Lemos Meira, Silvio R. and de Ar\'{u}jo, Patrick Carlos T. and de A. Lima, Jefferson Ferreira and Filho, Sindolfo Miranda},
  title = {Uma proposta de modelo de componentes para sistemas embarcados e seu uso para adicionar capacidade de reconfiguração ao middleware {FlexTV}},
  crossref = {proceedings:webmedia:2006},
  pages = {203--212},
  doi = {10.1145/1186595.1186620},
  abstract = {O FlexTV é uma proposta de middleware de referência desenvolvida para o Sistema Brasileiro de TV Digital. Apesar de ter uma arquitetura modular, a primeira versão do FlexTV não utilizou um modelo de componentes que possibilitasse a sua reconfiguração em tempo de execução. Este trabalho apresenta um modelo de componentes projetado para ser utilizado em sistemas embarcados como, por exemplo, Set-Top Boxes(STB) e aparelhos de televisão digital. O modelo proposto foi utilizado no middleware FlexTV agregando a este funcionalidades que tornaram possível a reconfiguração (adição, remoção e substituição) dos seus componentes em tempo de execução. Além disso, esse trabalho apresenta a arquitetura de alto nível de um mecanismo que possibilita que seja gerada uma representação do contexto de execução de middlewares. Tal representação pode ser utilizada para identificar quais componentes precisam ser reconfigurados, visando tornar o middleware mais adequado ao seu contexto de execução corrente.},
  abstract-en = {FlexTV is a reference middleware platform developed in the context of the Brazilian Digital TV project. The first FlexTV version did not use a component model which could make it possible to reconfigure the middleware at runtime. This paper presents a component model which was designed to be used in embedded systems, like Set-Top Boxes and Digital TV sets. The proposed model was used to implement a new version of the FlexTV middleware and to incorporate some functionality to that middleware which made it possible to reconfigure its components at runtime. Therefore, this work also presents a high level architecture for a mechanism that can be used to generate a representation of the middleware's execution context. Such a representation can be used to identify the components which need to be reconfigured, aiming to make the middleware more suited to its execution context.},
  keywords-en = {component based development, context representation, digital television, middleware},
  lang = {pt},
  title-en = {A component model proposal for embedded systems and its use to add reconfiguration capabilities to the {FlexTV} middleware}
}

@INPROCEEDINGS{Leiva-etal:2002a,
  author = {W. D. Leiva and M. C. F. Oliveira and P. C. Masiero and R. P. M. Fortes},
  title = {{MDE}: A Hypertext Model for Online Courses},
  crossref = {proceedings:sbmidia:2002},
  pages = {333--340},
  abstract = {Although many models have been designed for specification of hyper-documents, there is no general model targeted at the specification of content and navigation for the domain of Distance Education. This domain has some inherent characteristics, such as the need of simple mechanisms to describe organization of course material and define navigation over this material taking into acount learner performance. This motivated the proposal of MDE (Model for Distance Education), based on simplification of the Statechart formalism that allows specification of the organizational structure and the browsing semantics of hyperdocuments. MDE uses conceptual mapping, and provides mechanisms for defining different type of assessments.},
  address = {Fortaleza},
  booktitle = {Simpósio Brasileiro de Multimídia e Sistemas Hipermídia -- Workshop de Ferramentas e Aplicações},
  lang = {en},
  location = {Fortaleza, CE, Brasil},
  month = oct,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {2002}
}

@INPROCEEDINGS{Leiva-etal:2002b,
  author = {W. D. Leiva and M. C. F. Oliveira and P. C. Masiero and R. P. M. Fortes},
  title = {{ATEnA}: Adaptive Tutorial Environment with Support for Assessment},
  crossref = {proceedings:sbmidia:2002},
  pages = {399--406},
  abstract = {ATEnA (Adaptive Tutorial Environment with Support for Assessment) is a Web Information System based on an underlying hypermedia model called MDE (Model for Distance Education). MDE is based on startcharts. It describes both the hierarchical organization and the navigation features allowed on the on-line course contents. It also embeds resources for defining student assessment criteria. The environment will provide an authorship module and a browsing module. It allows the inclusion of three types of assessment: diagnostic, formative and summative. The questions of each assessment will be chosen adaptively from a database. The authorship process is based on conceptual maps, built automatically from input provided by the course's author.},
  address = {Fortaleza},
  booktitle = {Simpósio Brasileiro de Multimídia e Sistemas Hipermídia (SBMIDIA 2002) -- Workshop de Ferramentas e Aplicações},
  month = oct,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {2002}
}

@ARTICLE{Lemos-etal:2013,
  author = {Otávio Augusto Lazzarini Lemos and Fabiano Cutigi Ferrari and Marcelo Medeiros Eler and José Carlos Maldonado and Paulo Cesar Masiero},
  title = {Evaluation studies of software testing research in Brazil and in the world: A survey of two premier software engineering conferences},
  crossref = {journal:elsevier:jss},
  volume = {86},
  number = {4},
  month = apr,
  year = {2013},
  pages = {951--969},
  doi = {10.1016/j.jss.2012.11.040},
  abstract = {This paper reports on a historical perspective of the evaluation studies present in software testing research published in the Brazilian Symposium on Software Engineering (SBES) in comparison to the International Conference on Software Engineering (ICSE). The survey characterizes the software testing-related papers published in the 25-year history of SBES, investigates the types of evaluation presented in these publications, and how the rate of evaluations has evolved over the years. A similar analysis within the same period is made for ICSE, allowing for a comparison between the national and international scenario. Results show that the rate of papers that present evaluation studies in SBES has significantly increased over the years. However, among the papers that described some kind of evaluation, only around 20% performed more rigorous evaluations (i.e. case studies, quasi experiments, or controlled experiments). Such percentage is low when compared to ICSE, which presented 40% of papers with more rigorous evaluations within the same period. Nevertheless, we noticed that both venues still lack the publication of research reporting controlled experiments: only a single paper in each conference presented this type of evaluation.},
  keywords = {Software testing, Evaluation studies, Software testing research in Brazil}
}

@INPROCEEDINGS{Lemos-etal:2012,
  author = {Lemos, Otávio Augusto Lazzarini and Ferrari, Fabiano Cutigi and Silveira, Fábio Fagundes and Garcia, Alessandro},
  title = {Development of Auxiliary Functions: Should You Be Agile? An Empirical Assessment of Pair Programming and Test-first Programming},
  crossref = {proceedings:icse:2012},
  pages = {529--539},
  abstract = {A considerable part of software systems is comprised of functions that support the main modules, such as array or string manipulation and basic math computation. These auxiliary functions are usually considered less complex, and thus tend to receive less attention from developers. However, failures in these functions might propagate to more critical modules, thereby affecting the system's overall reliability. Given the complementary role of auxiliary functions, a question that arises is whether agile practices, such as pair programming and test-first programming, can improve their correctness without affecting time-to-market. This paper presents an empirical assessment comparing the application of these agile practices with more traditional approaches. Our study comprises independent experiments of pair versus solo programming, and test-first versus test-last programming. The first study involved 85 novice programmers who applied both traditional and agile approaches in the development of six auxiliary functions within three different domains. Our results suggest that the agile practices might bring benefits in this context. In particular, pair programmers delivered correct implementations much more often, and test-first programming encouraged the production of larger and higher coverage test sets. On the downside, the main experiment showed that both practices significantly increase total development time. A replication of the test-first experiment with professional developers shows similar results.},
  owner = {magsilva},
  timestamp = {2014.08.31}
}

@ARTICLE{Lemos-etal:2009,
  author = {Otávio Augusto Lazzarini Lemos and Ivan Gustavo Franchin and Paulo Cesar Masiero},
  title = {Integration testing of Object-Oriented and Aspect-Oriented programs: A structural pairwise approach for Java},
  crossref = {journal:elsevier:scp},
  volume = {74},
  number = {10},
  month = aug,
  year = {2009},
  pages = {861--878},
  doi = {10.1016/j.scico.2009.05.001},
  abstract = {Several testing approaches focus on finding faults in software units of implementation. A problem not addressed by unit testing is the interaction among units, with respect to the correctness of their interfaces. In this paper a structural integration testing approach for Object-Oriented (OO) and Aspect-Oriented (AO) Java programs is presented. To make the activity more feasible, we address the testing of pairs of units (i.e., methods and pieces of advice). A model called (PairWise Def-Use) graph to represent the flow of control and data between pairs of units is proposed. Based on the , the following family of testing criteria is defined: all-pairwise-integrated-nodes (control-flow based), all-pairwise-integrated-edges (control-flow based), and all-pairwise-integrated-uses (data-flow based). To evaluate the proposed approach, an implementation of the criteria in a testing tool is presented along with an example of usage and an exploratory study. The study with 7 AO programs that are also OO was conducted to investigate the cost of application and usefulness of the approach. Results provided evidence that the criteria are practical and useful for integration testing of OO and AO programs.},
  keywords = {Software testing; Object-Oriented programming; Aspect-Oriented programming; Structural testing; Integration testing;Testing criteria; Testing Object-Oriented programs; Testing Aspect-Oriented programs; Java}
}

@ARTICLE{Lemos-Masiero:2011,
  author = {Otávio Augusto Lazzarini Lemos and Paulo Cesar Masiero},
  title = {A pointcut-based coverage analysis approach for aspect-oriented programs},
  crossref = {journal:elsevier:is},
  volume = {181},
  number = {13},
  month = jul,
  year = {2011},
  pages = {2721--2746},
  doi = {10.1016/j.ins.2010.06.003},
  abstract = {Aspect-oriented programming (AOP) is a promising technology that supports separation of crosscutting concerns (i.e., functionality that tends to be tangled with, and scattered through the rest of the system). In AOP, a method-like construct named advice is applied to join points in the system through a special construct named pointcut. This mechanism supports the modularization of crosscutting behavior; however, since the added interactions are not explicit in the source code, it is hard to ensure their correctness. To tackle this problem, this paper presents a rigorous coverage analysis approach to ensure exercising the logic of each advice -- statements, branches, and def-use pairs -- at each affected join point. To make this analysis possible, a structural model based on Java bytecode -- called PointCut-based Def-Use Graph (PCDU) -- is proposed, along with three integration testing criteria. Theoretical, empirical, and exploratory studies involving 12 aspect-oriented programs and several fault examples present evidence of the feasibility and effectiveness of the proposed approach.},
  keywords = {Software testing; Aspect-oriented programming; Structural testing; Integration testing; Testing criteria; testing aspect-oriented programs; Java; AspectJ}
}

@ARTICLE{Lemos-etal:2007,
  author = {Otávio Augusto Lazzarini Lemos and Auri Marcelo Rizzo Vincenzi and José Carlos Maldonado and Paulo Cesar Masiero},
  title = {Control and data flow structural testing criteria for aspect-oriented programs},
  crossref = {journal:elsevier:jss},
  volume = {80},
  number = {6},
  month = jun,
  year = {2007},
  pages = {862--882},
  doi = {10.1016/j.jss.2006.08.022},
  abstract = {Although it is claimed that, among other features, aspect-oriented programming (AOP) increases understandability and eases the maintenance burden, this technology cannot provide correctness by itself, and thus it also requires the use of systematic verification, validation and testing (VV&T) approaches. With the purpose of producing high quality software, many approaches to apply structural testing criteria for the unit testing of procedural and object-oriented (OO) programs have been proposed. Nevertheless, until now, few works have addressed the application of such criteria to test aspect-oriented programs. In this paper we define a family of control flow and data flow based testing criteria for aspect-oriented programs inspired by the implementation strategy adopted by AspectJ - an aspect-oriented extension of the Java language - and extending a previous work proposed for Java programs. We propose the derivation of a control and data flow model for aspect-oriented programs based upon the static analysis of the object code (the Java bytecode) resulted from the compilation/weaving process. Using this model, called aspect-oriented def-use graph (), traditional and also aspect-oriented testing criteria are defined (called Control and Data Flow Structural Testing Criteria for Aspect-Oriented Programs - CDSTC-AOP). The main idea is that composition of aspect-oriented programs leads to new crosscutting interfaces in several modules of the system, which must be considered for coverage during structural testing. The implementation of a prototype tool - the JaBUTi/AJ tool - to support the proposed criteria and model is presented along with an example. Also, theoretical and practical questions regarding the CDSTC-AOP criteria are discussed.},
  keywords = {Software testing; aspect-oriented programming; structural testing; testing criteria; testing aspect-oriented programs}
}

@INCOLLECTION{Lerma:2007,
  author = {Carlos Francisco Lerma},
  title = {Creating Learning Objects},
  chapter = {13},
  pages = {379-399},
  crossref = {Harman-Koohang:2007}
}

@ARTICLE{Leska:2004,
  author = {Leska, Chuck},
  title = {Testing across the curriculum: square one!},
  crossref = {journal:ccsc:jcsc},
  volume = {19},
  number = {5},
  month = may,
  year = {2004},
  pages = {163--169},
  abstract = {Software quality assurance activities typically do not receive much attention in the undergraduate computer science curriculum. This paper endeavors to provide a stepping- stone for incorporating these activities into courses across-the-curriculum. In the paper we delineate a set of quality assurance activities that we were able to incorporate into a CS 1 course. In addition, we reflect on the impact of the inclusion of these activities in terms of coverage of topics and on student performance.}
}

@ARTICLE{Lethbridge:2000,
  author = {Timothy C. Lethbridge},
  title = {What knowledge is important to a software professional?},
  crossref = {journal:ieee:computer},
  volume = {33},
  number = {5},
  month = may,
  year = {2000},
  pages = {44--50},
  doi = {10.1109/2.841783},
  abstract = {Efforts to develop licensing requirements, curricula, or training programs for software professionals should consider the experience of the practitioners who actually perform the work. We surveyed software professionals representing a wide variety of industries, job functions, and countries to learn which educational topics have proved most important to them in their careers and to identify the topics for which their education or current knowledge could be improved.}
}

@INPROCEEDINGS{Lethbridge-etal:2007,
  author = {Lethbridge, Timothy C. and Diaz-Herrera, Jorge and LeBlanc, Richard J. Jr. and Thompson, J. Barrie},
  title = {Improving software practice through education: Challenges and future trends},
  crossref = {proceedings:fose:2007},
  pages = {12--28},
  doi = {10.1109/FOSE.2007.13},
  abstract = {We argue that the software engineering (SE) community could have a significant impact on the future of the discipline by focusing its efforts on improving the education of software engineers. There are some bright spots such as the various projects to codify knowledge, and the development of undergraduate SE programs. However, there remain several key challenges, each of which is addressed in this paper: The challenges are 1) making programs attractive to students, 2) focusing education appropriately, 3) communicating industrial reality more effectively, 4) defining curricula that are forward-looking, 5) providing education for existing practitioners, 6) making SE education more evidencebased, 7) ensuring that SE educators have the necessary background, and 8) raising the prestige and quality of SE educational research. For each challenge, we provide action items and open research questions.}
}

@ARTICLE{Leveson-Turner:1993,
  author = {Nancy G. Leveson and Clark S. Turner},
  title = {An investigation of the {Therac-25} accidents},
  crossref = {journal:ieee:computer},
  volume = {26},
  number = {7},
  month = jul,
  year = {1993},
  pages = {18--41},
  abstract = {Between June 1985 and January 1987, the Therac-25 medical electron accelerator was involved in six massive radiation overdoses. As a result, several people died and others were seriously injured. A detailed investigation of the factors involved in the software-related overdoses and attempts by users, manufacturers, and government agencies to deal with the accidents is presented. The authors demonstrate the complex nature of accidents and the need to investigate all aspects of system development and operation in order to prevent future accidents. The authors also present some lessons learned in terms of system engineering, software engineering, and government regulation of safety-critical systems containing software components.}
}

@INPROCEEDINGS{Lewis-etal:2005,
  author = {Lewis, Tracy L. and Chase, J. D. and Pérez-Quiñones, Manuel A. and Rosson, Mary Beth},
  title = {The Effects of Individual Differences on {CS2} Course Performance Across Universities},
  crossref = {proceedings:sigcse:2005},
  pages = {426--430},
  doi = {10.1145/1047344.1047483},
  abstract = {Research is presented that examined the effects of various measures of prior computer science experience and cognitive abilities on overall performance in a CS2 course. Participants selected from the CS2 course at two southeastern state universities were used within this study, resulting in a sample size of 161 (School A, n = 76; School B, n = 85). School A is a mid-sized comprehensive university and School B is a large research-intensive university.Self-reported data were collected on measures of experience in object-oriented processing, UNIX programming, web design, computing platforms, and various CS experience. Further, cognitive abilities measures of spatial orientation, visualization, logical reasoning, and flexibility were administered.The results show that the schools significantly differed on all measures of cognitive ability and most measures of prior computer science experience. The schools also differed on the extent to which these measures were related to overall course performance. The results suggest that, for school A, the cognitive ability visualization and the prior computer science experience measure of OO processing were significantly related to course performance. However, when examining school B, no measures were found significant.},
  keywords = {cognitive abilities, course performance, individual differences, object-oriented design, prior computer science experience}
}

@ARTICLE{LeytonBrown-etal:2014,
  author = {Leyton-Brown, Kevin and Hoos, Holger H. and Hutter, Frank and Xu, Lin},
  title = {Understanding the Empirical Hardness of {NP}-complete Problems},
  crossref = {journal:acm:cacm},
  volume = {57},
  number = {5},
  month = may,
  year = {2014},
  pages = {98--107},
  doi = {10.1145/2594413.2594424},
  abstract = {Using machine learning to predict algorithm runtime.}
}

@ARTICLE{Li-etal:2012,
  author = {Bixin Li and Lulu Wang and Hareton Leung and Fei Liu},
  title = {Profiling all paths: A new profiling technique for both cyclic and acyclic paths},
  crossref = {journal:elsevier:jss},
  volume = {85},
  number = {7},
  month = jul,
  year = {2012},
  pages = {1558--1576},
  doi = {10.1016/j.jss.2012.01.046},
  abstract = {As an important technique in dynamic program analysis, path profiling collects the execution frequency of different paths, and has been widely used in a variety of areas. However, existing intra-procedural profiling techniques cannot effectively deal with loops, i.e., they are limited in either working with acyclic paths, or with a small number of loop iteration. This paper presents a new profiling technique called PAP (Profiling All Paths), which can profile all finite-length paths within a procedure. PAP consists of two basic phases, the probe instrumentation phase which assigns a unique pathid to each path, and the backwalk phase which uses the pathids to determine the corresponding executed paths. Furthermore, breakpoints are introduced to store the probe value which may overflow during long executions, and the number of probes is reduced based on the integration of PAP with an existing profiling technique. From our case study and experiments, PAP is found to be effective and efficient in profiling both cyclic and acyclic paths.},
  keywords = {Path profiling; Cyclic paths; Dynamic analysis; Probe instrumentation; Path backwalk; Breakpoint}
}

@INCOLLECTION{Light-etal:2007,
  author = {Tracy Penny Light and Kevin Harrigan and Liwana Bringelson and Tom Carey},
  title = {Collaboration and Community Building: Extending Design Processes for Learning Objects to Foster Reusability},
  chapter = {7},
  pages = {197-218},
  crossref = {Koohang-Harman:2007}
}

@INPROCEEDINGS{Lima-etal:2013,
  author = {Fernando Cesar de Lima and José Augusto Fabri and Alexandre L'Erario},
  title = {A proposal of a software package insert using mind maps},
  crossref = {proceedings:clei:2013},
  pages = {1--7},
  doi = {10.1109/CLEI.2013.6670602},
  abstract = {This paper aims to present a new software artifact based on the initial idea presented in the article "Bula de Software: Uma Estrutura Definida para Promover a Melhoria da Transparência em Software" which compares with a user directions found in a remedy package. This paper proposes the creation of a mental map that shows clearly what are the features of a given software and also shows other information related to the technology and procedures used for its installation.},
  keywords = {Transparency, documentation, software}
}

@INPROCEEDINGS{Lin:2001,
  author = {Fuhua Lin},
  title = {Modeling online instruction knowledge using Petri nets},
  crossref = {proceedings:pacrim:2001},
  pages = {212--215},
  doi = {10.1109/PACRIM.2001.953560},
  abstract = {This paper presents an approach to modeling online instruction knowledge for developing online training systems. To overcome the difficulty in online instruction knowledge acquisition and verification, we use Petri nets theory as a tool for specifying and verifying varied training plans and corresponding training scenarios whereby the online instruction knowledge is derived. An experimental example, the virtual reality based computerized numeric control (CNC) operations training system, shows that Petri nets based training tasks and training scenarios analysis can facilitate creating a knowledge base of online training systems}
}

@ARTICLE{Lindland-etal:1994,
  author = {Lindland, O. I. and Sindre, G. and Solvberg, A.},
  title = {Understanding quality in conceptual modeling},
  crossref = {journal:ieee:software},
  volume = {11},
  number = {2},
  month = mar,
  year = {1994},
  pages = {42--49},
  doi = {10.1109/52.268955},
  abstract = {With the increasing focus on early development as a major factor in determining overall quality, many researchers are trying to define what makes a good conceptual model. However, existing frameworks often do little more than list desirable properties. The authors examine attempts to define quality as it relates to conceptual models and propose their own framework, which includes a systematic approach to identifying quality-improvement goals and the means to achieve them. The framework has two unique features: it distinguishes between goals and means by separating what you are trying to achieve in conceptual modeling from how to achieve it (it has been made so that the goals are more realistic by introducing the notion of feasibility); and it is closely linked to linguistic concepts because modeling is essentially making statements in some language.}
}

@INPROCEEDINGS{Lino-etal:2011,
  author = {Lino, Natasha and Siebra, Clauirton and Araújo, Jonatas and Anabuki, Davi and Patricio, José and Batista, Marcelle and Nóbrega, Ramon and Amaro, Manoel and Lemos, Guido},
  title = {Knowledge tv},
  crossref = {proceedings:euroitv:2011},
  pages = {29--38},
  doi = {10.1145/2000119.2000126},
  abstract = {While iTV content is aimed at human manipulation, it does not appropriately support the performance of computational processes, such as search engines. The principal problem is that the meaning of multimedia documents cannot be explored, reducing the actuation limit of services and applications. In this context, this project proposes the definition of a semantic layer to the iTV platform, based on the Semantic Web concepts, which organizes its content and offers intelligent services, such as semantic queries and recommendation. Thus, this project tries to avoid the same problems that are currently presented by the Web platform, following the Semantic Web trend and increasing the potential to the development of more advanced applications. This technology is being developed in accordance with the Ginga project, which is the official specification for the Brazilian iTV middleware.},
  keywords = {kdd, semantic services, semantic web}
}

@INPROCEEDINGS{Lisboa-etal:2012,
  author = {Lisboa, Rafaela Ponte and Furtado, Maria Elizabeth Sucupira and Borges Neto, Herm\'{\i}nio},
  title = {Verification of crossmedia content for interactive digital television},
  crossref = {proceedings:webmedia:2012},
  pages = {233--236},
  doi = {10.1145/2382636.2382686},
  abstract = {Since the standard interactive Digital Television (DTV) has been defined, there is the expectation of creation of universal network of Distance Education. But there are limitations concerning the techniques and profile of the Brazilian, however, one sees an improvement of the technology for use in educational settings and across many sectors. So this paper proposes recommendations for the production of such content, grouped into the categories of usability, communication and technology that were enriched from experiences with students of the public school system. The contribution of this research is a checklist to support in verification of production of content.},
  keywords = {categories, crossmedia, digital television, learning objects}
}

@INPROCEEDINGS{Liskov-etal:1977,
  author = {Liskov, Barbara and Snyder, Alan and Atkinson, Russell and Schaffert, Craig},
  title = {Abstraction mechanisms in {CLU}},
  crossref = {proceedings:ldrs:1977},
  pages = {140},
  doi = {10.1145/800022.808322},
  abstract = {CLU is a new programming language designed to support the use of abstractions in program construction. Work in programming methodology has led to the realization that three kinds of abstractions, procedural, control, and especially data abstractions, are useful in the programming process. Of these, only the procedural abstraction is supported well by conventional languages, through the procedure or subroutine. CLU provides, in addition to procedures, novel linguistic mechanisms that support the use of data and control abstractions. This paper provides an introduction to the abstraction mechanisms in CLU. By means of programming examples, we illustrate the utility of the three kinds of abstractions in program construction and show how CLU programs may be written to use and implement abstractions. We also discuss the CLU library, which permits incremental program development with complete type-checking performed at compile-time.},
  keywords = {Control abstractions, Data abstractions, Data types, Programming languages, Programming methodology, Separate compilation}
}

@ARTICLE{Lister2012,
  author = {Lister, Raymond},
  title = {A variation on {Kvale}'s one thousand page question},
  crossref = {journal:acm:inroads},
  volume = {3},
  number = {3},
  month = sep,
  year = {2012},
  pages = {24--25},
  doi = {10.1145/2339055.2339063}
}

@ARTICLE{Lister2012a,
  author = {Lister, Raymond},
  title = {Rare research: why is research uncommon in the computing education universe?},
  crossref = {journal:acm:inroads},
  volume = {3},
  number = {4},
  month = dec,
  year = {2012},
  pages = {16--17},
  doi = {10.1145/2381083.2381090}
}

@ARTICLE{Lister2012b,
  author = {Lister, Raymond},
  title = {The {CC2013} Strawman and Bloom's taxonomy},
  crossref = {journal:acm:inroads},
  volume = {3},
  number = {2},
  month = jun,
  year = {2012},
  pages = {12--13},
  doi = {10.1145/2189835.2189840}
}

@ARTICLE{Lister:2011,
  author = {Lister, Raymond},
  title = {Geek genes and bimodal grades},
  crossref = {journal:acm:inroads},
  volume = {1},
  number = {3},
  month = sep,
  year = {2011},
  pages = {16--17},
  doi = {10.1145/1835428.1835434}
}

@ARTICLE{Lister:2011a,
  author = {Lister, Raymond},
  title = {Programming, syntax and cognitive load (part 1)},
  crossref = {journal:acm:inroads},
  volume = {2},
  number = {2},
  month = jun,
  year = {2011},
  pages = {21--22},
  doi = {10.1145/1963533.1963539},
  acmid = {1963539},
  issue = {2},
  issue_date = {June 2011},
  numpages = {2}
}

@ARTICLE{Lister:2011b,
  author = {Lister, Raymond},
  title = {Programming, syntax and cognitive load (part 2)},
  crossref = {journal:acm:inroads},
  volume = {2},
  number = {3},
  month = aug,
  year = {2011},
  pages = {16--17},
  doi = {10.1145/2003616.2003622},
  acmid = {2003622},
  issue = {3},
  issue_date = {September 2011},
  lang = {en},
  numpages = {2}
}

@ARTICLE{Lister:2011c,
  author = {Lister, Raymond},
  title = {What if we approached teaching like software engineering?},
  crossref = {journal:acm:inroads},
  volume = {2},
  number = {1},
  month = mar,
  year = {2011},
  pages = {17--18},
  doi = {10.1145/1929887.1929893}
}

@ARTICLE{Lister:2011d,
  author = {Lister, Raymond},
  title = {Ten years after the McCracken Working Group},
  crossref = {journal:acm:inroads},
  volume = {2},
  number = {4},
  month = dec,
  year = {2011},
  pages = {18--19},
  doi = {10.1145/2038876.2038882}
}

@ARTICLE{Lister:2010,
  author = {Lister, Raymond},
  title = {Teaching the super profs to fish},
  crossref = {journal:acm:inroads},
  volume = {1},
  number = {2},
  month = jun,
  year = {2010},
  pages = {16--17},
  doi = {10.1145/1805724.1805729}
}

@ARTICLE{Lister-etal:2006,
  author = {Lister, Raymond and Berglund, Anders and Clear, Tony and Bergin, Joe and Garvin-Doxas, Kathy and Hanks, Brian and Hitchner, Lew and Luxton-Reilly, Andrew and Sanders, Kate and Schulte, Carsten and Whalley, Jacqueline L.},
  title = {Research perspectives on the objects-early debate},
  crossref = {journal:acm:sigcse-bulletin},
  volume = {38},
  number = {4},
  month = jun,
  year = {2006},
  pages = {146--165},
  doi = {10.1145/1189136.1189183},
  abstract = {In March 2004, SIGCSE members contributed to a mailing list discussion on the question of whether programming should be taught objects first or imperative first. We analyse that discussion, exploring how the CS community debates the issue and whether contributors' positions are supported by the research literature on novice programmers. We applied four distinct research methods to the discussion: cognitive science, rhetorical analysis in the critical tradition, phenomenography and biography. We identify the cognitive claims made in the email discussion and find there is not a consensus in the research literature as to whether the objects first approach or the imperative approach is harder to learn. From the rhetorical analysis, we find that the discussion was not so much a debate between OO-first versus imperative-first, but instead was more for and against OO-first. Our phenomenographic analysis identified and categorized the underlying complexity of the discussion. We also applied a biographical method to explore the extent to which the participants' views are shaped by their own prior experience. The paper concludes with some reflections upon paradigms, and the manner in which the CS discipline community defines itself.},
  keywords = {CS1, object early, object-oriented programming}
}

@ARTICLE{Litecky-Davis:1976,
  author = {Litecky, Charles R. and Davis, Gordon B.},
  title = {A study of errors, error-proneness, and error diagnosis in {Cobol}},
  crossref = {journal:acm:cacm},
  volume = {19},
  number = {1},
  month = jan,
  year = {1976},
  pages = {33--38},
  doi = {10.1145/359970.359991},
  abstract = {This paper provides data on Cobol error frequency for correction of errors in student-oriented compilers, improvement of teaching, and changes in programming language. Cobol was studied because of economic importance, widespread usage, possible error-inducing design, and lack of research. The types of errors were identified in a pilot study; then, using the 132 error types found, 1,777 errors were classified in 1,400 runs of 73 Cobol students. Error density was high: 20 percent of the types contained 80 percent of the total frequency, which implies high potential effectiveness for software-based correction of Cobol. Surprisingly, only four high-frequency errors were error-prone, which implies minimal error inducing design. 80 percent of Cobol misspellings were classifiable in the four error categories of previous researchers, which implies that Cobol misspellings are correctable by existent algorithms. Reserved word usage was not error-prone, which implies minimal interference with usage of reserved words. Over 80 percent of error diagnosis was found to be inaccurate. Such feedback is not optimal for users, particularly for the learning user of Cobol.},
  keywords = {Cobol, diagnostics, error analysis, error correction, error frequency, error-proneness, errors in programming, learning of programming, programming language errors, spelling errors, syntactic errors, teaching of programming}
}

@INCOLLECTION{Litto:2009,
  author = {Fredric Michael Litto},
  title = {O atual cenário internacional da {EAD}},
  chapter = {3},
  pages = {14-20},
  crossref = {Litto-Formiga:2009}
}

@INCOLLECTION{Litto:2009:OER,
  author = {Fredric Michael Litto},
  title = {Recursos educacionais abertos},
  chapter = {42},
  pages = {304-309},
  crossref = {Litto-Formiga:2009}
}

@ARTICLE{Liu-etal:2011,
  author = {Liu, H. and Niu, Z. and Ma, Z. and Shao, W.},
  title = {Suffix tree-based approach to detecting duplications in sequence diagrams},
  crossref = {journal:iet:software},
  volume = {5},
  number = {4},
  month = aug,
  year = {2011},
  pages = {385--397},
  doi = {10.1049/iet-sen.2009.0029},
  abstract = {Models are core artefacts in software development and maintenance. Consequently, quality of models, especially maintainability and extensibility, becomes a big concern for most non-trivial applications. For some reasons, software models usually contain some duplications. These duplications had better be detected and removed because the duplications may reduce maintainability, extensibility and reusability of models. As an initial attempt to address the issue, the author propose an approach in this study to detecting duplications in sequence diagrams. With special preprocessing, the author convert 2-dimensional (2-D) sequence diagrams into an 1-D array. Then the author construct a suffix tree for the array. With the suffix tree, duplications are detected and reported. To ensure that every duplication detected with the suffix tree can be extracted as a separate reusable sequence diagram, the author revise the traditional construction algorithm of suffix trees by proposing a special algorithm to detect the longest common prefixes of suffixes. The author also probe approaches to removing duplications. The proposed approach has been implemented in DuplicationDetector. With the implementation, the author evaluated the proposed approach on six industrial applications. Evaluation results suggest that the approach is effective in detecting duplications in sequence diagrams. The main contribution of the study is an approach to detecting duplications in sequence diagrams, a prototype implementation and an initial evaluation.}
}

@ARTICLE{Liu-etal:2011:spe,
  author = {Liu, Huai and Xie, Xiaodong and Yang, Jing and Lu, Yansheng and Chen, Tsong Yueh},
  title = {Adaptive random testing through test profiles},
  crossref = {journal:wiley:spe},
  volume = {41},
  number = {10},
  year = {2011},
  pages = {1131--1154},
  doi = {10.1002/spe.1067},
  abstract = {Random testing (RT), which simply selects test cases at random from the whole input domain, has been widely applied to test software and assess the software reliability. However, it is controversial whether RT is an effective method to detect software failures. Adaptive random testing (ART) is an enhancement of RT in terms of failure-detection effectiveness. Its basic intuition is to evenly spread random test cases all over the input domain. There are various notions to achieve the goal of even spread, and each notion can be implemented by different algorithms. For example, 'by exclusion' and 'by partitioning' are two different notions to evenly spread test cases. Restricted random testing (RRT) is a typical algorithm for the notion of 'by exclusion', whereas the notion of 'by partitioning' can be implemented by either the technique of bisection (ART-B) or the technique of random partitioning (ART-RP). In this paper, we propose a generic approach that can be used to implement different notions. In the new approach, test cases are simply selected based on test profiles that are in turn designed according to certain notions. In this study, we design several test profiles for the notions of 'by exclusion' and 'by partitioning', and then use these profiles to illustrate our new approach. Our experimental results show that compared with the original RRT, ART-B, and ART-RP algorithms, our new approach normally brings at least a higher failure-detection capability or a lower computational overhead.},
  keywords = {software quality, software testing, random testing, adaptive random testing, test profile}
}

@ARTICLE{Liu-etal:2009,
  author = {Liu, Shaoying and Takahashi, Kazuhiro and Hayashi, Toshinori and Nakayama, Toshihiro},
  title = {Teaching formal methods in the context of software engineering},
  crossref = {journal:acm:inroads},
  volume = {41},
  number = {2},
  month = jun,
  year = {2009},
  pages = {17--23},
  doi = {10.1145/1595453.1595457},
  abstract = {Formal methods were developed to provide systematic and rigorous techniques for software development, and they must be taught in the context of software engineering. In this paper, we discuss the importance of such a teaching paradigm and describe several specific techniques for teaching formal methods. These techniques have been tested over the last fifteen years in our formal methods education programs for undergraduate and graduate students at universities as well as practitioners at companies. We also present a curriculum to systematically introduce formal methods to students at university and a successful program of teaching formal methods to industry. Our experience shows that students can gain confidence in formal methods only when they learn their clear benefits in the context of software engineering.},
  keywords = {education, formal engineering methods, formal methods, software engineering, teaching methods}
}

@ARTICLE{LlamasNistal-etal:2011,
  author = {Llamas-Nistal, M. and Caeiro-Rodriguez, M. and Castro, M.},
  title = {Use of E-Learning Functionalities and Standards: The {Spanish} Case},
  crossref = {journal:ieee:te},
  volume = {54},
  number = {4},
  month = nov,
  year = {2011},
  pages = {540--549},
  doi = {10.1109/TE.2010.2090154},
  abstract = {This paper shows the results of a survey performed in Spain on the different functionalities of e-learning platforms. This survey was filled in by a group of teachers, experts in engineering education from across Spain, within the scope of the Spanish Chapter of the IEEE Education Society. This paper presents their opinions on several aspects of e-learning functionalities, such as knowledge levels, levels of use, and usefulness, as well as describing the most commonly used platforms. One of the objectives of this work is to create a debate in the international community about the use of e-learning platforms and their main functionalities, the most frequently used standards, the implications for and the levels of support by institutions in their use of e-learning platforms, and in general, their advantages and disadvantages.},
  keywords = {E-learning functionalities, e-learning platforms, digital repositories, standards}
}

@INPROCEEDINGS{Llana-etal:2012,
  author = {Llana, Luis and Martin-Martin, Enrique and Pareja-Flores, Cristóbal},
  title = {{FLOP}, a Free Laboratory of Programming},
  crossref = {proceedings:koli-calling:2012},
  pages = {93--99},
  doi = {10.1145/2401796.2401807},
  abstract = {The Test Driven Design (TDD) methodology is currently a very common approach for programming and software engineering learning. On-line judges are widely used in everyday teaching, and their use in the scope of programming contests is currently especially well known. There are good tools and collections of programming problems available for exams as well as for contests. We have developed a simple, light, and practical open laboratory. The term open is used here in two senses: It is free for students to use and free to download and distribute under the GPL license. This laboratory hosts programming problems, it allows the instructor to easily add new ones, and it also automatically assesses the solutions sent by the students. In addition to the system, we have developed a collection of programming problems for CS1/2, designed from a pedagogical point of view and covering several levels of difficulty.},
  keywords = {automatic grading, online judge, programming learning, programming teaching, web system},
  owner = {magsilva},
  timestamp = {2014.10.14}
}

@ARTICLE{Lo-etal:2012,
  author = {David Lo and Leonardo Mariani and Mauro Santoro},
  title = {Learning extended FSA from software: An empirical assessment},
  crossref = {journal:springer:jss},
  volume = {85},
  number = {9},
  month = sep,
  year = {2012},
  pages = {2063--2076},
  doi = {10.1016/j.jss.2012.04.001},
  abstract = {A number of techniques that infer finite state automata from execution traces have been used to support test and analysis activities. Some of these techniques can produce automata that integrate information about the data-flow, that is, they also represent how data values affect the operations executed by programs. The integration of information about operation sequences and data values into a unique model is indeed conceptually useful to accurately represent the behavior of a program. However, it is still unclear whether handling heterogeneous types of information, such as operation sequences and data values, necessarily produces higher quality models or not. In this paper, we present an empirical comparative study between techniques that infer simple automata and techniques that infer automata extended with information about data-flow. We investigate the effectiveness of these techniques when applied to traces with different levels of sparseness, produced by different software systems. To the best of our knowledge this is the first work that quantifies both the effect of adding data-flow information within automata and the effectiveness of the techniques when varying sparseness of traces.},
  keywords = {FSA inference, Empirical validation, Behavioral models}
}

@INPROCEEDINGS{Lochmann-Goeb:2011,
  author = {Lochmann, Klaus and Goeb, Andreas},
  title = {A unifying model for software quality},
  crossref = {proceedings:wosq:2011},
  pages = {3--10},
  doi = {10.1145/2024587.2024591},
  abstract = {Assuring high quality of software is crucial, but a highly complex topic. It is intermingled with most disciplines of software engineering, which have developed their own quality assurance approaches. However, they lack a common foundation, which leads to loss of information between the disciplines and requires additional tracking effort. There is no comprehensive framework to describe all different concepts relating to software quality in a common way. In this paper we present a general quality model, providing the possibility to describe very different concepts related to quality. We show that our quality model is able to integrate the various concepts found in standards, quality models, guidelines, and static code checker rules. Furthermore, we show that the quality model is able to describe the interrelations of disciplines, like requirements engineering and software test, to software quality. With this quality model, we provide a common foundation for concepts related to software quality, enabling consistency and continuity of quality-related information during software development.},
  keywords = {quality model, software quality}
}

@INPROCEEDINGS{Long-etal:1998,
  author = {Long, Timothy J. and Weide, Bruce W. and Bucci, Paolo and Gibson, David S. and Hollingsworth, Joe and Sitaraman, Murali and Edwards, Steve},
  title = {Providing Intellectual Focus to {CS1/CS2}},
  crossref = {proceedings:sigcse:1998},
  pages = {252--256},
  doi = {10.1145/273133.274307},
  abstract = {First-year computer science students need to see clearly that computer science as a discipline has an important intellectual role to play and that it offers deep philosophical questions, much like the other hard sciences and mathematics; that CS is not "just programming". An appropriate intellectual focus for CS1/CS2 can be built on the foundations of systems thinking and mathematical modeling, as these principles are manifested in a component-based software paradigm. We outline some of the main technical features of this approach to CS1/CS2 and report preliminary observations from our experience with it.},
  owner = {magsilva},
  timestamp = {2014.08.29}
}

@INPROCEEDINGS{Lopes-etal:2006,
  author = {Lopes, Adilson and Silva, Carlos and Elias, Gledson and Magalhães, Maurício F.},
  title = {A meta-component model for dynamic adaptation support in a middleware system for interactive tv},
  crossref = {proceedings:webmedia:2006},
  pages = {193--202},
  doi = {10.1145/1186595.1186619},
  abstract = {Interactive digital television systems should adopt concepts of adaptation in order to make possible the development of configurable and extensible applications. On the other hand, software component technologies allow software designers to design, develop, maintain and evolve software systems based upon the integration, substitution and adaptation of already available, reusable software artifacts. In previous papers we presented an adaptive middleware with this objective. The present paper extends this middleware to include a meta-component model to describe and to represent applications independently of technology aspects. The paper also describes the implementation of the model that has been used to build an example application.Plataformas para sistemas de televisão digital interativa devem adotar conceitos de adaptação, de forma a viabilizar o desenvolvimento de aplicações configur´veis e extensíveis. Por outro lado, a tecnologia de componentes permite que o projeto e o desenvolvimento dos sistemas de software possam ser realizados a partir da integração e adaptação de artefatos de software reutiliz´veis. Em artigos anteriores, apresentamos um projeto de um PLGGOHZDUH adaptativo para estes sistemas. O presente artigo estende esse PLGGOHZDUH propondo um modelo de metacomponentes que permite descrever e representar aplicações de forma independente de aspectos de tecnologia; o artigo descreve também a implementação do modelo, a qual est´ sendo usada para construir uma aplicação-exemplo.},
  keywords = {adaptive middleware, interactive TV, software components}
}

@INPROCEEDINGS{LopezNores-etal:2010a,
  author = {López-Nores, Martín and Blanco-Fernández, Yolanda and Pazos-Arias, José J. and García-Duque, Jorge},
  title = {T-learning in Telecommunication Engineering: The Value of Interactive Digital TV in the European Higher Education Area},
  crossref = {proceedings:icalt:2010},
  pages = {624--626},
  doi = {10.1109/ICALT.2010.177},
  abstract = {The implantation of the European Higher Education Area pursues a profound renewal of the teaching methodologies, emphasizing the role of ICTs to enable possibilities of continuous, lifelong learning. We describe a pioneering project in the application of Interactive Digital TV technologies to higher education, as a means to facilitate the understanding of concepts taught at the Telecommunication Engineering School of the University of Vigo. Preliminary experiences with volunteer students reveal the pedagogical and motivating value of the proposed approach, yielding useful observations for the application of the t-learning paradigm in other areas.},
  keywords = {T-learning, higher education, concurrency},
  isbn = {978-0-7695-4055-9},
  lang = {en}
}

@ARTICLE{Louridas:2011,
  author = {Louridas, Panos},
  title = {Test Management},
  crossref = {journal:ieee-software},
  volume = {28},
  number = {5},
  month = sep # {-} # oct,
  year = {2011},
  pages = {86 -91},
  doi = {10.1109/MS.2011.111},
  abstract = {In many projects, testing consumes the single biggest amount of resources of all activities. Companies tend to collect test cases like stamps without clear strategy -- just in case. Many companies suffer with insufficient quality, visibility and test progress management. This article introduces test management.},
  issn = {0740-7459},
  journal = {Software, IEEE},
  publisher = {IEEE}
}

@INPROCEEDINGS{Lu-etal:2008,
  author = {Heng Lu and Chan, W.K. and Tse, T.H.},
  title = {Testing pervasive software in the presence of context inconsistency resolution services},
  crossref = {proceedings:icse:2008},
  pages = {61--70},
  doi = {10.1145/1368088.1368098},
  abstract = {Pervasive computing software adapts its behavior according to the changing contexts. Nevertheless, contexts are often noisy. Context inconsistency resolution provides a cleaner pervasive computing environment to context-aware applications. A faulty context-aware application may, however, mistakenly mix up inconsistent contexts and resolved ones, causing incorrect results. This paper studies how such faulty context-aware applications may be affected by these services. We model how programs should handle contexts that are continually checked and resolved by context inconsistency resolution, develop novel sets of data flow equations to analyze the potential impacts, and thus formulate a new family of test adequacy criteria for testing these applications. Experimentation shows that our approach is promising.},
  keywords = {pervasive computing, context inconsistency resolution, test adequacy}
}

@ARTICLE{Lucas:2014,
  author = {Lucas, Henry},
  title = {Disrupting and Transforming the University},
  crossref = {journal:acm:cacm},
  volume = {57},
  number = {10},
  month = sep,
  year = {2014},
  pages = {32--35},
  doi = {10.1145/2661055},
  abstract = {Higher education institutions must modify their business models in response to technology-driven influences.},
  owner = {magsilva},
  timestamp = {2014.10.14}
}

@ARTICLE{lugmayr-etal:2008,
  author = {Lugmayr, Artur and Adrian, Hornsby and Golebiowski, Piotr and Jumisko-Pyykko, Satu and Ubis, Fernando and Reymann, Simon and Bruns, Volker and Kybartaite, Asta and Kauranen, Jarkko and Matthes, Dirk},
  title = {{E = MC2 + 1}: a fully digital, collaborative, high-definition ({HD}) production from scene to screen},
  crossref = {journal:acm:cie},
  volume = {6},
  number = {2},
  month = jul,
  year = {2008},
  pages = {26:1--26:33},
  doi = {10.1145/1371216.1371229}
}

@ARTICLE{Lunt-etal:2010,
  author = {Lunt, Barry and Ekstrom, J. and Reichgelt, Han and Bailey, Michael and Leblanc, Richard},
  title = {IT 2008: The History of a New Computing Discipline},
  crossref = {journal:acm:cacm},
  volume = {53},
  number = {12},
  month = dec,
  year = {2010},
  pages = {133--141},
  doi = {10.1145/1859204.1859236}
}

@ARTICLE{Lutteri-etal:2011,
  author = {Lutteri, Emiliano and Russo, Barbara and Succi, Giancarlo},
  title = {Report of the 4th international symposium on empirical software engineering and measurement ESEM 2010},
  crossref = {journal:acm:sigsoft},
  volume = {36},
  number = {2},
  month = mar,
  pages = {28--34},
  doi = {10.1145/1943371.1943393},
  abstract = {This report summarizes the research works, in particular the full and short papers, presented at the 4th International Symposium on Empirical Software Engineering and Measurement (ESEM 2010), held the 16th and 17th of September in Bolzano-Bozen, Italy. The program provided thirty full papers, twenty six short papers and three invited talks held by Bertrand Meyer, Steve Fraser and Carlo Ghezzi.},
  keywords = {ESEM, empirical software engineering, software engineering, software measurement}
}

@ARTICLE{Luts:1990,
  author = {Mike Lutz},
  title = {Testing Tools},
  crossref = {journal:ieee:software},
  volume = {7},
  number = {3},
  month = may,
  year = {1990},
  pages = {53--57},
  doi = {10.1109/52.55228},
  abstract = {After a brief overview, separate presentations are given on tools that support the testing process in a variety of ways. Some tools simulate the final execution environment as a way of expediting test execution, others automate the development of test plans, and still others collect performance data during execution. The tools address three aspects of the testing process. They provide a controlled environment in which testing can take place as well as test-data control, and some tools actually perform the tests, capturing and organizing the resulting output. The tools covered are: RUTE (Real-Time Unix Text Environment); Xray/DX; TDC (Testing and Debugging Concurrent) Ada; T; Mothra; Specification Analyzer; and Test inc.}
}

@INPROCEEDINGS{Luukkainen-etal:2012,
  author = {Luukkainen, Matti and Vihavainen, Arto and Vikberg, Thomas},
  title = {A software craftsman's approach to data structures},
  crossref = {proceedings:sigcse:2012},
  pages = {439--444},
  doi = {10.1145/2157136.2157266},
  abstract = {Data Structures (CS2) courses and course books do not usually put much emphasis in the process of how a data structure is engineered or invented. Instead, algorithms are readily given, and the main focus is in the mathematical complexity analysis of the algorithms. We present an alternative approach on presenting data structures using worked examples, i.e., by explicitly displaying the process that leads to the invention and creation of a data stucture and its algorithms. Our approach is heavily backed up by some of the best programming practices advocated by the Agile and Software Craftsmanship communities. It brings the often mathematically oriented CS2 course closer to modern software engineering and practical problem solving, without a need for compromise in proofs and analysis.},
  keywords = {data structures, instructional design, software engineering best practices, worked example}
}

@INPROCEEDINGS{Luyten-etal:2006,
  author = {Luyten, Kris and Thys, Kristof and Huypens, Steven and Coninx, Karin},
  title = {Telebuddies: social stitching with interactive television},
  crossref = {proceedings:chi:2006},
  pages = {1049--1054},
  doi = {10.1145/1125451.1125651},
  abstract = {In this paper we report on our work to enable "laid-back" social interactions using television as a primary interaction medium. By integrating semantic web techniques with interactive television we were able to create smart applications that can run as extensions of television shows and stimulate groups of users to communicate. Groups are based on the shared characteristics that can be found for subsets of spectators. Communication between spectators is brought about at two levels: direct communication like instant messaging and indirect communication like cooperating in a team to win a quiz. Our system does not necessarily require a new television format, but is able to reuse existing television shows and to "socialize" them so they can be re-broadcasted with support for group interaction.},
  keywords = {common ground, cooperative user interfaces, interactive television, semantic web}
}

@ARTICLE{Lavallee-etal:2014,
  author = {Lavallé M. and Robillard, P. N. and Mirsalari, R.},
  title = {Performing Systematic Literature Reviews With Novices: An Iterative Approach},
  crossref = {journal:ieee:education},
  volume = {57},
  number = {3},
  month = aug,
  year = {2014},
  pages = {175--181},
  doi = {10.1109/TE.2013.2292570},
  abstract = {Reviewers performing systematic literature reviews require understanding of the review process and of the knowledge domain. This paper presents an iterative approach for conducting systematic literature reviews that addresses the problems faced by reviewers who are novices in one or both levels of understanding. This approach is derived from traditional systematic literature reviews and based on observations from four systematic reviews performed in an academic setting. These reviews demonstrated the importance of defining iterations for the eight tasks of the review process. The iterative approach enables experiential learning from the two levels of understanding: the process level and the domain level.},
  owner = {magsilva},
  timestamp = {2014.08.29}
}

@ARTICLE{Ma-etal:2013,
  author = {Xiujuan Ma and Minghui Zhou and Dirk Riehle},
  title = {How Commercial Involvement Affects Open Source Projects: Three Case Studies on Issue Reporting},
  crossref = {journal:springer:scis},
  volume = {56},
  month = aug,
  year = {2013},
  doi = {10.1007/s11432-013-4914-6},
  abstract = {Most research on Internet software today has focused on inventing new technologies to keep track of a changing Internet. Little attention has been paid to the software development processes of Internet software. A large part of the software running the Internet is open source software. Open source software is developed both by volunteers and commercial companies, and often jointly. Companies get involved in open source projects for commercial reasons and bring with them a commercial software development process. Thus, it is important to understand how commercial involvement affects the software development processes of open source projects. This article presents a multiple-case case study of three open source application servers that are each being developed jointly by a volunteer community and one primary software company. We are interested in better understanding developer behavior, specifically task distribution and performance, based on whether the developer is a volunteer, working on spare time, or a commercial developer, being paid for their time. To achieve this, we look at issue reporting as an example of commercial involvement in open source projects. Particularly, we investigate the task distribution among volunteers and commercial developers via studying the majority of issue reporters and quantified task performance on user experience via the issue resolution speed. We construct measures based on the historical records in issue tracking repositories. Our results show that with intensified commercial involvement, the majority of issue reporting tasks would be undertaken by commercial developers, and user experience on issue resolution speed would get improved. We hope our methods and results could provide practical insights for designing an efficient and high user experience hybrid development in Internet software environment.},
  keywords = {Open source software development, commercial involvement, hybrid, contributor participation, issue reporting},
  review = {The proportion of external reports suggests that with commercial involvement, internal groups reported most of the issues, which implies that the original situation of OSS issue-reporting practice has changed. With commercial involvement, the major source of reported issues has shifted from users to developers. In hybrid projects, the resolution speed of user reports is influenced by commercial strategies.},
  timestamp = {2013-08-09}
}

@ARTICLE{Ma-Chen:2013,
  author = {Ma, Z. and Chen, H.},
  title = {Analysing the quality of object-oriented models from novice modellers},
  crossref = {journal:iet:software},
  volume = {7},
  number = {4},
  month = aug,
  year = {2013},
  pages = {187--194},
  doi = {10.1049/iet-sen.2012.0124},
  abstract = {Syntactic, semantic and pragmatic defects in object-oriented (OO) models all will result in poor quality of applications based on the models. This study analyses the quality of OO models from two types of novice modellers based on the course projects from the authors 4 years teaching practice. In this study, the authors summarise a set of quality defect types and the typical design activities, quantify the level of occurrence for the defect types and lack of the activities, explore the causes for the defects to occur in OO models in the aspects of syntax, semantics and pragmatics in the phases of OO analysis and design, and conclude preventive measures. These findings can be used for improving the novice modellers' skills for building OO models with good quality.}
}

@INPROCEEDINGS{Machado-etal:2011,
  author = {Joice B. Machado and Graciotto Silva, Marco Aurélio and José C. Maldonado and Ellen F. Barbosa},
  title = {Reengineering of Educational Content: an Experience in the Computer Networks Domain},
  crossref = {proceedings:sbie:2011},
  pages = {361--370},
  abstract = {The growing demand for high-quality educational products, capable of better engaging learners and instructors in an active learning process, has pointed out the need for more efficient and productive learning development mechanisms. The IMA-CID approach address such concerns, defining an integrated approach for modeling educational content. By means of a set of models, IMA-CID helps the content developers to determine the relevant parts of the knowledge domain, providing a systematic way to structure the concepts and related information. In this paper we summarize the key characteristics of IMA-CID, and define guidelines for its application, illustrating them in the reengineering of an educational content in the Computer Networks domain.},
  url = {http://www.br-ie.org/sbie-wie2011/SBIE-Trilha2/93202_1.pdf}
}

@INPROCEEDINGS{Machado-etal:2009,
  author = {Machado, R.J. and Guerreiro, P. and Johnston, E. and Delimar, M. and Brito, M.A.},
  title = {{IEEEXtreme}: From a student competition to the promotion of real-world programming education},
  crossref = {proceedings:fie:2009},
  pages = {1--2},
  doi = {10.1109/FIE.2009.5350540},
  abstract = {IEEEXtreme is an IEEE Student Activities Committee initiative to create a worldwide programming contest for IEEE student branches. The success of the past editions and the way IEEEXtreme is evolving, suggests that it will become the only worldwide competition capable of promoting the computer programming skills of collegiate students within a global software engineering approach of real-world programming problems. Real-world problems that require programming skills are invariably framed within a software engineering approach, where code writing is just the visible dimension of the global effort. Professionals are increasingly compelled to work in multidisciplinary contexts where soft skills are as important as technical ones. This reality should be expressly considered when educational courses are planned to teach programming techniques at undergraduate level. This paper discusses the positive impact that worldwide events like IEEEXtreme might have on the adoption of problem based learning approaches in programming education at undergraduate computing degree programs.},
  keywords = {Programming competitions, Programming education, Project based learning, Real-world programming problems}
}

@ARTICLE{Macias:2012,
  author = {Macias, J. A.},
  title = {Enhancing Project-Based Learning in Software Engineering Lab Teaching Through an E-Portfolio Approach},
  crossref = {journal:ieee:te},
  volume = {55},
  number = {4},
  month = nov,
  year = {2012},
  pages = {502--507},
  doi = {10.1109/TE.2012.2191787},
  abstract = {Project-based learning is one of the main successful student-centered pedagogies broadly used in computing science courses. However, this approach can be insufficient when dealing with practical subjects that implicitly require many deliverables and a great deal of feedback and organizational resources. In this paper, a worked e-portfolio is presented as an approach to improve the teaching/learning and evaluation processes in project-based learning environments needing considerable resources. To validate this approach, a practical project-based software engineering course supported by a Moodle-based e-portfolio was designed and taught. The results obtained corroborated the effectiveness of the e-portfolio in practical software engineering teaching; this approach can be extended to similar subjects in other studies and/or curricula.},
  keywords = {Electronic portfolio, laboratory education, project-based learning, software engineering education, teaching strategies}
}

@ARTICLE{Madeyski:2010:ist,
  author = {Lech Madeyski},
  title = {The impact of Test-First programming on branch coverage and mutation score indicator of unit tests: An experiment},
  crossref = {journal:elsevier:ist},
  volume = {52},
  number = {2},
  month = feb,
  year = {2010},
  pages = {169--184},
  doi = {10.1016/j.infsof.2009.08.007},
  abstract = {Background: Test-First programming is regarded as one of the software development practices that can make unit tests to be more rigorous, thorough and effective in fault detection. Code coverage measures can be useful as indicators of the thoroughness of unit test suites, while mutation testing turned out to be effective at finding faults. Objective: This paper presents an experiment in which Test-First vs. Test-Last programming practices are examined with regard to branch coverage and mutation score indicator of unit tests. Method: Student subjects were randomly assigned to Test-First and Test-Last groups. In order to further reduce pre-existing differences among subjects, and to get a more sensitive measure of our experimental effect, multivariate analysis of covariance was performed. Results: Multivariate tests results indicate that there is no statistically significant difference between Test-First and Test-Last practices on the combined dependent variables, i.e. branch coverage and mutation score indicator, (F (2, 9) = . 52, p > . 05), even if we control for the pre-test results, the subjects' experience, and when the subjects who showed deviations from the assigned programming technique are excluded from the analysis. Conclusion: According to the preliminary results presented in this paper, the benefits of the Test-First practice in this specific context can be considered minor. Limitation: It is probably the first-ever experimental evaluation of the impact of Test-First programming on mutation score indicator of unit tests and further experimentation is needed to establish evidence. © 2009 Elsevier B.V. All rights reserved.},
  keywords = {Empirical study; Test-driven development; Test-First programming; Unit tests},
  owner = {magsilva},
  references = {Beck, K., Andres, C., (2004) Extreme Programming Explained: Embrace Change. second ed., , Addison-Wesley; Beck, K., (2002) Test Driven Development: By Example, , Addison-Wesley; Koskela, L., (2007) Test Driven: Practical TDD and Acceptance TDD for Java Developers, , Manning Publications; Astels, D., (2003) A Practical Guide, , Test Driven development:, Prentice Hall; Williams, L., Maximilien, E.M., Vouk, M., Test-driven development as a defect-reduction practice (2003) ISSRE '03: Proceedings of the 14th International Symposium on Software Reliability Engineering, pp. 34-48. , IEEE Computer Society, Washington, DC, USA; Maximilien, E.M., Williams, L.A., Assessing test-driven development at IBM (2003) ICSE '03: Proceedings of the 25th International Conference on Software Engineering, pp. 564-569. , IEEE Computer Society; Canfora, G., Cimitile, A., Garcia, F., Piattini, M., Visaggio, C.A., Evaluating advantages of test driven development: a controlled experiment with professionals (2006) ISESE '06: Proceedings of the 2006 ACM/IEEE International Symposium on Empirical Software Engineering, pp. 364-371. , ACM Press, New York, NY, USA; Bhat, T., Nagappan, N., Evaluating the efficacy of test-driven development: industrial case studies (2006) ISESE '06: Proceedings of the 2006 ACM/IEEE International Symposium on Empirical Software Engineering, pp. 356-363. , ACM Press, New York, NY, USA; Sanchez, J.C., Williams, L., Maximilien, E.M., On the sustained use of a test-driven development practice at ibm (2007) AGILE '07: Proceedings of the 2007 Conference on Agile Software Development, pp. 5-14. , IEEE Computer Society, Washington, DC, USA; Nagappan, N., Maximilien, E.M., Bhat, T., Williams, L., Realizing quality improvement through test driven development: results and experiences of four industrial teams (2008) Empirical Software Engineering, 13 (3), pp. 289-302; Janzen, D., Saiedian, H., Does test-driven development really improve software design quality? (2008) IEEE Software, 25 (2), pp. 77-84; Edwards, S.H., Rethinking computer science education from a test-first perspective (2003) OOPSLA '03: Companion of the 18th Annual ACM SIGPLAN Conference on Object-Oriented Programming, Systems, Languages, and Applications, pp. 148-155. , ACM, New York, NY, USA; Edwards, S.H., Teaching software testing: automatic grading meets test-first coding (2003) OOPSLA '03: Companion of the 18th Annual ACM SIGPLAN Conference on Object-Oriented Programming, Systems, Languages, and Applications, pp. 318-319. , ACM, New York, NY, USA; Melnik, G., Maurer, F., A cross-program investigation of students' perceptions of agile methods (2005) ICSE '05: Proceedings of the 27th International Conference on Software Engineering, pp. 481-488; Müller, M.M., Hagner, O., Experiment about test-first programming (2002) IEE Procedings-Software, 149 (5), pp. 131-136; Pancur, M., Ciglaric, M., Trampus, M., Vidmar, T., Towards empirical evaluation of test-driven development in a university environment (2003) EUROCON '03: Proceedings of the International Conference on Computer as a Tool, pp. 83-86; Erdogmus, H., Morisio, M., Torchiano, M., On the effectiveness of the test-first approach to programming (2005) IEEE Transactions on Software Engineering, 31 (3), pp. 226-237; Flohr, T., Schneider, T., Lessons learned from an XP experiment with students: test-first need more teachings (2006) Lecture Notes in Computer Science, 4034, pp. 305-318. , Product Focused Software Process Improvement. Münch J., and Vierimaa M. (Eds), Springer, Berlin, Heidelberg; Madeyski, L., Preliminary analysis of the effects of pair programming and test-driven development on the external code quality (2005) Frontiers in Artificial Intelligence and Applications, 130, pp. 113-123. , http://madeyski.e-informatyka.pl/download/Madeyski05b.pdf, Software Engineering: Evolution and Emerging Technologies. Zielinski K., and Szmuc T. (Eds), IOS Press; Madeyski, L., The impact of pair programming and test-driven development on package dependencies in object-oriented design - an experiment (2006) Lecture Notes in Computer Science, 4034, pp. 278-289. , http://madeyski.e-informatyka.pl/download/Madeyski06.pdf, Product Focused Software Process Improvement. Münch J., and Vierimaa M. (Eds), Springer, Berlin, Heidelberg; Gupta, A., Jalote, P., An experimental evaluation of the effectiveness and efficiency of the test driven development (2007) ESEM '07: Proceedings of the First International Symposium on Empirical Software Engineering and Measurement, pp. 285-294. , IEEE Computer Society, Washington, DC, USA; Huang, L., Holcombe, M., Empirical investigation towards the effectiveness of Test First programming (2009) Information and Software Technology, 51 (1), pp. 182-194; Jeffries, R.E., Anderson, A., Hendrickson, C., (2000) Extreme Programming Installed, , Addison-Wesley Longman Publishing Co. Inc., Boston, MA, USA; S. Ambler, Introduction to test driven design (TDD). <http://www.agiledata.org/essays/tdd.html>, 2008 (accessed 2008)Mattu, B., Shankar, R., Test driven design methodology for component-based system (2007) First Annual IEEE Systems Conference, pp. 1-7; http://www.exampler.com/testing-com/writings/coverage.pdf, B. Marick, How to misuse code coverage, in: Proceedings of the 16th International Conference on Testing Computer Software, Washington, USA, 1999P.J. Walsh, A Measure of Test Case Completeness, Ph.D. Thesis, University of New York, 1985Frankl, P.G., Weiss, S.N., Hu, C., All-uses vs. mutation testing: an experimental comparison of effectiveness (1997) Journal of Systems and Software, 38 (3), pp. 235-253; Offutt, A.J., Pan, J., Tewary, K., Zhang, T., An experimental evaluation of data flow and mutation testing (1996) Software Practice and Experience, 26 (2), pp. 165-176; Wohlin, C., Runeson, P., Höst, M., Ohlsson, M.C., Regnell, B., Wesslén, A., (2000) Experimentation in Software Engineering: An Introduction, , Kluwer Academic Publishers, Norwell, MA, USA; Robson, C., (2002) Real World Research: A Resource for Social Scientists and Practitioner-Researchers, , Blackwell Publishing Limited; Boehm, B.W., A Spiral Model of Software Development and Enhancement (1988) IEEE Computer, 21 (5), pp. 61-72; (1987) ANSI/IEEE Std, 1008. , IEEE Standard for Software Unit Testing; L. Madeyski, Empirical studies on the impact of test-first programming, Technical Report I32/09/, Wroclaw University of Technology, Institute of Informatics, <http://madeyski.e-informatyka.pl/download/Madeyski09TFStudies.pdf>, 2009Madeyski, L., Szata, T., The impact of test-driven development on software development productivity - an empirical study (2007) Lecture Notes in Computer Science, 4764, pp. 200-211. , http://madeyski.e-informatyka.pl/download/Madeyski07d.pdf, Software Process Improvement. Abrahamsson P., Baddoo N., Margaria T., and Messnarz R. (Eds), Springer; Ynchausti, R.A., Integrating unit testing into a software development team's process (2001) XP 2001: Proceedings of the 2nd International Conference on Extreme Programming and Flexible Processes in Software Engineering, pp. 84-87. , M. Marchesi, G. Succi Eds, Sardinia, Italy; George, B., Williams, L., An initial investigation of test driven development in industry (2003) SAC '03: Proceedings of the 2003 ACM Symposium on Applied Computing, pp. 1135-1139. , ACM, New York, NY, USA; George, B., Williams, L.A., A structured experiment of test-driven development (2004) Information and Software Technology, 46 (5), pp. 337-342; Geras, A., Smith, M.R., Miller, J., A prototype empirical evaluation of test driven development (2004) IEEE METRICS'2004: Proceedings of the 10th IEEE International Software Metrics Symposium, pp. 405-416. , IEEE Computer Society; Damm, L.-O., Lundberg, L., Results from introducing component-level test automation and Test-Driven Development (2006) Journal of Systems and Software, 79 (7), pp. 1001-1014; Damm, L.-O., Lundberg, L., Quality impact of introducing component-level test automation and test-driven development (2007) Lecture Notes in Computer Science, 4764, pp. 187-199. , Software Process Improvement. Abrahamsson P., Baddoo N., Margaria T., and Messnarz R. (Eds), Springer; Abrahamsson, P., Hanhineva, A., Jäälinoja, J., Improving business agility through technical solutions: a case study on test-driven development in mobile software development (2005) IFIP International Federation for Information Processing, 180, pp. 1-17. , Proceedings of the IFIP TC8 WG 8.6 International Working Conference on Business Agility and Information Technology Diffusion. Baskerville R., Mathiassen L., Pries-Heje J., and DeGross J.I. (Eds), Springer; Siniaalto, M., Abrahamsson, P., A comparative case study on the impact of test-driven development on program design and test coverage (2007) ESEM '07: Proceedings of the First International Symposium on Empirical Software Engineering and Measurement, pp. 275-284. , IEEE Computer Society; Müller, M.M., The effect of test-driven development on program code (2006) XP '06: Extreme Programming and Agile Processes in Software Engineering, 7th International Conference, XP 2006, Oulu, Finland, June 17-22, 2006, pp. 94-103. , Springer; Runeson, P., Using students as experiment subjects - an analysis of graduate and freshmen student data (2003) EASE '03: Proceedings of 7th International Conference on Empirical Assessment and Evaluation in Software Engineering, pp. 95-102. , British Computer Society; Höst, M., Regnell, B., Wohlin, C., Using students as subjects - a comparative study of students and professionals in lead-time impact assessment (2000) Empirical Software Engineering, 5 (3), pp. 201-214; Tichy, W.F., Hints for reviewing empirical work in software engineering (2000) Empirical Software Engineering, 5 (4), pp. 309-312; Kitchenham, B., Pfleeger, S.L., Pickard, L., Jones, P., Hoaglin, D.C., Emam, K.E., Rosenberg, J., Preliminary guidelines for empirical research in software engineering (2002) IEEE Transactions on Software Engineering, 28 (8), pp. 721-734; Jeffries, R., Melnik, G., Guest editors' introduction: TDD - The art of fearless programming (2007) IEEE Software, 24 (3), pp. 24-30; Maxwell, S.E., Delaney, H.D., (2004) Designing Experiments and Analyzing Data: A Model Comparison Perspective. second ed., , Lawrence Erlbaum, Mahwah; Madeyski, L., On the effects of pair programming on thoroughness and fault-finding effectiveness of unit tests (2007) Lecture Notes in Computer Science, 4589, pp. 207-221. , http://madeyski.e-informatyka.pl/download/Madeyski07.pdf, Product Focused Software Process Improvement. Münch J., and Abrahamsson P. (Eds), Springer; Madeyski, L., The impact of pair programming on thoroughness and fault detection effectiveness of unit tests suites (2008) Wiley, Software Process: Improvement and Practice, 13 (3), pp. 281-295. , http://madeyski.e-informatyka.pl/download/Madeyski08.pdf; Cook, T.D., Campbell, D.T., (1979) Quasi-Experimentation: Design and Analysis Issues, , Houghton Mifflin Company; Fowler, M., Beck, K., Brant, J., Opdyke, W., Roberts, D., (1999) Refactoring: Improving the Design of Existing Code, , Addison-Wesley; E. Gamma, K. Beck, JUnit, <http://www.junit.org/>, 2006 (accessed 2006)Massol, V., Husted, T., (2003) JUnit in Action. first ed., , Manning Publications; Hamill, P., (2004) Unit Test Frameworks, , O'Reilly; S. Cornett, Code coverage analysis, <http://www.bullseye.com/coverage.html>, 2007 (accessed 2007)Atlassian Pty Ltd., Clover project, <http://www.atlassian.com/software/clover/>, 2008 (accessed 2008)DeMillo, R.A., Lipton, R.J., Sayward, F.G., Hints on test data selection: help for the practicing programmer (1978) IEEE Computer, 11 (4), pp. 34-41; Hamlet, R.G., Testing programs with the aid of a compiler (1977) IEEE Transactions on Software Engineering, 3 (4), pp. 279-290; Zhu, H., Hall, P.A.V., May, J.H.R., Software unit test coverage and adequacy (1997) ACM Computing Surveys, 29 (4), pp. 366-427; Offutt, A.J., Untch, R.H., (2001) Mutation Testing for the New Century, , Kluwer Academic Publishers, Norwell, MA, USA Ch. Mutation 2000: Uniting the Orthogonal; N. Radyk, L. Madeyski, Judy - mutation testing tool for Java. <http://www.e-informatyka.pl/sens/Wiki.jsp?page=Projects.Judy>, <http://madeyski.e-informatyka.pl/download/tools/judy/judy-0.1.zip>, 2009 (accessed 2009)Ant project, <http://ant.apache.org/>, 2006 (accessed 2006)Offutt, A.J., Lee, A., Rothermel, G., Untch, R.H., Zapf, C., An experimental determination of sufficient mutant operators (1996) ACM Transactions on Software Engineering and Methodology, 5 (2), pp. 99-118; Ammann, P., Offutt, J., (2008) Introduction to Software Testing, , Cambridge University Press, Cambridge, UK; Ma, Y.-S., Kwon, Y.-R., Offutt, J., Inter-class mutation operators for Java (2002) ISSRE '02: Proceedings of the 13th International Symposium on Software Reliability Engineering (ISSRE'02), pp. 352-363. , IEEE Computer Society, Washington, DC, USA; Ma, Y.-S., Harrold, M.J., Kwon, Y.-R., Evaluation of mutation testing for object-oriented programs (2006) ICSE '06: Proceeding of the 28th International Conference on Software Engineering, pp. 869-872. , ACM Press, New York, NY, USA; Höst, M., Wohlin, C., Thelin, T., Experimental context classification: incentives and experience of subjects (2005) ICSE '05: Proceedings of the 27th International Conference on Software Engineering, pp. 470-478. , ACM Press, New York, NY, USA; Howitt, D., Cramer, D., (2008) Introduction to SPSS in Psychology. fourth ed., , Pearson Education Limited; Stevens, J.P., (2002) Applied Multivariate Statistics for the Social Sciences. fourth ed., , Lawrence Erlbaum, Mahwah; Seshadri, G., (1999) Understanding JavaServer Pages Model 2 Architecture - exploring the MVC design pattern, , http://www.javaworld.com/javaworld/jw-12-1999/jw-12-ssj-jspmvc.html; Cactus project, <http://jakarta.apache.org/cactus/>, 2006 (accessed 2006)Madeyski, L., Stochmiatek, M., Architectural design of modern web applications (2005) Foundations of Computing and Decision Sciences Journal, 30 (1), pp. 49-60. , http://madeyski.e-informatyka.pl/download/23.pdf; Williams, L., Shukla, A., Antón, A.I., An initial exploration of the relationship between pair programming and brooks' law (2004) ADC '04: Proceedings of the Agile Development Conference (ADC'04), pp. 11-20. , IEEE Computer Society, Washington, DC, USA; Tabachnick, B.G., Fidell, L.S., (2006) Using Multivariate Statistics. fifth ed., , Allyn and Bacon, Inc., Needham Heights, MA, USA; American Psychological Association, (2001) Publication Manual of the American Psychological Association. fifth ed., , American Psychological Association, Washington, DC, USA; Field, A., (2005) Discovering Statistics Using SPSS, , SAGE Publications; Shadish, W.R., Cook, T.D., Campbell, D.T., (2002) Experimental and Quasi-Experimental Designs for Generalized Causal Inference, , Houghton, Mifflin; Rubin, A., Babbie, E.R., (2004) Research Methods for Social Work. fifth ed., , Wadsworth Publishing; Prechelt, L., Malpohl, G., Phlippsen, M., Finding Plagiarisms among a set of programs with JPlag (2002) Journal of Universal Computer Science, 8 (11), pp. 1016-1038. , http://www2.informatik.uni-erlangen.de/Forschung/Publikationen/download/jplag.pdf; Sørumgård, L.S., (1997) Verification of Process Conformance in Empirical Studies of Software Development, , http://www.idi.ntnu.no/grupper/su/publ/phd/sorumgard_thesis.pdf, Ph.D. Thesis, The Norwegian University of Science and Technology; Wang, Y., Erdogmus, H., The role of process measurement in test-driven development (2004) Lecture Notes in Computer Science, 3134, pp. 32-42. , XP/Agile Universe. Zannier C., Erdogmus H., and Lindstrom L. (Eds), Springer; Müller, M.M., Höfer, A., The effect of experience on the test-driven development process (2007) Empirical Software Engineering, 12 (6), pp. 593-615; M. Fowler, The new methodology, <http://www.martinfowler.com/articles/newMethodology.html>, 2007 (accessed 2007)Arisholm, E., Sjøberg, D.I.K., Evaluating the effect of a delegated versus centralized control style on the maintainability of object-oriented software (2004) IEEE Transactions on Software Engineering, 30 (8), pp. 521-534; Lipsey, M.W., Wilson, D.B., (2001) Practical Meta-Analysis, , Sage Publications, California, USA; Kampenes, V.B., Dybå, T., Hannay, J.E., Sjøberg, D.I.K., Systematic review: a systematic review of effect size in software engineering experiments (2007) Information and Software Technology, 49 (11-12), pp. 1073-1086; L. Madeyski, The impact of test-first programming on branch coverage and mutation score indicator of unit tests: a raw data from an experiment, (raw data from SPSS), Wroclaw University of Technology, Institute of Informatics, <http://madeyski.e-informatyka.pl/download/Madeyski09bExp2RawData.pdf>, <http://madeyski.e-informatyka.pl/download/Madeyski09bExp2RawData.sav>, 2009},
  timestamp = {2014.08.19}
}

@ARTICLE{Madeyski-etal:2013,
  author = {Lech Madeyski and Wojciech Orzeszyna and Richard Torkar and Mariusz J?zala},
  title = {Overcoming the Equivalent Mutant Problem: A Systematic Literature Review and a Comparative Experiment of Second Order Mutation},
  crossref = {journal:ieee:tse},
  year = {2013},
  doi = {10.1109/TSE.2013.44},
  abstract = {The equivalent mutant problem (EMP) is one of the crucial problems in mutation testing widely studied over decades. The objectives are: to present a systematic literature review (SLR) in the field of EMP; to identify, classify and improve the existing, or implement new, methods which try to overcome EMP and evaluate them. We performed SLR based on the search of digital libraries. We implemented four second order mutation (SOM) strategies, in addition to first order mutation (FOM), and compared them from different perspectives. Our SLR identified 17 relevant techniques (in 22 articles) and three categories of techniques: detecting (DEM); suggesting (SEM); and avoiding equivalent mutant generation (AEMG). The experiment indicated that SOM in general and JudyDiffOp strategy in particular provide the best results in the following areas: total number of mutants generated; the association between the type of mutation strategy and whether the generated mutants were equivalent or not; the number of not killed mutants; mutation testing time; time needed for manual classification. The results in the DEM category are still far from perfect. Thus, the SEM and AEMG categories have been developed. The JudyDiffOp algorithm achieved good results in many areas.},
  keywords = {mutation testing, equivalent mutant problem, higher order mutation, second order mutation}
}

@INPROCEEDINGS{Mafra-etal:2006,
  author = {Sômulo Nogueira Mafra and Rafael Ferreira Barcelos and Guilherme Horta Travassos},
  title = {Aplicando uma Metodologia Baseada em Evidência na Definição de Novas Tecnologias de Software},
  crossref = {proceedings:sbes:2006},
  pages = {239--254},
  abstract = {A introdução de tecnologias de software recém-definidas no contexto industrial pode trazer conseqüências indesejáveis caso a tecnologia não possua um grau adequado de maturidade. Nesse sentido, o presente artigo visa a ilustrar como a utilização de uma metodologia baseada em evidência pode auxiliar a minimizar essa situação. A utilização de tal metodologia é ilustrada através de dois casos concretos relacionados à definição e à avaliação experimental de uma técnica de leitura de requisitos de software e de uma abordagem para inspeção de documentos arquiteturais. Além disso, são discutidas as principais lições aprendidas do uso de tal metodologia.},
  abstract-en = {The transfer of Software technologies to the industrial context could bring undesirable consequences if such technologies are not under an adequate maturity level. This paper aims at to describe the use of an evidence-based methodology that can support the reduction of this risk. The application of such methodology is illustrated through two concrete cases regarding the definition of a software requirements reading technique and a checklist based approach for inspecting software architectural models. Besides, some lessons learned by using the methodology are also described.},
  lang = {pt}
}

@INPROCEEDINGS{Magdaleno,
  author = {Magdaleno, Andréa M. and Araujo, Renata M. and Werner, Cláudia M. L.},
  title = {An Exploratory Study on Collaboration Understanding in Software Development Social Networks},
  crossref = {proceedings:criwg:2012},
  pages = {113--120},
  doi = {10.1007/978-3-642-33284-5_9},
  abstract = {Collaboration is important for productivity, quality, and knowledge sharing in software development. In this context, the use of social networks analysis can help to track the level of collaboration in a development project. In this work, an exploratory study was conducted, in the context of free/open source software, using EvolTrack-SocialNetwork tool, to investigate collaboration in software teams. The preliminary results indicate a potential to increase ones ability to understand the course that the collaboration is taking.},
  keywords = {Collaboration; social network; software development}
}

@INPROCEEDINGS{Magdaleno-etal:2010,
  author = {Magdaleno, Andréa Magalhães and Werner, Cláudia Maria Lima and Araujo, Renata Mendes},
  title = {Analyzing Collaboration in Software Development Processes through Social Networks},
  crossref = {proceedings:isola:2010},
  pages = {435--446},
  doi = {10.1007/978-3-642-16558-0_37},
  abstract = {Plan-driven, agile or free/open source are software development models that although effective, cannot fully address all the variability of projects and organizations alone. In this work, it is argued that two distinct characteristics of these models -- collaboration and discipline -- can be the drivers to tailor software development processes to meet projects and organizations needs. In particular, this article focuses on the aspect of collaboration and argues that it can be analyzed through social networks. In this sense, we studied several tools and identified the requirements necessary to explore collaboration, through social networks, in software development processes. These requirements motivated the construction of EvolTrack-SocialNetwork tool.},
  keywords = {collaboration; social networks; software processes}
}

@ARTICLE{Mahdizadeh-etal:2008,
  author = {Hossein Mahdizadeh and Harm Biemans and Martin Mulder},
  title = {Determining factors of the use of e-learning environments by university teachers},
  crossref = {journal:elsevier:ce},
  volume = {51},
  number = {1},
  month = aug,
  year = {2008},
  pages = {142--154},
  doi = {10.1016/j.compedu.2007.04.004},
  abstract = {E-learning environments increasingly serve as important infrastructural features of universities that enable teachers to provide students with different representations of knowledge and to enhance interaction between teachers and students and amongst students themselves. This study was designed to identify factors that can explain teachers' use of e-learning environments in higher education. A questionnaire was completed by 178 teachers from a wide variety of departments at Wageningen University in the Netherlands. We found that 43% of the total variance in teacher use of e-learning environments could be explained by their opinions about web-based activities and their opinions about computer-assisted learning (predictors) and the perceived added value of e-learning environments (mediating variable). In other words, teachers' use of e-learning environments can be explained to a high extent by their perceptions of the added value of these environments, which in turn are substantially influenced by their opinions about web-based activities and computer-assisted learning.},
  keywords = {Computer-mediated communication, Cooperative/collaborative learning, Distance education and telelearning, Media in education, Multimedia/hypermedia systems}
}

@INPROCEEDINGS{Mahmoud:2011a,
  author = {Mahmoud, Qusay H.},
  title = {A mobile web-based approach to introductory programming},
  crossref = {proceedings:itcse:2011},
  pages = {334--334},
  doi = {10.1145/1999747.1999845},
  abstract = {In this paper an approach for teaching introductory programming courses using mobile web-based technologies is introduced. This approach focuses on using standard Web technologies, such as HTML, JavaScript, and Cascading Style Sheets to make teaching computer programming fun, especially for users of mobile devices. This approach is supported by the CMER Academic Kit for integrating mobile devices into the Computer Science Curriculum.},
  keywords = {blackberry, mobile application development, mobile devices, programming for fun, teaching computer programming, teaching tools}
}

@INPROCEEDINGS{Mahmoud:2011b,
  author = {Mahmoud, Qusay H.},
  title = {Best practices in teaching mobile application development},
  crossref = {proceedings:itcse:2011},
  pages = {333--333},
  doi = {10.1145/1999747.1999844},
  abstract = {This paper presents best practices for teaching mobile application development across the Computing curricula. While the focus is on the BlackBerry smartphone, the best practices can be used when teaching application development for other mobile platforms. The best practices are supported by the freely available CMER Academic Kit for integrating mobile devices into the Computer Science Curriculum.},
  keywords = {blackberry, mobile application development, mobile devices, programming for fun, teaching computer programming, teaching tools}
}

@ARTICLE{raey,
  author = {Maia, Guilherme and Vaz de Melo, Pedro O. S. and Guidoni, Daniel L. and Souza, Fernanda S. H. and Silva, Thiago H. and Almeida, Jussara M. and Loureiro, Antonio A. F.},
  title = {On the analysis of the collaboration network of the {Brazilian} symposium on computer networks and distributed systems},
  crossref = {journal:springer:jbcs},
  month = mar,
  year = {2013},
  pages = {1--22},
  doi = {10.1007/s13173-013-0109-7},
  abstract = {The Brazilian symposium on computer networks and distributed systems (SBRC) reached its 30th edition as the paramount scientific event in the area of computer networks and distributed systems in Brazil. Faced with this opportune moment in the event?s history, we here study the collaboration network established among authors who have jointly published in the symposium. Towards that end, we collected bibliographic data from all 30 editions, and built the co-authorship network of the event. We then analyzed the network structural features and evolution throughout its history. Our results reveal the main kind of co-author relationship among authors, show the most prominent communities within SBRC, the regions of Brazil that attracts the most authors, the researchers with central roles in the network as well as the importance of inter-state collaborations. Finally, we align our results with historical facts that may have had a key impact on the symposium success.},
  keywords = {Collaboration networks; Scientific networks; Social networks; SBRC}
}

@ARTICLE{Major-etal:2012,
  author = {Major, L. and Kyriacou, T. and Brereton, O.P.},
  title = {Systematic literature review: teaching novices programming using robots},
  crossref = {journal:iet:software},
  volume = {6},
  number = {6},
  month = dec,
  year = {2012},
  pages = {502--513},
  doi = {10.1049/iet-sen.2011.0125},
  abstract = {Teaching programming to novices is a difficult task due to the complex nature of the subject, the negative stereotypes are associated with programming and because introductory programming courses often fail to encourage student understanding. This study investigates the effectiveness of using robots as tools in the teaching of introductory programming and to determine whether such technology can help to overcome the current barriers for learners in this context. The systematic literature review (SLR) methodology is used to address this aim. Nine electronic databases, the proceedings from six conferences and two journals were searched for relevant literature and exclusion criteria, and after performing several validation exercises, in total, 75% of included papers report that robots are an effective teaching tool and can help novice programmers in their studies. Most of these papers focus on the use of physical robots, however, and further research is needed to assess the effectiveness of using simulated robots.}
}

@INPROCEEDINGS{Major-etal:2011,
  author = {Major, Louis and Kyriacou, Theocharis and Brereton, Pearl},
  title = {Experiences of Prospective High School Teachers Using a Programming Teaching Tool},
  crossref = {proceedings:koli-calling:2011},
  pages = {126--131},
  doi = {10.1145/2094131.2094161},
  abstract = {During their time at school few high school students are exposed to basic computing concepts as Computer Science (CS) is not considered to be an important part of the curriculum. As a result many high school students do not encounter programming during their studies. In the UK, despite newly qualified CS and ICT (Information and Communication Technology) teachers having specific subject knowledge, in recent years schools have steadily 'watered down' the content of CS courses and have aligned the subject with disciplines such as Business Studies. This has distanced Computing from the other sciences whilst adding to students' confusion about what the subject actually entails. This paper presents the results of a study which involved 23 trainee CS/ICT teachers. The study took the form of a day-long workshop session and had the objectives of determining what perceptions and opinions the trainee teachers held in regards to programming as well as to discover the effectiveness and potential of a programming teaching tool based on the concept of a robot simulator. Analysis of data collected during the session shows how, despite the majority of trainees having some programming experience, a number of trainees had difficulty completing basic programming challenges. This displays how some CS/ICT teachers may lack fundamental programming knowledge. Moreover, whilst most of the trainees felt programming should be taught to high school students studying a CS or ICT course, fewer than half of the trainees said they had the confidence to teach the subject. An evaluation of the effectiveness of the robot simulator as a teaching tool is also presented as is a discussion on the implications which these findings may have.},
  keywords = {high school, java, programming, simulator, teachers, teaching},
  owner = {magsilva},
  timestamp = {2014.08.30}
}

@INPROCEEDINGS{Makinen-Munch:2014,
  author = {Mäkinen, S. and Münch, J.},
  title = {Effects of test-driven development: A comparative analysis of empirical studies},
  crossref = {proceedings:swqd:2014},
  pages = {155--169},
  doi = {10.1007/978-3-319-03602-1},
  abstract = {Test-driven development is a software development practice where small sections of test code are used to direct the development of program units. Writing test code prior to the production code promises several positive effects on the development process itself and on associated products and processes as well. However, there are few comparative studies on the effects of test-driven development. Thus, it is difficult to assess the potential process and product effects when applying testdriven development. In order to get an overview of the observed effects of test-driven development, an in-depth review of existing empirical studies was carried out. The results for ten different internal and external quality attributes indicate that test-driven development can reduce the amount of introduced defects and lead to more maintainable code. Parts of the implemented code may also be somewhat smaller in size and complexity. While maintenance of test-driven code can take less time, initial development may last longer. Besides the comparative analysis, this article sketches related work and gives an outlook on future research. © Springer International Publishing Switzerland 2014.},
  keywords = {Empirical study; Software engineering; Software testing; Software verification; Test-driven development; Test-first programming},
  owner = {magsilva},
  references = {Beck, K., (2003) Test-Driven Development: By Example, , Addison-Wesley; Turhan, B., Layman, L., Diep, M., Erdogmus, H., Shull, F., How Effective is Test-Driven Development (2010) Making Software: What Really Works, pp. 207-219. , In: Oram, A., Wilson, G. (eds.), and Why We Believe It,. O'Reilly; Jeffries, R., Melnik, G., Guest Editors' Introduction: TDD-The Art of Fearless Programming (2007) IEEE Software, 24 (3), pp. 24-30; Rafique, Y., Misic, V., The Effects of Test-Driven Development on External Quality and Productivity: A Meta Analysis (2013) IEEE Transactions on Software Engineering, 39 (6), pp. 835-856; Desai, C., Janzen, D., Savage, K., A Survey of Evidence for Test-Driven Development in Academia (2008) SIGCSE Bulletin, 40 (2), pp. 97-101; Runeson, P., Höst, M., Guidelines for Conducting and Reporting Case Study Research in Software Engineering (2009) Empirical Software Engineering, 14, pp. 131-164; Merriam, S.B., (2009) Qualitative Research: A Guide to Design and Implementation, , John Wiley & Sons; Torraco, R.J., Writing Integrative Literature Reviews: Guidelines and Examples (2005) Human Resource Development Review, 4 (3), pp. 356-367; Kitchenham, B., Charters, S., (2007) Guidelines for Performing Systematic Literature Reviews in Software Engineering. Technical Report Version 2. 3, , Keele University and University of Durham (July; Creswell, J.W., (2009) Research Design: Qualitative, Quantitative, and Mixed Methods Approaches, , Sage Publications; Mäkinen, S., (2012) Driving Software Quality and StructuringWork Through Test-Driven Development. Master's thesis, , Department of Computer Science, University of Helsinki (October; Bhat, T., Nagappan, N., Evaluating the Efficacy of Test-driven Development: Industrial Case Studies (2006) Proceedings of the 2006 ACM/IEEE International Symposium on Empirical Software Engineering, pp. 356-363. , In:, ISESE 2006,. ACM, New York; Canfora, G., Cimitile, A., Garcia, F., Piattini, M., Visaggio, C.A., Evaluating Advantages of Test Driven Development: A Controlled Experiment with Professionals (2006) Proceedings of the 2006 ACM/IEEE International Symposium on Empirical Software Engineering, pp. 364-371. , In:, ISESE 2006,. ACM, New York; Dogsa, T., Batic, D., The Effectiveness of Test-Driven Development: An Industrial Case Study (2011) Software Quality Journal, 19, pp. 643-661; George, B., Williams, L., An Initial Investigation of Test Driven Development in Industry (2003) Proceedings of the 2003 ACM Symposium on Applied Computing, pp. 1135-1139. , In:, SAC 2003,. ACM, New York; Geras, A., Smith, M., Miller, J., A Prototype Empirical Evaluation of Test Driven Development (2004) Proceedings of the 10th International Symposium on Software Metrics. METRICS 2004, pp. 405-416. , In:, (September; Maximilien, E., Williams, L., Assessing Test-Driven Development at IBM (2003) Proceedings of the 25th International Conference on Software Engineering, pp. 564-569. , In:, ICSE 2003, (May; Nagappan, N., Maximilien, E., Bhat, T., Williams, L., Realizing Quality Improvement through Test Driven Development: Results and Experiences of Four Industrial Teams (2008) Empirical Software Engineering, 13, pp. 289-302; Williams, L., Maximilien, E.M., Vouk, M., Test-Driven Development as a Defect-Reduction Practice (2003) Proceedings of the 14th International Symposium on Software Reliability Engineering, pp. 34-45. , In:, ISSRE 2003, (November; Janzen, D.S., Saiedian, H., Does Test-Driven Development Really Improve Software Design Quality? (2008) IEEE Software, 25 (2), pp. 77-84; Madeyski, L., Szata, T., The Impact of Test-Driven Development on Software Development Productivity-An Empirical Study (2007) EuroSPI 2007. LNCS, 4764, pp. 200-211. , In: Abrahamsson, P., Baddoo, N., Margaria, T., Messnarz, R. (eds.),. Springer, Heidelberg; Müller, M., Höfer, A., The Effect of Experience on the Test-Driven Development Process (2007) Empirical Software Engineering, 12 (6), pp. 593-615; Desai, C., Janzen, D.S., Clements, J., Implications of Integrating Test-Driven Development Into CS1/CS2 Curricula (2009) Proceedings of the 40th ACM Technical Symposium on Computer Science Education, pp. 148-152. , In:, SIGCSE 2009,. ACM, New York; Gupta, A., Jalote, P., An Experimental Evaluation of the Effectiveness and Efficiency of the Test Driven Development (2007) Proceedings of the First International Symposium on Empirical Software Engineering and Measurement, pp. 285-294. , In:, ESEM 2007, (September; Huang, L., Holcombe, M., Empirical Investigation Towards the Effectiveness of Test First Programming (2009) Information and Software Technology, 51 (1), pp. 182-194; Janzen, D., Saiedian, H., On the Influence of Test-Driven Development on Software Design (2006) Proceedings of the 19th Conference on Software Engineering Education and Training, pp. 141-148. , In:, CSEET 2006, (April; Madeyski, L., The Impact of Test-First Programming on Branch Coverage and Mutation Score Indicator of Unit Tests: An Experiment (2010) Information and Software Technology, 52 (2), pp. 169-184; Pancur, M., Ciglaric, M., Impact of Test-Driven Development on Productivity, Code and Tests: A Controlled Experiment (2011) Information and Software Technology, 53 (6), pp. 557-573; Vu, J., Frojd, N., Shenkel-Therolf, C., Janzen, D., Evaluating Test-Driven Development in an Industry-Sponsored Capstone Project (2009) Proceedings of the Sixth International Conference on Information Technology, pp. 229-234. , In:, ITNG 2009,. New Generations (April; Wilkerson, J., Nunamaker, J.J., Mercer, R., Comparing the Defect Reduction Benefits of Code Inspection and Test-Driven Development (2012) IEEE Transactions on Software Engineering, 38 (3), pp. 547-560; Fenton, N.E., Pfleeger, S.L., (1997) Software Metrics: A Rigorous and Practical Approach, , PWS Publishing Company, Boston; Pezzè, M., Young, M., (2008) Software Testing and Analysis: Process, Principles and Techniques, , Wiley, Chichester; McCabe, T., A Complexity Measure (1976) IEEE Transactions on Software Engineering SE, 2 (4), pp. 308-320; Chidamber, S., Kemerer, C., A Metrics Suite for Object Oriented Design (1994) IEEE Transactions on Software Engineering, 20 (6), pp. 476-493; Cook, S., He, J., Harrison, R., Dynamic and Static Views of Software Evolution (2001) Proceedings of the IEEE International Conference on Software Maintenance, pp. 592-601},
  timestamp = {2014.08.19}
}

@INPROCEEDINGS{Maldonado-etal:2000:SelectiveMutationEvaluation,
  author = {José Carlos Maldonado and Ellen Francine Barbosa and Auri Marcelo Rizzo Vincenzi and Márcio Eduardo Delamaro},
  title = {Evaluating N-Selective Mutation for {C} programs: Unit and Integration Testing},
  crossref = {proceedings:mutation:2000},
  pages = {22--33},
  abstract = {Mutation testing has been found to be an effective fault-revealing criterion. However, its high cost of application, mainly due to the high number of mutants created and the effort to determine the equivalent mutants, has motivated the proposition of alternative approaches for its application. One of them, named N-Selective Mutation, aims at reducing the number of generated mutants through a reduction on the number of the most prevalent mutant operators expecting that would not occur a significant reduction on the effectiveness. Previously, other researchers investigated the N-Selective Mutation in the context of FORTRAN language, for the unit testing. The results showed that it is possible to have a large cost reduction preserving a high mutation score. Recently, the underlying mutation concept has been explored at the integration testing phase by the proposition of the Interface Mutation criterion. In the same research line, this work investigates the N-Selective Mutation for C programs, considering the unit and the integration testing phases, in the perspective of contributing to the establishement of low-cost, effective mutation-based testing strategies. N-Selective Mutation is also compared with othe Selective Mutation criteria as well as with Randomly Selected Mutation.},
  keywords = {N-Selective Mutation; Mutation Analysis; Interface Mutation; Unit and Integration Testing}
}

@INPROCEEDINGS{Maldonado-etal:2000:Proteum,
  author = {José Carlos Maldonado and Márcio Eduardo Delamaro and Sandra C. P. F. Fabbri and Adenilso da Silva Simão and Tatiana Sugeta and Auri Marcelo Rizzo Vincenzi and Paulo Cesar Masiero},
  title = {Proteum: A Family of Tools to Support Specification and Program Testing Based on Mutation},
  crossref = {proceedings:mutation:2000},
  pages = {113--116},
  abstract = {The qualification of the VV&T- Verification, Validation and Testing - activity is extremely relevant to the software development process. The establishment of a low-cost, effective testing and validation strategy and the development of supporting tools have been pursued by many researchers. This presentation discusses the main architectural and operational aspects of a family of tools that support specification and program testing based on mutation. The testing of C programs is supported by Proteum/IM 2.0, at the unit and at the integration level as well. Proteum is an acronym for PROgram Testing Using Mutants. At the specification level the application of mutation testing for validating Reactive Systems (RS) specifications based on Finite State Machines (FSM), Statecharts and Petri Nets is support by Proteum/RS.},
  keywords = {testing tools; mutation testing; specification testing; program testing}
}

@INPROCEEDINGS{Malheiros-etal:2007,
  author = {Viviane Malheiros and Erika Höhn and Roberto Pinho and Manoel Mendonca and José Carlos Maldonado},
  title = {A Visual Text Mining approach for Systematic Reviews},
  crossref = {proceedings:esem:2007},
  pages = {245--254},
  doi = {10.1109/ESEM.2007.21},
  abstract = {The software engineering research community has been adopting systematic reviews as an unbiased and fair way to assess a research topic. Despite encouraging early results, a systematic review process can be time consuming and hard to conduct. Thus, tools that help on its planning or execution are needed. This article suggests the use of Visual Text Mining (VTM) to aid systematic reviews. A feasibility study was conducted comparing the proposed approach with a manual process. We observed that VTM can contribute to Systematic Review and we propose a new strategy called VTM-Based Systematic Review.}
}

@INPROCEEDINGS{Malheiros-etal:2012,
  author = {Malheiros, Y. and Moraes, A. and Trindade, C. and Meira, S.},
  title = {A Source Code Recommender System to Support Newcomers},
  crossref = {proceedings:compsac:2012},
  pages = {19--24},
  doi = {10.1109/COMPSAC.2012.11},
  abstract = {Newcomers in a software development project often need assistance to complete their first tasks. Then a mentor, an experienced member of the team, usually teaches the newcomers what they need to complete their tasks. But, to allocate an experienced member of a team to teach a newcomer during a long time is neither always possible nor desirable, because the mentor could be more helpful doing more important tasks. During the development the team interacts with a version control system, bug tracking and mailing lists, and all these tools record data creating the project memory. Recommender systems can use the project memory to help newcomers in some tasks answering their questions, thus in some cases the developers do not need a mentor. In this paper we present Mentor, a recommender system to help newcomers to solve change requests. Mentor uses the Prediction by Partial Matching (PPM) algorithm and some heuristics to analyze the change requests, and the version control data, and recommend potentially relevant source code that will help the developer in the change request solution. We did three experiments to compare the PPM algorithm with the Latent Semantic Indexing (LSI). Using PPM we achieved results for recall rate between 37% and 66.8%, and using LSI the results were between 20.3% and 51.6%.},
  keywords = {recommender systems; software engineering; software maintenance; information theory}
}

@INPROCEEDINGS{Malmi:2014,
  author = {Malmi, Lauri},
  title = {Doctoral Studies in Computing Education Research -- part 2},
  crossref = {journal:acm:inroads},
  pages = {26--27},
  doi = {10.1145/2568195.2568203},
  volume = {5},
  number = {1},
  owner = {magsilva},
  timestamp = {2014.09.01}
}

@ARTICLE{Malmi:2013,
  author = {Malmi, Lauri},
  title = {A pathway into computing education research},
  crossref = {journal:acm:inroads},
  volume = {4},
  number = {3},
  month = sep,
  year = {2013},
  pages = {42--43},
  doi = {10.1145/2505990.2505997},
  timestamp = {2013-09-08}
}

@INPROCEEDINGS{Malmi-etal:2002,
  author = {Lauri Malmi and Ari Korhonen and Riku Saikkonen},
  title = {Experiences in Automatic Assessment on Mass Courses and Issues for Designing Virtual Courses},
  crossref = {proceedings:itcse:2002},
  pages = {55--59},
  doi = {10.1145/544414.544433},
  abstract = {In this paper, we present some experiences on using automatic assessment in large scale courses of introductory programming, data structures, and algorithms over a period of 10 years. Automatic assessment provides an effective method for giving immediate 24/7 feedback service for students of mass courses. A very important factor in the promoting of learning is the possibility to resubmit answers after receiving the feedback. However, our experience shows that the resubmission option is not the only key motivation factor. More important factors include the challenge of exercises and the grading scale or the course assignments. A successful combination of all of these can produce good learning results.}
}

@INPROCEEDINGS{Malmi-etal:2010,
  author = {Malmi, Lauri and Sheard, Judy and Simon and Bednarik, Roman and Helminen, Juha and Korhonen, Ari and Myller, Niko and Sorva, Juha and Taherkhani, Ahmad},
  title = {Characterizing research in computing education: a preliminary analysis of the literature},
  crossref = {proceedings:icer:2010},
  pages = {3--12},
  doi = {10.1145/1839594.1839597},
  abstract = {This paper presents a preliminary analysis of research papers in computing education. While previous analysis has explored what research is being done in computing education, this project explores how that research is being done. We present our classification system, then the results of applying it to the papers from all five years of ICER. We find that this subset of computing education research has more in common with research in information systems than with that in computer science or software engineering; and that the papers published at ICER generally appear to conform to the specified ICER requirements.},
  keywords = {classifying publications, computing education, research methods}
}

@ARTICLE{Manikas-Hansen:2013,
  author = {Konstantinos Manikas and Klaus Marius Hansen},
  title = {Software ecosystems -- A systematic literature review},
  crossref = {journal:elsevier:jss},
  volume = {86},
  number = {5},
  month = may,
  year = {2013},
  pages = {1294--1306},
  doi = {10.1016/j.jss.2012.12.026},
  abstract = {A software ecosystem is the interaction of a set of actors on top of a common technological platform that results in a number of software solutions or services. Arguably, software ecosystems are gaining importance with the advent of, e.g., the Google Android, Apache, and Salesforce.com ecosystems. However, there exists no systematic overview of the research done on software ecosystems from a software engineering perspective. We performed a systematic literature review of software ecosystem research, analyzing 90 papers on the subject taken from a gross collection of 420. Our main conclusions are that while research on software ecosystems is increasing (a) there is little consensus on what constitutes a software ecosystem, (b) few analytical models of software ecosystems exist, and (c) little research is done in the context of real-world ecosystems. This work provides an overview of the field, while identifying areas for future research.},
  keywords = {Software ecosystems, Software ecosystem, Systematic literature review },
  owner = {magsilva},
  timestamp = {2014.09.13}
}

@ARTICLE{Marathe-Vullikanti:2013,
  author = {Marathe, Madhav and Vullikanti, Anil Kumar S.},
  title = {Computational Epidemiology},
  crossref = {journal:acm:cacm},
  volume = {56},
  number = {7},
  month = jul,
  year = {2013},
  pages = {88--96},
  doi = {10.1145/2483852.2483871},
  abstract = {The challenge of developing and using computer models to understand and control the diffusion of disease through populations.}
}

@INPROCEEDINGS{Marceau-etal:2011,
  author = {Marceau, Guillaume and Fisler, Kathi and Krishnamurthi, Shriram},
  title = {Measuring the Effectiveness of Error Messages Designed for Novice Programmers},
  crossref = {proceedings:sigcse:2011},
  pages = {499--504},
  doi = {10.1145/1953163.1953308},
  abstract = {Good error messages are critical for novice programmers. Re-cognizing this, the DrRacket programming environment provides a series of pedagogically-inspired language subsets with error messages customized to each subset. We apply human-factors research methods to explore the effectiveness of these messages. Unlike existing work in this area, we study messages at a fine-grained level by analyzing the edits students make in response to various classes of errors. We present a rubric (which is not language specific) to evaluate student responses, apply it to a course-worth of student lab work, and describe what we have learned about using the rubric effectively. We also discuss some concrete observations on the effectiveness of these messages.},
  keywords = {error messages, novice programmers, user-studies},
  owner = {magsilva},
  timestamp = {2014.08.13}
}

@INPROCEEDINGS{Marchenko-etal:2009,
  author = {Marchenko, Artem and Abrahamsson, Pekka and Ihme, Tuomas},
  title = {Long-Term Effects of Test-Driven Development A Case Study},
  crossref = {proceedings:xp:2009},
  pages = {13--22},
  doi = {10.1007/978-3-642-01853-4_4},
  abstract = {Test-Driven Development (TDD) is one of the most widely debated agile practices. There are a number of claims about its effect on the software quality and team productivity. The current studies present contradicting results and very little research has been performed with industrial projects, which have used TDD over an extensive period of time. This paper is reporting the long-term effects on a three year-long application of TDD in a Nokia Siemens Networks team. We present qualitative findings based on interviews with the team members. We conclude that TDD has been found to improve the team confidence in the code quality and simplify significantly the software maintenance. The examined team did not notice any significant negative effects over the long-term TDD application and is eager to continue improving the practice application. The authors suggest that results bear direct relevance to the industry and academia. Further research avenues are indicated.},
  keywords = {Test-Driven Development; agile; case study; long-term},
  owner = {magsilva},
  timestamp = {2014.10.20}
}

@INPROCEEDINGS{Marmorstein:2011,
  author = {Marmorstein, Robert},
  title = {Open source contribution as an effective software engineering class project},
  crossref = {proceedings:itcse:2011},
  pages = {268--272},
  doi = {10.1145/1999747.1999823},
  abstract = {Software engineering courses often include a semester project designed to give students experience with real-world programming challenges and to expose them to phases of the software development cycle not covered in other classes. One means of engaging students in realistic programming challenges is to make participation in open source development a part of the semester project. This paper describes an assignment in which students contribute to an open source project. The project is designed to immerse students in the open source community and expose them to the work flow and design strategies of a large project. Students work in small groups and decide both which open source community to contribute to and which specific contributions they will make. They can choose to focus on implementation of new features over software maintenance or can focus on documentation and design over both. The assignment contains a proposal phase that allows the instructor to ensure that students are exposed to a healthy cross section of the development cycle.},
  keywords = {open source, real-world projects, software engineering, software maintenance, team programming}
}

@ARTICLE{MarquesNeto-Santos:2010,
  author = {Marques Neto, Manoel and Santos, Celso},
  title = {{StoryToCode}: a new model for specification of convergent interactive digital {TV} applications},
  crossref = {journal:springer:jbcs},
  volume = {16},
  number = {4},
  month = nov,
  year = {2010},
  pages = {215--227},
  doi = {10.1007/s13173-010-0021-3},
  abstract = {This paper presents a model, called the StoryToCode, which allows designing iTV programs focusing on using software components. First, StoryToCode allows transforming a storyboard into an abstract description of an element set. After this, this model transforms these elements into a specific programming language source code. In StoryToCode a software component is treated as a special element that can be reused in other contexts (web, mobile, and so on). StoryToCode is based on Model Driven Architecture (MDA) and allows designing and implementing applications, with context free, considering iTV program specific characteristics.},
  keywords = {MDA; iTV; convergence; storyboard}
}

@INPROCEEDINGS{MarquesNeto-Santos:2009,
  author = {Marques Neto, Manoel Carvalho. and Santos, Celso A. S.},
  title = {{StoryToCode}: Um Modelo Baseado em Componentes para Especificação de Aplicações de {TV} Digital e Interativa Convergentes},
  crossref = {proceedings:webmedia:2009},
  pages = {1--8},
  doi = {10.1145/1858477.1858485},
  keywords = {MDA, TVDI, storyboard, transformações},
  abstract-en = {This paper presents a model, called the StoryToCode, which allows the specication of IDTV programs with focus on the use of software components. First, the StoryToCode allows the transformation of a storyboard in an abstract description of an element set that make up the storyboard. After this, the StoryToCode transform these elements in a specific programing language source code. In StoryToCode a software component is treated as a special element that can be reused in other contexts (web, mobile and etc). The StoryToCode is based on MDA (Model Driven Architecture) and allows design and implement of an application, independent of context, taking into account the particularities of an IDTV program.},
  lang = {pt},
  title-en = {{StoryToCode}: a model based on components for specifying interactive digital {TV} convergent applications}
}

@INPROCEEDINGS{Marrero-Settle:2005,
  author = {Marrero, Will and Settle, Amber},
  title = {Testing first: emphasizing testing in early programming courses},
  crossref = {proceedings:itcse:2005},
  pages = {4--8},
  doi = {10.1145/1067445.1067451},
  abstract = {The complexity of languages like Java and C++ can make introductory programming classes in these languages extremely challenging for many students. Part of the complexity comes from the large number of concepts and language features that students are expected to learn while having little time for adequate practice or examples. A second source of difficulty is the emphasis that object-oriented programming places on abstraction. We believe that by placing a larger emphasis on testing in programming assignments in these introductory courses, students have an opportunity for extra practice with the language, and this affords them a gentler transition into the abstract thinking needed for programming. In this paper we describe how we emphasized testing in introductory programming assignments by requiring that students design and implement tests before starting on the program itself. We also provide some preliminary results and student reactions.},
  keywords = {CS1, CS2, TDD, testing}
}

@ARTICLE{Marshall-etal:1990,
  author = {A. C. Marshall and D. Hedley and I. J. Riddell and M. A. Hennell},
  title = {Static Dataflow-Aided Weak Mutation Analysis (SDAWM)},
  crossref = {journal:elsevier:ist},
  volume = {32},
  number = {1},
  month = jan # {/} # feb,
  year = {1990},
  pages = {99--104}
}

@INPROCEEDINGS{Marshall-Brereton:2013,
  author = {Marshall, C. and Brereton, P.},
  title = {Tools to Support Systematic Literature Reviews in Software Engineering: A Mapping Study},
  crossref = {proceedings:esem:2013},
  pages = {296--299},
  doi = {10.1109/ESEM.2013.32},
  abstract = {Background: Systematic literature reviews (SLRs) have become an established methodology in software engineering (SE) research however they can be very time consuming and error prone. Aim: The aims of this study are to identify and classify tools that can help to automate part or all of the SLR process within the SE domain. Method: A mapping study was performed using an automated search strategy plus snowballing to locate relevant papers. A set of known papers was used to validate the search string. Results: 14 papers were accepted into the final set. Eight presented text mining tools and six discussed the use of visualisation techniques. The stage most commonly targeted was study selection. Only two papers reported an independent evaluation of the tool presented. The majority were evaluated through small experiments and examples of their use. Conclusions: A variety of tools are available to support the SLR process although many are in the early stages of development and usage.},
  keywords = {systematic literature review; automated tool}
}

@INPROCEEDINGS{Marshall-etal:2014,
  author = {Marshall, Christopher and Brereton, Pearl and Kitchenham, Barbara},
  title = {Tools to Support Systematic Reviews in Software Engineering: A Feature Analysis},
  crossref = {proceedings:ease:2014},
  pages = {13:1--13:10},
  doi = {10.1145/2601248.2601270},
  abstract = {Background The labour intensive and error prone nature of the systematic review process has led to the development and use of a range of tools to provide automated support. Aim The aim of this research is to evaluate a set of candidate tools that provide support for the overall systematic review process. Method A feature analysis is performed to compare and evaluate four candidate tools. Results Each of the candidates has some strengths and some weaknesses. SLuRp has the highest overall score and SLRTOOL has the lowest overall score. SLuRp scores well on process management features such as support for multiple users and document management and less well on ease of installation. Conclusions Although the tools do not yet support the whole systematic review process they provide a good basis for further development. We suggest a community effort to establish a set of features that can inform future tool development.},
  keywords = {feature analysis, systematic literature review, systematic review, systematic review support tools},
  owner = {magsilva},
  timestamp = {2014.09.13}
}

@INPROCEEDINGS{Marshall-Mitchell:2007,
  author = {Marshall, S. J. and Mitchell, G.},
  title = {Benchmarking International E-learning Capability with the E-Learning Maturity Model},
  crossref = {proceedings:educase-aus:2007}
}

@ARTICLE{Martin:2011,
  author = {Martin, C. Dianne},
  title = {Reasoning with ethics},
  crossref = {journal:acm:inroads},
  volume = {2},
  number = {1},
  month = mar,
  year = {2011},
  pages = {8--9},
  doi = {10.1145/1929887.1929889},
  abstract = {"IDEALLY ETHICS IS TAUGHT not just in courses focused specifically on ethics, but in any course to which ethics might potentially apply. Otherwise, there is the risk that what students learn will be inert, that students will not see how to apply it outside the one course on ethics. Students need to learn how to reason about and apply ethical principles by being confronted with ethical problems in a variety of domains. They also need to be inoculated against the pressures to behave unethically, such as occur when there is retaliation for whistleblowing (Sternberg, 2009).}
}

@ARTICLE{Martin:2009,
  author = {Martin, C. Dianne},
  title = {Taking the high road: ethics on the run: the principle of the ordinary person},
  crossref = {journal:acm:inroads},
  volume = {41},
  number = {2},
  month = jun,
  year = {2009},
  pages = {66--67},
  doi = {10.1145/1595453.1595466}
}

@INPROCEEDINGS{Martins-etal:2010:SIGDOC,
  author = {Martins, Diogo S. and Oliveira, Lílian S. and Pimentel, Maria da Graça C.},
  title = {Designing the user experience in {iTV}-based interactive learning objects},
  crossref = {proceedings:sigdoc:2010},
  pages = {243--250},
  doi = {10.1145/1878450.1878491},
  abstract = {This paper reports the design of the user experience in EducaTV, an architecture for the association of value-added interactive content to educational TV programs. To properly tackle the unique user interface (UI) challenges posed by educational TV applications, EducaTV was designed through User-Centered Design (UCD) principles with extensive evaluation along the process. We report the main issues of access and findings obtained throughout the design process. Our findings revealed that iDTV applications must provide strategies to signalize interactive content without being obtrusive. Additionally, the context of the users must be taken into account, for instance by providing functionalities to enable collaborative interaction in learning groups, as well as mobilization affordances to encompass the different levels of technological literacy. Moreover, a recurrent issue that affected user experience was the proper synchronization of the live program with the interactive content.},
  keywords = {distance education, e-learning, evaluation, interactive TV, interface design, multimedia},
  series = {SIGDOC '10},
  acmid = {1878491},
  address = {New York, NY, EUA},
  booktitle = {International Conference on Design of Communication},
  isbn = {978-1-4503-0403-0},
  lang = {en},
  numpages = {8},
  publisher = {ACM}
}

@ARTICLE{Martins-etal:2011,
  author = {Martins, Diogo Santana and Vega-Oliveros, Didier Augusto and da Graça Campos Pimentel, Maria},
  title = {Automatic authoring of interactive multimedia documents via media-oriented operators},
  crossref = {journal:acm:acr},
  volume = {11},
  number = {4},
  month = dec,
  year = {2011},
  pages = {26--37},
  doi = {10.1145/2107756.2107759},
  abstract = {When capturing multimedia records of collaborative activities (e.g. lectures, meetings, etc.), later access to the captured activity is usually provided by a linear video comprising the contents of the exchanged media. Such alternative impairs the review of the activity to the extent that the user only counts on the traditional timeline-based video controls. In scenarios in which automated tools generate interactive multimedia documents as a result of capturing an activity, the literature reports the use of ink-based and audio-based operators that allow the identification of points of interaction in the resulting document. In previous work, we defined a taxonomy of media-based operators in order to take into account user interactions with boards and videos, and extended the audio and ink-based operators with action-based alternatives. In this paper, the applicability of the operators is demonstrated in the context of the automatic generation of multimedia documents for interactive TV. Results from the user evaluation suggest that the operators provide means for faster review of a session when compared to a linear video.},
  keywords = {authoring, document engineering, interactive video}
}

@INPROCEEDINGS{Arimoto-Barbosa:2013,
  author = {Massaru Arimoto, M. and Barbosa, E. F.},
  title = {Towards the establishment of an agile method for {OERs} development and delivery},
  crossref = {proceedings:fie:2013},
  pages = {541--547},
  doi = {10.1109/FIE.2013.6684882},
  abstract = {Open Educational Resources (OERs) have been emerged as an important mechanism for democratization of access to education. In fact, the free and open distribution of these resources contributes with the dissemination of knowledge and facilitates the access to information, benefiting the society as a whole. Similar to software, the development of OERs requires the application of appropriate methods and practices to ensure the productivity and quality of the resulting products. Agile methods seem to be an interesting approach in this perspective. However, initiatives to foster the development and delivery of quality and reliable OERs, according to agile principles and with reduced costs, are still incipient. In our work we discuss the establishment of an agile method for the development and delivery of OERs. The proposed method is based on the main characteristics, practices and principles of well-known agile methods for software. To illustrate our ideas, the method is discussed in terms of its application in the development of an OER in the FLOSS (Free / Libre and Open Source Software) domain.},
  keywords = {open educational resources; open content; agile methods},
  owner = {magsilva},
  timestamp = {2014.07.21}
}

@INPROCEEDINGS{Matsubara-etal:2012,
  author = {Matsubara, Yasuko and Sakurai, Yasushi and Prakash, B. Aditya and Li, Lei and Faloutsos, Christos},
  title = {Rise and fall patterns of information diffusion: model and implications},
  crossref = {proceedings:kdd:2012},
  pages = {6--14},
  doi = {10.1145/2339530.2339537},
  abstract = {The recent explosion in the adoption of search engines and new media such as blogs and Twitter have facilitated faster propagation of news and rumors. How quickly does a piece of news spread over these media? How does its popularity diminish over time? Does the rising and falling pattern follow a simple universal law? In this paper, we propose SpikeM, a concise yet flexible analytical model for the rise and fall patterns of influence propagation. Our model has the following advantages: (a) unification power: it generalizes and explains earlier theoretical models and empirical observations; (b) practicality: it matches the observed behavior of diverse sets of real data; (c) parsimony: it requires only a handful of parameters; and (d) usefulness: it enables further analytics tasks such as fore- casting, spotting anomalies, and interpretation by reverse- engineering the system parameters of interest (e.g. quality of news, count of interested bloggers, etc.). Using SpikeM, we analyzed 7.2GB of real data, most of which were collected from the public domain. We have shown that our SpikeM model accurately and succinctly describes all the patterns of the rise-and-fall spikes in these real datasets.},
  keywords = {information diffusion, social networks}
}

@INPROCEEDINGS{Fortes-etal:2004b,
  author = {Renata Pontin de Mattos Fortes and Marco Aurélio Graciotto Silva and Christian Robottom Reis},
  title = {Levantamento sobre Processo de Software Livre},
  crossref = {proceedings:wsl:2004},
  pages = {207-210},
  abstract = {This paper presents the main results gathered from an extensive research on Open Source Projects. The research consists of a survey and, regarding the obtained answers, characteristics of the open source process could be identified.},
  abstract-en = {This paper presents the main results gathered from an extensive research on Open Source Projects. The research consists of a survey and, regarding the obtained answers, characteristics of the open source process could be identified.},
  abstract-pt = {Este artigo apresenta alguns dos principais resultados obtidos de uma ampla pesquisa sobre processo de software livre. A pesquisa foi veiculada por meio de questionário e, com base nas respostas obtidas, puderam ser identificadas características do processo de software livre.},
  address = {Porto Alegre, Brasil},
  booktitle = {V Workshop sobre Software Livre (WSL 2004), parte do V Fórum Internacional de Software Livre (FISL 2004)},
  owner = {magsilva},
  timestamp = {2006.09.28},
  title-pt = {Levantamento sobre Processo de Software Livre},
  year = {2004}
}

@INPROCEEDINGS{McCall:1977,
  author = {J. A. McCall and P. K. Richards and G. F. Walters},
  title = {Metrics for Software Quality Evaluation and Prediction},
  crossref = {proceedings:ssew:1997},
  pages = {49--52},
  abstract = {This paper describes the utility of software metrics in providing a means for quantitative specification and measurement of software quality. It is based on the derivation, evaluation, and validation of software metrics conducted in part during a study of the factors in software quality for the Air Force Electronic Systems Division and Rome Air Development Center.},
  keywords = {software quality, software metrics},
  booktitle = {Second Summer Software Engineering Workshop}
}

@INPROCEEDINGS{McCormack-etal:2008,
  author = {McCormack, Cameron and Marriott, Kim and Meyer, Bernd},
  title = {Authoring adaptive diagrams},
  crossref = {proceedings:doceng:2008},
  pages = {154--163},
  doi = {10.1145/1410140.1410172},
  abstract = {The web and digital media requires intelligent, adaptive documents whose appearance and content adapts to the viewing context and which support user interaction. While previous research has focussed on textual and multimedia content, this is also true for diagrammatic conte nt. We have designed and implemented an authoring tool which supports the construction of adaptive diagrams. Adaptive layout behaviour is specified by using constraint-based placement tools as well as by allowing the author to specify more radical layout changes using alternate layout configurations. As well as specifying alternate layouts, the author can specify alternate representations for an object, alternate styles and alternate textual content. The resulting space of different versions of the diagram is the cross product of these different alternatives. At display time the version is constructed dynamically, taking into account the author specified preference order on the alternatives, current viewing environment, and user interaction.},
  keywords = {adaptive layout, authoring, diagrams},
  series = {DocEng '08},
  acmid = {1410172},
  address = {New York, NY, USA},
  isbn = {978-1-60558-081-4},
  numpages = {10}
}

@ARTICLE{McCracken-Jackson:1982,
  author = {McCracken, Daniel D. and Jackson, Michael A.},
  title = {Life cycle concept considered harmful},
  crossref = {journal:acm:sen},
  volume = {7},
  number = {2},
  month = apr,
  year = {1982},
  pages = {29--32},
  doi = {10.1145/1005937.1005943},
  owner = {magsilva},
  timestamp = {2014.10.23}
}

@ARTICLE{McCracken-etal:2001,
  author = {McCracken, Michael and Almstrum, Vicki and Diaz, Danny and Guzdial, Mark and Hagan, Dianne and Kolikant, Yifat Ben-David and Laxer, Cary and Thomas, Lynda and Utting, Ian and Wilusz, Tadeusz},
  title = {A multi-national, multi-institutional study of assessment of programming skills of first-year CS students},
  crossref = {journal:acm:sigcse-bulletin},
  volume = {33},
  number = {4},
  month = dec,
  year = {2001},
  pages = {125--180},
  doi = {10.1145/572139.572181},
  abstract = {In computer science, an expected outcome of a student's education is programming skill. This working group investigated the programming competency students have as they complete their first one or two courses in computer science. In order to explore options for assessing students, the working group developed a trial assessment of whether students can program. The underlying goal of this work was to initiate dialog in the Computer Science community on how to develop these types of assessments. Several universities participated in our trial assessment and the disappointing results suggest that many students do not know how to program at the conclusion of their introductory courses. For a combined sample of 216 students from four universities, the average score was 22.89 out of 110 points on the general evaluation criteria developed for this study. From this trial assessment we developed a framework of expectations for first-year courses and suggestions for further work to develop more comprehensive assessments.},
  lang = {en}
}

@INPROCEEDINGS{McDonald:2001,
  author = {McDonald, David W.},
  title = {Evaluating Expertise Recommendations},
  crossref = {proceedings:group:2001},
  pages = {214--223},
  doi = {10.1145/500286.500319},
  keywords = {CSCW, computer-supported cooperative work, expertise location, recommendation systems, user evaluation}
}

@ARTICLE{McKenna:2004,
  author = {McKenna, Peter},
  title = {Gender and black boxes in the programming curriculum},
  crossref = {journal:acm:jeric},
  volume = {4},
  number = {1},
  month = mar,
  year = {2004},
  pages = {1--12},
  doi = {10.1145/1060071.1060077},
  abstract = {This paper summarizes the results of an investigation into whether women and men have different (concrete and abstract) styles of programming, and whether the standard computing curriculum is therefore biased against women. The theory underpinning the hypothesis is critically reviewed in practical programming contexts. A concrete means of testing attitudinal gender differences to black-boxed programming elements is reported and the results described and analyzed. A survey of 50 students, designed to test the hypothesis that women are more likely to reject the techniques and way of thinking of abstraction in programming, casts doubt on the idea that there is any significant difference between female and male attitudes to prepackaged routines. This paper distinguishes between programming and ways of learning to program -- between concrete learning strategies and the use of abstraction in programming -- and discusses pedagogical practice as well as curriculum content.},
  keywords = {Gender, black boxes, programming styles}
}

@ARTICLE{McKenney:2013,
  author = {McKenney, Paul E.},
  title = {Structured Deferral: Synchronization via Procrastination},
  crossref = {journal:acm:cacm},
  volume = {56},
  number = {7},
  month = jul,
  year = {2013},
  pages = {40--49},
  doi = {10.1145/2483852.2483867},
  abstract = {We simply do not have a synchronization mechanism that can enforce mutual exclusion.}
}

@INPROCEEDINGS{McKinney-etal:2004,
  author = {McKinney, Dawn and Froeseth, Julie and Robertson, Jason and Denton, Leo F. and Ensminger, David},
  title = {Agile {CS1} Labs: eXtreme Programming Practices in an Introductory Programming Course},
  crossref = {proceedings:xp:2004},
  pages = {164--174},
  doi = {10.1007/978-3-540-27777-4_17},
  abstract = {Many students begin to form their software development habits in introductory programming courses. Although problem-solving strategies and other good practices are taught at the introductory level, early experiences in programming tend to involve small assignments and so students do not always see the benefits and value of good software engineering practices. Consequently, they develop habits which are hard to break later when faced with significant problems where good practices are essential for success. Furthermore, students report that typical CS1 lab experiences tend to be unsatisfactory and even irrelevant. In order to give the students early meaningful experiences in developing good habits using a software engineering methodology which fits the limited time-constraints of the academic environment, eXtreme Programming (XP) was employed for the lab portion of a second semester CS1 course. This paper describes how XP practices were incorporated into a semester-long project where classes met once a week in a closed lab. Specific affective objectives were also introduced which were measured quantitatively and qualitatively. This paper describes our methodology, assessment, results, and plans for improvement.},
  owner = {magsilva},
  timestamp = {2014.10.21}
}

@ARTICLE{Mead:2009,
  author = {Mead, Nancy R.},
  title = {Software engineering education: How far we've come and how far we have to go},
  crossref = {journal:elsevier:jss},
  volume = {82},
  number = {4},
  month = apr,
  year = {2009},
  pages = {571--575},
  doi = {10.1016/j.jss.2008.12.038},
  abstract = {In this paper I trace the history of software engineering education and focus on some of the key players. I highlight what has been accomplished in degree programs and curricula, conferences and working groups, professionalism, certification, and industry-university collaboration. I also look at the challenges that lie ahead-the global reach of education, new delivery mechanisms, new professional efforts, and the need to engage in leadership in software engineering education. What new approaches should be considered? How can we educators maintain our vitality? How can we best nurture new educators and encourage others to join our profession?},
  keywords = {Software engineering education, Software engineering history}
}

@ARTICLE{Mealy:1955,
  author = {George H. Mealy},
  title = {A Method for Synthesizing Sequential Circuits},
  crossref = {journal:wiley:bell},
  volume = {34},
  number = {5},
  month = sep,
  year = {1955},
  pages = {1045--1079},
  doi = {10.1002/j.1538-7305.1955.tb03788.x},
  abstract = {The theoretical basis of sequential circuit synthesis is developed, with particular reference to the work of D. A. Huffman and E. F. Moore. A new method of synthesis is developed which emphasizes formal procedures rather than the more familiar intuitive ones. Familiarity is assumed with the use of switching algebra in the synthesis of combinational circuits.}
}

@INPROCEEDINGS{Mehlenbacher-etal:2010,
  author = {Mehlenbacher, Brad and Holstein, Krista and Gordon, Brett and Khammar, Khalil},
  title = {Reviewing the research on distance education and e-learning},
  crossref = {proceedings:sigdoc:2010},
  pages = {237--242},
  doi = {10.1145/1878450.1878490},
  abstract = {This paper will provide insight into the current emphasis of research on distance education and e-learning. The review is organized by three intersecting activities. First, we informally collected and reviewed approximately 300 peer-reviewed journals for articles published on distance education and instruction and technology broadly defined. Second, we read and reviewed the numerous meta-analyses of distance education, multimedia, e-learning, and collaborative computing published over the last fifteen years. Third, we performed our own meta-analysis of the abstracts of articles published in 10 peer-reviewed journals on distance learning and e-learning. Our goal in all these activities was to generate a list of significant topics or themes contained in publications about distance education and e-learning, in part to demonstrate the lack of consistent terminology.},
  keywords = {distance education, distance learning, e-learning, education},
  series = {SIGDOC '10},
  acmid = {1878490},
  address = {New York, NY, USA},
  isbn = {978-1-4503-0403-0},
  numpages = {6}
}

@INPROCEEDINGS{Melia-Pahl:2010,
  author = {Mark Melia and Claus Pahl},
  title = {Model-driven description and validation of composite learning content},
  crossref = {proceedings:ed-media:2010},
  pages = {3060--3065},
  abstract = {Authoring of learning content for courseware systems is a complex activity requiring the combination of a range of design and validation techniques. We introduce the CAVIAr courseware models allowing for learning content description and validation. Model-based representation and analysis of different concerns such as the subject domain, learning context, resources and instructional design used are key contributors to this integrated solution. Personalised learning is particularly difficult to design as dynamic configurations cannot easily be predicted and tested. A tool-supported technique based on CAVIAr can alleviate this complexity through the validation of a set of pedagogical and non-pedagogical requirements. Courseware validation checks intra- and inter-content relationships and the compliance with requirements and educational theories.},
  url = {http://www.editlib.org/p/35079}
}

@ARTICLE{Melia-Pahl:2009,
  author = {Melia, Mark and Pahl, Claus},
  title = {Constraint-Based Validation of Adaptive e-Learning Courseware},
  crossref = {journal:ieee:tlt},
  volume = {2},
  number = {1},
  month = jan # {-} # mar,
  year = {2009},
  pages = {37--49},
  doi = {10.1109/TLT.2009.7},
  abstract = {Personalized e-learning allows the course creator to create courseware that dynamically adapts to the needs of individual learners or learner groupings. This dynamic nature of adaptive courseware makes it difficult to evaluate what the delivery time courseware will be for the learner. The course creator may attempt to validate adaptive courseware through dummy runs, but cannot eliminate the risk of pedagogical problems due to adaptive courseware's inherent variability. Courseware validation checks whether adaptive courseware conforms to a set of pedagogical and nonpedagogical requirements. The validation of adaptive courseware limits the risk of pedagogical problems at delivery time. In this paper, we present our approach to adaptive courseware validation using the Courseware Authoring Validation Information Architecture (CAVIAr). We outline how CAVIAr captures adaptive courseware authoring concerns and validates courseware using a constraint-based approach. We also describe how CAVIAr can be integrated with the state of the art in adaptive e-learning and evaluate our validation approach.},
  keywords = {adaptive; courseware; validation; CAVIAr; modeling; interoperability}
}

@INPROCEEDINGS{Melo-etal:2012,
  author = {Melo, Erick Lazaro and Viel, Caio César and Teixeira, Cesar Augusto Camillo},
  title = {{WebNCL}: a web-based presentation machine for multimedia documents},
  crossref = {proceedings:webmedia:2012},
  pages = {403--410},
  doi = {10.1145/2382636.2382719},
  abstract = {Presentation machines for multimedia declarative languages especially the ones related with Interactive Digital TV (iDTV) and Internet Protocol TV (IPTV) are usually embedded in devices and strongly coupled with the platforms when native code and API for the device's platform are used. Since much of the complexity to implement presentation machines lies on presenting and controlling different types of media (video, audio, image, text), and given that most of the modern browsers natively support those requirements, it becomes interesting to implement presentation machines using Web technologies to reduce their coupling with platforms. In this paper we discuss the advantages of a presentation machine for declarative multimedia languages implemented on top of Web technologies. As a proof of concept we implemented the WebNCL, a lightweight NCL presentation machine based on the web technologies stack (HTML 5/ JavaScript/ CSS). By using WebNCL, NCL documents can be presented in any device that has a HTML5 compatible browser, such as tablets, smartphones, smart TVs and PCs.},
  keywords = {HTML5, NCL, multimedia, presentation machine}
}

@ARTICLE{AlvesJr-Domingues:2011,
  author = {Mozart de Melo Alves Júnior and Arturo Hernández Domínguez},
  title = {{A-TVDBR}: Um Modelo de Atividades para {TV} Digital Brasileira},
  crossref = {journal:rbie},
  volume = {19},
  number = {3},
  year = {2011},
  pages = {41-52},
  doi = {10.5753/RBIE.2011.19.03.42},
  abstract = {Este trabalho propõe um modelo de atividades de aprendizagem para TV Digital Brasileira (A- TVDBR) possibilitando, de forma ativa e principalmente interativa, o aprendizado e a formação atra- vés da TV Digital, tendo como público alvo os alunos portadores de deficiências físicas e que possu- em limitação motora da associação dos deficientes físicos do estado de Alagoas (ADEFAL). O mode- lo foi especificado e implementado para GINGA-NCL, utilizando-se da linguagem declarativa NCL (Nested Context Language). Foi realizado um curso para deficientes físicos que possuem limitação motora. Os resultados obtidos mostram que os alunos que usaram a TV-Digital obtiveram um melhor desempenho que os alunos que usaram um ambiente virtual de aprendizagem com o mesmo conteúdo.},
  keywords = {TV Digital, Modelo de atividades de aprendizagem, AVA, GINGA, NCL, portadores de deficiências físicas},
  abstract-en = {This paper presents a Digital TV Learning Activities Model (A-TVDBR) that allows interactive learning and teaching activities on Digital TV. The target audience is students with motion restrictions of the association of the disabled of Alagoas state (ADEFAL). The model was designed and implemented using GINGA-NCL (Nested Context Language). It was executed a course for disabled people who have limited mobility. The results show that the students of the Digital TV group had better performance than the students of the Virtual Learning Environment group, the same course content was used with the two groups of students.},
  keywords-en = {Digital TV, Learning Activities Model, Learning Management System, GINGA, NCL, users with motion restrictions},
  lang = {pt}
}

@INCOLLECTION{Memmel:2007,
  author = {Martin Memmel and Eric Ras and Klaus P. Jantke and Michael Yacci},
  title = {Approaches to Learning Object Oriented Instructional Design},
  chapter = {10},
  pages = {281-325},
  crossref = {Koohang-Harman:2007}
}

@INPROCEEDINGS{Memon-etal:2010,
  author = {Memon, Atif and Porter, Adam and Sussman, Alan},
  title = {Community-based, collaborative testing and analysis},
  crossref = {proceedings:foser:2010},
  pages = {239--244},
  doi = {10.1145/1882362.1882412},
  abstract = {This article proposes a research agenda aimed at enabling optimized testing and analysis processes and tools to support component-based software development communities. We hypothesize that de facto communities---sets of projects that provide, maintain and integrate many shared infrastructure components---are commonplace. Currently, community members, often unknown to each other, tend to work in isolation, duplicating work, failing to learn from each other's effort, and missing opportunities to efficiently improve the common infrastructure. We further hypothesize that as software integration continues to become the predominant mode of software development, there will be increasing value in tools and techniques that empower these communities to coordinate and optimize their development efforts, and to generate and broadly share information. Such tools and techniques will greatly improve the robustness, quality and usability of the common infrastructure which, in turn, will greatly reduce the time and effort needed to produce and use the end systems that are the true goal of the entire community.},
  keywords = {component-based software development communities, testing and analysis}
}

@INPROCEEDINGS{Mendonca-etal:2008,
  author = {Mendonça, M. G. and Maldonado, J. C. and de Oliveira, M. C. F. and Carver, J. and Fabbri, C. P. F. and Shull, F. and Travassos, G. H. and Hohn, E.N. and Basili, V. R.},
  title = {A Framework for Software Engineering Experimental Replications},
  crossref = {proceedings:iceccs:2008},
  pages = {203--212},
  doi = {10.1109/ICECCS.2008.38},
  abstract = {Experimental replications are very important to the advancement of empirical software engineering. Replications are one of the key mechanisms to confirm previous experimental findings. They are also used to transfer experimental knowledge, to train people, and to expand a base of experimental evidence. Unfortunately, experimental replications are difficult endeavors. It is not easy to transfer experimental know-how and experimental findings. Based on our experience, this paper discusses this problem and proposes a Framework for Improving the Replication of Experiments (FIRE). The FIRE addresses knowledge sharing issues both at the intra-group (internal replications) and inter-group (external replications) levels. It encourages coordination of replications in order to facilitate knowledge transfer for lower cost, higher quality replications and more generalizable results.},
  keywords = {Framework for Improving the Replication of Experiments;experimental evidence;experimental knowledge transfer;knowledge sharing;software engineering experimental replication;software engineering;}
}

@ARTICLE{Meneely-etal:2013,
  author = {Meneely, Andrew and Smith, Ben and Williams, Laurie},
  title = {Validating Software Metrics: A Spectrum of Philosophies},
  crossref = {journal:acm:tosem},
  volume = {21},
  number = {4},
  month = feb,
  year = {2013},
  pages = {24:1--24:28},
  doi = {10.1145/2377656.2377661},
  abstract = {Researchers proposing a new metric have the burden of proof to demonstrate to the research community that the metric is acceptable in its intended use. This burden of proof is provided through the multi-faceted, scientific, and objective process of software metrics validation. Over the last 40 years, however, researchers have debated what constitutes a valid metric. The debate over what constitutes a valid metric centers on software metrics validation criteria. The objective of this article is to guide researchers in making sound contributions to the field of software engineering metrics by providing a practical summary of the metrics validation criteria found in the academic literature. We conducted a systematic literature review that began with 2,288 papers and ultimately focused on 20 papers. After extracting 47 unique validation criteria from these 20 papers, we performed a comparative analysis to explore the relationships amongst the criteria. Our 47 validation criteria represent a diverse view of what constitutes a valid metric. We present an analysis of the criteria's categorization, conflicts, common themes, and philosophical motivations behind the validation criteria. Although the 47 validation criteria are not conflict-free, the diversity of motivations and philosophies behind the validation criteria indicates that metrics validation is complex. Researchers proposing new metrics should consider the applicability of the validation criteria in terms of our categorization and analysis. Rather than arbitrarily choosing validation criteria for each metric, researchers should choose criteria that can confirm that the metric is appropriate for its intended use. We conclude that metrics validation criteria provide answers to questions that researchers have about the merits and limitations of a metric.},
  keywords = {Software metrics, systematic literature review, validation criterion}
}

@INPROCEEDINGS{Meneely-Williams:2011,
  author = {Meneely, Andrew and Williams, Laurie},
  title = {Socio-technical developer networks: should we trust our measurements?},
  crossref = {proceedings:icse:2011},
  pages = {281--290},
  doi = {10.1145/1985793.1985832},
  abstract = {Software development teams must be properly structured to provide effectiv collaboration to produce quality software. Over the last several years, social network analysis (SNA) has emerged as a popular method for studying the collaboration and organization of people working in large software development teams. Researchers have been modeling networks of developers based on socio-technical connections found in software development artifacts. Using these developer networks, researchers have proposed several SNA metrics that can predict software quality factors and describe the team structure. But do SNA metrics measure what they purport to measure? The objective of this research is to investigate if SNA metrics represent socio-technical relationships by examining if developer networks can be corroborated with developer perceptions. To measure developer perceptions, we developed an online survey that is personalized to each developer of a development team based on that developer's SNA metrics. Developers answered questions about other members of the team, such as identifying their collaborators and the project experts. A total of 124 developers responded to our survey from three popular open source projects: the Linux kernel, the PHP programming language, and the Wireshark network protocol analyzer. Our results indicate that connections in the developer network are statistically associated with the collaborators whom the developers named. Our results substantiate that SNA metrics represent socio-technical relationships in open source development projects, while also clarifying how the developer network can be interpreted by researchers and practitioners.},
  keywords = {developer network, developers, social network analysis},
  review = {Connections in the developer network are statistically associated with the colaborators whom the developers named.},
  timestamp = {2013-08-09}
}

@ARTICLE{Menzies:2013,
  author = {Tim Menzies},
  title = {Beyond Data Mining},
  crossref = {journal:ieee:computer},
  volume = {30},
  number = {3},
  month = may # {--} # jun,
  year = {2013},
  pages = {92},
  doi = {10.1109/MS.2013.49},
  abstract = {Last century, it wasn't known if data miners could find structure within software projects. This century, we know better: data mining has been successfully applied to many different artifacts from software projects. So it's time to move on to "What's next?" In the author's view, "discussion mining" is the next great challenge for the predictive modeling community. These discussion miners know that while predictions and decisions are important, so too are the questions and insights generated on the way to those conclusions.},
  timestamp = {2013-08-01}
}

@ARTICLE{Mernik-etal:2005,
  author = {Mernik, Marjan and Heering, Jan and Sloane, Anthony M.},
  title = {When and how to develop domain-specific languages},
  crossref = {journal:csur},
  volume = {37},
  number = {4},
  month = dec,
  year = {2005},
  pages = {316-344},
  doi = {10.1145/1118890.1118892},
  abstract = {Domain-specific languages (DSLs) are languages tailored to a specific application domain. They offer substantial gains in expressiveness and ease of use compared with general-purpose programming languages in their domain of application. DSL development is hard, requiring both domain knowledge and language development expertise. Few people have both. Not surprisingly, the decision to develop a DSL is often postponed indefinitely, if considered at all, and most DSLs never get beyond the application library stage.Although many articles have been written on the development of particular DSLs, there is very limited literature on DSL development methodologies and many questions remain regarding when and how to develop a DSL. To aid the DSL developer, we identify patterns in the decision, analysis, design, and implementation phases of DSL development. Our patterns improve and extend earlier work on DSL design patterns. We also discuss domain analysis tools and language development systems that may help to speed up DSL development. Finally, we present a number of open problems.},
  keywords = {Domain-specific language, application language, domain analysis, language development system},
  acmid = {1118892},
  address = {New York, NY, USA},
  issn = {0360-0300},
  issue = {4},
  journal = {ACM Computing Surveys},
  numpages = {29},
  publisher = {ACM}
}

@INBOOK{Merrill:2009,
  chapter = {3},
  pages = {41-56},
  title = {First Principles of Instruction},
  author = {M. David Merrill},
  crossref = {Reigeluth-CarrChellman:2009}
}

@ARTICLE{Merrill:2001,
  author = {M. David Merrill},
  title = {Components of instruction: toward a theoretical tool for instructional design},
  crossref = {journal:springer:is},
  volume = {29},
  number = {4-5},
  month = jul,
  year = {2001},
  pages = {291-310},
  doi = {10.1023/A:1011943808888},
  abstract = {This article defines primary knowledge components for entities, actions, and processes. It also defines primary instructional strategy components. It proposes that a different combination of strategy and knowledge components is required for different kinds of instructional goals. It further proposes that if these fundamental strategy-knowledge component combinations are not present that there will be a decrement in the student's effective and efficient acquisition of the desired knowledge and skill. It further proposes that the underlying architecture of an instructional strategy is a combination of primary strategy components and primary knowledge components appropriate for, and consistent with, a given instructional goal. Instructional components are a theoretical tool. They are not a method or development procedure. These instructional strategy and knowledge components can be imbedded in a wide variety of different instructional architectures based on a variety of different philosophical orientations. It is hoped that one of the primary benefits of instructional components is to provide a common vocabulary that will enable designers, theorists, and instructional developers to more clearly describe their products and procedures.},
  keywords = {Instructional component, knowledge component, knowledge object, entity, activity, process, property}
}

@INCOLLECTION{Merrill:1983,
  author = {M. D. Merrill},
  title = {Component Display Theory},
  booktitle = {Instructional Design Theories and Models: An Overview of their Current States},
  publisher = {Lawrence Erlbaum},
  year = {1983},
  address = {Hillsdale, NJ},
  crossref = {Reigeluth:1983},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@ARTICLE{Meter-Horsman:2013,
  author = {Meter, Rodney Van and Clare Horsman},
  title = {A blueprint for building a quantum computer},
  crossref = {journal:acm:cacm},
  volume = {56},
  number = {10},
  month = oct,
  year = {2013},
  pages = {84--93},
  doi = {10.1145/2494568},
  abstract = {Quantum computer architecture holds the key to building commercially viable systems.},
  owner = {magsilva},
  timestamp = {2014.01.16}
}

@ARTICLE{Metz-etal:2003,
  author = {Pierre Metz and John O'Brien and Wolfgang Weber},
  title = {Specifying Use Case Interaction: Types of Alternative Courses},
  crossref = {journal:jot},
  volume = {2},
  number = {2},
  month = mar # {--} # apr,
  year = {2003},
  pages = {111--131},
  abstract = {Use cases are a powerful and widely recognised tool for the elicitation and specification of functional software requirements. However, major problems and gaps still exist; practitioners frequently encounter these. One of these is the specification of alternative use case interaction courses. Experience shows that practitioners do not only need to specify alternative interaction courses that are inserted subject to a business condition; they also need to express partially or fully parallel interaction courses, exceptional use case behaviour, and cyclic interaction paths. Based on an extensive literature review and practical observations, this paper provides definitions for types of alternative interaction courses, as well as clarifying conceptual differences between, and providing illustrative real-world examples of, each. Moreover, these definitions are related to Cockburn's relevant practical approach of use case goals and use case business results in the context of goal-driven requirements engineering. Finally, the provided definitions will contribute to an understanding of use case interaction specification and goal-driven requirements engineering in practice; they also present clear advice on how to perform use case model refactoring through the application of UML's repeatedly discussed extend-relationship.},
  url = {http://www.jot.fm/issues/issue_2003_03/article1},
  timestamp = {2013-11-13}
}

@ARTICLE{Meye-etal:2009,
  author = {Meyer, Bertrand and Choppy, Christine and Staunstrup, J{\o}rgen and van Leeuwen, Jan},
  title = {Research evaluation for computer science},
  crossref = {journal:acm:cacm},
  volume = {52},
  number = {4},
  month = apr,
  year = {2009},
  pages = {31--34},
  doi = {10.1145/1498765.1498780},
  abstract = {Reassessing the assessment criteria and techniques traditionally used in evaluating computer science research effectiveness.}
}

@INPROCEEDINGS{Main-etal:2005,
  author = {Paula Mian and Tayana Conte and Ana Natali and Jorge Biolchini and Guilherme Travassos.},
  title = {Systematic Review Process for Software Engineering},
  crossref = {proceedings:eselaw:2005},
  abstract = {Usually researches start with their research work accomplishing a literature review of some sort. However, unless the review is true, far and repeatable, it is of little scientific value. In this sense, a systematic literature reviews aim at providing the means for carrying out literature reviews that are thorough and unbiased, such that produces scientific value results. This paper describes a systematic way to execute literature review on Software Engineering, presenting a protocol template and corresponding process capable of driving researchers throughout the review conduction process.}
}

@ARTICLE{Middleton:2012,
  author = {Middleton, David},
  title = {Trying to teach problem-solving instead of just assigning it: some practical issues},
  crossref = {journal:ccsc:jcsc},
  volume = {27},
  number = {5},
  month = may,
  year = {2012},
  pages = {60--65},
  url = {http://dl.acm.org/citation.cfm?id=2168874.2168891}
}

@ARTICLE{Midha-Palvia:2012,
  author = {Vishal Midha and Prashant Palvia},
  title = {Factors affecting the success of Open Source Software},
  crossref = {journal:elsevier:jss},
  volume = {85},
  number = {4},
  month = apr,
  pages = {895--905},
  doi = {10.1016/j.jss.2011.11.010},
  abstract = {With the rapid rise in the use of Open Source Software (OSS) in all types of applications, it is important to know which factors can lead to OSS success. OSS projects evolve and transform over time; therefore success must be examined longitudinally over a period of time. In this research, we examine two measures of project success: project popularity and developer activity, of 283 OSS projects over a span of 3 years, in order to observe changes over time. A comprehensive research model of OSS success is developed which includes both extrinsic and intrinsic attributes. Results show that while many of the hypothesized relationships are supported, there were marked differences in some of the relationships at different points in time lending support to the notion that different factors need to be emphasized as the OSS project unfolds over time.},
  keywords = {Open Source Software; system success; longitudinal effects, intrinsic cues; extrinsic cues}
}

@ARTICLE{Miller:1995,
  author = {George A. Miller},
  title = {{WordNet}: a lexical database for {English}},
  crossref = {journal:acm:cacm},
  volume = {38},
  number = {11},
  month = nov,
  year = {1995},
  pages = {39--41},
  doi = {10.1145/219717.219748},
  abstract = {Because meaningful sentences are composed of meaningful words, any system that hopes to process natural languages as people do must have information about words and their meanings. This information is traditionally provided through dictionaries, and machine-readable dictionaries are now widely available. But dictionary entries evolved for the convenience of human readers, not for machines. WordNet provides a more effective combination of traditional lexicographic information and modern computing. WordNet is an online lexical database designed for use under program control. English nouns, verbs, adjectives, and adverbs are organized into sets of synonyms, each representing a lexicalized concept. Semantic relations link the synonym sets.}
}

@ARTICLE{Minnen-etal:2001,
  author = {Minnen, Guido and Carroll, John and Pearce, Darren},
  title = {Applied morphological processing of {English}},
  crossref = {journal:cambridge:nle},
  volume = {7},
  number = {3},
  month = sep,
  year = {2001},
  pages = {207--223},
  doi = {10.1017/S1351324901002728},
  abstract = {We describe two newly developed computational tools for morphological processing: a program for analysis of English inflectional morphology, and a morphological generator, automatically derived from the analyser. The tools are fast, being based on finite-state techniques, have wide coverage, incorporating data from various corpora and machine readable dictionaries, and are robust, in that they are able to deal effectively with unknown words. The tools are freely available. We evaluate the accuracy and speed of both tools and discuss a number of practical applications in which they have been put to use.}
}

@ARTICLE{Misra-etal:2012,
  author = {Misra, S. and Akman, I. and Colomo-Palacios, R.},
  title = {Framework for evaluation and validation of software complexity measures},
  crossref = {journal:iet:software},
  volume = {6},
  number = {4},
  month = aug,
  year = {2012},
  pages = {323--334},
  doi = {10.1049/iet-sen.2011.0206},
  abstract = {This study proposes a framework for the evaluation and validation of software complexity measure. This framework is designed to analyse whether or not software metric qualifies as a measure from different perspectives. Unlike existing frameworks, it takes into account the practical usefulness of the measure and includes all the factors that are important for theoretical and empirical validation including measurement theory. The applicability of the framework is tested by using cognitive functional size measure. The testing process shows that in the same manner the proposed framework can be applied to any software measure. A comparative study with other frameworks has also been performed. The results reflect that the present framework is a better representation of most of the parameters that are required to evaluate and validate a new complexity measure.}
}

@ARTICLE{Mitzenmacher:2010,
  author = {Mitzenmacher, Michael},
  title = {An introduction to human-guided search},
  crossref = {journal:acm:xrds},
  volume = {17},
  number = {2},
  month = dec,
  year = {2010},
  pages = {34--35},
  doi = {10.1145/1869086.1869098},
  abstract = {Can people help computers solve challenging optimization problems?}
}

@INPROCEEDINGS{Mockus-etal:2000,
  author = {Mockus, Audris and Fielding, Roy T. and Herbsleb, James},
  title = {A Case Study of Open Source Software Development: The Apache Server},
  crossref = {proceedings:icse:2000},
  pages = {263--272},
  doi = {10.1145/337180.337209},
  abstract = {According to its proponents, open source style software development has the capacity to compete successfully, and perhaps in many cases displace, traditional commercial development methods. In order to begin investigating such claims, we examine the development process of a major open source application, the Apache web server. By using email archives of source code change history and problem reports we quantify aspects of developer participation, core team size, code ownership, productivity, defect density, and problem resolution interval for this OSS project. This analysis reveals a unique process, which performs well on important measures. We conclude that hybrid forms of development that borrow the most effective techniques from both the OSS and commercial worlds may lead to high performance software processes.},
  keywords = {code ownership, defect density, open source, repair interval, software process},
  owner = {magsilva},
  timestamp = {2014.05.29}
}

@ARTICLE{Mockus-etal:2002,
  author = {Mockus, Audris and Fielding, Roy T. and Herbsleb, James D.},
  title = {Two Case Studies of Open Source Software Development: Apache and Mozilla},
  crossref = {journal:acm:tosem},
  volume = {11},
  number = {3},
  month = jul,
  year = {2002},
  pages = {309--346},
  doi = {10.1145/567793.567795},
  abstract = {According to its proponents, open source style software development has the capacity to compete successfully, and perhaps in many cases displace, traditional commercial development methods. In order to begin investigating such claims, we examine data from two major open source projects, the Apache web server and the Mozilla browser. By using email archives of source code change history and problem reports we quantify aspects of developer participation, core team size, code ownership, productivity, defect density, and problem resolution intervals for these OSS projects. We develop several hypotheses by comparing the Apache project with several commercial projects. We then test and refine several of these hypotheses, based on an analysis of Mozilla data. We conclude with thoughts about the prospects for high-performance commercial/open source process hybrids.},
  keywords = {Apache, Mozilla, Open source software, code ownership, defect density, repair interval},
  owner = {magsilva},
  timestamp = {2014.05.29}
}

@ARTICLE{Mok:2012,
  author = {Mok, H.N.},
  title = {Student Usage Patterns and Perceptions for Differentiated Lab Exercises in an Undergraduate Programming Course},
  crossref = {journal:ieee:te},
  volume = {55},
  number = {2},
  month = may,
  year = {2012},
  pages = {213--217},
  doi = {10.1109/TE.2011.2162070},
  abstract = {Differentiated instruction in the form of tiered take-home lab exercises was implemented for students of an undergraduate-level programming course. This paper attempts to uncover the perceptions and usage patterns of students toward these new lab exercises using a comprehensive survey. Findings reveal that these tiered exercises are generally very well received and preferred over their traditional #x201C;one size fits all #x201D; counterparts. Although the study does not show that tiered exercises have improved proficiency or scores, it does seem to indicate higher student engagement and motivation levels. Based on the survey results, a list of recommendations is put forth for the structure and format of tiered exercises that can be applied to future offerings of this programming course as well as to other similar courses.},
  keywords = {Computer science education, differentiated instruction (DI), differentiated learning, educational activities, higher education, student engagement and satisfaction, teaching/learning strategies}
}

@INPROCEEDINGS{Molleri-Benitti:2012,
  author = {Jefferson Seide Molléri and Fabiane Barreto Vavassori Benitti},
  title = {Automated Approaches to Support Secondary Study Processes: a Systematic Review},
  crossref = {proceedings:seke:2012},
  pages = {143--147},
  abstract = {There is the need to identify automated methodologies for supporting the systematic review process. To conduct a systematic review of the literature searching for automated approaches used by researchers to support the systematic review process. We undertook a systematic review following the guidelines set out in Kitchenham and Charters', analyzed the relevant studies,and compared our findings with previous studies. 508 papers have been identified and reviewed according toinclusion and exclusion criteria, resulting in 31 relevant studies. A wide variation in the approaches were identified, inthe concentrate context of selection on of primary studies, dataextraction and monitoring and data synthesis from the conducting the review phase.}
}

@INPROCEEDINGS{Monsalve-etal:2011,
  author = {Elizabeth Suescún Monsalve and Vera Maria B. Werneck and Julio Cesar Sampaio Prado Leite},
  title = {Teaching software engineering with {SimulES-W}},
  crossref = {proceedings:cseet:2011},
  pages = {31--40},
  doi = {10.1109/CSEET.2011.5876102},
  abstract = {This work presents an educational board and card game named SimulES-W, as a tool for teaching Software Engineering. It encompasses 5 years of evolution, in which the game Problems and Programmers was the fundamental source. SimulES-W innovates in three distinct areas: it is a web based game, it relies on a broad view of the software process and it is customizable for content. SimulES-W is supported by collaborative software that implements the SimulES board game. The paper describes the game, stresses its strong points, provides initial data on its use and discusses its future.},
  booktitle = {Software Engineering Education and Training (CSEE T), 2011 24th IEEE-CS Conference on},
  issn = {1093-0175},
  year = {2011}
}

@ARTICLE{Montagud-etal:2012,
  author = {Montagud, Sonia and Abrahão, Silvia and Insfran, Emilio},
  title = {A systematic review of quality attributes and measures for software product lines},
  crossref = {journal:springer:sqj},
  volume = {20},
  number = {3--4},
  month = sep,
  year = {2012},
  pages = {425--486},
  doi = {10.1007/s11219-011-9146-7},
  abstract = {It is widely accepted that software measures provide an appropriate mechanism for understanding, monitoring, controlling, and predicting the quality of software development projects. In software product lines (SPL), quality is even more important than in a single software product since, owing to systematic reuse, a fault or an inadequate design decision could be propagated to several products in the family. Over the last few years, a great number of quality attributes and measures for assessing the quality of SPL have been reported in literature. However, no studies summarizing the current knowledge about them exist. This paper presents a systematic literature review with the objective of identifying and interpreting all the available studies from 1996 to 2010 that present quality attributes and/or measures for SPL. These attributes and measures have been classified using a set of criteria that includes the life cycle phase in which the measures are applied; the corresponding quality characteristics; their support for specific SPL characteristics (e.g., variability, compositionality); the procedure used to validate the measures, etc. We found 165 measures related to 97 different quality attributes. The results of the review indicated that 92% of the measures evaluate attributes that are related to maintainability. In addition, 67% of the measures are used during the design phase of Domain Engineering, and 56% are applied to evaluate the product line architecture. However, only 25% of them have been empirically validated. In conclusion, the results provide a global vision of the state of the research within this area in order to help researchers in detecting weaknesses, directing research efforts, and identifying new research lines. In particular, there is a need for new measures with which to evaluate both the quality of the artifacts produced during the entire SPL life cycle and other quality characteristics. There is also a need for more validation (both theoretical and empirical) of existing measures. In addition, our results may be useful as a reference guide for practitioners to assist them in the selection or the adaptation of existing measures for evaluating their software product lines.},
  keywords = {Software product lines; Quality; Measures; Quality attributes; Systematic literature review}
}

@ARTICLE{Montanez:2011,
  author = {Montanez, Luigi},
  title = {How can software engineers help make government better?},
  crossref = {journal:acm:xrds},
  volume = {18},
  number = {2},
  month = dec,
  year = {2011},
  pages = {23--25},
  doi = {10.1145/2043236.2043247},
  abstract = {Using their technical expertise to bring transparency to the federal government, developers are unlocking data one API at a time.}
}

@INPROCEEDINGS{Montebelo-etal:2007,
  author = {Renan Montebelo and Alex Orlando and Daniel Porto and Dênis Zaniro and Sandra Fabbri},
  title = {{SRAT} ({S}ystematic {R}eview {A}utomatic {T}ool) - Uma Ferramenta Computacional de Apoio à Revisão Sistemática},
  crossref = {proceedings:eselaw:2007},
  abstract = {Systematic Review is a technique used to search for evidence in scientific literature in a formal manner. The process has well-defined stages and all activities are executed in accordance with a previously defined protocol. There are several stages and activities that must be executed through the Systematic Review process. Therefore, it's execution characterizes itself as laborious and time-consuming. Aim: This paper presents the prototype of a computational tool - called SRAT (Systematic Review Automatic Tool) - that supports the Systematic Review process, which aims to make Systematic Reviews more agile, precise and replicable. Method: The tool was specified during a Graduate class in which all students applied Systematic Review and it's being developed collaboratively by four students. Results: The actual results are the tool specification, a partial ready graphical user interface and the module that interacts with the IEEE search engine.Conclusion: It is expected that by using SRAT - which is currently beingdeveloped - more researchers practically apply the technique.}
}

@ARTICLE{Montpetit-Medard:2012,
  author = {Montpetit, M.-J. and Medard, M.},
  title = {Social Television: Enabling Technologies and Architectures},
  crossref = {journal:ieee:proceedings},
  volume = {100},
  number = {Special Centennial Issue},
  month = {13},
  year = {2012},
  pages = {1395--1399},
  doi = {10.1109/JPROC.2012.2189804},
  abstract = {In this paper, we review recent networking developments that will help create the next-generation social television experiences. These include revisiting the way networks are created and using social connectivity to drive physical connectivity and network virtualization. Multipath dissemination and reduction of interruptions will provide better quality of experience. Content protection and privacy are also essential to enable social commentary and metadata applications and will be briefly introduced. Examples of potential applications and results of field trials are also included.}
}

@INPROCEEDINGS{Moon:2013,
  author = {Moon, Eunyoung},
  title = {Gendered Patterns of Politeness in Free/Libre Open Source Software Development},
  crossref = {proceedings:hicss:2013},
  pages = {3168--3177},
  doi = {10.1109/HICSS.2013.240},
  abstract = {In this paper, a qualitative case study of women-dominated Free/Libre Open Source Software (FLOSS) project is conducted to explore factors which successfully involve and sustain women FLOSS participants by drawing on Brown and Levinson's politeness theory. The culture and norms of FLOSS appear to be formulated by what is privileged/marginalized by men in the context of FLOSS, and such men's valuing is likely to threaten women FLOSS participants'; face. Our findings are 1) in the FLOSS context, there are gender-based differences in determining what threatens face on the basis of gendered expectations of what is polite, and 2) women-dominated FLOSS participants are practically polite in software development practices. These findings were explored through an in-depth analysis of interaction episodes on the email list, archival public interview data of women FLOSS developers, FLOSS development environment, and instructive materials shared in public. Our paper shows how politeness theory can be extended to the practice of coding and non-coding work, and provides FLOSS communities with guidelines for involving and sustaining women participants in FLOSS development.}
}

@ARTICLE{Moons-Backer:2013,
  author = {Jan Moons and Carlos De Backer},
  title = {The design and pilot evaluation of an interactive learning environment for introductory programming influenced by cognitive load theory and constructivism},
  crossref = {journal:elsevier:ce},
  volume = {60},
  number = {1},
  month = jan,
  year = {2013},
  pages = {368--384},
  doi = {10.1016/j.compedu.2012.08.009},
  abstract = {This article presents the architecture and evaluation of a novel environment for programming education. The design of this programming environment, and the way it is used in class, is based on the findings of constructivist and cognitivist learning paradigms. The environment is evaluated based on qualitative student and teacher evaluations and experiments performed over a three year timespan. As the findings show, the students and teachers see the environment and the way it is used as an invaluable part of their education, and the experiments show that the environment can help with understanding programming concepts that most students consider very difficult.},
  keywords = {Architectures for educational technology system, Interactive learning environments, Programming and programming languages}
}

@INCOLLECTION{Moore:1993,
  author = {Michael G. Moore},
  title = {Theory of transactional distance},
  pages = {22-38},
  address = {New York, NY, United States},
  crossref = {Keegan:1993}
}

@INPROCEEDINGS{Moraes-etal:2010,
  author = {Moraes, Alan and Silva, Eduardo and da Trindade, Cleyton and Barbosa, Yuri and Meira, Silvio},
  title = {Recommending experts using communication history},
  crossref = {proceedings:rsse:2010},
  pages = {41--45},
  doi = {10.1145/1808920.1808929},
  abstract = {In distributed software development the communication is inefficient because of geographical and temporal distances, affecting the team's performance and awareness. The low level of awareness makes hard the task of finding the expert of a piece of source code, delaying the implementation whenever a developer needs help. To identify and to recommend the people with right knowledge to people in trouble during the implementation can improve the collaboration and awareness of the team because it can reduce the waiting time for an answer, since the expert can be contacted directly. In this paper we propose recommender system for expert location with the aim to reduce delays of finding the right person whenever somebody needs assistance during coding. Our approach uses the communication history of the project (the developer's mailing list) in addition to usual source code history. We also present results which show the practical potential of our approach.},
  keywords = {distributed software development, expert recommender system, global software engineering, knowledge management}
}

@ARTICLE{Moreno-etal:2012,
  author = {Ana M. Moreno and Maria-Isabel Sanchez-Segura and Fuensanta Medina-Dominguez and Laura Carvajal},
  title = {Balancing software engineering education and industrial needs},
  crossref = {journal:elsevier:jss},
  volume = {85},
  number = {7},
  month = jul,
  year = {2012},
  pages = {1607--1620},
  doi = {10.1016/j.jss.2012.01.060},
  abstract = {In the world of information and communications technologies the demand for professionals with software engineering skills grows at an exponential rate. On this ground, we have conducted a study to help both academia and the software industry form a picture of the relationship between the competences of recent graduates of undergraduate and graduate software engineering programmes and the tasks that these professionals are to perform as part of their jobs in industry. Thanks to this study, academia will be able to observe which skills demanded by industry the software engineering curricula do or do not cater for, and industry will be able to ascertain which tasks a recent software engineering programme graduate is well qualified to perform. The study focuses on the software engineering knowledge guidelines provided in SE2004 and GSwE2009, and the job profiles identified by Career Space.},
  keywords = {Software engineering education; Software engineering curricula; Software industry profiles; Software engineer competences; Software engineer skills}
}

@ARTICLE{Moreno-etal:2014,
  author = {Moreno, A. M. and Sánchez-Segura, M. I. and Medina-Dominguez, F. and Cuevas, G.},
  title = {Process Improvement from an Academic Perspective: How Could Software Engineering Education Contribute to CMMI Practices?},
  crossref = {journal:ieee:software},
  volume = {31},
  number = {4},
  month = jul # {--} # aug,
  year = {2014},
  pages = {91--97},
  doi = {10.1109/MS.2013.70},
  abstract = {Educating software engineers is a longstanding challenge, but the results of examining the overlap between software engineering educational standards (SE 2004 and GSwE 2009) and one of the most well-known software process improvement models (CMMI-DEV) could prove useful to both industry and academia.},
  owner = {magsilva},
  timestamp = {2014.09.13}
}

@INPROCEEDINGS{Moreno-etal:2010,
  author = {Marcio Ferreira Moreno and Marcelo Ferreira Moreno and Luiz Fernando Gomes Soares},
  title = {Transmissão de Aplicações e Comandos de Edição ao Vivo em {IPTV} e {DTV} Terrestre},
  crossref = {proceedings:webmedia:2010},
  pages = {203--210},
  abstract = {Aplicações de TV digital (com seus objetos de mídia relacionados) e comandos de edição de aplicações ao vivo (com seus parâmetros associados) são transportados em estruturas de dados de serviços assíncronos definidas em cada sistema de TV Digital específico. Este artigo propõe várias alternativas de transportes para o middleware Ginga-NCL, salientando as estruturas de dados que permitem não apenas o controle do ciclo de vida das aplicações e o mapeamento de referências do ambiente de autoria na sintaxe de transferência sem a intervenção, ou conhecimento, do autor, mas também um maior desempenho na transmissão e processamento de aplicações. Embora propostas para o middleware Ginga-NCL, focando tanto a TV digital terrestre quanto sistemas de IPTV, as opções podem ser estendidas a outros middlewares.},
  keywords = {Multimedia Synchronism, Declarative Middleware, Ginga-NCL, Interactive DTV, NCL, SBTVD-T},
  abstract-en = {DTV applications (with their related media objects) and live editing commands (with their associated parameters) are transmitted embedded in data structures supported by asynchronous transport services that must be defined by each particular DTV system. This paper proposes several transport alternatives to Ginga-NCL middleware, stressing their data structures that allow for not only controlling the application life cycle and mapping the authoring syntax to the transfer syntax without the author's intervention and knowledge, but also for improving the transmission and processing performance of DTV applications. Although focusing on the Ginga-NCL middleware for terrestrial TV and IPTV systems, the proposed alternatives can be extended to other middlewares.}
}

@INPROCEEDINGS{Moreno-etal:2005,
  author = {Marcio Ferreira Moreno and Romualdo Monteiro de Resende Costa and Rogério Ferreira Rodrigues and Luiz Fernando Gomes Soares},
  title = {Edição de documentos hipermídia em tempo de exibição},
  crossref = {proceedings:webmedia:2005},
  pages = {67--76},
  abstract-en = {In some hypermedia system scenarios, like non-linear interactive TV program environments, the authoring and the presentation of hypermedia documents need to be simultaneously done, with authors not knowing part of the document until the actual presentation moment (e.g. live programs). This paper proposes an approach where document modifications, specified by an author, are updated on the fly in the presentation subsystem, maintaining all the document relationships, including those defining the document logical structuring. To validate this proposal, it was developed an implementation using the Nested Context Model (NCM) and editing commands carried through stream events metadata.},
  lang = {pt}
}

@INPROCEEDINGS{Moreno-etal:2008,
  author = {Moreno, Marcio Ferreira and Salles Soares Neto, Carlos and Nagato, Felippe and Soares, Luiz Fernando Gomes},
  title = {Uma abordagem declarativa para geraçãao e adaptação de aplicações de guias Eletrônicos de Programação},
  crossref = {proceedings:webmedia:2008},
  pages = {99--106},
  doi = {10.1145/1666091.1666109},
  abstract = {This paper aims to provide architecture to create Electronic Program Guide applications that can be customized in real time. The Electronic Guide can be used not only as a stand alone application, but also as part of any other digital TV application. The proposed architecture was implemented having the support of the reference implementation of the Ginga middleware. Although specialized for the Brazilian Digital TV System and its declarative language, the architecture can be applied to generate computational code in different target-languages, with a clear separation among style, structure and navigational aspects of the Electronic Program Guide.},
  keywords = {DTV, EPG, Ginga-NCL, NCL, SBTVD-T, middleware}
}

@INPROCEEDINGS{Moth-etal:2011,
  author = {Moth, Andreas Leon Aagaard and Villadsen, Joergen and Ben-Ari, Mordechai},
  title = {{SyntaxTrain}: relieving the pain of learning syntax},
  crossref = {proceedings:itcse:2011},
  pages = {387--387},
  doi = {10.1145/1999747.1999900},
  abstract = {SyntaxTrain parses a Java program and displays the syntax diagrams associated with a syntax error.},
  keywords = {learning programming, syntax, syntax diagram}
}

@INCOLLECTION{Motta-etal:2011,
  author = {Motta, Claudia Lage Rebello da and Ana Cristina Bicharra Garcia and Adriana Santarosa Vivacqua and Flávia Maria Santoro and Jonice de Oliveira Sampaio},
  title = {Sistemas de recomendação},
  chapter = {15},
  pages = {230--244},
  crossref = {Pimentel-Fuks:2011},
  timestamp = {2013-09-26}
}

@ARTICLE{Mudge:2001,
  author = {Mudge, Trevor},
  title = {Power: a first-class architectural design constraint},
  crossref = {journal:ieee:computer},
  volume = {34},
  number = {4},
  month = apr,
  year = {2001},
  pages = {52--58},
  doi = {10.1109/2.917539},
  abstract = {Power is a design constraint not only for portable computers and mobile communication devices but also for high-end systems, and the design process should not subordinate it to performance}
}

@INPROCEEDINGS{Mugridge:2003,
  author = {Mugridge, Rick},
  title = {Challenges in Teaching Test Driven Development},
  crossref = {proceedings:xp:2003},
  pages = {410--413},
  doi = {10.1007/3-540-44870-5_63},
  abstract = {We identify two main challenges in the teaching of Test Driven Development (TDD) over the last two years. The first challenge is to get students to rethink learning and design, and to really engage with this new approach. The second challenge is to explicitly develop their skills in testing, design and refactoring, given that they have little experience in these areas. This requires that fast and effective feedback be provided.},
  owner = {magsilva},
  timestamp = {2014.10.21}
}

@ARTICLE{Mujacic-etal:2012,
  author = {Mujacic, Samra and Debevc, Matjaz and Kosec, Primoz and Bloice, Marcus and Holzinger, Andreas},
  title = {Modeling, design, development and evaluation of a hypervideo presentation for digital systems teaching and learning},
  crossref = {journal:springer:mta},
  volume = {58},
  number = {2},
  month = may,
  year = {2012},
  pages = {435-452},
  doi = {10.1007/s11042-010-0665-1},
  abstract = {Hypervideos are multimedia files, which differ from traditional video files in that they can be navigated by using links that are embedded in them. Students can therefore easily access content that explains and clarifies certain points of the lectures that are difficult to understand, while at the same time not interrupting the flow of the original video presentation. In this paper we report on the design, development and evaluation of a hypermedia e-Learning tool for university students. First, the structure of the hypervideo model is presented; once the structure is known, the process of creating hypervideo content is described in detail, as are the various ways in which content can be linked together. Finally, an evaluation is presented, which has been carried out in the context of an engineering class by use of an interactive experiment, involving N = 88 students from a digital systems course. In this study the students were randomly assigned to two groups; one group participated in the course as usual, whilst the second group participated in the same course while also combining the conventional learning with the hypervideo content developed for the course. The students' learning results showed that the students who had access to the hypervideo content performed significantly better than the comparison group.},
  keywords = {Hypervideo; e-Learning; Multimedia service;Navigation; SMIL}
}

@INPROCEEDINGS{Muller:2006,
  author = {Müller, Matthias M.},
  title = {The Effect of Test-Driven Development on Program Code},
  crossref = {proceedings:xp:2006},
  pages = {94--103},
  doi = {10.1007/11774129_10},
  abstract = {Usage of test-driven development (TDD) is said to lead to better testable programs. However, no study answers either the question how this better testability can be measured nor whether the feature of better testability exists. To answer both questions we present the concept of the controllability of assignments. We studied this metric on various TDD and conventional projects. Assignment controllability seems to support the rules of thumb for testable code, e.g. small classes with low coupling are better testable than large classes with high coupling. And as opposed to the Chidamber and Kemerer metric suite for object-oriented design, controllability of assignments seems to be an indicator whether a project was developed with TDD or not.},
  owner = {magsilva},
  timestamp = {2014.10.20}
}

@INPROCEEDINGS{Mullery:1979,
  author = {G. P. Mullery},
  title = {{CORE} -- a method for controlled requirements specifications},
  crossref = {proceedings:icse:1979},
  pages = {126--135},
  abstract = {Attempts to specify requirements adequately normally fail - sometimes catastrophically. One reason is the lack of a rigorously defined method which directly addresses the needs of requirement specification. CORE, the subject of this paper, is such a method. CORE is the result of several years of practical experiment by the author, using a number of published approaches to specification and design. It is supported by a diagrammatic notation whose key features are a composite of ideas drawn from several widely used notations for expression of requirement or design.},
  timestamp = {2008.07.30}
}

@ARTICLE{Munir-etal:2014:ist,
  author = {Hussan Munir and Misagh Moayyed and Kai Petersen},
  title = {Considering rigor and relevance when evaluating test driven development: A systematic review},
  crossref = {journal:elsevier:ist},
  volume = {56},
  number = {4},
  month = apr,
  year = {2014},
  pages = {375--394},
  doi = {10.1016/j.infsof.2014.01.002},
  abstract = {Context: Test driven development (TDD) has been extensively researched and compared to traditional approaches (test last development, TLD). Existing literature reviews show varying results for TDD. Objective: This study investigates how the conclusions of existing literature reviews change when taking two study quality dimension into account, namely rigor and relevance. Method: In this study a systematic literature review has been conducted and the results of the identified primary studies have been analyzed with respect to rigor and relevance scores using the assessment rubric proposed by Ivarsson and Gorschek 2011. Rigor and relevance are rated on a scale, which is explained in this paper. Four categories of studies were defined based on high/low rigor and relevance. Results: We found that studies in the four categories come to different conclusions. In particular, studies with a high rigor and relevance scores show clear results for improvement in external quality, which seem to come with a loss of productivity. At the same time high rigor and relevance studies only investigate a small set of variables. Other categories contain many studies showing no difference, hence biasing the results negatively for the overall set of primary studies. Given the classification differences to previous literature reviews could be highlighted. Conclusion: Strong indications are obtained that external quality is positively influenced, which has to be further substantiated by industry experiments and longitudinal case studies. Future studies in the high rigor and relevance category would contribute largely by focusing on a wider set of outcome variables (e.g. internal code quality). We also conclude that considering rigor and relevance in TDD evaluation is important given the differences in results between categories and in comparison to previous reviews.},
  keywords = {Test-driven development (TDD), Test-last development (TLD), Internal code quality, External code quality, Productivity }
}

@INPROCEEDINGS{Munir-etal:2014:ease,
  author = {Munir, H. and Wnuk, K. and Petersen, K. and Moayyed, M.},
  title = {An experimental evaluation of Test Driven Development vs. Test-Last Development with industry professionals},
  crossref = {proceedings:ease:2014},
  pages = {50:1--50:10},
  doi = {10.1145/2601248.2601267},
  abstract = {Test-Driven Development (TDD) is a software development approach where test cases are written before actual development of the code in iterative cycles. Context: TDD has gained attention of many software practitioners during the last decade since it has contributed several benefits to the software development process. However, empirical evidence of its dominance in terms of internal code quality, external code quality and productivity is fairly limited. Objective: The aim behind conducting this controlled experiment with professional Java developers is to see the impact of Test-Driven Development (TDD) on internal code quality, external code quality and productivity compared to Test-Last Development (TLD). Results: Experiment results indicate that values found related to number of acceptance test cases passed, McCabe's Cyclomatic complexity, branch coverage, number of lines of code per person hours, number of user stories implemented per person hours are statistically in-significant. However, static code analysis results were found statistically significant in the favor of TDD. Moreover, the results of the survey revealed that the majority of developers in the experiment prefer TLD over TDD, given the lesser required level of learning curve as well as the minimum effort needed to understand and employ TLD compared to TDD. Copyright 2014 ACM.},
  keywords = {Internal or external code quality; Productivity; TDD; Test-driven development; Test-last development; TLD},
  owner = {magsilva},
  references = {Larman, C., Basili, V.R., Iterative and incremental developments. A brief history (2003) Computer, 36 (6), pp. 47-56. , June; Beck, K., Andres, C., (2004) Extreme Programming Explained: Embrace Change, , Addison-Wesley Professional, 2 edition, November; Pancur, M., Ciglaric, M., Trampus, M., Vidmar, T., (2003) Towards Empirical Evaluation of Test-driven Development in A University Environment, 2. , IEEE; Cibulski, H., Yehudai, A., Regression test selection techniques for test-driven development 2011 IEEE Fourth International Conference on Software Testing, Verification and Validation Workshops (ICSTW), pp. 115-124. , IEEE, March 2011; Huang, L., Holcombe, M., Empirical investigation towards the effectiveness of test first programming (2009) Information and Software Technology, 51 (1), pp. 182-194; Ambler, S., Quality in an agile world (2005) Software Quality Professional, 7 (4), p. 34; Yenduri, S., Perkins, L.A., Impact of using test-driven development: A case study (2006) Software Engineering Research and Practice, pp. 126-129; Bhat, T., Nagappan, N., Evaluating the efficacy of test-driven development: Industrial case studies (2006) ISCE'06-5th ACM-IEEE International Symposium on Empirical Software Engineering, pp. 356-363. , volume 2006 of ISESE'06-Proceedings of the 5th ACM-IEEE International Symposium on Empirical Software Engineering, Rio de Janeiro, Brazil, ACM; Muller, M.M., Hagner, O., Experiment about test-first programming (2002) IEE Proceedings-Software, 149 (5), pp. 131-136. , October; Gupta, A., Jalote, P., An experimental evaluation of the effectiveness and efficiency of the test driven development (2007) 1st International Symposium on Empirical Software Engineering and Measurement, ESEM, Proceedings-1st International Symposium on Empirical Software Engineering and Measurement, ESEM, pp. 285-294. , Madrid, Spain, 2007. Inst. of Elec. and Elec. Eng. Computer Society; Pancur, M., Ciglaric, M., Impact of test-driven development on productivity, code and tests: A controlled experiment (2011) Information and Software Technology, 53 (6), pp. 557-573; Kollanus, S., Test-driven development-still a promising approach? (2010) 7th International Conference on the Quality of Information and Communications Technology, QUATIC Proceedings-7th International Conference on the Quality of Information and Communications Technology, QUATIC, pp. 403-408. , Porto, Portugal, 2010. IEEE Computer Society; Erdogmus, H., Morisio, M., Torchiano, M., On the effectiveness of the test-first approach to programming (2005) IEEE Transactions on Software Engineering, 31 (3), pp. 226-237; Geras, A., Smith, M., Miller, J., A prototype empirical evaluation of test driven development (2004) Proceedings-10th International Symposium on Software Metrics, METRICS, pp. 405-416. , September 14, 2004-September 16, 2004, Proceedings-International Software Metrics Symposium, Chicago, IL, United states, IEEE Computer Society. 2004; George, B., Williams, L., (2004) A Structured Experiment of Test-driven Development, pp. 337-342. , volume 46 of Information and Software Technology, Elsevier; Maximilien, E.M., Williams, L., Assessing test-driven development at IBM (2003) IEEE 25th International Conference on Software Engineering, pp. 564-569. , 3-10 May Los Alamitos, CA, USA, 2003. IEEE Comput. Soc; Munir, H., Moayyed, M., Petersen, K., Considering rigor and relevance when evaluating test driven development: A systematic review (2014) Information and Software Technology; Shull, F., Melnik, G., Turhan, B., Layman, L., Diep, M., Erdogmus, H., What do we know about test-driven development? (2010) IEEE Software, 27 (6), pp. 16-19; Pancur, M., Ciglaric, M., Trampus, M., Vidmar, T., Towards empirical evaluation of test-driven development in a university environment (2003) Proc. IEEE Region 8 EUROCON 2003-Computer As A Tool, Volume vol.2 of IEEE Region 8 EUROCON 2003. Computer As A Tool. Proceedings (Cat. No.03EX655), pp. 83-86. , Piscataway, NJ, USA, IEEE; George, B., Williams, L., An initial investigation of test driven development in industry Proceedings of the 2003 ACM Symposium on Applied Computing, pp. 1135-1139. , March 9, 2003-March 12, 2003, Proceedings of the ACM Symposium on Applied Computing, Melbourne, FL, United states, 2003. Association for Computing Machinery; Canfora, G., Cimitile, A., Garcia, F., Piattini, M., Aaron Visaggio, C., Evaluating advantages of test driven development: A controlled experiment with professionals (2006) ISCE'06-5th ACM-IEEE International Symposium on Empirical Software Engineering, pp. 364-371. , September 21, 2006-September 22, 2006, Rio de Janeiro, Brazil, 2006. Association for Computing Machinery; Damm, L., Lundberg, L., Results from introducing component-level test automation and test-driven development (2006) Journal of Systems and Software, 79 (7), pp. 1001-1014; Nagappan, N., Michael Maximilien, E., Bhat, T., Williams, L., Realizing quality improvement through test driven development: Results and experiences of four industrial teams (2008) Empirical Software Engineering, 13 (3), pp. 289-302; Williams, L., Maximilien, E.M., Vouk, M., Test-driven development as a defect-reduction practice 14th International Symposium on Software Reliability Engineering, pp. 34-45. , 17-20 Nov. 2003, 14th International Symposium on Software Reliability Engineering, Los Alamitos, CA, USA, 2003. IEEE Comput. Soc; Wohlin, C., Runeson, P., Host, M., (1999) Experimentation in Software Engineering: An Introduction, , Springer, 1st edition, December; Eclipse IDE for Java Developers J Eclipse Packages; Martin, R.C., (2002) Agile Software Development and Principles Patterns and Practices, , Prentice Hall, 1st edition, October; Fenton, N.E., Peeger, S.L., (1998) Software Metrics: A Rigorous and Practical Approach, Revised, , Course Technology, 2 edition, February; Henderson-Sellers, B., (1995) Object-Oriented Metrics: Measures of Complexity, , Prentice Hall, 1 edition, December; Tukey, J.W., (1977) Exploratory Data Analysis, , Addison-Wesley Publishing Company; Kachigan, S.K., (1986) Statistical Analysis: An Interdisciplinary Introduction to Univariate & Multivariate Methods, , Radius Press, January; Dyba, T., Kampenes, V.B., Sjoberg, D.I.K., A systematic review of statistical power in software engineering experiments (2006) Information and Software Technology, 48 (8), pp. 745-755; Desai, C., Janzen, D., Savage, K., A survey of evidence for test-driven development in academia (2008) SIGCSE Bulletin, 40 (2), pp. 97-101. , June; Janzen, D.S., Saiedian, H., A leveled examination of test-driven development acceptance (2007) 29th International Conference on Software Engineering, ICSE, pp. 719-722. , May 20, 2007-May 26, 2007, Proceedings-International Conference on Software Engineering, Minneapolis, MN, United states, 2007. Inst. of Elec. and Elec. Eng. Computer Society; Janzen, D.S., Saiedian, H., Does test-driven development really improve software design quality? (2008) Software, IEEE, 25 (2), pp. 77-84; Janzen, D.S., Saiedian, H., (2006) On the Inuence of Test-driven Development on Software Design, 2006, pp. 141-148. , Turtle Bay, HI, United states; Madeyski, L., The impact of test-first programming on branch coverage and mutation score indicator of unit tests: An experiment (2010) Information and Software Technology, 52 (2), pp. 169-184; Madeyski, L., Szala, L., The impact of test-driven development on software development productivity an empirical study (2007) Software Process Improvement, pp. 200-211; Huan Vu, J., Frojd, N., Shenkel-Therolf, C., Janzen, D.S., (2009) 6th International Conference on Information Technology: New Generations, ITNG, pp. 229-234. , Las Vegas, NV, United states, IEEE Computer Society; Flohr, T., Schneider, T., Lessons learned from an XP experiment with students: Test-first needs more teachings (2006) Product-Focused Software Process Improvement, 4034, pp. 305-318. , Springer Berlin Heidelberg, Berlin, Heidelberg},
  timestamp = {2014.08.19}
}

@ARTICLE{Munson:2012,
  author = {Munson, M. Arthur},
  title = {A study on the importance of and time spent on different modeling steps},
  crossref = {journal:acm:sigkdd},
  volume = {13},
  number = {2},
  month = may,
  year = {2012},
  pages = {65--71},
  doi = {10.1145/2207243.2207253},
  abstract = {Applying data mining and machine learning algorithms requires many steps to prepare data and to make use of modeling results. This study investigates two questions: (1) how time consuming are the pre- and post-processing steps? (2) how much research energy is spent on these steps? To answer these questions I surveyed practitioners about their experiences in applying modeling techniques and categorized data mining and machine learning research papers from 2009 according to the modeling step(s) they addressed. Survey results show that model building consumes only 14% of the time spent on a typical project; the remaining time is spent on pre- and post-processing steps. Both survey responses and the categorization of research papers show that data mining and machine learning researchers spend the majority of their energy on algorithms for constructing models and significantly less energy on other steps. These findings collectively suggest that there are research opportunities to simplify the steps that precede and follow model building.}
}

@INPROCEEDINGS{Murgia-etal:2010,
  author = {Murgia, Alessandro and Concas, Giulio and Marchesi, Michele and Tonelli, Roberto},
  title = {A Machine Learning Approach for Text Categorization of Fixing-issue Commits on {CVS}},
  crossref = {proceedings:esem:2010},
  pages = {6:1--6:10},
  doi = {10.1145/1852786.1852794},
  abstract = {We studied data mining from CVS repositories of two large OO projects, Eclipse and Netbeans, focusing on "fixing-issue" commits. We highlight common characteristics of issue reporting, and problems related to the identification of these messages, and compare static traditional approaches, like Knowledge Engineering, to dynamic approaches based on Machine Learning techniques. We compare for the first time performances of Machine Learning (ML) techniques to automatic classify "fixing-issues" among message commits. Our study calculates precision and recall of different Machine Learning Classifiers for the correct classification of issue-reporting commits. Our results show that some ML classifiers can correctly classify up to 99.9% of such commits.},
  keywords = {classifier, data mining, machine learning}
}

@ARTICLE{mussbacher-etal:2011,
  author = {Mussbacher, Gunter and Araújo, João and Moreira, Ana and Amyot, Daniel},
  title = {AoURN-based modeling and analysis of software product lines},
  crossref = {journal:springer:sqj},
  year = {2011},
  pages = {1--43},
  doi = {10.1007/s11219-011-9153-8},
  abstract = {Software Product Line Engineering concerns itself with domain engineering and application engineering. During domain engineering, the whole product family is modeled with a preferred flavor of feature models and additional models as required (e.g., domain models or scenario-based models). During application engineering, the focus shifts toward a single family member and the configuration of the member's features. Recently, aspectual concepts have been employed to better encapsulate individual features of a Software Product Line (SPL), but the existing body of SPL work does not include a unified reasoning framework that integrates aspect-oriented feature description artifacts with the capability to reason about stakeholders' goals while taking feature interactions into consideration. Goal-oriented SPL approaches have been proposed, but do not provide analysis capabilities that help modelers meet the needs of the numerous stakeholders involved in an SPL while at the same time considering feature interactions. We present an aspect-oriented SPL approach for the requirements phase that allows modelers (a) to capture features, goals, and scenarios in a unified framework and (b) to reason about stakeholders' needs and perform trade-off analyses while considering undesirable interactions that are not obvious from the feature model. The approach is based on the Aspect-oriented User Requirements Notation (AoURN) and helps identify, prioritize, and choose products based on analysis results provided by AoURN editor and analysis tools. We apply the AoURN-based SPL framework to the Via Verde SPL to demonstrate the feasibility of this approach through the selection of a Via Verde product configuration that satisfies stakeholders' needs and results in a high-level, scenario-based specification that is free from undesirable feature interactions.}
}

@ARTICLE{Nagappan-etal:2009,
  author = {Nachiappan Nagappan and Andreas Zeller and Thomas ZImmermann},
  title = {Future of Mining Software Archives: A Roundtable},
  crossref = {journal:ieee:computer},
  volume = {26},
  number = {1},
  month = jan # {--} # feb,
  year = {2009},
  pages = {67--70},
  doi = {10.1109/MS.2009.10},
  abstract = {When mining software archives, we want to learn from the past to shape the future. But what does the research so far tell us about the future of the field itself? For this special issue, we invited and collected statements from nine research leaders in the field. These statements show opportunities for data collection and exploitation (Michael Godfrey, Ahmad Hassan, and James Herbsleb), enhancing programmer productivity (Gail Murphy and Martin Robillard), examining the role of social networking (Prem Devanbu), leveraging data for industry (Audris Mockus), and answering open research questions (Dewayne Perry). David Notkin, though, warns against too much enthusiasm: ``Let us not mine for fool's gold.'' Enjoy!}
}

@INPROCEEDINGS{Naguib-etal:2013,
  author = {Naguib, Hoda and Narayan, Nitesh and Brügge, Bernd and Helal, Dina},
  title = {Bug report assignee recommendation using activity profiles},
  crossref = {proceedings:msr:2013},
  pages = {22--30},
  doi = {10.1109/MSR.2013.6623999},
  abstract = {One question which frequently arises within the context of artifacts stored in a bug tracking repository is: who should work on this bug report? A number of approaches exist to semi-automatically identify and recommend developers, e.g. using machine learning techniques and social networking analysis. In this work, we propose a new approach for assignee recommendation leveraging user activities in a bug tracking repository. Within the bug tracking repository, an activity profile is created for each user from the history of all his activities (i.e. review, assign, and resolve). This profile, to some extent, indicates the users role, expertise, and involvement in this project. These activities influence and contribute to the identification and ranking of suitable assignees. In order to evaluate our work, we apply it to bug reports of three different projects. Our results indicate that the proposed approach is able to achieve an average hit ratio of 88%. Comparing this result to the LDA-SVMbased assignee recommendation technique, it was found that the proposed approach performs better.},
  keywords = {activity profile, bug report, assignee recommendation, bug tracking},
  tags = {expertise metric, activity profile, expert recommendation},
  timestamp = {2013-08-01}
}

@ARTICLE{Nakagawa-etal:2011a,
  author = {Elisa Y. Nakagawa and Fabiano C. Ferrari and Mariela M.F. Sasaki and José C. Maldonado},
  title = {An aspect-oriented reference architecture for Software Engineering Environments},
  crossref = {journal:jss},
  volume = {84},
  number = {10},
  year = {2011},
  pages = {1670 - 1684},
  doi = {10.1016/j.jss.2011.04.052},
  abstract = {Reusable and evolvable Software Engineering Environments (SEEs) are essential to software production and have increasingly become a need. In another perspective, software architectures and reference architectures have played a significant role in determining the success of software systems. In this paper we present a reference architecture for SEEs, named RefASSET, which is based on concepts coming from the aspect-oriented approach. This architecture is specialized to the software testing domain and the development of tools for that domain is discussed. This and other case studies have pointed out that the use of aspects in RefASSET provides a better Separation of Concerns, resulting in reusable and evolvable SEEs.},
  keywords = {Software Engineering Environment, Software architecture, Reference architecture, Aspect orientation, Software testing},
  url = {http://www.sciencedirect.com/science/article/pii/S0164121211001038},
  issn = {0164-1212},
  journal = {Journal of Systems and Software}
}

@INPROCEEDINGS{Nakagawa-etal:2011b,
  author = {Elisa Yumi Nakagawa and Elaine Parros Machado de Sousa and José Carlos Maldonado},
  title = {An experience of open source development for historical heritage domain},
  crossref = {proceedings:iadis-is:2011},
  pages = {307--311},
  abstract = {In the last years, Free/Libre/Open Source Software (FLOSS) has sparked considerable interest, mainly due to a diversity of well-known FLOSS projects and the FLOSS Development (FLOSSD) processes conducted in these projects. Considering the success of these processes, their investigation and adoption in different contexts seem also to be promising. In this paper, we present an experience of applying a FLOSSD process to build an information system, more specifically a web system for historical heritage domain in the context of a research project; i.e. in a context quite different from traditional FLOSS projects. Learned lessons and adjustments in the FLOSSD process are discussed, aiming at contributing to processes in similar contexts.},
  keywords = {Software development process; Open source software; Historical heritage}
}

@INPROCEEDINGS{Narayanaswamy-Goldman:1992,
  author = {K. Narayanaswamy and Neil Goldman},
  title = {Lazy Consistency: A Basis for Cooperative Software Development},
  crossref = {proceedings:cscw:1992},
  pages = {257--264},
  doi = {10.1145/143457.143521},
  abstract = {One of the major problems in cooperative software development is that of maintaining certain global con- sistency properties. Broadcasting changes that have already occured, as many programming environments do, will not resolve this problem. We argue in fa- vor of an architecture where the announcements deal with impending or proposed changes as well as changes that have already occurred. One can then formulate consistency requirements on the system that are main- tained ``lazily'' as it evolves. Such an architecture can support a wider range of cooperative processes than traditional software development environments. This paper describes the design and implementation of this architecture.},
  timestamp = {2008.07.30}
}

@INPROCEEDINGS{neale-etal:2004,
  author = {Dennis C. Neale and John M. Carroll and Mary Beth Rosson},
  title = {Evaluating Computer-Supported Cooperative Work: Models and Frameworks},
  crossref = {proceedings:cscw:2004},
  pages = {112-121},
  abstract = {Evaluating distributed CSCW applications is a difficult endeavor. Frameworks and methodologies for structuring this type of evaluation have become a central concern for CSCW researchers. In this paper we describe the problems involved in evaluating remote collaborations, and we review some of the more prominent conceptual frameworks of group interaction that have driven CSCW evaluation in the past. A multifaceted evaluation framework is presented that approaches the problem from the relationships underlying joint awareness, communication, collaboration, coordination, and work coupling. Finally, recommendations for carrying out multifaceted evaluations of remote interaction are provided.},
  keywords = {CSCW evaluation, models, awareness, common ground},
  volume = {6},
  number = {3},
  year = {2004}
}

@INPROCEEDINGS{Neelofar-etal:2012,
  author = {Neelofar and Javed, M. Y. and Mohsin, H.},
  title = {An Automated Approach for Software Bug Classification},
  crossref = {proceedings:cisis:2012},
  pages = {414--419},
  doi = {10.1109/CISIS.2012.132},
  abstract = {Open source projects for example Eclipse and Firefox have open source bug repositories. User reports bugs to these repositories. Users of these repositories are usually non-technical and cannot assign correct class to these bugs. Triaging of bugs, to developer, to fix them is a tedious and time consuming task. Developers are usually expert in particular areas. For example, few developers are expert in GUI and others are in java functionality. Assigning a particular bug to relevant developer could save time and would help to maintain the interest level of developers by assigning bugs according to their interest. However, assigning right bug to right developer is quite difficult for triager without knowing the actual class, the bug belongs to. In this research, we have classified the bugs in different labels on the basis of summary of the bug. Multinomial Naïve Bayes text classifier is used for classification purpose. For feature selection, Chi-Square and TFIDF algorithms were used. Using Naïve Bayes and Chi- square, we get average of 83% accuracy.},
  keywords = {Text mining, classification, software repositories, open source software projects, triaging, feature extraction}
}

@ARTICLE{Nelson:2012,
  author = {Nelson, Jelani},
  title = {Sketching and streaming algorithms for processing massive data},
  crossref = {journal:acm:xrds},
  volume = {19},
  number = {1},
  month = sep,
  year = {2012},
  pages = {14--19},
  doi = {10.1145/2331042.2331049},
  abstract = {The rate at which electronic information is generated in the world is exploding. In this article we explore techniques known as sketching and streaming for processing massive data both quickly and memory-efficiently.}
}

@INPROCEEDINGS{Neris-etal:2005,
  author = {Neris, Vania P. A. and Anacleto, Junia C. and Mascarenhas, Silvia and Talarico Neto, Americo},
  title = {Hyper documents with quality for distance learning: cognitive strategies to help teachers in the navigational project and content organization},
  crossref = {proceedings:webmedia:2005},
  pages = {1--7},
  doi = {10.1145/1114223.1114228},
  abstract = {The main goal of this work was to evaluate the use of a group of Cognitive Strategies as a help in the structure and organization of the instructional material content by the interface, targeting to increase the hyper document usability and so its quality. For an effective process of distance learning it is necessary to assist teachers during the design of instructional material, helping them to design the material structure, navigation, organization and layout and considering pedagogical aspects that facilitate the student knowledge building. Considering usability as the needed effort to use the software, and considering the material as an interface to students, so if the material is made even easier to be understood, teachers are reducing the students' effort and so increasing this material usability. The case studies realized suggested that the Cognitive Strategies proposed enhanced the hyper documents usability.},
  keywords = {cognitive strategies, distance learning, hyper documents edition, usability evaluation}
}

@ARTICLE{Nerson:1992,
  author = {Nerson, Jean-Marc},
  title = {Applying object-oriented analysis and design},
  crossref = {journal:acm:cacm},
  volume = {35},
  number = {9},
  month = sep,
  year = {1992},
  pages = {63--74},
  doi = {10.1145/130994.130997},
  keywords = {analysis, flexible software architecture, object-oriented notation and methodology, object-oriented software engineering, reliable component reusability},
  timestamp = {2013-09-03}
}

@INPROCEEDINGS{NerySilva-etal:2008,
  author = {Nery e Silva, Lincoln David and Tavares, Tatiana Aires and de Souza Filho, Guido Lemos},
  title = {Desenvolvimento de programas de {TVDI} explorando as funções inovadoras do {Ginga-J}},
  crossref = {proceedings:webmedia:2008},
  pages = {75--82},
  doi = {10.1145/1666091.1666106},
  abstract = {No panorama nacional, a especificação do middleware Ginga permite a incorporação de novas funcionalidades através da API de Integração de Dispositivos, explorada neste artigo. Neste artigo, apresentamos uma visão geral do middleware Ginga e, em especial do Ginga-J, detalhamos a API de Integração de Dispositivos e, ainda, discutimos diferentes cenários de uso para essa API abordando recursos multimídia e suporte multiusuário. Por fim, apresentamos os resultados obtidos através da implementação de aplicações piloto.},
  keywords = {TV digital, dispositivos móveis, Ginga},
  abstract-en = {The specification of Brazilian DTV middleware Ginga allows the incorporation of new functionalities using the Device Integration API. In this paper, we present a Ginga overview and, in particular, Ginga-J, we detail the used API and discuss different application scenarios of this API. These scenarios address multimedia resources and multiuser support. Finally, we present the obtained results.},
  lang = {pt}
}

@ARTICLE{Nesic-etal:2011,
  author = {Sasa Nesic and Dragan Gasevic and Mehdi Jazayeri and Monica Landoni},
  title = {A Learning Content Authoring Approach based on Semantic Technologies and Social Networking: an Empirical Study},
  crossref = {journal:ifets:ets},
  volume = {14},
  number = {4},
  year = {2011},
  pages = {35--48},
  abstract = {Semantic web technologies have been applied to many aspects of learning content authoring including semantic annotation, semantic search, dynamic assembly, and personalization of learning content. At the same time, social networking services have started to play an important role in the authoring process by supporting authors' collaborative activities. Whether semantic web technologies and social networking improved the authoring process and to what extent they make authors' life easier, however, remains an open question that we try to address in this paper. We report on the results of an empirical study based on the experiments that we conducted with the prototype of a novel document architecture called SDArch. Semantic web technologies and social networking are two pillars of SDArch, thus potential benefits of SDArch naturally extend to them. Results of the study show that the utilization of SDArch in authoring improves user' performances compared to the authoring with conventional tools. In addition, the users' satisfaction collected from their subjective feedback was also highly positive.},
  keywords = {Empirical study, Learning content authoring, Semantic web technologies, Social networking}
}

@INPROCEEDINGS{TalaricoNeto-Fortes:2010,
  author = {Neto, Americo Talarico and de Mattos Fortes, Renata Pontin},
  title = {Improving multimodal interaction design with the MMWA authoring environment},
  crossref = {proceedings:sigdoc:2010},
  pages = {151--158},
  doi = {10.1145/1878450.1878476},
  abstract = {Multimodal Interfaces are designed to increase the human-machine communication bandwidth and to enhance user's satisfaction and task completion efficiency by providing a more natural way of interacting with computers. In contrast, developing multimodal interfaces is still a difficult task due to the lack of tools that consider not only code generation, but usability of such interfaces. In this paper, we present the MultiModal Web Approach's authoring environment, whose main goal is enhancing the dissemination of knowledge used in a project for future developments that are benefited by proven solutions to recurring problems in the multimodal context.},
  keywords = {design rationale and design patterns, multimodal interfaces design},
  series = {SIGDOC '10},
  acmid = {1878476},
  address = {New York, NY, USA},
  isbn = {978-1-4503-0403-0},
  numpages = {8}
}

@ARTICLE{Neto:2009,
  author = {João José Neto},
  title = {A Teoria da Computação e o Profissional de Informática},
  crossref = {journal:puc-sp:rct},
  volume = {1},
  number = {1},
  year = {2009},
  pages = {4--21},
  abstract = {This paper discusses the importance of mastering and having detailed domain of theoretical and abstract knowledge as a part of the conceptual background for professionals in the field of informatics. A broad landscape of this field is shown, a diversity of interesting theoretical subjects are commented and interrelated, and their relevance for a competent professional practice is emphasized.},
  keywords = {informatics; Computation; Theory of Computation; abstraction; science; technology; foundations; practice; applications},
  abstract-orig = {Discute-se neste trabalho a importância do domínio do conhecimento e da fluência em assuntos teóricos e abstratos como parte da bagagem conceitual dos profissionais da área de Informática. Apresenta-se um quadro panorâmico geral da área, tecendo-se comentários sobre diversos assuntos teóricos de interesse, procurando-se correlacioná-los e mostrar a sua relevância para o exercício competente da prática profissional.},
  keywords-orig = {informática; Computação; Teoria da Computação; abstrações; ciência; tecnologia; fundamentos; prática; aplicação},
  owner = {magsilva},
  timestamp = {2014.04.07}
}

@INPROCEEDINGS{LustosaNeto-etal:2013,
  author = {Neto, Vicente Lustosa and Coelho, Roberta and Leite, Larissa and Guerrero, Dalton S. and Mendonça, Andrea P.},
  title = {{POPT}: a problem-oriented programming and testing approach for novice students},
  crossref = {proceedings:icse:2013},
  pages = {1099--1108},
  abstract = {There is a growing interest of the Computer Science education community for including testing concepts on introductory programming courses. Aiming at contributing to this issue, we introduce POPT, a Problem-Oriented Programming and Testing approach for Introductory Programming Courses. POPT main goal is to improve the traditional method of teaching introductory programming that concentrates mainly on implementation and neglects testing. According to POPT, students skills must be developed by dealing with ill-defined problems, from which students are stimulated to develop test cases in a table-like manner in order to enlighten the problems requirements and also to improve the quality of generated code. This paper presents POPT and a case study performed in an Introductory Programming course of a Computer Science program at the Federal University of Rio Grande do Norte, Brazil. The study results have shown that, when compared to a Blind Testing approach, POPT stimulates the implementation of programs of better external quality - the first program version submitted by POPT students passed in twice the number of test cases (professor-defined ones) when compared to non-POPT students. Moreover, POPT students submitted fewer program versions and spent more time to submit the first version to the automatic evaluation system, which lead us to think that POPT students are stimulated to think better about the solution they are implementing.}
}

@INPROCEEDINGS{noor-etal:2009,
  author = {Siti Fadzilah Mat Noor and Norazah Yusof and Siti Zaiton Mohd Hashim},
  title = {A Metrics Suite for Measuring Reusability of Learning Objects},
  crossref = {proceedings:isda:2009},
  pages = {961-963},
  doi = {10.1109/ISDA.2009.114},
  abstract = {Learning Object (LO) is one of the main research topics in the E-Learning community in the recent years, and most researchers pay attention to the issue of Learning Object Reusability. The most obvious motivation is the economic interest of reusing learning material instead of repeatedly authoring it. Reusability requires the LO to be in a fine-grain form because raw media elements are often much easier to reuse than aggregate assemblies. In other words, as the LO size decreases (lower granularity), its potential for reuse increases. Therefore, when designing learning objects, reusability must be considered as a key consideration. This paper shows how we adapted and applied some of the metrics from the software engineering field for the purpose of measuring reusability of learning objects.},
  year = {2009}
}

@ARTICLE{Norman:2010,
  author = {Norman, Donald A.},
  title = {Natural user interfaces are not natural},
  crossref = {journal:acm:interactions},
  volume = {17},
  number = {3},
  month = may,
  year = {2010},
  pages = {6--10},
  doi = {10.1145/1744161.1744163}
}

@ARTICLE{Norman-Nielson:2010,
  author = {Norman, Donald A. and Nielsen, Jakob},
  title = {Gestural interfaces: a step backward in usability},
  crossref = {journal:acm:interactions},
  volume = {17},
  number = {5},
  month = sep,
  year = {2010},
  pages = {46--49},
  doi = {10.1145/1836216.1836228}
}

@INPROCEEDINGS{Norris-etal:2008,
  author = {Norris, Cindy and Barry, Frank and Fenwick Jr., James B. and Reid, Kathryn and Rountree, Josh},
  title = {{ClockIt}: collecting quantitative data on how beginning software developers really work},
  crossref = {proceedings:itcse:2008},
  pages = {37--41},
  doi = {10.1145/1384271.1384284},
  abstract = {The Information Technology sector is suffering from a dramatic reduction in the number of students studying the field and subsequently entering the IT market. The number of freshmen expressing "interest in CS" has dramatically decreased since 2000 [16] and CS attrition rates are very high (DUE 0633640). As part of an effort funded by the National Science Foundation (DUE 0633640), this paper introduces the ClockIt toolset that we believe can be used to help educators understand and reduce the high attrition rates of CS 1 and CS 2 students. Using ClockIt, we can unobtrusively monitor and log student software development activities allowing us to determine what practices make a student a successful software developer and what practices do not.},
  keywords = {assessment, cs1, cs2, programming practices}
}

@INCOLLECTION{Nunes:2009,
  author = {Ivônio Barros Nunes},
  title = {A história da {EAD} no mundo},
  chapter = {1},
  pages = {2-8},
  crossref = {Litto-Formiga:2009}
}

@INPROCEEDINGS{OFallon-etal:2004,
  author = {A. O'Fallon and O. Pilskalns and A. Knight and A. Andrews},
  title = {Defining and Qualifying Components in the Design Phase},
  crossref = {proceedings:seek:2004},
  pages = {1--6},
  abstract = {Component based development in the design phase necessitates a comprehensive look at both static and dynamic UML views. If a design is to incorporate third-party components, one must define component interfaces. We propose a method for defining components in the design phase that can be used for qualification purposes. Coupling and frequency metrics are used to make component definition decisions. Component interface definitions allow for qualifying candidate components.}
}

@ARTICLE{OGrady:2012,
  author = {O'Grady, Michael J.},
  title = {Practical Problem-Based Learning in Computing Education},
  crossref = {journal:acm:toce},
  volume = {12},
  number = {3},
  month = jul,
  year = {2012},
  pages = {10:1--10:16},
  doi = {10.1145/2275597.2275599},
  abstract = {Computer Science (CS) is a relatively new disciple and how best to introduce it to new students remains an open question. Likewis, the identification of appropriate instructional strategies for the diverse topics that constitute the average curriculum remains open to debate. One approach considered by a number of practitioners in CS education involves Problem-Based Learning (PBL), a radical departure from the conventional lecturing format. PBL has been adopted in other domains with success, but whether these positive experiences will be replicated in CS remains to be seen. In this article, a systematic review of PBL initiatives in undergraduate and postgraduate CS is presented from a Computing Education Research (CER) perspective. This includes analyses of a range of practical didactic issues, including the degree to which PBL has been systematically evaluated, practical problem description in the literature, as well as a survey of topics for which a PBL approach has been adopted.},
  keywords = {Computing Education Research (CER), Problem-Based Learning (PBL)}
}

@INPROCEEDINGS{Obrist-etal:2007,
  author = {Obrist, Marianna and Bernhaupt, Regina and Beck, Elke and Tscheligi, Manfred},
  title = {Focusing on elderly: an {iTV} usability evaluation study with eye-tracking},
  crossref = {proceedings:euroitv:2007},
  pages = {66--75},
  doi = {10.1007/978-3-540-72559-6_8},
  abstract = {Elderly people often experience difficulties using interactive TV. This paper presents the findings of a usability evaluation study in combination with eye-tracking conducted for an information oriented interactive TV application. We explored two user groups: elderly users (50 years and above) and users between 20 and 30 years of age. Our focus was on how elderly people perceive and interpret a navigation oriented iTV application. Apart from the standard usability data we used eye-tracking data to gain more insight on why iTV usage seemed to be more difficult for the group of elderly.},
  keywords = {elderly, eye-tracking, interactive TV, usability evaluation}
}

@INPROCEEDINGS{Oettinger:1961,
  author = {A. G. Oettinger},
  title = {Automatic syntatic analysis and the pushdown store},
  crossref = {proceedings:am:1961},
  pages = {104--129},
  owner = {magsilva},
  timestamp = {2014.07.15}
}

@ARTICLE{Offutt:2013,
  author = {Offutt, J.},
  title = {Putting the Engineering into Software Engineering Education},
  crossref = {journal:ieee:software},
  volume = {30},
  number = {1},
  month = jan # {-} # feb,
  year = {2013},
  pages = {96},
  doi = {10.1109/MS.2013.12},
  abstract = {Based on over 20 years of teaching and research experience, the author provides his assessment of software engineering education. He then builds on the analysis to provide recommendations on how we need to diverge from computer science to increase our impact, gain credibility, and ultimately ensure the success and recognition of our young discipline. A key behind the author's message is that we need to become a true engineering discipline.},
  keywords = {scientific discipline , software engineering education , teaching paradigm},
  comment = {This paper is enlightning! For the first time I really understand why 'software engineering' must be a different course. For sure it must have some components from Computer Science, but just enough to teach our students how to developed good software. The analogy of mechanical engineering (actually, any other traditional engineering) with physics is simply great! It also noteworthy that Software Engineering is best taught if not part of a Computer Science program. It has so many differences, specially on the mentality to assess the learning, rather different from the traditional "just one possible solution" from Computer Science. It remembers me the discussions at FIE 2011, where they were evaluating the students by projects, providing a divergent thinking environment.}
}

@ARTICLE{Offutt:2011,
  author = {Jeff Offutt},
  title = {A mutation carol: Past, present and future},
  crossref = {journal:elsevier:ist},
  volume = {53},
  number = {10},
  month = oct,
  year = {2011},
  pages = {1098--1107},
  doi = {10.1016/j.infsof.2011.03.007},
  abstract = {Context The field of mutation analysis has been growing, both in the number of published papers and the number of active researchers. This special issue provides a sampling of recent advances and ideas. But do all the new researchers know where we started? Objective To imagine where we are going, we must first know where we are. To understand where we are, we must know where we have been. This paper reviews past mutation analysis research, considers the present, then imagines possible future directions. Method A retrospective study of past trends lets us the ability to see the current state of mutation research in a clear context, allowing us to imagine and then create future vectors. Results The value of mutation has greatly expanded since the early view of mutation as an expensive way to unit test subroutines. Our understanding of what mutation is and how it can help has become much deeper and broader. Conclusion Mutation analysis has been around for 35 years, but we are just now beginning to see its full potential. The papers in this issue and future mutation workshops will eventually allow us to realize this potential.},
  keywords = {Mutation analysis; Software testing; Prediction},
  lang = {en}
}

@INPROCEEDINGS{Oliveira-etal:2008,
  author = {Oliveira, Edmar Welington and Siqueira, Sean Wolfgand M. and Braz, Maria Helena L. B.},
  title = {Using {OWL} to represent metadata of multimedia learning objects},
  crossref = {proceedings:webmedia:2008},
  pages = {226--233},
  doi = {10.1145/1666091.1666129},
  abstract = {The continuous development of the information and communication technologies makes possible the use of new strategies to support learning processes. In addition, there is an increasingly large number of worldwide available content, which could be used as learning materials. However, in spite of offering an inexhaustible source for search processes, this large number of content makes difficult to find a specific material, appropriated to a particular need. So, the work presented in this paper aims at providing a formal and more comprehensive description of the content embedded in Multimedia Learning Objects (MLOs) through complementary groups of metadata with focus in educational and multimedia properties. Thus, parts of the LOM and MPEG-7 metadata standards, both of them represented in OWL, were used in an architecture of multimedia LO description. This paper argues that through these standards it is possible to describe MLOs in a more appropriate way, increasing the retrieval effectiveness of users' searches and improving the reuse potential of these materials. Moreover, through OWL it is possible to build conceptual links between different multimedia resources as well as perform inference tasks and automatically discovering relationships between them. A prototype and a case study present the functionality of the proposed architecture.},
  keywords = {metadata, methodology, multimedia learning objects description; authoring tools, standards}
}

@INPROCEEDINGS{Oliveira:2008,
  author = {Oliveira, João Batista S. de},
  title = {Two algorithms for automatic document page layout},
  crossref = {proceedings:doceng:2008},
  pages = {141--149},
  doi = {10.1145/1410140.1410170},
  abstract = {This paper describes two approaches to the problem of automatically placing document items on pages of some output device. Both solutions partition the page into regions where each item is to be placed, but work on different input data according to the application: One approach assumes that previously defined rectangular items are to be placed freely on the page (as in a sales brochure), whereas the second approach places free-form items on pages divided into columns (as in a newspaper). Moreover, both approaches try to preserve the reading order provided by the input and use all available area on the page. The algorithms implementing those approaches and based on recursive page division are presented, as well as test results, possible changes and research directions.},
  keywords = {automatic page layout, packing, placement algorithms}
}

@ARTICLE{Oliveira-etal:2011,
  author = {Kethure Aline Oliveira and Marília Abrahão Amaral and Gabriela Recipputi Domingos},
  title = {A Avaliação do uso de Objetos de Aprendizagem na Educação de Jovens e Adultos},
  crossref = {journal:rbie},
  volume = {19},
  number = {3},
  year = {2011},
  pages = {53-64},
  doi = {10.5753/RBIE.2011.19.03.53},
  abstract = {A introdução de softwares educacionais nas escolas públicas do Brasil é uma prática que vem ganhando destaque no âmbito educacional. Sob essa perspectiva, diversas ferramentas dão apoio à aprendizagem, uma delas são os Objetos de Aprendizagem, definidos como qualquer recurso digital que pode ser reutilizado para promover a aprendizagem. A presente pesquisa pretende analisar o uso de Objetos de Aprendizagem como forma de ferramenta auxiliadora do processo ensino-aprendizagem da Educação de Jovens e Adultos. Os dados coletados indicam aspectos positivos na utilização dessa ferramenta em níveis de ensino distintos, confirmando assim a possibilidade de reutilização da ferramenta para promover a aprendizagem de públicos distintos em situações e disciplinas curriculares diferentes.},
  keywords = {Informática, Software Educacional, Reutilização, Objetos de Aprendizagem, Educação de Jovens e Adultos},
  journal = {Revista Brasileira de Informática na Educação},
  lang = {pt}
}

@INPROCEEDINGS{Oliveira-etal:2009:webmedia,
  author = {Oliveira, Lílian S. and Martins, Diogo S. and Goulart, Rudinei and Pimentel, Maria G.},
  title = {{EducaTV}: uma arquitetura para acesso a conteúdos educacionais via TVDi},
  crossref = {proceedings:webmedia:2009},
  pages = {1--4},
  doi = {10.1145/1858477.1858525},
  abstract = {Este artigo descreve uma abordagem para prover acesso a conteúdos educacionais por meio de TV Digital interativa (TVDi) e é habilitado por tecnologias XML e padrões de projeto. A abordagem é baseada nos padrões brasileiros para TVDi e provê funcionalidades para apresentação de objetos de aprendizagem em TV voltada a cenários de Educação a Distância (EaD).},
  keywords = {TV digital interativa, aprendizado eletrônico, educação a distância},
  abstract-en = {This paper describes an approach to provide access to educational content through interactive Digital TV (iDTV) enabled by XML technologies and design patterns. The project is based on Brazilian standards for iDTV anad provides functionalities for presenting learning objects on TV, embedded in scenarios of distance education.},
  title-en = {EducaTV: an architecture to access educational content through IDTV}
}

@INPROCEEDINGS{Oliveira-etal:2009:sbie,
  author = {Lilian S. Oliveira and Diogo S. Martins and Maria da Graça C. Pimentel},
  title = {{EducaTV}: uma abordagem para execução de objetos de aprendizagem em {TVDi} compatível com {Ginga-J}},
  crossref = {proceedings:sbie:2009},
  pages = {1-10},
  abstract = {Este artigo propõe o uso da TV Digital interativa, segundo os padrões brasileiros, por meio de uma abordagem para prover acesso a conteúdo educacional usando tecnologias XML e padrões de projeto. A abordagem provê funcionalidades para apresentação de objetos de aprendizagem em TV voltada a cenários de Educação a Distância (EaD).},
  abstract-en = {This paper describes an approach to provide access to educational content through interactive Digital TV (iDTV) enabled by XML technologies and design patterns. The project is based on Brazilian standards for iDTV and provides functionalities for presenting learning objects on TV, considering scenarios of distance education.},
  lang = {pt}
}

@INCOLLECTION{Olivier-Tattersall:2005,
  author = {Bill Olivier and Colin Tattersall},
  title = {The Learning Design Specification},
  chapter = {2},
  pages = {21-40},
  crossref = {Koper-Tattersall:2005}
}

@INPROCEEDINGS{Orso-etal:2001,
  author = {Alessandro Orso and Mary Jean Harrold and David Rosenblum and Gregg Rothermel Mary Lou Soffa and Hyunsook Do},
  title = {Using component metacontent to support the regression testing of component-based software},
  crossref = {proceedings:icsm:2001},
  pages = {716--725},
  doi = {10.1109/ICSM.2001.972790},
  abstract = {Component based software technologies are viewed as essential for creating the software systems of the future. However, the use of externally-provided components has serious drawbacks for a wide range of software engineering activities, often because of a lack of information about the components. Previously (A. Orso et al., 2000), we proposed the use of component metacontents: additional data and methods provided with a component, to support software engineering tasks. The authors present two new metacontent based techniques that address the problem of regression test selection for component based applications: a code based approach and a specification based approach. First, we illustrate the two techniques. Then, we present a case study that applies the code based technique to a real component based system. On the system studied, on average, 26% of the overall testing effort was saved over seven releases, with a maximum savings of 99% for one version},
  tags = {component-based testing, code coverage, vending machine}
}

@INPROCEEDINGS{Klaus-etal:2011,
  author = {Ostermann, Klaus and Giarrusso, Paolo G. and Kästner, Christian and Rendel, Tillmann},
  title = {Revisiting information hiding: reflections on classical and nonclassical modularity},
  crossref = {proceedings:ecoop:2011},
  pages = {155--178},
  doi = {10.1007/978-3-642-22655-7_8},
  abstract = {What is modularity?Which kind of modularity should developers strive for? Despite decades of research on modularity, these basic questions have no definite answer. We submit that the common understanding of modularity, and in particular its notion of information hiding, is deeply rooted in classical logic. We analyze how classical modularity, based on classical logic, fails to address the needs of developers of large software systems, and encourage researchers to explore alternative visions of modularity, based on nonclassical logics, and henceforth called nonclassical modularity.}
}

@INPROCEEDINGS{Ostrand-Weyuker:2010,
  author = {Ostrand, Thomas and Weyuker, Elaine},
  title = {Software testing research and software engineering education},
  crossref = {proceedings:foser:2010},
  pages = {273--276},
  doi = {10.1145/1882362.1882419},
  abstract = {Software testing research has not kept up with modern software system designs and applications, and software engineering education falls short of providing students with the type of knowledge and training that other engineering specialties require. Testing researchers should pay more attention to areas that are currently relevant for practicing software developers, such as embedded systems, mobile devices, safety-critical systems and other modern paradigms, in order to provide usable results and techniques for practitioners. We identify a number of skills that every software engineering student and faculty should have learned, and also propose that education for future software engineers should include significant exposure to real systems, preferably through hands-on training via internships at software-producing firms.},
  keywords = {embedded systems, industrial internship, software engineering training}
}

@INPROCEEDINGS{Ostrand-etal:2004,
  author = {Ostrand, Thomas J. and Weyuker, Elaine J. and Bell, Robert M.},
  title = {Where the bugs are},
  crossref = {proceedings:issta:2004},
  pages = {86--96},
  doi = {10.1145/1007512.1007524},
  abstract = {The ability to predict which files in a large software system are most likely to contain the largest numbers of faults in the next release can be a very valuable asset. To accomplish this, a negative binomial regression model using information from previous releases has been developed and used to predict the numbers of faults for a large industrial inventory system. The files of each release were sorted in descending order based on the predicted number of faults and then the first 20% of the files were selected. This was done for each of fifteen consecutive releases, representing more than four years of field usage. The predictions were extremely accurate, correctly selecting files that contained between 71% and 92% of the faults, with the overall average being 83%. In addition, the same model was used on data for the same system's releases, but with all fault data prior to integration testing removed. The prediction was again very accurate, ranging from 71% to 93%, with the average being 84%. Predictions were made for a second system, and again the first 20% of files accounted for 83% of the identified faults. Finally, a highly simplified predictor was considered which correctly predicted 73% and 74% of the faults for the two systems.},
  keywords = {empirical study, fault-prone, prediction, regression model, software faults, software testing}
}

@ARTICLE{Ovatman-Buzluca:2013,
  author = {Tolga Ovatman and Feza Buzluca},
  title = {Model-based cache-aware dispatching of object-oriented software for multicore systems },
  crossref = {journal:elsevier:jss},
  volume = {86},
  number = {11},
  month = nov,
  year = {2013},
  pages = {2754--2770},
  doi = {10.1016/j.jss.2013.06.025},
  abstract = {Abstract In recent years, processor technology has evolved towards multicore processors, which include multiple processing units (cores) in a single package. Those cores, having their own private caches, often share a higher level cache memory dedicated to each processor die. This multi-level cache hierarchy in multicore processors raises the importance of cache utilization problem. Assigning parallel-running software components with common data to processor cores that do not share a common cache increases the number of cache misses. In this paper we present a novel approach that uses model-based information to guide the OS scheduler in assigning appropriate core affinities to software objects at run-time. We build graph models of software and cache hierarchies of processors and devise a graph matcher algorithm that provides mapping between these two graphs. Using this mapping we obtain candidate core sets that each software object can be affiliated with at run-time. These affiliations are determined based on the idea that software components that have the potential to share common data at run-time should run on cores that share a common cache. We also develop an object dispatcher algorithm that keeps track of object affiliations at run-time and dispatches objects by using the information from the compile-time graph matcher. We apply our approach on design pattern implementations and two different application program running on servers using CFS scheduling. Our results show that cache-aware dispatching based on information obtained from software model, decreases number of cache misses significantly and improves CFS' scheduling performance.},
  keywords = {Model-based scheduling, Object-oriented design for multicore systems, Cache-aware object dispatching },
  timestamp = {2013-09-09}
}

@INPROCEEDINGS{Overdorf-Lang:2011,
  author = {Overdorf, Rebekah and Lang, Matthew},
  title = {Reaching out to Aid in Retention: Empowering Undergraduate Women},
  crossref = {proceedings:sigcse:2011},
  pages = {583--588},
  doi = {10.1145/1953163.1953325},
  abstract = {Creating programs that engage undergraduate women with the broader community and encourage them to take an active role in changing the underrepresentation of women in computer science can effectively address both retention and recruitment of women in the discipline. This paper is an experience report describing the creation and outcomes of an outreach program for K-12 girls run entirely by undergraduate women. The contributions of this paper are the description of the creation of a successful student-led outreach program and a set of active-learning modules for K-12 students that illustrate advanced topics.},
  keywords = {K-12 outreach, gender issues, retention, women in computing}
}

@INPROCEEDINGS{Overmyer-etal:2001,
  author = {Overmyer, Scott P. and Lavoie, Benoit and Rambow, Owen},
  title = {Conceptual modeling through linguistic analysis using {LIDA}},
  crossref = {proceedings:icse:2001},
  pages = {401--410},
  abstract = {Despite the advantages that object technology can provide to the software development community and its customers, the fundamental problems associated with identifying objects, their attributes, and methods remain: it is a largely manual process driven by heuristics that analysts acquire through experience. While a number of methods exist for requirements development and specification, very few tools exist to assist analysts in making the transition from textual descriptions to other notations for object-oriented analysis and other conceptual models. In this paper we describe a methodology and a prototype tool, Linguistic assistant for Domain Analysis (LIDA), which provide linguistic assistance in the model development process. We first present our methodology to conceptual modeling through linguistic analysis. We give an overview of LIDA's functionality and present its technical design and the functionality of its components. We also provide a comparison of LIDA's functionality with that of other research prototypes. Finally, we present an example of how LIDA is used in a conceptual modeling task.},
  timestamp = {2013-08-01}
}

@ARTICLE{Pacheco-Garcia:2012,
  author = {Carla Pacheco and Ivan Garcia},
  title = {A systematic literature review of stakeholder identification methods in requirements elicitation},
  crossref = {journal:springer:jss},
  volume = {85},
  number = {9},
  month = sep,
  year = {2012},
  pages = {2171--2181},
  doi = {10.1016/j.jss.2012.04.075},
  abstract = {This paper presents a systematic review of relevant published studies related to topics in Requirements Engineering, specifically, concerning stakeholder identification methods in requirements elicitation, dated from 1984 to 2011. Addressing four specific research questions, this systematic literature review shows the following evidence gathered from these studies: current status of stakeholder identification in software requirement elicitation, the best practices recommended for its performance, consequences of incorrect identification in requirements quality, and, aspects which need to be improved. Our findings suggest that the analyzed approaches still have serious limitations in terms of covering all aspects of stakeholder identification as an important part of requirements elicitation. However, through correctly identifying and understanding the stakeholders, it is possible to develop high quality software.},
  keywords = {Systematic review, Requirements engineering, Stakeholder identification, Requirements elicitation, Software engineering}
}

@BOOK{PageJones:2001,
  publisher = {Pearson Education},
  year = {2001},
  author = {Meilir Page-Jones},
  isbn = {85-346-1243-9},
  pages = {462},
  address = {São Paulo, SP, } # Brazil,
  edition = {1},
  note = {Tradução por Celso Roberto Paschoa},
  booktitle = {Fundamentos do desenho orientado a objeto com {UML}},
  crossref = {PageJones:2000}
}

@ARTICLE{Pahl:2004,
  author = {Claus Pahl},
  title = {Data mining technology for the evaluation of learning content interaction},
  crossref = {journal:aace:ijel},
  volume = {3},
  number = {4},
  year = {2004},
  pages = {1--16},
  abstract = {Interactivity is central for the success of learning. In e-learning and other educational multimedia environments, the evaluation of interaction and behaviour is particularly crucial. Data mining -- a non-intrusive, objective analysis technology -- shall be proposed as the central evaluation technology for the analysis of the usage of computer-based educational environments and in particular of the interaction with educational content. Basic mining techniques are reviewed and their application in a Web-based third-level course environment is illustrated. Analytic models capturing interaction aspects from the application domain (learning) and the software infrastructure (interactive multimedia) are required for the meaningful interpretation of mining results.},
  keywords = {e-learning educational multimedia; evaluation; data and Web mining; interactivity; content interaction},
  url = {http://doras.dcu.ie/16530/}
}

@INPROCEEDINGS{Pahl-Melia:2006,
  author = {Pahl, Claus and Melia, Mark},
  title = {Semantic modelling of learning objects and instruction},
  crossref = {proceedings:ec-tel:2006},
  pages = {512--517},
  doi = {10.1007/11876663_45},
  abstract = {We introduce an ontology-based semantic modelling framework that addresses subject domain modelling, instruction modelling, and interoperability aspects in the development of complex reusable learning objects. Ontologies are knowledge representation frameworks, ideally suited to support knowledge-based modelling of these learning objects. We illustrate the benefits of semantic modelling for learning object assemblies within the context of standards such as SCORM Sequencing and Navigation and Learning Object Metadata.},
  lang = {en}
}

@ARTICLE{Palma:2001,
  author = {Palma, Paul De},
  title = {Why women avoid computer science},
  crossref = {journal:acm:cacm},
  volume = {44},
  number = {6},
  month = jun,
  year = {2001},
  pages = {27--30},
  doi = {10.1145/376134.376145}
}

@ARTICLE{Pancur-Ciglaric:2011,
  author = {Pan\v{c}ur, Matja and Ciglari\v{c}, Mojca},
  title = {Impact of Test-driven Development on Productivity, Code and Tests: A Controlled Experiment},
  crossref = {journal:elsevier:ist},
  volume = {53},
  number = {6},
  month = jun,
  year = {2011},
  pages = {557--573},
  doi = {10.1016/j.infsof.2011.02.002},
  abstract = {Context: Test-driven development is an approach to software development, where automated tests are written before production code in highly iterative cycles. Test-driven development attracts attention as well as followers in professional environment; however empirical evidence of its superiority regarding its effect on productivity, code and tests compared to test-last development is still fairly limited. Moreover, it is not clear if the supposed benefits come from writing tests before code or maybe from high iterativity/short development cycles. Objective: This paper describes a family of controlled experiments comparing test-driven development to micro iterative test-last development with emphasis on productivity, code properties (external quality and complexity) and tests (code coverage and fault-finding capabilities). Method: Subjects were randomly assigned to test-driven and test-last groups. Controlled experiments were conducted for two years, in an academic environment and in different developer contexts (pair programming and individual programming contexts). Number of successfully implemented stories, percentage of successful acceptance tests, McCabe's code complexity, code coverage and mutation score indicator were measured. Results: Experimental results and their selective meta-analysis show no statistically significant differences between test-driven development and iterative test-last development regarding productivity (@g^2(6)=4.799, p=1.0, r=.107, 95% CI (confidence interval): -.149 to .349), code complexity (@g^2(6)=8.094, p=.46, r=.048, 95% CI: -.254 to .341), branch coverage (@g^2(6)=13.996, p=.059, r=.182, 95% CI: -.081 to .421), percentage of acceptance tests passed (one experiment, Mann-Whitney U=125.0, p=.98, r=.066) and mutation score indicator (@g^2(4)=3.807, p=.87, r=.128, 95% CI: -.162 to .398). Conclusion: According to our findings, the benefits of test-driven development compared to iterative test-last development are small and thus in practice relatively unimportant, although effects are positive. There is an indication of test-driven development endorsing better branch coverage, but effect size is considered small.},
  keywords = {Controlled experiment, Empirical software engineering, Iterative test-last development, Test-driven development}
}

@INPROCEEDINGS{Pansanato-Fortes:2005,
  author = {Luciano T. E. Pansanato and Renata P. M. Fortes},
  title = {Strategies for automatic {LOM} metadata generating in a web-based {CSCL} tool},
  crossref = {proceedings:webmedia:2005},
  pages = {1--8},
  doi = {10.1145/1114223.1114231},
  abstract = {In this paper, we describe our experience of implementing an application profile based on Learning Object Metadata (LOM) and increased with elements to adjust it to our application domain. The educational resources considered here are collaborative Web pages based on Wiki. We discuss strategies for automatic and semi-automatic generation of metadata. Furthermore, we also report the implementation and evaluation of an interface to support the application profile and these strategies.}
}

@INPROCEEDINGS{Papadakis-LeTraon:2013,
  author = {Papadakis, Mike and Le Traon, Yves},
  title = {Mutation testing strategies using mutant classification},
  crossref = {proceedings:sac:2013},
  pages = {1223--1229},
  doi = {10.1145/2480486.2480592},
  abstract = {Mutation testing has a widespread reputation of being a rather powerful testing technique. However, its practical application requires the detection of equivalent mutants. Detecting equivalent mutants is cumbersome since it requires manual analysis, resulting in unbearable testing cost. To overcome this difficulty, researchers have proposed the use of mutant classification, an approach that helps isolating equivalent mutants. From this perspective, the present paper establishes and assesses possible mutant classification strategies. The conducted study suggests that while mutant classification can be useful in isolating equivalent mutants, it fails to kill some mutants. Indeed, the experimental results show that the proposed strategies achieve to kill approximately 95% of the introduced killable mutants.},
  keywords = {mutant classification, mutants' impact, mutation testing}
}

@ARTICLE{Papadimitriou-etal:2012,
  author = {Alexis Papadimitriou and Panagiotis Symeonidis and Yannis Manolopoulos},
  title = {Fast and accurate link prediction in social networking systems},
  crossref = {journal:springer:jss},
  volume = {85},
  number = {9},
  month = sep,
  year = {2012},
  pages = {2119--2132},
  doi = {10.1016/j.jss.2012.04.019},
  abstract = {Online social networks (OSNs) recommend new friends to registered users based on local-based features of the graph (i.e. based on the number of common friends that two users share). However, OSNs do not exploit all different length paths of the network. Instead, they consider only pathways of maximum length 2 between a user and his candidate friends. On the other hand, there are global-based approaches, which detect the overall path structure in a network, being computationally prohibitive for huge-sized social networks. In this paper we provide friend recommendations, also known as the link prediction problem, by traversing all paths of a limited length, based on the `algorithmic small world hypothesis`. As a result, we are able to provide more accurate and faster friend recommendations. We also derive variants of our method that apply to different types of networks (directed/undirected and signed/unsigned). We perform an extensive experimental comparison of the proposed method against existing link prediction algorithms, using synthetic and three real data sets (Epinions, Facebook and Hi5). We also show that a significant accuracy improvement can be gained by using information about both positive and negative edges. Finally, we discuss extensively various experimental considerations, such as a possible MapReduce implementation of FriendLink algorithm to achieve scalability.},
  keywords = {Link prediction, Friend recommendation, Social networks}
}

@INCOLLECTION{Paquette-etal:2005b,
  author = {Gilbert Paquette and Teja, Ileana de la and Michel Leónard and Karin Lundgren-Cayrol and Olga Marino},
  title = {An Instructional Engineering Method and Tool for the Design of Units of Learning},
  chapter = {9},
  pages = {161-184},
  crossref = {Koper-Tattersall:2005}
}

@ARTICLE{pardo-kloos:2011,
  author = {Pardo, Abelardo and Kloos, Carlos Delgado},
  title = {SubCollaboration: large-scale group management in collaborative learning},
  crossref = {journal:wiley:spe},
  volume = {41},
  number = {4},
  year = {2011},
  pages = {449--465},
  doi = {10.1002/spe.1023},
  abstract = {Abstract Computer-supported collaborative learning is a paradigm that uses technology to support collaborative methods of instruction. When combining collaborative learning with the need to exchange documents between students and the teaching staff in a blended learning scenario, version control systems (VCSs) greatly simplify this collaboration. Furthermore, these tools need to be adopted in regular classes as they are used in industrial environments. But deploying a collaborative environment in which version control is used does not scale for large classes. This paper presents SubCollaboration, a platform that uses the VCS Subversion to manage a large number of work spaces in a collaborative learning environment. The tool maintains a reference workspace where teaching staff introduces new material that is then synchronized with the team repositories. Two case studies are presented showing that students easily learn the use of version control and its deployment in large classes is feasible.},
  keywords = {version control systems, computer-supported collaborative systems, software management}
}

@ARTICLE{Pardo-etal:2013,
  author = {César Pardo and Francisco J. Pino and Félix Garcia and Maria Teresa Baldassarre and Mario Piattini},
  title = {From chaos to the systematic harmonization of multiple reference models: A harmonization framework applied in two case studies},
  crossref = {journal:elsevier:jss},
  volume = {86},
  number = {1},
  month = jan,
  year = {2013},
  pages = {125--143},
  doi = {10.1016/j.jss.2012.07.072},
  abstract = {At the present time, we can observe that in an effort to deal with the issue of quality, a variety of models, standards and methodologies have been developed to give support in different domains of the IT industry. This wide range of heterogeneous models makes it possible to resolve multiple needs. In recent years, as the integration of different models has increased, organizations have started to note that their business and technical processes can be aligned with more than one model. Currently, however, we are not aware of any other attempts to provide an explicit and systematic solution that would allow us to address the issue of harmonization of multiple reference models in such a way as to satisfy the needs of the companies. In the quest to help support the work of harmonization of multiple models, this paper presents (i) a framework that defines elements needed to support the harmonization of multiple reference models, (ii) a process, which is the backbone and way of integrating all the elements defined in the framework thus allowing the implementation of a harmonization project to be guided systematically, harmonizing multiple models through the configuration of a harmonization strategy, and (iii) a set of methods, which allows us to know 'what to do', as well as 'how to put' two or more models in consonance with each other. The experience of the application of our proposal is illustrated in two case studies. The findings obtained show that the harmonization process has enabled us to harmonize and put the models involved in consonance with each other.},
  keywords = {Harmonization process, Harmonization of multiple models, Multi-model, Harmonization, Improvement process, SPI, Case study}
}

@ARTICLE{Pareto-etal:2012,
  author = {Lars Pareto and Anna Börjesson Sandberg and Peter Eriksson and Staffan Ehnebom},
  title = {Collaborative prioritization of architectural concerns},
  crossref = {journal:springer:jss},
  volume = {85},
  number = {9},
  month = sep,
  pages = {1971--1994},
  doi = {10.1016/j.jss.2012.04.054},
  abstract = {Efficient architecture work involves balancing the degree of architecture documentation with attention to needs, costs, agility and other factors. This paper presents a method for prioritizing architectural concerns in the presence of heterogeneous stakeholder groups in large organizations that need to evolve existing architecture. The method involves enquiry, analysis, and deliberation using collaborative and analytical techniques. Method outcomes are action principles directed to managers, and assessment of user needs directed to architects, along with evidence. The method results from 4 years of action research at Ericsson AB with the purpose of adding missing views to architecture documentation and removing superfluous ones. It is illustrated on a case where 29 senior engineers and managers within Ericsson prioritized 37 architectural concerns areas to arrive at 8 action principles, 5 prioritized improvement areas, and 24 improvement suggestions. Feedback from the organization is that the method has been effective in prioritizing architectural concerns, that data collection and analysis is more extensive compared to traditional prioritization practices, but that extensive analysis seems inevitable in architecture improvement work.},
  keywords = {Requirement prioritization, Software architecture documentation, Software architecture evolution}
}

@ARTICLE{Parizi-etal:2011,
  author = {Reza Meimandi Parizi and Abdul Azim Abdul Ghani and Rusli Abdullah and Rodziah Atan},
  title = {Empirical evaluation of the fault detection effectiveness and test effort efficiency of the automated AOP testing approaches},
  crossref = {journal:elsevier:ist},
  volume = {53},
  number = {10},
  month = oct,
  year = {2011},
  pages = {1062--1083},
  doi = {10.1016/j.infsof.2011.05.004},
  abstract = {Testing process is a time-consuming, expensive, and labor-intensive activity in any software setting including aspect-oriented programming (AOP). To reduce the testing costs, human effort, and to achieve the improvements in both quality and productivity of AOP, it is desirable to automate testing of aspect-oriented programs as much as possible. In recent past years, a lot of research effort has been devoted to testing aspect-oriented programs but less effort has been dedicated to the automated AOP testing. This denotes that the current research on automated AOP testing is not sufficient and is still in a stage of infancy. In order to advance the state of the research in this area and to provide testers of AOP-based projects with a comparison basis, a detailed evaluation of the current automated AOP testing approaches in a thorough and experimental manner is required. Thus, the objective of this paper is to provide such evaluation of the current approaches. In this paper, we carry out an empirical study based on mutation analysis to examine four (namely Wrasp, Aspectra, Raspect, and EAT) existing automated AOP testing approaches, particularly their underlying test input generation and selection strategies, with regard to fault detection effectiveness. In addition, the approaches are compared in terms of required effort in detecting faults as part of efficiency evaluation. The experimental results and comparison provided insights into the effectiveness and efficiency of automated AOP testing with their respective strengths and weaknesses. Results showed that EAT is more effective than the other automated AOP testing approaches but not significant for all approaches. EAT was found to be significantly better than Wrasp at 95% confidence level (i.e. p < 0.05), but not significantly better than Aspectra or Raspect. Concerning the test effort efficiency, Wrasp was significantly (p < 0.05) efficient with requiring the lowest amount of test effort compared to the other approaches. Whereas, EAT showed to be not very efficient by recording the highest amount of test effort. This implies that EAT can currently be the most effective automated AOP testing approach but perhaps less efficient. More generally, search-based testing (as underlying strategy of EAT approach) might achieve better effectiveness but at the cost of greater test effort compared to random testing (as underlying strategy of other approaches).},
  keywords = {Aspect-oriented programming, Software testing, Automated testing, Aspect testing, Empirical study},
  lang = {en}
}

@INPROCEEDINGS{Park-etal:2012,
  author = {Park, Sangmin and Hossain, B. M. Mainul and Hussain, Ishtiaque and Csallner, Christoph and Grechanik, Mark and Taneja, Kunal and Fu, Chen and Xie, Qing},
  title = {{CarFast}: achieving higher statement coverage faster},
  crossref = {proceedings:fse:2012},
  pages = {35:1--35:11},
  doi = {10.1145/2393596.2393636},
  abstract = {Test coverage is an important metric of software quality, since it indicates thoroughness of testing. In industry, test coverage is often measured as statement coverage. A fundamental problem of software testing is how to achieve higher statement coverage faster, and it is a difficult problem since it requires testers to cleverly find input data that can steer execution sooner toward sections of application code that contain more statements. We created a novel fully automatic approach for aChieving higher stAtement coveRage FASTer (CarFast), which we implemented and evaluated on twelve generated Java applications whose sizes range from 300 LOC to one million LOC. We compared CarFast with several popular test case generation techniques, including pure random, adaptive random, and Directed Automated Random Testing (DART). Our results indicate with strong statistical significance that when execution time is measured in terms of the number of runs of the application on different input test data, CarFast outperforms the evaluated competitive approaches on most subject applications.},
  keywords = {experimentation, statement coverage, testing}
}

@INPROCEEDINGS{Shelly-Maurer:2010,
  author = {Park, Shelly and Maurer, Frank},
  title = {A Literature Review on Story Test Driven Development},
  crossref = {proceedings:xp:2010},
  pages = {208--213},
  doi = {10.1007/978-3-642-13054-0_20},
  abstract = {This paper presents a literature review on story-test driven development. Our findings suggest that there are many lessons learned papers that provide anecdotal evidence about the benefits and issues related to the story test driven development. We categorized these findings into seven themes: cost, time, people, code design, testing tools, what to test and test automation. We analyzed research papers on story test driven development to find out how many of these anecdotal findings were critically examined by researchers and analyzed the gaps in between. The analysis can be used by researchers as a ground for further empirical investigation.},
  keywords = {Story Test Driven Development; Executable Acceptance Test Driven Development; Requirements; Systematic Review; Testing; Empirical software engineering; Agile software development},
  owner = {magsilva},
  timestamp = {2014.10.20}
}

@INPROCEEDINGS{Parnas:1971,
  author = {David L. Parnas},
  title = {Information distribution aspects of design methodology},
  crossref = {proceedings:ifip:1971},
  pages = {26--30},
  abstract = {The role of documentation in the design and implementation of complex systems is explored, resulting in suggestions in sharp contrast with current practice. The concept of system structure is studied by examining the meaning of the phrase 'connections between modules.' It is shown that several system design goals (each suggesting a partial time ordering of the decisions) may be inconsistent. Some properties of programmers are discussed. System documentation, which makes all information accessible to anyone working on the project, is discussed. The thesis that such information 'broadcasting' is harmful, that it is helpful if most system information is hidden from most programmers, is supported by use of the above mentioned considerations as well as by examples. An information hiding technique of documentation is given in the appendix.},
  volume = {TA-3}
}

@INPROCEEDINGS{Parnas:1978,
  author = {Parnas, David L.},
  title = {Designing Software for Ease of Extension and Contraction},
  crossref = {proceedings:icse:1978},
  pages = {264--277},
  abstract = {Designing software to be extensible and easily contracted is discussed as a special case of design for change. A number of ways that extension and contraction problems manifest themselves in current software are explained. Four steps in the design of software that is more flexible are then discussed. The most critical step is the design of a software structure called the 'uses' relation. Some criteria for design decisions are given and illustrated using a small example. It is shown that the identification of minimal subsets and minimal extensions can lead to software that can be tailored to the needs of a broad variety of users.},
  owner = {magsilva},
  timestamp = {2014.09.11}
}

@INPROCEEDINGS{Parnas:1994,
  author = {Parnas, David Lorge},
  title = {Software Aging},
  crossref = {proceedings:icse:1994},
  pages = {279--287},
  doi = {10.1109/ICSE.1994.296790},
  abstract = {Programs, like people, get old. We can't prevent aging, but we can understand its causes, take steps to limits its effects, temporarily reverse some of the damage it has caused, and prepare for the day when the software is no longer viable. A sign that the software engineering profession has matured will be that we lose our preoccupation with the first release and focus on the long-term health of our products. Researchers and practitioners must change their perception of the problems of software development. Only then will software engineering deserve to be called engineering.},
  owner = {magsilva},
  timestamp = {2014.09.25}
}

@INCOLLECTION{Parnas:2002,
  author = {David L. Parnas},
  title = {The Secret History of Information Hiding},
  chapter = {12},
  pages = {399--409},
  abstract = {The concept of information-hiding as a software design principle is widely accepted in academic circles. Many successful designs can be seen as successful applications of abstraction or information hiding. On the other hand, most industrial software developers do not apply the idea and many consider it unrealistic. This paper describes how the idea developed, discusses difficulties in its application, and speculates on why it has not been completely successful.},
  crossref = {Broy-Denert:2002}
}

@ARTICLE{Parnas:1979,
  author = {Parnas, D. L.},
  title = {Designing Software for Ease of Extension and Contraction},
  crossref = {journal:ieee:tse},
  volume = {5},
  number = {2},
  month = mar,
  year = {1979},
  pages = {128--138},
  doi = {10.1109/TSE.1979.234169},
  abstract = {Designing software to be extensible and easily contracted is discussed as a special case of design for change. A number of ways that extension and contraction problems manifest themselves in current software are explained. Four steps in the design of software that is more flexible are then discussed. The most critical step is the design of a software structure called the 'uses' relation. Some criteria for design decisions are given and illustrated using a small example. It is shown that the identification of minimal subsets and minimal extensions can lead to software that can be tailored to the needs of a broad variety of users.},
  keywords = {contractibility, extensibility, modularity, software engineering, subsets, supersets},
  owner = {magsilva},
  timestamp = {2014.09.11}
}

@ARTICLE{Parnas:1972a,
  author = {Parnas, D. L.},
  title = {On the criteria to be used in decomposing systems into modules},
  crossref = {journal:acm:cacm},
  volume = {15},
  number = {12},
  month = dec,
  year = {1972},
  pages = {1053--1058},
  doi = {10.1145/361598.361623},
  abstract = {This paper discusses modularization as a mechanism for improving the flexibility and comprehensibility of a system while allowing the shortening of its development time. The effectiveness of a 'modularization' is dependent upon the criteria used in dividing the system into modules. A system design problem is presented and both a conventional and unconventional decomposition are described. It is shown that the unconventional decompositions have distinct advantages for the goals outlined. The criteria used in arriving at the decompositions are discussed. The unconventional decomposition, if implemented with the conventional assumption that a module consists of one or more subroutines, will be less efficient in most cases. An alternative approach to implementation which does not have this effect is sketched.},
  keywords = {KWIC index, modularity, modules, software, software design, software engineering}
}

@ARTICLE{Parnas-etal:1985,
  author = {Parnas, D. L. and Clements, P. C. and Weiss, D. M.},
  title = {The modular structure of complex systems},
  crossref = {journal:ieee:tse},
  volume = {11},
  number = {3},
  month = mar,
  year = {1985},
  pages = {259--266},
  doi = {10.1109/TSE.1985.232209},
  abstract = {This paper discusses the organization of software that is inherently complex because there are very many arbitrary details that must be precisely right for the software to be correct. We show how the software design technique known as information hiding or abstraction can be supplemented by a hierarchically-structured document, which we call a module guide. The guide is intended to allow both designers and maintainers to identify easily the parts of the software that they must understand without reading irrelevant details about other parts of the software. The paper includes an extract from a software module guide to illustrate our proposals.}
}

@INPROCEEDINGS{Patil-Sidnal:2013,
  author = {Abhinandan H. Patil and Nandini S. Sidnal},
  title = {{CodeCover}: A Code Coverage Tool For {Java} Projects},
  crossref = {proceedings:ercica:2013},
  pages = {414--421},
  abstract = {In this paper we describe about code coverage tool called CodeCover. Most tools available for code coverage give statement coverage and branch coverage. The CodeCover which uses source code instrumentation technique gives statement, branch, loop, term (inclusive of MC/DC) and synchronized coverage. The tool can be used across operating system platforms. The tool supports measurements for JAVA and COBOL languages but can be extended for other programming languages. The tool is open source software under EPL License which makes it attractive for researchers. The tool helps in test suite reduction, test suite augmentation, regression test suite pruning/enhancement. The tool can be used in command line (most suited for regression testing metrics), Ant integration mode (suited for projects which build using Ant), Eclipse integration mode (Suited for projects which do UT in Eclipse environment). This paper investigates the versatile CodeCover tool suitability for Java projects. The paper mentions about enhancements which are being done as part of project.},
  keywords = {Statement coverage, Branch coverage, Loop coverage, Term coverage, Synchronized coverage, MC/DC coverage, Ant, Command line, Eclipse, CodeCover},
  owner = {magsilva},
  timestamp = {2014.07.21}
}

@ARTICLE{Patil-Sidnal:2014,
  author = {Patil, Abhinandan H. and Sidnal, Nandini S.},
  title = {{CodeCover}: Enhancement of {CodeCover}},
  crossref = {journal:acm:sen},
  volume = {39},
  number = {1},
  month = feb,
  year = {2014},
  pages = {1--4},
  doi = {10.1145/2557833.2557850},
  abstract = {The previous published paper on the topic of CodeCover highlights the strengths of CodeCover and discusses the versatility of the tool for various coverage testing needs. In this paper we are highlighting a portion of work done as part of a study project. This paper talks about the minimal efforts needed to tweak the product for specific needs. The existing, well structured code base of CodeCover can be reused as a library for implementing the work to be carried out. The impact to the lower layer of the product is minimal and at times nil for implementing the intended task because of the well laid design. In this paper we talk about how the CodeCover can be used to prioritize the test cases for uncovered branches of the code under test for a given session of testing.},
  keywords = {CodeCover, ESS, ant, architexa, command line, eclipse, uncovered branch weight, uncovered branches}
}

@ARTICLE{Patterson:2014,
  author = {Patterson, David},
  title = {How to Build a Bad Research Center},
  crossref = {journal:acm:cacm},
  volume = {57},
  number = {3},
  month = mar,
  year = {2014},
  pages = {33--36},
  doi = {10.1145/2566969},
  abstract = {Sharing lessons learned from experiences creating successful multidisciplinary research centers.}
}

@INPROCEEDINGS{Pau-etal:2011,
  author = {Pau, Reena and Hall, Wendy and Grace, Marcus and Woollard, John},
  title = {Female students' experiences of programming: it's not all bad!},
  crossref = {proceedings:itcse:2011},
  pages = {323--327},
  doi = {10.1145/1999747.1999837},
  abstract = {Programming has been cited as a barrier for female students to enjoy and pursue computing as a career or at higher education. However, there are examples of good practice, which demonstrate that programming can act as a bridge rather than a barrier. As a result of surveying 103 students and interviewing 60 students from 3 different UK higher education institutions and this paper demonstrates that female students can enjoy programming and take it further for their careers.},
  keywords = {women in computing}
}

@INPROCEEDINGS{Paulovich-etal:2011,
  author = {Fernando V. Paulovich and Danilo M. Eler and Jorge Poco and Charl P. Botha and Rosane Minghim and Luis G. Nonato},
  title = {Piecewise Laplacian-based Projection for Interactive Large Data Exploration and Organization},
  crossref = {proceedings:eurovis:2011},
  pages = {1091--1100},
  doi = {10.1111/j.1467-8659.2011.01958.x},
  address = {Bergen, Noruega},
  publisher = {Blackwell Publishing Ltd}
}

@INPROCEEDINGS{Paulovich-Minghim:2006,
  author = {Fernando V. Paulovich and Rosane Minghim},
  title = {Text map explorer: a tool to create and explore document maps},
  crossref = {proceedings:iv:2006},
  pages = {245--251},
  doi = {10.1109/IV.2006.104},
  abstract = {This paper presents a tool, called text map explorer, which can be used to create and explore document maps (visual representations of document collections). This tool is capable of grouping (and separating) documents by their contents, revealing to the user relationships amongst them. This paper also presents a novel multi-dimensional projection technique for text that reduces the quadratic time complexity of our previous approach to O(N3/2), keeping the same quality of maps. The technique creates a surface that reveals intrinsic patterns and supports various kinds of exploration of a text collection.}
}

@INPROCEEDINGS{Paulovich-etal:2007,
  author = {Fernando V. Paulovich and Maria Cristina F. Oliveira and Rosane Minghim},
  title = {The {Projection Explorer}: A flexible tool for projection-based multidimensional visualization},
  crossref = {proceedings:sibgrapi:2007},
  pages = {27--36},
  doi = {10.1109/SIBGRAPI.2007.21},
  abstract = {Multidimensional projections map data points, defined in a high-dimensional data space, into a 1D, 2D or 3D representation space. Such a mapping may be typically achieved with dimensional reduction, clustering, or force directed point placement. Projections can be displayed and navigated by data analysts by means of visual representations, which may vary from points on a plane to graphs, surfaces or volumes. Typically, projections strive to preserve distance relationships amongst data points, as defined in the original space. Information loss is inevitable and the projection approach defines the extent to which the distance preserving goal is attained. We introduce PEx-the projection explorer - a visualization tool for mapping and exploration of high-dimensional data via projections. A set of examples - on both structured (table) and unstructured (text) data - illustrate how projection based visualizations, coupled with appropriate exploration tools, offer a flexible set-up for multidimensional data exploration. The projections in PEx handle relatively large data sets at a computational cost adequate to user interaction.},
  isbn = {0-7695-2996-8}
}

@ARTICLE{Paulson-etal:2004,
  author = {Paulson, James W. and Succi, Giancarlo and Eberlein, Armin},
  title = {An Empirical Study of Open-Source and Closed-Source Software Products},
  crossref = {journal:ieee:tse},
  volume = {30},
  number = {4},
  month = apr,
  year = {2004},
  pages = {246--256},
  doi = {10.1109/TSE.2004.1274044},
  abstract = {This paper describes an empirical study of open-source and closed-source software projects. The motivation for this research is to quantitatively investigate common perceptions about open-source projects, and to validate these perceptions through an empirical study. This paper investigates the hypothesis that open-source software grows more quickly, but does not find evidence to support this. The project growth is similar for all the projects in the analysis, indicating that other factors may limit growth. The hypothesis that creativity is more prevalent in open-source software is also examined, and evidence to support this hypothesis is found using the metric of functions added over time. The concept of open-source projects succeeding because of their simplicity is not supported by the analysis, nor is the hypothesis of open-source projects being more modular. However, the belief that defects are found and fixed more rapidly in open-source projects is supported by an analysis of the functions modified. The paper finds support for two of the five common beliefs and concludes that, when implementing or switching to the open-source development model, practitioners should ensure that an appropriate metrics collection strategy is in place to verify the perceived benefits.},
  keywords = {Open source, software metrics, empirical studies, software growth models.}
}

@ARTICLE{Paxton:2007,
  author = {Paxton, John},
  title = {Programming Competition Problems As a Basis for an Algorithms and Data Structures Course},
  crossref = {journal:ccsc:jcsc},
  volume = {23},
  number = {2},
  month = dec,
  year = {2007},
  pages = {27--32},
  abstract = {This paper describes an algorithms and data structures course that uses ACM programming competition problems as the basis for the lectures, homework and exams. The course, designed and developed as part of a Fulbright Award, was delivered to students at The University of Leipzig in Leipzig, Germany during Winter Semester 2006/2007. The course is described, assessed and evaluated for future usage.},
  owner = {magsilva},
  timestamp = {2014.08.30}
}

@INPROCEEDINGS{Paz:2012,
  author = {Paz, Mônica de Sá Dantas},
  title = {Gênero e o movimento software livre no Brasil: conhecendo alguns grupos de mulheres},
  crossref = {proceedings:coneco:2012},
  pages = {5:1--5:13},
  abstract = {Este trabalho visa apresentar parte da atual pesquisa de doutoramento da autora e pode ser considerado como a caracterização do objeto de estudo, bem como, a formulação de questões para esta pesquisa dentro da temática mulher e tecnologia. Para tanto, é realizada a observação da atuação e organização de mulheres da comunidade software livre no Brasil. Dessa forma, o objetivo desse trabalho é apresentar alguns dos diferentes tipos de atuação e temáticas trabalhadas por mulheres e por grupos de mulheres do movimento software livre que apresentam sensibilidade de gênero. A fundamentação teórica do trabalho se apoia em autoras que tratam da brecha digital de gênero e que indicam que esta deve ser resolvida não só com a inclusão digital de mulheres, mas também através do debate e da crítica acerca do processo de desenvolvimento e consumo de tecnologia, que normalmente são baseados em práticas excludentes.},
  keywords = {Gênero, Mulher, Tecnologia, Software Livre, Tecnofeminismo},
  owner = {magsilva},
  timestamp = {2014.04.01},
  url = {http://www.coneco.uff.br/ocs/index.php/1/conecorio/paper/viewFile/223/111}
}

@ARTICLE{PazosArias-etal:2006,
  author = {Pazos-Arias, José J. and López-Nores, Martín and García-Duque, Jorge and Gil-Solla, Alberto and Ramos-Cabrer, Manuel and Blanco-Fernández, Yolanda and Díaz-Redondo, Rebeca P. and Fernández-Vilas, Ana},
  title = {{ATLAS}: a framework to provide multiuser and distributed t-learning services over {MHP}},
  crossref = {journal:wiley:spe},
  volume = {36},
  number = {8},
  month = jul,
  year = {2006},
  pages = {845--869},
  doi = {10.1002/spe.v36:8},
  abstract = {The increasing need of the developed countries to carry out effective distance learning strategies has led to a great development of Internet-based learning technologies (e-learning). Despite its evident advantages, the expansion of e-learning has been limited by the difficulty in reaching important social sectors, and also by the absence of mechanisms to fight the feeling of isolation of the users, which often leads them to abandoning the distance learning activities. This paper tackles these problems by introducing ATLAS, a framework for the development and deployment of multiuser t-learning services (i.e. learning services over Interactive Digital TV). This framework is built around three major features: an architecture for the services that exploits the multimedia capabilities of the television, a communications infrastructure that promotes the establishment of virtual learning communities, and a development tool that allows services to be created with minimum programming knowledge. ATLAS has been designed by considering several features that make Interactive Digital TV quite different from the PC, advising against the direct translation of the models developed for the Internet. In particular, ATLAS adheres to the Multimedia Home Platform (MHP) standard, which is gaining worldwide acceptance as one of the technical solutions that will shape the future of Interactive Digital TV.},
  keywords = {formal specification, peer-to-peer technologies, synchronous interaction, t-learning, visual development}
}

@ARTICLE{Pea:1986,
  author = {Roy D. Pea},
  title = {Language-Independent Conceptual ``Bugs'' in Novice Programming},
  crossref = {journal:baywood:jecr},
  volume = {2},
  number = {1},
  year = {1986},
  pages = {25--36},
  doi = {10.2190/689T-1R2A-X4W4-29J2},
  abstract = {This article argues for the existence of persistent conceptual ``bugs'' in how novices program and understand programs. These bugs are not specific to a given programming language, but appear to be language-independent. Furthermore, such bugs occur for novices from primary school to college age. Three different classes of bugs -- parallelism, intentionality, and egocentrism -- are identified, and exemplified through student errors. It is suggested that these classes of conceptual bugs are rooted in a "superbug," the default strategy that there is a hidden mind somewhere in the programming language that has intelligent interpretive powers.}
}

@INPROCEEDINGS{Pedroni-Meyer:2010,
  author = {Pedroni, Michela and Meyer, Bertrand},
  title = {Object-Oriented Modeling of Object-Oriented Concepts},
  crossref = {proceedings:issep:2010},
  pages = {155--169},
  doi = {10.1007/978-3-642-11376-5_15},
  owner = {magsilva},
  timestamp = {2014.07.17}
}

@INPROCEEDINGS{Pedroni-etal:2008b,
  author = {Pedroni, Michela and Oriol, Manuel and Meyer, Bertrand and Albonico, Enrico and Angerer, Lukas},
  title = {Course management with {TrucStudio}},
  crossref = {proceedings:itcse:2008},
  pages = {260--264},
  doi = {10.1145/1384271.1384341},
  abstract = {Ever growing expectations from students, university management and other stakeholders make course preparation increasingly time-consuming. Setting up a course from scratch requires producing many supporting documents such as syllabi, schedules, and course web sites listing the concepts being taught. This can be a considerable effort, taking time away from tasks with a more immediate pedagogical value, such as answering student questions and refining the concepts themselves. The TrucStudio course development framework supports a systematic approach to these necessary but arduous tasks. TrucStudio is organized like a modern programming environment, but its elements of discourse, rather than software modules, are units of knowledge such as notions, Trucs and clusters. In addition to course development, applications of TrucStudio include checking sound coverage of topics and comparing courses on an objective basis. This presentation focuses on two novel features of TrucStudio: version management of knowledge units and course information; and generation of output documents in various formats from knowledge units and other material managed by TrucStudio.},
  keywords = {course design, curriculum design, knowledge modeling, output generation, versioning}
}

@INPROCEEDINGS{Pedroni-etal:2008a,
  author = {Pedroni, Michela and Oriol, Manuel and Meyer, Bertrand and Angerer, Lukas},
  title = {Automatic extraction of notions from course material},
  crossref = {proceedings:sigcse:2008},
  pages = {251--255},
  doi = {10.1145/1352135.1352225},
  abstract = {Formally defining the knowledge units taught in a course helps instructors ensure a sound coverage of topics and provides an objective basis for comparing the content of two courses. The main issue is to list and define the course concepts, down to basic knowledge units. Ontology learning techniques can help partially automate the process by extracting information from existing materials such as slides and textbooks. The TrucStudio course planning tool, discussed in this article, provides such support and relies on Text2Onto to extract concepts from course material. We conducted experiments on two different programming courses to assess the quality of the results.},
  keywords = {course design, curriculum design, knowledge modeling, ontology learning}
}

@INPROCEEDINGS{Pedroso-etal:2010,
  author = {Pedroso, Bruno and Jacobi, Ricardo and Pimenta, Marcelo},
  title = {TDD Effects: Are We Measuring the Right Things?},
  crossref = {proceedings:xp:2010},
  pages = {393--394},
  doi = {10.1007/978-3-642-13054-0_48},
  abstract = {Scientific studies about the impact of Test-Driven Development (TDD) start to appear since 2002, resulting in approximately 30 papers until now. In general the two main evaluated hypothesis are the ones stated by Kent Beck: that TDD produces code with less defects (external quality) and that it produces code that is simpler, less coupled and more cohesive (internal quality). Although studies may suggest good results in term of external quality, it does not conclude too much regarding internal attributes. Common difficulties, like controlling the experiments variables, are generally considered in the studies. But the few conclusions may be result of a bigger problem: we may have adopted wrong hypothesis or assumptions about the practice's benefits.},
  keywords = {test-driven development; agile software development; testing; design; programming},
  owner = {magsilva},
  timestamp = {2014.10.20}
}

@INPROCEEDINGS{Pellan-Cyril:2008,
  author = {Pellan, Benoît and Concolato, Cyril},
  title = {Adaptation of scalable multimedia documents},
  crossref = {proceedings:doceng:2008},
  pages = {32--41},
  doi = {10.1145/1410140.1410148},
  abstract = {Several scalable media codecs have been standardized in recent years to cope with heterogeneous usage conditions and to aim at always providing audio, video and image content in the best possible quality. Today, interactive multimedia presentations are becoming accessible on handheld terminals and face the same adaptation challenges as the media elements they present: quite diversified screen, memory and processing power capabilities. In this paper, we address the adaptation of multimedia documents by applying the concept of scalability to their presentation. The Scalable MSTI document model introduced in this paper has been designed with two main requirements in mind. First, the adaptation process must be simple to execute because it may be performed on limited terminals in broadcast scenarios. Second, the adaptation process must be simple to describe so that authored adaptation directives can be transported along with the document with a limited bandwidth overhead. The Scalable MSTI model achieves both objectives by specifying Spatial, Temporal and Interactive scalability axes on which incremental authoring can be performed to create progressive presentation layers. Our experiments are conducted on scalable multimedia documents designed for Digital Radio services on DMB channels using MPEG-4 BIFS and also for web services using XHTML, SVG, SMIL and Flash. A scalable image gallery is described throughout this article and illustrates the features offered by our document model in a rich multimedia example.},
  keywords = {document adaptation, document model, multimedia scalability},
  series = {DocEng '08},
  acmid = {1410148},
  address = {New York, NY, USA},
  isbn = {978-1-60558-081-4},
  numpages = {10},
  year = {2008}
}

@INPROCEEDINGS{PerezCervantes-etal:2012,
  author = {Perez-Cervantes, E. and Mena-Chalco, J. P. and Cesar, R. M.},
  title = {Towards a quantitative academic internationalization assessment of {Brazilian} research groups},
  crossref = {proceedings:escience:2012},
  pages = {1--8},
  doi = {10.1109/eScience.2012.6404456},
  abstract = {This paper introduces a new computational method to automatically estimate the International Publication Ratio (IPR) based on the analysis of bibliographical productions of Brazilian research groups, a task that would be too difficult (in many cases, impossible) to be performed manually. The proposed method explores the DOI number to identify the countries of every co-author who participated in each publication. Considering the bibliometric data from the Brazilian Lattes platform we show that is possible to make a good estimation of the IPR for research groups. Calculating the IPR is important in order to make a quantitative evaluation of the science progress and to establish a comparison between the academic institutions or knowledge areas. The experiments considering research groups, belonging to the 100 more collaborative researchers of five Brazilian major knowledge areas, confirm that the our proposal leads to an effective way to infer the IPR.},
  keywords = {bibliographic systems;publishing;research and development;Brazilian Lattes platform;Brazilian major knowledge areas;Brazilian research groups;DOI;IPR;academic institutions;bibliographical productions;international publication ratio;quantitative academic internationalization assessment;Biology;Collaboration;Earth;Intellectual property;International collaboration;Production;Web pages}
}

@INPROCEEDINGS{PerezMarin-etal:2006,
  author = {D. Perez-Marin and I. Pascual-Nieto and E. Alfonseca and P. Rodriguez},
  title = {Automatic identification of terms for the generation of students concept maps},
  crossref = {conference:micte:2006},
  pages = {2007-2011},
  abstract = {Willow, an adaptive multilingual free-text Computer-Assisted Assessment system, automatically evaluates students' free-text answers given a set of correct ones. This paper presents an extension of the system in order to generate the students' concept maps while they are being assessed. To that aim, a new module for the automatic identification of the terms of a particular knowledge field has been created. It identifies and keeps track of the terms that are being used in the students' answers, and calculates a confidence score of the student's knowledge about each term. An empyrical evaluation using the students' real answers show that it is robust enough to generate a good set of terms from a very small set of answers.},
  booktitle = {Current Developments in Technology-Assisted Education},
  year = {2006}
}

@INPROCEEDINGS{Perry-etal:2000,
  author = {Perry, Dewayne E. and Porter, Adam A. and Votta, Lawrence G.},
  title = {Empirical Studies of Software Engineering: A Roadmap},
  crossref = {proceedings:icse:2000},
  pages = {345--355},
  doi = {10.1145/336512.336586},
  abstract = {In this article we summarize the strengths and weaknesses of empirical research in software engineering. We argue that in order to improve the current situation we must create better studies and draw more credible interpretations from them. We finally present a roadmap for this improvement, which includes a general structure for software empirical studies and concrete steps for achieving these goals: designing better studies, collecting data more effectively, and involving others in our empirical enterprises.},
  keywords = {empirical studies, software engineering},
  owner = {magsilva},
  timestamp = {2014.02.23}
}

@INPROCEEDINGS{Petersen-etal:2011,
  author = {Petersen, Andrew and Craig, Michelle and Zingaro, Daniel},
  title = {Reviewing {CS1} exam question content},
  crossref = {proceedings:sigcse:2011},
  pages = {631--636},
  doi = {10.1145/1953163.1953340},
  abstract = {Many factors have been cited for poor performance of students in CS1. To investigate how assessment mechanisms may impact student performance, nine experienced CS1 instructors reviewed final examinations from a variety of North American institutions. The majority of the exams reviewed were composed predominantly of high-value, integrative code-writing questions, and the reviewers regularly underestimated the number of CS1 concepts required to answer these questions. An evaluation of the content and cognitive requirements of individual questions suggests that in order to succeed, students must internalize a large amount of CS1 content. This emphasizes the need for focused assessment techniques to provide students with the opportunity to demonstrate their knowledge.},
  keywords = {CS1, exams, novice programming}
}

@INPROCEEDINGS{Petersen-etal:2008,
  author = {Kai Petersen and Robert Feldt and Shahid Mujtaba and Michael Mattsson},
  title = {Systematic Mapping Studies in Software Engineering},
  crossref = {proceedeings:ease:2008},
  pages = {68--77},
  abstract = {A software engineering systematic map is a defined method to build a classification scheme and structure a software engineering field of interest. The analysis of results focuses on frequencies of publications for categories within the scheme. Thereby, the coverage of the research field can be determined. Different facets of the scheme can also be combined to answer more specific research questions. We describe how to conduct a systematic mapping study in software engineering and provide guidelines. We also compare systematic maps and systematic reviews to clarify how to chose between them. This comparison leads to a set of guidelines for systematic maps. We have defined a systematic mapping process and applied it to complete a systematic mapping study. Furthermore, we compare systematic maps with systematic reviews by systematically analyzing existing systematic reviews. We describe a process for software engineering systematic mapping studies and compare it to systematic reviews. Based on this, guidelines for conducting systematic maps are defined. Systematic maps and reviews are different in terms of goals, breadth, validity issues and implications. Thus, they should be used complementarily and require different methods (e.g., for analysis).},
  url = {http://www.bcs.org/content/conWebDoc/19543}
}

@ARTICLE{Petersen-Wohlin:2010,
  author = {Petersen, Kai and Wohlin, Claes},
  title = {The effect of moving from a plan-driven to an incremental software development approach with agile practices},
  crossref = {journal:springer:ese},
  volume = {15},
  number = {6},
  month = dec,
  year = {2010},
  pages = {654--693},
  doi = {10.1007/s10664-010-9136-6},
  abstract = {So far, only few in-depth studies focused on the direct comparison of process models in general, and between plan-driven and incremental/agile approaches in particular. That is, it is not made explicit what the effect is of moving from one model to another model. Furthermore, there is limited evidence on advantages and issues encountered in agile software development, this is specifically true in the context of large-scale development. The objective of the paper is to investigate how the perception of bottlenecks, unnecessary work, and rework (from hereon referred to as issues) changes when migrating from a plan-driven to an incremental software development approach with agile practices (flexible product backlog, face-to-face interaction, and frequent integration), and how commonly perceived these practices are across different systems and development roles. The context in which the objective should be achieved is large-scale development with a market-driven focus. The selection of the context was based on the observation in related work that mostly small software development projects were investigated and that the investigation was focused on one agile model (eXtreme programming). A case study was conducted at a development site of Ericsson AB, located in Sweden in the end of 2007. In total 33 interviews were conducted in order to investigate the perceived change when migrating from plan-driven to incremental and agile software development, the interviews being the primary source of evidence. For triangulation purposes measurements collected by Ericsson were considered, the measurements relating to unnecessary work (amount of discarded requirements) and rework (data on testing efficiency and maintenance effort). Triangulation in this context means that the measurements were used to confirm the perceived changes with an additional data source. In total 64 issues were identified, 24 being of general nature and the remaining 40 being local and therefore unique to individual's opinions or a specific system. The most common ones were documented and analyzed in detail. The commonality refers to how many persons in different roles and across the systems studied have mentioned the issues for each of the process models. The majority of the most common issues relates to plan-driven development. We also identified common issues remaining for agile after the migration, which were related to testing lead-time, test coverage, software release, and coordination overhead. Improvements were identified as many issues commonly raised for the plan-driven approach were not raised anymore for the incremental and agile approach. It is concluded that the recent introduction (start in 2005 with the study being conducted in the end of 2007) of incremental and agile practices brings added values in comparison to the plan-driven approach, which is evident from the absence of critical issues that are encountered in plan-driven development.},
  keywords = {Incremental; Agile; Plan-driven; Case study; Migration},
  owner = {magsilva},
  timestamp = {2014.09.24}
}

@INPROCEEDINGS{Petre:2013,
  author = {Petre, Marian},
  title = {{UML} in Practice},
  crossref = {proceedings:icse:2013},
  pages = {722--731},
  doi = {10.1109/ICSE.2013.6606618},
  abstract = {UML has been described by some as "the lingua franca" of software engineering. Evidence from industry does not necessarily support such endorsements. How exactly is UML being used in industry if it is? This paper presents a corpus of interviews with 50 professional software engineers in 50 companies and identifies 5 patterns of UML use.},
  owner = {magsilva},
  timestamp = {2014.09.13}
}

@ARTICLE{Petre:2011,
  author = {Petre, Marian},
  title = {Open source as distance ed},
  crossref = {journal:acm:inroads},
  volume = {2},
  number = {4},
  month = dec,
  year = {2011},
  pages = {21--22},
  doi = {10.1145/2038876.2038884}
}

@ARTICLE{Petre:2010,
  author = {Petre, Marian},
  title = {What works for you?: digital technologies for doctoral dialogues},
  crossref = {journal:acm:inroads},
  volume = {1},
  number = {4},
  month = dec,
  year = {2010},
  pages = {20--21},
  doi = {10.1145/1869746.1869754},
  acmid = {1869754},
  issue = {4},
  issue_date = {December 2010},
  lang = {en},
  numpages = {2}
}

@INPROCEEDINGS{Pfaff-etal:2009,
  author = {Pfaff, Ben and Romano, Anthony and Back, Godmar},
  title = {The {Pintos} instructional operating system kernel},
  crossref = {proceedings:sigcse:2009},
  pages = {453--457},
  doi = {10.1145/1508865.1509023},
  abstract = {Pintos is an instructional operating system, complete with documentation and ready-made, modular projects that introduce students to the principles of multi-programming, scheduling, virtual memory, and filesystems. By allowing students to run their work product on actual hardware, while simultaneously benefiting from debugging and dynamic analysis tools provided in simulated and emulated environments, Pintos increases student engagement. Unlike tailored versions of commercial or open source OS such as Linux, Pintos is designed from the ground up from an educational perspective. It has been used by multiple institutions for a number of years and is available for wider use.},
  keywords = {instructional kernel, instructional operating system, pintos}
}

@ARTICLE{Pfleeger:part2:1995,
  author = {Pfleeger, Shari Lawrence},
  title = {Experimental Design and Analysis in Software Engineering: Part 2: How to Set Up and Experiment},
  crossref = {journal:acm:sen},
  volume = {20},
  number = {1},
  month = jan,
  year = {1995},
  pages = {22--26},
  doi = {10.1145/225907.225910}
}

@ARTICLE{Pfleeger:part3:1995,
  author = {Pfleeger, Shari Lawrence},
  title = {Experimental Design and Analysis in Software Engineering: Types of Experimental Design},
  crossref = {journal:acm:sen},
  volume = {20},
  number = {2},
  month = apr,
  year = {1995},
  pages = {14--16},
  doi = {10.1145/224155.565630}
}

@ARTICLE{Pfleeger:part4:1995,
  author = {Pfleeger, Shari Lawrence},
  title = {Experimental design and analysis in software engineering, part 4: choosing an experimental design},
  crossref = {journal:acm:sen},
  volume = {20},
  number = {3},
  month = jul,
  year = {1995},
  pages = {13--15},
  doi = {10.1145/219308.219311}
}

@ARTICLE{Pfleeger:part5:1995,
  author = {Pfleeger, Shari Lawrence},
  title = {Experimental design and analysis in software engineering, part 5: analyzing the data},
  crossref = {journal:acm:sen},
  volume = {20},
  number = {5},
  month = dec,
  year = {1995},
  pages = {14--17},
  doi = {10.1145/217030.217032}
}

@ARTICLE{Pfleeger:part1:1994,
  author = {Pfleeger, Shari Lawrence},
  title = {Design and analysis in software engineering: the language of case studies and formal experiments},
  crossref = {journal:acm:sen},
  volume = {19},
  number = {4},
  month = oct,
  year = {1994},
  pages = {16--20},
  doi = {10.1145/190679.190680}
}

@ARTICLE{Pfleeger-Kitchenham:part1:2001,
  author = {Pfleeger, Shari Lawrence and Kitchenham, Barbara A.},
  title = {Principles of Survey Research: Part 1: Turning Lemons into Lemonade},
  crossref = {journal:acm:sen},
  volume = {26},
  number = {6},
  month = nov,
  year = {2001},
  pages = {16--18},
  doi = {10.1145/505532.505535}
}

@ARTICLE{PiatetskyShapiro-Fayyad:2012,
  author = {Piatetsky-Shapiro, Gregory and Fayyad, Usama},
  title = {An introduction to {SIGKDD} and a reflection on the term 'data mining'},
  crossref = {journal:acm:sigkdd},
  volume = {13},
  number = {2},
  month = may,
  year = {2012},
  pages = {102--103},
  doi = {10.1145/2207243.2207269}
}

@INPROCEEDINGS{PicininJr-etal:2012,
  author = {Picinin Jr., Delcino and Farines, Jean-Marie and Koliver, Cristian},
  title = {An approach to verify live {NCL} applications},
  crossref = {proceedings:webmedia:2012},
  pages = {223--232},
  doi = {10.1145/2382636.2382685},
  abstract = {This paper describes a NCL 3.0 hypermedia application development toolchain which supports the verification of temporal and spatial consistency of NCL applications. In this toolchain, the application is translated into a TSS code and temporal logic formulas are used for checking the desired properties. It is proposed an approach for incremental verification of live NCL applications. The paper illustrates the proposed approach with a case study of a NCL-based interactive TV application.},
  keywords = {NCL, incremental verification, interactive digital TV, model checking}
}

@ARTICLE{Pickard-etal:1998,
  author = {Lesley M. Pickard and Barbara A. Kitchenham and Peter W. Jones},
  title = {Combining empirical results in software engineering},
  crossref = {journal:elsevier:ist},
  volume = {40},
  number = {14},
  month = dec,
  year = {1998},
  pages = {811--821},
  doi = {10.1016/S0950-5849(98)00101-3},
  abstract = {In this paper we investigate the techniques used in medical research to combine results from independent empirical studies of a particular phenomenon: meta-analysis and vote-counting. We use an example to illustrate the benefits and limitations of each technique and to indicate the criteria that should be used to guide your choice of technique. Meta-analysis is appropriate for homogeneous studies when raw data or quantitative summary information, e.g. correlation coefficient, are available. It can also be used for heterogeneous studies where the cause of the heterogeneity is due to well-understood partitions in the subject population. In other circumstances, meta-analysis is usually invalid. Although intuitively appealing, vote-counting has a number of serious limitations and should usually be avoided. We suggest that combining study results is unlikely to solve all the problems encountered in empirical software engineering studies, but some of the infrastructure and controls used by medical researchers to improve the quality of their empirical studies would be useful in the field of software engineering.},
  keywords = {Empirical studies}
}

@ARTICLE{Pilskalns-etal:2007,
  author = {Pilskalns, Orest and Andrews, Anneliese and Knight, Andrew and Ghosh, Sudipto and France, Robert},
  title = {Testing UML designs},
  crossref = {journal:elsevier:ist},
  volume = {49},
  number = {8},
  month = aug,
  year = {2007},
  pages = {892--912},
  doi = {10.1016/j.infsof.2006.10.002},
  abstract = {Early detection and correction of faults in the software design phase can reduce total cost and time to market of a software product. In this paper we describe an approach for testing UML design models to uncover inconsistencies. Our approach uses behavioral views such as Sequence Diagrams to simulate state change in an aggregate model. The aggregate model is the artifact of merging information from behavioral and structural UML views. OCL pre-conditions, post-conditions and invariants are used as a test oracle.},
  keywords = {Class diagrams, OCL pre-condition and post-condition, Sequence diagrams, UML design models, UML views}
}

@INPROCEEDINGS{Pimentel-etal:2008,
  author = {Pimentel, Maria da Graça and Cattelan, Renan G. and Melo, Erick L. and Prado, Antonio F. and Teixeira, Cesar A. C.},
  title = {Ubiquitous end-user live editing of interactive multimedia programs},
  crossref = {proceedings:webmedia:2008},
  pages = {123--129},
  doi = {10.1145/1666091.1666113},
  abstract = {Watching TV is a practice many people enjoy and feel comfortable with. In the context of interactive TV, a program is defined by means of a structured multimedia document delivered to the viewer's digital TV equipment. While watching TV, a user can be offered the opportunity to edit the program with explicit or implicit edit operations. In this paper we exploit the concept of end-user live editing of interactive video programs by proposing an environment where such a live editing can take place. We contextualize our proposed approach in the context of the Brazilian Interactive Digital TV platform.},
  keywords = {NCL, authoring, document engineering, interactive video}
}

@INPROCEEDINGS{Pimentel,
  author = {Pimentel, Maria da Graça C. and Cattelan, Renan G. and Melo, Erick L. and Teixeira, Cesar A.C.},
  title = {End-user editing of interactive multimedia documents},
  crossref = {proceedings:doceng:2008},
  pages = {298--301},
  doi = {10.1145/1410140.1410204},
  abstract = {The problem of allowing user-centric control within multimedia presentations is important to document engineering when the presentations are specified as structured multimedia documents. In this paper we investigate the problem in the context of end-user "real-time" editing of interactive video programs.},
  keywords = {interactive multimedia, interactive video},
  series = {DocEng '08},
  acmid = {1410204},
  address = {New York, NY, USA},
  isbn = {978-1-60558-081-4},
  numpages = {4}
}

@ARTICLE{Pinto:2010,
  author = {Pinto, Yma},
  title = {A strategy, implementation and results of a flexible competency based curriculum},
  crossref = {journal:acm:inroads},
  volume = {1},
  number = {2},
  month = jun,
  year = {2010},
  pages = {54--61},
  doi = {10.1145/1805724.1805739},
  abstract = {Computer science education faces two major problems -- the continuous evolvement of the discipline itself and the issue of appropriate employment of graduating students. Instructors and educators need to periodically reinvent and restructure their curriculum to keep their learners abreast. The question is, therefore: How do we design a curriculum that is flexible, yet targeted towards the learner acquiring the necessary knowledge and skill set to make him/her "employable"? An effective approach is to structure the curriculum by defining the requisite competencies as the instructional goals and subsequently defining the conceptual requirements to achieve these goals. The results of the effectiveness of this strategy are analyzed in the paper.},
  keywords = {competency, conceptual mapping, curriculum design, data management systems}
}

@INPROCEEDINGS{Pleuss:2005,
  author = {Andreas Pleuss},
  title = {{MML}: a language for modeling interactive multimedia applications},
  crossref = {proceedings:multimedia:2005},
  pages = {1--9},
  doi = {10.1109/ISM.2005.80},
  abstract = {The development of highly interactive multimedia applications is still a challenging and complex task. In addition to the application logic multimedia applications typically provide a sophisticated user interface with integrated media objects. As a consequence, the development process involves different experts for software design, user interface design, and media design. There is still a lack of concepts for a structured development process to integrate these requirements. In this paper we introduce the Multimedia Modeling Language (MML), a visual modeling language supporting the design process in multimedia application development. It is part of a model-driven development approach for multimedia applications. The language is oriented on well-established software engineering concepts, in particular UML 2.0. It integrates the results of two different research lines: application-oriented multimedia modeling and model-based user interface development. In this paper we describe the concepts of the language and present the modeling process with MML. In particular we show how MML aims to integrate the different developer roles in multimedia application design.}
}

@ARTICLE{Polo-etal:2013,
  author = {Polo, M. and Reales, P. and Piattini, M. and Ebert, C.},
  title = {Test Automation},
  crossref = {journal:ieee:software},
  volume = {30},
  number = {1},
  month = jan # {--} # feb,
  year = {2013},
  pages = {84--89},
  doi = {10.1109/MS.2013.15},
  abstract = {Testing is a destructive task in which the goal is to find relevant defects as early as possible. It requires automation to reduce cost and ensure high regression, thus delivering determined quality. This article reviews technologies for test automation.}
}

@INPROCEEDINGS{Poncin-etal:2011,
  author = {Poncin, W. and Serebrenik, A. and Brand, M.},
  title = {Process Mining Software Repositories},
  crossref = {proceedings:csmr:2011},
  pages = {5--14},
  doi = {10.1109/CSMR.2011.5},
  abstract = {Software developers' activities are in general recorded in software repositories such as version control systems, bug trackers and mail archives. While abundant information is usually present in such repositories, successful information extraction is often challenged by the necessity to simultaneously analyze different repositories and to combine the information obtained. We propose to apply process mining techniques, originally developed for business process analysis, to address this challenge. However, in order for process mining to become applicable, different software repositories should be combined, and related software development events should be matched: e.g., mails sent about a file, modifications of the file and bug reports that can be traced back to it. The combination and matching of events has been implemented in FRASR (Framework for Analyzing Software Repositories), augmenting the process mining framework ProM. FRASR has been successfully applied in a series of case studies addressing such aspects of the development process as roles of different developers and the way bug reports are handled.},
  keywords = {Process mining, software repositories}
}

@INPROCEEDINGS{Poon-etal:2012,
  author = {Poon, Jonathan Y.H. and Sugiyama, Kazunari and Tan, Yee Fan and Kan, Min-Yen},
  title = {Instructor-centric source code plagiarism detection and plagiarism corpus},
  crossref = {proceedings:itcse:2012},
  pages = {122--127},
  doi = {10.1145/2325296.2325328},
  abstract = {Existing source code plagiarism systems focus on the problem of identifying plagiarism between pairs of submissions. The task of detection, while essential, is only a small part of managing plagiarism in an instructional setting. Holistic plagiarism detection and management requires coordination and sharing of assignment similarity -- elevating plagiarism detection from pairwise similarity to cluster-based similarity; from a single assignment to a sequence of assignments in the same course, and even among instructors of different courses. To address these shortcomings, we have developed Student Submissions Integrity Diagnosis (SSID), an open-source system that provides holistic plagiarism detection in an instructor-centric way. SSID's visuals show overviews of plagiarism clusters throughout all assignments in a course as well as highlighting most-similar submissions on any specific student. SSID supports plagiarism detection workflows; e.g., allowing student assistants to flag suspicious assignments for later review and confirmation by an instructor with proper authority. Evidence is automatically entered into SSID's logs and shared among instructors. We have additionally collected a source code plagiarism corpus, which we employ to identify and correct shortcomings of previous plagiarism detection engines and to optimize parameter tuning for SSID deployment. Since its deployment, SSID's workflow enhancements have made plagiarism detection in our faculty less tedious and more successful.},
  keywords = {corpus studies, plagiarism assessment, plagiarism detection, programming, similarity, user interface}
}

@INPROCEEDINGS{Port-Klappholz:2006,
  author = {Port, Daniel and Klappholz, David},
  title = {So You Want Brooks in Your Classroom?},
  crossref = {proceedings:icse:2006},
  pages = {655--660},
  doi = {10.1145/1134285.1134384},
  abstract = {Fred Brooks' seminal book, "The Mythical Man-Month" (MMM) is a firmly established classic in software engineering. Many of us feel compelled to use this work to help our students appreciate and put into practice the fundamental software engineering concepts contained between its covers. This often amounts to using "passive" lesson plans such as required readings followed by lectures and exams; these rarely fully satisfy our learning objectives. Rather, students often have mixed reactions to MMM with the result that it has little impact on their attitudes and practices, both in and out of the classroom. This paper outlines a more active approach to incorporating MMM into the classroom, one that we have refined over 6 years, at multiple universities and in both graduate and undergraduate courses. It includes learning objectives, a lesson plan, sample materials, an implementation discussion, and an evaluation of the approach's impact.},
  keywords = {Fred Brooks, mythical man month, software development process},
  owner = {magsilva},
  timestamp = {2014.09.24}
}

@INPROCEEDINGS{Porter,
  author = {Porter, Leo and Bailey Lee, Cynthia and Simon, Beth and Cutts, Quintin and Zingaro, Daniel},
  title = {Experience report: a multi-classroom report on the value of peer instruction},
  crossref = {proceedings:itcse:2011},
  pages = {138--142},
  doi = {10.1145/1999747.1999788},
  abstract = {Peer Instruction (PI) has a significant following in physics, biology, and chemistry education. Although many CS educators are aware of PI as a pedagogy, the adoption rate in CS is low. This paper reports on four instructors with varying motivations and course contexts and the value they found in adopting PI. Although there are many documented benefits of PI for students (e.g. increased learning), here we describe the experience of the instructor by looking in detail at one particular question they posed in class. Through discussion of the instructors' experiences in their classrooms, we support educators in consideration of whether they would like to have similar classroom experiences. Our primary findings show instructors appreciate that PI assists students in addressing course concepts at a deep level, assists instructors in dynamically adapting their class to address student misunderstandings and, overall, that PI encourages students to be engaged in conversations which help build technical communication skills. We propose that using PI to engage students in these activities can effectively support training in analysis and teamwork skills.},
  keywords = {active learning., classroom response, clickers, cs1, peer instruction, prs}
}

@INPROCEEDINGS{Porter-etal:2011,
  author = {Porter, Leo and Bailey Lee, Cynthia and Simon, Beth and Zingaro, Daniel},
  title = {Peer instruction: do students really learn from peer discussion in computing?},
  crossref = {proceedings:icer:2011},
  pages = {45--52},
  doi = {10.1145/2016911.2016923},
  abstract = {Peer Instruction (PI) is an instructional approach that engages students in constructing their own understanding of concepts. Students individually respond to a question, discuss with peers, and respond to the same question again. In general, the peer discussion portion of PI leads to an increase in the number of students answering a question correctly. But are these students really learning, or are they just "copying" the right answer from someone in their group? In an article in the journal Science, Smith et al. affirm that genetics students individually learn from discussion: having discussed a first question with their peers, students are better able to correctly, individually answer a second, conceptually-related question. We replicate their study, finding that students in upper-division computing courses (architecture and theory of computation) also learn from peer discussions, and explore differences between our results and those of Smith et al. Our work reveals that using raw percentage gains between paired questions may not fully illuminate the value of peer discussion. We define a new metric, Weighted Learning Gain, which better reflects the learning value of discussion. By applying this metric to both genetics and computing courses, we consistently find that 85-89% of "potential learners" benefit from peer discussion.},
  keywords = {active learning, classroom response, clickers, peer instruction, prs}
}

@ARTICLE{Porter-etal:2013,
  author = {Porter, Leo and Guzdial, Mark and McDowell, Charlie and Simon, Beth},
  title = {Success in introductory programming: what works?},
  crossref = {journal:acm:cacm},
  volume = {56},
  number = {8},
  month = aug,
  year = {2013},
  pages = {34--36},
  doi = {10.1145/2492007.2492020},
  abstract = {How pair programming, peer instruction, and media computation have improved computer science education.}
}

@INPROCEEDINGS{Posnett-etal:2013,
  author = {Posnett, Daryl and D'Souza, Raissa and Devanbu, Premkumar and Filkov, Vladimir},
  title = {Dual Ecological Measures of Focus in Software Development},
  crossref = {proceedings:icse:2013},
  pages = {452--461},
  doi = {10.1109/ICSE.2013.6606591},
  abstract = {Work practices vary among software developers. Some are highly focused on a few artifacts; others make wide-ranging contributions. Similarly, some artifacts are mostly authored, or owned, by one or few developers; others have very wide ownership. Focus and ownership are related but different phenomena, both with strong effect on software quality. Prior studies have mostly targeted ownership; the measures of ownership used have generally been based on either simple counts, information-theoretic views of ownership, or social-network views of contribution patterns. We argue for a more general conceptual view that unifies developer focus and artifact ownership. We analogize the developer-artifact contribution network to a predator-prey food web, and draw upon ideas from ecology to produce a novel, and conceptually unified view of measuring focus and ownership. These measures relate to both cross-entropy and Kullback-Liebler divergence, and simultaneously provide two normalized measures of focus from both the developer and artifact perspectives. We argue that these measures are theoretically well-founded, and yield novel predictive, conceptual, and actionable value in software projects. We find that more focused developers introduce fewer defects than defocused developers. In contrast, files that receive narrowly focused activity are more likely to contain defects than other files.},
  owner = {magsilva},
  timestamp = {2014.02.22}
}

@INPROCEEDINGS{Posnett-etal:2011,
  author = {Posnett, Daryl and Filkov, Vladimir and Devanbu, Premkumar},
  title = {Ecological Inference in Empirical Software Engineering},
  crossref = {proceedings:ase:2011},
  pages = {362--371},
  doi = {10.1109/ASE.2011.6100074},
  abstract = {Software systems are decomposed hierarchically, for example, into modules, packages and files. This hierarchical decomposition has a profound influence on evolvability, maintainability and work assignment. Hierarchical decomposition is thus clearly of central concern for empirical software engineering researchers; but it also poses a quandary. At what level do we study phenomena, such as quality, distribution, collaboration and productivity? At the level of files? packages? or modules? How does the level of study affect the truth, meaning, and relevance of the findings? In other fields it has been found that choosing the wrong level might lead to misleading or fallacious results. Choosing a proper level, for study, is thus vitally important for empirical software engineering research; but this issue hasn't thus far been explicitly investigated. We describe the related idea of ecological inference and ecological fallacy from sociology and epidemiology, and explore its relevance to empirical software engineering; we also present some case studies, using defect and process data from 18 open source projects to illustrate the risks of modeling at an aggregation level in the context of defect prediction, as well as in hypothesis testing.},
  owner = {magsilva},
  timestamp = {2014.02.22}
}

@ARTICLE{Prakash:2012,
  author = {Prakash, B. Aditya},
  title = {Propagation and immunization in large networks},
  crossref = {journal:acm:xrds},
  volume = {19},
  number = {1},
  month = sep,
  year = {2012},
  pages = {56--59},
  doi = {10.1145/2331042.2331059},
  abstract = {Many interesting research questions can be explored by studying processes running over networks.}
}

@ARTICLE{Prey-etal:2013,
  author = {Prey, Jane Chu and Timanovsky, Yan and Tims, Jodi L. and Zweben, Stuart},
  title = {{ACM} {NDC} Study: A New Annual Study of Non-doctoral-granting Departments in Computing},
  crossref = {journal:acm:inroads},
  volume = {4},
  number = {3},
  month = sep,
  year = {2013},
  pages = {4--14},
  doi = {10.1145/2513368},
  keywords = {Taulbee survey, computing education data and analysis, computing survey, computing trends}
}

@ARTICLE{Procaccia:2013,
  author = {Procaccia, Ariel D.},
  title = {Cake Cutting: Not Just Child's Play},
  crossref = {journal:acm:cacm},
  volume = {56},
  number = {7},
  month = jul,
  year = {2013},
  pages = {78--87},
  doi = {10.1145/2483852.2483870},
  abstract = {How to fairly allocate divisible resources, and why computer scientists should take notice.}
}

@ARTICLE{Procaccia:2011,
  author = {Procaccia, Ariel D.},
  title = {Computational social choice: the first four centuries},
  crossref = {journal:acm:xrds},
  volume = {18},
  number = {2},
  month = dec,
  year = {2011},
  pages = {31--34},
  doi = {10.1145/2043236.2043249},
  abstract = {Making the right decision.}
}

@INPROCEEDINGS{Proulx:2009,
  author = {Proulx, Viera K.},
  title = {Test-driven design for introductory {OO} programming},
  crossref = {proceedings:sigcse:2009},
  pages = {138--142},
  doi = {10.1145/1508865.1508919},
  abstract = {Test-Driven Design (TDD) has been shown to increase the productivity of programming teams and improve the quality of the code they produce. However, most of the introductory curricula provide no introduction to test design, no support for defining the tests, and do not insist on a comprehensive test coverage that is the driving force of the TDD. This paper presents a curriculum, pedagogy, and the software support for introductory object-oriented program design that uses the TDD consistently from the very beginning. The testing software does not increase the program complexity and is designed to work with the simplest programs. It has been used by hundreds of students at several colleges and is freely available on the web. Our experiences show that besides improving the quality of code students produce, TDD combined with the novice-appropriate test libraries reinforces students' understanding of the object oriented program design.},
  keywords = {cs1/2, design, pedagogy, programming education, test driven design}
}

@ARTICLE{Kristen-Lidar:2013,
  author = {Pudenz, Kristen L. and Lidar, Daniel A.},
  title = {Quantum adiabatic machine learning},
  crossref = {journal:springer:qip},
  volume = {12},
  number = {5},
  month = may,
  year = {2013},
  pages = {2027--2070},
  doi = {10.1007/s11128-012-0506-4},
  abstract = {We develop an approach to machine learning and anomaly detection via quantum adiabatic evolution. This approach consists of two quantum phases, with some amount of classical preprocessing to set up the quantum problems. In the training phase we identify an optimal set of weak classifiers, to form a single strong classifier. In the testing phase we adiabatically evolve one or more strong classifiers on a superposition of inputs in order to find certain anomalous elements in the classification space. Both the training and testing phases are executed via quantum adiabatic evolution. All quantum processing is strictly limited to two-qubit interactions so as to ensure physical feasibility. We apply and illustrate this approach in detail to the problem of software verification and validation, with a specific example of the learning phase applied to a problem of interest in flight control systems. Beyond this example, the algorithm can be used to attack a broad class of anomaly detection problems.},
  keywords = {Adiabatic quantum computation; Quantum algorithms; Software verification and validation; Anomaly detection}
}

@INPROCEEDINGS{Quadros-Martins:2005,
  author = {Teresinha Quadros and Joberto S. B. Martins},
  title = {A prática interdisciplinar em programas de educação a distância num cenário de novas tecnologias da informação e comunicação},
  crossref = {proceedings:sbie:2005},
  pages = {351--361},
  abstract = {O presente trabalho pretende pontuar os fatores conjunturais que conduzem à necessidade de realização de novas práticas pedagógicas que viabilizem a construção de um modelo de saber pautado na interdisciplinaridade. Em um segundo momento, é discutida a especificidade do ensino a distância no enfrentamento dessa problemática e o potencial das novas tecnologias para o exercício da interdisciplinaridade em projetos de Educação a Distância que utilizam o ensino pela Internet.},
  abstract-en = {This paper points, initially, to the main factors indicating the need for realizing new pedagogical practices that, in turn, promote the construction of new knowledge models based on interdisciplinary approaches. In sequence, the distance learning specific aspects are discussed with respect to the real issues of using new information and communications technologies in supporting interdisciplinary activities in projects using an internet-based approach.},
  address = {Juiz de Fora, MG, Brasil},
  lang = {pt},
  owner = {magsilva},
  timestamp = {2008.01.20},
  url = {http://br-ie.org/pub/index.php/sbie/article/view/419}
}

@INPROCEEDINGS{Queiros-Leal:2012:itcse,
  author = {Queirós, Ricardo Alexandre Peixoto and Leal, José Paulo},
  title = {{PETCHA}: a programming exercises teaching assistant},
  crossref = {proceedings:itcse:2012},
  pages = {192--197},
  doi = {10.1145/2325296.2325344},
  abstract = {This paper presents a tool called Petcha that acts as an automated Teaching Assistant in computer programming courses. The ultimate objective of Petcha is to increase the number of programming exercises effectively solved by students. Petcha meets this objective by helping both teachers to author programming exercises and students to solve them. It also coordinates a network of heterogeneous systems, integrating automatic program evaluators, learning management systems, learning object repositories and integrated programming environments. This paper presents the concept and the design of Petcha and sets this tool in a service oriented architecture for managing learning processes based on the automatic evaluation of programming exercises. The paper presents also a case study that validates the use of Petcha and of the proposed architecture.},
  keywords = {automatic evaluation, interoperability, learning objects, programming exercises, teaching assistant}
}

@ARTICLE{Queiros-Leal:2012:spe,
  author = {Queirós, Ricardo and Leal, José Paulo},
  title = {{crimsonHex}: a learning objects repository for programming exercises},
  crossref = {journal:wiley:spe},
  month = jun,
  year = {2012},
  pages = {1--25},
  doi = {10.1002/spe.2132},
  abstract = {A repository of learning objects is a system that stores electronic resources in a technology-mediated learning process. The need for this kind of repository is growing as more educators become eager to use digital educational contents and more of it becomes available. The sharing and use of these resources relies on the use of content and communication standards as a means to describe and exchange educational resources, commonly known as learning objects. This paper presents the design and implementation of a service-oriented repository of learning objects called crimsonHex. This repository supports new definitions of learning objects for specialized domains and we illustrate this feature with the definition of programming exercises as learning objects and its validation by the repository. The repository is also fully compliant with existing communication standards and we propose extensions by adding new functions, formalizing message interchange and providing a REST interface. To validate the interoperability features of the repository, we developed a repository plug-in for Moodle that is expected to be included in the next release of this popular learning management system.},
  keywords = {eLearning, repositories, SOA, standards, interoperability}
}

@INPROCEEDINGS{Queiroz-etal:2008,
  author = {Magno J. S. Queiroz and Jemerson F. Damásio and Patrícia D. L. Machado.},
  title = {Automating Acceptance Testing of Digital Television Applications with {EasyAccept DTV}},
  crossref = {proceedings:sast:2008},
  pages = {11--20},
  abstract = {Digital television technology has promoted the use of interactive applications that can be transmitted and executed together with television programs. Application execution may be concurrent and distributed. Moreover, applications usually run on embedded systems. Altogether these bring additional challenges to current development and validation processes. Particularly, test automation demand specialized techniques and tools that can cope with the support needed to define and execute test cases. Nevertheless, effective support for these activities is still unavailable. This paper presents a tool to assist the creation and execution of automated acceptance tests of Java digital television applications.},
  keywords = {acceptance testing, digital television, Java}
}

@ARTICLE{Raccoon-Dog:2014,
  author = {Raccoon and Dog},
  title = {The Best Laid Plans of Mice and Men},
  crossref = {journal:acm:sen},
  volume = {39},
  number = {2},
  month = mar,
  year = {2014},
  pages = {7--14},
  doi = {10.1145/2579281.2579286},
  owner = {magsilva},
  timestamp = {2014.09.13}
}

@ARTICLE{Rafique-Misi:2013,
  author = {Rafique, Y.a and Misí, V.B.b},
  title = {The effects of test-driven development on external quality and productivity: A meta-analysis},
  crossref = {journal:ieee:tse},
  volume = {39},
  number = {6},
  month = jun,
  year = {2013},
  pages = {835--856},
  doi = {10.1109/TSE.2012.28},
  abstract = {This paper provides a systematic meta-analysis of 27 studies that investigate the impact of Test-Driven Development (TDD) on external code quality and productivity. The results indicate that, in general, TDD has a small positive effect on quality but little to no discernible effect on productivity. However, subgroup analysis has found both the quality improvement and the productivity drop to be much larger in industrial studies in comparison with academic studies. A larger drop of productivity was found in studies where the difference in test effort between the TDD and the control group's process was significant. A larger improvement in quality was also found in the academic studies when the difference in test effort is substantial; however, no conclusion could be derived regarding the industrial studies due to the lack of data. Finally, the influence of developer experience and task size as moderator variables was investigated, and a statistically significant positive correlation was found between task size and the magnitude of the improvement in quality.},
  keywords = {agile software development; code quality; meta-analysis; programmer productivity; Test-driven development},
  owner = {magsilva},
  references = {Ambler, S., Test-driven development is the combination of test first development and refactoring (2006) Dr. Dobbs' Agile Newsletter, , June; Astels, D., (2003) Test Driven Development: A Practical Guide, , Prentice-Hall; Beck, K., (2003) Test-Driven Development: By Example, , Prentice-Hall; Andrea, J., Test-driven development: Driving new standards of beauty (2009) Beautiful Testing: Leading Professionals Reveal How They Improve Software, pp. 181-194. , O'Reilly Media; Erdogmus, H., Morisio, M., Torchiano, M., On the effectiveness of the test-first approach to programming (2005) IEEE Transactions on Software Engineering, 31 (3), pp. 226-237. , DOI 10.1109/TSE.2005.37; Lipsey, M., Wilson, D., (2001) Practical Meta-Analysis, , Sage Publications Inc; Kitchenham, B., Charters, S., Guidelines for performing systematic literature reviews in software engineering (2007) Keele Univ., Technical Report EBSE, 2007. , 001; Hannay, J., Dyba, T., Arisholm, E., Sjøberg, D., The effectiveness of pair programming: A meta-analysis (2009) Information and Software Technology, 51 (7), pp. 1110-1122; Huedo-Medina, T.B., Sanchez-Meca, J., Marin-Martinez, F., Botella, J., Assessing heterogeneity in meta-analysis: Q statistic or I2 Index? (2006) Psychological Methods, 11 (2), pp. 193-206. , DOI 10.1037/1082-989X.11.2.193; Melnik, G., Maurer, F., A cross-program investigation of students' perceptions of agile methods (2005) Proc. 27th Int'l Conf. Software Eng., pp. 481-488; Kollanus, S., Isomo Ttonen, V., Understanding TDD in academic environment: Experiences from two experiments (2008) Proc. Eighth Int'l Conf. Computing Education Research, pp. 25-31; Rendell, A., Effective and pragmatic test driven development (2008) Proc. AGILE, pp. 298-303; Langr, J., Evolution of test and code via test-first design (2001) Proc. ACM Conf. Object-Oriented Programming, Systems, Languages, and Applications, , http://www.objectmentor.com/resources/articles/tfd.pdf, , Oct; Steinberg, D.H., The effect of unit tests on entry points, coupling and cohesion in an introductory java programming course (2001) Proc. XP Universe, , Oct; Abrahamsson, P., Hanhineva, A., Jaalinoja, J., Improving business agility through technical solutions: A case study on test-driven development in mobile software development (2005) Proc. Int'l Working Conf. Int'l Federation for Information Processing, pp. 227-243; Sanchez, J., Williams, L., Maximilien, E., On the sustained use of a test-driven development practice at IBM (2007) Proc. AGILE, pp. 5-14; Madeyski, L., The impact of pair programming and test-driven development on package dependencies in object-oriented design - An experiment (2006) Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics), LNCS 4034, pp. 278-289. , Product-Focused Software Process Improvement - 7th International Conference, PROFES 2006, Proceedings; Siniaalto, M., The impact of test-driven development on design quality (2006) Information Technology for European Advancement, Technical Report, , D.5.2.10 v1.0; Janzen, D.S., Turner, C.S., Saiedian, H., Empirical software engineering in industry short courses (2007) Software Engineering Education Conference, Proceedings, pp. 89-96. , DOI 10.1109/CSEET.2007.20, 4271594, Proceedings - 20th Conference on Software Engineering Education and Training, CSEET 2007; Siniaalto, M., Abrahamsson, P., A comparative case study on the impact of test-driven development on program design and test coverage (2007) Proc. First Int'l Symp. Empirical Software Eng. and Measurement, pp. 275-284; Siniaalto, M., Abrahamsson, P., Does test-driven development improve the program code? Alarming results from a comparative case study (2007) Proc. Second IFIP TC 2 Central and East European Conf. Software Eng. Techniques, pp. 143-156; Janzen, D.S., Saiedian, H., Does test-driven development really improve software design quality? (2008) IEEE Software, 25 (2), pp. 77-84. , DOI 10.1109/MS.2008.34; Madeyski, L., The impact of test-first programming on branch coverage and mutation score indicator of unit tests: An experiment (2010) Information and Software Technology, 52 (2), pp. 169-184; Ynchausti, R., Integrating unit testing into a software development teams process (2001) Proc. Second Int'l Conf. Extreme Programming and Flexible Processes in Software Eng., pp. 79-83. , May; Damm, L.-O., Lundberg, L., Olsson, D., Introducing test automation and test-driven development: An experience report (2005) Electronic Notes in Theoretical Computer Science, 116 (SPEC.ISS.), pp. 3-15. , DOI 10.1016/j.entcs.2004.02.090, PII S1571066104052739; Madeyski, L., Szata, L., The impact of test-driven development on software development productivity-an empirical study (2007) Proc. 14th European Conf. Software Process Improvement, pp. 200-211; George, B., Williams, L., An initial investigation of test driven development in industry (2003) Proc. ACM Symp. Applied Computing, pp. 1135-1139; George, B., (2002) Analysis and Quantification of Test-driven Development Approach, , master's thesis, North Carolina State Univ; Maximilien, E., Williams, L., Assessing test-driven development at IBM (2003) Proc. 25th Int'l Conf. Software Eng., pp. 564-569; Williams, L., Maximilien, E., Vouk, M., Test-driven development as a defect-reduction practice (2003) Proc. IEEE Int'l Symp. Software Reliability Eng., pp. 34-45; Edwards, S.H., Using software testing to move students from trial-andor to reflectlon-in-action (2004) SIGCSE Bulletin (Association for Computing Machinery, Special Interest Group on Computer Science Education), 36 (1), pp. 26-30. , DOI 10.1145/1028174.971312, inroads - SIGCSE Bulletin - Proceedings of the Thirty-Fifth SIGCSE Technical Symposium on Computer Science Education; Edwards, S., Using test-driven development in the classroom: Providing students with automatic, concrete feedback on performance (2003) Proc. Int'l Conf. Education and Information Systems Technologies and Applications, 3, pp. 421-426; George, B., Williams, L., A structured experiment of test- driven development (2004) Information and Software Technology, 46 (5), pp. 337-342; Geras, A., (2004) The Effectiveness of Test-Driven Development, , master's thesis, Univ. of Calgary, Canada; Geras, A., Smith, M., Miller, J., A prototype empirical evaluation of test driven development (2004) Proceedings - International Software Metrics Symposium, pp. 405-416. , Proceedings - 10th International Symposium on Software Metrics, METRICS 2004; Hanhineva, A., (2004) Test-driven Development in Mobile Java Environment, , master's thesis, Univ. of Oulu, Finland; Bhat, T., Nagappan, N., Evaluating the efficacy of test-driven development: Industrial case studies (2006) ISCE'06 - Proceedings of the 5th ACM-IEEE International Symposium on Empirical Software Engineering, 2006, pp. 356-363. , DOI 10.1145/1159733.1159787, ISCE'06 - Proceedings of the 5th ACM-IEEE International Symposium on Empirical Software Engineering; Nagappan, N., Maximilien, E., Bhat, T., Williams, L., Realizing quality improvement through test driven development: Results and experiences of four industrial teams (2008) Empirical Software Eng., 13 (3), pp. 289-302; Canfora, G., Cimitile, A., Garcia, F., Piattini, M., Visaggio, C.A., Productivity of test driven development: A controlled experiment with professionals (2006) Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics), LNCS 4034, pp. 383-388. , Product-Focused Software Process Improvement - 7th International Conference, PROFES 2006, Proceedings; Canfora, G., Cimitile, A., Garcia, F., Piattini, M., Visaggio, C.A., Evaluating advantages of test driven development: A controlled experiment with professionals (2006) ISCE'06 - Proceedings of the 5th ACM-IEEE International Symposium on Empirical Software Engineering, 2006, pp. 364-371. , DOI 10.1145/1159733.1159788, ISCE'06 - Proceedings of the 5th ACM-IEEE International Symposium on Empirical Software Engineering; Janzen, D.S., Saiedian, H., On the influence of test-driven development on software design (2006) Software Engineering Education Conference, Proceedings, 2006, pp. 141-148. , DOI 10.1109/CSEET.2006.25, 1617340, Proceedings - 19th Conference on Software Engineering Education and Training, CSEE and T 2006; Janzen, D., (2006) An Empirical Evaluation of the Impact of Test-Driven Development on Software Quality, , PhD dissertation Univ. of Kansas; Shull, F., Melnik, G., Turhan, B., Layman, L., Diep, M., Erdogmus, H., What do we know about test-driven development? (2010) IEEE Software, 27 (6), pp. 16-19. , Nov./Dec; (2013), http://www.meta-analysis.com/Kampenes, V.B., Dyba, T., Hannay, J.E., Sjoberg, D.I.K., A systematic review of effect size in software engineering experiments (2007) Information and Software Technology, 49 (11-12), pp. 1073-1086. , DOI 10.1016/j.infsof.2007.02.015, PII S0950584907000195; Borenstein, M., Hedges, L.V., Higgins, J.P., Rothstein, H.R., A basic introduction to fixed-effect and random-effects models for meta-analysis (2010) Research Synthesis Methods, 1 (2), pp. 97-111; Gupta, A., Jalote, P., An experimental evaluation of the effectiveness and efficiency of the test driven development (2007) Proc. First Int'l Symp. Empirical Software Eng. and Measurement, pp. 285-294; Madeyski, L., Preliminary analysis of the effects of pair programming and test-driven development on the external code quality (2005) Proc. Conf. Software Eng.: Evolution and Emerging Technologies, pp. 113-123; Pancur, M., Ciglaric, M., Impact of test-driven development on productivity, code, and tests: A controlled experiment Information and Software Technology, 53 (2011), pp. 557-573; Desai, C., Janzen, D., Clements, J., Implications of integrating test-driven development into CS1/CS2 curricula (2009) ACM SIGCSE Bulletin, 41 (1), pp. 148-152; Flohr, T., Schneider, T., Lessons learned from an XP experiment with students: Test-first needs more teachings (2006) Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics), LNCS 4034, pp. 305-318. , Product-Focused Software Process Improvement - 7th International Conference, PROFES 2006, Proceedings; Huang, L., Holcombe, M., Empirical investigation towards the effectiveness of test first programming (2009) Information and Software Technology, 51 (1), pp. 182-194; Kaufmann, R., Janzen, D., Implications of test-driven development: A pilot study (2003) Proc. 18th Ann. ACM SIGPLAN Conf. Object-Oriented Programming, Systems, Languages, and Applications, pp. 298-299; Muller, M.M., Hagner, O., Experiment about test-first programming (2002) IEE Proceedings: Software, 149 (5), pp. 131-136. , DOI 10.1049/ip-sen:20020540; Pancur, M., Ciglari-c, M., Trampus, M., Vidmar, T., Towards empirical evaluation of test-driven development in a university environment (2003) Proc. Int'l Conf. Computer As A Tool, pp. 83-86; Rahman, S., Applying the TBC method in introductory programming courses (2007) Proc. 37th Ann. Frontiers in Education Conf.-Global Eng.: Knowledge Without Borders, Opportunities Without Passports, pp. T1E-T20; Vu, J., Frojd, N., Shenkel-Therolf, C., Janzen, D., Evaluating test-driven development in an industry-sponsored capstone project (2009) Proc. Sixth Int'l Conf. Information Technology: New Generations, pp. 229-234; Xu, S., Li, T., Evaluation of test-driven development: An academic case study (2009) Software Eng. Research, Management and Applications, pp. 229-238. , Springer; Yenduri, S., Perkins, L., Impact of using test-driven development: A case study (2006) Software Eng. Research and Practice, pp. 126-129; Zhang, L., Akifuji, S., Kawai, K., Morioka, T., Comparison between test driven development and waterfall development in a small-scale project (2006) Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics), LNCS 4044, pp. 211-212. , Extreme Programming and Agile Processes in Software Engineering - 7th International Conference, XP 2006, Proceedings; Dogsa, T., Bati, C.D., The effectiveness of test-driven development: An industrial case study Software Quality J., 19 (2011), pp. 643-661; Lui, K.M., Chan, K.C.C., Test Driven Development and Software Process Improvement in China (2004) Lecture Notes in Computer Science, 3092, pp. 219-222. , Extreme Programming and Agile Processes in Software Engineering 5th International Conference, XP 2004 Garmisch-Partenkirchen, Germany, June 6-10, 2004 Proceedings; Slyngstad, O., Li, J., Conradi, R., Ronneberg, H., Landre, E., Wesenberg, H., The impact of test driven development on the evolution of a reusable framework of components: An industrial case study (2008) Proc. Third Int'l Conf. Software Eng. Advances, pp. 214-223; Hodgetts, P., Refactoring the development process: Experiences with the incremental adoption of agile practices (2004) Proceedings of the Agile Development Conference, ADC 2004, pp. 106-113. , Proceedings of the Agile Development Conference, ADC 2004; Turhan, B., Layman, L., Diep, M., Erdogmus, H., Shull, F., How effective is test driven development? (2010) Making Software What Really Works, and Why We Believe It, pp. 207-219. , A. Oram and G. Wilson, eds. O'Reilly Media; Muller, M.M., Hofer, A., The effect of experience on the test-driven development process (2007) Empirical Software Engineering, 12 (6), pp. 593-615. , DOI 10.1007/s10664-007-9048-2; Höfer, A., Philipp, M., An empirical study on the TDD conformance of novice and expert pair programmers (2009) Agile Processes in Software Eng. and Extreme Programming, pp. 33-42. , Springer; Madeyski, L., Is external code quality correlated with programming experience or feelgood factor? (2006) Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics), LNCS 4044, pp. 65-74. , Extreme Programming and Agile Processes in Software Engineering - 7th International Conference, XP 2006, Proceedings; Siniaalto, M., Test driven development: Empirical body of evidence (2006) Information Technology for European Advancement, Eindhoven, the Netherlands, Agile Deliverable, D. , 2.7; Kollanus, S., Test-driven development-still a promising approach? (2010) Proc. Seventh Int'l Conf. Quality of Information and Comm. Technology, pp. 403-408. , Oct; Damm, L., Lundberg, L., Quality impact of introducing component-level test automation and test-driven development (2007) Software Process Improvement, 4764, pp. 187-199. , P. Abrahamsson, N. Baddoo, T. Margaria, and R. Messnarz, eds. Springer},
  timestamp = {2014.08.24}
}

@ARTICLE{Ralph-etal:2013,
  author = {Ralph, Paul and Johnson, Pontus and Jordan, Howell},
  title = {Report on the first {SEMAT} workshop on general theory of software engineering ({GTSE} 2012)},
  crossref = {journal:acm:sen},
  volume = {38},
  number = {2},
  month = mar,
  year = {2013},
  pages = {26--28},
  doi = {10.1145/2439976.2439999},
  abstract = {Many academic disciplines have general theories, which apply across the discipline and underlie much of its research. Examples include the Big Bang theory (cosmology), Maxwell's equations (electrodynamics), the theories of the cell and evolution (biology), the theory of supply and demand (economics), and the general theory of crime (criminology). Software engineering, in contrast, has no widely-accepted general theory. Consequently, the SEMAT Initiative organized a workshop to encourage development of general theory in software engineering. Workshop participants reached broad consensus that software engineering would benefit from better theoretical foundations, which require diverse theoretical approaches, consensus on a primary dependent variable and better instrumentation and descriptive research.},
  keywords = {general theory, software engineering, workshop report}
}

@INPROCEEDINGS{Ramampiaro-etal:2010,
  author = {Ramampiaro, H. and Cruzes, D. and Conradi, R. and Mendona, M.},
  title = {Supporting evidence-based Software Engineering with collaborative information retrieval},
  crossref = {proceedings:collaboratecom:2010},
  pages = {1--5},
  abstract = {The number of scientific publications is constantly increasing, and the results published on Empirical Software Engineering are growing even faster. Some software engineering publishers have began to collaborate with research groups to make available repositories of software engineering empirical data. However, these initiatives are limited due to issues related to the available search tools. As a result, many researchers in the area have adopted a semi-automated approach for performing searches for systematic reviews as a mean to extract empirical evidence from published material. This makes this activity labor intensive and error prone. In this paper, we argue that the use of techniques from information retrieval, as well as text mining, can support systematic reviews and improve the creation of repositories of SE empirical evidence.},
  keywords = {Collaborative Information Retrieval; Empirical Software Engineering; Systematic Review}
}

@INPROCEEDINGS{Ramnath-Dathan:2008,
  author = {Ramnath, Sarnath and Dathan, Brahma},
  title = {Evolving an integrated curriculum for object-oriented analysis and design},
  crossref = {proceedings:sigcse:2008},
  pages = {337--341},
  doi = {10.1145/1352135.1352252},
  abstract = {Object-Oriented Analysis and Design has established itself as an integral and critically vital part of the software development process. In this paper, we describe an integrated approach to teaching this subject so that it covers vital components of this vast field: analysis, object-oriented design principles such as the Liskov Substitution Principle, the design process, which shows how and where the rules are applied, modeling, design and architectural patterns, language features, and refactoring. The course has evolved over the past 10 years to one that revolves around three major case studies. This evolution has resulted in a course that covers all important aspects of OOAD in a manner that emphasizes their inter-relatedness and hence their relevance to overall design process. Feedback suggests that this approach has improved students' understanding of the OOAD concepts.},
  keywords = {case-studies, object-oriented analysis and design},
  timestamp = {2013-08-01}
}

@ARTICLE{Ramos:2009,
  author = {Marcus Vinícius Midena Ramos},
  title = {Ensino de linguagens formais e autômatos em cursos superiores de computação},
  crossref = {journal:puc-sp:rct},
  volume = {1},
  number = {1},
  year = {2009},
  pages = {22--34},
  abstract = {Formal languages and automata theory is a fundamental discipline in undergraduate computer programs, specially those with emphasis in the scientific education of the student, such as Computer Science and Computer Engineering . The discipline belongs to the kernel known as 'Foundations of Computing' (according to the Brazilian Computer Society [1]), and contains a body of knowledge which is normally considered, by its students, as highly abstract, complex and unrelated to their future professional activities, thus reducing their interest and motivation for its study. The objective of the present article is to reflect upon common practices adopted in the development of its contents, presenting some alternatives that may contribute for a better absorption of the discipline. It starts with an analysis of the most usual approaches adopted, and then presents proposals that might contribute for a higher degree of motivation of the students, as well as for a more efficient learning process.},
  keywords = {formal languages, automata, teaching, learning},
  url = {http://revistas.pucsp.br/index.php/ReCET/article/view/1033},
  abstract-orig = {Linguagens formais e autômatos é uma disciplina fundamental dos cursos superiores da área de computação, especialmente daqueles que apresentam ênfase na formação científica do aluno, como é o caso dos cursos de bacharelado em Ciência da Computação e de vários cursos de Engenharia de Computação. Ela faz parte do núcleo denominado 'Fundamentos da Computação' (conforme o currículo de referência da Sociedade Brasileira de Computação [1]), e contempla tópicos que, normalmente, são considerados, pelos alunos, excessivamente áridos, abstratos, complexos e desvinculados da sua futura realidade profissional, o que contribui para reduzir o interesse e a motivação pelo seu aprendizado. O objetivo do presente artigo é refletir sobre os conteúdos programáticos usualmente adotados para o ensino do seu conteúdo, oferecendo alternativas que possam contribuir para uma melhor assimilação dos tópicos da disciplina. Inicialmente é feita uma análise da enfoque comumente adotado para a construção e o desenvolvimento do referido conteúdo. A seguir, apresentam-se propostas que possam contribuir para uma maior motivação dos alunos para o estudo da disciplina, Assim como para uma aprendizagem mais eficiente.},
  keywords-orig = {linguagens formais, autômatos, ensino, aprendizagem},
  timestamp = {2014.04.07}
}

@ARTICLE{Rattan-etal:2013,
  author = {Dhavleesh Rattan and Rajesh Bhatia and Maninder Singh},
  title = {Software clone detection: A systematic review },
  crossref = {journal:elsevier:ist},
  volume = {55},
  number = {7},
  month = jul,
  year = {2013},
  pages = {1165--1199},
  doi = {10.1016/j.infsof.2013.01.008},
  abstract = {Context Reusing software by means of copy and paste is a frequent activity in software development. The duplicated code is known as a software clone and the activity is known as code cloning. Software clones may lead to bug propagation and serious maintenance problems. Objective This study reports an extensive systematic literature review of software clones in general and software clone detection in particular. Method We used the standard systematic literature review method based on a comprehensive set of 213 articles from a total of 2039 articles published in 11 leading journals and 37 premier conferences and workshops. Results Existing literature about software clones is classified broadly into different categories. The importance of semantic clone detection and model based clone detection led to different classifications. Empirical evaluation of clone detection tools/techniques is presented. Clone management, its benefits and cross cutting nature is reported. Number of studies pertaining to nine different types of clones is reported. Thirteen intermediate representations and 24 match detection techniques are reported. Conclusion We call for an increased awareness of the potential benefits of software clone management, and identify the need to develop semantic and model clone detection techniques. Recommendations are given for future research. },
  keywords = {Software clone, Clone detection, Systematic literature review, Semantic clones, Model based clone }
}

@ARTICLE{Reales-etal:2014,
  author = {Reales, Pedro and Polo, Macario and Fernandez-Aleman, Jose Luis and Toval, Ambrosio and Piattini, Mario},
  title = {Mutation Testing},
  crossref = {journal:ieee:software},
  volume = {31},
  number = {3},
  month = may,
  year = {2014},
  pages = {30--35},
  doi = {10.1109/MS.2014.68},
  abstract = {This article gives a short overview of the main characteristics of mutation tools. If a test suite finds all the artificial errors inserted in the mutants and finds no fault in the original, it's likely that the program under test is free of them. Obviously, the validity of this affirmation depends on the nature of the artificial fault: some of them are better than others. This testing technique has been used in the research arena to check the effectiveness of new proposed testing techniques, but it hasn't been used until recently in industry due to its costs and the lack of knowledge and industrial tools.},
  keywords = {debugging;mutation testing;software testing;test suite}
}

@INPROCEEDINGS{Reategui-Cazella:2005,
  author = {Eliseo Berni Reategui and Sílvio César Cazella},
  title = {Sistemas de Recomendação},
  crossref = {proceedings:enia:2005},
  pages = {306--348},
  abstract = {Recommending products, items of information to an Internet user is one of the biggest challenges of the virtual world. The appropriate recommendation of a book, for example, can make the difference between getting or loosing a customer. Because of this need to "conquer" the users, personalization has become a very important factor. This chapter gives an overview of recommender systems used in personalization tasks. It describes the most popular recommendation techniques, details the systems architecture and brings examples of their use both in the industry and academia. The chapter also discusses the privacy problem and presents future trends.},
  abstract-original = {Recomendar produtos, itens ou informações para um usuário da Internet apresenta-se como um dos maiores desafios no mundo virtual. A recomendação adequada de um livro, por exemplo, pode fazer a diferença entre conquistar o usuário ou perdê-lo. Devido a esta necessidade de conquista, a personalização tem se apresentado como um fator facilitador no momento de "cativar" o usuário . Este capítulo dá uma visão geral sobre os sistemas de recomendação utilizados nas tarefas de personalização. Descreve as técnicas e estratégias de recomendação mais util izadas, detalha a arquitetura dos sistemas e traz exemplos de utilização destes tanto no meio acadêmico quanto na indústria. Discute ainda o problema da privacidade e aborda tópicos que apontam para novas tendências na área.},
  lang = {pt},
  timestamp = {2013-09-20}
}

@ARTICLE{Rech-Ras:2011,
  author = {Rech, Jörg and Ras, Eric},
  title = {Aggregation of experiences in experience factories into software patterns},
  crossref = {journal:acm:sigsoft},
  volume = {36},
  number = {2},
  month = mar,
  pages = {1--4},
  doi = {10.1145/1943371.1943390},
  abstract = {In software engineering Experience Factories have been in use for a long time to store and manage experiences from software projects, typically in large organizations. Beside the preservation of quantitative or numerical experiences, e.g., in form of project effort data or data from empirical studies, many experience facto-ries also preserve subjective or qualitative experiences, e.g., in form of observations or lessons learned from the projects. A key issue of experience management is to aggregate these documented experiences into more valuable software patterns. In this article we report about the aggregation (i.e., formalization and generalization) of documented experiences in an experience factory to software patterns. Observations from real-world projects are formalized (i.e., structurally contextualized) into semi-formal experiences and, over time, several similar of these experiences are generalized (i.e., systematically de-contextualized) into software patterns.},
  keywords = {design patterns, experience factory, experience management}
}

@INPROCEEDINGS{Recker-etal:2007,
  author = {Recker, Mimi and Giersch, Sarah and Walker, Andrew and Halioris, Sam and Mao, Xin and Palmer, Bart},
  title = {A study of how online learning resource are used},
  crossref = {proceedings:jcdl:2007},
  pages = {179-180},
  doi = {10.1145/1255175.1255209},
  abstract = {This paper defines a model of teacher practice ("teaching as design"), and describes a professional development curriculum in which K-12 teachers design learning activities using resources and tools from education digital libraries. It then presents preliminary findings from an application of this model in which teachers' artifacts are analyzed to learn how online learning resources are used in situ. Initial results suggest that learning resources of a smaller granularity are more likely to be adapted or improvised upon in teacher-designed learning activities, which further supports teachers' becoming contributors of online resources and active participants in an education cyberinfrastructure.},
  keywords = {education digital libraries, online learning resources, use},
  series = {JCDL '07},
  acmid = {1255209},
  address = {New York, NY, USA},
  booktitle = {International Joint Conference on Digital Libraries},
  isbn = {978-1-59593-644-8},
  location = {Vancouver, BC, Canada},
  numpages = {2},
  publisher = {ACM, IEEE},
  year = {2007}
}

@INPROCEEDINGS{Redmond-etal:2013,
  author = {Redmond, Katie and Evans, Sarah and Sahami, Mehran},
  title = {A Large-scale Quantitative Study of Women in Computer Science at Stanford University},
  crossref = {proceedings:sigcse:2013},
  pages = {439--444},
  doi = {10.1145/2445196.2445326},
  abstract = {In this paper, we analyze gender dynamics in the undergraduate Computer Science program at Stanford University through a quantitative analysis of 7209 academic transcripts and 536 survey responses. We examine previously studied effects as well as present new findings. We also introduce Fisher's Noncentral Hypergeometric Distribution as a model for estimating the impact of program changes on underrepresented populations and explain why it is a more robust measure than changes in the percentage of minority participants.},
  keywords = {gender diversity, women in computer science}
}

@ARTICLE{Reed-Guzdial:2011,
  author = {Reed, Daniel and Guzdial, Mark},
  title = {From idea to product: how schools of education can help {CS}},
  crossref = {journal:cacm},
  volume = {54},
  number = {10},
  month = oct,
  year = {2011},
  pages = {8-9},
  doi = {10.1145/2001269.2001273},
  acmid = {2001273},
  address = {New York, NY, USA},
  issn = {0001-0782},
  issue = {10},
  issue_date = {October 2011},
  journal = {Communications of the ACM},
  numpages = {2},
  publisher = {ACM}
}

@INPROCEEDINGS{Reek:1989,
  author = {Reek, Kenneth A.},
  title = {The {TRY} system -- or -- how to avoid testing student programs},
  crossref = {proceedings:sigcse:1989},
  pages = {112--116},
  doi = {10.1145/65293.71198},
  abstract = {This paper discusses TRY, a software package for the UNIX1 operating system that tests student programs. The motivation for developing the system is established by describing problems associated with traditional grading methods and electronic program submission. The design and use of the TRY system is discussed, along with the advantages it provides to both the student and the instructor.}
}

@INCOLLECTION{Reid:2007,
  author = {Ian C. Reid},
  title = {Embedding Instructional Design with Learning Objects},
  chapter = {2},
  pages = {39-57},
  crossref = {Koohang-Harman:2007}
}

@INCOLLECTION{Reigeluth:1983:Chapter1,
  author = {Charles M Reigeluth},
  title = {Instrucional Design: What Is It And Why Is It?},
  chapter = {1},
  pages = {3--36},
  crossref = {Reigeluth:1983},
  timestamp = {2012.01.31}
}

@INCOLLECTION{Reigeluth-CarrChellman:2009:inbook,
  author = {Charles M. Reigeluth and Alison A. Carr-Chellman},
  title = {Understanding Instructional Theory},
  chapter = {1},
  pages = {3-26},
  crossref = {Reigeluth-CarrChellman:2009}
}

@INBOOK{Reigeluth-Keller:2009,
  chapter = {2},
  pages = {27-39},
  title = {Understanding Instruction},
  author = {Charles M. Reigeluth and John B. Keller},
  crossref = {Reigeluth-CarrChellman:2009}
}

@INBOOK{Reigeluth-Stein:1983,
  title = {The Elaboration Theory of Instruction},
  publisher = {Lawrence Erlbaum},
  year = {1983},
  author = {C. M. Reigeluth and F. S. Stein},
  address = {Hillsdale, NJ},
  booktitle = {Instructional Design Theories and Models: An Overview of their Current States},
  crossref = {Reigeluth:1983},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{ResendeCosta-etal:2006,
  author = {Resende Costa, Romualdo Monteiro and Moreno, Márcio Ferreira and Rodrigues, Rogério Ferreira and Soares, Luiz Fernando Gomes},
  title = {Live editing of hypermedia documents},
  crossref = {proceedings:doceng:2006},
  pages = {165--172},
  doi = {10.1145/1166160.1166202},
  abstract = {In some hypermedia system applications, like interactive digital TV applications, authoring and presentation of documents may have to be done concomitantly. This is the case of live programs, where not only some contents are not known a priori, but also some temporal and spatial relationships, among program media objects, may have to be established after the unknown content definition. This paper proposes a method for hypermedia document live editing, preserving not only the presentation semantics but also the logical structure semantics defined by an author. To validate this proposal, an implementation has been done for the Brazilian Digital TV System, which is also presented.},
  keywords = {NCL, SBTVD, declarative middleware, ginga, interactive digital TV}
}

@ARTICLE{Resnick-Varian:1997,
  author = {Resnick, Paul and Varian, Hal R.},
  title = {Recommender systems},
  crossref = {journal:acm:cacm},
  volume = {40},
  number = {3},
  month = mar,
  year = {1997},
  pages = {56--58},
  doi = {10.1145/245108.245121},
  timestamp = {2013-09-03}
}

@ARTICLE{ReyLopez-etal:2009,
  author = {Rey-López, Marta and Díaz-Redondo, Rebeca P. and Fernández-Vilas, Ana and Pazos-Arias, José J. and García-Duque, Jorge and Gil-Solla, Alberto and Ramos-Cabrer, Manuel},
  title = {An extension to the {ADL} {SCORM} standard to support adaptivity: The t-learning case-study},
  crossref = {journal:elsevier:csi},
  volume = {31},
  number = {2},
  month = feb,
  year = {2009},
  pages = {309--318},
  doi = {10.1016/j.csi.2008.02.006},
  keywords = {Adaptive Hypermedia, Distance learning, SCORM, t-learning}
}

@INPROCEEDINGS{Ricci-Schwabe:2006,
  author = {Ricci, Luiz A. and Schwabe, Daniel},
  title = {An authoring environment for model-driven web applications},
  crossref = {proceedings:webmedia:2006},
  pages = {11--19},
  doi = {10.1145/1186595.1186598},
  abstract = {This paper presents a development environment and framework that supports a Model Driven Development approach to Web Application Development. In this framework, the models are described through graphical diagrams that are processed by the environment. The main purpose is to ease the development of a web application using Visual Studio .Net 2005 as an IDE and Semantic Hypermedia Development Method (SHDM) as development method, allowing the application architect to focus on the application modeling. We also discuss how the meta-modeling facilities of VS .Net 2005 were extensively used.},
  keywords = {DSL, OOHDM, SHDM, model-driven development}
}

@INPROCEEDINGS{Riehle-etal:2014,
  author = {Dirk Riehle and Philipp Riemer and Carsten Kolassa and Michael Schmidt},
  title = {Paid vs. Volunteer Work in Open Source},
  crossref = {proceedings:hicss:2014},
  abstract = {Many open source projects have long become commercial. This paper shows just how much of open source software development is paid work and how much has remained volunteer work. Using a conservative approach, we find that about 50% of all open source software development has been paid work for many years now and that many small projects are fully paid for by companies. However, we also find that any non-trivial project balances the amount of paid developer with volunteer work, and we suggest that the ratio of volunteer to paid work can serve as an indicator for the health of open source projects and aid the management of the respective communities.},
  timestamp = {2013-08-23}
}

@INPROCEEDINGS{Ritchie:1993,
  author = {Ritchie, Dennis M.},
  title = {The development of the C language},
  crossref = {proceedings:hopl:1993},
  pages = {201--208},
  doi = {10.1145/154766.155580},
  abstract = {The C programming language was devised in the early 1970s as a system implementation language for the nascent Unix operating system. Derived from the typeless language BCPL, it evolved a type structure; created on a tiny machine as a tool to improve a meager programming environment, it has become one of the dominant languages of today. This paper studies its evolution.}
}

@INPROCEEDINGS{Ritchie-Thompson:1973,
  author = {Ritchie, Dennis M. and Thompson, Ken},
  title = {The {UNIX} time-sharing system},
  crossref = {proceedings:sosp:1973},
  pages = {27--27},
  doi = {10.1145/800009.808045},
  abstract = {UNIX is a general-purpose, multi-user, interactive operating system for the Digital Equipment Corporation PDP-1 1/40 and 11/45 computers. It offers a number of features seldom found even in larger operating systems, including 1. A hierarchical file system incorporating demountable volumes, 2. Compatible file, device, and inter-process I/O, 3. The ability to initiate asynchronous processes, 4. System command language selectable on a per-user basis, 5. Over 100 subsystems including a dozen languages. This paper discusses the usage and implementation of the file system and of the user command interface.}
}

@ARTICLE{Ritchie-Thompson:1974,
  author = {Ritchie, Dennis M. and Thompson, Ken},
  title = {The {UNIX} time-sharing system},
  crossref = {journal:acm:cacm},
  volume = {17},
  number = {7},
  month = jul,
  year = {1974},
  pages = {365--375},
  abstract = {UNIX is a general-purpose, multi-user, interactive operating system for the Digital Equipment Corporation PDP-11/40 and 11/45 computers. It offers a number of features seldom found even in larger operating systems, including: (1) a hierarchical file system incorporating demountable volumes; (2) compatible file, device, and inter-process I/O; (3) the ability to initiate asynchronous processes; (4) system command language selectable on a per-user basis; and (5) over 100 subsystems including a dozen languages. This paper discusses the nature and implementation of the file system and of the user command interface.},
  keywords = {PDP-11, command language, file system, operating system, time-sharing}
}

@INPROCEEDINGS{Robbes-Rothlisberger:2013,
  author = {Robbes, Romain and Röthlisberger, David},
  title = {Using developer interaction data to compare expertise metrics},
  crossref = {proceedings:msr:2013},
  pages = {297--300},
  doi = {10.1109/MSR.2013.6624041},
  abstract = {The expertise of a software developer is said to be a crucial factor for the development time required to complete a task. Even if this hypothesis is intuitive, research has not yet quantified the effect of developer expertise on development time. A related problem is that the design space for expertise metrics is large; out of the various automated expertise metrics proposed, we do not know which metric most reliably captures expertise. What prevents a proper evaluation of expertise metrics and their relation with development time is the lack of data on development tasks, such as their precise duration. Fortunately, this data is starting to become available in the form of growing developer interaction repositories. We show that applying MSR techniques to these developer interaction repositories gives us the necessary tools to perform such an evaluation.},
  tags = {expertise metric, recommendation system, interaction data},
  timestamp = {2013-08-01}
}

@ARTICLE{Roberts-etal:2006,
  author = {Jeffrey A. Roberts and Il-Horn Hann and Sandra A. Slaughter},
  title = {Understanding the Motivations, Participation, and Performance of Open Source Software Developers: A Longitudinal Study of the Apache Projects},
  crossref = {journal:informs:ms},
  volume = {52},
  number = {7},
  month = jul,
  year = {2006},
  pages = {984--999},
  doi = {10.1287/mnsc.1060.0554},
  owner = {magsilva},
  timestamp = {2014.05.29}
}

@ARTICLE{Robertson:2012,
  author = {Robertson, Judy},
  title = {Likert-type Scales, Statistical Methods, and Effect Sizes},
  crossref = {journal:acm:cacm},
  volume = {55},
  number = {5},
  month = may,
  year = {2012},
  pages = {6--7},
  doi = {10.1145/2160718.2160721}
}

@INPROCEEDINGS{Robles-GonzalesBarahona:2005,
  author = {Robles, Gregorio and Gonzalez-Barahona, Jesus M.},
  title = {Developer identification methods for integrated data from various sources},
  crossref = {proceedings:msr:2005},
  pages = {1--5},
  doi = {10.1145/1082983.1083162},
  abstract = {Studying a software project by mining data from a single repository has been a very active research field in software engineering during the last years. However, few efforts have been devoted to perform studies by integrating data from various repositories, with different kinds of information, which would, for instance, track the different activities of developers. One of the main problems of these multi-repository studies is the different identities that developers use when they interact with different tools in different contexts. This makes them appear as different entities when data is mined from different repositories (and in some cases, even from a single one). In this paper we propose an approach, based on the application of heuristics, to identify the many identities of developers in such cases, and a data structure for allowing both the anonymized distribution of information, and the tracking of identities for verification purposes. The methodology will be presented in general, and applied to the GNOME project as a case example. Privacy issues and partial merging with new data sources will also be considered and discussed.}
}

@INCOLLECTION{Robles:2007,
  author = {Marcel M. Robles},
  title = {Applying Instructional Design Theory When Using Learning Objects},
  chapter = {13},
  pages = {407-436},
  crossref = {Koohang-Harman:2007}
}

@ARTICLE{Rocha-etal:2012,
  author = {Rocha, Henrique and Couto, Cesar and Maffort, Cristiano and Garcia, Rogel and Simoes, Clarisse and Passos, Leonardo and Valente, Marco},
  title = {Mining the impact of evolution categories on object-oriented metrics},
  crossref = {journal:springer:sqj},
  year = {2012},
  pages = {1--21},
  doi = {10.1007/s11219-012-9186-7},
  abstract = {Despite the relevance of the software evolution phase, there are few characterization studies on recurrent evolution growth patterns and on their impact on software properties, such as coupling and cohesion. In this paper, we report a study designed to investigate whether the software evolution categories proposed by Lanza can be used to explain not only the growth of a system in terms of lines of code (LOC), but also in terms of metrics from the Chidamber and Kemerer (CK) object-oriented metrics suite. Our results show that high levels of recall (ranging on average from 52 to 72 %) are achieved when using LOC to predict the evolution of coupling and size. For cohesion, we have achieved smaller recall rates (< 27 % on average).}
}

@INPROCEEDINGS{Rodrigues-etal:2006,
  author = {Rodrigues, Rogério Ferreira and Moreno, Marcio Ferreira and Soares, Luiz Fernando Gomes},
  title = {Presentation control of declarative applications in interactive digital tv system receivers},
  crossref = {proceedings:webmedia:2006},
  pages = {184--192},
  doi = {10.1145/1186595.1186618},
  abstract = {This paper aims at discussing the issues on the design and implementation of hypermedia formatters (commonly known as presentation engines) for interactive digital TV systems. The paper describes how these issues have been handled in the development project of the Maestro presentation engine. Maestro is the core of the declarative support offered by the middleware Ginga, whose architecture has been proposed as the reference model for the middleware of the Brazilian Digital TV System.Este artigo tem por objetivo discutir as peculiaridades no projeto e na implementação de formatadores hipermídia (comumente chamados de m´quinas de apresentação) para sistemas de TV digital interativa. O artigo descreve como tais questões foram tratadas no projeto de desenvolvimento da m´quina de apresentação Maestro. Maestro é o núcleo do suporte declarativo oferecido pelo middleware Ginga, cuja arquitetura é proposta como modelo de referência para o middleware do Sistema Brasileiro de TV Digital.},
  keywords = {SBTVD, formatador hipermídia, ginga-NCL, máquina de apresentação, maestro, middleware declarativo, nested context language}
}

@INPROCEEDINGS{Rodrigues-Soares:2006,
  author = {Rogério Ferreira Rodrigues and Luiz Fernando Gomes Soares},
  title = {Produção de Conteúdo Declarativo para {TV} Digital},
  crossref = {proceedings:semish:2006},
  pages = {1--16},
  abstract = {O direito à geração e disseminação de informação (conteúdo digital), permitindo ao cidadão que sua produção cultural seja registrada e divulgada, conseqüentemente diminuindo as desigualdades regionais e sociais, pode estar mais perto com o advento da TV digital. Este artigo discute a produção de programas não-lineares, para o sistema de TV digital brasileiro, utilizando a linguagem NCL. Ao mesmo tempo que os conceitos da linguagem são introduzidos, uma metodologia para concepção dos programas é apresentada.},
  abstract-en = {The right to generate and disseminate information (digital content), allowing citizens to register and publish their cultural production, consequently reducing the regional and social disparities, can be closer with the digital TV introduction. This paper discusses the composition of non-linear programs, for the Brazilian digital TV system, using the NCL language. The paper explains the main concepts of the language and, at the same time, presents a methodology for NCL program authoring.}
}

@INPROCEEDINGS{rodriguez-etal:2007,
  author = {Rodríguez, Maria Luisa and Garrido, José Luis and Hurtado, María V. and Noguera, Manuel},
  title = {An approach to the model-based design of groupware multi-user interfaces},
  crossref = {proceedings:icw:2007},
  pages = {157--164},
  abstract = {The rapid development of technology allows organizations to operate on interactive environments in which work is organized and assigned to groups of people cooperating in order to reach their purposes. In groupware applications, the user interface is essential because it must support the process of sharing information and group work appropriately. Thereby, the user interface design requires the understanding of the tasks that a group must accomplish in the system and the different users' characteristics, as well as to address technological issues. The use of models, at different abstraction levels, should be taken into account in order to tackle the complexity while designing groupware interfaces. This paper proposes an approach to the model-based design of multi-user interfaces for groupware applications.},
  keywords = {group awareness, groupware applications, model-based development, multi-user interfaces},
  series = {CRIWG'07},
  acmid = {1784443},
  address = {Berlin, Heidelberg},
  booktitle = {Proceedings of the 13th international conference on Groupware: design implementation, and use},
  isbn = {978-3-540-74811-3},
  location = {Bariloche, Argentina},
  numpages = {8},
  publisher = {Springer-Verlag},
  url = {http://portal.acm.org/citation.cfm?id=1784428.1784443},
  year = {2007}
}

@ARTICLE{Roibas-Sala:2004,
  author = {Roibás, Anxo Cereijo and Sala, Riccardo},
  title = {Main {HCI} issues for the design of interfaces for ubiquitous interactive multimedia broadcast},
  crossref = {journal:acm:interactions},
  volume = {11},
  number = {2},
  month = mar,
  year = {2004},
  pages = {51--53},
  doi = {10.1145/971258.971274}
}

@ARTICLE{Rolfe:2012,
  author = {Rolfe, Timothy},
  title = {Dynamic programming of the towers},
  crossref = {journal:acm:inroads},
  volume = {3},
  number = {3},
  month = sep,
  year = {2012},
  pages = {40--45},
  doi = {10.1145/2339055.2339070},
  keywords = {Towers of Hanoi, dynamic programming, memoization, optimization}
}

@INPROCEEDINGS{RomeroFelizardo-etal:2013,
  author = {Romero Felizardo, K. and Souza, S.R.S. and Maldonado, J.C.},
  title = {The Use of Visual Text Mining to Support the Study Selection Activity in Systematic Literature Reviews: A Replication Study},
  crossref = {proceedings:reser:2013},
  pages = {91--100},
  doi = {10.1109/RESER.2013.9},
  abstract = {Background: Systematic literature reviews (SLRs)are an important component to identify and aggregate research evidence from different empirical studies. One of the activities associated with the SLR process is the selection of primary studies. The process used to select primary studies can be arduous, particularly when the researcher faces large volumes of primary studies. Aim: An experiment was conducted as a pilot test to compare the performance and effectiveness of graduate students in selecting primary studies manually and using visual text mining (VTM) techniques. This paper describes a replication study. Method: The same experimental design and materials of the previous experiment were used in the current experiment. Result: The previous experiment revealed that VTM techniques can speed up the selection of primary studies and increase the number of studies correctly included/excluded (effectiveness). The results of the replication confirmed that studies are more rapidly selected using VTM. We observed that the level of experience in researching has a direct relationship with the effectiveness. Conclusion: VTM techniques have proven valuable in the selection of primary studies.},
  keywords = {Controlled Experiment; Experimental Replication, Laboratory Package, Systematic Literature Review, Visual Text Mining}
}

@INPROCEEDINGS{Rosenbloom:2009,
  author = {Rosenbloom, Arnold},
  title = {Running a programming contest in an introductory computer science course},
  crossref = {proceedings:itcse:2009},
  pages = {347--347},
  doi = {10.1145/1562877.1562988},
  abstract = {We describe how to run a motivating in-class competition for an Introductory Computer Science course. We outline the students background, the problems, the motivation and the materials needed to run the competition.},
  keywords = {contests, course pedagogy}
}

@INBOOK{Rosmalen-Boticario:2005,
  chapter = {18},
  pages = {291-301},
  title = {Using Learning Design to Support Design and Runtime Adaptation},
  author = {Rosmalen, Peter van and Jesús Boticario},
  crossref = {Koper-Tattersall:2005}
}

@ARTICLE{Ross-Schoman:1977,
  author = {D. T. Ross and K. E. SchomanO},
  title = {Structured Analysis for Requirements Definition},
  crossref = {journal:ieee:tse},
  volume = {3},
  number = {1},
  month = jan,
  year = {1977},
  pages = {6--15},
  doi = {10.1109/TSE.1977.229899},
  abstract = {Requirements definition encompasses all aspects of system development prior to actual system design. We see the lack of an adequate approach to requirements definition as the source of major difficulties in current systems worlk This paper examines the needs for requirements definition, and proposes meeting those objectives with three interrelated subjects: context analysis, functional specification, and design constraints. Requirements definition replaces the widely used, but never well-defined, term ``requirements analysis''.},
  timestamp = {2008.07.30}
}

@ARTICLE{Rossling-etal:2008,
  author = {Rössling, Guido and Joy, Mike and Moreno, Andrés and Radenski, Atanas and Malmi, Lauri and Kerren, Andreas and Naps, Thomas and Ross, Rockford J. and Clancy, Michael and Korhonen, Ari and Oechsle, Rainer and Iturbide, J. Ángel Velázquez},
  title = {Enhancing learning management systems to better support computer science education},
  crossref = {journal:acm:inroads},
  volume = {40},
  number = {4},
  month = nov,
  year = {2008},
  pages = {142--166},
  doi = {10.1145/1473195.1473239},
  abstract = {Many individual instructors -- and, in some cases, entire universities -- are gravitating towards the use of comprehensive learning management systems (LMSs), such as Blackboard and Moodle, for managing courses and enhancing student learning. As useful as LMSs are, they are short on features that meet certain needs specific to computer science education. On the other hand, computer science educators have developed -- and continue to develop -- computer-based software tools that aid in management, teaching, and/or learning in computer science courses. In this report we provide an overview of current CS specific on-line learning resources and guidance on how one might best go about extending an LMS to include such tools and resources. We refer to an LMS that is extended specifically for computer science education as a Computing Augmented Learning Management System, or CALMS. We also discuss sound pedagogical practices and some practical and technical principles for building a CALMS. However, we do not go into details of creating a plug-in for some specific LMS. Further, the report does not favor one LMS over another as the foundation for a CALMS.},
  keywords = {CALMS, LMS, computer science education, computing augmented learning management system, learning management system}
}

@INPROCEEDINGS{Rostaher-Hericko:2002,
  author = {Rostaher, Matevz and Hericko, Marjan},
  title = {Tracking Test First Pair Programming -- An Experiment},
  crossref = {proceedings:xp:2002},
  pages = {174--184},
  doi = {10.1007/3-540-45672-4_17},
  abstract = {The authors ran an experiment where a group of professional programmers working in pairs and a control group programming alone implemented a small system from predefined requirements. Most programmers spent between 50% and 60% of time on testing; only the most inexperienced spent less. Programmers reported more problems with refactoring than testing. The rhythm of switching the driver and navigator role is essential for test-first pair programming. The experiment showed that partners switched roles 21 times per day on average. The comparison of the control group of individuals and the group programming in pairs showed that both groups spent almost the same amount of time to complete the tasks. The result of this comparison is by applying a t-test not statistically significant. We believe that more detailed research apart of evaluating test-first programming is needed to compare solo vs. pair programming in the investigated group.},
  owner = {magsilva},
  timestamp = {2014.10.21}
}

@INPROCEEDINGS{Royce:1970,
  author = {Royce, Winston W.},
  title = {Managing the Development of Large Software Systems: Concepts and Techniques},
  crossref = {proceedings:wescon:1970},
  pages = {1--9},
  owner = {magsilva},
  timestamp = {2014.10.22}
}

@INPROCEEDINGS{Royce:1987,
  author = {Royce, Winston W.},
  title = {Managing the Development of Large Software Systems: Concepts and Techniques},
  crossref = {proceedings:icse:1987},
  pages = {328--338},
  owner = {magsilva},
  reprint-of = {Royce:1970},
  timestamp = {2014.10.21}
}

@ARTICLE{Rubinfeld:2012,
  author = {Rubinfeld, Ronitt},
  title = {Taming big probability distributions},
  crossref = {journal:acm:xrds},
  volume = {19},
  number = {1},
  month = sep,
  year = {2012},
  pages = {24--28},
  doi = {10.1145/2331042.2331052},
  abstract = {New algorithms for estimating parameters of distributions over big domains need significantly fewer samples.}
}

@INPROCEEDINGS{RubioSanchez-etal:2008,
  author = {Rubio-Sánchez, Manuel and Urquiza-Fuentes, Jaime and Pareja-Flores, Cristóbal},
  title = {A gentle introduction to mutual recursion},
  crossref = {proceedings:itcse:2008},
  pages = {235--239},
  doi = {10.1145/1384271.1384334},
  abstract = {Recursion is an important topic in computer science curricula. It is related to the acquisition of competences regarding problem decomposition, functional abstraction and the concept of induction. In comparison with direct recursion, mutual recursion is considered to be more complex. Consequently, it is generally addressed superficially in CS1/2 programming courses and textbooks. We show that, when a problem is approached appropriately, not only can mutual recursion be a powerful tool, but it can also be easy to understand and fun. This paper provides several intuitive and attractive algorithms that rely on mutual recursion, and which have been designed to help strengthen students' ability to decompose problems and apply induction. Furthermore, we show that a solution based on mutual recursion may be easier to design, prove and comprehend than other solutions based on direct recursion. We have evaluated the use of these algorithms while teaching recursion concepts. Results suggest that mutual recursion, in comparison with other types of recursion, is not as hard as it seems when: (1) determining the result of a (mathematical) function call, and, most importantly, (2) designing algorithms for solving simple problems.},
  keywords = {combinatorics, counting problems, fibonacci numbers, mutual recursion, recursion problems}
}

@ARTICLE{Ruparelia:2010,
  author = {Ruparelia, Nayan B.},
  title = {Software development lifecycle models},
  crossref = {journal:acm:sen},
  volume = {35},
  number = {3},
  month = may,
  year = {2010},
  pages = {8--13},
  doi = {10.1145/1764810.1764814},
  abstract = {This history column article provides a tour of the main software development life cycle (SDLC) models. (A lifecycle covers all the stages of software from its inception with requirements definition through to fielding and maintenance.) System development lifecycle models have drawn heavily on software and so the two terms can be used interchangeably in terms of SDLC, especially since software development in this respect encompasses software systems development. Because the merits of selecting and using an SDLC vary according to the environment in which software is developed as well as its application, I discuss three broad categories for consideration when analyzing the relative merits of SDLC models. I consider the waterfall model before the other models because it has had a profound effect on software development, and has additionally influenced many SDLC models prevalent today. Thereafter, I consider some of the mainstream models and finish with a discussion of what the future could hold for SDLC models.},
  keywords = {B-model, RAD, SDLC, SEN history column, Vmodel, incremental, spiral, unified, waterfall, wheel-and-spoke}
}

@INPROCEEDINGS{Ryoo-etal:2008,
  author = {Ryoo, Jungwoo and Fonseca, Frederico and Janzen, David S.},
  title = {Teaching Object-Oriented Software Engineering through Problem-Based Learning in the Context of Game Design},
  crossref = {proceedings:cseet:2008},
  pages = {137--144},
  doi = {10.1109/CSEET.2008.26},
  abstract = {Although Object Orientation is emphasized in software engineering education, few have attempted to alleviate the initial learning curve associated with an inexperienced audience in non-computer science disciplines. The authors propose a Problem-Based Learning curriculum centered on game development to deliver basic Object-Oriented programming concepts in an interactive and engaging manner. Class activities occur within the context of the Object-Oriented Rational Unified Process. One of the most significant contributions of this paper lies in the design of class modules containing tasks intended to educate students onObject-Oriented Software Engineering in an incremental and self-actuated way.},
  keywords = {Object-Oriented Software Engineering, Problem-Based Learning, Game Design}
}

@ARTICLE{Sadikov-Medina:2012,
  author = {Sadikov, Eldar and Medina, Montse},
  title = {Want a tenure?: try a startup},
  crossref = {journal:acm:xrds},
  volume = {18},
  number = {4},
  month = jun,
  pages = {16--19},
  doi = {10.1145/2173637.2173646},
  abstract = {Why running a startup is a lot like building a research lab.}
}

@ARTICLE{Sadler:1989,
  author = {Sadler, D. Royce},
  title = {Formative assessment and the design of instructional systems},
  crossref = {journal:springer:is},
  volume = {18},
  number = {2},
  month = jun,
  year = {1989},
  pages = {119-144},
  doi = {10.1007/BF00117714},
  abstract = {The theory of formative assessment outlined in this article is relevant to a broad spectrum of learning outcomes in a wide variety of subjects. Specifically, it applies wherever multiple criteria are used in making judgments about the quality of student responses. The theory has less relevance for outcomes in which student responses may be assessed simply as correct or incorrect. Feedback is defined in a particular way to highlight its function in formative assessment. This definition differs in several significant respects from that traditionally found in educational research. Three conditions for effective feedback are then identified and their implications discussed. A key premise is that for students to be able to improve, they must develop the capacity to monitor the quality of their own work during actual production. This in turn requires that students possess an appreciation of what high quality work is, that they have the evaluative skill necessary for them to compare with some objectivity the quality of what they are producing in relation to the higher standard, and that they develop a store of tactics or moves which can be drawn upon to modify their own work. It is argued that these skills can be developed by providing direct authentic evaluative experience for students. Instructional systems which do not make explicit provision for the acquisition of evaluative expertise are deficient, because they set up artificial but potentially removable performance ceilings for students.},
  owner = {magsilva},
  timestamp = {2014.08.13}
}

@INPROCEEDINGS{Sajeev-Datta:2013,
  author = {Sajeev, A. S. M. and Datta, Subhajit},
  title = {Introducing Programmers to Pair Programming: A Controlled Experiment},
  crossref = {proceedings:xp:2013},
  pages = {31--45},
  doi = {10.1007/978-3-642-38314-4_3},
  abstract = {Pair programming is a key characteristic of the Extreme Programming (XP) method. Through a controlled experiment we investigate pair programming behaviour of programmers without prior experience in XP. The factors investigated are: (a) characteristics of pair programming that are less favored (b) perceptions of team effectiveness and how they relate to product quality, and (c) whether it is better to train a pair by giving routine tasks first or by giving complex tasks first. Our results show that: (a) the least liked aspects of pair programming were having to share the screen, keyboard and mouse, and having to switch between the roles of driver and navigator (b) programmers solved complex problems more effectively in pairs compared to routine problems, however, perceptions of team effectiveness was higher when solving routine problems than when solving complex problems and (c) programmers who started pair programming with routine tasks and moved on to complex tasks were more effective than those who started with complex ones and moved on to routine ones. We discuss how these results will assist the industry in inducting programmers without prior pair-programming experience into XP process environments.},
  keywords = {pair programming; empirical software engineering; agile methods; extreme programming; software process; controlled experiment},
  owner = {magsilva},
  timestamp = {2014.10.20}
}

@INPROCEEDINGS{SoaresNeto-etal:2010:WebMedia,
  author = {Carlos de Salles Soares Neto and Luiz Fernando Gomes Soares and Clarisse Sieckenius de Souza},
  title = {{TAL} -- Linguagem para Autoria de Templates de Documentos Hipermídia},
  crossref = {proceedings:webmedia:2010},
  pages = {147--154},
  abstract = {Este artigo apresenta TAL (Template Authoring Language), uma linguagem para autoria de templates de documentos hipermídia. Templates descrevem famílias de documentos estruturalmente ou semanticamente similares entre si. TAL permite que se descreva um template de forma independente da linguagem hipermídia alvo. O artigo também apresenta um processador TAL que é capaz de gerar documentos hipermídia completos tendo como entrada a especificação do template em TAL e um arquivo de preenchimento com aquilo que torna o documento único em sua família.},
  abstract-en = {This paper presents TAL (Template Authoring Language), an authoring language for hypermedia document templates. Templates describe document families that are structurally or semantically similar among them. TAL enables the description of a template independently of the target hypermedia authoring language. The paper also presents a TAL processor that generates complete hypermedia documents taking as input the template specification in TAL and a data file with the information that makes that document unique in its family.},
  keywords-en = {TAL, Nested Context Language, Archetype oriented programming}
}

@ARTICLE{Salvaneschi-etal:2012,
  author = {Guido Salvaneschi and Carlo Ghezzi and Matteo Pradella},
  title = {Context-oriented programming: A software engineering perspective},
  crossref = {journal:elsevier:jss},
  volume = {85},
  number = {8},
  month = aug,
  year = {2012},
  pages = {1801--1817},
  doi = {10.1016/j.jss.2012.03.024},
  abstract = {The implementation of context-aware systems can be supported through the adoption of techniques at the architectural level such as middlewares or component-oriented architectures. It can also be supported by suitable constructs at the programming language level. Context-oriented programming (COP) is emerging as a novel paradigm for the implementation of this kind of software, in particular in the field of mobile and ubiquitous computing. The COP paradigm tackles the issue of developing context-aware systems at the language-level, introducing ad hoc language abstractions to manage adaptations modularization and their dynamic activation. In this paper we review the state of the art in the field of COP in the perspective of the benefits that this technique can provide to software engineers in the design and implementation of context-aware applications.},
  keywords = {Context-oriented programming; Context; Context-awareness}
}

@ARTICLE{Sampson-Zervas:2011,
  author = {Demetrios G. Sampson and Paagiotis Zervas},
  title = {A Workflow for Learning Objects Lifecycle and Reuse: Towards Evaluating Cost Effective Reuse},
  crossref = {journal:ifets:ets},
  volume = {14},
  number = {4},
  year = {2011},
  pages = {64--76},
  abstract = {Over the last decade Learning Objects (LOs) have gained a lot of attention as a common format for developing and sharing digital educational content in the field of technology-enhanced learning. The main advantage of LOs is considered to be their potential for component-based reuse in different learning settings supporting different learning activities. However, despite the importance of the concept of reuse and its potential benefits in digital educational content production and deployment, there are only sporadic efforts to study issues related to LOs reuse that would allow interested parties (such as people, organizations and initiatives) to assess the conditions for and eventually implement systematic LOs reuse within the context of learning activities design and development. This is a drawback in adopting the LOs paradigm towards reducing costs and effort. In this paper, we study existing efforts for the definition of the different steps involved during the LOs lifecycle, we identify the aspects of LOs reuse within the context of learning activities design and development, we propose a thorough workflow for LOs lifecycle that can support LOs reuse and enable us to define a set of metrics for cost effective LOs reuse, and discuss the cost effectiveness conditions in various use cases.},
  keywords = {Learning object, learning objects lifecycle, reuse workflow, cost metrics, cost effectiveness}
}

@ARTICLE{Sanders:2002,
  author = {Sanders, Dean},
  title = {Extreme Programming: The Student View},
  crossref = {journal:routledge:cse},
  volume = {12},
  number = {3},
  month = aug,
  year = {2002},
  pages = {235--250},
  doi = {10.1076/csed.12.3.235.8615},
  abstract = {Students in two offerings of a software engineering course were asked to write opinion papers regarding the use of Extreme Programming (XP) in an undergraduate computer science curriculum. The majority opposed the use of XP as the preferred life-cycle model for the project in that course, but they did support introducing some of the practices of XP in selected courses. They felt that unit testing and coding standards should become part of the introductory programming courses, but other practices should be deferred to specific project-oriented courses, or not introduced at all. Two pilot studies provided additional insights that are consistent with the students' opinions. }
}

@INPROCEEDINGS{Sanders-etal:2008:sigcse,
  author = {Sanders, Kate and Boustedt, Jonas and Eckerdal, Anna and McCartney, Robert and Moström, Jan Erik and Thomas, Lynda and Zander, Carol},
  title = {Student Understanding of Object-oriented Programming As Expressed in Concept Maps},
  crossref = {proceedings:sigcse:2008},
  pages = {332--336},
  doi = {10.1145/1352135.1352251},
  abstract = {In this paper, we present the results of an experiment in which we sought to elicit students' understanding of object-oriented (OO) concepts using concept maps. Our analysis confirmed earlier research indicating that students do not have a firm grasp on the distinction between "class" and "instance." Unlike earlier research, we found that our students generally connect classes with both data and behavior. Students rarely included any mention of the hardware/software context of programs, their users, or their real-world domains. Students do mention inheritance, but not encapsulation or abstraction. And the picture they draw of OO is a static one: we found nothing that could be construed as referring to interaction among objects in a program. We then discuss the implications for teaching introductory OO programming.},
  keywords = {concept maps, cs1, empirical research, object-oriented},
  owner = {magsilva},
  timestamp = {2014.07.17}
}

@INPROCEEDINGS{Sanders-etal:2008:icer,
  author = {Sanders, Kate and Richards, Brad and Moström, Jan Erik and Almstrum, Vicki and Edwards, Stephen and Fincher, Sally and Gunion, Kat and Hall, Mark and Hanks, Brian and Lonergan, Stephen and McCartney, Robert and Morrison, Briana and Spacco, Jaime and Thomas, Lynda},
  title = {{DCER}: sharing empirical computer science education data},
  crossref = {proceedings:icer:2008},
  pages = {137--148},
  doi = {10.1145/1404520.1404534},
  abstract = {Data sharing is common, and sometimes even required, in other disciplines. Creating a mechanism for data sharing in computer science education research will benefit both individual researchers and the community. While it is easy to say that data sharing is desirable, it is much more difficult to make it a practical reality. This paper reports on an examination of the issues involved by researchers who gathered at a one-day NSF-sponsored workshop held in connection with SIGCSE 2008. We outline the advantages and challenges of developing a repository, show how the challenges have been addressed by repositories in other fields, describe a possible prototype system for empirical computer science education data, and discuss how to move the project forward.},
  keywords = {computer science education, data repositories, data sharing, empirical data, information science education, research, research methods}
}

@INPROCEEDINGS{Sanders-Thomas:2007,
  author = {Sanders, Kate and Thomas, Lynda},
  title = {Checklists for grading object-oriented {CS1} programs: concepts and misconceptions},
  crossref = {proceedings:itcse:2007},
  pages = {166--170},
  doi = {10.1145/1268784.1268834},
  abstract = {In this paper, we begin by considering object-oriented programming concepts and typical novice misconceptions as identified in the literature. We then present the results of a close examination of student programs, in an objects-first CS1 course, in which we find concrete evidence of students learning these concepts while also displaying some of these misconceptions. This leads to the development of two checklists that educators can use when designing or grading student programs.},
  keywords = {CS1, assessment, empirical research, misconceptions, object-oriented concepts}
}

@ARTICLE{Sanderson-Croft:2012,
  author = {Sanderson, M. and Croft, W. B.},
  title = {The History of Information Retrieval Research},
  crossref = {journal:ieee:proceedings},
  volume = {100},
  number = {Special Centennial Issue},
  year = {2012},
  pages = {1444 -1451},
  doi = {10.1109/JPROC.2012.2189916},
  abstract = {This paper describes a brief history of the research and development of information retrieval systems starting with the creation of electromechanical searching devices, through to the early adoption of computers to search for items that are relevant to a user's query. The advances achieved by information retrieval researchers from the 1950s through to the present day are detailed next, focusing on the process of locating relevant information. The paper closes with speculation on where the future of information retrieval lies.}
}

@INPROCEEDINGS{Sant:2009,
  author = {Sant, Joseph A.},
  title = {Mailing it in: email-centric automated assessment},
  crossref = {proceedings:itcse:2009},
  pages = {308--312},
  doi = {10.1145/1562877.1562971},
  abstract = {The automated assessment of student programming assignments is now considered to be in its third generation. Today, these server-based systems use web front-ends and employ sophisticated testing techniques. While automated assessment has proven its benefits over the last 40 years, these systems are simply not feasible for many scenarios because of their infrastructure, support or training requirements. Today's extensible email clients are capable of handling many of the functions performed by these modern assessment systems without requiring extra infrastructure. This paper summarizes experiences using graphical email-clients that were extended to support menu-activated automated processing of a student-submitted program sent as an email message or attachment. The email-client automatically captured the results of the automated assessment in an email window for instructor annotation. This client-based system provides many of the same benefits as those provided by web-based systems.},
  keywords = {CS1/2, automated assessment, client-based, email, experience report, instructional technologies, tools},
  timestamp = {2013-08-23}
}

@INPROCEEDINGS{SantAnna-etal:2008,
  author = {Sant'Anna, Francisco and Cerqueira, Renato and Soares, Luiz Fernando Gomes},
  title = {{NCLua}: objetos imperativos {Lua} na linguagem declarativa {NCL}},
  crossref = {proceedings:webmedia:2008},
  pages = {83--90},
  doi = {10.1145/1666091.1666107},
  abstract = {Declarative languages are easier to learn by non-programmer professionals. On the other hand, they lack flexibility, being hard to perform tasks out of the language's scope. The power of a declarative language is leveraged when integrated with an imperative language, bringing generic computation to the language. This integration should not conflict with the principles of the declarative language, keeping a clear boundary between the two environments. This work presents the integration between the declarative NCL and imperative Lua languages, specified and developed for the middleware Ginga, part of the brazilian digital TV standard.},
  keywords = {NCL, declarative languages, digital TV, ginga, lua, middlewares, multimedia systems}
}

@ARTICLE{Santiago-Raabe:2010,
  author = {Santiago, Rafael de and Andre L. A. Raabe},
  title = {Architecture for Learning Objects Sharing among Learning Institutions -- LOP2P},
  crossref = {journal:ieee:tlt},
  volume = {3},
  number = {2},
  month = apr # {--} # jun,
  year = {2010},
  pages = {91--95},
  doi = {10.1109/TLT.2010.9},
  abstract = {This paper presents an interoperability architecture that allows different educational institutions to share their learning object repositories, in order to create courses using Learning Management Systems (LMS). The initiative is in line with a current trend in educational institutions to produce learning objects and make them freely available through open web repositories. The proposed mechanism is based on Peer-to-Peer architecture, in which each institution is a peer. This paper details the two main components of the architecture, plug-in, for LMS-like systems, and Mediation Layer. Some implementation issues are also discussed.}
}

@ARTICLE{Santos-etal:JSIS:2013,
  author = {Carlos Santos and George Kuk and Fabio Kon and John Pearson},
  title = {The attraction of contributors in free and open source software projects},
  crossref = {journal:elsevier:jsis},
  volume = {22},
  number = {1},
  month = mar,
  year = {2013},
  pages = {26--45},
  doi = {10.1016/j.jsis.2012.07.004},
  abstract = {As firms increasingly sanction an open sourcing strategy, the question of which open source project to undertake remains tentative. The lack of established metrics makes it difficult to formulate such strategy. While many projects have been formed and created, only a few managed to remain active. With the majority of these projects failing, firms need a reliable set of criteria to assess what makes a project appealing not only to developers but also to visitors, users and commercial sponsors. In this paper, we develop a theoretical model to explore the contextual and causal factors of project attractiveness in inducing activities such as source code contribution, software maintenance, and usage. We test our model with data derived from more than 4000 projects spanning 4 years. Our main findings include that projects' set of conditions such as license restrictiveness and their available resources provide the context that directly influence the amount of work activities observed in the projects. It was also found that indirect and unintended contributions such as recommending software, despite of being non-technical, cannot be ignored for project activeness, diffusion and sustainability. Finally, our analysis provide evidence that higher attractiveness leads to more code-related activities with the downside of slowing down responsiveness to address projects' tasks, such as the implementation of new features and bug fixes. Our model underscores the significance of the reinforcing effects of attractiveness and work activities in open source projects, giving us the opportunity to discuss strategies to manage common traps such as the liability of newness. We conclude by discussing the applicability of the research model to other user-led initiatives.},
  keywords = {Attractiveness, Open source, Free software, Preferential attachment, Contributors, Contributions, Software development}
}

@INPROCEEDINGS{Santos-etal:2010b,
  author = {Rodrigo Costa Mesquita Santos and Thiago Alencar Gomes and Roberto Gerson Albuquerque Azevedo and Carlos de Salles Soares Neto and Mario Meireles Teixeira},
  title = {Correção de Código Semi-Automática em Nested Context Language},
  crossref = {proceedings:webmedia:2010},
  pages = {1--8},
  abstract = {O uso de ferramentas textuais para o desenvolvimento de aplicações hipermídia em NCL (Nested Context Language) aproxima o autor e o código fonte produzido. Por outro lado, essas ferramentas propiciam a criação de um ambiente mais sujeito a erros de programação, exigindo um autor de aplicações com um conhecimento moderado da linguagem e que seja capaz de identificar possíveis soluções para esses erros. Este trabalho apresenta técnicas de sugestão de correção semi-automática de erros, de forma a reduzir o tempo gasto na correção dos mesmos e, consequentemente, no desenvolvimento das aplicações, encorajando autores sem muita experiência a utilizarem ferramentas textuais. Também é discutida a implementação dessas técnicas na ferramenta NCL Eclipse.}
}

@ARTICLE{Santos-etal:JBCS:2013,
  author = {Santos, Rodrigo Costa Mesquita and Neto, José Rios Cerqueira and Salles Soares Neto, Carlos and Teixeira, MárioMeireles},
  title = {Incremental validation of {NCL} hypermedia documents},
  crossref = {journal:springer:jbcs},
  month = may,
  year = {2013},
  pages = {1--22},
  doi = {10.1007/s13173-013-0110-1},
  abstract = {This paper proposes an incremental, structural and contextual validation method for Nested Context Language (NCL) documents. As part of the proposed method, we define a declarative metalanguage to ensure low coupling between NCL structure and the validator code, which simplifies the validation of new language profiles. Requirements such as incremental processing and multilingual messages are also covered by this work. We present an implementation of this method using component architecture as a proof of concept and also conduct a performance evaluation to compare the traditional and incremental validation approaches.},
  keywords = {NCL; Incremental validation; Code validation; Ginga; ISDB-Tb; iDTV}
}

@INPROCEEDINGS{Santos-etal:2008,
  author = {Rodrigo Pereira dos Santos and Paulo Sérgio M. Santos and Guilherme Horta Travassos},
  title = {Uma Estratégia para Apoiar a Pesquisa em Educação em Engenharia de Software no Brasil},
  crossref = {proceedings:eselaw:2008},
  abstract = {The process of human resources formation in Software Engineering (SE) as well as in other areas of Computer Science depends on the education knowledge. Considering SE, it is possible to identify efforts that are being accomplished by the community. However, in most of the cases, they represent isolated and localized initiatives, hindering their diffusion and use in large scale in the national scenery. This work presents a strategy to support the educational research in SE, with strong focus in experimentation, aiming to contribute to the organization of a body of knowledge in SE education in Brazil.}
}

@INPROCEEDINGS{Sato-etal:2008,
  author = {Sato, D. T. and Corbucci, H. and Bravo, M. V.},
  title = {{Coding Dojo}: An Environment for Learning and Sharing Agile Practices},
  crossref = {proceedings:agile:2008},
  pages = {259--464},
  doi = {10.1109/Agile.2008.11},
  abstract = {A Coding Dojo is a meeting where a group of programmers gets together to learn, practice, and share experiences. This report describes the authors' experience of creating and running an active Coding Dojo in Sao Paulo, Brazil, sharing the lessons learned from the experience. The role of the Dojo in the learning process is discussed, showing how it creates an environment for fostering and sharing agile practices such as test-driven development, refactoring and pair programming, among others.},
  owner = {magsilva},
  timestamp = {2014.01.16}
}

@ARTICLE{Sattar-Lorenzen:2009,
  author = {Sattar, Abdul and Lorenzen, Torben},
  title = {Teach Alice programming to non-majors},
  crossref = {journal:acm:inroads},
  volume = {41},
  number = {2},
  month = jun,
  year = {2009},
  pages = {118--121},
  doi = {10.1145/1595453.1595488},
  abstract = {This paper presents the design and implementation of an introductory computer programming course using Alice for non-CS majors. This course gives a broad overview of computer science as an academic discipline and teaches computer programming to non-CS majors in a fun way.},
  keywords = {Alice, classes, computer programming, computer science, methods, object-oriented programming, objects}
}

@ARTICLE{Sattar-etal:2010,
  author = {Sattar, Abdul and Mondshein, Lee and Lorenzen, Torben},
  title = {An operating systems course with projects in {Java}},
  crossref = {journal:acm:inroads},
  volume = {1},
  number = {2},
  month = jun,
  year = {2010},
  pages = {24--26},
  doi = {10.1145/1805724.1805734},
  abstract = {This paper describes a set of five programming projects in an undergraduate Operating Systems course. The problems are designed to reinforce the fundamental concepts that are discussed in most operating systems textbooks. Students are required to write programs that will simulate the behavior of the process management, process synchronization, memory management, and storage management components of an operating system.},
  keywords = {Java, operating systems education}
}

@ARTICLE{Savage:2014,
  author = {Savage, Neil},
  title = {Gradual Evolution},
  crossref = {journal:acm:cacm},
  volume = {57},
  number = {10},
  month = sep,
  year = {2014},
  pages = {16--18},
  doi = {10.1145/2659764},
  abstract = {Dynamically typed languages adopt features of static typing to cope with growth.},
  owner = {magsilva},
  timestamp = {2014.10.14}
}

@INPROCEEDINGS{Scacchi-etal:2005,
  author = {W. Scacchi and C. Jensen and J. Noll and M. Elliott},
  title = {Multi-Modal Modeling, Analysis and Validation of Open Source Software Requirements Processes},
  crossref = {proceedings:oss:2005},
  pages = {1--8},
  abstract = {Understanding the context, structure, activities, and content of software development processes found in practice has been and remains a challenging problem. In the world of free/open source software development, discovering and understanding what processes are used in particular projects is important in determining how they are similar to or different from those advocated by the software engineering community. Prior studies however have revealed that the requirements processes in OSSD projects are different in a number of ways, including the general lack of explicit software requirements specifications. In this paper, we describe how a variety of modeling perspectives and techniques are used to elicit, analyze, and validate software requirements processes found in OSSD projects, with examples drawn from studies of the NetBeans.org project.},
  keywords = {softwar process, process modeling, software requirements, open source software development, empirical studies of software engineering}
}

@INCOLLECTION{Schaalje:2007,
  author = {Jared Schaalje},
  title = {Instructional Design of Learning Objects for the Cognitive Domain},
  chapter = {2},
  pages = {45-81},
  crossref = {Koohang-Harman:2007:theory}
}

@ARTICLE{Schaefer:2012,
  author = {Schaefer, Robert},
  title = {The secret life of academic papers},
  crossref = {journal:acm:sen},
  volume = {37},
  number = {2},
  month = apr,
  pages = {7--8},
  doi = {10.1145/2108144.2108161}
}

@ARTICLE{Schaub:2009,
  author = {Schaub, Stephen},
  title = {Teaching {CS1} with web applications and test-driven development},
  crossref = {journal:acm:inroads},
  volume = {41},
  number = {2},
  month = jun,
  year = {2009},
  pages = {113--117},
  doi = {10.1145/1595453.1595487},
  abstract = {Teaching client/server web application development in CS1 can help increase student motivation without introducing a heavy curriculum footprint. This paper summarizes the author's experience teaching CS1 for several years using a web application focus. The use of an appropriate web API, good development environment, and Test-Driven Development methodology helps ensure student success.},
  keywords = {CS1, test-driven development, unit testing, web applications}
}

@INPROCEEDINGS{scherer:1998,
  author = {Marco Scherer},
  title = {An extended model for interactive learning systems},
  crossref = {proceedings:fie:1998},
  pages = {1119},
  doi = {10.1109/FIE.1998.738578},
  abstract = {Our main interest consists in developing a concept to formalize interactive learning systems (ILS). The development of such a formalism has been motivated by different learning systems which were produced in our department. These systems were developed for commercial application as well as for lectures held at our university. In computer science there are some formal methods available for creating an abstract representation of interactive systems. In the late 1980s and early 1990s there were a large amount of publications in this special field, but only a few techniques have been left over. One approach is the model-based Vienna Development Method. A representation according to VDM specifies all data objects, defined as nodes, structures and networks as well as the different operations on them. A standard specification language is available (VDM-SL). We decided to use this method as a starting point for further developments. Our work shows that it is possible to build an abstract model for modern interactive learning systems which is able to support the development process and the maintenance of the system by formal means.},
  volume = {3},
  acmid = {1254155},
  year = {1998}
}

@INPROCEEDINGS{Schilling:2012,
  author = {Schilling, Andreas},
  title = {Links to the source - a multidimensional view of social ties for the retention of {FLOSS} developers},
  crossref = {proceedings:sigmis-cpr:2012},
  pages = {103--108},
  doi = {10.1145/2214091.2214119},
  abstract = {Free Libre Open Source Software (FLOSS) is of vital importance for the daily life of many private and corporate users. However, the majority of all FLOSS initiatives fail, most commonly due to a lack of sustained developers. In contrast to previous research which used an individual centric or a structural perspective, this dissertation combines motivational and relational aspects to build a comprehensive understanding for FLOSS developers' ongoing project commitment. A unified research model is developed by drawing on established theories from organizational and sociological literature, in particular by combining Self-Determination-Theory (SDT) and Social-Identity-Theory (SIT). Both SDT and SIT have been found valuable concepts for staffing decisions in organizations. In addition to the development and evaluation of the research model, this dissertation derives operational strategies for project managers of FLOSS initiatives on how to enhance the retention behavior of their contributor base.},
  keywords = {it personnel, job satisfaction, open source, retention, self-determination-theory, social-identity-theory, turnover intention}
}

@INPROCEEDINGS{Schilling-etal:2012,
  author = {Schilling, Andreas and Laumer, Sven and Weitzel, Tim},
  title = {Train and retain: the impact of mentoring on the retention of FLOSS developers},
  crossref = {proceedings:sigmis-cpr:2012},
  pages = {79--84},
  doi = {10.1145/2214091.2214112},
  abstract = {The acquisition of new knowledge is a critical task for software development. IT companies spend considerable resources in the training of their employees to succeed in a continuously changing industry. Depending on the voluntary commitment of their contributors, initiatives developing Free Libre Open Source Software (FLOSS) identified members' learning and their retention as vital. Although contributors' knowledge building has been repeatedly found to facilitate their project continuance, FLOSS projects are lacking operational advices on how to assist their members' learning. Drawing on previous literature which emphasizes project members' social interactions and their practical experiences to build new knowledge, we propose mentoring as a training method for FLOSS projects. Based on organizational experiences, we propose a measure to evaluate mentoring as an appropriate strategy for FLOSS initiatives to facilitate individuals' learning and to retain their contributors on longitudinal base.},
  keywords = {free libre open source software, knowledge building, mentoring, open source software development, retention, turnover behavior}
}

@ARTICLE{Schimpf:2012,
  author = {Schimpf, Paul H.},
  title = {You say reference, I say pointer: a clarification},
  crossref = {journal:acm:inroads:1:3},
  pages = {38--41},
  doi = {10.1145/2077808.2077821},
  abstract = {This article discusses a common confusion between references and pointers that will be familiar to many faculty members teaching programming courses. It does so in the guise of a conversation between a faculty member and a student. In this conversation, the faculty member resolves the confusion in a manner that is somewhat different from the resolution commonly heard, at least by the author. More importantly, this article attempts to illustrate how important programming concepts can become obscured by the language used in a curriculum, and how such confusions can be leveraged to encourage the student to think beyond the bounds of the language that is being used, thereby gaining a deeper understanding of programming languages in general.},
  keywords = {pointers, references}
}

@ARTICLE{Schnettler:2009,
  author = {Sebastian Schnettler},
  title = {A structured overview of 50 years of small-world research },
  crossref = {journal:elsevier:sn},
  volume = {31},
  number = {3},
  month = jun,
  year = {2009},
  pages = {165--178},
  doi = {10.1016/j.socnet.2008.12.004},
  abstract = {This paper offers a structured overview of 50 years of small-world research. Initially formulated by Pool and Kochen in the mid-1950s, the small-world concept can be divided into six research foci, based on three dimensions (structural, process-related, psychological), and two process-related themes (diffusion, search). Building on this analytical distinction, the article provides a historical summary of the different phases of research on the small-world problem, and summarizes the empirical and theoretical progress on different facets of the small-world phenomenon. The paper concludes with a brief assessment of accomplishments and open questions, suggesting some possible future research areas. },
  keywords = {Small-world phenomenon, Social networks, Six degrees of separation, Small-world experiment, Social process, Social structure, Complex networks, New science of networks, Milgram, Social capital, Network dynamics }
}

@INPROCEEDINGS{Schots-etal:2012,
  author = {Schots, Marcelo and Werner, Cláudia and Mendonça, Manoel},
  title = {Awareness and Comprehension in Software/Systems Engineering Practice and Education: Trends and Research Directions},
  crossref = {proceedings:sbes:2012},
  pages = {186--190},
  doi = {10.1109/SBES.2012.25},
  abstract = {The creation of tools, techniques and methodologies to support the manipulation of large data sets has been receiving special attention of both scientific and industrial communities, in order to discover new ways of dealing with the underlying information, including learning purposes, identification of patterns, decision making support, amongst others. However, making use of computing resources to enhance awareness and understanding of software information and the software itself is still a challenge in software/systems engineering, since it involves the identification of suitable mechanisms, adequate abstractions, and studies on stimulation of the human perceptive and cognitive abilities. This paper presents some of the challenges in this context, based on current trends of software development lifecycle, program comprehension, and software engineering education. At the end, a special focus is given on ongoing research on using and improving current mechanisms for supporting software reuse practices and software comprehension in general.}
}

@ARTICLE{Schutzenberger:1963,
  author = {M.P. Schützenberger},
  title = {On context-free languages and push-down automata},
  crossref = {journal:elsevier:ic},
  volume = {6},
  number = {3},
  month = sep,
  year = {1963},
  pages = {246--264},
  doi = {10.1016/S0019-9958(63)90306-1},
  abstract = {This note describes a special type of one-way, one-tape automata in the sense of Rabin and Scott that idealizes some of the elementary formal features used in the so-called push-down store programming techniques. It is verified that the sets of words accepted by these automata form a proper subset of the family of the unambiguous context-free languages of Chomsky's and that this property admits a weak converse.}
}

@ARTICLE{Schwabe-Rossi:1995:CACM,
  author = {Schwabe, Daniel and Rossi, Gustavo},
  title = {The object-oriented hypermedia design model},
  crossref = {proceedings:acm:cacm},
  volume = {38},
  number = {8},
  month = aug,
  year = {1995},
  pages = {45--46},
  doi = {10.1145/208344.208354},
  acmid = {208354},
  issue = {8},
  numpages = {2}
}

@INCOLLECTION{Schwartzman-etal:2007,
  author = {Roy Schwartzman and Darla Runyon and Holzen, Roger von},
  title = {Where Theory Meets Practice: Design and Deployment of Learning Objects},
  chapter = {1},
  pages = {1-44},
  crossref = {Koohang-Harman:2007:theory}
}

@ARTICLE{Seaton-etal:2014,
  author = {Seaton, Daniel T. and Bergner, Yoav and Chuang, Isaac and Mitros, Piotr and Pritchard, David E.},
  title = {Who Does What in a Massive Open Online Course?},
  crossref = {journal:acm:cacm},
  volume = {57},
  number = {4},
  month = apr,
  year = {2014},
  pages = {58--65},
  doi = {10.1145/2500876},
  abstract = {Student-participation data from the inaugural MITx (now edX) course---6.002x: Circuits and Electronics---unpacks MOOC student behavior.}
}

@ARTICLE{Segura-etal:2011,
  author = {Sergio Segura and Robert M. Hierons and David Benavides and Antonio Ruiz-Cortés},
  title = {Mutation testing on an object-oriented framework: An experience report},
  crossref = {journal:information-software-technology},
  volume = {53},
  number = {10},
  month = oct,
  year = {2011},
  pages = {1124 - 1136},
  doi = {10.1016/j.infsof.2011.03.006},
  abstract = {The increasing presence of Object-Oriented (OO) programs in industrial systems is progressively drawing the attention of mutation researchers toward this paradigm. However, while the number of research contributions in this topic is plentiful, the number of empirical results is still marginal and mostly provided by researchers rather than practitioners. This article reports our experience using mutation testing to measure the effectiveness of an automated test data generator from a user perspective. In our study, we applied both traditional and class-level mutation operators to FaMa, an open source Java framework currently being used for research and commercial purposes. We also compared and contrasted our results with the data obtained from some motivating faults found in the literature and two real tools for the analysis of feature models, FaMa and SPLOT. Our results are summarized in a number of lessons learned supporting previous isolated results as well as new findings that hopefully will motivate further research in the field. We conclude that mutation testing is an effective and affordable technique to measure the effectiveness of test mechanisms in OO systems. We found, however, several practical limitations in current tool support that should be addressed to facilitate the work of testers. We also missed specific techniques and tools to apply mutation testing at the system level.},
  keywords = {Mutation testing, Test adequacy, Test data generation, Automated analysis, Feature models},
  lang = {en}
}

@ARTICLE{Selic:2003,
  author = {Selic, B.},
  title = {The pragmatics of model-driven development},
  crossref = {journal:ieee:software},
  volume = {20},
  number = {5},
  month = sep # {-} # oct,
  year = {2003},
  pages = { 19 - 25},
  doi = {10.1109/MS.2003.1231146},
  abstract = {The potential benefits of using models are significantly greater in software than in other engineering disciplines because of the potential for a seamless link between models and the systems they represent. Unfortunately, models have rarely produced anticipated benefits. The key lies in resolving pragmatic issues related to the artifacts and culture of the previous generation of software technologies.},
  keywords = {artifacts; culture; industrial experience; model-driven development methods; pragmatic issues; software development; software engineering; modelling; software engineering; software standards;},
  issn = {0740-7459},
  journal = {IEEE Software},
  publisher = {IEEE Computer Society}
}

@INPROCEEDINGS{Sen-etal:2005,
  author = {Sen, Koushik and Marinov, Darko and Agha, Gul},
  title = {{CUTE}: a concolic unit testing engine for {C}},
  crossref = {proceedings:fse:2005},
  pages = {263--272},
  doi = {10.1145/1081706.1081750},
  abstract = {In unit testing, a program is decomposed into units which are collections of functions. A part of unit can be tested by generating inputs for a single entry function. The entry function may contain pointer arguments, in which case the inputs to the unit are memory graphs. The paper addresses the problem of automating unit testing with memory graphs as inputs. The approach used builds on previous work combining symbolic and concrete execution, and more specifically, using such a combination to generate test inputs to explore all feasible execution paths. The current work develops a method to represent and track constraints that capture the behavior of a symbolic execution of a unit with memory graphs as inputs. Moreover, an efficient constraint solver is proposed to facilitate incremental generation of such test inputs. Finally, CUTE, a tool implementing the method is described together with the results of applying CUTE to real-world examples of C code.},
  keywords = {concolic testing, data structure testing, explicit path model-checking, random testing, testing C programs, unit testing}
}

@ARTICLE{Shaffer:2005,
  author = {Shaffer, Steven C.},
  title = {Ludwig: An Online Programming Tutoring and Assessment System},
  crossref = {journal:acm:sigcse-bulletin},
  volume = {37},
  number = {2},
  month = jun,
  year = {2005},
  pages = {56--60},
  doi = {10.1145/1083431.1083464},
  abstract = {An online programming tutoring and assessment system is described, and the results of a preliminary study are presented. Ten students in an introductory C++ programming course used the system; both qualitative and quantitative data were collected and suggest that a future large-scale implementation will yield beneficial results},
  keywords = {assessment, online, programming, tutoring, web-based}
}

@ARTICLE{Shaffer-Rosson:2013,
  author = {Shaffer, Steven C. and Rosson, Mary Beth},
  title = {Increasing Student Success by Modifying Course Delivery Based on Student Submission Data},
  crossref = {journal:acm:inroads},
  volume = {4},
  number = {4},
  month = dec,
  year = {2013},
  pages = {81--86},
  doi = {10.1145/2537753.2537778},
  keywords = {distance education, introductory programming, mastery learning, retention}
}

@INPROCEEDINGS{Shaffer-Shaffer:2013,
  author = {Shaffer, Steven C. and Shaffer, Cliff},
  title = {Automated Generation and Grading of Programming Assignments},
  crossref = {proceedings:sigcse:2013},
  pages = {745--745},
  doi = {10.1145/2445196.2445463},
  abstract = {A problem with teaching large classes of introductory programming students is that students need copious practice but instructors do not have time to grade thousands of student programs. Large classes might require the instructor to restrict the graded programs to a handful. However, students need much more practice than this, and experience shows that if an assignment is not being graded then many students will not do it. Also, if the same problem is assigned to all students, copying of answers will occur. Programs that generate unique assignments and automatically grade submissions have been developed. Beginning with a brief example, this session will focus on experiences attendees have had with such approaches, and what an idealized system might look like, including exemplar use cases.},
  keywords = {assessment, assignments, computer science education, grading}
}

@INPROCEEDINGS{Shams:2013:icer,
  author = {Shams, Zalia},
  title = {Automatically Assessing the Quality of Student-written Tests},
  crossref = {proceedings:icer:2013},
  pages = {189--190},
  doi = {10.1145/2493394.2493428},
  abstract = {Software testing is frequently being added to programming courses at many schools, but current assessment techniques for evaluating student-written software tests are imperfect. Code coverage measures are typically used in practice, but that approach does not assess how much of the expected behavior is checked by the tests and sometimes overestimates the true quality of the tests. Running one student's tests against others' code (known as all-pairs testing) and mutation analysis are better indicators of test quality but both of them posed a number of practical obstacles to classroom use. This proposal describes technical obstacles behind using these two approaches in automated grading. We propose novel and practical solutions to apply all-pairs testing and mutation analysis of student-written tests, especially in an automated grading context. Experimental results of applying our techniques in eight CS1 and CS2 assignments submitted by 147 students show feasibility of our solution. Finally, we discuss our plan to combine the approaches to evaluate tests of assignments having large amounts of design freedom and explain their evaluation plan.},
  keywords = {design, experimentation, languages, verification},
  owner = {magsilva},
  timestamp = {2014.08.31}
}

@INPROCEEDINGS{Shams:2013:splash,
  author = {Shams, Zalia},
  title = {Automated Assessment of Students' Testing Skills for Improving Correctness of Their Code},
  crossref = {proceedings:splash:docsym:2013},
  pages = {37--40},
  doi = {10.1145/2508075.2508078},
  abstract = {Although software testing is included as a regular part of many programming courses, current assessment techniques used in automated grading tools for evaluating student-written software tests are imperfect. Code coverage measures are typically used in practice, but that approach does not assess how much of the expected behavior is checked by the tests and sometimes, overestimates the true quality of the tests. Two robust and thorough measures for evaluating student-written tests are running each students' tests against others' solutions(known as all-pairs testing) and injecting artificial bugs to determine if tests can detect them (also known as mutation analysis). Even though they are better indicators of test quality, both of them posed a number of practical obstacles to classroom use. This proposal describes technical obstacles behind using these two approaches in automated grading. We propose novel and practical solutions to apply all-pairs testing and mutation analysis of student-written tests, especially in the context of classroom grading tools. Experimental results of applying our techniques in eight CS1 and CS2 assignments submitted by 147 students show the feasibility of our solution. Finally, we discuss our plan to combine the approaches to evaluate tests of assignments having variable amounts of design freedom and explain their evaluation method.},
  keywords = {automated grading, bytecode transformation, mutation testing, reflection, software testing, test coverage, test driven development},
  owner = {magsilva},
  timestamp = {2014.08.31}
}

@INPROCEEDINGS{Shams-Edwards:2013:icer,
  author = {Shams, Zalia and Edwards, Stephen H.},
  title = {Toward Practical Mutation Analysis for Evaluating the Quality of Student-written Software Tests},
  crossref = {proceedings:icer:2013},
  pages = {53--58},
  doi = {10.1145/2493394.2493402},
  abstract = {Software testing is being added to programming courses at many schools, but current assessment techniques for evaluating student-written tests are imperfect. Code coverage measures are typically used in practice, but they have limitations and sometimes overestimate the true quality of tests. Others have proposed using mutation analysis instead, but mutation analysis poses a number of practical obstacles to classroom use. This paper describes a new approach to mutation analysis of student-written tests that is more practical for educational use, especially in an automated grading context. This approach combines several techniques to produce a novel solution that addresses the shortcomings raised by more traditional mutation analysis. An evaluation of this approach in the context of both CS1 and CS2 courses illustrates how it differs from code coverage analysis. At the same time, however, the evaluation results also raise questions of concern for CS educators regarding the relative value of more comprehensive assessment of test quality, the value of more open-ended assignments that offer significant design freedom for students, the cost of providing higher-quality reference solutions in order to support better quality assessment, and the cost of supporting assignments that require more intensive testing, such as GUI assignments.},
  keywords = {automated assessment, automated grading, bytecode transformation, mutation testing, programming assignments, reflection, software testing, test coverage, test-driven development},
  owner = {magsilva},
  timestamp = {2014.08.31}
}

@INPROCEEDINGS{Shams-Edwards:2013:sigcse,
  author = {Shams, Zalia and Edwards, Stephen H.},
  title = {An Experiment to Test Bug Density in Students' Code},
  crossref = {proceedings:sigcse:2013},
  pages = {742--742},
  doi = {10.1145/2445196.2445454},
  abstract = {A normal industry standard measure, bug density (bugs per thousand non-commented source line of code), is a through mechanism to assess code quality. If it is used for evaluating students' code, students will realize their ability to write bug free code from professional context. The main issues of using bug density for object oriented languages are creating a comprehensive test suit, and running them against all solutions as the test cases are written as part of solutions may fail to compile against other codes. We provide a novel four phase Java specific solution: 1) developing a comprehensive master test suit by collecting all the students written valid test cases; 2) transforming the test cases to use late binding so that they can run against any solution; 3) running the entire tests against all the programs and removing redundant test suits; and 4) estimating bugs/KSLOC by determining the relationship between test case failures in the master suite and latent bugs hidden in student programs. The first two phases of this ongoing research are applied to two programming assignments in two different courses encompassing 147 student programs and 240,158 individual test cases. Experimental results show that we have indeed removed compile-time dependencies from test cases using late binding and thus, have resolved the main technical challenge of using bug density for accessing students' code. Our experimental results will help students to realize the quality of their code in terms of industry standard.},
  keywords = {automated assessment, bytecode transformation, programming assignments, reflection, software testing, test coverage, test-driven development},
  owner = {magsilva},
  timestamp = {2014.08.31}
}

@ARTICLE{Sasha:2010,
  author = {Dennis E. Shasha},
  title = {Puzzle: No Tipping},
  crossref = {journal:acm:xrds},
  volume = {17},
  number = {2},
  month = dec,
  year = {2010},
  pages = {60--60}
}

@INPROCEEDINGS{Shaw:2000,
  author = {Mary Shaw},
  title = {Software Engineering Education: A Roadmap},
  crossref = {proceedings:icse:2000},
  pages = {371--380},
  doi = {10.1145/336512.336592}
}

@INPROCEEDINGS{Sheard-etal:2008,
  author = {Sheard, Judy and Carbone, Angela and Lister, Raymond and Simon, Beth and Thompson, Errol and Whalley, Jacqueline L.},
  title = {Going {SOLO} to assess novice programmers},
  crossref = {proceedings:itcse:2008},
  pages = {209--213},
  doi = {10.1145/1384271.1384328},
  abstract = {This paper explores the programming knowledge of novices using Biggs' SOLO taxonomy. It builds on previous work of Lister et al. (2006) and addresses some of the criticisms of that work. The research was conducted by studying the exam scripts for 120 introductory programming students, in which three specific questions were analyzed using the SOLO taxonomy. The study reports the following four findings: when the instruction to students used by Lister et al. - "In plain English, explain what the following segment of Java code does" - is replaced with a less ambiguous instruction, many students still provide multistructural responses; students are relatively consistent in the SOLO level of their answers; student responses on SOLO reading tasks correlate positively with performance on writing tasks; postgraduates students manifest a higher level of thinking than undergraduates.},
  keywords = {CS1, comprehension, novice programmers, solo taxonomy}
}

@INPROCEEDINGS{Sheard:2009,
  author = {Sheard, Judy and Simon, S. and Hamilton, Margaret and L\"{o}nnberg, Jan},
  title = {Analysis of research into the teaching and learning of programming},
  crossref = {proceedings:icer:2009},
  pages = {93--104},
  doi = {10.1145/1584322.1584334},
  abstract = {This paper presents an analysis of research papers about programming education that were published in computing education conferences in the years 2005 to 2008. We employed Simon's classification scheme to identify the papers of interest from the ICER, SIGCSE, ITiCSE, ACE, Koli Calling and NACCQ conferences. Having identified the papers, we analyzed the type of data collected, whether the analysis was qualitative, quantitative, or mixed, and the aims and outcomes being reported. The greatest number of papers employed quantitative research methods, investigated the ability, aptitude, or understanding of students, and were based in single courses. The theme of the research and the type of study conducted vary across the conferences, indicating the different nature and role of each conference. Papers that investigated student learning of programming in terms of established theories or models of learning were not common, indicating an area of research that deserves more attention.},
  keywords = {classifying publications, computing education, research methods, teaching and learning of programming}
}

@INPROCEEDINGS{Shelton-etal:2012,
  author = {Shelton, W. and Nan Li and Ammann, P. and Offutt, J.},
  title = {Adding Criteria-Based Tests to Test Driven Development},
  crossref = {proceedings:icst:2012},
  pages = {878--886},
  doi = {10.1109/ICST.2012.191},
  abstract = {Test driven development (TDD) is the practice of writing unit tests before writing the source. TDD practitioners typically start with example-based unit tests to verify an understanding of the software's intended functionality and to drive software design decisions. Hence, the typical role of test cases in TDD leans more towards specifying and documenting expected behavior, and less towards detecting faults. Conversely, traditional criteria-based test coverage ignores functionality in favor of tests that thoroughly exercise the software. This paper examines whether it is possible to combine both approaches. Specifically, can additional criteria based tests improve the quality of TDD test suites without disrupting the TDD development process? This paper presents the results of an observational study that generated additional criteria-based tests as part of a TDD exercise. The criterion was mutation analysis and the additional tests were designed to kill mutants not killed by the TDD tests. The additional unit tests found several software faults and other deficiencies in the software. Subsequent interviews with the programmers indicated that they welcomed the additional tests, and that the additional tests did not inhibit their productivity.},
  keywords = {fault diagnosis;object-oriented methods;program testing;software fault tolerance;software quality;TDD development process;TDD practitioners;TDD test;criteria-based test;example-based unit tests;mutation analysis;software design decisions;software fault detection;software intended functionality;software testing;test driven development;Java;Programming;Rhythm;Software;Software testing;Writing}
}

@ARTICLE{Shen-etal:2011,
  author = {Wen-Hsiang Shen and Nien-Lin Hsueh and Wei-Mann Lee},
  title = {Assessing {PSP} effect in training disciplined software development: A Plan-Track-Review model},
  crossref = {journal:elsevier:ist},
  volume = {53},
  number = {2},
  month = feb,
  year = {2011},
  pages = {137--148},
  doi = {10.1016/j.infsof.2010.09.004},
  abstract = {Context In training disciplined software development, the PSP is said to result in such effect as increased estimation accuracy, better software quality, earlier defect detection, and improved productivity. But a systematic mechanism that can be easily adopted to assess and interpret PSP effect is scarce within the existing literature.Objective The purpose of this study is to explore the possibility of devising a feasible assessment model that ties up critical software engineering values with the pertinent PSP metrics.Method A systematic review of the literature was conducted to establish such an assessment model (we called a Plan-Track-Review model). Both mean and median approaches along with a set of simplified procedures were used to assess the commonly accepted PSP training effects. A set of statistical analyses further followed to increase understanding of the relationships among the PSP metrics and to help interpret the application results.Results Based on the results of this study, PSP training effect on the controllability, manageability, and reliability of a software engineer is quite positive and largely consistent with the literature. However, its effect on one's predictability on project in general (and on project size in particular) is not implied as said in the literature. As for one's overall project efficiency, our results show a moderate improvement. Our initial finding also suggests that a prior stage PSP effect could have an impact on later stage training outcomes.Conclusion It is concluded that this Plan-Track-Review model with the associated framework can be used to assess PSP effect regarding a disciplined software development. The generated summary report serves to provide useful feedback for both PSP instructors and students based on internal as well as external standards.},
  keywords = {Personal software process (PSP)},
  lang = {en}
}

@ARTICLE{Shepperd-etal:2013,
  author = {Shepperd, M. and Song, Q. and Sun, Z. and Mair, C.},
  title = {Data Quality: Some Comments on the {NASA} Software Defect Data Sets},
  crossref = {journal:ieee:tse},
  doi = {10.1109/TSE.2013.11},
  abstract = {BACKGROUND - self evidently empirical analyses rely upon the quality of their data. Likewise replications rely upon accurate reporting and using the same rather than similar versions of data sets. In recent years there has been much interest in using machine learners to classify software modules into defect-prone and not defect-prone categories. The publicly available NASA datasets have been extensively used as part of this research. OBJECTIVE - this short note investigates the extent to which published analyses based on the NASA defect data sets are meaningful and comparable. METHOD - we analyse the five studies published in IEEE Transactions on Software Engineering since 2007 that have utilised these data sets and compare the two versions of the data sets currently in use. RESULTS - we find important differences between the two versions of the data sets, implausible values in one data set and generally insufficient detail documented on data set pre-processing. CONCLUSIONS - it is recommended that researchers (i) indicate the provenance of the data sets they use (ii) report any pre-processing in sufficient detail to enable meaningful replication and (iii) invest effort in understanding the data prior to applying machine learners.},
  keywords = {Artificial Intelligence , Computing Methodologies , Learning , Machine learning , Measurement applied to SQA , Metrics/Measurement , Product metrics , Software Engineering , Software Quality/SQA , Software/Software Engineering}
}

@ARTICLE{Shi-etal:2014,
  author = {Shi, Yue and Larson, Martha and Hanjalic, Alan},
  title = {Collaborative Filtering Beyond the User-Item Matrix: A Survey of the State of the Art and Future Challenges},
  crossref = {journal:acm:csur},
  volume = {47},
  number = {1},
  month = may,
  year = {2014},
  pages = {3:1--3:45},
  doi = {10.1145/2556270},
  abstract = {Over the past two decades, a large amount of research effort has been devoted to developing algorithms that generate recommendations. The resulting research progress has established the importance of the user-item (U-I) matrix, which encodes the individual preferences of users for items in a collection, for recommender systems. The U-I matrix provides the basis for collaborative filtering (CF) techniques, the dominant framework for recommender systems. Currently, new recommendation scenarios are emerging that offer promising new information that goes beyond the U-I matrix. This information can be divided into two categories related to its source: rich side information concerning users and items, and interaction information associated with the interplay of users and items. In this survey, we summarize and analyze recommendation scenarios involving information sources and the CF algorithms that have been recently developed to address them. We provide a comprehensive introduction to a large body of research, more than 200 key references, with the aim of supporting the further development of recommender systems exploiting information beyond the U-I matrix. On the basis of this material, we identify and discuss what we see as the central challenges lying ahead for recommender system technology, both in terms of extensions of existing techniques as well as of the integration of techniques and technologies drawn from other research areas.},
  keywords = {Algorithms, applications, challenges, collaborative filtering, recommender systems, social networks, survey}
}

@ARTICLE{Shihab-etal:2013,
  author = {Emad Shihab and Yasutaka Kamei and Bram Adams and Ahmed E. Hassan},
  title = {Is lines of code a good measure of effort in effort-aware models? },
  crossref = {journal:elsevier:ist},
  volume = {55},
  number = {11},
  month = nov,
  year = {2013},
  pages = {1981--1993},
  doi = {10.1016/j.infsof.2013.06.002},
  abstract = {Effort-aware models, e.g., effort-aware bug prediction models aim to help practitioners identify and prioritize buggy software locations according to the effort involved with fixing the bugs. Since the effort of current bugs is not yet known and the effort of past bugs is typically not explicitly recorded, effort-aware bug prediction models are forced to use approximations, such as the number of lines of code (LOC) of the predicted files. Although the choice of these approximations is critical for the performance of the prediction models, there is no empirical evidence on whether LOC is actually a good approximation. Therefore, in this paper, we investigate the question: is LOC a good measure of effort for use in effort-aware models? We perform an empirical study on four open source projects, for which we obtain explicitly-recorded effort data, and compare the use of LOC to various complexity, size and churn metrics as measures of effort. We find that using a combination of complexity, size and churn metrics are a better measure of effort than using LOC alone. Furthermore, we examine the impact of our findings on previous effort-aware bug prediction work and find that using LOC as a measure for effort does not significantly affect the list of files being flagged, however, using LOC under-estimates the amount of effort required compared to our best effort predictor by approximately 66%. Studies using effort-aware models should not assume that LOC is a good measure of effort. For the case of effort-aware bug prediction, using LOC provides results that are similar to combining complexity, churn, size and LOC as a proxy for effort when prioritizing the most risky files. However, we find that for the purpose of effort-estimation, using LOC may under-estimate the amount of effort required.},
  keywords = {Effort-aware prediction, Prediction models, Defect prediction},
  timestamp = {2013-09-08}
}

@INPROCEEDINGS{Shmallo-etal:2012,
  author = {Shmallo, Ronit and Ragonis, Noa and Ginat, David},
  title = {Fuzzy {OOP}: Expanded and Reduced Term Interpretations},
  crossref = {proceedings:itcse:2012},
  pages = {309--314},
  doi = {10.1145/2325296.2325368},
  abstract = {We display a novel perspective of novice OOP difficulties. In a thorough study of 120 undergraduates, in their first OOP course, we noticed a variety of misconceptions and difficulties with a wide range of basic terms and notions. Careful analysis revealed a recurring phenomenon, of fuzzy OOP conceptions, which derive from expansion and reduction of basic term features. Novices tended to expand and/or reduce properties not only of terms such as "class" and "object", but also of terms such as "static", "access", and "instance". Particular misconceptions were of the forms: "One vs. Many". We display a detailed categorization of our findings, in an ordered hierarchical structure, and discuss its cognitive characteristics.},
  keywords = {computer science education, expansion, object-oriented programming, reduction},
  owner = {magsilva},
  timestamp = {2014.07.17}
}

@INPROCEEDINGS{Shokripour-etal:2013,
  author = {Shokripour, Ramin and Anvik, John and Kasirun, Zarinah M. and Zamani, Sima},
  title = {Why So Complicated? Simple Term Filtering and Weighting for Location-based Bug Report Assignment Recommendation},
  crossref = {proceedings:msr:2013},
  pages = {2--11},
  abstract = {Large software development projects receive many bug reports and each of these reports needs to be triaged. An important step in the triage process is the assignment of the report to a developer. Most previous efforts towards improving bug report assignment have focused on using an activity-based approach. We address some of the limitations of activity-based approaches by proposing a two-phased location-based approach where bug report assignment recommendations are based on the predicted location of the bug. The proposed approach utilizes a noun extraction process on several information sources to determine bug location information and a simple term weighting scheme to provide a bug report assignment recommendation. We found that by using a location-based approach, we achieved an accuracy of 89.41% and 59.76% when recommending five developers for the Eclipse and Mozilla projects, respectively.},
  series = {MSR '13},
  acmid = {2487089},
  address = {Piscataway, NJ, USA},
  booktitle = {Proceedings of the 10th Working Conference on Mining Software Repositories},
  isbn = {978-1-4673-2936-1},
  location = {San Francisco, CA, USA},
  numpages = {10},
  publisher = {IEEE Press},
  url = {http://dl.acm.org/citation.cfm?id=2487085.2487089},
  year = {2013}
}

@ARTICLE{Shrivastava-etal:2014,
  author = {Suprika V. Shrivastava and Urvashi Rathod},
  title = {Categorization of risk factors for distributed agile projects },
  crossref = {journal:elsevier:ist},
  year = {2014},
  doi = {10.1016/j.infsof.2014.07.007},
  abstract = {AbstractContext Organizations combine agile approach and Distributed Software Development (DSD) in order to develop better quality software solutions in lesser time and cost. It helps to reap the benefits of both agile and distributed development but pose significant challenges and risks. Relatively scanty evidence of research on the risks prevailing in distributed agile development (DAD) has motivated this study. Objective This paper aims at creating a comprehensive set of risk factors that affect the performance of distributed agile development projects and identifies the risk management methods which are frequently used in practice for controlling those risks. Method The study is an exploration of practitioners' experience using constant comparison method for analyzing in-depth interviews of thirteen practitioners and work documents of twenty-eight projects from thirteen different information technology (IT) organizations. The field experience was supported by extensive research literature on risk management in traditional, agile and distributed development. Results Analysis of qualitative data from interviews and project work documents resulted into categorization of forty-five DAD risk factors grouped under five core risk categories. The risk categories were mapped to Leavitt's model of organizational change for facilitating the implementation of results in real world. The risk factors could be attributed to the conflicting properties of DSD and agile development. Besides that, some new risk factors have been experienced by practitioners and need further exploration as their understanding will help the practitioners to act on time. Conclusion Organizations are adopting DAD for developing solutions that caters to the changing business needs, while utilizing the global talent. Conflicting properties of DSD and agile approach pose several risks for DAD. This study gives a comprehensive categorization of the risks faced by the practitioners in managing \{DAD\} projects and presents frequently used methods to reduce their impact. The work fills the yawning research void in this field. },
  keywords = {Distributed Agile Development (DAD), Agile software development (ASD), Distributed Software Development (DSD), Risk factor classification, Leavitt's' model, Risk management in distributed agile development },
  owner = {magsilva},
  timestamp = {2014.09.25}
}

@ARTICLE{Shull:2013,
  author = {Shull, Forrest},
  title = {A Lifetime Guarantee},
  crossref = {journal:ieee:software},
  volume = {30},
  number = {6},
  month = nov # {--} # dec,
  year = {2013},
  pages = {4--8},
  doi = {10.1109/MS.2013.119},
  abstract = {IEEE Software editor-in-chief Forrest Shull discusses the software sustainability and his interview with Girish Seshagiri, the CEO of AIS, an organization that offers "firm fixed-price contracting with performance guarantees, including a lifetime warranty on software defects" in government contracts. In addition, he discusses the best paper award at the 21st Annual IEEE International Requirements Engineering Conference and the best research paper award at the Agile Conference. The first Web extra at http://youtu.be/L1XN0R4koRk is an audio interview highlighting IEEE Software editor in chief Forrest Shull's discussion with Girish Seshagiri, the CEO of AIS, about the organization's philosophy of offering "firm fixed-price contracting with performance guarantees, including a lifetime warranty on software defects" in government contracts. The second Web extra at http://youtu.be/iFsZlrhSM9E is the complete audio interview in which IEEE Software editor in chief Forrest Shull's speaks with Girish Seshagiri, the CEO of AIS, about the organization's philosophy of offering "firm fixed-price contracting with performance guarantees, including a lifetime warranty on software defects" in government contracts.},
  quotes = {Software sustainability -- the capability of software systems to endure different types of change over their lifetimes. What are the trade-offs between paying for extra robustness and software quality up front versus handling changes on an as-needed basis after delivery?},
  timestamp = {2014.01.13}
}

@ARTICLE{Shull:2012a,
  author = {Shull, Forrest},
  title = {A Brave New World of Testing? An Interview with Google's James Whittaker},
  crossref = {journal:ieee:software},
  volume = {29},
  number = {2},
  month = mar # {--} # apr,
  year = {2012},
  pages = {4--7},
  doi = {10.1109/MS.2012.23},
  abstract = {The increasing pervasiveness of cloud computing is changing the state of the practice in software testing. In an interview with James Whittaker, an engineering director at Google, editor in chief Forrest Shull explores some of the important trends in cloud computing and their implications. The conversation covers key technology changes, such as more pervasive access to monitoring frameworks, the ability to aggregate and act on feedback directly from massive user communities (the "crowdsourcing" of quality assurance), and the ability to know the exact machine configuration when bugs are discovered. All of these changes are having concrete impacts on which skills are important and which no longer so for software testers. An accompanying audio interview provides a complete recording of the conversation and more details on points such as privacy testing.},
  keywords = {cloud computing , functional testing , privacy , quality assurance , software engineering training , software testing}
}

@ARTICLE{Shull:2012b,
  author = {Shull, Forrest},
  title = {Research 2.0?},
  crossref = {journal:ieee:software},
  volume = {29},
  number = {6},
  month = nov # {--} # dec,
  year = {2012},
  pages = {4 -8},
  doi = {10.1109/MS.2012.164},
  abstract = {IEEE Software Editor in Chief Forrest Shull discuss the state of research in software engineering, focusing on empirical software engineering (ESE) and the expanded goal question metric strategies (GQM+Strategies) to tie specific measurements to the technical goals that they address. He also welcomes Girish Suryanarayana as the magazine's newest member of its Industry Advisory Board.},
  keywords = {empirical software engineering , goal-question-metric , gqm , metrics , research , software , systems , tdd , test-driven development}
}

@INPROCEEDINGS{Shull-etal:2002,
  author = {F. Shull and V. Basili and B. Boehm and A. W. Brown and P. Costa and M. Lindvall and D. Port and I. Rus and R. Tesoriero and M. Zelkowitz},
  title = {What we have learned about fighting defects},
  crossref = {proceedings:metrics:2002},
  pages = {249--258},
  doi = {10.1109/METRIC.2002.1011343},
  abstract = {The Center for Empirically Based Software Engineering helps improve software development by providing guidelines for selecting development techniques, recommending areas for further research, and supporting software engineering education. A central activity toward achieving this goal has been the running of "e- Workshops" that capture expert knowledge with a minimum of overhead effort to formulate heuristics on a particular topic. The resulting heuristics are a useful summary of the current state of knowledge in an area based on expert opinion. This paper discusses the results to date of a series of e-Workshops on software defect reduction. The original discussion items are presented along with an encapsulated summary of the expert discussion. The reformulated heuristics can be useful both to researchers (for pointing out gaps in the current state of the knowledge requiring further investigation) and to practitioners (for benchmarking or setting expectations about development practices).}
}

@ARTICLE{Shull-etal:2010,
  author = {Shull, F. and Melnik, G. and Turhan, B. and Layman, L. and Diep, M. and Erdogmus, H.},
  title = {What Do We Know about Test-Driven Development?},
  crossref = {journal:ieee:software},
  volume = {27},
  number = {6},
  month = nov,
  year = {2010},
  pages = {16-19},
  doi = {10.1109/MS.2010.152},
  abstract = {What if someone argued that one of your basic conceptions about how to develop software was misguided? What would it take to change your mind? That's essentially the dilemma faced by advocates of test-driven development (TDD). The TDD paradigm argues that the basic cycle of developing code and then testing it to make sure it does what it's supposed to do-something drilled into most of us from the time we began learning software development- isn't the most effective approach. TDD replaces the traditional "code then test" cycle. First, you develop test cases for a small increment of functionality; then you write code that makes those tests run correctly. After each increment, you refactor the code to maintain code quality.},
  keywords = {code development;code quality;code refactoring;software development;test driven development;program testing;software maintenance;software quality;},
  issn = {0740-7459},
  journal = {IEEE Software}
}

@ARTICLE{Shull-etal:2004,
  author = {F. Shull and M. Mendonça and V. Basili and J. Carver and J. C. Maldonado and S. Fabbri and G. Travassos and M. Ferreira},
  title = {Knowledge-Sharing Issues in Experimental Software Engineering},
  crossref = {journal:springer:ese},
  volume = {9},
  number = {1-2},
  month = mar,
  year = {2004},
  pages = {111--137},
  doi = {10.1023/B:EMSE.0000013516.80487.33},
  abstract = {Recently the awareness of the importance of replicating studies has been growing in the empirical software engineering community. The results of any one study cannot simply be extrapolated to all environments because there are many uncontrollable sources of variation between different environments. In our work, we have reasoned that the availability of laboratory packages for experiments can encourage better replications and complementary studies. However, even with effectively specified laboratory packages, transfer of experimental know-how can still be difficult. In this paper, we discuss the collaboration structures we have been using in the Readers' Project, a bilateral project supported by the Brazilian and American national science agencies that is investigating replications and transfer of experimental know-how issues. In particular, we discuss how these structures map to the Nonaka-Takeuchi knowledge sharing model, a well-known paradigm used in the knowledge management literature. We describe an instantiation of the Nonaka-Takeuchi Model for software engineering experimentation, establishing a framework for discussing knowledge sharing issues related to experimental software engineering. We use two replications to illustrate some of the knowledge sharing issues we have faced and discuss the mechanisms we are using to tackle those issues in Readers' Project.},
  lang = {en}
}

@ARTICLE{Sicilia-etal:2011,
  author = {Sicilia, Miguel-Ángel and Lytras, Miltiadis D. and Sánchez-Alonso, Salvador and García-Barriocanal, Elena and Zapata-Ros, Miguel},
  title = {Modeling instructional-design theories with ontologies: Using methods to check, generate and search learning designs},
  crossref = {journal:elsevier:chb},
  volume = {27},
  number = {4},
  month = jul,
  year = {2011},
  pages = {1389--1398},
  doi = {10.1016/j.chb.2010.07.040},
  abstract = {Instructional theories have been defined as practice-oriented theories offering explicit guidance on how to help people learn that offer situation-specific methods. The descriptions of many instructional theories include recommendations or rules that can be subject to modeling in formal knowledge representation languages. Further, recent work in the application of ontologies to learning technology has made openly available formal representation schemas for activity sequences and learning resource descriptions, based on evolving standards. Combining these with the representation of instructional-design theories provides a framework for developing rule-based, instructional theory-aware support tools for different practical purposes. These purposes include (partially) checking the compatibility of learning designs with instructional theories in authoring tools, using methods as query criteria in learning resource repositories, and the generation of tentative learning activities for some given instructional design methods. This paper addresses the main epistemological issues and the representation of the main elements of instructional models using the formal ontology language OWL, which can be used in conjunction with the SWRL rule language for the purposes described. Following existing conceptualizations, methods and conditions are modeled in a generic way able of capturing a plurality of views.},
  keywords = {IMS LD, Instructional design, Learning objects, OWL, Ontologies, SWRL}
}

@ARTICLE{Silberman-etal:2010,
  author = {Silberman, M. Six and Irani, Lilly and Ross, Joel},
  title = {Ethics and tactics of professional crowdwork},
  crossref = {journal:acm:xrds},
  volume = {17},
  number = {2},
  month = dec,
  year = {2010},
  pages = {39--43},
  doi = {10.1145/1869086.1869100},
  abstract = {Paid crowd workers are not just an API call---but all too often, they are treated like one.}
}

@INPROCEEDINGS{Silva-etal:2011b,
  author = {Cristiane Carneiro da Silva and Elisa Yumi Nakagawa and Thiago Bianchi and José Carlos Maldonado},
  title = {Uso de Metodologias e Ferramentas de Engenharia de Software na Documentação do Sistema Memória Virtual},
  crossref = {proceedings:siicusp:2011},
  pages = {1--1}
}

@INPROCEEDINGS{Silva-etal:2011a,
  author = {Francisco Miguel da Silva and Francisco Milton Mendes Neto and Aquiles Medeiros Filgueira Burlamaqui and Alex Lima Silva and Jefferson Bruno Oliveira Lessa},
  title = {{T-SCORM}: Uma Extensão do Padrão SCORM para Apoiar o Projeto de Conteúdos Educacionais para t-Learning},
  crossref = {proceedings:sbie:2011},
  pages = {274--283},
  abstract = {A TV Digital Interativa (TVDi) tem facilitado e ampliado a comunicação e inte- ração na aquisição de conhecimento, entretenimento e lazer no contexto de Ensino a Distân- cia (EaD). Esse novo contexto de aprendizagem e ensino tem sido chamado de t-Learning. Nesse contexto, os Objetos de Aprendizagem (OAs) tem um importante papel para ajudar no desenvolvimento de cursos eletrônicos. Devido ao rápido progresso do e-Learning, alguns esforços de padronização surgiram para permitir a reusabilidade de conteúdos educacionais e a interoperabilidade entre sistemas, dentre eles temos o Sharable Content Object Reference Model (SCORM). Assim, o foco principal deste trabalho é apresentar uma extensão do SCORM adaptando-o de forma que melhore o suporte para a busca e navegação de OAs com conteúdos educacionais para a t-Learning. Isso será feito através de uma ferramenta de autoria chamada T-SCORM ADAPTER a qual permitirá aplicar esta extensão de forma rápida e eficiente.},
  abstract-en = {The Interactive Digital Television (iDTV) has facilitated and expanded the communication and interaction in activities of knowledge acquisitions, entertainment and recreation in Distance Learning field. This new way of teaching and learning has been called t-Learning. In this context, the Learning Objects (LOs) have an important role to assist in the electronic courses' development. Due the fast progress of e-Learning, some efforts to standardization have appeared in order to enable the reusability of educational contents and interoperability among systems, and one of these standards is the Sharable Content Object Reference Model (SCORM). Therefore, the main goal of this work is to present an extension of SCORM aiming to adapt it in order to improve the search and navigation of LOs with educational content for t-Learning. That will be done through an authoring tool named T-SCORM ADAPTER, which will be able to apply this extension in a fast and efficient way.},
  timestamp = {2012.02.10}
}

@INPROCEEDINGS{Silva-etal:2004,
  author = {Silva, Heron V. O. and Rodrigues, Rogério F. and Soares, Luiz Fernando G. and Muchaluat Saade, Débora C.},
  title = {{NCL} 2.0: integrating new concepts to {XML} modular languages},
  crossref = {proceedings:doceng:2004},
  pages = {188--197},
  doi = {10.1145/1030397.1030433},
  abstract = {This paper presents the main new features of Nested Context Language (NCL) version 2.0. NCL 2.0 is a modular and declarative hypermedia language, whose modules can be combined to other languages, such as SMIL, to provide new facilities. Among the NCL 2.0 new features, we can highlight the support for handling hypermedia relations as first-class entities, through the definition of hypermedia connectors, and the possibility of specifying any semantics for a hypermedia composition, using the concept of composition templates. Another important goal of this paper is to describe a framework to facilitate the development of NCL parsing and processing tools. Based on this framework, the paper comments several implemented compilers, which allow, for instance, the conversion of NCL documents into SMIL specifications.},
  keywords = {NCL, SMIL, XConnector, XTemplate, composition template, framework for parsing and processing XML, hypermedia connector}
}

@INPROCEEDINGS{Silva-etal:2012,
  author = {Silva, José Teodoro and Gerosa, Marco Aurélio and Wiese, Igor and Ré, Reginaldo and Steinmacher, Igor},
  title = {An Extensible Service for Experts Recommendation on Distributed Software Development Projects},
  crossref = {proceedings:remidi:2012},
  pages = {18--21},
  doi = {10.1109/ICGSEW.2012.9},
  abstract = {A common challenge in Distributed software development (DSD) is the identification and ranking of experts that can provide help to team members on their tasks. This paper presents a survey conducted with distributed software developers to identify a set of requirements to improve collaboration among team members by providing experts location features. We submit an architecture that was proposed based on the survey results. Therefore, the developed architecture enables the addition of new mining and ranking methods in one search engine, also enabling the use of different ways to present the ranking.},
  keywords = {distributed software development, expert recommendation; architecture}
}

@INPROCEEDINGS{Silva,
  author = {L. F. Silva and J. C. S. P. Leite and K. K. Breitman},
  title = {Ensino de Engenharia de Software: Relato de Experiências},
  crossref = {proceedings:wei:2004}
}

@INPROCEEDINGS{silva-etal:2008:fees,
  author = {Marco Aurélio Graciotto Silva and Vanessa Araujo Borges and Ellen Francine Barbosa and José Carlos Maldonado},
  title = {Novas Tendências em Educação de Engenharia de Software: um Estudo de Caso no Domínio de Teste de Software},
  crossref = {proceedings:fees:2008},
  pages = {22-30},
  abstract = {Information dissemination, allied with new technologies, has changed the educational scenario, strengthening concepts that led to the building of new cognitive environments and improved the teaching and learning process. In this context, new educational perspective should be explored in the following years: distance learning, digital television, collaboration, and open content development. What are we doing to build this future? Researches related to educational content modeling and engineering process have shown the benefits of the systematic production of educational modules. Evidences, gathered at Software Testing undergraduation courses, have shown improvement in learners' performance. The upcoming digital television foster the specialization and creation of new methods, enacting the investigation of education under a new perspective, in the building of interactive, flexible, and reusable content, and leveraging the quality of educational modules.},
  keywords = {education, software engineering, educational modules, quality, digital television},
  abstract-en = {Information dissemination, allied with new technologies, has changed the educational scenario, strengthening concepts that led to the building of new cognitive environments and improved the teaching and learning process. In this context, new educational perspective should be explored in the following years: distance learning, digital television, collaboration, and open content development. What are we doing to build this future? Researches related to educational content modeling and engineering process have shown the benefits of the systematic production of educational modules. Evidences, gathered at Software Testing undergraduation courses, have shown improvement in learners' performance. The upcoming digital television foster the specialization and creation of new methods, enacting the investigation of education under a new perspective, in the building of interactive, flexible, and reusable content, and leveraging the quality of educational modules.},
  abstract-pt = {A disseminação de informação, aliada ao uso de novas tecnologias, tem alterado de forma significativa o cenário educacional. Assim, vivencia-se o fortalecimento de conceitos que favorecem a construção de novos ambientes cognitivos, capazes de contribuir para a melhoria da qualidade no processo de ensino e aprendizado. Dentro desse contexto, novas tendências e perspectivas de educação deverão ser exploradas nos próximos anos: educação à distância, televisão digital, colaboração e desenvolvimento de conteúdos abertos. O que estamos fazendo para construir este futuro? Pesquisas relacionadas à modelagem e ao processo de engenharia de conteúdos educacionais demonstram os benefícios da sistematização da produção de módulos educacionais. Aplicados em cursos de graduação, no domínio de Teste de Software, a qualidade dos módulos é evidenciada pelo melhor desempenho dos alunos. O advento da televisão digital instiga a especialização e criação de novos métodos, possibilitando explorar o ensino sob uma nova perspectiva, na construção de conteúdos interativos, flexíveis e reutilizáveis, e propiciando um novo incremento na qualidade dos módulos educacionais.},
  address = {Campinas, SP},
  booktitle = {Fórum de Educação em Engenharia de Software (FEES'08) / Simpósio Brasileiro de Engenharia de Software (SBES'08)},
  keywords-en = {education, software engineering, educational modules, quality, digital television},
  keywords-pt = {educação, engenharia de software, módulos educacionais, qualidade, televisão digital},
  month = oct,
  timestamp = {2008.10.05},
  title-pt = {Novas tendências em educação de Engenharia de Software: um estudo de caso no domínio de Teste de Software},
  url = {http://fees.inf.puc-rio.br/FEESArtigos/FEES08/silva.pdf},
  year = {2008}
}

@INPROCEEDINGS{Silva-Fortes:2006,
  author = {Marco Aurélio Graciotto Silva and Renata Pontin de Mattos Fortes},
  title = {Uma ferramenta Web colaborativa para apoiar a engenharia de requisitos em software livre},
  crossref = {proceedings:std:icmc:2006},
  pages = {1-12},
  abstract = {Requirement engineering is a second-class citizen within free software projects development when facing the current state of art. However, free software is acknowledged as a high quality product, status that would be impossible to achieve if its user's requirements were not satisfied. Recent researches about free software development processes state that free software requirements are publicly asserted after the code development, depending upon the developer?s abilities for a correct elicitation, analysis and specification of the requirements. However, there is a constant concern about documentating the source code but not the requirements. One reason is that there isn't a suitable tool to register those requirements and make them public, requiring the developers to use plain text files or web pages, whose difficult management hinders the constant information updating required by the process. A possible solution to the problem is the use of web enabled agile and collaborative edition tools, allowing fast documentation updates by any stakeholder. The Wiki/RE provides an environment that satisfies those needs, along with others requirements desired for a requirement management tool. The Wiki/RE, tool developed under this work, is a wiki that supports the collaborative development of requirements hyperdocuments, supporting the management and quality assessment of the requirements document.},
  keywords = {Requirement engineering, free software, wiki},
  address = {São Carlos, Brasil},
  owner = {magsilva},
  school = {Universidade de São Paulo},
  timestamp = {2006.09.28}
}

@INPROCEEDINGS{silva:2003,
  author = {Marco Aurélio Graciotto Silva and Renata Pontin de Mattos Fortes},
  title = {Processo de Engenharia de Requisitos com um Apoio de Hiperdocumentos},
  crossref = {procedings:sbes-wtes:2003},
  pages = {65-70},
  abstract = {A integração de diversas técnicas de engenharia de requisitos, conciliadas à comunicação eficaz com as pessoas envolvidas no processo, engenheiros e stakeholders, é um fator importante, porém não trivial, a ser considerado na engenharia de software. Uma abordagem para tratar este problema é a utilização de sistemas hipermídia abertos, possibilitando a criação de hiperdocumentos que sirvam de elo de ligação entre os diversos artefatos e sejam sendo explorados de maneiras adequada ao seu público alvo. Neste trabalho investigam-se pontos a serem explorados neste relacionamento entre Engenharia de Requisitos e Sistemas Hipermídia.},
  abstract-pt = {A integração de diversas técnicas de engenharia de requisitos, conciliadas à comunicação eficaz com as pessoas envolvidas no processo, engenheiros e stakeholders, é um fator importante, porém não trivial, a ser considerado na engenharia de software. Uma abordagem para tratar este problema é a utilização de sistemas hipermídia abertos, possibilitando a criação de hiperdocumentos que sirvam de elo de ligação entre os diversos artefatos e sejam sendo explorados de maneiras adequada ao seu público alvo. Neste trabalho investigam-se pontos a serem explorados neste relacionamento entre Engenharia de Requisitos e Sistemas Hipermídia.},
  address = {Manaus, Brasil},
  booktitle = {VVIII Workshop de Teses em Engenharia de Software (WTES 2003), realizado no Simpósio Brasileiro de Engenharia de Software (SBES 2003)},
  lang = {pt},
  month = oct,
  owner = {magsilva},
  timestamp = {2008.07.30},
  title-pt = {Processo de Engenharia de Requisitos com um Apoio de Hiperdocumentos},
  year = {2003}
}

@ARTICLE{TorresSilva-etal:2001,
  author = {Viviane Torres da Silva and Carlos José Pereira de Lucena and Hugo Fuks},
  title = {{ContentNet}: a framework for the interoperability of educational content using standard {IMS}},
  crossref = {journal:elsevier:ce},
  volume = {37},
  number = {3--4},
  month = nov # {--} # dec,
  year = {2001},
  pages = {273 - 295},
  doi = {10.1016/S0360-1315(01)00052-5},
  abstract = {The World Wide Web arises as a means to facilitate communication and provide an easier user interface to obtain distributed data. The WWW was organized to allow information contained within it to be read by machines, without them needing to be concerned about interpreting the content. With the increase in the volume of information on the Web, finding, accessing and obtaining information from it became extremely difficult. Seeking a solution to this problem, the IMS project, a consortium of academic, commercial and governmental organizations, has been developing and proposing specifications to facilitate the growth and viability of online activities in the area of education. One of the most important activities of the project is the learning process on the Internet, with the possibility of interoperability between different environments to give support to Web-based education. Based on this project and on the need to re-use the contents already present in the Web-based education servers, this work presents an object-oriented framework that facilitates the description, localization and use of educational content available in servers compatible with the IMS project.},
  keywords = {Architectures for educational technology systems; Computer-mediated communication; Cooperative/collaborative learning; Distance education and telelearning; Distributed learning environments}
}

@ARTICLE{Simao-Maldonado:2002,
  author = {Adenilso da Silva Simão and José Carlos Maldonado},
  title = {MuDeL: a language and a system for describing and generating mutants},
  crossref = {journal:sbc:jbcs},
  volume = {8},
  number = {1},
  month = jul,
  year = {2002},
  pages = {73--86},
  abstract = {Mutation Testing is an approach for assessing the quality of a test case suite by analyzing its ability in distinguishing the product under test from a set of alternative products, the so-called mutants. The mutants are generated from the product under test by applying a set of mutant operators, which produce products with slight syntactical differences. The mutant operators are usually based on typical errors that occur during the software development and can be related to a fault model. In this paper, we propose a language -- named MuDeL, -- for describing mutant operators aiming not only at automating the mutant generation, but also at providing precision and formality to the operator descriptions. The language was designed using concepts that come from transformational and logical programming paradigms, as well as from context-free grammar theory. The language is illustrated with some examples. We also describe the mudelgen system, developed to support this language.},
  keywords = {testing; programming language; mutation testing; mutant generation}
}

@INCOLLECTION{Silveira-etal:2007,
  author = {Ismar Frango Silveira and Araújo Jr., Carlos Fernando de and Luiz Henrique Amaral and Oliveira, Ivan Carlos Alcântara de and Juliano Schimiguel and Manuel Fernández-Paradela Ledón and Maria Alica Grigas Varella Ferreira},
  title = {Granularity and Reusability of Learning Objects},
  chapter = {5},
  pages = {139-170},
  crossref = {Koohang-Harman:2007}
}

@INPROCEEDINGS{Duarte-etal:2013,
  author = {Silveira Duarte, A. and L'Erario, A. and Domingues, A. L. S. and Fabri, J. A.},
  title = {Proposal of a model to classify software residency environments},
  crossref = {proceedings:cisti:2013},
  pages = {1--6},
  abstract = {In Brazil the idea of residence in software (transposition from medical residency to the software production) has proliferated in recent years. Have all these environments a defined and institutionalized process, project quality management policies and them can be characterized as residence? This paper proposes a classifying environments model for residence in software, with the goal is answering this question. To delineate the model the authors used the theory that permeates the idea of residence in software and assumptions of the process evaluation methods (ISO / IEC 15504, SCAMPI and MA-MPS-BR - Evaluation Model of Brazilian Improvement Model Software Process). The model validation is characterized by a multiple case study, eight environments from north to south of Brazil were analyzed.},
  keywords = {software residency environments, residency, software process, software project}
}

@ARTICLE{Simao-etal:2009:CLSS,
  author = {Adenilso Simão and José Carlos Maldonado and Roberto da Silva Bigonha},
  title = {A transformational language for mutant description},
  crossref = {journal:elsevier:clss},
  volume = {35},
  number = {3},
  month = oct,
  year = {2009},
  pages = {322--339},
  doi = {10.1016/j.cl.2008.10.001},
  abstract = {Mutation testing has been used to assess the quality of test case suites by analyzing the ability in distinguishing the artifact under testing from a set of alternative artifacts, the so-called mutants. The mutants are generated from the artifact under testing by applying a set of mutant operators, which produce artifacts with simple syntactical differences. The mutant operators are usually based on typical errors that occur during the software development and can be related to a fault model. In this paper, we propose a language -- named MuDeL (MUtant DEfinition Language) -- for the definition of mutant operators, aiming not only at automating the mutant generation, but also at providing precision and formality to the operator definition. The proposed language is based on concepts from transformational and logical programming paradigms, as well as from context-free grammar theory. Denotational semantics formal framework is employed to define the semantics of the MuDeL language. We also describe a system -- named mudelgen -- developed to support the use of this language. An executable representation of the denotational semantics of the language is used to check the correctness of the implementation of mudelgen. At the very end, a mutant generator module is produced, which can be incorporated into a specific mutant tool/environment.},
  keywords = {mutation testing; transformation languages; logical languages; software testing; prototyping}
}

@ARTICLE{Simao-etal:2009:IET,
  author = {Simão, A. and Petrenko, A. and Maldonado, J. C.},
  title = {Comparing finite state machine test},
  crossref = {journal:iet:software},
  volume = {3},
  number = {2},
  month = apr,
  year = {2009},
  pages = {91--105},
  doi = {10.1049/iet-sen.2008.0018},
  abstract = {To plan testing activities, testers face the challenge of determining a strategy, including a test coverage criterion that offers an acceptable compromise between the available resources and test goals. Known theoretical properties of coverage criteria do not always help and, thus, empirical data are needed. The results of an experimental evaluation of several coverage criteria for finite state machines (FSMs) are presented, namely, state and transition coverage; initialisation fault and transition fault coverage. The first two criteria focus on FSM structure, whereas the other two on potential faults in FSM implementations. The authors elaborate a comparison approach that includes random generation of FSM, construction of an adequate test suite and test minimisation for each criterion to ensure that tests are obtained in a uniform way. The last step uses an improved greedy algorithm.}
}

@ARTICLE{Simon-Cutts:2012a,
  author = {Simon, Beth and Cutts, Quintin},
  title = {{CS} principles pilot at University of California, San Diego},
  crossref = {journal:acm:inroads},
  volume = {3},
  number = {2},
  month = jun,
  year = {2012},
  pages = {61--63},
  doi = {10.1145/2189835.2189854}
}

@ARTICLE{Simon-Cutts:2012b,
  author = {Simon, Beth and Cutts, Quintin},
  title = {How to implement a peer instruction-designed {CS} principles course},
  crossref = {journal:acm:inroads},
  volume = {3},
  number = {2},
  month = jun,
  year = {2012},
  pages = {72--74},
  doi = {10.1145/2189835.2189858},
  abstract = {The CS Principles curriculum framework includes explicit learning goals regarding student abilities in communication and collaboration. Computing majors need these skills. However, what kinds of activities support the development of these skills, especially in a large lecture course? This paper describes Peer Instruction---a pedagogy developed to support students in developing deep understanding in a lecture environment---and its use in the pilot offering of CS Principles in 2010-11 at the University of California at San Diego.},
  keywords = {CS principles, computer science education, pedagogy, peer instruction}
}

@ARTICLE{Simon-Cutts:2012c,
  author = {Simon, Beth and Cutts, Quintin},
  title = {Peer instruction: a teaching method to foster deep understanding},
  crossref = {journal:acm:cacm},
  volume = {55},
  number = {2},
  month = feb,
  year = {2012},
  pages = {27--29},
  doi = {10.1145/2076450.2076459},
  abstract = {How the computing education community can learn from physics education.}
}

@INPROCEEDINGS{Simon-etal:2010,
  author = {Simon, Beth and Kohanfars, Michael and Lee, Jeff and Tamayo, Karen and Cutts, Quintin},
  title = {Experience report: peer instruction in introductory computing},
  crossref = {proceedings:sigcse:2010},
  pages = {341--345},
  doi = {10.1145/1734263.1734381},
  abstract = {Peer Instruction (PI) is a pedagogical technique to increase engagement in lectures. Students answer a multiple choice question (MCQ) typically using clickers (hand-held remote devices with a minimum of 5 option buttons), discuss the question with their peers, and then answer the question again. In physics, PI has years of evidence of increased conceptual learning, as measured by the Force Concept Inventory (FCI)[7]. In this experience report, we describe how PI was applied in CS1 and CS1.5 courses teaching Java. We identify specifics of the standard PI model which were adopted, adapted, or discarded for use in introductory computing, describe the process involved for the instructor, give examples of the types of questions asked of students, report on students' performance in answering these questions, reflect on the value for the instructor, and report the attitudes and opinions of the students. We conclude with observations, advice and suggested improvements.},
  keywords = {active learning, classroom response, clickers, cs1, peer instruction, prs}
}

@ARTICLE{Singh-Holt:2013,
  author = {Vandana Singh and Lila Holt},
  title = {Learning and best practices for learning in open-source software communities },
  crossref = {journal:elsevier:ce},
  volume = {63},
  month = apr,
  year = {2013},
  pages = {98--108},
  doi = {10.1016/j.compedu.2012.12.002},
  abstract = {This research is about participants who use open-source software (OSS) discussion forums for learning. Learning in online communities of education as well as non-education-related online communities has been studied under the lens of social learning theory and situated learning for a long time. In this research, we draw parallels among these two types of communities and explore what can be learned from open-source software communities about online learning. Thematic network analysis was used to code the qualitative data from the open-ended questions in the survey and the interviews. The results indicate that learning in online open-source software communities encompasses much more than just learning about the software being discussed. 283 Open-source forum participants were surveyed, and 21 were interviewed to develop an understanding of the challenges to learning in these communities as well as to identify the practices that promote learning. Identifying these practices helps to understand online learning and enables the integration of best practices into online education. },
  keywords = {Computer-mediated communication, Cooperative/collaborative learning, Interactive learning environments, Learning communities, Teaching/learning strategies }
}

@ARTICLE{Sinha-Jain:2013,
  author = {Sinha, Atish P. and Jain, Hemant},
  title = {Ease of Reuse: An Empirical Comparison of Components and Objects},
  crossref = {journal:ieee:software},
  volume = {30},
  number = {5},
  month = sep # {--} # oct,
  year = {2013},
  pages = {70-75},
  doi = {10.1109/MS.2012.131},
  abstract = {Component-based development is a relatively new paradigm for software development, compared to more established approaches such as object-oriented analysis and design. The authors conducted a study to examine the ease-of-reuse perceptions of analysts in modeling business systems using a library of components versus a library of objects. A survey of the IT professionals who participated in the study showed that perceived components to be much easier to reuse than objects. Users also expressed significantly higher satisfaction with components and, by a large majority, a preference for reusing components to reusing objects.},
  keywords = {Decision support systems;Libraries;Object oriented programming;Software development;Software reusability;class library;component library;component-based development;software reuse;usability},
  timestamp = {2013-09-08}
}

@INPROCEEDINGS{Sinha-etal:2011,
  author = {Sinha, Vibha Singhal and Mani, Senthil and Sinha, Saurabh},
  title = {Entering the circle of trust: developer initiation as committers in open-source projects},
  crossref = {proceedings:msr:2011},
  pages = {133--142},
  doi = {10.1145/1985441.1985462},
  abstract = {The success of an open-source project depends to a large degree on the proactive and constructive participation by the developer community. An important role that developers play in a project is that of a code committer. However, code-commit privilege is typically restricted to the core group of a project. In this paper, we study the phenomenon of the induction of external developers as code committers. The trustworthiness of an external developer is one of the key factors that determines the granting of commit privileges. Therefore, we formulate different hypotheses to explain how the trust is established in practice. To investigate our hypotheses, we developed an automated approach based on mining code repositories and bug-tracking systems. We implemented the approach and performed an empirical study, using the Eclipse projects, to test the hypotheses. Our results indicate that, most frequently, developers establish trust and credibility in a project by contributing to the project in a non-committer role. Moreover, the employing organization of a developer is another factor--although a less significant one--that influences trust.},
  keywords = {code committer, developer roles, mining bug repository, mining code repository, open-source software}
}

@INPROCEEDINGS{Sipser:1992,
  author = {Sipser, Michael},
  title = {The history and status of the {P} versus {NP} question},
  crossref = {proceedings:stoc:1992},
  pages = {603--618},
  doi = {10.1145/129712.129771}
}

@INPROCEEDINGS{Skoglund:2009:RSS:2227040.2227044,
  author = {Skoglund, Mats and Runeson, Per},
  title = {Reference-based search strategies in systematic reviews},
  crossref = {proceedings:ease:2009},
  pages = {31--40},
  abstract = {In systematic reviews, the number of articles found by search strings tend to be very large. In order to limit the number of articles to handle manually, we investigate a search strategy based on references between papers. We first identify a ``take-off paper'' which is the starting point for the search and then we follow the references from that paper. We also investigate ``cardinal papers'', i.e. papers that are referenced by many authors, and let the references to those papers guide the selection in the systematic review. We evaluate the search strategies on three published systematic reviews. The results vary greatly between the three studied systematic reviews, from 88% reduction to 92% extension of the original paper set.}
}

@INBOOK{Sloep-etal:2005,
  chapter = {8},
  pages = {139-160},
  title = {Basic Design Procedures for E-Learning Courses},
  author = {Peter Sloep and Hans Hummel and Jocelyn Manderveld},
  crossref = {Koper-Tattersall:2005}
}

@ARTICLE{Smith:1990,
  author = {Alan Jay Smith},
  title = {The Task of the Referee},
  crossref = {journal:ieee:computer},
  volume = {23},
  number = {4},
  month = apr,
  year = {1990},
  pages = {65--71},
  doi = {10.1109/2.55470},
  abstract = {Computer researchers have a professional obligation to referee the work of others. This article tells you how to evaluate a paper and write a report using common standards and procedures. It focuses on research papers in applied areas of computer science and engineering, such as systems architecture, hardware, communications, and performance evaluation, but most of the discussion is generally applicable; separate sections consider research proposals and survey and tutorial papers.}
}

@INPROCEEDINGS{Smith-etal:2008,
  author = {Smith, Ben and Shin, Yonghee and Williams, Laurie},
  title = {Proposing {SQL} statement coverage metrics},
  crossref = {proceedings:sess:2008},
  pages = {49--56},
  doi = {10.1145/1370905.1370912},
  abstract = {An increasing number of cyber attacks are occurring at the application layer when attackers use malicious input. These input validation vulnerabilities can be exploited by (among others) SQL injection, cross site scripting, and buffer overflow attacks. Statement coverage and similar test adequacy metrics have historically been used to assess the level of functional and unit testing which has been performed on an application. However, these currently-available metrics do not highlight how well the system protects itself through validation. In this paper, we propose two SQL injection input validation testing adequacy metrics: target statement coverage and input variable coverage. A test suite which satisfies both adequacy criteria can be leveraged as a solid foundation for input validation scanning with a blacklist. To determine whether it is feasible to calculate values for our two metrics, we perform a case study on a web healthcare application and discuss some issues in implementation we have encountered. We find that the web healthcare application scored 96.7% target statement coverage and 98.5% input variable coverage.},
  keywords = {SQL, SQL injection, attack, coverage criteria, security, test, threat}
}

@INPROCEEDINGS{Smith-Williams:2007,
  author = {Smith, Ben H. and Williams, Laurie},
  title = {An Empirical Evaluation of the {MuJava} Mutation Operators},
  crossref = {proceedings:taicpart-mutation:2007},
  pages = {193--202},
  doi = {10.1109/TAIC.PART.2007.12},
  abstract = {Mutation testing is used to assess the fault-finding effectiveness of a test suite. Information provided by mutation testing can also be used to guide the creation of additional valuable tests and/or to reveal faults in the implementation code. However, concerns about the time efficiency of mutation testing may prohibit its widespread, practical use. We conducted an empirical study using the MuClipse automated mutation testing plug-in for Eclipse on the back end of a small web-based application. The first objective of our study was to categorize the behavior of the mutants generated by selected mutation operators during successive attempts to kill the mutants. The results of this categorization can be used to inform developers in their mutant operator selection to improve the efficiency and effectiveness of their mutation testing. The second outcome of our study identified patterns in the implementation code that remained untested after attempting to kill all mutants.}
}

@ARTICLE{Smith-Williams:2009:ese,
  author = {Smith, Ben H. and Williams, Laurie},
  title = {On guiding the augmentation of an automated test suite via mutation analysis},
  crossref = {journal:springer:ese},
  volume = {14},
  number = {3},
  month = jun,
  year = {2009},
  pages = {341--369},
  doi = {10.1007/s10664-008-9083-7},
  abstract = {Mutation testing has traditionally been used as a defect injection technique to assess the effectiveness of a test suite as represented by a 'mutation score.' Recently, mutation testing tools have become more efficient, and industrial usage of mutation analysis is experiencing growth. Mutation analysis entails adding or modifying test cases until the test suite is sufficient to detect as many mutants as possible and the mutation score is satisfactory. The augmented test suite resulting from mutation analysis may reveal latent faults and provides a stronger test suite to detect future errors which might be injected. Software engineers often look for guidance on how to augment their test suite using information provided by line and/or branch coverage tools. As the use of mutation analysis grows, software engineers will want to know how the emerging technique compares with and/or complements coverage analysis for guiding the augmentation of an automated test suite. Additionally, software engineers can benefit from an enhanced understanding of efficient mutation analysis techniques. To address these needs for additional information about mutation analysis, we conducted an empirical study of the use of mutation analysis on two open source projects. Our results indicate that a focused effort on increasing mutation score leads to a corresponding increase in line and branch coverage to the point that line coverage, branch coverage and mutation score reach a maximum but leave some types of code structures uncovered. Mutation analysis guides the creation of additional 'common programmer error' tests beyond those written to increase line and branch coverage. We also found that 74% of our chosen set of mutation operators is useful, on average, for producing new tests. The remaining 26% of mutation operators did not produce new test cases because their mutants were immediately detected by the initial test suite, indirectly detected by test suites we added to detect other mutants, or were not able to be detected by any test.},
  keywords = {Mutation testing; Line coverage; Fault injection; Empirical effectiveness; Test case augmentation; Mutation analysis; Mutation testing tool; Statement coverage; Test adequacy; Web application; Open source; Unit testing}
}

@ARTICLE{Smith-Williams:2009:jss,
  author = {Ben H. Smith and Laurie Williams},
  title = {Should software testers use mutation analysis to augment a test set?},
  crossref = {journal:elsevier:jss},
  volume = {82},
  number = {11},
  month = nov,
  year = {2009},
  pages = {1819--1832},
  doi = {10.1016/j.jss.2009.06.031},
  abstract = {Mutation testing has historically been used to assess the fault-finding effectiveness of a test suite or other verification technique. Mutation analysis, rather, entails augmenting a test suite to detect all killable mutants. Concerns about the time efficiency of mutation analysis may prohibit its widespread, practical use. The goal of our research is to assess the effectiveness of the mutation analysis process when used by software testers to augment a test suite to obtain higher statement coverage scores. We conducted two empirical studies and have shown that mutation analysis can be used by software testers to effectively produce new test cases and to improve statement coverage scores in a feasible amount of time. Additionally, we find that our user study participants view mutation analysis as an effective but relatively expensive technique for writing new test cases. Finally, we have shown that the choice of mutation tool and operator set can play an important role in determining how efficient mutation analysis is for producing new test cases.},
  keywords = {Mutation testing, Empirical effectiveness, User study, Mutation analysis, Test adequacy, Web application, Open source, Unit testing, Mutation testing tool}
}

@INPROCEEDINGS{Smith-etal:2014,
  author = {Smith, Therese Mary and McCartney, Robert and Gokhale, Swapna S. and Kaczmarczyk, Lisa C.},
  title = {Selecting Open Source Software Projects to Teach Software Engineering},
  crossref = {proceedings:sigcse:2014},
  pages = {397--402},
  doi = {10.1145/2538862.2538932},
  abstract = {Aspiring software engineers must be able to comprehend and evolve legacy code, which is challenging because the code may be poorly documented, ill structured, and lacking in human support. These challenges of understanding and evolving existing code can be illustrated in academic settings by leveraging the rich and varied volume of Open Source Software (OSS) code. To teach SE with OSS, however, it is necessary to select uniform projects of appropriate size and complexity. This paper reports on our search for suitable OSS projects to teach an introductory SE course with a focus on maintenance and evolution. The search turned out to be quite labor intensive and cumbersome, contrary to our expectations that it would be quick and simple. The chosen projects successfully demonstrated the maintenance challenges, highlighting the promise of using OSS. The burden of selecting projects, however, may impede widespread integration of OSS into SE and other computing courses.},
  keywords = {maintenance, open source, program comprehension, software engineering}
}

@ARTICLE{Snyder:2013,
  author = {Snyder, Lawrence},
  title = {An Interview with Hadi Partovi},
  crossref = {journal:acm:cacm},
  volume = {56},
  number = {9},
  month = sep,
  year = {2013},
  pages = {41--45},
  doi = {10.1145/2500133},
  abstract = {The Code.org founder discusses his first program, inspirations, and "seizing the day."}
}

@ARTICLE{Snyder:2012,
  author = {Snyder, Lawrence},
  title = {{CS} principles pilot at University of Washington},
  crossref = {journal:acm:inroads},
  volume = {3},
  number = {2},
  month = jun,
  year = {2012},
  pages = {66--68},
  doi = {10.1145/2189835.2189856}
}

@ARTICLE{Snyder-etal:2012a,
  author = {Snyder, Lawrence and Barnes, Tiffany and Garcia, Dan and Paul, Jody and Simon, Beth},
  title = {The first five computer science principles pilots: summary and comparisons},
  crossref = {journal:acm:inroads},
  volume = {3},
  number = {2},
  month = jun,
  year = {2012},
  pages = {54--57},
  doi = {10.1145/2189835.2189852}
}

@ARTICLE{Snyder-etal:2012b,
  author = {Snyder, Lawrence and Barnes, Tiffany and Garcia, Dan and Paul, Jody and Simon, Beth},
  title = {Analysis},
  crossref = {journal:acm:inroads},
  volume = {3},
  number = {2},
  month = jun,
  year = {2012},
  pages = {69--71},
  doi = {10.1145/2189835.2189857},
  abstract = {The five pilots were taught "under a microscope." Extensive surveying, weekly conference calls, instructor summaries and other methods were used to gather data to understand how well the courses were succeeding. The final report on the pilot 1 courses [6] gives complete data. For the purposes on this article, a few selected graphs seem most useful.},
  keywords = {CS principles, computer science education, pedagogy}
}

@ARTICLE{Soares-Vergilio:2004,
  author = {Soares, Inali Wisniewski and Vergilio, Silvia Regina},
  title = {Mutation Analysis and Constraint-Based Criteria: Results from an Empirical Evaluation in the Context of Software Testing},
  crossref = {journal:springer:jet},
  volume = {20},
  number = {4},
  month = aug,
  year = {2004},
  pages = {439--445},
  doi = {10.1023/B:JETT.0000039611.63828.bf},
  abstract = {Several software testing criteria have been proposed during last years with the goal of aiming the test set generation and revealing many faults as possible. They are considered complementary because can reveal different kind of faults and are based on different principles. For example, structural criteria use the internal structure of the program for deriving test cases; Mutation Analysis is a fault-based criterion; and Constraint Based Criteria use constraints to be satisfied during the program execution. Because of this, some questions can be posed, such as: ``What criterion should be used or be first applied?''. Many research works compare criteria with the goal of answering these questions. However, some criteria as Mutation Analysis and Constraint Based Criteria are theoretically incomparable and only empirical studies can point out the relation between them. This work presents results from an empirical evaluation of Mutation Analysis and All-Constrained-Potential-Uses criterion considering the factors: cost (number of test cases), efficacy (number of revealed faults) and strength (difficulty of satisfying a criterion, given that another one has been satisfied). The obtained results show an empirical relation, which is used to propose a strategy for application of different testing criteria.},
  keywords = {structural testing criteria; constraint-based testing; mutation testing}
}

@ARTICLE{Soares-etal:2010b,
  author = {Luiz Fernando Gomes Soares and Marcelo Ferreira Moreno and Romualdo Monteiro de Resende Costa and Marcio Ferreira Moreno},
  title = {Towards the convergence of digital {TV} systems},
  crossref = {journal:springer:jisa},
  volume = {1},
  number = {1},
  month = may,
  year = {2010},
  pages = {69--79},
  doi = {10.1007/s13174-010-0002-y},
  abstract = {To allow producing digital TV applications independently from receiver's hardware and operating system, and also to provide better support to application designs, middleware layer is introduced in digital TV system architectures. At first, middleware systems were developed aiming at specific transport platforms (IPTV, terrestrial DTV, etc.), offering support to services specifically designed for those platforms. However, the next generation of digital TV pulls all TV services present in all current platforms together into a single core of distributed services, as a result of the transport platforms convergence. In this hybrid TV, transport systems shall be concealed by the middleware to applications, as other operating system and hardware resources are hidden. This paper emphasizes the middleware natural role as key technology for this upcoming convergent digital TV, raising some requirements to be committed. NCL and Ginga-NCL features -- technologies recommended by ITU-T for IPTV services, and ISDB standards for terrestrial DTV -- are used as examples of some proposed solutions, as well as to illustrate some issues which deserve future research attention and new better results.},
  keywords = {Convergent digital TV; Middleware; Declarative languages; Ginga-NCL}
}

@ARTICLE{Soares-etal:2010,
  author = {L. F. G. Soares and M. F. Moreno and C. de Salles Soares Neto},
  title = {{Ginga-NCL}: Declarative middleware for multimedia {IPTV} services},
  crossref = {journal:ieee:communications},
  volume = {48},
  number = {6},
  month = jun,
  year = {2010},
  pages = {74--81},
  doi = {10.1109/MCOM.2010.5473867},
  abstract = {This article presents the innovative features of Ginga-NCL, an open middleware specification for multimedia IPTV services. Ginga-NCL relies on the Nested Context Language, a domain-specific declarative language targeting multimedia application authoring. As a glue language, NCL relates media objects in time and space without restricting or imposing any media content type, including media objects with imperative and declarative code written using other languages. Other NCL features include support for multidevice presentations, content adaptations, presentation adaptations, and advanced code reuse. Ginga-NCL allows NCL applications to be modified on the fly by means of live editing commands. Initially defined as the standard middleware for the Brazilian terrestrial DTV system, Ginga-NCL has recently become part of ISDB standards and an ITU-T Recommendation for IPTV services.}
}

@INPROCEEDINGS{Soares-etal:2006,
  author = {Luiz Fernando Gomes Soares and others},
  title = {{MAESTRO}: The Declarative Middleware Proposal for the {SBTVD}},
  crossref = {proceedings:euroitv:2006},
  pages = {1--4},
  abstract = {This paper deals with the declarative middleware proposal for the SBTVD. The middleware, named MAESTRO, is based on the Nested Context Language (NCL) and was implemented in C++ and also in Java. It can run alone in a set-top box, or integrated with a procedural middleware, or even run as an XLet.}
}

@ARTICLE{Soares-etal:2007,
  author = {Luiz Fernando Gomes Soares and Rogério Ferreira Rodrigues and Marcio Ferreira Moreno},
  title = {{Ginga-NCL}: the Declarative Environment of the {Brazilian} Digital {TV} System},
  crossref = {journal:sbc:jbcs},
  volume = {12},
  number = {4},
  month = mar,
  year = {2007},
  pages = {37--46},
  doi = {10.1590/S0104-65002007000100005},
  abstract = {As in all main terrestrial DTV Systems, the Brazilian middleware, named Ginga, supports both declarative applications (through its presentation, or declarative, environment Ginga-NCL) and procedural applications (through its execution, or procedural, environment Ginga-J). Since hybrid applications are common, either type of Ginga application may make use of facilities of both presentation and execution application environments. This paper focuses on the presentation environment Ginga-NCL. The main Brazilian inovations are then presented, regarding the Ginga architecture, the declarative NCL language specification, the editing commands for live application production, and the transport data structure.},
  keywords = {Ginga; NCL; middleware; declarative environment; digital TV}
}

@ARTICLE{GomesSoares-etal:2000,
  author = {Soares, Luiz Fernando G. and Rodrigues, Rogério F. and Muchaluat Saade, Débora C.},
  title = {Modeling, authoring and formatting hypermedia documents in the HyperProp system},
  crossref = {journal:springer:multimedia-systems},
  volume = {8},
  number = {2},
  month = mar,
  year = {2000},
  pages = {118--134},
  doi = {10.1007/s005300050155},
  abstract = {This paper discusses multimedia and hypermedia modeling, authoring and formatting tools, presenting the proposals of the HyperProp system and comparing them to related work. It also highlights several research challenges that still need to be addressed. Moreover, it stresses the importance of document logical structuring and considers the use of compositions in order to represent context relations, synchronization relations, derivation relations and task relations in hypermedia systems. It discusses temporal and spatial synchronization among multimedia objects and briefly presents the HyperProp graphical authoring and formatting tools. Integration between the proposed system and the WWW is also addressed.},
  issue = {2},
  keyword = {Computer Science}
}

@INPROCEEDINGS{GomesSoares-etal:2006,
  author = {Soares, Luiz Fernando Gomes and Rodrigues, Rogério Ferreira and de Resende Costa, Romualdo Monteiro},
  title = {Geração automática de frameworks para processamento de documentos {XML}},
  crossref = {proceedings:webmedia:2006},
  pages = {118--127},
  doi = {10.1145/1186595.1186611},
  abstract = {Este artigo apresenta um modelo em duas camadas para o desenvolvimento de processadores de linguagens baseadas em XML. Na primeira camada, um framework (processador genérico) é automaticamente gerado a partir do XML Schema de uma determinada linguagem (linguagem de entrada). Além de definir a estrutura de processamento, o processador genérico implementa métodos que podem ser reusados por implementações de processadores/compiladores para a linguagem de entrada selecionada. Na segunda camada, um processador para um modelo de dados de saída específico é implementado, reusando a estrutura e os métodos especificados pelo framework. Baseado nessa proposta, diversos conversores foram construídos para algumas das principais linguagens de autoria multimídia e hipermídia, incluindo NCL, SMIL e XMT-O (MPEG-4).},
  keywords = {middleware declarativo, NCL, SBTVD, TV digital, XML, framework, maestro},
  abstract-en = {This paper presents a two-layer model for the development of XML-based language compilers. In the first layer, a framework (generic compiler) is automatically generated from the XML Schema of a selected language (the input language). Besides defining the compiler structure, the generic compiler implements methods that can be reused by compilers of the selected input language. In the second layer, a compiler for a specific output data model is implemented, reusing the structure and methods specified by the framework. Based on this proposal, several compilers were built for some of the main hypermedia and multimedia authoring languages, including NCL, SMIL and XMT-O (MPEG-4).},
  title-en = {Automatic building of frameworks for processing XML documents}
}

@INPROCEEDINGS{SoaresdeOliveira-etal:2009,
  author = {Soares de Oliveira, Felipe and Mangueira, Jorge Andrade and de Souza Filho, Guido Lemos},
  title = {Architecture for production and collaboration of {TV} content on the Internet},
  crossref = {proceedings:webmedia:2009},
  pages = {1--4},
  doi = {10.1145/1858477.1858528},
  abstract = {The Internet has innovated in the electronic media and enhanced the capacity and access in the distribution of television content. In recent years has improved communication and services diffusion through its multitude of services. The television, way in which we know, has also evolved to add new formats and services, especially with arrival of digital TV. In this scenario of digital convergence, ease of collaboration, personalization and production TV content becomes really viable and accessible by the Internet. The approach of Web 2.0 expands the vision of the Internet as mere network of computers and services, to a view social, comprised of individuals who make up communities that are communicate and collaborate. Within this context, we present a Reference Architecture that unifies the concepts of television, journalism and Web 2.0.},
  keywords = {Social Media, Web 2.0, colaboração, multimídia}
}

@ARTICLE{SoaresNeto-etal:2010:JBCS,
  author = {Soares Neto, Carlos and Soares, Luiz and de Souza, Clarisse},
  title = {The {Nested Context Language} reuse features},
  crossref = {journal:springer:jbcs},
  volume = {16},
  number = {4},
  month = nov,
  year = {2010},
  pages = {229-245},
  doi = {10.1007/s13173-010-0017-z},
  abstract = {NCL, the standard declarative language of the Brazilian Terrestrial Digital TV System and ITU-T Recommendation for IPTV Services, provides a high level of reuse in the design of hypermedia applications. In this paper we detail how its design and conceptual model have succeeded in supporting reuse at a declarative level. NCL supports not only static but also running code reuse. It also allows for reuse inside applications, reuse between applications, and reuse of code spans stored in external libraries. For a specification language to promote reuse, however, it must have a number of usability merits. Aspects of NCL usability are thus analyzed with the Cognitive Dimensions of Notation framework.},
  keyword = {Computer Science}
}

@INPROCEEDINGS{SoaresNeto-Soares:2009,
  author = {Soares Neto, Carlos de Salles and Soares, Luiz Fernando Gomes},
  title = {Reuse and imports in {Nested Context Language}},
  crossref = {proceedings:webmedia:2009},
  pages = {1--8},
  doi = {10.1145/1858477.1858497},
  abstract = {NCL, standard declarative language of the Brazilian Terrestrial Digital TV System and ITU-T Recommendation for IPTV Services, provides a high level of reuse in the design of hypermedia applications. Not only static code reuse is possible, speeding up the application design time and minimizing the probability of programming errors by reusing already tested code spans, but also the reuse of code spans in execution, making easier the application understanding and the definition of relationships among application's components. Moreover, NCL allows not only the reuse inside the same application, but also the reuse among applications, besides the reuse of code spans stored in libraries external to the application. This paper discusses all the features provided by the language and implicitly proposes a methodology to take profit of these features.},
  keywords = {DTV, Ginga-NCL, NCL, SBTVD-T, middleware}
}

@ARTICLE{Sommerville:2013,
  author = {Ian Sommerville},
  title = {Teaching cloud computing: A software engineering perspective },
  crossref = {journal:elsevier:jss},
  volume = {86},
  number = {9},
  month = oct,
  year = {2013},
  pages = {2330--2332},
  doi = {10.1016/j.jss.2013.01.050},
  abstract = {This article discusses the teaching of cloud computing in a software engineering course. It suggests that all courses should have some material introducing students to cloud computing, that practical teaching should focus on Platform as a Service and that there is scope for a graduate course in cloud software engineering covering map-reduce, schema-free databases, service-oriented computing, security and compliance and design for resilience. },
  keywords = {Software engineering, Cloud computing, Education },
  url = {http://www.sciencedirect.com/science/article/pii/S0164121213000198},
  issn = {0164-1212},
  journal = {Journal of Systems and Software },
  timestamp = {2013-09-05}
}

@ARTICLE{Song-etal:2014,
  author = {Song, C. and Porter, A. and Foster, J.S.},
  title = {{iTree}: Efficiently Discovering High-Coverage Configurations Using Interaction Trees},
  crossref = {proceedings:ieee:tse},
  volume = {40},
  number = {3},
  month = mar,
  year = {2014},
  pages = {251--265},
  doi = {10.1109/TSE.2013.55},
  abstract = {Modern software systems are increasingly configurable. While this has many benefits, it also makes some software engineering tasks,such as software testing, much harder. This is because, in theory,unique errors could be hiding in any configuration, and, therefore,every configuration may need to undergo expensive testing. As this is generally infeasible, developers need cost-effective technique for selecting which specific configurations they will test. One popular selection approach is combinatorial interaction testing (CIT), where the developer selects a strength t and then computes a covering array (a set of configurations) in which all t-way combinations of configuration option settings appear at least once. In prior work, we demonstrated several limitations of the CIT approach. In particular, we found that a given system's effective configuration space -- the minimal set of configurations needed to achieve a specific goal -- could comprise only a tiny subset of the system's full configuration space. We also found that effective configuration space may not be well approximated by t-way covering arrays. Based on these insights we have developed an algorithm called interaction tree discovery (iTree). iTree is an iterative learning algorithm that efficiently searches for a small set of configurations that closely approximates a system's effective configuration space. On each iteration iTree tests the system on a small sample of carefully chosen configurations, monitors the system's behaviors, and then applies machine learning techniques to discover which combinations of option settings are potentially responsible for any newly observed behaviors. This information is used in the next iteration to pick a new sample of configu- ations that are likely to reveal further new behaviors. In prior work, we presented an initial version of iTree and performed an initial evaluation with promising results. This paper presents an improved iTree algorithm in greater detail. The key improvements are based on our use of composite proto-interactions -- a construct that improves iTree's ability to correctly learn key configuration option combinations, which in turn significantly improves iTree's running time, without sacrificing effectiveness. Finally, the paper presents a detailed evaluation of the improved iTree algorithm by comparing the coverage it achieves versus that of covering arrays and randomly generated configuration sets, including a significantly expanded scalability evaluation with the ~1M-LOC MySQL. Our results strongly suggest that the improved iTree algorithm is highly scalable and can identify a high-coverage test set of configurations more effectively than existing methods.},
  keywords = {Empirical software engineering, software configurations, software testing and analysis}
}

@INPROCEEDINGS{Sousa-etal:2009,
  author = {Sousa, S. F. and Balieiro, M. A. and dos R. Costa, J. M. and de Souza, C. R. B.},
  title = {Multiple Social Networks Analysis of {FLOSS} Projects using {Sargas}},
  crossref = {proceedings:hicss:2009},
  pages = {1--10},
  doi = {10.1109/HICSS.2009.316},
  abstract = {Due to their characteristics and claimed advantages, several researchers have been investigating free and open-source projects. Different aspects are being studied: for instance, what motivates developers to join FLOSS projects, the tools, processes and practices used in FLOSS projects, the evolution of FLOSS communities among other things. Researchers have studied collaboration and coordination of open source software developers using an approach known as social network analysis and have gained important insights about these projects. Most researchers, however, have not focused on the integrated study of these networks and, accordingly, in their interrelationships. This paper describes an approach and tool to combine multiple social networks to study the evolution of open-source projects. Our tool, named Sargas, allows comparison and visualization of different social networks at the same time. Initial results of our analysis can be used to extend the "onion-model" of open source participation.},
  keywords = {FLOSS projects , Sargas , multiple social networks analysis , open source software}
}

@INPROCEEDINGS{Borges-etal:2014,
  author = {de Sousa Borges, Simone and Durelli, Vinicius H. S. and Reis, Helena Macedo and Isotani, Seiji},
  title = {A Systematic Mapping on Gamification Applied to Education},
  crossref = {proceedings:sac:2014},
  pages = {216--222},
  doi = {10.1145/2554850.2554956},
  abstract = {Gamification is a term that refers to the use of game elements in non-game contexts with the goal of engaging people in a variety of tasks. There is a growing interest in gamification as well as its applications and implications in the field of Education since it provides an alternative to engage and motivate students during the process of learning. Despite this increasing interest, to the best of our knowledge, there are no studies that cover and classify the types of research being published and the most investigated topics in the area. As a first step towards bridging this gap, we carried out a systematic mapping to synthesize an overview of the area. We went through 357 papers on gamification. Among them, 48 were related to education and only 26 met the criteria for inclusion and exclusion of articles defined in this study. These 26 papers were selected and categorized according to their contribution. As a result, we provide an overview of the area. Such an overview suggests that most studies focus on investigating how gamification can be used to motivate students, improve their skills, and maximize learning.},
  keywords = {education, engagement, gamification, literature review, motivation, persuasive computing, survey, systematic mapping},
  owner = {magsilva},
  timestamp = {2014.08.29}
}

@INPROCEEDINGS{Celes-Souza:2007,
  author = {Clayson Sandro Francisco de Sousa Celes and Cidcley Teixeira de Souza},
  title = {Estilos Arquiteturais de Software na Construção de Objetos de Aprendizagem para a {TV} Digital Interativa},
  crossref = {proceedings:sbie:2007},
  pages = {290--299},
  abstract = {Atualmente, Objetos de Aprendizagem (OAs) têm se apresentado como uma tecnologia eficiente no auxílio à educação. Contudo, ainda é uma tarefa bastante complexa a construção de OAs a partir da seleção de um conjunto de recursos digitais ou do reuso de recursos a partir de outros OAs. Para facilitar essa tarefa, propomos nesse trabalho a adoção dos conceitos de estilos arquiteturais para o auxílio à construção de OAs para a TV Digital Interativa. Na nossa abordagem, realizamos a geração automática de código dos OAs na linguagem NCL a partir da descrição de um estilo, de modo a facilitar a construção de complexas estruturas hipermídia para fins educacionais.},
  abstract-en = {Nowadays, Learning Objects (LOs) have present themselves as an effective technology in educational aid. However, building LOs from the selection of a set of digital resources or from the reuse of resources of other LOs are still extremely complex tasks. To facilitate these tasks, we propose in the work the adoption of architectural style concepts to aid the construction of LOs to the Interactive TV. In our approach, we perform an automatic code generation of LOs in the NCL language from the description of a style, in a way to facilitate the construction of complex educational hypermedia structures.},
  address = {São Paulo, SP, Brasil},
  lang = {pt},
  publisher = {SBC},
  url = {http://www.br-ie.org/pub/index.php/sbie/article/view/578}
}

@INPROCEEDINGS{Monteiro-etal:2009,
  author = {Bruno de Sousa Monteiro and Fernando da Fonseca de Souza and Alex Sandro Gomes},
  title = {Amadeus-TV: Portal Educacional na TV Digital Integrado a um Sistema de Gestão de Aprendizado},
  crossref = {proceedings:sbie:2009},
  pages = {1-10},
  abstract = {O processo de digitalização da televisão analógica criou possibilidades que vão além da simples melhoria da qualidade do sinal recebido. O equilíbrio entre a tecnologia e os aspectos humano e social surge como caminho para o desenvolvimento de recursos, no campo do T-learning, que respeitam os diferentes contextos sócio-culturais do país, contribuem na formação de pessoas e impulsionam a inovação. Este trabalho descreve a extensão do conjunto de funcionalidades do Sistema de Gestão de Aprendizagem Amadeus para o contexto da TV Digital, que esteja ao mesmo tempo integrado com outras aplicações interativas, como Objetos de Aprendizagem, dispositivos móveis e ambientes Web.},
  abstract-en = {The digitalization process of the analogical television has enabled possibilities that go far beyond the mere improvement of the quality of the received signal. The balance between technology and the social context appears as a way to the development of T-Learning resources that respect regional reality and stimulate innovation. This paper aims at extending a range of functionalities of a Learning Management System within the context of interactive digital television. This system is at the same time integrated with other interactive applications in such a context, such as Learning Objects, mobile devices and Web environments.},
  publisher = {SBC}
}

@INPROCEEDINGS{South-etal:2013,
  author = {South, David and Ray, Austin and Thomas, Kevin and Graham, Stephanie and Huff, Shiloh and Rainge, Sarah and Shuman, Mary and Sridharan, Mohan and Urban, Susan D. and Urban, Joseph E. and Peeler, Sabyne},
  title = {DOROTHY: Integrating Graphical Programming with Robotics to Stimulate Interest in Computing Careers},
  crossref = {proceedings:alice:2013},
  pages = {5:1--5:6},
  doi = {10.1145/2532333.2532338},
  abstract = {This paper describes DOROTHY, a novel educational tool that enhances the Alice 3D programming environment to enable bidirectional communication of sensor data and commands with robots capable of autonomous operation. Users without any programming experience can quickly create graphical routines consisting of one or more simulated robots in virtual worlds. Command dictionaries and socket streams enable real-time translation of these routines to software for synchronous or asynchronous control of sensing and actuation on one or more mobile robots with on-board sensing, resulting in adaptive behavior in the real-world. Multiple execution scenarios are described to illustrate the capabilities of the educational tool. Furthermore, the paper outlines a curriculum that can be used with the tool to teach core concepts of computing, concurrent execution and real-world sensing to middle school and high school students, thus stimulating interest in computing.},
  keywords = {Computational thinking, autonomous mobile robots, graphical programming environments}
}

@INPROCEEDINGS{Souza-etal:2008,
  author = {Souza, Daniel Abella C. M. and Fujioka, Rodrigo da Cruz and Azevedo, Ryan R. and Freitas, Fred and Siqueira, Marcelo and de Vasconcelos, César Rocha},
  title = {Uma proposta de um ambiente extensível de ensino à distância aplicado à área de Engenharia de Software},
  crossref = {proceedings:webmedia:2008},
  pages = {133--136},
  doi = {10.1145/1809980.1810016},
  keywords = {ambientes virtuais, realidade virtual},
  abstract-en = {Due to the technologies evolution for development of virtual environments, even more realistic user interfaces have been created. In the last years, virtual environments have become an important element adopted for knowledge development in several areas. This paper introduces an extensible environment for distance learning applied to the Software Engineering area, however not limited only for this area. For development of this environment, this work proposes an infrastructure that allows the dynamic association of functionalities to the browser, so that the environment can be easily customized in real time.},
  lang = {pt}
}

@INPROCEEDINGS{Souza-etal:2011:APPLETS,
  author = {Draylson Souza and José Maldonado and Ellen Francine Barbosa},
  title = {{ProgTest}: Apoio Automatizado ao Ensino Integrado de Programação e Teste de Software},
  crossref = {proceedings:applets:2011},
  pages = {1893--1897},
  abstract = {Dentre as várias iniciativas investigadas a fim de amenizar os problemas associados ao ensino de programação destaca-se a introdução de conceitos de teste em disciplinas introdutórias dos cursos de Computação. Nesse cenáario, ferramentas capazes de fornecer feedback adequado sobre o desempenho dos alunos tornam-se fundamentais. Neste trabalho, é apresentada a PROGTEST -- uma ferramenta web de apoio à submissão e avaliação automática de trabalhos de programação baseada em atividades de teste.},
  timestamp = {2013-09-23}
}

@INPROCEEDINGS{Souza-etal:2013,
  author = {Draylson Micael de Souza and Sofia Larissa da Costa and Nemesio Freitas Duarte Filho and Ellen Francine Barbosa.},
  title = {Um Estudo Experimental do Ambiente ProgTest no Ensino de Programação},
  crossref = {proceedings:eselaw:2013},
  abstract = {Ambientes de apoio a submissão e avaliação automática de trabalhos práticos de programação vêm sendo desenvolvidos como ferramentas de apoio ao ensino integrado de programação e teste de software. Dentre eles, destaca-se ProgTest, que avalia o trabalho dos alunos tanto em relação à atividade de programação quanto em relação à atividade de teste. Este artigo tem como objetivo apresentar um experimento cujo objetivo foi analisar a efetividade da ProgTest na aprendizagem dos alunos. São apresentados detalhes do planejamento, execução e análise dos dados, descrevendo as experiências, benefícios e dificuldades em relação à utilização do ambiente, sendo que os resultados fornecem indícios de que a ProgTest melhora a aprendizagem dos alunos.}
}

@INPROCEEDINGS{Souza-etal:2012,
  author = {Draylson Micael de Souza and José Carlos Maldonado and Ellen Francine Barbosa},
  title = {Aspectos de Desenvolvimento e Evolução o de um Ambiente de Apoio ao Ensino de Programação e Teste de Software},
  crossref = {proceedings:sbie:2012},
  pages = {1--10},
  abstract = {Ambientes de apoio a submissão e avaliação automática de trabalhos práticos vêm sendo desenvolvidos como ferramentas de apoio ao ensino de programação e teste de software. Dentre eles, destaca-se a PROGTEST. Em sua primeira versão, a PROGTEST apenas apoiava a linguagem Java e critérios de teste estruturais. Este artigo descreve a evolução da PROGTEST a fim de torná-la capaz de apoiar diferentes linguagens de programação e critérios de teste. Para isso, foram analisadas e integradas à PROGTEST diferentes ferramentas de teste. Os resultados obtidos a partir de uma validação mostram que a PROGTEST, com as novas ferramentas, pode avaliar os trabalhos de programação e teste de uma forma mais adequada.},
  timestamp = {2013-09-22}
}

@INPROCEEDINGS{Souza-etal:2011:CSEET,
  author = {Souza, Draylson Micael de and Maldonado, Jose Carlos and Barbosa, Ellen Francine},
  title = {{ProgTest}: An environment for the submission and evaluation of programming assignments based on testing activities},
  crossref = {proceedings:cseet:2011},
  pages = {1--10},
  doi = {10.1109/CSEET.2011.5876088},
  abstract = {Programming foundations is not an easy subject to be taught--many students have difficulties understanding the abstract concepts of programming and have a wrong view about the programming activity. In order to address these problems, experiences have suggested the integrated teaching of programming concepts and software testing in introductory CS courses. Shortly, the idea is that testing can contribute to enhance the students' capabilities of understanding and analysis. However, such perspective requires tools to provide an adequate feedback to evaluate the students' performance concerning programming and testing activities. In this paper we describe ProgTest--a web-based tool for the submission and automatic evaluation of practical programming assignments based on testing activities. Results from a preliminary validation of ProgTest are also presented. Such results provide evidences on the practical use of ProgTest as a supporting mechanism for the integrated teaching of programming foundations and software testing.}
}

@INPROCEEDINGS{Souza-etal:2000,
  author = {S. R. S. Souza and J. C. Maldonado and S. C. P. F. Fabbri and W. {Lopes de Souza}},
  title = {Mutation Testing Applied to {Estelle} Specifications},
  crossref = {proceedings:hicss:2000},
  pages = {1--10},
  doi = {10.1109/HICSS.2000.926973},
  abstract = {Many researchers have pursued the establishment of a low-cost, effective testing and validation strategy at the program level as well as at the specification level. Mutation Testing is an error-based approach, originally introduced for program testing, that provides testers a systematic way to evaluate how good a given tester is. Some studies have also investigated its use to generate testers. In this article the application of Mutation Testing for validating Estelle specifications is proposed. A mutation operator set for Estelle-one of the crucial points for effectively applying Mutation Testing-is defined, addressing: the validation of the behavior of the modules, the communication among modules and the architecture of the specification. In this scope, these operators can be taken as a fault model. Considering this context, a strategy for validating Estelle-based specification is proposed and exemplified using the alternating-bit protocol.}
}

@ARTICLE{Souza-etal:1999,
  author = {S. R. S. Souza and J. C. Maldonado and S. C. P. F. Fabbri and Souza, W. Lopes},
  title = {Mutation Testing Applied to {Estelle} Specifications},
  crossref = {journal:springer:sqj},
  volume = {8},
  number = {4},
  month = dec,
  year = {1999},
  pages = {285--301},
  doi = {10.1023/A:1008978021407},
  abstract = {Many researchers have pursued the establishment of a low-cost, effective testing and validation strategy at the program level as well as at the specification level. Mutation Testing is an error-based approach, originally introduced for program testing, that provides testers a systematic way to evaluate how good a given test set is. Some studies have also investigated its use to generate test sets. In this article, the application of Mutation Testing for validating Estelle specifications is proposed. A mutant operator set for Estelle -- one of the crucial points for effectively applying Mutation Testing -- is defined, addressing: the validation of the behavior of the modules, the communication among modules and the architecture of the specification. In this scope, these operators can be taken as a fault model. Considering this context, a strategy for validating Estelle-based specification is proposed and exemplified using the Alternating-bit protocol.},
  keywords = {specification-based testing; mutation testin; Estelle}
}

@ARTICLE{Souza-etal:2008:CCPE,
  author = {Souza, S. R. S. and Vergilio, S. R. and Souza, P. S. L. and Simão, A. S. and Hausen, A. C.},
  title = {Structural testing criteria for message-passing parallel programs},
  crossref = {journal:wiley:ccpe},
  volume = {20},
  number = {16},
  month = nov,
  year = {2008},
  pages = {1893--1916},
  doi = {10.1002/cpe.1297},
  abstract = {Parallel programs present some features such as concurrency, communication and synchronization that make the test a challenging activity. Because of these characteristics, the direct application of traditional testing is not always possible and adequate testing criteria and tools are necessary. In this paper we investigate the challenges of validating message-passing parallel programs and present a set of specific testing criteria. We introduce a family of structural testing criteria based on a test model. The model captures control and data flow of the message-passing programs, by considering their sequential and parallel aspects. The criteria provide a coverage measure that can be used for evaluating the progress of the testing activity and also provide guidelines for the generation of test data. We also describe a tool, called ValiPar, which supports the application of the proposed testing criteria. Currently, ValiPar is configured for parallel virtual machine (PVM) and message-passing interface (MPI). Results of the application of the proposed criteria to MPI programs are also presented and analyzed.},
  keywords = {parallel software testing, coverage criteria, testing tool, PVM, MPI}
}

@INPROCEEDINGS{Monteiro-etal:2008,
  author = {Bruno de Souza Monteiro and Thiago Monteiro Prota and Fernando da Fonseca de Souza and Alex Sandro Gomes},
  title = {Desenvolvimento de Objetos de Aprendizagem para {TVDi}},
  crossref = {proceedings:sbie:2008},
  pages = {1-10},
  abstract = {O uso de tecnologias da informação no contexto educacional vem contribuindo para tornar o processo de ensino-aprendizagem mais acessível, agradável e eficaz. O uso da TV Digital Interativa (TVDi), como forma de promover a difusão de conhecimento e redução da exclusão social, impulsiona importantes pesquisas associadas ao cenário brasileiro. Assim, além da transmissão de conteúdo instrutivo, a interatividade agora permite que o telespectador se torne um elemento ativo nesse processo. Com isto, este trabalho propõe a exploração desta nova mídia no contexto educacional, mesmo em situações em que o canal de retorno da infra-estrutura da TVDi não esteja disponível, por meio da exploração de Objetos de Aprendizagem.},
  abstract-en = {The use of information technologies on the educational context has contributed to ease the teaching-learning process by making it more accessible, pleasant and effective. The use of Digital TV as means to reduce social exclusion and promote knowledge diffusion has motivated important research. Most of them are aimed at developing educational tools for such a platform. Thus, besides accessing instructive content, the interactivity now allows the viewer to become an active element in this process. Thus, this work proposes the exploration of interactivity, even in situations where the return channel of the infrastructure of the Digital TV is not available, through the use of Learning Objects.},
  timestamp = {2012.02.10}
}

@INPROCEEDINGS{Spacco-etal:2006:itcse,
  author = {Spacco, Jaime and Hovemeyer, David and Pugh, William and Emad, Fawzi and Hollingsworth, Jeffrey K. and Padua-Perez, Nelson},
  title = {Experiences with {Marmoset}: designing and using an advanced submission and testing system for programming courses},
  crossref = {proceedings:itcse:2006},
  pages = {13--17},
  doi = {10.1145/1140124.1140131},
  abstract = {We developed Marmoset, an automated submission and testing system, to explore techniques to provide improved feedback to both students and instructors as students work on programming assignments, and to collect data to perform detailed research on the development processes of students. To address the issue of feedback, Marmoset provides students with limited access to the results of the instructor's private test cases using a novel token-based incentive system. This both encourages students to start their work early and to think critically about their work. Because students submit early, instructors can monitor all students' progress on test cases, helping identify challenging or ambiguous test cases early in order to update the project specification or devote additional time in lecture or lab sessions to the difficult test cases.To study and better understand the development process of students, Marmoset can be configured to transparently capture snapshots to a central repository everytime students save their files. These detailed development histories offer a unique, detailed perspective of each student's progress on a programming assignment, from the first line of code written and saved all the way through the final edit before the final submission. This type of data has proven extremely valuable many uses, such as mining new bug patterns and evaluating existing bug-finding tools.In this paper, we describe our initial experiences using Marmoset in several introductory computer science courses, from the perspectives of both instructors and students. We also describe some initial research results from analyzing the student snapshot database.},
  keywords = {code snapshots, project submission, testing}
}

@INPROCEEDINGS{Spacco-Pugh:2006,
  author = {Spacco, Jaime and Pugh, William},
  title = {Helping students appreciate test-driven development ({TDD})},
  crossref = {proceedings:oopsla:2006},
  pages = {907--913},
  doi = {10.1145/1176617.1176743},
  abstract = {Testing is an important part of the software development cycle that should be covered throughout the computer science curriculum. However, for students to truly learn the value of testing, they need to benefit from writing test cases for their own software.We report on our initial experiences teaching students to write test cases and evaluating student-written test suites, with an emphasis on our observation that, without proper incentive to write test cases early, many students will complete the programming assignment first and then add the build of their test cases afterwards. Based on these experiences, we propose new mechanisms to provide better incentives for students to write their test cases early.We also report on some of the limitations of code coverage as a tool for evaluating test suites, and finally conclude with a survey of related work on introducing testing into the undergraduate curriculum.},
  keywords = {computer science education, marmoset, tdd, test-driven development}
}

@INPROCEEDINGS{Spacco-etal:2006:oopsla,
  author = {Spacco, Jaime and Pugh, William and Ayewah, Nat and Hovemeyer, David},
  title = {The {Marmoset} project: an automated snapshot, submission, and testing system},
  crossref = {proceedings:oopsla:2006},
  pages = {669--670},
  doi = {10.1145/1176617.1176665},
  abstract = {Marmoset is a framework for storing and testing student submissions to programming assignments. It gives students a limited ability to release test their code using an instructor's private suite of test cases. This encourages them to start early and implement their own test cases. It also provides facilities for instructors to manage the grading process and gives researchers access to fine-grained snapshots of the student development process.},
  keywords = {code snapshots, project submission, testing},
  timestamp = {2013-09-23}
}

@ARTICLE{Spinellis-Spencer:2011,
  author = {Spinellis, D. and Spencer, H.},
  title = {Lessons from Space},
  crossref = {journal:ieee:software},
  volume = {28},
  number = {6},
  month = nov # {--} # dec,
  year = {2011},
  pages = {26--28},
  doi = {10.1109/MS.2011.143},
  abstract = {Given the parallels between the complexity of human spaceflight and large software systems, there are many things we developers can learn from successful space programs, such as the Soyuz. First, limiting a project's scope and complexity early on can have a dramatic payoff in its success and longevity. In addition, adding generous margins to early estimates (and any subsequent revisions) will ease the pain of development and deployment. Furthermore, gradual evolution with a working program at each step, rather than massive rewrites, benefits from successful architectures and teams, while also retaining the software's customer base and third-party contributors. Finally, a well-defined modular structure can increase the software's versatility yielding economies of scope and scale over its lifetime.},
  keywords = {human spaceflight complexity;massive rewrites;software customer base;software systems;software versatility;space programs;third-party contributors;aerospace computing;computational complexity;software architecture;},
  lang = {en}
}

@ARTICLE{Spinke:2013,
  author = {Volker Spinke},
  title = {An object-oriented implementation of concurrent and hierarchical state machines },
  crossref = {journal:elsevier:ist},
  volume = {55},
  number = {10},
  month = oct,
  year = {2013},
  pages = {1726--1740},
  doi = {10.1016/j.infsof.2013.03.005},
  abstract = {AbstractContext State machine diagrams are a powerful means to describe the behavior of reactive systems. Unfortunately, the implementation of state machines is difficult, because state machine concepts, like states, events and transitions, are not directly supported in commonly used programming languages. Most of the implementation approaches known so far have one or more serious drawbacks: they are difficult to understand and maintain, lack in performance, depend on the properties of a specific programming language or do not implement the more advanced state machine features like hierarchy, concurrency or history. Objective This paper proposes and examines an approach to implement state machines, where both states and events are objects. Because the reaction of the state machine depends on two objects (state and event), a method known as double-dispatch is used to invoke the transition between the states. The aim of this work is to explore this approach in detail. Method To prove the usefulness of the proposed approach, an example was implemented with the proposed approach as well as with other commonly known approaches. The implementation strategies are then compared with each other with respect to run-time, code size, maintainability and portability. Results The presented approach executes fast but needs slightly more memory than other approaches. It supports hierarchy, concurrency and history, is human authorable, easy to understand and easy to modify. Because of its pure object-oriented nature depending only on inheritance and late binding, it is extensible and can be implemented with a wide variety of programming languages. Conclusion The results show that the presented approach is a useful way to implement state machines, even on small micro-controllers. },
  keywords = {State machines; UML statecharts; State pattern; Double-dispatch; Code generation; Design pattern }
}

@ARTICLE{Spinola-Travassos:2012,
  author = {Rodrigo Oliveira Spínola and Guilherme Horta Travassos},
  title = {Towards a framework to characterize ubiquitous software projects},
  crossref = {journal:elsevier:ist},
  volume = {54},
  number = {7},
  month = jul,
  year = {2012},
  pages = {759--785},
  doi = {10.1016/j.infsof.2012.01.009},
  abstract = {Context Ubiquitous Computing (or UbiComp) represents a paradigm in which information processing is thoroughly integrated into everyday objects and activities. From a Software Engineering point of view this development scenario brings new challenges in tailoring or building software processes, impacting current software technologies. However, it has not yet been explicitly shown how to characterize a software project with the perception of ubiquitous computing. Objective This paper presents a conceptual framework to support the characterization of ubiquitous software projects according to their ubiquity adherence level. It also intends to apply such characterization approach to some projects, aiming at observing their adherence with ubiquitous computing principles. Method To follow a research strategy based on systematic reviews and surveys to acquire UbiComp knowledge and organize a conceptual framework regarding ubiquitous computing, which can be used to characterize UbiComp software projects. Besides, to demonstrate its application by characterizing some software projects. Results Ubiquitous computing encapsulates at least 11 different high abstraction level characteristics represented by 123 functional and 45 restrictive factors. Based on this a checklist was organized to allow the characterization of ubiquitous software projects, which has been applied on 26 ubiquitous software projects from four different application domains (ambient intelligence, pervasive healthcare, U-learning, and urban space). No project demonstrated to support more than 65% of the characteristics set. Service omnipresence was observed in all of these projects. However, some characteristics, although identified as necessary in the checklist, were not identified in any of them. Conclusion There are characteristics that identify a software project as ubiquitous. However, a ubiquitous software project does not necessarily have to implement all of them. The application domain can influence the appearing of UbiComp characteristics in software projects, promoting an increase of their adherence to UbiComp and, thus, for additional software technologies to deal with these ubiquitous requirements.},
  keywords = {Ubiquitous computing; Software projects characterization; Systematic review; Experimental software engineering}
}

@INPROCEEDINGS{Spohrer-Soloway:1986:chi,
  author = {Spohrer, J. C. and Soloway, E.},
  title = {Alternatives to construct-based programming misconceptions},
  crossref = {proceedings:chi:1986},
  pages = {183--191},
  doi = {10.1145/22627.22369},
  abstract = {In this paper, we investigate whether or not most novice programming bugs arise because students have misconceptions about the semantics of particular language constructs. Three high frequency bugs are examined in detail -- one that clearly arises from a construct-based misconception, one that does not, and one that is less cut and dry. Based on our empirical study of 101 bug types from three programming problems, we will argue that most bugs are not due to misconceptions about the semantics of language constructs.}
}

@ARTICLE{Spohrer-Soloway:1986:cacm,
  author = {Spohrer, James C. and Soloway, Elliot},
  title = {Novice mistakes: are the folk wisdoms correct?},
  crossref = {journal:acm:cacm},
  volume = {29},
  number = {7},
  month = jul,
  year = {1986},
  pages = {624--632},
  doi = {10.1145/6138.6145},
  abstract = {An evaluation of two folk wisdoms serves to elucidate the underlying or "deep-structure" reasons for novice errors.}
}

@ARTICLE{Spohrer-etal:1985,
  author = {Spohrer, James C. and Soloway, Elliot and Pope, Edgar},
  title = {A goal/plan analysis of buggy {Pascal} programs},
  crossref = {journal:erlbaum:hci},
  volume = {1},
  number = {2},
  month = jun,
  year = {1985},
  pages = {163--207},
  doi = {10.1207/s15327051hci0102_4},
  abstract = {In this paper, we present a descriptive theory of buggy novice programs and a bug categorization scheme that is based on this theory. Central to this theory is the cognitively plausible knowledge--goals and plans--that underlies programming. The bug categorization scheme makes explicit problem-dependent goal and plan knowledge at many different levels of detail. We provide several examples of how the scheme permits us to focus on bugs in a way that facilitates generating plausible accounts of why the bugs may have arisen. In particular, our approach has led us to one explanation of why some novice programs are buggier than others. A basic part of this explanation is the notion of merged goals and merged plans in which a single integrated plan is used to achieve multiple goal}
}

@INPROCEEDINGS{Squire:2013,
  author = {Squire, Megan},
  title = {A Replicable Infrastructure for Empirical Studies of Email Archives},
  crossref = {proceedings:reser:2013},
  pages = {43--49},
  doi = {10.1109/RESER.2013.11},
  abstract = {This paper describes a replicable infrastructure solution for conducting empirical software engineering studies based on email mailing list archives. Mailing list emails, such as those affiliated with free, libre, and open source software (FLOSS) projects, are currently archived in several places online, but each research team that wishes to study these email artifacts closely must design their own solution for collection, storage and cleaning of the data. Consequently, research results will be difficult to replicate, especially as the email archive for any living project will still be continually growing. This paper describes a simple, replicable infrastructure for the collection, storage, and cleaning of project email data and analyses.},
  keywords = {email, archive, mailing list, database, document-oriented database, collection, storage, cleaning},
  owner = {magsilva},
  timestamp = {2014.09.13}
}

@ARTICLE{Stath-Bosch:2014,
  author = {Daniel Stahl and Jan Bosch},
  title = {Modeling continuous integration practice differences in industry software development},
  crossref = {journal:elsevier:jss},
  volume = {87},
  number = {0},
  year = {2014},
  pages = {48 - 59},
  doi = {10.1016/j.jss.2013.08.032},
  abstract = {Abstract Continuous integration is a software practice where developers integrate frequently, at least daily. While this is an ostensibly simple concept, it does leave ample room for interpretation: what is it the developers integrate with, what happens when they do, and what happens before they do? These are all open questions with regards to the details of how one implements the practice of continuous integration, and it is conceivable that not all such implementations in the industry are alike. In this paper we show through a literature review that there are differences in how the practice of continuous integration is interpreted and implemented from case to case. Based on these findings we propose a descriptive model for documenting and thereby better understanding implementations of the continuous integration practice and their differences. The application of the model to an industry software development project is then described in an illustrative case study. },
  keywords = {Continuous integration, Agile software development }
}

@ARTICLE{Stahl-Bosch:2013,
  author = {Daniel Stahl and Jan Bosch},
  title = {Modeling Continuous Integration Practice Differences in Industry Software Development },
  crossref = {journal:elsevier:ist},
  number = {0},
  year = {2013},
  pages = { - },
  doi = {10.1016/j.jss.2013.08.032},
  abstract = {Abstract Continuous Integration is a software practice where developers integrate frequently, at least daily. While this is an ostensibly simple concept, it does leave ample room for interpretation: what is it the developers integrate with, what happens when they do, and what happens before they do? These are all open questions with regards to the details of how one implements the practice of continuous integration, and it is conceivable that not all such implementations in the industry are alike. In this paper we show through a literature review that there are differences in how the practice of continuous integration is interpreted and implemented from case to case. Based on these findings we propose a descriptive model for documenting and thereby better understanding implementations of the continuous integration practice and their differences. The application of the model to an industry software development project is then described in an illustrative case study. },
  keywords = {Continuous integration, Agile software development },
  url = {http://www.sciencedirect.com/science/article/pii/S0164121213002276},
  issn = {0164-1212},
  journal = {Journal of Systems and Software },
  timestamp = {2013-09-16}
}

@ARTICLE{Stamelos:2010,
  author = {Ioannis Stamelos},
  title = {Software project management anti-patterns },
  crossref = {journal:elsevier:jss},
  volume = {83},
  number = {1},
  month = jan,
  year = {2010},
  pages = {52--59},
  doi = {10.1016/j.jss.2009.09.016},
  abstract = {This paper explores the area of bad practices, namely anti-patterns, and their consequences in software project management (SPM). The paper surveys the multitude of anti-patterns that have been reported and documented up to now and stresses the need for tools to formally represent SPM anti-patterns, proposing specific formalisms for such purpose, namely Bayesian Belief Networks, Ontologies and Social Networks. It is also explained how the Web can provide an opportunity for capturing, storing, disseminating and ultimately avoiding SPM anti-patterns. As a consequence, anti-patterns may provide an excellent tool for educating active and future software managers. Finally, conclusions and future research trends are given.},
  keywords = {Anti-pattern, Software project management, Bayesian belief network, Knowledge management, Social network},
  owner = {magsilva},
  timestamp = {2014.09.13}
}

@ARTICLE{Starke:1993,
  author = {Starke, Gernot},
  title = {Urgent research issues in software process engineering},
  crossref = {journal:acm:sen},
  volume = {18},
  number = {4},
  month = oct,
  year = {1993},
  pages = {13--15},
  doi = {10.1145/163626.163628},
  abstract = {This paper outlines the major problems and research directions in software process engineering. These problems concern the terminology andlanguage of models; the difference between type and instance; the inherent reflexivity of detailed process models and the dynamic aspects of process models. Furthermore human factors are shown to impose major difficulties on process engineers.},
  keywords = {human factors, reflexivity, software process engineering, software process modeling, terminology, type-versus-instance}
}

@INPROCEEDINGS{StDenis-etal:2000,
  author = {Guy St-Denis and Reinhard Schauer and Rudolf K. Keller},
  title = {Selecting a Model Interchange Format: The {SPOOL} Case Study},
  crossref = {proceedings:hicss:2000},
  pages = {1--10},
  doi = {10.1109/HICSS.2000.927017},
  abstract = {The aim of the paper is to provide tool developers with effective strategies to minimize the risks, costs, effort and time involved in handling model interchange issues. Specifically, we establish a requirements list for model interchange formats and highlight the advantages and disadvantages of representative solutions RSF, TA, RDF, XIF and XMI. As a case study, we introduce SPOOL, our prototype environment for design recovery and composition, and discuss the particular project requirements that led us to envision an XMI-based model interchange engine. We then discuss implementation details and relate the lessons learned in pursuing the described path.}
}

@ARTICLE{Stearns:1967,
  author = {R.E. Stearns},
  title = {A regularity test for pushdown machines },
  crossref = {journal:elsevier:ic},
  volume = {11},
  number = {3},
  month = sep,
  year = {1967},
  pages = {323--340},
  doi = {10.1016/S0019-9958(67)90591-8},
  abstract = {It is possible to test a deterministic pushdown machine to determine if the language it recognizes is regular.},
  owner = {magsilva},
  timestamp = {2014.07.15}
}

@ARTICLE{Stegmaier-etal:2013,
  author = {Stegmaier, F. and Bailer, W. and Burger, T. and Suarez-Figueroa, M.C. and Mannens, E. and Evain, J. and Hoffernig, M. and Champin, P. and Doller, M. and Kosch, H.},
  title = {Unified Access to Media Metadata on the Web},
  crossref = {journal:ieee:multimedia},
  volume = {20},
  number = {2},
  month = apr # {--} # jun,
  year = {2013},
  pages = {22--29},
  doi = {10.1109/MMUL.2012.55},
  abstract = {The goal of the World Wide Web Consortium (W3C) Media Annotation Working Group (MAWG) is to promote interoperability between multimedia metadata formats on the Web. Audio-visual data is omnipresent on today's Web, but different interaction interfaces and especially diverse metadata formats prevent unified search, access, and navigation. MAWG has addressed this issue by developing an interlingua ontology and an associated API. This article discusses the rationale and core concepts of the ontology and API for media resources. The specifications developed by MAWG enable interoperable, contextualized, and semantic annotation and search, independent of the source metadata format, that connects multimedia data to the Linked Data Cloud.}
}

@ARTICLE{Steinmacher-etal:2013,
  author = {Steinmacher, Igor and Chaves, Ana Paula and Gerosa, Marco Aurélio},
  title = {Awareness Support in Distributed Software Development: A Systematic Review and Mapping of the Literature},
  crossref = {journal:springer:cscw},
  volume = {22},
  number = {2--3},
  month = apr,
  year = {2013},
  pages = {113--158},
  doi = {10.1007/s10606-012-9164-4},
  abstract = {The developers' physical dispersion in Distributed Software Development (DSD) imposes challenges related to awareness support during collaboration in such scenario. In this paper, we present a systematic literature review and mapping that gathered, analyzed, and classified studies that improve awareness support in DSD, providing an overview of the area. Our initial search returned 1967 papers, of which 91 were identified as reporting some awareness support to DSD. These papers were then analyzed, and classified according to the 3 C collaboration model and to the Gutwin et al. Awareness Framework. Our findings suggest that awareness in DSD is gaining increasingly attention, 71 out of 91 papers were published from 2006 to 2010. Most part of the papers presented tools with some awareness support. The classification showed that the coordination is by far the most supported dimension of the 3C model, while communication is the less explored. It also showed that workspace awareness elements play a central role on DSD collaboration.},
  keywords = {Awareness; Communication; Coordination; Cooperation; Distributed software development; Systematic mapping; Systematic review}
}

@INPROCEEDINGS{6391733,
  author = {Steinmacher, I. and Wiese, I.S. and Chaves, A.P. and Gerosa, M.A.},
  title = {Newcomers Withdrawal in Open Source Software Projects: Analysis of Hadoop Common Project},
  crossref = {proceedings:sbsc:2012},
  pages = {65--74},
  doi = {10.1109/SBSC.2012.16},
  abstract = {Collective production communities, like open source projects, are based on volunteers collaboration and require newcomers for their continuity. Newcomers face difficulties and obstacles when starting their contributions, resulting in a large withdrawal and consequent low retention rate. This paper presents an analysis of newcomers withdrawal, checking if the dropout is influenced by lack of answer, answers politeness and helpfulness, and the answer author. We have collected five years data from the developers mail list communication and task manager (Jira) discussions of Hadoop Common project. We observed the users' communication, identifying newcomers and classifying questions and answers content. For the study conducted, less than 20% of newcomers became long term contributors. There are evidences that the withdrawal is influenced by the respondents and by the type of response received. However, the lack of answer was not evidenced as a factor that influences newcomers withdrawal in the project.},
  keywords = {collaboration , communication , newcomer , open source software , withdrawal}
}

@INPROCEEDINGS{Steinmacher-etl:2013,
  author = {Steinmacher, I. and Wiese, I. and Chaves, A.P. and Gerosa, M.A.},
  title = {Why do newcomers abandon open source software projects?},
  crossref = {proceedings:chase:2013},
  pages = {25--32},
  doi = {10.1109/CHASE.2013.6614728},
  abstract = {Open source software projects, are based on volunteers collaboration and require a continuous influx of newcomers for their continuity. Newcomers face difficulties and obstacles when starting their contributions, resulting in a low retention rate. This paper presents an analysis of the first interactions of newcomers on a project, checking if the dropout may have been influenced by lack of answer, answers politeness and helpfulness, and the answer author. We have collected five years data from the developers' mailing list communication and issue manager (Jira) discussions of the Hadoop Common project. We observed developers' communication, identifying newcomers and classifying questions and answers content. In the analyzed period, less than 20% of newcomers became long-term contributors. There are evidences that the newcomers decision to abandon the project was influenced by the authors of the answers and by the type of answer received. However, the lack of answer was not evidenced as a factor that influences newcomers' decision to remain or abandon the project.},
  keywords = {newcomer, communication, collaboration, open source software, retention}
}

@INPROCEEDINGS{6233413,
  author = {Steinmacher, I. and Wiese, I.S. and Gerosa, M.A.},
  title = {Recommending mentors to software project newcomers},
  crossref = {proceedings:rsse:2012},
  pages = {63--67},
  doi = {10.1109/RSSE.2012.6233413},
  abstract = {Open Source Software projects success depends on the continuous influx of newcomers and their contributions. Newcomers play an important role as they are the potential future developers, but they face difficulties and obstacles when initiating their interaction with a project, resulting in a high amount of withdrawals. This paper presents a recommendation system aiming to support newcomers finding the most appropriate project member to mentor them in a technical task. The proposed system uses temporal and social aspects of developer's behavior, in addition to recent contextual information to recommend the most suitable mentor at the moment.},
  keywords = {mentor recommendation , newcomers , open source software , recommendation system}
}

@ARTICLE{Stonebraker-Hong:2012,
  author = {Stonebraker, Michael and Hong, Jason},
  title = {Researchers' big data crisis; understanding design and functionality},
  crossref = {journal:acm:cacm},
  volume = {55},
  number = {2},
  month = feb,
  year = {2012},
  pages = {10--11},
  doi = {10.1145/2076450.2076453}
}

@ARTICLE{Stotts-Furuta:1989,
  author = {Stotts, P. David and Furuta, Richard},
  title = {Petri-net-based hypertext: document structure with browsing semantics},
  crossref = {journal:acm:tois},
  volume = {7},
  number = {1},
  month = jan,
  year = {1989},
  pages = {3--29},
  doi = {10.1145/64789.64791},
  abstract = {We present a formal definition of the Trellis model of hypertext and describe an authoring and browsing prototype called alphaTrellis that is based on the model. The Trellis model not only represents the relationships that tie individual pieces of information together into a document (i.e., the adjacencies), but specifies the browsing semantics to be associated with the hypertext as well (i.e., the manner in which the information is to be visited and presented). The model is based on Petri nets, and is a generalization of existing directed graph-based forms of hypertext. The Petri net basis permits more powerful specification of what is to be displayed when a hypertext is browsed and permits application of previously developed Petri net analysis techniques to verify properties of the hypertext. A number of useful hypertext constructs, easily described in the Trellis model, are presented. These include the synchronization of simultaneous traversals of separate paths through a hypertext, the incorporation of access controls into a hypertext (i.e., specifying nodes that can be proven to be accessible only to certain classes of browsers), and construction of multiple specialized (tailored) versions from a single hypertext.},
  keywords = {access controls, browsing semantics, formal methods, Petri nets, synchronization, trellis model of hypertext},
  acmid = {64791},
  issue = {1},
  journal = {ACM Transactions on Information Systems},
  numpages = {27}
}

@ARTICLE{Stroele-etal:2013,
  author = {Victor Ströele and Geraldo Zimbrão and Jano M. Souza},
  title = {Group and link analysis of multi-relational scientific social networks},
  crossref = {journal:elsevier:jss},
  volume = {86},
  number = {7},
  month = jul,
  year = {2013},
  pages = {1819--1830},
  doi = {10.1016/j.jss.2013.02.024},
  abstract = {Analyzing social networks enables us to detect several inter and intra connections between people in and outside their organizations. We model a multi-relational scientific social network where researchers may have four different types of relationships with each other. We adopt some criteria to enable the modeling of a scientific social network as close as possible to reality. Using clustering techniques with maximum flow measure, we identify the social structure and research communities in a way that allows us to evaluate the knowledge flow in the Brazilian scientific community. Finally, we evaluate the temporal evolution of scientific social networks to suggest/predict new relationships.},
  keywords = {Multi-relational scientific social network analysis, Max-flow grouping algorithm, Link prediction/suggestion}
}

@ARTICLE{Stuikys-etal:2013,
  author = {Vytautas Stuikys and Renata Burbaite and Robertas Damasevicius},
  title = {Teaching of Computer Science Topics Using Meta-Programming-Based {GLOs} and {LEGO} Robots},
  crossref = {journal:imi:ie},
  volume = {12},
  number = {1},
  year = {2013},
  pages = {125--142},
  abstract = {The paper's contribution is a methodology that integrates two basic technologies (GLO and LEGO robot) to teach Computer Science (CS) topics at the school level. We present the methodology as a framework of 5 components (pedagogical activities, technology driven processes, tools, knowledge transfer actors, and pedagogical outcomes) and interactions among the components. GLOs are meta-programmed entities to generate LO instances on demand depending on the context of use and learning objectives. A GLO is a black-box entity, which is integrated in the framework through the generating process to source the teaching and learning process via robot-based visualization to demonstrate how programs and algorithms are transformed into real-world tasks and processes. The methodology is tested in the real e-learning setting. The pedagogical outcomes are evaluated by empirical data showing the increase of student engagement level, higher flexibility and reuse enhancement in learning.},
  keywords = {learning object (LO), generative learning object (GLO), LEGO NXT robot, CS teaching, educational visualization},
  timestamp = {2014-01-02}
}

@ARTICLE{Sun-Han:2013,
  author = {Sun, Yizhou and Han, Jiawei},
  title = {Mining heterogeneous information networks: a structural analysis approach},
  crossref = {journal:acm:sigkdd},
  volume = {14},
  number = {2},
  month = apr,
  year = {2013},
  pages = {20--28},
  doi = {10.1145/2481244.2481248},
  abstract = {Most objects and data in the real world are of multiple types, interconnected, forming complex, heterogeneous but often semi-structured information networks. However, most network science researchers are focused on homogeneous networks, without distinguishing different types of objects and links in the networks. We view interconnected, multityped data, including the typical relational database data, as heterogeneous information networks, study how to leverage the rich semantic meaning of structural types of objects and links in the networks, and develop a structural analysis approach on mining semi-structured, multi-typed heterogeneous information networks. In this article, we summarize a set of methodologies that can effectively and efficiently mine useful knowledge from such information networks, and point out some promising research directions.}
}

@ARTICLE{Sung-etal:2011,
  author = {Ahyoung Sung and Byoungju Choi and W. Eric Wong and Vidroha Debroy},
  title = {Mutant generation for embedded systems using kernel-based software and hardware fault simulation},
  crossref = {journal:elsevier:ist},
  volume = {53},
  number = {10},
  month = oct,
  year = {2011},
  pages = {1153--1164},
  doi = {10.1016/j.infsof.2011.03.010},
  abstract = {Mutation testing is a fault-injection-based technique to help testers generate test cases for detecting specific and predetermined types of faults. Before mutation testing can be effectively applied to embedded systems, traditional mutation testing needs to be modified. To inject a fault into an embedded system without causing any system failure or hardware damage is a challenging task as it requires some knowledge of the underlying layers such as the kernel and the corresponding hardware. We propose a set of mutation operators for embedded systems using kernel-based software and hardware fault simulation. These operators are designed for software developers so that they can use the mutation technique to test the entire system after the software is integrated with the kernel and hardware devices. A case study on a programmable logic controller for a digital reactor protection system in a nuclear power plant is conducted. Our results suggest that the proposed mutation operators are useful for fault-injection and this is evidenced by the fact that faults not injected by us were discovered in the subject software as a result of the case study. We conclude that our mutation operators are useful for integration testing of an embedded system.},
  keywords = {Mutation operators, Embedded systems, Fault injection, Integration testing},
  lang = {en}
}

@INPROCEEDINGS{Surian-etal:2010,
  author = {Surian, D. and Lo, D. and Ee-Peng Lim},
  title = {Mining Collaboration Patterns from a Large Developer Network},
  crossref = {journal:wcre:2010},
  pages = {269--273},
  doi = {10.1109/WCRE.2010.38},
  abstract = {In this study, we extract patterns from a large developer collaborations network extracted from Source Forge. Net at high and low level of details. At the high level of details, we extract various network-level statistics from the network. At the low level of details, we extract topological sub-graph patterns that are frequently seen among collaborating developers. Extracting sub graph patterns from large graphs is a hard NP-complete problem. To address this challenge, we employ a novel combination of graph mining and graph matching by leveraging network-level properties of a developer network. With the approach, we successfully analyze a snapshot of Source Forge. Net data taken on September 2009. We present mined patterns and describe interesting observations.}
}

@ARTICLE{Swan-etal:2012,
  author = {Karen Swan and Daniel Matthews and Leonard Bogle and Emily Boles and Scott Day},
  title = {Linking online course design and implementation to learning outcomes: A design experiment},
  crossref = {journal:elsevier:ihe},
  volume = {15},
  number = {2},
  month = mar,
  year = {2012},
  pages = {81--88},
  doi = {10.1016/j.iheduc.2011.07.002},
  abstract = {This paper reports on preliminary findings from ongoing design-based research being conducted in the fully online Master of Arts in Teacher Leadership (MTL) program at a small, Midwest public university. Researchers are using the Quality Matters (QM) and Community of Inquiry (CoI) frameworks to guide the iterative redesign of core courses in the program. Preliminary results from the redesign of one course suggest that such approach can improve student learning outcomes. Results also support the efficacy of the QM and CoI theoretical frames, and the usefulness of design-based approaches in online learning.},
  keywords = {Course redesign; Community of Inquiry; Quality Matters; Design experiment}
}

@INPROCEEDINGS{Sweedyk:2011,
  author = {Sweedyk, Elizabeth},
  title = {Women Build Games, Seriously},
  crossref = {proceedings:sigcse:2011},
  pages = {171--176},
  doi = {10.1145/1953163.1953218},
  abstract = {Recruitment of students to Computer Science has been a major focus of effort for educators since the dot-com bust in 2001. Two largely disparate themes in these efforts are women and games. There have been numerous efforts to broaden participation in computer science by attracting women to the field. At the same time, games are increasingly used to attract new students. Our interest lies at the intersection of these methods. We began using game design/development projects in our software engineering course, CS121, in 2002. The game focus was extremely successful with many of our students. But a nagging minority of students objected to building games, and women tend to be overrepresented in that group. So while are awed by the power of games to engage and motivate many of our students, we need to ask: Do games in our curriculum reinforce gender stereotypes of Computer Science? Do they foster development of the so-called "Geek mythology?" In short, must we choose: women or games? We argue the answer is no. While traditional game projects may disenfranchise women, our experience shows that serious game projects both attract and engage them. This paper describes our results.},
  keywords = {computer games, gender}
}

@INPROCEEDINGS{TalaricoNeto-etal:2006,
  author = {Talarico Neto, Americo and Anacleto, Junia Coutinho and Neris, Vânia Almeida and de Souza Godoi, Muriel and Carvalho, Aparecido Fabiano Pinatti},
  title = {A framework to support the design of learning objects based on the Cog-Learn Pattern Language},
  crossref = {proceedings:webmedia:2006},
  pages = {128--137},
  doi = {10.1145/1186595.1186612},
  abstract = {Projetar material instrucional para Web é uma tarefa difícil para professores que não têm experiência em pedagogia e projeto instrucional Web. Padrões surgiram como uma forma de capturar conhecimento de projeto em um contexto e apresentar soluções para os projetistas. Neste trabalho apresenta-se a ferramenta Cognitor que instancia um framework baseado na Linguagem de Padrões Cog-Learn. Pretende-se fornecer apoio aos professores durante o projeto e edição de objetos de aprendizagem no formato SCORM para sistemas de EAD com o objetivo de melhor organizar o conteúdo na interface visualizada pelo aluno, facilitando a sua interação e, conseqüentemente, facilitando o seu processo de aprendizagem.},
  keywords = {EAD, SCORM, cog-learn, cognitor, educação à distância, interação humano-computador, linguagem de padrões, projeto web},
  abstract-en = {In this paper we present the Cognitor, an authoring tool developed to support teachers designing instructional material for Web-based Distance Learning. Cognitor instantiates the Cog-Learn Pattern Language which captures design knowledge and present solutions for recurring problems at Distance Learning context. The framework provided by Cognitor makes it easier to design usable and accessible learning objects, which is a difficult task for novice teachers who lack experience in pedagogy and Web-based instructional design. Cognitor organizes the displayed content seen by the student, taking aim at facilitating his interaction and, consequently facilitating the knowledge process.}
}

@ARTICLE{Teixeira-etal:2010,
  author = {Teixeira, Cesar A. C. and Melo, Erick Lazaro and Cattelan, Renan G. and Pimentel, Maria da Graça Campos},
  title = {Taking advantage of contextualized interactions while users watch {TV}},
  crossref = {journal:springer:mta},
  volume = {50},
  number = {3},
  month = dec,
  year = {2010},
  pages = {587--607},
  doi = {10.1007/s11042-010-0481-7},
  abstract = {While watching TV, viewers use the remote control to turn the TV set on and off, change channel and volume, to adjust the image and audio settings, etc. Worldwide, research institutes collect information about audience measurement, which can also be used to provide personalization and recommendation services, among others. The interactive digital TV offers viewers the opportunity to interact with interactive applications associated with the broadcast program. Interactive TV infrastructure supports the capture of the user-TV interaction at fine-grained levels. In this paper we propose the capture of all the user interaction with a TV remote control -- including short term and instant interactions: we argue that the corresponding captured information can be used to create content pervasively and automatically, and that this content can be used by a wide variety of services, such as audience measurement, personalization and recommendation services. The capture of fine grained data about instant and interval-based interactions also allows the underlying infrastructure to offer services at the same scale, such as annotation services and adaptative applications. We present the main modules of an infrastructure for TV-based services, along with a detailed example of a document used to record the user-remote control interaction. Our approach is evaluated by means of a proof-of-concept prototype which uses the Brazilian Digital TV System, the Ginga-NCL middleware.},
  keywords = {Digital Interactive TV; Capture and access multimedia applications; User-media interaction}
}

@ARTICLE{Terrell-Caudill:2012,
  author = {Terrell, Robert L. and Caudill, Jason G.},
  title = {{OpenCourseWare}: open sharing of course content and design},
  crossref = {journal:ccsc:jcsc},
  volume = {27},
  number = {3},
  month = jan,
  year = {2012},
  pages = {38--42},
  abstract = {The OpenCourseWare movement has generated excitement in many circles through its potential contributions to both lifetime learning and ubiquitous learning. These courses are certainly beneficial to such groups, but OpenCourseWare can also make valuable contributions to traditional educational environments. Referencing established courses at some of the most prestigious universities in the world provides educational institutions of all types a means through which they can expose their students to the very highest levels of course design and subject matter. This paper will introduce the OpenCourseWare movement, its scope, and also how the materials may be applied to traditional educational environments.}
}

@INPROCEEDINGS{Terry-etal:2010,
  author = {Terry, Michael and Kay, Matthew and Lafreniere, Ben},
  title = {Perceptions and practices of usability in the free/open source software (FoSS) community},
  crossref = {proceedings:chi:2010},
  pages = {999--1008},
  doi = {10.1145/1753326.1753476},
  abstract = {This paper presents results from a study examining perceptions and practices of usability in the free/open source software (FOSS) community. 27 individuals associated with 11 different FOSS projects were interviewed to understand how they think about, act on, and are motivated to address usability issues. Our results indicate that FOSS project members possess rather sophisticated notions of software usability, which collectively mirror definitions commonly found in HCI textbooks. Our study also uncovered a wide range of practices that ultimately work to improve software usability. Importantly, these activities are typically based on close, direct interpersonal relationships between developers and their core users, a group of users who closely follow the project and provide high quality, respected feedback. These relationships, along with positive feedback from other users, generate social rewards that serve as the primary motivations for attending to usability issues on a day-to-day basis. These findings suggest a need to reconceptualize HCI methods to better fit this culture of practice and its corresponding value system.},
  keywords = {bleeding edge users, core users, reference users}
}

@INPROCEEDINGS{Tew-Guzdial:2010,
  author = {Tew, Allison Elliott and Guzdial, Mark},
  title = {Developing a validated assessment of fundamental CS1 concepts},
  crossref = {proceedings:sigcse:2010},
  pages = {97--101},
  doi = {10.1145/1734263.1734297},
  abstract = {Previous studies of student programming ability have raised questions about students' ability to problem solve, read and analyze code, and understand introductory computing concepts. However, it is unclear whether these results are the product of failures of student comprehension or our inability to accurately measure their performance. We propose a method for creating a language independent CS1 assessment instrument and present the results of our analysis used to define the common conceptual content that will serve as the framework for the exam. We conclude with a discussion of future work and our progress towards developing the assessment.},
  keywords = {assessment, cs1, programming, validity}
}

@INPROCEEDINGS{Tew-etal:2005,
  author = {Tew, Allison Elliott and McCracken, W. Michael and Guzdial, Mark},
  title = {Impact of alternative introductory courses on programming concept understanding},
  crossref = {proceedings:icer:2005},
  pages = {25--35},
  doi = {10.1145/1089786.1089789},
  abstract = {Computer science has long debated what to teach in the introductory course of the discipline, and leaders in our field have argued that the introductory course approach is critical to student development. We investigated the impact of alternative approaches to introductory computing by considering the questions of what students bring to their second class in computing and how the outcomes differ depending on the students' alternative first course. Our study showed significant differences in understanding of introductory concepts, such as iteration, conditionals, and arrays, at the beginning of the second course. However, by the end of the second course their understanding had converged.},
  keywords = {CS1, CS2, pedagogy, programming, understanding}
}

@INPROCEEDINGS{Thomas-etal:2002,
  author = {Lynda Thomas and Mark Ratcliffe and John Woodbury and Emma Jarman},
  title = {Learning Styles and Performance in the Introductory Programming Sequence},
  crossref = {proceedings:sigcse:2002},
  pages = {33--42},
  doi = {10.1145/563340.563352},
  abstract = {This paper reports on the implication of different preferred learning styles on students' performance in the introductory programming sequence and on work in progress on how to accommodate these different styles.Students were given a learning styles preference test and then their preferred learning styles were compared to their performance on the exam and the practical programming part of the introductory programming module. There were significant differences in performance between groups of students.This result could lead one to two possible conclusions. One might be that some students' learning styles are more suited to learning programming than others.An alternative explanation is that our current methods of teaching advantage students with certain learning preference styles. We are at present in the process of testing this second assumption by providing students with a wider range of learning materials. We will then see if student performance is improved by using our current results as a baseline for comparison},
  keywords = {Learning styles, Software Engineering Education, Introductory programming, Diagnostic testing, Student profiling}
}

@INPROCEEDINGS{Thomas:2009:GDR:1562877.1562973,
  author = {Thomas, Pete and Waugh, Kevin and Smith, Neil},
  title = {Generalised diagram revision tools with automatic marking},
  crossref = {proceedings:itcse:2009},
  pages = {318--322},
  doi = {10.1145/1562877.1562973},
  abstract = {In this paper, we describe an approach to the generalisation of tools for teaching and learning the skills associated with modelling with diagrams. We have implemented two revision tools that automatically mark and provide feedback on students' attempts at constructing diagrammatic models of given scenarios in different domains. The similarities between these tools and diagrams in other domains suggest that it might be possible to generalise both the marking algorithm and the drawing editor in such a way that new revision tools could be easily generated for new domains. This paper briefly describes the existing revision tools and our approach to automatic marking of diagrams, and discusses how we are approaching the generalisation of our work for application in other domains.},
  keywords = {automatic marking, diagrams, feedback, learning tools},
  timestamp = {2013-08-23}
}

@ARTICLE{Thompson-Chadhuri:2011,
  author = {Thompson, Hussein and Chadhuri, Pranay},
  title = {An alternative visual analysis of the build heap algorithm},
  crossref = {journal:acm:inroads},
  volume = {2},
  number = {3},
  month = aug,
  year = {2011},
  pages = {31--32},
  doi = {10.1145/2003616.2003630},
  abstract = {This article presents an alternative visual analysis of the BUILDHEAP algorithm provided by Goodrich and Tamassia. The analysis is based only on elementary properties of complete binary trees and a simple comparison of the areas of rectangles. As such, it should be accessible to a wide cross-section of students taking a typical algorithm design and analysis course.},
  keywords = {areas of rectangles, heaps, visual proof},
  acmid = {2003630},
  issue = {3},
  issue_date = {September 2011},
  lang = {en},
  numpages = {2}
}

@INPROCEEDINGS{Tillmann-etal:2011,
  author = {Tillmann, N. and De Halleux, J. and Tao Xie},
  title = {{Pex4Fun}: Teaching and learning computer science via social gaming},
  crossref = {proceedings:cseet:2011},
  pages = {546--548},
  doi = {10.1109/CSEET.2011.5876146},
  abstract = {Pex4Fun from Microsoft Research is a web-based serious gaming environment for teaching computer science. Pex4Fun can be used to teach and learn computer programming at many levels, from high school all the way through graduate courses. With Pex4Fun, a student edits code in any browser - with Intellisense - and Pex4Fun executes it and analyzes it in the cloud. Pex4Fun connects teachers, curriculum authors, and students in a unique social experience, tracking and streaming progress updates in real time. In particular, Pex4Fun finds interesting and unexpected input values that help students understand what their code is actually doing. The real fun starts with coding duels where students write code to implement a teacher's specification. Pex4Fun finds any discrepancies in behavior between the student's code and the specification. This tutorial equips participants with skills and knowledge of using Pex4Fun in teaching and learning, such as solving puzzles, solving coding duels, exploring course materials in feature courses, creating and teaching a course, creating and publishing coding duels, and learning advanced topics behind Pex4Fun.}
}

@INPROCEEDINGS{Tillmann-etal:2013,
  author = {Tillmann, Nikolai and De Halleux, Jonathan and Xie, Tao and Gulwani, Sumit and Bishop, Judith},
  title = {Teaching and learning programming and software engineering via interactive gaming},
  crossref = {proceedings:icse:2013},
  pages = {1117--1126},
  abstract = {Massive Open Online Courses (MOOCs) have recently gained high popularity among various universities and even in global societies. A critical factor for their success in teaching and learning effectiveness is assignment grading. Traditional ways of assignment grading are not scalable and do not give timely or interactive feedback to students. To address these issues, we present an interactive-gaming-based teaching and learning platform called Pex4Fun. Pex4Fun is a browser-based teaching and learning environment targeting teachers and students for introductory to advanced programming or software engineering courses. At the core of the platform is an automated grading engine based on symbolic execution. In Pex4Fun, teachers can create virtual classrooms, customize existing courses, and publish new learning material including learning games. Pex4Fun was released to the public in June 2010 and since then the number of attempts made by users to solve games has reached over one million. Our work on Pex4Fun illustrates that a sophisticated software engineering technique -- automated test generation -- can be successfully used to underpin automatic grading in an online programming system that can scale to hundreds of thousands of users.}
}

@INPROCEEDINGS{Tillmann-etal:2014,
  author = {Tillmann, Nikolai and Halleux, Jonathan and Xie, Tao and Bishop, Judith},
  title = {Constructing Coding Duels in Pex4Fun and Code Hunt},
  crossref = {proceedings:issta:2014},
  pages = {445--448},
  doi = {10.1145/2610384.2628054},
  abstract = {Pex is an automatic white-box test-generation tool for .NET. We have established that games can be built on top of Pex to open the tool to students and to the general public. In particular, we have released Pex4Fun (www.pexforfun.com) and its successor Code Hunt (www.codehunt.com) as web-based educational gaming environments for teaching and learning programming and software engineering. In Pex4Fun and Code Hunt, the main game type is a coding duel, where a player writes code in a method to achieve the same functionality as the secret method implementation, based on feedback provided by the underlying Pex tool. Players iteratively modify their code to match the functional behavior of the secret method. The scope of duels extends from the simplest one-line method to those including advanced concepts such as writing parameterized unit tests and code contracts. We have also used the game type for competitions with thousands of players, and have found that it differentiates well between beginners and top coders. This tool demonstration shows how coding duels in Pex4Fun and Code Hunt can be constructed and used in teaching and training programming and software engineering.},
  keywords = {Symbolic execution, educational platforms, gaming for learning},
  owner = {magsilva},
  timestamp = {2014.07.21}
}

@ARTICLE{Tims-Williams:2012,
  author = {Tims, Jodi L. and Williams, Susan R.},
  title = {The TauRUs project: a complement to the Taulbee report},
  crossref = {journal:acm:inroads:3:1},
  pages = {62--73},
  doi = {10.1145/2077808.2077827},
  keywords = {Taulbee survey, computing education data and analysis, computing survey, computing trends}
}

@INPROCEEDINGS{Tirronen-Isomottonen:2011,
  author = {Tirronen, Ville and Isomöttönen, Ville},
  title = {Making teaching of programming learning-oriented and learner-directed},
  crossref = {proceedings:koli-calling:2011},
  pages = {60--65},
  doi = {10.1145/2094131.2094143},
  abstract = {Programming education has been traditionally realized in the form of lecturing, but other approaches are under discussion. These emphasize active participation on the part of students, and, as a research activity, consider pedagogic questions holistically. We join this discussion by stating a course design in which we promote a learning-oriented study culture where learning should not be characterized principally as the task of meeting some predefined completion requirements. Moreover, we want our course to be learner-directed meaning that students should take control over their own learning process. Grounded on these goals, this discussion paper gives us a starting point for a subsequent action research undertaking.},
  keywords = {functional programming, learner-centered teaching, programming education}
}

@INPROCEEDINGS{Tirronen-Isomottonen:2012,
  author = {Tirronen, Ville and Isomöttönen, Ville},
  title = {On the design of effective learning materials for supporting self-directed learning of programming},
  crossref = {proceedings:koli-calling:2012},
  pages = {74--82},
  doi = {10.1145/2401796.2401805},
  abstract = {This paper reports on the action research that studies how to implement self-directed learning of programming in the academic context. Based on our findings from the previous steps with this research agenda, we focus on the design of learning materials. That is, we aim to facilitate the students' self-directed learning by developing illustrative and concise materials that the students could use to efficiently develop theoretical understanding of the learning topics. In designing the materials, we will rely on the cognitive load theory as the guiding theoretical framework. The paper demonstrates the planning stage of our second action research cycle.},
  keywords = {cognitive load theory, functional programming, programming education, self-direction}
}

@ARTICLE{Tom-etal:2013,
  author = {Edith Tom and Aybüke Aurum and Richard Vidgen},
  title = {An exploration of technical debt },
  crossref = {journal:elsevier:jss},
  volume = {86},
  number = {6},
  month = jun,
  year = {2013},
  pages = {1498--1516},
  doi = {10.1016/j.jss.2012.12.052},
  abstract = {Context Whilst technical debt is considered to be detrimental to the long term success of software development, it appears to be poorly understood in academic literature. The absence of a clear definition and model for technical debt exacerbates the challenge of its identification and adequate management, thus preventing the realisation of technical debt's utility as a conceptual and technical communication device. Objective To make a critical examination of technical debt and consolidate understanding of the nature of technical debt and its implications for software development. Method An exploratory case study technique that involves multivocal literature review, supplemented by interviews with software practitioners and academics to establish the boundaries of the technical debt phenomenon. Result A key outcome of this research is the creation of a theoretical framework that provides a holistic view of technical debt comprising a set of technical debts dimensions, attributes, precedents and outcomes, as well as the phenomenon itself and a taxonomy that describes and encompasses different forms of the technical debt phenomenon. Conclusion The proposed framework provides a useful approach to understanding the overall phenomenon of technical debt for practical purposes. Future research should incorporate empirical studies to validate heuristics and techniques that will assist practitioners in their management of technical debt. },
  keywords = {Technical debt, Code debt, Precedents, Outcomes, Benefits and drawbacks, Multivocal literature review}
}

@INPROCEEDINGS{Torres-etal:2013,
  author = {José Torres and Daniela Cruzes and Laís Salvador},
  title = {Automatically Locating Results to Support Systematic Reviews in Software Engineering},
  crossref = {proceedings:eselaw:2013},
  abstract = {Background: Systematic Reviews are extremely dependent on human effort and, therefore, costly and time consuming. Some authors in Software Engineering are starting to research the use of computer support to reduce human labor in some tasks of the process. Aim: Define a method for automatic location of sentences that describe the results in an unstructured scientific paper aiming to reduce the human effort. Method: Three sentence classification methods were analyzed and a new sentence classification method was proposed and tested with the same input set used in the other methods. Results: The method proposed in this work reached rates ranged between 60% and 72% of recall of the sentences describing results of the papers. Conclusions: The proximity between the recall rates found in automatic tests conducted with the proposed method and in a test with humans confirms the feasibility of this technique for automating part of the process.}
}

@ARTICLE{Trakhtenbrot:1984,
  author = {Trakhtenbrot, B. A.},
  title = {A Survey of Russian Approaches to {Perebor} (Brute-Force Searches) Algorithms},
  crossref = {journal:ieee:history-computing},
  volume = {6},
  number = {4},
  month = oct # {--} # dec,
  year = {1984},
  pages = {384--400},
  doi = {10.1109/MAHC.1984.10036},
  abstract = {Concerns about computational problems requiring brute-force or exhaustive search methods have gained particular attention in recent years because of the widespread research on the "P = NP?" question. The Russian word for "brute-force search" is "perebor. " It has been an active research area in the Soviet Union for several decades. Disputes about approaches to perebor had a certain influence on the development, and developers, of complexity theory in the Soviet Union. This paper is a personal account of some events, ideas, and academic controversies that surrounded this topic and to which the author was a witness and-to some extent-a participant. It covers a period that started in the 1950s and culminated with the discovery and investigation of non-deterministic polynomial (NP)-complete problems independently by S. Cook and R. Karp in the United States and L. Levin in the Soviet Union.}
}

@ARTICLE{Trienekens-etal:2010,
  author = {Trienekens, Jos J. M. and Kusters, Rob J. and Brussel, Dennis C.},
  title = {Quality specification and metrication, results from a case-study in a mission-critical software domain},
  crossref = {journal:springer:sqj},
  volume = {18},
  number = {4},
  month = dec,
  year = {2010},
  pages = {469--490},
  doi = {10.1007/s11219-010-9101-z},
  abstract = {Software quality is of increasing importance in mission-critical embedded software systems. Due to the fast growing complexity and accompanying risks of failures of these systems, software quality needs to be addressed explicitly by software developers, preferably with a systematic method for an optimal implementation of software qualities, such as reliability, time-behavior and usability. At the Centre of Automation of Mission-critical Systems (CAMS) of the Dutch Royal Navy, a new approach has been defined for software developers to improve the way that they deal with software quality in the process of mission-critical systems engineering. The stepwise approach is based on both an international quality standard for software product quality, i.e. ISO9126, and on Multi-Criteria Decision Making techniques, i.e. analytical hierarchy process (AHP). The stepwise approach has been validated in a case study. In particular, the tailoring of the ISO9126 standard toward the specific CAMS development situation, and the applicability of AHP techniques, from the perspective of software developers, has been investigated. The case study is carried out in a representative software development project, i.e. the software for combat management systems (CMS) of warships. Results of the case study show that software developers can explicitly deal with quality on the basis of both the ISO9126 standard and the AHP techniques, respectively regarding the specification, prioritization and metrication of software product quality.},
  keywords = {Software quality; Specification; ISO 9126; AHP; Prioritization; Metrication}
}

@INPROCEEDINGS{Trindade-etal:2009,
  author = {Trindade, Cleyton C. and Barbosa, Yuri A. M. and Moraes, Alan K. O. and Albuquerque, Jones O. and Meira, Silvio R. L.},
  title = {An Expert Recommender System to Distributed Software Development: Requirements, Project and Preliminary Results},
  crossref = {proceedings:sbsc:2009},
  pages = {161--168},
  doi = {10.1109/SBSC.2009.29},
  abstract = {In distributed software development, geographical and temporal distances turn communication inefficient and affect the various team's perceptions levels - proximity, activity, awareness, process and perspective. The low level of perception turns the task of expert location hard and not being able to quickly locate the experts in the source code during the implementation makes the project slower, consequently delaying its schedule. This paper proposes Presley, a tool to reduce these delays through identification and recommendation of experts in some areas of the source code using the project communication, decreasing the waiting time for help. We also present preliminary results which show the practical potential of our approach.},
  keywords = {distributed software development; expert recommender system; knowledge management}
}

@ARTICLE{Trotman-Handley:2008,
  author = {Trotman, Andrew and Handley, Chris},
  title = {Programming contest strategy},
  crossref = {journal:elsevier:ce},
  volume = {50},
  number = {3},
  month = apr,
  year = {2008},
  pages = {821--837},
  doi = {10.1016/j.compedu.2006.08.008},
  abstract = {Each year the ACM hosts a truly international programming contest - the International Collegiate Programming Contest (ICPC). Dating back to a contest held by Texas A&M University in 1970, this annual event, along with the associated regional contests, has grown to 5606 teams from 1733 universities in 84 countries (in the year 2006). Despite the maturity of the event, and the number of competitors, there has never been a systematic examination of contest strategy. Herein several strategies are proposed and examined to determine whether a team can gain an advantage by choosing a good strategy; and, if so, then what that strategy should be. We show that a team can gain an advantage by choosing a good strategy, but that there is no one best strategy. A team must choose between winning by number of solved problems and winning by points. Finding the optimal strategy to win by problems is shown to be NP-complete, while to win by points a team must solve problems in order from easiest to hardest.},
  keywords = {Programming contest}
}

@INPROCEEDINGS{Tucker-etal:2011,
  author = {Tucker, A. and Morelli, R. and de Lanerolle, T.},
  title = {The Humanitarian {FOSS} Project: Goals, Activities, and Outcomes},
  crossref = {proceedings:ghtc:2011},
  pages = {98-101},
  doi = {10.1109/GHTC.2011.78},
  abstract = {Begun in 2006, the Humanitarian Free and Open Source Software Project (HFOSS Project) is an educational initiative whose goal is to engage undergraduates in computer science by building free and open source software that benefits humanity, both locally and globally. During its short lifetime, the Project has inspired increasing numbers of students and instructors to make significant contributions to several humanitarian open source software development projects. In the last four years, the HFOSS Project has received material support from several partners, including the National Science Foundation, Accenture, Google, and Mozilla. This support has enabled the Project to expand its reach to add new college and university partners and to add more humanitarian software projects. Contributions to the HFOSS Project come from professionals in academia, IT organizations, and non-profit organizations that engage undergraduate students in courses, research projects, and summer internship experiences. Its curriculum is accessible to a wide range of undergraduates, since it includes courses for non- majors as well as computer science and engineering majors. This paper describes all these activities and their impact on undergraduate computing education, local non-profit organizations, and global FOSS communities. It concludes by identifying the progress that the HFOSS Project has made toward developing a sustainable infrastructure.},
  keywords = {software engineering; education;humanitarian; curriculum, open source; tools and techniques}
}

@ARTICLE{Tung-ShianShyong:2013,
  author = {Yuan-Hsin Tung and Shian-Shyong Tseng},
  title = {A novel approach to collaborative testing in a crowdsourcing environment },
  crossref = {journal:elsevier:jss},
  volume = {86},
  number = {8},
  month = aug,
  year = {2013},
  pages = {2143--2153},
  doi = {10.1016/j.jss.2013.03.079},
  abstract = {Abstract Software testing processes are generally labor-intensive and often involve substantial collaboration among testers, developers, and even users. However, considerable human resource capacity exists on the Internet in social networks, expert communities, or internet forums -- referred to as crowds. Effectively using crowd resources to support collaborative testing is an interesting and challenging topic. This paper defines the collaborative testing problem in a crowd environment as an NP-Complete job assignment problem and formulates it as an integer linear programming (ILP) problem. Although package tools can be used to obtain the optimal solution to an \{ILP\} problem, computational complexity makes these tools unsuitable for solving large-scale problems. This study uses a greedy approach with four heuristic strategies to solve the problem. This is called the crowdsourcing-based collaborative testing approach. This approach includes two phases, training phase and testing phase. The training phase transforms the original problem into an \{ILP\} problem. The testing phase solves the \{ILP\} using heuristic strategies. A prototype system, called the Collaborative Testing System (COTS), is also implemented. The experiment results show that the proposed heuristic algorithms produce good quality approximate solutions in an acceptable timeframe.},
  keywords = {Crowdsourcing; Cloud computing; Software testing; Collaborative testing; Integer linear programming }
}

@INPROCEEDINGS{Turhan-etal:2010,
  author = {Turhan, Burak and Bener, Ayse and Kuvaja, Pasi and Oivo, Markku},
  title = {A Quantitative Comparison of Test-First and Test-Last Code in an Industrial Project},
  crossref = {proceedings:xp:2010},
  pages = {232--237},
  doi = {10.1007/978-3-642-13054-0_24},
  abstract = {This paper presents a comparison of test-first and test-last development approaches on a customer account management software of a telecommunication company. While the management had plans for initiating a process that enforces test-first development over test-last, they also had concerns about the tradeoffs. Therefore, an exploratory case study with quantitative analysis is carried out on a pilot project where the code metrics and estimated manual inspection efforts of both approaches are compared. Our results indicate no statistical difference between the two approaches in terms of design (CK) metrics. On the other hand, we observe that test-last development yields significantly simpler code in terms of cyclomatic complexity and less (though not significant) manual inspection effort. Hence, our initial results indicate no superiority of test-first over test-last development in the described industrial context.},
  keywords = {Test first; Test last; Code metrics; Case study},
  owner = {magsilva},
  timestamp = {2014.10.20}
}

@INPROCEEDINGS{Tymchuk-etal:2014,
  author = {Tymchuk, Yuriy and Mocci, Andrea and Lanza, Michele},
  title = {Collaboration in Open-source Projects: Myth or Reality?},
  crossref = {proceedings:msr:2014},
  pages = {304--307},
  doi = {10.1145/2597073.2597093},
  abstract = {One of the fundamental principles of open-source projects is that they foster collaboration among developers, disregarding their geographical location or personal background. When it comes to software repositories collaboration is a rather ephemeral phenomenon which lacks a clear definition, and it must therefore be mined and modeled. This throws up the question whether what is mined actually maps to reality. In this paper we investigate collaboration by modeling it using a number of diverse approaches that we then compare to a ground truth obtained by surveying a substantial set of developers of the Pharo open-source community. Our findings indicate that the notion of collaboration must be revisited, as it is undermined by a number of factors that are often tackled in imprecise ways or not taken into account at all.},
  keywords = {Software ecosystems, collaboration},
  owner = {magsilva},
  timestamp = {2014.05.21}
}

@INPROCEEDINGS{Umphress-Hamilton:2002,
  author = {Umphress, D. A and Hamilton, J. A},
  title = {Software process as a foundation for teaching, learning, and accrediting},
  crossref = {proceedings:cseet:2002},
  pages = {160--169},
  doi = {10.1109/CSEE.2002.995208},
  abstract = {This paper describes experiences over ten academic terms in teaching a course on software development processes. Significant lessons learned include: (1) supplementing general information on processes with a hands-on in-class process (personal software process, in this case); (2) using a tool to assist in collecting and managing process data to meet the learning needs (Excel spreadsheets, in this case); and (3) using the process data obtained in the course as a means of supporting accreditation objectives},
  keywords = {accreditation;computer science education;educational courses;software engineering;teaching;accreditation;educational course;learning;personal software process;software development processes;teaching;Accreditation;Computer science;Education;Layout;Programming;Robustness;Software engineering;Software measurement;Software performance;Software quality},
  owner = {magsilva},
  timestamp = {2014.09.13}
}

@ARTICLE{Underwood:2013,
  author = {Sarah Underwood},
  title = {The {Alan Turing} Year leaves a rich legacy},
  crossref = {journal:acm:cacm},
  volume = {56},
  number = {10},
  month = oct,
  year = {2013},
  pages = {24--25},
  doi = {10.1145/2507771.2507785},
  abstract = {A year-long celebration of the life and work of a man whom many call the founding father of computer science.},
  owner = {magsilva},
  timestamp = {2014.01.16}
}

@INPROCEEDINGS{Bergh-etal:2007,
  author = {Van den Bergh, Jan and Bruynooghe, Bert and Moons, Jan and Huypens, Steven and Handekyn, Koen and Coninx, Karin},
  title = {Model-Driven Creation of Staged Participatory Multimedia Events on TV},
  crossref = {proceedings:euroitv:2007},
  pages = {21--30},
  doi = {10.1007/978-3-540-72559-6_3},
  abstract = {Broadcasted television shows are becoming more interactive. Some shows even let home viewers without professional equipment be part of a broadcasted television show. Staged Participatory Multimedia Events on TV take this approach another step further. In this type of television shows, viewers can not only participate in the show through interaction or videostreams, but also direct the show. In this paper we discuss this type of participation TV into more detail and discuss the models allowing quick and graphical creation of the structure of a format. The models can be serialized to a set of XML-files, which can be interpreted by the ParticipationTV runtime. Working proof-of-concept implementations for creating the models, generating the XML-files and the runtime that interprets the XML-files have been realized.}
}

@INPROCEEDINGS{Silva-MuchaluatSaade:2012,
  author = {Varanda da Silva, Júlia and Christina Muchaluat-Saade, Débora},
  title = {{NEXT}: graphical editor for authoring {NCL} documents supporting composite templates},
  crossref = {proceedings:webmedia:2012},
  pages = {387--394},
  doi = {10.1145/2382636.2382717},
  abstract = {Interactive multimedia application development can be facilitated and more attractive to non-expert authors through the use of graphical editors. In a graphical environment that permits creation and edition of multimedia documents and offers different views of the document as a whole, it is possible to develop applications with less difficulty. In addition, if the editor provides templates, the development can be easier as, in that case, the author can use a pre-configured document and fulfill it with its own media content. This paper presents NEXT - NCL Editor supporting XTemplate, a graphical editor that allows development of NCL documents using hypermedia composite templates, which represent generic structures of NCL context nodes. Composite templates can be created with the XTemplate 3.0 language. Besides supporting templates, NEXT is based on a kernel and a set of plugins, which allow its extensibility and adaptability to different author skills.},
  keywords = {NCL, NEXT, TV digital, Xtemplate, editor gr?fico, ferramenta de autoria, plugins, templates de composi??o hiperm?dia}
}

@ARTICLE{Vardi:2013,
  author = {Vardi, Moshe Y.},
  title = {Who begat computing?},
  crossref = {journal:acm:cacm},
  volume = {56},
  number = {1},
  month = jan,
  year = {2013},
  pages = {5--5},
  doi = {10.1145/2398356.2398357}
}

@ARTICLE{Vardi:2012a,
  author = {Vardi, Moshe Y.},
  title = {What is an algorithm?},
  crossref = {journal:cacm},
  volume = {55},
  number = {3},
  month = mar,
  year = {2012},
  pages = {5--5},
  doi = {10.1145/2093548.2093549}
}

@ARTICLE{Vardi:2012b,
  author = {Vardi, Moshe Y.},
  title = {Predatory scholarly publishing},
  crossref = {journal:acm:cacm},
  volume = {55},
  number = {7},
  month = jul,
  year = {2012},
  pages = {5--5},
  doi = {10.1145/2209249.2209250}
}

@INPROCEEDINGS{Vasilescu-etal:2013,
  author = {Bogdan Vasilescu and Alexander Serebrenik and Tom Mens},
  title = {A Historical Dataset of Software Engineering Conferences},
  crossref = {proceedings:msr:2013},
  pages = {373--376},
  doi = {10.1109/MSR.2013.6624051},
  abstract = {The Mining Software Repositories community typically focuses on data from software configuration management tools, mailing lists, and bug tracking repositories to uncover interesting and actionable information about the evolution of software systems. However, the techniques employed and the challenges faced when mining are not restricted to these types of repositories. In this paper, we present an atypical dataset of software engineering conferences, containing historical data about the accepted papers and the composition of programme committees for eleven well-established conferences. The dataset (published on Github at https://github.com/tue-mdse/conferenceMetrics) can be used, e.g., by conference steering committees or programme committee chairs to assess their selection process and compare against other conferences in the field, or by prospective authors to decide in which conferences to publish.}
}

@INCOLLECTION{RodriguesVaz:2009,
  author = {Maria Fernanda Rodrigues Vaz},
  title = {Os padrões internacionais para a construção de material educativo on-line},
  chapter = {53},
  pages = {386-394},
  crossref = {Litto-Formiga:2009}
}

@ARTICLE{VazquezPoletti-etal:2013,
  author = {J. L. Vazquez-Poletti and R. Moreno-Vozmediano and R. S. Montero and E. Huedo and I. M. Llorente},
  title = {Solidifying the foundations of the cloud for the next generation Software Engineering },
  crossref = {journal:elsevier:jss},
  volume = {86},
  number = {9},
  month = sep,
  year = {2013},
  pages = {2321--2326},
  doi = {10.1016/j.jss.2013.05.063},
  abstract = {Abstract Infrastructure clouds are expected to play an important role in the next generation Software Engineering but currently there are some drawbacks. These clouds are too infrastructure oriented and they lack advanced service oriented capabilities such as service elasticity, quality of service or admission control to perform a holistic management of a whole application. The deployment of complex multi-tier applications on top of IaaS infrastructures requires to provide the IaaS platforms with an extra service layer that provides advanced service management functionality. },
  keywords = {Cloud computing, IaaS },
  timestamp = {2013-09-05}
}

@INPROCEEDINGS{VegaOliveiros-etal:2009,
  author = {Vega Oliveiros, Didier A. and Pedrosa, Diogo C. and Pimentel, Maria da Graça Campos and Goularte, Rudinei},
  title = {Navegação em Vídeo via Quadros Recentes},
  crossref = {proceedings:webmedia:2009},
  pages = {1--4},
  doi = {10.1145/1858477.1858513},
  keywords = {navegação em vídeo, TV digital interativa, Ginga, Nested Content Language, NCL, Lua, HCI, memória episódica},
  series = {WebMedia '09},
  abstract-en = {The large number of television channels offered by the digital TV, combined with the possibility of recording the audiovisual content offered by various decoders, requires the development of tools that help the viewer with the task of temporal and spatial (between channels) content navigation. This work proposes a timeline-based model which, allows users to select frames of interest at starting points for video playback.},
  acmid = {1858513},
  address = {New York, NY, USA},
  articleno = {36},
  isbn = {978-1-60558-880-3},
  lang = {pt},
  numpages = {4},
  title-en = {Video navigation based on recent frames}
}

@INPROCEEDINGS{VegaOliveros-etal:2010,
  author = {Vega-Oliveros, Didier Augusto and Pedrosa, Diogo de Carvalho and Pimentel, Maria da Graça Campos and de Mattos Fortes, Renata Pontin},
  title = {An approach based on multiple text input modes for interactive digital {TV} applications},
  crossref = {proceedings:sigdoc:2010},
  pages = {191--198},
  doi = {10.1145/1878450.1878483},
  abstract = {The development of interactive digital TV applications is hindered by the user-interaction options allowed when traditional remote controls are used. In this work, we describe the model of a software component that allows text entry in interactive TV applications based on an interface with multiple input modes --- the component offers a virtual keyboard mode, a cell keypad mode, and a speech mode. We discuss our considerations with respect to the design, development and evaluation of a prototype corresponding to our model, built according to the user-centered design methodology. After conducting a research on existing text input methods in television systems, we interviewed four experts in the interactive TV domain. We also applied 153 questionnaires to TV users, with the aim of gathering a user profile of users who make use of text entry mechanisms. During the development of the prototype, we conducted usability tests using the think aloud protocol, and usability inspections using the heuristic evaluation and cognitive walkthrough techniques. The evaluations allowed the detection of both, a number of problems and of several improvement opportunities; at the same time that they highlighted the importance of using complementary text input modes in order to satisfy the needs of different users. Overall, the evaluation results suggest that the proposed approach provides a satisfactory level of usability by overcoming the limitations of text input in the context of user-interaction with interactive TV applications.},
  keywords = {interactive digital TV, multi-tap, multiple input modes, predictive text, text input, virtual keyboard}
}

@INPROCEEDINGS{VelazquezIturbide-etal:2008,
  author = {Velázquez-Iturbide, J. Ángel and Pérez-Carrasco, Antonio and Urquiza-Fuentes, Jaime},
  title = {{SRec}: an animation system of recursion for algorithm courses},
  crossref = {proceedings:itcse:2008},
  pages = {225--229},
  doi = {10.1145/1384271.1384332},
  abstract = {In this paper we describe SRec, a system to animate recursion in Java programs. It is intended to assist in algorithm courses to better understand and analyze algorithm behavior. We make several contributions. Firstly, SRec exhibits a comprehensive set of animation and educational features. It provides three complem- entary, coordinated views of recursion: traces, the execution stack and activation trees. SRec allows the user constructing and modifying animations without effort. The animation can be played flexibly, both forward and backwards. It also provides facilities to integrate animations into courses. Secondly, the paper describes the educational features of the system and its use in algorithm courses. Thirdly, the system has been fully evaluated with respect to usability (using formative and summative methods) and has been compared to other systems reported in the literature. The results of both evaluations are highly positive.},
  keywords = {activation trees, program animation, recursion, usability}
}

@ARTICLE{Vergilio-etal:2006:JBCS,
  author = {Silvia Regina Vergilio and José Carlos Maldonado and Mario Jino},
  title = {Infeasible paths in the context of data flow based testing criteria: identification, classification and prediction},
  crossref = {proceedings:sbc:jbcs},
  volume = {12},
  number = {1},
  month = jun,
  year = {2006},
  pages = {73--88},
  doi = {10.1007/BF03192389},
  abstract = {Infeasible paths constitute a bottleneck for the complete automation of software testing, one of the most expensive activities of software quality assurance. Research efforts have been spent on infeasible paths, basically on three main approaches: prediction, classification and identification of infeasibility. This work reports the results of experiments on data flow based criteria and of studies aimed at the three approaches above. Identification, classification, and prediction of infeasible paths are revisited in the context of data flow based criteria (Potential Uses Criteria-PU). Additionally, these aspects are also addressed in the scope of integration and object-oriented testing. Implementation aspects of mechanisms and facilities to deal with infeasibility are presented taking into consideration Poketool -- a tool that supports the application of the Potential Uses Criteria Family. The results and ideas presented contribute to reduce the efforts spent during the testing activity concerning infeasible paths.},
  keywords = {software testing; data flow based criteria; infeasible paths}
}

@ARTICLE{Virgilio-etal:2001,
  author = {Vergilio, Silvia Regina and Maldonado, José Carlos and Jino, Mario},
  title = {Constraint Based Criteria: An Approach for Test Case Selection in the Structural Testing},
  crossref = {journal:springer:jet},
  volume = {17},
  number = {2},
  month = apr,
  year = {2001},
  pages = {175--183},
  doi = {10.1023/A:1011130028226},
  abstract = {The selection of test cases to satisfy a structural testing criterion is a very important task because it concerns the quality of the generated test cases. The question is ``How to select a test case or path to cover an element required by a structural criterion?'' The Constraint Based Criteria are proposed with the goal of answering this question and improving the efficacy, that is, the number of revealed faults. These criteria permit the use of different testing strategies by associating constraints to the required elements. The constraints describe faults generally not revealed by the structural technique. The Constraint Based Criteria can also be used to assess test data sets adequacy.},
  keywords = {structural testing criteria; constraint based testing; mutation analysis}
}

@ARTICLE{Vergilio-etal:2006:JSS,
  author = {Silvia Regina Vergilio and José Carlos Maldonado and Mario Jino and Inali Wisniewski Soares},
  title = {Constraint based structural testing criteria},
  crossref = {journal:elsevier:jss},
  volume = {79},
  number = {6},
  month = jun,
  year = {2006},
  pages = {756--771},
  doi = {10.1016/j.jss.2005.06.012},
  abstract = {Structural criteria generally divide the input domain of the program under test and require the execution of at least one point from each derived sub-domain without addressing the most relevant question: ``Which points from each sub-domain should be selected?''. This question is related to data-sensitive faults which lead to one of the drawbacks of the testing activity. The constraints and conditions used by fault-based data generation techniques describe faults related to the boundaries of these sub-domains. Our conjecture is that we would improve the efficacy of the adequate test case sets by associating those constraints and conditions to the elements required by a criterion. With this goal, this work presents Constraint Based Criteria (CBC) that associate a constraint C to an element E, required by a structural criterion. CBC allow to combine the fundamentals of different testing generation techniques with structural testing, increasing the probability of revealing faults described by C. We also discuss complexity, inclusion relation and automation aspects of CBC. Results from three experiments of CBC evaluation using the factors cost, efficacy and strength provide evidence that our objectives have been achieved. We also present some results from the evaluation of random test sets.},
  keywords = {data flow based criteria; constraint based testing; mutation analysis}
}

@ARTICLE{Verhoeff:2006,
  author = {Verhoeff, Tom},
  title = {The {IOI} is (Not) a {Science Olympiad}},
  crossref = {journal:imi:ie},
  volume = {5},
  number = {1},
  month = jan,
  year = {2006},
  pages = {147--159},
  abstract = {The International Olympiad in Informatics (IOI) aspires to be a science olympiad alongside such international olympiads in mathematics, physics, chemistry, and biology. Informatics as a discipline is well suited to a scientific approach and it offers numerous possibilities for competitions with a high scientific standing. We argue that, in its current form, the IOI fails to be scientific in the way it evaluates the work of the contestants.In this paper, we describe the major ingredients of the IOI to guide further discussions. By presenting the results of an extensive analysis of two IOI competition tasks, we hope to create an awareness of the urgency to address the shortcomings. We offer some suggestions to raise the scientific quality of the IOI.},
  keywords = {computer science, informatics competitions, programming contests},
  owner = {magsilva},
  timestamp = {2014.08.30}
}

@INPROCEEDINGS{Vianna-Bruno:2009,
  author = {Vianna, Henrique Damasceno and Bruno, Gaspare Giuliano Elias},
  title = {Um modelo de ambiente orientado a serviços MPEG-7},
  crossref = {proceedings:webmedia:2009},
  pages = {61--64},
  doi = {10.1145/1809980.1809997},
  keywords = {MPEG-7, SOA, XQuery, component oriented model, multimedia},
  abstract-en = {With the ever growing multimedia content usage on the internet a need for a standard that could facilitate this content search and access developed. MPEG-7 - also known as Multimedia Content Description Interface - was created to describe multimedia metadata. A great number of MPEG-7 studies has been made, but none of them attempts at creating a model which could integrate different kinds of MPEG-7 applications. This work presents such model, using service-oriented architecture. The service-oriented environment model is composed of three layers Descriptors Base, Services, and Services Directory. Aided by service composition, it is possible to create innumerous multimedia applications, who would make use of the MPEG-7 standard. The environment is disposed in a service-oriented architecture, thus facilitating the creation and acquisition of new functionalities to the model.},
  acmid = {1809997}
}

@INPROCEEDINGS{Vihavainen-etal:2014,
  author = {Vihavainen, Arto and Airaksinen, Jonne and Watson, Christopher},
  title = {A Systematic Review of Approaches for Teaching Introductory Programming and Their Influence on Success},
  crossref = {proceedings:icer:2014},
  pages = {19--26},
  doi = {10.1145/2632320.2632349},
  abstract = {Decades of effort has been put into decreasing the high failure rates of introductory programming courses. Whilst numerous studies suggest approaches that provide effective means of teaching programming, to date, no study has attempted to quantitatively compare the impact that different approaches have had on the pass rates of programming courses. In this article, we report the results of a systematic review on articles describing introductory programming teaching approaches, and provide an analysis of the effect that various interventions can have on the pass rates of introductory programming courses. A total of 60 pre-intervention and post-intervention pass rates, describing thirteen different teaching approaches were extracted from relevant articles and analyzed. The results showed that on average, teaching interventions can improve programming pass rates by nearly one third when compared to a traditional lecture and lab based approach.},
  keywords = {analysis, cs1, introductory programming, programming education, systematic review, teaching interventions},
  owner = {magsilva},
  timestamp = {2014.09.13}
}

@INPROCEEDINGS{Vihavainen-etal:2012,
  author = {Vihavainen, Arto and Luukkainen, Matti and Kurhila, Jaakko},
  title = {Multi-faceted support for {MOOC} in programming},
  crossref = {proceedings:sigite:2012},
  pages = {171--176},
  doi = {10.1145/2380552.2380603},
  abstract = {Many massive open online courses (MOOC) have been tremendously popular, causing a stir in academic institutions. The most successful courses have reached tens of thousands of participants. In our MOOC on introductory programming, we aimed to improve distinctive challenges that concern most of the open online courses: allowing and requiring the participants to be more active in their online learning ("flipped-classroom"), demanding them to go deeper than typical CS1 course, and added incentives for participant retention by treating the course as a formal entrance exam to CS/IT degree. Our Extreme Apprenticeship (XA) method for programming education appeared to be successful in an online environment as well.},
  keywords = {automatic assessment service, extreme apprenticeship, formal acknowledgement, mooc, programming}
}

@INPROCEEDINGS{Vilela-etal:1997,
  author = {Plinio Vilela and Jose C. Maldonado and Mario Jino},
  title = {Data-Based Flow Testing of Programs with Pointers A Strategy Based on Potential Use},
  crossref = {proceedings:iqw:1997},
  pages = {1--12},
  abstract = {Test data selection criteria can be defined based on specification only information (i.e. functional criteria) or on implementation based criteria (i.e. structural criteria). This paper concentrates on the data flow based structural criteria, which is complicated in "realworld" programs by the occurrence of pointers, arrays, and structured variables. A new approach that promises to overcome some of these objections by combining work of Moldonado and a new conservative data flow model is presented.}
}

@INCOLLECTION{Villani:2007,
  author = {Shari L. Villani},
  title = {Learning Objects and instructional Design: Theories, Methods and Tools Useful in Creating Effective e-Learning Environments},
  chapter = {9},
  pages = {371-416},
  crossref = {Koohang-Harman:2007:theory}
}

@INPROCEEDINGS{Vilner-Zur:2006,
  author = {Vilner, Tamar and Zur, Ela},
  title = {Once She Makes It, She is There: Gender Differences in Computer Science Study},
  crossref = {proceedings:itcse:2006},
  pages = {227--231},
  doi = {10.1145/1140124.1140185},
  abstract = {When you sit in a Computer Science lecture at any university in the western world, what are the chances that the person sitting next to you will be a woman? Furthermore, what are the chances that the lecturer will be a woman? And if we were to enter a Computer Science classroom in a high school, what percentage of the students would be female? Computer Science is possibly one of the few remaining disciplines that is almost entirely controlled by men in the university staff, and in which the percentage of female students is usually below 30%. This phenomenon is prevalent throughout the western world.In this paper we present data about women studying Computer Science in universities and high schools in Israel. It deals with the specific problems that lead to a low rate of female enrollment in Computer Science courses and a high female-dropout rate. It describes some suggested solutions to encourage female enrollment and retention rate in Computer Science programs. The research was done at the Open University of Israel. An attempt has been made to identify whether there is a specific stage in the undergraduate program that is the most difficult for women to pass. Finally, we discuss ways to assist female students and enable them to overcome this obstacle and remain in the program.},
  keywords = {diversity of CS courses, gender and CS, success rates}
}

@ARTICLE{Vinagre-Jorge:2012,
  author = {Vinagre, João and Jorge, Alípio Mário},
  title = {Forgetting mechanisms for scalable collaborative filtering},
  crossref = {journal:sbc:jbcs},
  volume = {18},
  number = {4},
  month = nov,
  year = {2012},
  pages = {271--282},
  doi = {10.1007/s13173-012-0077-3},
  abstract = {Collaborative filtering (CF) has been an important subject of research in the past few years. Many achievements have been made in this field, however, many challenges still need to be faced, mainly related to scalability and predictive ability. One important issue is how to deal with old and potentially obsolete data in order to avoid unnecessary memory usage and processing time. Our proposal is to use forgetting mechanisms. In this paper, we present and evaluate the impact of two forgetting mechanisms -- sliding windows and fading factors -- in user-based and item-based CF algorithms with implicit binary ratings under a scenario of abrupt change. Our results suggest that forgetting mechanisms reduce time and space requirements, improving scalability, while not significantly affecting the predictive ability of the algorithms.},
  keywords = {Collaborative filtering; Recommender systems; Forgetting; Data streams}
}

@ARTICLE{Vincenzi-etal:2006:SPE,
  author = {Vincenzi, A. M. R. and Delamaro, M. E. and Maldonado, J. C. and Wong, W. E.},
  title = {Establishing structural testing criteria for Java bytecode},
  crossref = {journal:wiley:spe},
  volume = {36},
  number = {14},
  month = nov,
  year = {2006},
  pages = {1513--1541},
  doi = {10.1002/spe.v36:14},
  abstract = {This paper describes intra-method control-flow and data-flow testing criteria for the Java bytecode language. Six testing criteria are considered for the generation of testing requirements: four control-flow and two data-flow based. The main reason to work at a lower level is that, even when there is no source code, structural testing requirements can still be derived and used to assess the quality of a given test set. It can be used, for instance, to perform structural testing on third-party Java components. In addition, the bytecode can be seen as an intermediate language, so the analysis performed at this level can be mapped back to the original high-level language that generated the bytecode. To support the application of the testing criteria, we have implemented a tool named JaBUTi (Java Bytecode Understanding and Testing). JaBUTi is used to illustrate the application of the ideas developed in this paper.},
  keywords = {software testing; structural testing; program analysis; Java bytecode}
}

@ARTICLE{Vincenzi-etal:2001:STVR,
  author = {A. M. R. Vincenzi and J. C. Maldonado and E. F. Barbosa and M. E. Delamaro},
  title = {Unit and integration testing strategies for {C} programs using mutation},
  crossref = {journal:wiley:stvr},
  volume = {11},
  number = {4},
  month = dec,
  year = {2001},
  pages = {249--268},
  doi = {10.1002/stvr.242},
  abstract = {Mutation testing, originally proposed for unit testing, has been extended to integration testing with the proposition of the Interface Mutation criterion. This paper presents the results of an experiment using two mutation-based testing criteria for unit and integration testing phases: the Mutation Analysis and the Interface Mutation adequacy criteria, respectively. The aim is to investigate how they can be used in a complementary way during the testing activity, establishing an incremental testing strategy comprising the unit and integration testing phases and guidelines on how to obtain a high mutation score with respect to mutation testing with a low cost, in terms of the number of mutants generated.},
  keywords = {incremental testing strategy; unit testing; integration testing; mutation analysis; interface mutation}
}

@ARTICLE{Vincenzi-etal:2005,
  author = {Vincenzi, A. M. R. and Maldonado, J. C. and Wong, W. E. and Delamaro, M. E.},
  title = {Coverage testing of Java programs and components},
  crossref = {journal:elsevier:scp},
  volume = {56},
  number = {1--2},
  month = apr,
  year = {2005},
  pages = {211--230},
  doi = {10.1016/j.scico.2004.11.013},
  abstract = {Although software testing is a crucial activity in the software development process, only recently have more sound and consistent testing tools become available for testing Java programs and their components. These tools support mostly functional and control-flow based structural criteria. In this paper we explore control-flow and data-flow based coverage criteria to support the testing of Java programs and/or components. We also describe a testing tool, named JaBUTi, which can be used by both the component developer and the component user to test Java-based components and/or systems. To achieve this goal, the tool works at the bytecode level such that no source code is required during the testing activity. We illustrate these ideas and concepts with an example extracted from the literature.},
  keywords = {Java program testing; Java component testing;Java bytecode; Structural testing; Control-flow testing; Data-flow testing},
  url = {http://ccsl.icmc.usp.br/projects/jabuti}
}

@ARTICLE{Vincenzi-etal:2006:JBCS,
  author = {A. M. R. Vincenzi and A. S. Simão and M. E. Delamaro and J. C. Maldonado},
  title = {{Muta-Pro}: Towards the definition of a mutation testing process},
  crossref = {journal:sbc:jbcs},
  volume = {12},
  number = {2},
  month = jun,
  year = {2006},
  pages = {49--61},
  doi = {10.1007/BF03192394},
  abstract = {Mutation Testing originated from a classical method for digital circuit testing and today is used at program and specification levels. It can be used either to generate or to assess the quality of test sets. In spite of being very effective in detecting faults, Mutation Testing is usually considered a high cost criterion due to: i) the large number of generated mutants; ii) the time-consuming activity of determining equivalent mutants; and iii) the mutant execution time. Many initiatives aiming at reducing the Mutation Testing application cost have been conducted, most of them addressing one of the drawbacks mentioned above. In this paper, we identify and summarize some of the most relevant researches and results related to Mutation Testing cost reduction, e.g., Constrained-Mutation, Constraint-Based Testing and Bayesian Learning. Moreover, we propose a Mutation Testing process, named Muta-Pro, that synergetically integrates the related approaches and mechanisms. This process is intended to be incremental and tailorable to a specific application domain such as C programs or finite state machine models. The main ideas in this paper are illustrated using a UNIX utility program. This process is being integrated in a Mutation Testing environment, based on the authors' previous experience on implementing the Proteum Family tools, aiming at promoting the technology transfer to industry and providing the basis for improving the Muta-Pro process itself.},
  keywords = {mutation testing; mutation testing process; testing environment}
}

@INBOOK{Vixie:1999,
  pages = {91--100},
  title = {Software Engineering},
  author = {Paul Vixie},
  edition = {1},
  crossref = {DiBona-Ockman:1999},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INCOLLECTION{Votgen-etal:2005,
  author = {Hubert Vogten and Rob Koper and Harrie Martens and Colin Tattersall},
  title = {An Architecture for Learning Design Engines},
  chapter = {5},
  pages = {75-90},
  crossref = {Koper-Tattersall:2005}
}

@ARTICLE{Volter:2011,
  author = {Volter, M.},
  title = {From Programming to Modeling - and Back Again},
  crossref = {journal:ieee:software},
  volume = {28},
  number = {6},
  month = nov # {--} # dec,
  year = {2011},
  pages = {20--25},
  doi = {10.1109/MS.2011.139},
  abstract = {The authors describe an issue that they think is extremely important: the relationship between applications and solutions in the software engineering and information systems fields. In particular, they believe the fields desperately need a taxonomy of application domains, a taxonomy of solution approaches, and a mapping between the two. This article has a Web extra that offers an interview with one of the article's authors, Robert L. Glass, about the "dark side" of this topic.},
  keywords = {application domains;information systems;software engineering;information systems;programming;software engineering;},
  lang = {en}
}

@INCOLLECTION{Vossen-Westerkamp:2007,
  author = {Gottfried Vossen and Peter Westerkamp},
  title = {Service-Oriented Provisioning of Learning Objects},
  chapter = {10},
  pages = {287-324},
  crossref = {Harman-Koohang:2007}
}

@ARTICLE{VujosevicJanicic-etal:2013,
  author = {Milena Vujosevic-Janicic and Mladen Nikolic and Dusan Tosic and Viktor Kuncak},
  title = {Software verification and graph similarity for automated evaluation of students' assignments},
  crossref = {journal:elsevier:ist},
  volume = {55},
  number = {6},
  month = jun,
  year = {2013},
  pages = {1004--1016},
  doi = {10.1016/j.infsof.2012.12.005},
  abstract = {Context The number of students enrolled in universities at standard and on-line programming courses is rapidly increasing. This calls for automated evaluation of students assignments. Objective We aim to develop methods and tools for objective and reliable automated grading that can also provide substantial and comprehensible feedback. Our approach targets introductory programming courses, which have a number of specific features and goals. The benefits are twofold: reducing the workload for teachers, and providing helpful feedback to students in the process of learning. Method For sophisticated automated evaluation of students' programs, our grading framework combines results of three approaches (i) testing, (ii) software verification, and (iii) control flow graph similarity measurement. We present our tools for software verification and control flow graph similarity measurement, which are publicly available and open source. The tools are based on an intermediate code representation, so they could be applied to a number of programming languages. Results Empirical evaluation of the proposed grading framework is performed on a corpus of programs written by university students in programming language C within an introductory programming course. Results of the evaluation show that the synergy of proposed approaches improves the quality and precision of automated grading and that automatically generated grades are highly correlated with instructor-assigned grades. Also, the results show that our approach can be trained to adapt to teacher's grading style. Conclusions In this paper we integrate several techniques for evaluation of student's assignments. The obtained results suggest that the presented tools can find real-world applications in automated grading.},
  keywords = {Automated grading, Software verification, Graph similarity, Computer supported education }
}

@ARTICLE{Wachenchauzer:2014,
  author = {Wachenchauzer, Rosita},
  title = {The Evolution of Computer Education in {Latin} {America}: The Case of {Argentina}},
  crossref = {journal:acm:inroads},
  volume = {5},
  number = {1},
  month = mar,
  year = {2014},
  pages = {70--76},
  doi = {10.1145/2568195.2568215},
  keywords = {Argentine Society of Informatics, accreditation process, computer and information science education in Argentina}
}

@INPROCEEDINGS{Wagner-etal:2012,
  author = {Wagner, S. and Lochmann, K. and Heinemann, L. and Klas, M. and Trendowicz, A. and Plosch, R. and Seidi, A. and Goeb, A. and Streit, J.},
  title = {The {Quamoco} product quality modelling and assessment approach},
  crossref = {proceedings:icse:2012},
  pages = {1133--1142},
  doi = {10.1109/ICSE.2012.6227106},
  abstract = {Published software quality models either provide abstract quality attributes or concrete quality assessments. There are no models that seamlessly integrate both aspects. In the project Quamoco, we built a comprehensive approach with the aim to close this gap. For this, we developed in several iterations a meta quality model specifying general concepts, a quality base model covering the most important quality factors and a quality assessment approach. The meta model introduces the new concept of a product factor, which bridges the gap between concrete measurements and abstract quality aspects. Product factors have measures and instruments to operationalise quality by measurements from manual inspection and tool analysis. The base model uses the ISO 25010 quality attributes, which we refine by 200 factors and 600 measures for Java and C# systems. We found in several empirical validations that the assessment results fit to the expectations of experts for the corresponding systems. The empirical analyses also showed that several of the correlations are statistically significant and that the maintainability part of the base model has the highest correlation, which fits to the fact that this part is the most comprehensive. Although we still see room for extending and improving the base model, it shows a high correspondence with expert opinions and hence is able to form the basis for repeatable and understandable quality assessments in practice.},
  keywords = {quality model; quality assessment; meta model; empirical validation}
}

@ARTICLE{Wainer-etal:2013,
  author = {Wainer, Jacques and Eckmann, Michael and Goldenstein, Siome and Rocha, Anderson},
  title = {How productivity and impact differ across computer science subareas},
  crossref = {journal:acm:cacm},
  volume = {56},
  number = {8},
  month = aug,
  year = {2013},
  pages = {67--73},
  doi = {10.1145/2492007.2492026},
  abstract = {How to understand evaluation criteria for CS researchers.},
  timestamp = {2013-07-31}
}

@ARTICLE{Wainer-etal:2009,
  author = {Wainer, Jacques and Xavier, EduardoC. and Bezerra, Fabio},
  title = {Scientific production in {Computer Science}: A comparative study of {Brazil} and other countries},
  crossref = {journal:springer:scientometrics},
  volume = {81},
  number = {2},
  month = nov,
  year = {2009},
  pages = {535--547},
  doi = {10.1007/s11192-008-2156-y},
  abstract = {In this paper we present a study about scientific production in Computer Science in Brazil and several other countries, as measured by the number of articles in journals and conference proceedings indexed by ISI and by Scopus. We compare the Brazilian production from 2001 to 2005 with some Latin American, Latin European, BRIC (Brazil, Russia, India, China), and other relevant countries (South Korea, Australia and USA). We also classify and compare these countries according to the ratio of publications in journals and conferences (the ones indexed by the two services). The results show that Brazil has by far the largest production among Latin American countries, has a production about one third of Spain's, one fourth of Italy's, and about the same as India and Russia. The growth in Brazilian publications during the period places the country in the mid-range group and the distribution of Brazilian production according to impact factor is similar to most countries.}
}

@ARTICLE{Walker:2011,
  author = {Walker, Henry M.},
  title = {How to challenge students},
  crossref = {journal:acm:inroads},
  volume = {2},
  number = {3},
  month = aug,
  year = {2011},
  pages = {14--15},
  doi = {10.1145/2003616.2003621},
  acmid = {2003621},
  issue = {3},
  issue_date = {September 2011},
  lang = {en},
  numpages = {2}
}

@ARTICLE{Walker2011,
  author = {Walker, Henry M.},
  title = {When is a computing curriculum bloated?},
  crossref = {journal:acm:inroads},
  volume = {2},
  number = {2},
  month = jun,
  year = {2011},
  pages = {18--20},
  doi = {10.1145/1963533.1963538},
  acmid = {1963538},
  issue = {2},
  issue_date = {June 2011},
  lang = {en},
  numpages = {3}
}

@ARTICLE{Walker:2009,
  author = {Walker, Henry M.},
  title = {Course descriptions and public relations for computer science},
  crossref = {journal:acm:inroads},
  volume = {41},
  number = {2},
  month = jun,
  year = {2009},
  pages = {74--75},
  doi = {10.1145/1595453.1595471}
}

@ARTICLE{Wallach:2011,
  author = {Wallach, Dan S.},
  title = {Rebooting the CS publication process},
  crossref = {journal:cacm},
  volume = {54},
  number = {10},
  month = oct,
  year = {2011},
  pages = {32-35},
  doi = {10.1145/2001269.2001283}
}

@INPROCEEDINGS{Wang-etal:2012,
  author = {Wang, Chia Q. and Tang, Carmen and Zhang, Liyang and Cukierman, Diana},
  title = {{Try/CATCH} - a {CS} Outreach Event Organized by Female University Students for Female High School Students: A Positive Experience for All the Parts Involved},
  crossref = {proceedings:wccce:2012},
  pages = {12--18},
  doi = {10.1145/2247569.2247574},
  abstract = {Try/CATCH (Computing and Technology Conference for Her) is a computing science female high school outreach event, which is run and organized almost exclusively by graduate and undergraduate students in the School of Computing science at Simon Fraser University. In this paper we describe the Try/CATCH event, including main activities that took place during the event and how this event started and evolved to its current version. We also analyze how Try/CATCH 2011 was perceived and experienced by the high school student participants as well as the university student organizers, based on postworkshop self-perception surveys and interviews. Results obtained so far are very encouraging, indicating a positive influence on the student participants and the event organizers.},
  keywords = {K-12, diversity, female support network, girls, outreach, perceptions of computing science, recruitment}
}

@ARTICLE{Wang-etal:2012b,
  author = {Dan J. Wang and Xiaolin Shi and Daniel A. McFarland and Jure Leskovec},
  title = {Measurement error in network data: A re-classification },
  crossref = {journal:elsevier:sn},
  volume = {34},
  number = {4},
  month = oct,
  year = {2012},
  pages = {396--409},
  doi = {10.1016/j.socnet.2012.01.003},
  abstract = {Research on measurement error in network data has typically focused on missing data. We embed missing data, which we term false negative nodes and edges, in a broader classification of error scenarios. This includes false positive nodes and edges and falsely aggregated and disaggregated nodes. We simulate these six measurement errors using an online social network and a publication citation network, reporting their effects on four node-level measures -- degree centrality, clustering coefficient, network constraint, and eigenvector centrality. Our results suggest that in networks with more positively-skewed degree distributions and higher average clustering, these measures tend to be less resistant to most forms of measurement error. In addition, we argue that the sensitivity of a given measure to an error scenario depends on the idiosyncracies of the measures calculation, thus revising the general claim from past research that the more 'global' a measure, the less resistant it is to measurement error. Finally, we anchor our discussion to commonly-used networks in past research that suffer from these different forms of measurement error and make recommendations for correction strategies.},
  keywords = {Measurement error, Missing data, Simulation}
}

@INPROCEEDINGS{Wang-etal:2010,
  author = {Huai Wang and Ke Zhai and Tse, T.H.},
  title = {Correlating Context-Awareness and Mutation Analysis for Pervasive Computing Systems},
  crossref = {proceedings:qsic:2010},
  pages = {151--160},
  doi = {10.1109/QSIC.2010.57},
  abstract = {Pervasive computing systems often use middleware as a means to communicate with the changing environment. However, the interactions with the context-aware middleware as well as the interactions among applications sharing the same middleware may introduce faults that are difficult to reveal by existing testing techniques. Our previous work proposed the notion of context diversity as a metric to measure the degree of changes in test inputs for pervasive software. In this paper, we present a case study on how much context diversity for test cases relates to fault-based mutants in pervasive software. Our empirical results show that conventional mutation operators can generate sufficient candidate mutants to support test effectiveness evaluation of pervasive software, and test cases with higher context diversity values tend to have higher mean mutation scores. On the other hand, for test cases sharing the same context diversity, their mutation scores can vary significantly in terms of standard derivations.},
  keywords = {context diversity; mutation analysis; pervasive computing}
}

@INPROCEEDINGS{Wang-Erdogmus:2004,
  author = {Wang, Yihong and Erdogmus, Hakan},
  title = {The Role of Process Measurement in Test-Driven Development},
  crossref = {proceedings:xp:2004},
  pages = {32--42},
  doi = {10.1007/978-3-540-27777-4_4},
  abstract = {Test-Driven Development (TDD) is a coding technique in which programmers write unit tests before writing or revising production code. We present a process measurement approach for TDD that relies on the analysis of fine-grained data collected during coding activities. This data is mined to produce abstractions regarding programmers' work patterns. Programmers, instructors, and coaches receive concrete feedback by visualizing these abstractions. Process measurement has the potential to accelerate the learning of TDD, enhance its effectiveness, aid in its empirical evaluation, and support project tracking.},
  owner = {magsilva},
  timestamp = {2014.10.21}
}

@ARTICLE{Wangenheim-etal:2013,
  author = {Christiane Gresse von Wangenheim and Rafael Savi and Adriano Ferreti Borgatto},
  title = {SCRUMIA -- An Educational Game for Teaching \{SCRUM\} in Computing Courses },
  crossref = {journal:elsevier:jss},
  year = {2013},
  doi = {10.1016/j.jss.2013.05.030},
  abstract = {Abstract Due to the increasing use of agile methods, teaching \{SCRUM\} as an agile project management methodology has become more and more important. In order to teach students to be able to apply \{SCRUM\} in concrete situations, often educational (simulation) games are used. However, most of these games have been developed more for professional trainings than taking into consideration typical restrictions of university courses (such as, class duration and low financial resources for instructional materials). Therefore, we present a manual paper &amp; pencil game to reinforce and teach the application of \{SCRUM\} in undergraduate computing programs complementing theoretical lectures. The game has been developed following a systematic instructional design process and based on our teaching experience. It has been applied several times in two undergraduate project management courses. We evaluated motivation, user experience and the game's contribution to learning through case studies on Kirkpatrick's level one based on the perception of the students. First results indicate the potential of the game to contribute to the learning of \{SCRUM\} in an engaging way, keeping students immersed in the learning task. In this regard, the game offers a low-budget alternative to complement traditional instructional strategies for teaching \{SCRUM\} in the classroom. },
  keywords = {SCRUM, Project Management, Teaching, Education, Game}
}

@ARTICLE{Wangenheim-etal:2012,
  author = {Christiane Gresse von Wangenheim and Rafael Savi and Adriano Ferreti Borgatto},
  title = {DELIVER! -- An educational game for teaching Earned Value Management in computing courses},
  crossref = {journal:elsevier:ist},
  volume = {54},
  number = {3},
  year = {2012},
  pages = {286--298},
  doi = {10.1016/j.infsof.2011.10.005},
  abstract = {To meet the growing need for education in Software Project Management, educational games have been introduced as a beneficial instructional strategy. However, there are no low-cost board games openly available to teach Earned Value Management (EVM) in computing programs. This paper presents an educational board game to reinforce and teach the application of EVM concepts in the context of undergraduate computing programs complementing expository lessons on EVM basics. The game has been developed based on project management fundamentals and teaching experience in this area. So far, it has been applied in two project management courses in undergraduate computing programs at the Federal University of Santa Catarina. We evaluated motivation, user experience and the game's contribution to learning through case studies on Kirkpatrick's level one based on the perception of the students. First results of the evaluation of the game indicate a perceived potential of the game to contribute to the learning of EVM concepts and their application. The results also point out a very positive effect of the game on social interaction, engagement, immersion, attention and relevance to the course objectives. We conclude that the game DELIVER! can contribute to the learning of the EVM on the cognitive levels of remembering, understanding and application. The illustration of the application of EVM through the game can motivate its usefulness. The game has proven to be an engaging instructional strategy, keeping students on the task and attentive. In this respect, the game offers a possibility to complement traditional instructional strategies for teaching EVM. In order to further generalize and to strengthen the validity of the results, it is important to obtain further evaluations.},
  keywords = {Project management; Serious game; Teaching; Education; Earned Value Management; Computing},
  lang = {en}
}

@INPROCEEDINGS{Watson-etal:2014,
  author = {Watson, Christopher and Li, Frederick W. B. and Godwin, Jamie L.},
  title = {No Tests Required: Comparing Traditional and Dynamic Predictors of Programming Success},
  crossref = {proceedings:sigcse:2014},
  pages = {469--474},
  doi = {10.1145/2538862.2538930},
  abstract = {Research over the past fifty years into predictors of programming performance has yielded little improvement in the identification of at-risk students. This is possibly because research to date is based upon using static tests, which fail to reflect changes in a student's learning progress over time. In this paper, the effectiveness of 38 traditional predictors of programming performance are compared to 12 new data-driven predictors, that are based upon analyzing directly logged data, describing the programming behavior of students. Whilst few strong correlations were found between the traditional predictors and performance, an abundance of strong significant correlations based upon programming behavior were found. A model based upon two of these metrics (Watwin score and percentage of lab time spent resolving errors) could explain 56.3% of the variance in coursework results. The implication of this study is that a student's programming behavior is one of the strongest indicators of their performance, and future work should continue to explore such predictors in different teaching contexts.},
  keywords = {CS1, error quotient, learning strategies, learning styles, prediction, predictors of success, programming behavior, watwin}
}

@INPROCEEDINGS{Webb-Rosson:2013,
  author = {Webb, Heidi and Rosson, Mary Beth},
  title = {Using Scaffolded Examples to Teach Computational Thinking Concepts},
  crossref = {proceedings:sigcse:2013},
  pages = {95--100},
  doi = {10.1145/2445196.2445227},
  abstract = {In this paper we describe a set of computing activities that were used in an outreach enrichment program for middle school girls. The computing activities used a combination of scaffolded exam-ples and minimalist workbooks to introduce and support interaction with computational thinking (CT) concepts, including problem solving, abstraction and basic computational vocabulary. We describe the activities briefly, followed by a discussion of the girls' experiences, drawing primarily from interviews conducted at the end of each activity.},
  keywords = {middle school girls, scaffolded example, scratch}
}

@ARTICLE{Webster-Watson:2002,
  author = {Webster, Jane and Watson, Richard T.},
  title = {Analyzing the past to prepare for the future: writing a literature review},
  crossref = {journal:misrc:misq},
  volume = {26},
  number = {2},
  month = jun,
  year = {2002},
  pages = {xiii--xxiii}
}

@ARTICLE{Wedyan-Ghosh:2012,
  author = {Fadi Wedyan and Sudipto Ghosh},
  title = {On generating mutants for AspectJ programs},
  crossref = {journal:elsevier:ist},
  volume = {54},
  number = {8},
  month = aug,
  year = {2012},
  pages = {900--914},
  doi = {10.1016/j.infsof.2011.12.001},
  abstract = {Mutation analysis has been widely used in research studies to evaluate the effectiveness of test suites and testing techniques. Faulty versions (i.e., mutants) of a program are generated such that each mutant contains one seeded fault. The mutation score provides a measure of effectiveness. We study three problems with the use of mutation analysis for testing AspectJ programs: (1) the manual identification and removal of equivalent mutants is difficult and time consuming. We calculate the percentage of equivalent mutants generated for benchmark AspectJ programs using available mutation tools; (2) the generated mutants need to cover the various fault types described in the literature on fault models for AspectJ programs. We measure the distribution of the mutants generated using available mutation tools with respect to the AspectJ fault types; (3) we measure the difficulty of killing the generated mutants. We propose the use of simple analysis of the subject programs to prevent the generation of some equivalent mutants. We revised existing AspectJ fault models and presented a fault model that removes the problems in existing fault models, such as overlapping between fault types and missing fault types. We also defined three new fault types that occur due to incorrect data-flow interactions occurring in AspectJ programs. We used three mutation tools: AjMutator, Proteum/AJ, and MuJava on three AspectJ programs. To measure the difficulty of killing the mutants created using a mutation operator, we compared the average number of the mutants killed by 10 test suites that satisfy block coverage criterion. A high percentage of the mutants are equivalent. The mutation tools do not cover all the fault types. Only 4 out of 27 operators generated mutants that were easy to kill. Our analysis approach removed about 80% of the equivalent mutants. Higher order mutation is needed to cover all the fault types.},
  keywords = {AspectJ; Aspect-oriented programming; Mutation testing; Fault models; Test generation; High order mutation}
}

@INPROCEEDINGS{Wellington-etal:2007,
  author = {Wellington, C. A. and Briggs, T. H. and Girard, C. D.},
  title = {Experiences Using Automated Tests and Test Driven Development in {Computer Science I}},
  crossref = {proceedings:agile:2007},
  pages = {106--112},
  doi = {10.1109/AGILE.2007.27},
  abstract = {We are interested in how to expose our students to test driven development (TDD) and have experimented with a variety of ways of leveraging testing technology to help our students learn to program in our first programming course. Initially, we developed a framework that allows the students to run tests that are developed by the faculty member. That experience led us to developing a JUnit plug-in that allowed the students to specify the tests without having to write the test code. As a result of these experiences, we have re-structured this class into these roughly sequential phases: learning to read code, learning to write code, and learning to program. Throughout this course, the students are using TDD, writing their own JUnit tests, and refactoring as they develop their code iteratively. This change has been made without dropping any of the required course content.}
}

@ARTICLE{Wellman-etal:2009,
  author = {Wellman, Briana Lowe and Anderson, Monica and Vrbsky, Susan V.},
  title = {{PREOP} As a Tool to Increase Student Retention in {CS}},
  crossref = {journal:ccsc:jcsc},
  volume = {25},
  number = {2},
  month = dec,
  year = {2009},
  pages = {167--175},
  abstract = {The demand for computer scientists is expected to continue to increase irrespective of the current state of the economy. Unfortunately, the supply is not expected to match the demand as the number of computer science majors has decreased substantially since the year 2000. As a result, universities and colleges are attempting to identify new ways to attract and retain prospective students into the field of computer science in order to increase the number of majors. In this paper we describe our approach to increase participation and retention through the use of PREOP (Providing Robotic Experiences through Object-Based Programming), an approach that combines the Alice interface and robots for a CS1 Laboratory. PREOP is an interactive 3D animation programming environment, that allows students to program real robots using a drag-and-drop, syntax-free interface. The goal is to foster student motivation and increase student understanding of the fundamental concepts within the first-year curriculum. Initial results indicate that the students in the PREOP Lab who are eligible for CS2 are more likely to rate their skills and knowledge above average than the students in the non-PREOP Labs, and more likely to be registered for the CS2 course than the students in the non-PREOP Labs.},
  owner = {magsilva},
  timestamp = {2014.08.30}
}

@ARTICLE{Wells-etal:2012,
  author = {Wells, J. and Barry, R. M. and Spence, A.},
  title = {Using Video Tutorials as a Carrot-and-Stick Approach to Learning},
  crossref = {journal:ieee:te},
  volume = {55},
  number = {4},
  month = nov,
  year = {2012},
  pages = {453--458},
  doi = {10.1109/TE.2012.2187451},
  abstract = {Traditional teaching styles practiced at universities do not generally suit all students' learning styles. For a variety of reasons, students do not always engage in learning in the courses in which they are enrolled. New methods to create and deliver educational material are available, but these do not always improve learning outcomes. Acknowledging these truths and developing and delivering educational material that provides diverse ways for students to learn is a constant challenge. This study examines the use of video tutorials within a university environment in an attempt to provide a teaching model that is valuable to all students, and in particular to those students who are not engaging in learning. The results of a three-year study have demonstrated that the use of well-designed, assessment-focused, and readily available video tutorials have the potential to improve student satisfaction and grades by enabling and encouraging students to learn how they want, when they want, and at a pace that suits their needs.},
  keywords = {Curriculum development, education, learning, programming, tutorials, videos}
}

@ARTICLE{Werner-etal:2004,
  author = {Werner, Linda L. and Hanks, Brian and McDowell, Charlie},
  title = {Pair-programming helps female computer science students},
  crossref = {journal:acm:jeric},
  volume = {4},
  number = {1},
  month = mar,
  year = {2004},
  pages = {1--8},
  doi = {10.1145/1060071.1060075},
  abstract = {Pair-programming has been found to be very beneficial in educational settings. Students who pair in their introductory programming course are more confident, have greater course completion and pass rates, and are more likely to persist in computer-related majors. Although pairing helps all students, we believe that it is particularly beneficial for women because it addresses several significant factors that limit women's participation in computer science. We provide reasons for our belief that pair-programming helps women persist in these majors. We also repeat, with special emphasis on the impact on women, some details published elsewhere regarding our experiments on pair-programming with college and university students. Additionally, we provide new data that supports our original findings.},
  keywords = {Pair programming, collaboration, gender}
}

@ARTICLE{Wesselius-Ververs:1990,
  author = {Jacco Wesselius and Frans Ververs},
  title = {Some elementary questions on software quality control},
  crossref = {journal:iee:sej},
  volume = {5},
  number = {6},
  month = nov,
  year = {1990},
  pages = {319--330},
  abstract = {Some elementary questions relating to the subject of quality control in software development are addressed. What is software quality? What obstacles should be removed in order to obtain quality control? What are directions for research regarding quality control in software development? A central issue is the notion that complete objectivity in quality assessment cannot be achieved. It is argued that the consequences of this should not be ignored if any progress is to be made towards the achievement of quality control. The result of the exploration into quality is that three distinct components of quality can be identified: an objectively assessable component, a subjectively assessable component and a nonassessable component. It is argued that it would be unwise to limit attention to any single one of these, although only the first is suited to be engineered.}
}

@INPROCEEDINGS{weyuker:1993,
  author = {Weyuker, E. J.},
  title = {Can we measure software testing effectiveness?},
  crossref = {proceedings:metrics:1993},
  pages = {100--107},
  doi = {10.1109/METRIC.1993.263796},
  abstract = {The paper examines the issues of measuring and comparing the effectiveness of testing criteria. It argues that measurement, in the usual sense, is generally not possible, but that comparison is. In particular, it argues that uniform relations that guarantee that one criterion is better at fault detection than another, according to certain types of well-understood probabilistic measures of effectiveness, are especially valuable}
}

@ARTICLE{Weyuker:2004,
  author = {Elaine J. Weyuker},
  title = {How to judge testing progress },
  crossref = {journal:elsevier:ist},
  volume = {46},
  number = {5},
  month = apr,
  year = {2004},
  pages = {323--328},
  doi = {10.1016/j.infsof.2003.09.008},
  abstract = {It is usual to base the assessment of software testing progress on a coverage measure such as code coverage or specification coverage, or on the percentage of the input domain exercised. In this paper it is argued that these characteristics do not provide good indications of the degree to which the software has been tested. Instead we propose that the assessment of testing progress be based on the total percentage of the probability mass that corresponds to the test cases selected and run. To do this, it is necessary to collect data that profiles how the software will be used once it is operational in the field. By so doing, we are able to accurately determine how much testing has been done, and whether it has met the standards of completeness for the product under consideration. },
  keywords = {Operational distribution, Software testing, Test data adequacy, Test progress },
  timestamp = {2013-09-14}
}

@INPROCEEDINGS{Whalen-etal:2010,
  author = {Whalen, Michael W. and Godefroid, Patrice and Mariani, Leonardo and Polini, Andrea and Tillmann, Nikolai and Visser, Willem},
  title = {{FITE}: future integrated testing environment},
  crossref = {proceedings:foser:2010},
  pages = {401--406},
  doi = {10.1145/1882362.1882444},
  abstract = {It is well known that the later software errors are discovered during the development process, the more costly they are to repair, yet testing and automated analysis tools tend to be applied late in the development cycle. In this paper, we describe a future integrated testing environment (FITE) that continually analyzes code for a variety of functional and nonfunctional properties to provide developer feedback as code is being written. This instant feedback allows developers to fix errors as they are introduced, increasing developer productivity and software quality.},
  keywords = {compositional analysis, incremental analysis, non-functional analysis}
}

@INPROCEEDINGS{Whalley-Philpott:2011,
  author = {Whalley, Jacqueline L. and Philpott, Anne},
  title = {A Unit Testing Approach to Building Novice Programmers' Skills and Confidence},
  crossref = {proceedings:ace:2011},
  pages = {113--118},
  abstract = {This paper discusses the integration of unit tests into a first semester programming course. The students were supplied with unit tests to support their learning and assessments. A questionnaire was completed by the student cohort about their use and perceptions of these unit tests. As a result of both the students and our experiences we examine the advantages and disadvantages of introducing unit tests early and make some pedagogical recommendations for the introduction and use of unit tests in first year programming.},
  keywords = {assessment, novice programmers, testing},
  owner = {magsilva},
  timestamp = {2014.08.31}
}

@INCOLLECTION{Wharton-etal:1994,
  author = {Cathleen Wharton and John Rieman and Clayton Lewis and Peter Polson},
  title = {The Cognitive Walkthrough Method: A Practioner's Guide},
  chapter = {5},
  pages = {105-140},
  crossref = {Nielsen-Mack:1994}
}

@INPROCEEDINGS{Wieringa:2010,
  author = {Wieringa, Roel},
  title = {Design science methodology: principles and practice},
  crossref = {proceedings:icse:2010},
  pages = {493--494},
  doi = {10.1145/1810295.1810446},
  abstract = {Design scientists have to balance the demands of methodological rigor that they share with purely curiosity-driven scientists, with the demands of practical utility that they share with utility-driven engineers. Balancing these conflicting demands can be conceptually complex and may lead to methodological mistakes. For example, treating a design question as an empirical research question may lead to researcher to omit the identification of the practical problem to solve, to omit the identification of stakeholder-motivated evaluation criteria, or to omit trade-off and sensitivity analysis. This tutorial aims to clear up this methodological mist in the case of software engineering (SE) research.},
  volume = {2}
}

@ARTICLE{Wieringa:2005,
  author = {Wieringa, Roel},
  title = {Requirements researchers: are we really doing research?},
  crossref = {journal:springer:re},
  volume = {10},
  number = {4},
  month = nov,
  year = {2005},
  pages = {304--306},
  doi = {10.1007/s00766-005-0013-6}
}

@INPROCEEDINGS{Wieringa-etal:2011,
  author = {Wieringa, Roel and Daneva, Maya and Condori-Fernandez, Nelly},
  title = {The Structure of Design Theories, and an Analysis of their Use in Software Engineering Experiments},
  crossref = {proceedings:esem:2011},
  pages = {295--304},
  doi = {10.1109/ESEM.2011.38},
  abstract = {In this paper we analyse possible reasons for the relatively low use of theories in software engineering (SE) papers found by Hannay et al. (2007). We provide an initial explanation in terms of properties of theories, test this by analyzing 32 of the 40 theories reviewed by Hannay et al., and then revise our analysis based on this test. Our analysis revealed that background theories from other disciplines are context-free and make idealizing assumptions, which make it easier for them to be (re)used across settings. Theories built in SE are mid-range and context-sensitive, and make less idealizing assumptions. This is normal for engineering theories, but it does make them harder to (re)use across settings. We also found that background theories from other disciplines usually provide explanations for phenomena in terms of mechanisms, whereas SE theories are statistical models of phenomena observed in an experiment, which also makes them harder to (re)use across settings. We end the paper with a recommendation of bottom-up development of theories about mechanisms in software engineering projects by doing case studies.},
  keywords = {Research methodology, Generalization, Architectural theories}
}

@INPROCEEDINGS{Wieringa-etal:2009,
  author = {Wieringa, Roel and Heerkens, Hans and Regnell, Björn},
  title = {How to Write and Read a Scientific Evaluation Paper},
  crossref = {proceedings:re:2009},
  pages = {361--364},
  doi = {10.1109/RE.2009.17},
  abstract = {Scientific evaluation papers investigate existing problem situations or validate proposed solutions with scientific means, such as by experiment or case study. There is a growing amount of literature about how to report about empirical research in software engineering, but there is still some confusion about the difference between a scientific evaluation paper and other kinds of research papers. This is related to lack of clarity about the relation between empirical research, engineering, and industrial practice. In this minitutorial we give a brief rundown on how to structure a scientific evaluation papers as a special kind of research paper, using experiment reports and case study reports as examples. We give checklists of items that a reader should be able to find in these papers, and sketch the dilemmas that writers and readers of these papers face when applying these checklists.},
  keywords = {Research methodology, Research reporting, Scientific evaluation papers}
}

@INPROCEEDINGS{Wierzbicki-etal2010,
  author = {Wierzbicki, Robert J. and Kermer, Kerstin and Röbisch, Karolin and Schmieder, Thomas and Stra\ssburger, Tina},
  title = {Media pedagogics in converged environments of the future},
  crossref = {proceedings:euroitv:2010},
  pages = {23--26},
  doi = {10.1145/1809777.1809782},
  abstract = {Our life patterns and culture increasingly find their roots in visual media: film, video games, internet and multimedia. Visual media shape the image of our world and our society, thereby being, however, somewhat detached from reality, portraying the bold and the beautiful as role models. Entertainment has become a driving force in the creation of films, television programs and the design of computer games. Education and pedagogical aspects are often neglected. Values and norms in our society seem to be continually losing importance. Our society appears to be getting poorer, both financially and intellectually. In this article we demonstrate the potential that can be found in media forms of the future in respect of education and discuss a number of aspects of reader response and aesthetic response in connection with media and violence.},
  keywords = {GAMECAST, computer games, converged media, education, future media, media effects model, media effects research, media violence, pedagogics, phantovisor}
}

@ARTICLE{Wiley:2010,
  author = {David Wiley},
  title = {Openness as Catalyst for an Educational Reformation},
  crossref = {journal:educause:educause-review},
  volume = {45},
  number = {4},
  month = jul # {-} # aug,
  year = {2010},
  pages = {14--20}
}

@INCOLLECTION{Wiley:2001a,
  author = {David A. Wiley},
  title = {Connecting learning objects to instructional design theory: A definition, a metaphor, and a taxonomy},
  chapter = {1.1},
  pages = {1--35},
  crossref = {Wiley:2001},
  url = {http://reusability.org/read/chapters/wiley.doc}
}

@INCOLLECTION{Wiley:2009,
  author = {David A. Wiley},
  title = {Learning Objects and Instructional Theory},
  chapter = {16},
  pages = {349-363},
  crossref = {Reigeluth-CarrChellman:2009}
}

@ARTICLE{Williams-etal:2011,
  author = {Doug Williams and Marian F. Ursu and Joshan Meenowa and Pablo Cesar and Ian Kegel and Karl Bergström},
  title = {Video mediated social interaction between groups: System requirements and technology challenges},
  crossref = {journal:elsevier:ti},
  volume = {28},
  number = {4},
  month = nov,
  year = {2011},
  pages = {251--270},
  doi = {10.1016/j.tele.2010.11.001},
  abstract = {This paper discusses results from research related to the use of television as a device that supports social interaction between close-knit groups in settings that include more than two locations, each location being potentially equipped with more than one camera. The paper introduces the notion of a framing experience, as a specific scenario or situation within which social communication takes place. It reports on the evaluation of some of the key attributes of social communication through semi-structured interviews, with 16 families across four European countries. The inferences drawn from this study are reduced to four system capabilities including the ability to support: excitement, engagement and entertainment; high quality, reliable audiovisual communications; flexibility and adaptability sufficient to support the unpredictable and reactive nature of human interaction and discourse. These system requirements are, in turn, reduced to a number of technology challenges which if solved will help enable effective social communications between groups, mediated by the television. These technology challenges include: high quality reliable audio visual communication; interaction orchestration, multimedia interpretation and multimedia composition. Finally the paper reflects on the impact the use of framing experiences, such as those described here, could have on strategy and policy for service providers and regulators.},
  keywords = {Television, Interaction, IPTV, Social communication, Policy}
}

@INPROCEEDINGS{Williams-etal:2014,
  author = {Williams, James R. and Di Ruscio, Davide and Matragkas, Nicholas and Di Rocco, Juri and Kolovos, Dimitris S.},
  title = {Models of {OSS} Project Meta-information: A Dataset of Three Forges},
  crossref = {proceedings:msr:2014},
  pages = {408--411},
  doi = {10.1145/2597073.2597132},
  abstract = {The process of selecting open-source software (OSS) for adoption is not straightforward as it involves exploring various sources of information to determine the quality, maturity, activity, and user support of each project. In the context of the OSSMETER project, we have developed a forge-agnostic metamodel that captures the meta-information common to all OSS projects. We specialise this metamodel for popular OSS forges in order to capture forge-specific meta-information. In this paper we present a dataset conforming to these metamodels for over 500,000 OSS projects hosted on three popular OSS forges: Eclipse, SourceForge, and GitHub. The dataset enables different kinds of automatic analysis and supports objective comparisons of cross-forge OSS alternatives with respect to a user's needs and quality requirements.},
  keywords = {Data mining},
  owner = {magsilva},
  timestamp = {2014.05.21}
}

@ARTICLE{Wilson:2013,
  author = {Wilson, Cameron},
  title = {Making computer science count},
  crossref = {journal:acm:cacm},
  volume = {56},
  number = {11},
  month = nov,
  year = {2013},
  pages = {32--33},
  doi = {10.1145/2527189},
  abstract = {Combining efforts and expertise, ACM and Code.org are partnering to address a rapidly changing education landscape.}
}

@INBOOK{Wilson:2005,
  chapter = {3},
  pages = {41-62},
  title = {Architectures to Support Authoring and Content Management with Learning Design},
  author = {Scott Wilson},
  crossref = {Koper-Tattersall:2005}
}

@ARTICLE{Wing:2006,
  author = {Wing, Jeannette M.},
  title = {Computational thinking},
  crossref = {journal:acm:cacm},
  volume = {49},
  number = {3},
  month = mar,
  year = {2006},
  pages = {33--35},
  doi = {10.1145/1118178.1118215},
  abstract = {It represents a universally applicable attitude and skill set everyone, not just computer scientists, would be eager to learn and use.}
}

@INPROCEEDINGS{Winker-etal:2013,
  author = {Winkler, Dietmar and Kitzler, Martin and Steindl, Christoph and Biffl, Stefan},
  title = {Investigating the Impact of Experience and Solo/Pair Programming on Coding Efficiency: Results and Experiences from Coding Contests},
  crossref = {proceedings:xp:2013},
  pages = {106--120},
  doi = {10.1007/978-3-642-38314-4_8},
  abstract = {Developing working software is a key goal of software development. Beyond software processes, following traditional or agile approaches, coding strategies, i.e., solo and pair programming, are important aspects for constructing high quality software code. In addition developer experience has a critical impact on coding efficiency and code quality. Pair programming aims at increasing coding efficiency, code quality, and supports learning of development team members. Several controlled experiments have been conducted to investigate benefits of different development strategies, learning effects, and the impact on code quality in academia and industry. Nevertheless, reported study limitations and various results in different contexts require more studies to fully understand the effects of experience and programming strategies. Coding contests can be promising approaches to (a) involve different participant groups, e.g., junior and senior programmers and professionals, and (b) can represent a well-defined foundation for planning and executing large-scale empirical studies. In this paper we present coding contests as a promising strategy for conducting empirical studies with heterogeneous groups of participants and report on a set of findings from past coding contests. Main results are (a) that the concept of coding contests is a promising way for supporting empirical research and (b) the results partly confirm previous studies that report on the benefits of pair programming and development experience.},
  keywords = {Coding Contests; Large Scale Controlled Experiments; Solo Programming; Pair Programming; Developer Experience},
  owner = {magsilva},
  timestamp = {2014.10.20}
}

@ARTICLE{WirfsBrock:2006,
  author = {Wirfs-Brock, R. J.},
  title = {Looking for powerful abstractions},
  crossref = {journal:ieee:software},
  volume = {23},
  number = {1},
  month = jan # {--} # feb,
  year = {2006},
  pages = {13--15},
  doi = {10.1109/MS.2006.22},
  abstract = {In this paper the author explores the ways that have helped him to become a better designer. Designers must be able to see the problem out there in the real world and solve it by applying the right tools and technologies. Like artists, object designers need to see in special ways to create good solutions - call this modeling or designing. Object technology is just one tool in a very rich toolbox and author discusses the fundamental design skill of finding objects. Finding the right level of abstraction takes practice and experimentation. There are times when both concrete classes and their common abstraction add value to a design, and there are times when they don't. To find good classes, experienced designers make distinctions based on significant behavior differences},
  timestamp = {2013-08-04}
}

@INPROCEEDINGS{Wirth-Bertolacci:2006,
  author = {Wirth, Anthony and Bertolacci, Michael},
  title = {New algorithms research for first year students},
  crossref = {proceedings:itcse:2006},
  pages = {128--132},
  doi = {10.1145/1140124.1140160},
  abstract = {Motivated first-year undergraduate students should be exposed to some of the processes of research and some of the latest results. This brings them into the university culture quickly and encourages them to feel part of the development of the computer science discipline.To this end, students in a second-semester first-year computer science subject were presented with a programming project in which the goal was to implement several approximation algorithms for an active research problem. In addition, they were asked to complete four related mathematical puzzles. The lecturer author and the student author show how this project proved to be an exciting experience for them both. The paper concludes with some suggestions for expanding the research influence in this subject.},
  keywords = {CS1/2, approximation algorithms, haskell, research-led teaching, undergraduate research/capstones}
}

@ARTICLE{Wirth:2008,
  author = {Wirth, Michael},
  title = {Introducing recursion by parking cars},
  crossref = {journal:acm:inroads},
  volume = {40},
  number = {4},
  month = nov,
  year = {2008},
  pages = {52--55},
  doi = {10.1145/1473195.1473219},
  abstract = {Many approaches to teaching recursion in textbooks focus on classical examples such as Fibonacci, factorial, or the Towers of Hanoi. As established as these algorithms are, they don't really illustrate the potential of recursion. This paper explores the use of a novel recursive algorithm which requires innovative thinking, and the use of random numbers. The algorithm looks at the use of recursion to randomly park cars on a street.},
  keywords = {algorithms, car parking, random numbers, recursion}
}

@INPROCEEDINGS{Wirth:1993,
  author = {Wirth, Niklaus},
  title = {Recollections about the development of {Pascal}},
  crossref = {proceedings:hopl:1993},
  pages = {333--342},
  doi = {10.1145/154766.155378},
  abstract = {Pascal was defined in 1970 and, after a slow start, became one of the most widely used languages in introductory programming courses. This article first summarises the events leading to Pascal's design and implementation, and then proceeds with a discussion of some of the language's merits and deficiencies. In the last part, developments that followed its release are recounted. Its influence chiefly derived from its being a vehicle for structured programming and a basis for further development of languages and for experiments in program verification.}
}

@INCOLLECTION{Wirth:2002,
  author = {Niklaus Wirth},
  title = {Pascal and its successors},
  chapter = {5},
  pages = {109--119},
  abstract = {The programming language Pascal was designed in 1969 in the spirit of Algol 60 with a concisely defined syntax representing the paradigm of structured programming. Seven years later, with the advent of the micro-computer, it became widely known and was adopted in many schools and universities. In 1979 it was followed by Modula-2 which catered to the needs of modular programming in teams. This was achieved by the module construct and the separate compilation facility. In an effort to reduce language complexity and to accommodate object-oriented programming, Oberon was designed in 1988. Here we present some aspects of the evolution of this family of programming languages.},
  crossref = {Broy-Denert:2002}
}

@ARTICLE{Wirth:1974,
  author = {Wirth, Niklaus},
  title = {On the Composition of Well-Structured Programs},
  crossref = {journal:acm:csur},
  volume = {6},
  number = {4},
  month = dec,
  year = {1974},
  pages = {247--259},
  doi = {10.1145/356635.356639}
}

@ARTICLE{Wirth:1971a,
  author = {Niklaus Wirth},
  title = {The Programming Language {Pascal}},
  crossref = {journal:springer:acta-informatica},
  volume = {1},
  number = {1},
  month = mar,
  year = {1971},
  pages = {35--63},
  doi = {10.1007/BF00264291},
  abstract = {A programming language called Pascal is described which was developed on the basis ofAlgol 60. Compared toAlgol 60, its range of applicability is considerably increased due to a variety of data structuring facilities. In view of its intended usage both as a convenient basis to teach programming and as an efficient tool to write large programs, emphasis was placed on keeping the number of fundamental concepts reasonably small, on a simple and systematic language structure, and on efficient implementability. A one-pass compiler has been constructed for the CDC 6000 computer family; it is expressed entirely in terms of Pascal itself.}
}

@ARTICLE{Wirth:1971b,
  author = {Wirth, Niklaus},
  title = {Program development by stepwise refinement},
  crossref = {journal:acm:cacm},
  volume = {14},
  number = {4},
  month = apr,
  year = {1971},
  pages = {221--227},
  doi = {10.1145/362575.362577},
  keywords = {education in programming, programming techniques, stepwise program construction}
}

@INPROCEEDINGS{Wohlin:2014,
  author = {Wohlin, Claes},
  title = {Guidelines for Snowballing in Systematic Literature Studies and a Replication in Software Engineering},
  crossref = {proceedings:ease:2014},
  pages = {38:1--38:10},
  doi = {10.1145/2601248.2601268},
  abstract = {Background: Systematic literature studies have become common in software engineering, and hence it is important to understand how to conduct them efficiently and reliably. Objective: This paper presents guidelines for conducting literature reviews using a snowballing approach, and they are illustrated and evaluated by replicating a published systematic literature review. Method: The guidelines are based on the experience from conducting several systematic literature reviews and experimenting with different approaches. Results: The guidelines for using snowballing as a way to search for relevant literature was successfully applied to a systematic literature review. Conclusions: It is concluded that using snowballing, as a first search strategy, may very well be a good alternative to the use of database searches.},
  keywords = {replication, snowball search, snowballing, systematic literature review, systematic mapping studies},
  owner = {magsilva},
  timestamp = {2014.09.13}
}

@ARTICLE{Wohlin-Prikladniki:2013,
  author = {Claes Wohlin and Rafael Prikladniki},
  title = {Systematic literature reviews in software engineering },
  crossref = {journal:elsevier:ist},
  volume = {55},
  number = {6},
  month = jun,
  year = {2013},
  pages = {919--920},
  doi = {10.1016/j.infsof.2013.02.002}
}

@ARTICLE{Wohlin-etal:2013,
  author = {Claes Wohlin and Per Runeson and Paulo Anselmo da Mota Silveira Neto and Emelie Engström and Ivan do Carmo Machado and Eduardo Santana de Almeida},
  title = {On the reliability of mapping studies in software engineering },
  crossref = {journal:elsevier:jss},
  volume = {86},
  number = {10},
  month = oct,
  year = {2013},
  pages = {2594--2610},
  doi = {10.1016/j.jss.2013.04.076},
  abstract = {AbstractBackground Systematic literature reviews and systematic mapping studies are becoming increasingly common in software engineering, and hence it becomes even more important to better understand the reliability of such studies. Objective This paper presents a study of two systematic mapping studies to evaluate the reliability of mapping studies and point out some challenges related to this type of study in software engineering. Method The research is based on an in-depth case study of two published mapping studies on software product line testing. Results We found that despite the fact that the two studies are addressing the same topic, there are quite a number of differences when it comes to papers included and in terms of classification of the papers included in the two mapping studies. Conclusions From this we conclude that although mapping studies are important, their reliability cannot simply be taken for granted. Based on the findings we also provide four conjectures that further research has to address to make secondary studies (systematic mapping studies and systematic literature reviews) even more valuable to both researchers and practitioners. },
  keywords = {Systematic mapping study, Software product lines, Systematic literature review, Review of reviews, Software testing},
  timestamp = {2013-09-05}
}

@INPROCEEDINGS{Wong-etal:1994,
  author = {W. Eric Wong and José C. Maldonado and Márcio E. Delamaro and Aditya P. Mathur},
  title = {Constrained Mutation in {C} Programs},
  crossref = {proceedings:wts:1994},
  pages = {439--451},
  abstract = {Software development is always under the pressure of time and budget constraints before release. A good testing strategy should not only be effective and economical but also incremental. Although mutation testing has been empirically found to be effective in detecting faults, it remains unused for reasons of economics. A major obstacle to the use of mutation testing is its high computational cost. In this paper we report results from experiments designed to investigate six different constrained mutation mechanisms. Our data indicate that these alternatives not only reduce the cost of mutation significantly in terms of the number of test cases required and the number of mutants to be examined, but also mantain very good fault detection effectiveness. Effects of incremental mutation testing examining different sets of mutants are also discussed. Furthermore, our experiments are unique in that constrained mutation was perfomed directly on C programs. This eliminates the possible bias experienced by earlier mutation studies because of the programming language translation between the Fortran, Pascal, and C.},
  keywords = {mutation, constrained mutation, fault detection effectiveness}
}

@ARTICLE{Wood-Kleb:2003,
  author = {Wood, W. A. and Kleb, W. L.},
  title = {Exploring {XP} for Scientific Research},
  crossref = {journal:ieee:software},
  volume = {20},
  number = {3},
  month = may # {--} # jun,
  year = {2003},
  pages = {30--36},
  doi = {10.1109/MS.2003.1196317},
  abstract = {Can we successfully apply XP (Extreme Programming) in a scientific research context? A pilot project at the NASA Langley Research Center tested XPs applicability in this context. Since the cultural environment at a government research center differs from the customer-centric business view, eight of XPs 12 practices seemed incompatible with the existing research culture. Despite initial awkwardness, the authors determined that XP can function in situations for which it appears to be ill suited.},
  owner = {magsilva},
  timestamp = {2014.01.16}
}

@ARTICLE{Woodward:1993,
  author = {M. R. Woodward},
  title = {Mutation Testing -- its Origin and Evolution},
  crossref = {journal:elsevier:ist},
  volume = {35},
  number = {3},
  month = mar,
  year = {1993},
  pages = {163--169},
  doi = {10.1016/0950-5849(93)90053-6},
  abstract = {The aim of the paper is to provide a brief review of the program testing technique known as 'mutation testing' and outline current research directions in this area. Mutation testing is an example of what is sometimes called an error-based testing technique. In other words, it involves the construction of test data designed to uncover specific errors or classes of errors. A large number of simple changes (mutations) are made to a program, one at a time. Test data then has to be found which distinguishes the mutated versions from the original version. Although the idea was proposed more than a decade ago, it is in some ways still a 'new' technique. Originally it was seen by many as costly and somewhat bizarre. However, several variants of the basic method have evolved and these, possibly in conjunction with more efficient techniques for applying the method, can help reduce the cost. Also, by guaranteeing the absence of particular errors, it may be one way to achieve the high reliability necessary in critical software. A further advantage of mutation testing is its universal applicability to all programming languages.},
  lang = {en}
}

@ARTICLE{Wouters-Oostendorp:2013,
  author = {Pieter Wouters and Herre van Oostendorp},
  title = {A meta-analytic review of the role of instructional support in game-based learning},
  crossref = {journal:elsevier:ce},
  volume = {60},
  number = {1},
  month = jan,
  year = {2013},
  pages = {412--425},
  doi = {10.1016/j.compedu.2012.07.018},
  abstract = {Computer games can be considered complex learning environments in which players require instructional support to engage in cognitive processes such as selecting and actively organizing/integrating new information. We used meta-analytical techniques to test if instructional support enhances learning in game-based learning (k = 107, Nadj = 3675). We found that instructional support in game-based learning environments improved learning (d = .34, p &lt; .001). Additional moderator analyses revealed that the learning effect was largest when learning of skills was involved (d = .62, p &lt; .001) and when the instructional support aimed at the selection of relevant new information (d = .46, p &lt; .001). Furthermore, we found some evidence for a publication bias since the effect sizes for studies in peer-reviewed journals was significantly higher than for studies in proceedings and unpublished studies (journals: d = .44; proceedings: d = .08; unpublished: d = .14).},
  keywords = {Computer games, Serious games, Game-based learning, Cognition, Meta-analysis, Instructional support}
}

@ARTICLE{Wright:2013,
  author = {Wright, Alex},
  title = {Proving grounds},
  crossref = {journal:acm:communications},
  volume = {56},
  number = {5},
  month = may,
  year = {2013},
  pages = {17--19},
  doi = {10.1145/2447976.2447982},
  abstract = {Researchers are making headway with one of quantum computing's major theoretical problems: multi-prover interactive proofs.}
}

@ARTICLE{Wrinn:2012,
  author = {Wrinn, Michael},
  title = {Parallel computing: thoughts following a four-year tour of academic outreach},
  crossref = {journal:acm:inroads},
  volume = {3},
  number = {3},
  month = sep,
  year = {2012},
  pages = {4--8},
  doi = {10.1145/2339055.2339057},
  keywords = {CS principles, computational thinking, computer science education}
}

@INPROCEEDINGS{Xie:2012,
  author = {Tao Xie},
  title = {Cooperative Testing and Analysis: Human-Tool, Tool-Tool and Human-Human Cooperations to Get Work Done},
  crossref = {proceedings:scam:2012},
  pages = {1--3},
  doi = {10.1109/SCAM.2012.31},
  abstract = {Tool automation to reduce manual effort has been an active research area in various sub fields of software engineering such as software testing and analysis. To maximize the value of software testing and analysis, effective support for cooperation between engineers and tools is greatly needed and yet lacking in state-of-the-art research and practice. In particular, testing and analysis are in a great need of (1) effective ways for engineers to communicate their testing or analysis goals and guidance to tools and (2) tools with strong enough capabilities to accomplish the given testing or analysis goals and with effective ways to communicate challenges faced by them to engineers -- enabling a feedback loop between engineers and tools to refine and accomplish the testing or analysis goals. In addition, different tools have their respective strengths and weaknesses, and there is also a great need of allowing these tools to cooperate with each other. Similarly, there is a great need of allowing engineers (or even users) to cooperate to help tools such as in the form of crowd sourcing. A new research frontier on synergistic co operations between humans and tools, tools and tools, and humans and humans is yet to be explored. This paper presents recent example advances on cooperative testing and analysis.},
  keywords = {cooperative testing and analysis; human-assisted computing; human-centric computing; tool integration; crownd-sourcing},
  owner = {magsilva},
  timestamp = {2014.01.27},
  year = {2012}
}

@INPROCEEDINGS{Xie-etal:2007,
  author = {Tao Xie and Jian Pei and Hassan, A.E.},
  title = {Mining Software Engineering Data},
  crossref = {proceedings:icse:2007},
  pages = {172--173},
  doi = {10.1109/ICSECOMPANION.2007.50},
  abstract = {Software engineering data (such as code bases, exe- cution traces, historical code changes, mailing lists, and bug databases) contains a wealth of information about a projectÂ¿s status, progress, and evolution. Using well- established data mining techniques, practitioners and re- searchers can explore the potential of this valuable data in order to better manage their projects and to produce higher-quality software systems that are delivered on time and within budget. This tutorial presents the latest research in mining Soft- ware Engineering (SE) data, discusses challenges associ- ated with mining SE data, highlights SE data mining suc- cess stories, and outlines future research directions. Partic- ipants will acquire knowledge and skills needed to perform research or conduct practice in the field and to integrate data mining techniques in their own research or practice.}
}

@ARTICLE{Xie-etal:2009,
  author = {Tao Xie and Thummalapenta, S. and Lo, D. and Chao Liu},
  title = {Data Mining for Software Engineering},
  crossref = {journal:ieee:computer},
  volume = {42},
  number = {8},
  month = aug,
  year = {2009},
  pages = {55--62},
  doi = {10.1109/MC.2009.256},
  abstract = {To improve software productivity and quality, software engineers are increasingly applying data mining algorithms to various software engineering tasks. However, mining SE data poses several challenges. The authors present various algorithms to effectively mine sequences, graphs, and text from such data.},
  keywords = {Computational intelligence; Data mining; Design and test; Software engineering}
}

@INPROCEEDINGS{Xie-etal:2010,
  author = {Xie, Tao and Tillmann, Nikolai and de Halleux, Jonathan and Schulte, Wolfram},
  title = {Future of developer testing: building quality in code},
  crossref = {proceedings:foser:2010},
  pages = {415--420},
  doi = {10.1145/1882362.1882447},
  abstract = {Although much progress has been made in software verification, software testing remains by far the most widely used technique for improving software reliability. Among various types of testing, developer testing is a type of testing where developers test their code as they write it, as opposed to testing done by a separate quality assurance organization. Developer testing has been widely recognized as an important and valuable means of improving software reliability, partly due to its capabilities of exposing faults early in the development life cycle. In this position paper, we present our positions on future directions of developer testing along four dimensions (which of course we do not claim to be complete): correctness confidence, specifications,(dis)integration testing, and human factors. Our positions are originated from two recent promising technologies in developer testing: parameterized unit testing and dynamic symbolic execution, also called concolic testing.},
  keywords = {developer testing, human factors, software testing, specifications}
}

@INPROCEEDINGS{Xu-etal:2014,
  author = {Xu, Zhenbo and Zhang, Jian and Xu, Zhongxing and Wang, Jiteng},
  title = {Canalyze: A Static Bug-finding Tool for {C} Programs},
  crossref = {proceedings:issta:2014},
  pages = {425--428},
  doi = {10.1145/2610384.2628050},
  abstract = {Symbolic analysis is a commonly used approach for static bug finding. It usually performs a precise path-by-path symbolic simulation from program inputs. A major challenge is its scalability and precision on interprocedural analysis. The former limits the application to large programs. The latter may lead to many false alarms. This paper presents a flexible, scalable and practical static bug detection tool, called Canalyze, for C programs. The flexibility is embodied in our modular design that supports different precision-level constraint solvers and interprocedural analyses. Based on these options, one can enable the less precise options to achieve a more scalable analysis or the more time-consuming options to perform a more precise analysis. Our tool is also practical to analyze real-world applications. It has been applied to some industry systems and open source programs like httpd, lighttpd, etc. And hundreds of newly found bugs were confirmed by the maintainers of our benchmarks.},
  keywords = {Bug Finding, Constraint Solving, Interprocedural Analysis, Symbolic Analysis},
  owner = {magsilva},
  timestamp = {2014.07.21}
}

@ARTICLE{Yadin:2013,
  author = {Yadin, Aharon},
  title = {Using unique assignments for reducing the bimodal grade distribution},
  crossref = {journal:acm:inroads},
  volume = {4},
  number = {1},
  month = mar,
  year = {2013},
  pages = {38--42},
  doi = {10.1145/2432596.2432612},
  abstract = {This article describes a study that was intended to reduce the bimodal grade distribution of students of the Management Information Systems department. Unlike the normal distribution that represents many natural groups, a bimodal distribution represents two, sometimes unique, sub-populations within one group. There are many studies of the causes of this phenomenon; however, this study is mainly concerned with finding ways to reduce it. The significance of a bimodal distribution lies in its ability to predict future failures, especially in the lower sub-population. Dealing with these future failures is important due to the sharp reduction in the number of enrolled students and the increase in the dropout rate that has stemmed from various reasons. This eight-year study focused on strengthening students' learning habits, which played a significant role in increasing students' overall motivation and levels of self-accountability and produced a more homogeneous group, as represented by the normal grade distribution.},
  keywords = {bimodal distribution, individual and unique assignments, learning habits}
}

@ARTICLE{Yadin:2011,
  author = {Yadin, Aharon},
  title = {Reducing the dropout rate in an introductory programming course},
  crossref = {journal:acm:inroads},
  volume = {2},
  number = {4},
  month = dec,
  year = {2011},
  pages = {71--76},
  doi = {10.1145/2038876.2038894},
  abstract = {This article describes an action research for reducing the high students' dropout rate after an introductory programming course. As part of the action research, that was performed during four semesters several course structures and learning tactics were examined. The success was attributed to three main factors. (1) using Python as the first introductory programming language, which freed the students from detailed language syntax and allowed them to concentrate on algorithms and problem solving; (2) using a visualization environment (Micro-world) for the whole duration of the course, which helped in understanding the more complex and abstract issues; and (3) using individual assignments that enforced better learning habits. The article describes the various attempts, as well as the final structure that reduced the failing students by over 77%.},
  keywords = {introductory programming course, reducing dropout}
}

@ARTICLE{Yair:2014,
  author = {Yair, Yoav},
  title = {Did You Let a Robot Check My Homework?},
  crossref = {journal:acm:inroads},
  volume = {5},
  number = {2},
  month = jun,
  year = {2014},
  pages = {33--35},
  doi = {10.1145/2614512.2614522},
  owner = {magsilva},
  timestamp = {2014.10.06}
}

@ARTICLE{Yamagata-etal:2012,
  author = {Yamagata, Yoriyuki and Kong, Weiqiang and Fukuda, Akira and Nguyen, Van Tang and Ohsaki, Hitoshi and Taguchi, Kenji},
  title = {Formal semantics of extended hierarchical state transition matrix by CSP},
  crossref = {journal:acm:sigsoft},
  volume = {37},
  number = {4},
  month = jul,
  pages = {1--8},
  doi = {10.1145/2237796.2237805},
  abstract = {The Extended Hierarchical State Transition Matrix (EHSTM) is a table-based modeling language frequently used in industry for specifying behaviors of a system. However, assuring correctness, i.e., having a design satisfy certain desired properties, is a non-trivial task. To address this problem, a model checker dedicated to EHSTMs called Garakabu2 is developed. However, there is no formal justification of Garakabu2, since its semantics has never been fully formalized. In this paper, we give a formal semantics to EHSTM by translating it into CSP, Communicating Sequential Processes. Our semantics covers most of the features supported by Garakabu2. We manually translate the small examples of EHSTM to CSP, and verify them by PAT, a CSP based model checker. We also verify the examples directly using Garakabu2 and show the result are same. The experiments also show that verification using our translation and PAT is much faster than that of Garakabu2 for checking message type EHSTM.}
}

@INPROCEEDINGS{Yamashita-etal:2014,
  author = {Yamashita, Kazuhiro and McIntosh, Shane and Kamei, Yasutaka and Ubayashi, Naoyasu},
  title = {Magnet or Sticky? An OSS Project-by-project Typology},
  crossref = {proceedings:msr:2014},
  pages = {344--347},
  doi = {10.1145/2597073.2597116},
  abstract = {For Open Source Software (OSS) projects, retaining existing contributors and attracting new ones is a major concern. In this paper, we expand and adapt a pair of population migration metrics to analyze migration trends in a collection of open source projects. Namely, we study: (1) project stickiness, i.e., its tendency to retain existing contributors and (2) project magnetism, i.e., its tendency to attract new contributors. Using quadrant plots, we classify projects as attractive (highly magnetic and sticky), stagnant (highly sticky, weakly magnetic), fluctuating (highly magnetic, weakly sticky), or terminal (weakly magnetic and sticky). Through analysis of the MSR challenge dataset, we find that: (1) quadrant plots can effectively identify at-risk projects, (2) stickiness is often motivated by professional activity and (3) transitions among quadrants as a project ages often coincides with interesting events in the evolution history of a project.},
  keywords = {Developer migration, Magnet, Open source, Sticky},
  owner = {magsilva},
  timestamp = {2014.05.21}
}

@INPROCEEDINGS{Yamauchi-etal:2000,
  author = {Yutaka Yamauchi and Makoto Yokozawa and Takeshi Shinohara and Toru Ishida},
  title = {Collaboration with Lean Media: How Open-Source Software Succeeds},
  crossref = {proceedings:cscw:2000},
  pages = {329-338},
  doi = {10.1145/358916.359004},
  abstract = {Open-source software, usually created by volunteer programmers dispersed worldwide, now competes with that developed by software firms. This achievement is particularly impressive as open-source programmers rarely meet. They rely heavily on electronic media, which preclude the benefits of face-to-face contact that programmers enjoy within firms. In this paper, we describe findings that address this paradox based on observation, interviews and quantitative analyses of two open-source projects. The findings suggest that spontaneous work coordinated afterward is effective, rational organizational culture helps achieve agreement among members and communications media moderately support spontaneous work. These findings can imply a new model of dispersed collaboration.},
  keywords = {CVS, cooperative work, distributed work, electronic media, innovation, open-source, software engineering}
}

@ARTICLE{Yang:2010,
  author = {Yang, Feng-Jen},
  title = {The ideology of intelligent tutoring systems},
  crossref = {journal:acm:inroads},
  volume = {1},
  number = {4},
  month = dec,
  year = {2010},
  pages = {63--65},
  doi = {10.1145/1869746.1869765},
  abstract = {After approximately four decades of evolution, the attempt of using Intelligent Tutoring Systems (ITS) as extracurricular assistances is now widely accepted. As a rapid growing subarea of expert systems, their accomplishments are remarkable. During the exploration of making virtual tutors more humanlike, researchers have made a great deal of efforts on the investigation of further in-depth rationales and technologies such as tutoring paradigms, student modeling, instruction modeling, adaptive curriculum planning, and user interfaces. In this paper, I compiled some literatures on those essential issues and concluded the future of ITS at the end.},
  keywords = {e-learning, intelligent tutoring systems, virtual tutors},
  acmid = {1869765},
  issue = {4},
  issue_date = {December 2010},
  lang = {en},
  numpages = {3}
}

@ARTICLE{Yang:2008,
  author = {Yang, Feng-Jen},
  title = {Another outlook on linear recursion},
  crossref = {journal:acm:inroads},
  volume = {40},
  number = {4},
  month = nov,
  year = {2008},
  pages = {38--41},
  doi = {10.1145/1473195.1473216},
  abstract = {Recursion is a well known hurdle for computer science beginners. This powerful problem solving technique challenges both instructors and students on how to convey and learn this skill correctively and efficiently. In this paper, I presented an analogy-based approach to expound the theoretical detail of linear recursion.},
  keywords = {analogical instruction, heuristic, linear recursion}
}

@INPROCEEDINGS{Yao-etal:2014,
  author = {Yao, Xiangjuan and Harman, Mark and Jia, Yue},
  title = {A Study of Equivalent and Stubborn Mutation Operators Using Human Analysis of Equivalence},
  crossref = {proceedings:icse:2014},
  pages = {919--930},
  doi = {10.1145/2568225.2568265},
  abstract = {Though mutation testing has been widely studied for more than thirty years, the prevalence and properties of equivalent mutants remain largely unknown. We report on the causes and prevalence of equivalent mutants and their relationship to stubborn mutants (those that remain undetected by a high quality test suite, yet are non-equivalent). Our results, based on manual analysis of 1,230 mutants from 18 programs, reveal a highly uneven distribution of equivalence and stubbornness. For example, the ABS class and half UOI class generate many equivalent and almost no stubborn mutants, while the LCR class generates many stubborn and few equivalent mutants. We conclude that previous test effectiveness studies based on fault seeding could be skewed, while developers of mutation testing tools should prioritise those operators that we found generate disproportionately many stubborn (and few equivalent) mutants.},
  keywords = {Equivalent Mutant, Mutation Testing, Stubborn Mutant},
  owner = {magsilva},
  timestamp = {2014.05.22}
}

@INPROCEEDINGS{Ye-Kishida:2003,
  author = {Ye, Yunwen and Kishida, Kouichi},
  title = {Toward an Understanding of the Motivation Open Source Software Developers},
  crossref = {proceedings:icse:2003},
  pages = {419--429},
  doi = {10.1109/ICSE.2003.1201220},
  abstract = {An Open Source Software (OSS) project is unlikely to be successful unless there is an accompanied community that provides the platform for developers and users to collaborate. Members of such communities are volunteers whose motivation to participate and contribute is of essential importance to the success of OSS projects. In this paper, we aim to create an understanding of what motivates people to participate in OSS communities. We theorize that learning is one of the motivational forces. Our theory is grounded in the learning theory of Legitimate Peripheral Participation, and is supported by analyzing the social structure of OSS communities and the co-evolution between OSS systems and communities. We also discuss practical implications of our theory for creating and maintaining sustainable OSS communities as well as for software engineering research and education.},
  owner = {magsilva},
  timestamp = {2014.05.29}
}

@ARTICLE{Yong-etal:2013,
  author = {Jianming Yong and Weiming Shen and Anne James},
  title = {Collaborative computing technologies and systems },
  crossref = {journal:elsevier:jss},
  volume = {86},
  number = {7},
  month = jul,
  year = {2013},
  pages = {1725--1726},
  doi = {10.1016/j.jss.2013.03.058}
}

@INPROCEEDINGS{Yoshida:2014,
  author = {Kohel Yoshida},
  title = {Life after Calc Core Change},
  crossref = {proceedings:libreoffice:2014},
  pages = {22-22},
  abstract = {4.2 releases were perhaps most memorable in my whole LibreOffice history. I will discuss how that experience went; what I expected, and what actually happened, what were the pitfalls and how they should be handled in the future, and how all of that experience will affect the future maintenance of this code base going forward.},
  owner = {magsilva},
  timestamp = {2014.09.12}
}

@INPROCEEDINGS{Yuan-etal:2003,
  author = {Yuan, Jing and Holcombe, Mike and Gheorghe, Marian},
  title = {Where Do Unit Tests Come from?},
  crossref = {proceedings:xp:2003},
  pages = {161--169},
  doi = {10.1007/3-540-44870-5_21},
  abstract = {In Extreme programming unit testing is organized so that the unit tests are written before coding commences. For many programmers the selection of the test cases is something of an ad hoc process. Where programmers are experienced in writing test sets it is common for them to use white box or structural test techniques. However, these rely on the structure of the code being available which is not the case with XP. This article describes a principled way of creating powerful, functional unit tests from informal descriptions of the units.},
  owner = {magsilva},
  timestamp = {2014.10.21}
}

@ARTICLE{Yue-etal:2004,
  author = {Kwok-Bun Yue and T. Andrew Yang and Wei Ding and Ping Chen},
  title = {Open courseware and computer science education},
  crossref = {journal:ccsc:jcsc},
  volume = {20},
  number = {1},
  year = {2004},
  pages = {178--186},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@INPROCEEDINGS{Zaccai-etal:2014,
  author = {Zaccai, Diego and Tagore, Aditi and Hoffman, Dustin and Kirschenbaum, Jason and Bainazarov, Zakariya and Friedman, Harvey M. and Pearl, Dennis K. and Weide, Bruce W.},
  title = {Syrus: Providing Practice Problems in Discrete Mathematics with Instant Feedback},
  crossref = {proceedings:sigcse:2014},
  pages = {61--66},
  doi = {10.1145/2538862.2538929},
  abstract = {Syrus is courseware designed with the goal of helping students better understand logical sentences involving quantifiers. Syrus uses template-guided mutation of "seed" formulas to generate candidate practice problems, and third-party theorem-provers to automatically determine the truth value of each. It provides students with a virtually unlimited supply of unique and relevant practice problems and provides immediate feedback on each problem. Results of an empirical study of its efficacy are reported.},
  keywords = {discrete mathematics, interactive learning, mathematical theories in cs, on-line education, predicate calculus}
}

@INPROCEEDINGS{Zaina-etal:2010,
  author = {Zaina, Luciana A. M. and Rodrigues,Jr, Jose F. and Bressan, Graça},
  title = {An approach to design the student interaction based on the recommendation of e-learning objects},
  crossref = {proceedings:sigdoc:2010},
  pages = {223--228},
  doi = {10.1145/1878450.1878488},
  abstract = {In the last years, the adoption of recommender systems for improving user interaction has increased in e-learning applications. In the educational area, the recommendation of relevant and interesting content can attract the student's attention, motivating her/him during the learning-teaching process. It is very important, thus, to know learner preferences to suggest suitable contents to the students. The goal of this work is to present an approach to design the student interaction based on the recommendation of e-learning content, determining a more suitable relationship between learning objects and learning profiles. In our proposal, the learning profile is split into categories to attend different student preferences during the teaching-learning process: perception, presentation-format and participation. Our recommendation uses these categories to filter out the most suitable learning objects organized according to the IEEE LOM standard. We present a prototype architecture named e-LORS, over which we perform demonstrative experiments.},
  keywords = {Felder-Silverman learning style model, LOM standard, learning model, learning objects, learning profile, recommendation systems},
  series = {SIGDOC '10},
  acmid = {1878488},
  address = {New York, NY, USA},
  booktitle = {Proceedings of the 28th ACM International Conference on Design of Communication},
  isbn = {978-1-4503-0403-0},
  location = {São Carlos, São Paulo, Brazil},
  numpages = {6},
  publisher = {ACM},
  year = {2010}
}

@ARTICLE{Zamani-etal:2014,
  author = {Sima Zamani and Sai Peck Lee and Ramin Shokripour and John Anvik},
  title = {A noun-based approach to feature location using time-aware term-weighting},
  crossref = {journal:elsevier:ist},
  volume = {56},
  number = {8},
  month = aug,
  year = {2014},
  pages = {991--1011},
  doi = {10.1016/j.infsof.2014.03.007},
  abstract = {Feature location aims to identify the source code location corresponding to the implementation of a software feature. Many existing feature location methods apply text retrieval to determine the relevancy of the features to the text data extracted from the software repositories. One of the preprocessing activities in text retrieval is term-weighting, which is used to adjust the importance of a term within a document or corpus. Common term-weighting techniques may not be optimal to deal with text data from software repositories due to the origin of term-weighting techniques from a natural language context. This paper describes how the consideration of when the terms were used in the repositories, under the condition of weighting only the noun terms, can improve a feature location approach. We propose a feature location approach using a new term-weighting technique that takes into account how recently a term has been used in the repositories. In this approach, only the noun terms are weighted to reduce the dataset volume and avoid dealing with dimensionality reduction. An empirical evaluation of the approach on four open-source projects reveals improvements to the accuracy, effectiveness and performance up to 50%, 17%, and 13%, respectively, when compared to the commonly-used Vector Space Model approach. The comparison of the proposed term-weighting technique with the Term Frequency-Inverse Document Frequency technique shows accuracy, effectiveness, and performance improvements as much as 15%, 10%, and 40%, respectively. The investigation of using only noun terms, instead of using all terms, in the proposed approach also indicates improvements up to 28%, 21%, and 58% on accuracy, effectiveness, and performance, respectively. In general, the use of time in the weighting of terms, along with the use of only the noun terms, makes significant improvements to a feature location approach that relies on textual information.},
  keywords = {Feature location, Software change request, Time-metadata, Term-weighting, Noun usage},
  owner = {magsilva},
  timestamp = {2014.05.22}
}

@INPROCEEDINGS{Zamboni-etal:2010,
  author = {Augusto Zamboni and André Di Thommazo and Elis Hernandes and Sandra Fabbri},
  title = {{StArt} -- Uma Ferramenta Computacional de Apoio à Revisão Sistemática},
  crossref = {proceedings:sbes-tools:2010},
  pages = {91--96},
  abstract = {Systematic Review (SR) is a technique used to search for evidence in scientific literature that is conducted in a formal manner, applying well-defined steps, according to a previously elaborated protocol. As the SR has many steps and activities, its execution is laborious and repetitive. Therefore, the support of a computational tool is essential to improve the quality of its application. This paper presents the tool called StArt (State of the Art through Systematic Review), which aims to help the researcher, giving support to the application of this technique. The StArt tool has being used by graduate students who have declared its positive support and its advantages in relation to other tools.}
}

@INPROCEEDINGS{Zanetti-etal:2013,
  author = {Marcelo Serrano Zanetti and Ingo Scholtes and Claudio Juan Tessone and Frank Schweitzer},
  title = {The rise and fall of a central contributor: Dynamics of social organization and performance in the {GENTOO} community},
  crossref = {proceedings:chase:2013},
  pages = {49--56},
  doi = {10.1109/CHASE.2013.6614731},
  abstract = {Social organization and division of labor crucially influence the performance of collaborative software engineering efforts. In this paper, we provide a quantitative analysis of the relation between social organization and performance in Gentoo, an Open Source community developing a Linux distribution. We study the structure and dynamics of collaborations as recorded in the project's bug tracking system over a period of ten years. We identify a period of increasing centralization after which most interactions in the community were mediated by a single central contributor. In this period of maximum centralization, the central contributor unexpectedly left the project, thus posing a significant challenge for the community. We quantify how the rise, the activity as well as the subsequent sudden dropout of this central contributor affected both the social organization and the bug handling performance of the Gentoo community. We analyze social organization from the perspective of network theory and augment our quantitative findings by interviews with prominent members of the Gentoo community which shared their personal insights.},
  timestamp = {2013-12-18}
}

@ARTICLE{Zelkowitz:2012,
  author = {Zelkowitz, Marvin V.},
  title = {What have we learned about software engineering?},
  crossref = {journal:acm:cacm},
  volume = {55},
  number = {2},
  month = feb,
  year = {2012},
  pages = {38--39},
  doi = {10.1145/2076450.2076463}
}

@ARTICLE{Zendler-etal:2011,
  author = {Zendler, A. and Spannagel, C. and Klaudt, D.},
  title = {Marrying Content and Process in Computer Science Education},
  crossref = {journal:ieee:te},
  volume = {54},
  number = {3},
  month = aug,
  year = {2011},
  pages = {387 -397},
  doi = {10.1109/TE.2010.2062184},
  abstract = {Constructivist approaches to computer science education emphasize that as well as knowledge, thinking skills and processes are involved in active knowledge construction. K-12 computer science curricula must not be based on fashions and trends, but on contents and processes that are observable in various domains of computer science, that can be taught at every intellectual level, that will stay relevant in the longer term, and that are related to everyday language and/or thinking. Only recently, two empirically determined lists, one of central content concepts (algorithm, computer, data, system, etc.) and another of central process concepts (problem solving and problem posing, analyzing, classifying, generalizing, etc.), have become available for computer science education. This paper tackles the problem of finding content and process concepts to be taught in combination. Computer science experts are surveyed in order to identify combinations of content and process concepts-so-called blocks-that are relevant to computer science education. By using cluster analyses, 15 central blocks for teaching computer science in schools are determined. The results of this study may serve as a reference system for the systematic design of instruction in K-12 computer science education.},
  keywords = {K-12 computer science curricula;active knowledge construction;cluster analyses;computer science education;thinking skills;computer science educatio;educational courses;pattern clustering;}
}

@ARTICLE{Zhang-etal:2013,
  author = {He Zhang and Muhammad Ali Babar},
  title = {Systematic reviews in software engineering: An empirical investigation },
  crossref = {journal:elsevier:ist},
  volume = {55},
  number = {7},
  month = jul,
  year = {2013},
  pages = {1341--1354},
  doi = {10.1016/j.infsof.2012.09.008},
  abstract = {Background Systematic Literature Reviews (SLRs) have gained significant popularity among Software Engineering (SE) researchers since 2004. Several researchers have also been working on improving the scientific and methodological infrastructure to support \{SLRs\} in SE. We argue that there is also an apparent and essential need for evidence-based body of knowledge about different aspects of the adoption of \{SLRs\} in SE. Objective The main objective of this research is to empirically investigate the adoption, value, and use of \{SLRs\} in \{SE\} research from various perspectives. Method We used mixed-methods approach (systematically integrating tertiary literature review, semi-structured interviews and questionnaire-based survey) as it is based on a combination of complementary research methods which are expected to compensate each others' limitations. Results A large majority of the participants are convinced of the value of using a rigourous and systematic methodology for literature reviews in \{SE\} research. However, there are concerns about the required time and resources for SLRs. One of the most important motivators for performing \{SLRs\} is new findings and inception of innovative ideas for further research. The reported \{SLRs\} are more influential compared to the traditional literature reviews in terms of number of citations. One of the main challenges of conducting \{SLRs\} is drawing a balance between methodological rigour and required effort. Conclusions \{SLR\} has become a popular research methodology for conducting literature review and evidence aggregation in SE. There is an overall positive perception about this relatively new methodology to \{SE\} research. The findings provide interesting insights into different aspects of SLRs. We expect that the findings can provide valuable information to readers about what can be expected from conducting \{SLRs\} and the potential impact of such reviews. },
  keywords = {Systematic (literature) reviews, Evidence-based software engineering, Research methodology, Methodology adoption, Mixed-methods research, Tertiary study}
}

@ARTICLE{Zhang-etal:2011:ist,
  author = {He Zhang and Muhammad Ali Babar and Paolo Tell},
  title = {Identifying relevant studies in software engineering},
  crossref = {journal:elsevier:ist},
  volume = {53},
  number = {6},
  month = jun,
  year = {2011},
  pages = {625--637},
  doi = {10.1016/j.infsof.2010.12.010},
  abstract = {Context Systematic literature review (SLR) has become an important research methodology in software engineering since the introduction of evidence-based software engineering (EBSE) in 2004. One critical step in applying this methodology is to design and execute appropriate and effective search strategy. This is a time-consuming and error-prone step, which needs to be carefully planned and implemented. There is an apparent need for a systematic approach to designing, executing, and evaluating a suitable search strategy for optimally retrieving the target literature from digital libraries.Objective The main objective of the research reported in this paper is to improve the search step of undertaking SLRs in software engineering (SE) by devising and evaluating systematic and practical approaches to identifying relevant studies in SE.Method We have systematically selected and analytically studied a large number of papers (SLRs) to understand the state-of-the-practice of search strategies in EBSE. Having identified the limitations of the current ad-hoc nature of search strategies used by SE researchers for SLRs, we have devised a systematic and evidence-based approach to developing and executing optimal search strategies in SLRs. The proposed approach incorporates the concept of [`]quasi-gold standard' (QGS), which consists of collection of known studies, and corresponding [`]quasi-sensitivity' into the search process for evaluating search performance.Results We conducted two participant-observer case studies to demonstrate and evaluate the adoption of the proposed QGS-based systematic search approach in support of SLRs in SE research.Conclusion We report their findings based on the case studies that the approach is able to improve the rigor of search process in an SLR, as well as it can serve as a supplement to the guidelines for SLRs in EBSE. We plan to further evaluate the proposed approach using a series of case studies on varying research topics in SE.},
  keywords = {Search strategy},
  lang = {en}
}

@INPROCEEDINGS{Zhang-etal:2011:ease,
  author = {He Zhang and Babar, M.A. and Xu Bai and Juan Li and Liguo Huang},
  title = {An empirical assessment of a systematic search process for systematic reviews},
  crossref = {proceedings:ease:2011},
  pages = {56--65},
  doi = {10.1049/ic.2011.0007},
  abstract = {Background: Systematic Literature Reviews (SLRs) have been gaining significant attention from Software Engineering (SE) researchers. Several researchers are also working on improving SLR methodology for SE. Objective: The study reported in this paper aims to validate the QGS-based search process for SLR, i.e. whether a more effective (sensitive) and/or productive (precise) search can be achieved by following the QGS-based process. Method: We used a dual-case study, in which each case includes two observations of SE literature search for the same SLR but using and not using the QGS-based approach. The overall sensitivity and precision were calculated for each observation that implemented different search design. Results: The use of QGS-based search process resulted in higher sensitivity and precision in this dual-case study. Conclusions: A systematic search process can help capture more relevant studies as well as save researchers' time spent on literature search activities. Our observations also support that an integrated search strategy is recommended for SLRs in SE to avoid the possible limitations of applying a single (manual or automated) search method.}
}

@INPROCEEDINGS{Zhang:2007:ENO:1242572.1242603,
  author = {Zhang, Jun and Ackerman, Mark S. and Adamic, Lada},
  title = {Expertise Networks in Online Communities: Structure and Algorithms},
  crossref = {proceedings:www:2007},
  pages = {221--230},
  doi = {10.1145/1242572.1242603},
  abstract = {Web-based communities have become important places for people to seek and share expertise. We find that networks in these communities typically differ in their topology from other online networks such as the World Wide Web. Systems targeted to augment web-based communities by automatically identifying users with expertise, for example, need to adapt to the underlying interaction dynamics. In this study, we analyze the Java Forum, a large online help-seeking community, using social network analysis methods. We test a set of network-based ranking algorithms, including PageRank and HITS, on this large size social network in order to identify users with high expertise. We then use simulations to identify a small number of simple simulation rules governing the question-answer dynamic in the network. These simple rules not only replicate the structural characteristics and algorithm performance on the empirically observed Java Forum, but also allow us to evaluate how other algorithms may perform in communities with different characteristics. We believe this approach will be fruitful for practical algorithm design and implementation for online expertise-sharing communities.},
  keywords = {expertise finding, expertise locators, help seeking, online communities, simulation, social network analysis},
  owner = {magsilva},
  timestamp = {2014.05.18}
}

@ARTICLE{Zhang-etal:2010,
  author = {Zhang, Qi and Cheng, Lu and Boutaba, Raouf},
  title = {Cloud computing: state-of-the-art and research challenges},
  crossref = {journal:springer:jisa},
  volume = {1},
  number = {1},
  month = may,
  year = {2010},
  pages = {7--18},
  doi = {10.1007/s13174-010-0007-6},
  abstract = {Cloud computing has recently emerged as a new paradigm for hosting and delivering services over the Internet. Cloud computing is attractive to business owners as it eliminates the requirement for users to plan ahead for provisioning, and allows enterprises to start from the small and increase resources only when there is a rise in service demand. However, despite the fact that cloud computing offers huge opportunities to the IT industry, the development of cloud computing technology is currently at its infancy, with many issues still to be addressed. In this paper, we present a survey of cloud computing, highlighting its key concepts, architectural principles, state-of-the-art implementation as well as research challenges. The aim of this paper is to provide a better understanding of the design challenges of cloud computing and identify important research directions in this increasingly important area.},
  keywords = {Cloud computing; Data centers; Virtualization}
}

@ARTICLE{Zhou-etal:2014,
  author = {Yuming Zhou and Yibiao Yang and Baowen Xu and Hareton Leung and Xiaoyu Zhou},
  title = {Source code size estimation approaches for object-oriented systems from \{UML\} class diagrams: A comparative study },
  crossref = {journal:elsevier:ist},
  volume = {56},
  number = {2},
  month = feb,
  year = {2014},
  pages = {220--237},
  doi = {10.1016/j.infsof.2013.09.003},
  abstract = {Background Source code size in terms of SLOC (source lines of code) is the input of many parametric software effort estimation models. However, it is unavailable at the early phase of software development. We investigate the accuracy of early SLOC estimation approaches for an object-oriented system using the information collected from its UML class diagram available at the early software development phase. We use different modeling techniques to build the prediction models for investigating the accuracy of six types of metrics to estimate SLOC. The used techniques include linear models, non-linear models, rule/tree-based models, and instance-based models. The investigated metrics are class diagram metrics, predictive object points, object-oriented project size metric, fast&&serious class points, objective class points, and object-oriented function points. Based on 100 open-source Java systems, we find that the prediction model built using object-oriented project size metric and ordinary least square regression with a logarithmic transformation achieves the highest accuracy (mean MMRE=0.19 and mean Pred(25)=0.74). We should use object-oriented project size metric and ordinary least square regression with a logarithmic transformation to build a simple, accurate, and comprehensible SLOC estimation model. },
  keywords = {Object-oriented, Code size, Estimation, UML, Class diagrams}
}

@ARTICLE{Zhu-etal:1997,
  author = {H. Zhu and P. Hall and J. May},
  title = {Software Unit Test Coverage and Adequacy},
  crossref = {journal:acm:csur},
  volume = {29},
  number = {4},
  month = dec,
  year = {1997},
  pages = {366--427},
  doi = {10.1145/267580.267590},
  abstract = {Objective measurement of test quality is one of the key issues in software testing. It has been a major research focus for the last two decades. Many test criteria have been proposed and studied for this purpose. Various kinds of rationales have been presented in support of one criterion or another. We survey the research work in this area. The notion of adequacy criteria is examined together with its role in software dynamic testing. A review of criteria classification is followed by a summary of the methods for comparison and assessment of criteria.},
  keywords = {comparing testing effectiveness, fault detection, software unit test, test adequacy criteria, test coverage, testing methods},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{Zingaro-etal:2012,
  author = {Zingaro, Daniel and Petersen, Andrew and Craig, Michelle},
  title = {Stepping up to integrative questions on {CS1} exams},
  crossref = {proceedings:sigcse:2012},
  pages = {253--258},
  doi = {10.1145/2157136.2157215},
  abstract = {In this paper, we explore the use of sequences of small code writing questions ("concept questions") designed to incrementally evaluate single programming concepts. We report on a study of student performance on a CS1 final examination that included a traditional code-writing question and four intentionally corresponding concept questions. We find that the concept questions are significant predictors of performance on both the corresponding code-writing question and the final exam as a whole. We argue that concept questions provide more accurate formative feedback and simplify marking by reducing the number of variants that must be considered. An analysis of responses categorized by the students' previous programming experience suggests that inexperienced students have the most to gain from the use of concept questions.},
  keywords = {CS1, exams, novice programming}
}

@INPROCEEDINGS{Zsombori-etal:2011,
  author = {Zsombori, Vilmos and Frantzis, Michael and Guimaraes, Rodrigo Laiola and Ursu, Marian Florin and Cesar, Pablo and Kegel, Ian and Craigie, Roland and Bulterman, Dick C.A.},
  title = {Automatic generation of video narratives from shared {UGC}},
  crossref = {proceedings:ht:2011},
  pages = {325--334},
  doi = {10.1145/1995966.1996009},
  abstract = {This paper introduces an evaluated approach to the automatic generation of video narratives from user generated content gathered in a shared repository. In the context of social events, end-users record video material with their personal cameras and upload the content to a common repository. Video narrative techniques, implemented using Narrative Structure Language (NSL) and ShapeShifting Media, are employed to automatically generate movies recounting the event. Such movies are personalized according to the preferences expressed by each individual end-user, for each individual viewing. This paper describes our prototype narrative system, MyVideos, deployed as a web application, and reports on its evaluation for one specific use case: assembling stories of a school concert by parents, relatives and friends. The evaluations carried out through focus groups, interviews and field trials, in the Netherlands and UK, provided validating results and further insights into this approach.},
  keywords = {computational narrativity, digital storytelling, interactive narrative, interactive storytelling, interactive television, media share, nsl, shapeshifting media, smil, user generated content, video}
}

@INPROCEEDINGS{Zurcher-Randel:1968,
  author = {F. W. Zurcher and B. Randell},
  title = {Iterative multi-level modeling: a methodology for computer system design},
  crossref = {proceedings:ifip:1968},
  pages = {867--871},
  abstract = {The paper presents a method of modelling a computer system design as it evolves, so that evaluation can be made an integral part of the design process. The paper introduces the concept of concurrent existence, within a single model, of several representations of the system being modelled, at differing levels of abstraction. Thus important design decisions are expressed directly in terms of appropriately abstract quantities, facilitating understanding, validation, and modification of the system design. The paper includes brief details of an experimental implementation of the modelling technique and of the use of the technique to model both hardware and software components of a multi-processing system},
  volume = {2},
  owner = {magsilva},
  timestamp = {2014.10.23}
}

@MISC{journal:acm:inroads:2:4,
  month = dec,
  crossref = {journal:acm:inroads},
  number = {4},
  volume = {2}
}

@MISC{journal:acm:inroads:1:3,
  month = mar,
  year = {2012},
  crossref = {journal:acm:inroads},
  number = {1},
  volume = {3}
}

@PROCEEDINGS{proceedings:remidi:2012,
  booktitle = {6th International Workshop on Tool Support Development and Management in Distributed Software Projects},
  year = {2012},
  month = aug,
  location = {Porto Alegre, RS, #Brazil#},
  publisher = {IEEE Computer Society},
  colocated-with = {IEEE 7th International Conference on Global Software Engineering},
  crossref = {proceedings:icgsew:2012},
  day = {27--30}
}

@ARTICLE{Amorim-Borba:2012,
  author = {Fernanda d'Amorim and Paulo Borba},
  title = {Modularity analysis of use case implementations},
  volume = {85},
  number = {4},
  month = apr,
  year = {2012},
  pages = {1012 - 1027},
  doi = {10.1016/j.jss.2011.11.1025},
  abstract = {A component-based decomposition can result in implementations having use cases code tangled with other concerns and scattered across components. Modularity mechanisms such as aspects, mixins, and virtual classes have been proposed to address this kind of problem. One can use such mechanisms to group together code related to a single use case. This paper quantitatively analyzes the impact of this kind of use case modularization. We apply one specific technique, aspect oriented programming, to modularize the use case implementations of two information systems that conform to the layered architecture pattern. We extract traditional and contemporary metrics - including cohesion, coupling, and separation of concerns - to analyze modularity in terms of quality attributes such as changeability, support for independent development, and pluggability. Our findings indicate that the results of a given modularity analysis depend on other factors beyond the chosen system, metrics, and the applied modularity technique.},
  keywords = {Modularity; Use cases; Aspect-oriented programming; Empirical software engineering},
  url = {http://www.sciencedirect.com/science/article/pii/S0164121211002950},
  issn = {0164-1212},
  journal = {Journal of Systems and Software}
}

@INPROCEEDINGS{xiaomei-etal:2009:iccse,
  author = {Yang Xiao-mei and Dai Heng and Gu Ping},
  title = {Mapping approach for model transformation of MDA based on xUML},
  pages = {862 -865},
  doi = {10.1109/ICCSE.2009.5228207},
  abstract = {Based on Model-Driven Architecture (MDA) software development process, UML had still many inadequacies, so that OMG proposed eXecutable UML-based object-oriented system modeling techniques and methods, and more effectively support the MDA modeling process and improving the software development efficiency and quality. In this paper, through the use of IBM's Rational Software Architect (RSA) development tools, proposed xUML which described PIM, the use of standard design XMI conversion rules, automatically converted to the realization of PIM based on the XMI/XML technology platform to support the PSM.},
  keywords = {model transformation;model-driven architecture;object-oriented system;rational software architect;software development;software development process;unified modeling language;Unified Modeling Language;XML;object-oriented programming;software architecture;software quality;},
  booktitle = {International Conference on Computer Science Education},
  month = jul,
  year = {2009}
}

@INPROCEEDINGS{xiaomei-etal:2009:iwetcs,
  author = {Yang Xiao-mei and Gu Ping and Dai Heng},
  title = {Mapping Approach for Model Transformation of MDA Based on XMI/XML Platform},
  pages = {1016 -1019},
  doi = {10.1109/ETCS.2009.733},
  abstract = {Model driven architecture (MDA), which takes platform independent modeling and platform specific transforming as its core technologies, is a software development method and standards system using modeling newly issued by OMG. It analyzes the basic theorem of ROSE, and point out deficiency the model transformation from PIM to PSM. This paper presents a vision of mapping method from PIM to PSM based on XMI/XML platform, using UML. UML profile and MOF makes up PIM and designs theorem of transformation through XMI.},
  keywords = {ROSE theorem;UML profile;Unified Modeling Language;XMI platform;XML metadata interchange;XML platform;mapping method;meta object facility;model driven architecture;model transformation;platform independent model;platform specific model;software development method;Unified Modeling Language;XML;meta data;object-oriented programming;software architecture;},
  volume = {2},
  booktitle = {International Workshop on Education Technology and Computer Science},
  month = mar,
  year = {2009}
}

@MISC{software:cmaptools,
  author = {{Institute for Human and Machine Cognition} (IHMC)},
  title = {CmapTools},
  howpublished = software,
  url = {http://cmap.ihmc.us/}
}

@MISC{law:brazil:resolution-cne-ces-1,
  author = brazil,
  title = {Resolução CNE/CES Nº. 1 de 2007},
  howpublished = resolution,
  month = jun,
  year = {2007},
  owner = {magsilva},
  timestamp = {2010.08.05}
}

@MISC{law:brazil:decree-5622,
  author = brazil,
  title = {Decreto nº. 5.622},
  howpublished = decree,
  month = dec,
  year = {2005},
  owner = {magsilva},
  timestamp = {2010.08.05}
}

@MISC{law:brazil:mec-ordinance-4059,
  author = brazil,
  title = {Portaria 4.059},
  howpublished = ordinance,
  month = dec,
  year = {2004},
  owner = {magsilva},
  timestamp = {2010.08.05}
}

@MISC{law:brazil:law-9394,
  author = Brazil,
  title = {Lei nº. 9.394 -- Lei de Diretrizes e Bases da Educação Nacional},
  howpublished = law,
  month = dec,
  year = {1996},
  owner = {magsilva},
  timestamp = {2010.08.05}
}

@MISC{software:conectiva,
  author = {Conectiva S. A.},
  title = {Conectiva Linux},
  howpublished = {Programa de Computador},
  month = oct,
  year = {1997},
  owner = {magsilva},
  timestamp = {2007.03.25}
}

@INPROCEEDINGS{AarreniemiJokipelto:2004,
  author = {Päivi Aarreniemi-Jokipelto},
  title = {Interactive Learning Environment in Digital {TV}: Results and Experiences},
  pages = {1602--1609},
  abstract = {The Industrial IT Laboratory (INIT) of Helsinki University of Technology (HUT) has conducted research in the use of digital TV as a learning environment for University courses since 2001. Digital TV has been used in learning to some extent but the use of Multimedia Home Platform (MHP) in the learning process is a genuinely novel approach. Starting in autumn 2002, HUT has made trials in an experimental environment, where students had the opportunity to study one module of the course "Local Demands for Global Enterprising" via digital TV. On January 12, 2004 a pilot group started with the Local Demands for Global Enterprising course over cable network Digital TV, which enables the entire learning process to be conducted via Digital TV. In this paper, we report the results of using of the MHP to accomplish an interactive learning environment in digital TV to respond to challenges for lifelong learning of engineering.},
  address = {Washington, DC, EUA},
  booktitle = {World Conference on E-Learning in Corporate, Government, Healthcare, and Higher Education},
  editor = {Janice Nall and Robby Robson},
  isbn = {1-880094-54-1},
  publisher = {AACE},
  url = {http://www.editlib.org/p/11485},
  year = {2004}
}

@PHDTHESIS{AarreniemiJokipelto:2006,
  author = {Paivi Aarreniemi-Jokipelto},
  title = {Modelling and content production of distance learning concept for interactive digital television},
  school = {Helsinki University of Technology},
  year = {2006},
  address = {Espoo, Finlândia},
  month = dec,
  isbn = {978-951-22-8541-9},
  issn = {1459-6458},
  note = Advisor # {: Juha Tuominen},
  pages = {200},
  publisher = {Otamedia Oy},
  timestamp = {2008.10.05}
}

@BOOK{Abiteboul-etal:1995,
  title = {Foundations of Databases},
  publisher = {Addison-Wesley},
  year = {1995},
  author = {Serge Abiteboul and Richard Hull and Victor Vianu},
  isbn = {0-201-53771-0},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@MISC{standard:abnt:15606-1:2007,
  author = {{ABNT}},
  title = {{ABNT} {NBR} 15606-1:2011 -- Televisão digital terrestre -- Codificação de dados e especificações de transmissão para radiofusão digital -- Parte 1: Codificação de dados},
  howpublished = standard,
  month = oct,
  year = {2011},
  abstract = {Esta parte da ABNT NBR 15606 especifica o modelo de referência que possibilita a difusão de dados que integra o sistema de difusão digital definido como sistema brasileiro de televisão digital (SBTVD), além das monomídias suportadas pelo sistema de difusão de dados e codificação do caption e caracteres sobrepostos.},
  isbn = {978-85-07-03072-0},
  lang = {pt},
  pages = {54},
  timestamp = {2008.10.10},
  title-en = {Digital terrestrial television -- Data coding and transmission specification for digital broadcasting -- Part 1: Data coding specification},
  url = {http://www.abntcolecao.com.br/norma.aspx?ID=88713}
}

@MISC{standard:abnt:15606-2:2011,
  author = {{ABNT}},
  title = {{ABNT} {NBR} 15606-2:2011 -- Televisão digital terrestre -- Codificação de dados e especificações de transmissão para radiofusão digital -- Parte 2: {Ginga-NCL} para receptores fixos e móveis -- Linguagem de aplicação {XML} para codificação de aplicações},
  howpublished = standard,
  month = may,
  year = {2011},
  abstract = {Esta parte da ABNT NBR 15606 especifica uma linguagem de aplicação XML denominda NCL (Nested Context Language), a linguagem declarativa do middleware Ginga, a codificação e a transmissão de dados para radiofusaõ digital.},
  address = {Rio de Janeiro, RJ, } # Brazil,
  isbn = {978-85-07-02783-6},
  lang = {pt},
  organization = {ABNT},
  pages = {299},
  title-en = {Digital terrestrial television - Data coding and transmission specification for digital broadcasting -- Part 2: {Ginga-NCL} for fixed and mobile receivers -- {XML} application language for application coding},
  url = {http://www.abntcolecao.com.br/norma.aspx?ID=87219}
}

@MISC{standard:abnt:15606-3:2010,
  author = {{ABNT}},
  title = {{ABNT} {NBR} 15606-3:2010 -- Televisão digital terrestre -- Codificação de dados e especificações de transmissão para radiofusão digital -- Parte 3: Especificação de transmisão de dados},
  howpublished = standard,
  month = nov,
  year = {2011},
  abstract = {Esta parte da ABNT NBR 15606 fornece uma especificação de codificação e transmissão de dados para o esquema de transmissão digital.},
  address = {Rio de Janeiro, RJ, Brazil},
  isbn = {978-85-07-02599-3},
  lang = {pt},
  pages = {83},
  title-en = {Digital terrestrial television - Data coding and transmission specification for digital broadcasting -- Part 2: {Ginga-NCL} for fixed and mobile receivers -- {XML} application language for application coding},
  url = {http://www.abntcolecao.com.br/norma.aspx?ID=86348}
}

@MISC{standard:abnt:15606-7:2011,
  author = {{ABNT}},
  title = {{ABNT} {NBR} 15606-7:2011 -- Televisão digital terrestre -- Codificação de dados e especificações de transmissão para radiofusão digital -- Parte 7: {Ginga-NCL} -- Diretrizes operacionais para as {ABNT}{NBR} 15606-2 e {ABNT} {NBR} 15606-5},
  howpublished = standard,
  month = mar,
  year = {2011},
  abstract = {Esta parte da ABNT NBR 15606 detalha e explica a especificação da linguagem de aplicação XML, denominada NCL (Nested Context Language), a linguagem declarativa do middleware Ginga, a codificação de dados e a transmissão de dados para radiodifusão digital, fornecendo as diretrizes operacionais para uma implementação de acordo com as ABNT NBR 15606-2 e ABNT NBR 15606-5.},
  address = {Rio de Janeiro, RJ, Brazil},
  isbn = {978-85-07-02685-3},
  lang = {pt},
  pages = {54},
  title-en = {Digital terrestrial television -- Data coding and transmission specification for digital broadcasting -- Part 7: Ginga-NCL: Operational guidelines to ABNT NBR 15606-2 and ABNT NBR 15606-5},
  url = {http://www.abntcolecao.com.br/norma.aspx?ID=86680}
}

@MISC{standard:abnt:15606-8:2011,
  author = {{ABNT}},
  title = {{ABNT} {NBR} 15606-8:2011 -- Televisão digital terrestre -- Codificação de dados e especificações de transmissão para radiodifusão digital -- Parte 8: {Ginga-J} -- Diretrizes operacionais para a {ABNT} {NBR} 15606-4},
  howpublished = standard,
  month = oct,
  year = {2011},
  abstract = {Esta parte da ABNT NBR 15606 detalha e explica os requisitos para a parte procedural do middleware para o sistema brasileiro de televisão digital terrestre (SBTVD), fornecendo as diretrizes operacionais para uma implementação de acordo com a ABNT NBR 15606-4.},
  address = {Rio de Janeiro, RJ, } # Brazil,
  isbn = {978-85-07-03056-0},
  lang = {pt},
  organization = {ABNT},
  pages = {47},
  title-en = {Digital terrestrial television - Data coding and transmission specification for digital broadcasting -- Part 8: Ginga-J - Operations guidleines for the ABNT NBR 15606-4},
  url = {http://www.abntcolecao.com.br/norma.aspx?ID=88638}
}

@MISC{standard:abnt:15606-9:2011,
  author = {{ABNT}},
  title = {{ABNT} {NBR} 15606-9:2011 -- Televisão digital terrestre -- Codificação de dados e especificações de transmissão para radiodifusão digital -- Parte 9: Diretrizes operacionais para a {ABNT} {NBR} 15606-1},
  howpublished = standard,
  month = dez,
  year = {2011},
  abstract = {Esta parte da ABNT NBR 15606 detalha e explica os requisitos para a parte procedural do middleware para o sistema brasileiro de televisão digital terrestre (SBTVD), fornecendo as diretrizes operacionais para uma implementação de acordo com a ABNT NBR 15606-4.},
  address = {Rio de Janeiro, RJ, Brazil},
  isbn = {978-85-07-03193-2},
  lang = {pt},
  pages = {8},
  title-en = {Digital terrestrial television -- Data coding and transmission specifi cation for digital broadcasting -- Part 9: Operations guidleines for the ABNT NBR 15606-1},
  url = {http://www.abntcolecao.com.br/norma.aspx?ID=89872}
}

@MISC{standard:abnt:15607-1:2011,
  author = {{ABNT}},
  title = {{ABNT} {NBR} 15607-1:2011 -- Televisão digital terrestre -- Canal de interatividade -- Parte 1: Protocolos, interfaces físicas e interfaces de software},
  howpublished = standard,
  month = jul,
  year = {2011},
  abstract = {Esta parte da ABNT NBR 15607 descreve os protocolos, interfaces físicas e interfaces de software para tecnologias de comunicações específicas a serem empregadas para o canal de interatividade do sistema brasileiro de televisão digital terrestre (SBTVD).},
  address = {Rio de Janeiro, RJ, Brazil},
  isbn = {978-85-07-02872-7},
  lang = {pt},
  pages = {20},
  title-en = {Digital terrestrial television -- Interactive channel -- Part 1: Protocols, physical interfaces and software interfaces},
  url = {http://www.abntcolecao.com.br/norma.aspx?ID=87512}
}

@MISC{standard:abnt:15608-3:2011,
  author = {{ABNT}},
  title = {{ABNT} {NBR} 15608-3:2011 -- Televisão digital terrestre -- Guia de operação -- Parte 3: Multiplexação e serviço de informação ({SI}) - Guia para implementação da {ABNT} {NBR} 15603:2007},
  howpublished = standard,
  month = jan,
  year = {2011},
  abstract = {Esta parte da ABNT NBR 15608 consiste em um guia para a implementação da ABNT NBR 15603 e contém informações adicionais referentes à operação das informações de serviço que compõem o sistema brasileiro de televisão digital terrestre (SBTVD).},
  address = {Rio de Janeiro, RJ, Brazil},
  isbn = {978-85-07-02583-2},
  lang = {pt},
  pages = {86},
  title-en = {Digital terrestrial television -- Operational guideline -- Part 3: Mulitplexing and service information (SI) - Guideline for ABNT NBR 15603:2007 implementation},
  url = {http://www.abntcolecao.com.br/norma.aspx?ID=86284}
}

@MISC{standard:abnt:15610-1:2011,
  author = {{ABNT}},
  title = {{ABNT} {NBR} 15610-1:2011 -- Televisão digital terrestre -- Acessibilidade -- Parte 1: Ferramentas de texto},
  howpublished = standard,
  month = dez,
  year = {2011},
  abstract = {Esta parte da ABNT NBR 15610 complementa as especificações para as ferramentas de acessibilidade closed caption e legendas do sistema brasileiro de televisão digital terrestre, além de prover orientações para sua implementação.},
  address = {Rio de Janeiro, RJ, Brazil},
  isbn = {978-85-07-02583-2},
  lang = {pt},
  pages = {86},
  title-en = {Digital terrestrial television -- Acessibility -- Part 1: Text tools},
  url = {http://www.abntcolecao.com.br/norma.aspx?ID=89588}
}

@MISC{standard:abnt:15606-4:2010,
  author = {{ABNT}},
  title = {{ABNT} {NBR} 15606-4:2010 -- Televisão digital terrestre -- Codificação de dados e especificações de transmissão para radiodifusão digital -- Parte 4: {Ginga-J} -- Ambiente para a execução de aplicações procedurais},
  howpublished = standard,
  month = apr,
  year = {2010},
  abstract = {Esta parte da ABNT NBR 15606 especifica os requisitos para a parte procedural do middleware para o sistema brasileiro de televisão digital terrestre (SBTVD).},
  address = {Rio de Janeiro, RJ, } # Brazil,
  isbn = {978-85-07-02022-6},
  lang = {pt},
  organization = {ABNT},
  pages = {91},
  title-en = {Digital terrestrial television - Data coding and transmission specification for digital broadcasting -- Part 2: {Ginga-NCL} for fixed and mobile receivers -- {XML} application language for application coding},
  url = {http://www.abntcolecao.com.br/norma.aspx?ID=58131}
}

@MISC{standard:abnt:15606-5:2011,
  author = {{ABNT}},
  title = {{ABNT} {NBR} 15606-5:2011 -- Televisão digital terrestre -- Codificação de dados e especificações de transmissão para radiodifusão digital -- Parte 5: {Ginga-NCL} para receptores portáteis -- Linguagem de aplicação {XML} para codificação de aplicações},
  howpublished = standard,
  month = apr,
  year = {2010},
  abstract = {Esta parte da ABNT NBR 15606 especifica a linguagem de aplicação XML, denominada NCL (Nested context linguage), a linguagem declarativa do middlewere Ginga, a codificação e a transmissão de dados para radiodifusão digital.},
  address = {Rio de Janeiro, RJ, Brazil},
  isbn = {978-85-07-02743-0},
  lang = {pt},
  pages = {119},
  title-en = {Digital terrestrial television - Data coding and transmission specification for digital broadcasting -- Part 5: Ginga-NCL for portable receivers - XML application language for application coding},
  url = {http://www.abntcolecao.com.br/norma.aspx?ID=86957}
}

@MISC{standard:abnt:15606-6:2010,
  author = {{ABNT}},
  title = {{ABNT} {NBR} 15606-6:2011 -- Televisão digital terrestre -- Codificação de dados e especificações de transmissão para radiodifusão digital -- Parte 6: Java DTV 1.3},
  howpublished = standard,
  month = jul,
  year = {2010},
  abstract = {Esta parte da ABNT NBR 15606 especifica os requerimentos do núcleo que serve de base para a parte procedural do middleware para o sistema brasileiro de televisão digital terrestre (SBTVD).},
  address = {Rio de Janeiro, RJ, } # Brazil,
  isbn = {978-85-07-02188-9},
  lang = {pt},
  organization = {ABNT},
  pages = {860},
  title-en = {Digital terrestrial television - Data coding and transmission specification for digital broadcasting -- Part 5: Ginga-NCL for portable receivers - XML application language for application coding},
  url = {http://www.abntcolecao.com.br/norma.aspx?ID=62080}
}

@MISC{standard:abnt:15608-2:2010,
  author = {{ABNT}},
  title = {{ABNT} {NBR} 15608-2:2010 -- Televisão digital terrestre -- Guia de operação -- Parte 2: Codificação de vídeo, audio e multiplexação - Guia para implementação da {ABNT} {NBR} 15602:2007},
  howpublished = standard,
  month = may,
  year = {2010},
  abstract = {Esta parte da ABNT NBR 15608 consiste em um guia para a implementação da ABNT NBR 15602 e contém informações adicionais dos parâmentros de codificação para os sinais de aúdio e vídeo para o sistema brasileiro de televisão digital terrestre (SBTVD).},
  address = {Rio de Janeiro, RJ, Brazil},
  isbn = {978-85-07-02083-7},
  lang = {pt},
  pages = {28},
  title-en = {Digital terrestrial television -- Operational guideline -- Part 2: Video coding, audio coding and multiplexing -- Guideline for ABNT NBR 15602:2007 implementation},
  url = {http://www.abntcolecao.com.br/norma.aspx?ID=58581}
}

@MISC{standard:abnt:15603-2:2009,
  author = {{ABNT}},
  title = {{ABNT} {NBR} 15603-2:2007 Versão Corrigida 3:2009 -- Televisão digital terrestre -- Multiplexação e serviços de informação ({SI}) -- Parte 2: Estrutura de dados e definições da informação básica de {SI}},
  howpublished = standard,
  month = sep,
  year = {2009},
  abstract = {Esta parte da ABNT NBR 15603 especifica as tabelas básicas de informação de serviço, conhecidas por tabelas SI, para os sinais de radiofusão que fazem parte da transmissão de dados do sistema brasileiro de televisão digital terrestre (SBTVD).},
  address = {Rio de Janeiro, RJ, Brazil},
  isbn = {978-85-07-00577-3},
  lang = {pt},
  pages = {40},
  title-en = {Digital terrestrial television -- Multiplexing and service information (SI) -- Part 2: Data structure and definition of basic information of SI},
  url = {http://www.abntcolecao.com.br/norma.aspx?ID=51877}
}

@MISC{standard:abnt:15603-3:2009,
  author = {{ABNT}},
  title = {{ABNT} {NBR} 15603-3:2007 Versão Corrigida 3:2009 -- Televisão digital terrestre - Multiplexação e serviços de informação ({SI}) -- Parte 3: Sintaxes e definições de informação estendida do {SI}},
  howpublished = standard,
  month = sep,
  year = {2009},
  abstract = {Esta parte da ABNT NBR 15603 especifica em detalhes a estrutura para a cosntrução das informações básicas relacionadas ao SI que fazem parte do sistema brasileiro de televisão digital terrestre (SBTV).},
  address = {Rio de Janeiro, RJ, Brazil},
  isbn = {978-85-07-00602-2},
  lang = {pt},
  pages = {53},
  title-en = {Digital terrestrial televisison -- Multiplexing and services information (SI) -- Part 3: Syntaxes and definitions of estension information of SI},
  url = {http://www.abntcolecao.com.br/norma.aspx?ID=51580}
}

@MISC{standard:abnt:15601-1:2008,
  author = {{ABNT}},
  title = {{ABNT} {NBR} 15601:2007 Versão Corrigida:2008 -- Televisão digital terrestre - Sistema de transmissão},
  howpublished = standard,
  month = apr,
  year = {2008},
  abstract = {Esta Norma especifica o sistema de transmissão do sistema brasileiro de televisão digital terrestre (SBTVD), compreendendo o sistema de codificação de canal e modulação, e descrevendo o processamento de sinal no modulador e os processos de demodulação na recepção.},
  address = {Rio de Janeiro, RJ, } # Brazil,
  isbn = {978-85-07-00539-1},
  lang = {pt},
  organization = {ABNT},
  pages = {57},
  title-en = {Digital terrestrial television - Transmission system},
  url = {http://www.abntcolecao.com.br/norma.aspx?ID=1606}
}

@MISC{standard:abnt:15602-1:2008,
  author = {{ABNT}},
  title = {{ABNT} {NBR} 15602-1:2007 Versão Corrigida:2008 -- Televisão digital terrestre -- Codificação de áudio, vídeo e multiplexação -- Parte 1: codificação de vídeo},
  howpublished = standard,
  month = apr,
  year = {2008},
  abstract = {Esta parte da ANBT NBR 15602 especifica a codificação de vídeo em alta definição, resolução-padrão e resolução reduzida, incluindo os parâmetros para os sinais na entrada do codificador e as restrições ao processo de codificação aplicáveis ao sistema brasileiro de televisão digital terrestre (SBTVD).},
  address = {Rio de Janeiro, RJ, } # Brazil,
  isbn = {978-85-07-00540-7},
  lang = {pt},
  organization = {ABNT},
  pages = {38},
  revision = {2008},
  title-en = {ABNT NBR 15602-1:2007 Corr:2008 -- Digital terrestrial television -- Video coding, audio coding and multiplexing -- Part 1: Video coding},
  url = {http://www.abntcolecao.com.br/norma.aspx?ID=1607}
}

@MISC{standard:abnt:15602-2:2008,
  author = {{ABNT}},
  title = {{ABNT} {NBR} 15602-2:2007 Versão Corrigida:2008 -- Televisão digital terrestre -- Codificação de vídeo, áudio e multiplexação -- Parte 2: Codificação de áudio},
  howpublished = standard,
  month = apr,
  year = {2008},
  abstract = {Esta parte da ABNT NBR 15602 especifica os parâmetros para os sinais de áudio e o sistema de codificação e decodificação de som a ser utilizado no sistema brasileiro de televisão digital terrestre (SBTVD).},
  address = {Rio de Janeiro, RJ, Brazil},
  isbn = {978-85-07-00560-5},
  lang = {pt},
  pages = {12},
  title-en = {Digital terrestrial television -- Video coding, audio coding and multiplexing -- Part 1: Audio coding},
  url = {http://www.abntcolecao.com.br/norma.aspx?ID=1612}
}

@MISC{standard:abnt:15602-3:2008,
  author = {{ABNT}},
  title = {{ABNT} {NBR} 15602-3:2007 Versão Corrigida:2008 -- Televisão digital terrestre -- Codificação de vídeo, áudio e multiplexação -- Parte 3: Sistemas de multiplexação de sinais},
  howpublished = standard,
  month = apr,
  year = {2008},
  abstract = {Esta parte da ABNT NBR 15602 especifica a multiplexação de sinais para radiofusão digital (áudio, vídeo e dados) dos mecanismos de transporte e da estrutura de dados aplicáveis aos sistema brasileiro de televisão digital terrestre (SBTVD).},
  address = {Rio de Janeiro, RJ, } # Brazil,
  isbn = {978-85-07-00576-6},
  lang = {pt},
  organization = {ABNT},
  pages = {17},
  title-en = {Digital terrestrial television -- Video coding, audio coding and multiplexing -- Part 3: Signal multiplexing systems},
  url = {http://www.abntcolecao.com.br/norma.aspx?ID=1617}
}

@MISC{standard:abnt:15603-1:2008,
  author = {{ABNT}},
  title = {{ABNT} {NBR} 15603-1:2007 Versão Corrigida 2:2008 -- Televisão digital terrestre -- Multiplexação e serviços de informação ({SI}) -- Parte 1: {SI} do sistema de radiofusão},
  howpublished = standard,
  month = aug,
  year = {2008},
  abstract = {Esta parte ABNT NBR 15603 especifica as tabelas de serviços de informação, conhecidas por tabelas SI, para os sinais de radiofusão que fazem parte da transmissão de dados do sistema brasileiro de televisão digital terrestre.},
  address = {Rio de Janeiro, RJ, Brazil},
  isbn = {978-85-07-00577-3},
  lang = {pt},
  pages = {40},
  title-en = {Digital terrestrial television -- Multiplexing and service information (SI) -- Part 1: SI for digital broadcasting systems},
  url = {http://www.abntcolecao.com.br/norma.aspx?ID=1172}
}

@MISC{standard:abnt:15604-1:2008,
  author = {{ABNT}},
  title = {{ABNT} {NBR} 15604:2007 Versão Corrigida:2008 -- Televisão digital terrestre -- Receptores},
  howpublished = standard,
  month = apr,
  year = {2008},
  abstract = {Esta Norma especifica o conjunto de funcionalidades essenciais requeridas dos dispositivos de recepção de televisão digital de 13 segmentos (full-seg), assim como os de um segmento (one-seg), destinados à receber sinais na modalidade fixa, móvel e portátil.},
  address = {Rio de Janeiro, RJ, Brazil},
  isbn = {978-85-07-00578-0},
  lang = {pt},
  pages = {68},
  title-en = {Digital terrestrial television - Receivers},
  url = {http://www.abntcolecao.com.br/norma.aspx?ID=1316}
}

@MISC{standard:abnt:15605-1:2009,
  author = {{ABNT}},
  title = {{ABNT} {NBR} 15605-1:2008 Versão Corrigida:2009 -- Televisão digital terrestre -- Tópicos de Segurança -- Parte 1: Controle de cópias},
  howpublished = standard,
  month = jul,
  year = {2008},
  abstract = {Esta parte da ABNT NBR 15605 estabelece os mecanismos e regras para o controle de cópias utilizando ferramentas internacionais de proteção aplicadas às saídas de vídeo, áudio e dados receptores do sitemas de televisão digital terrestre (SBTVD).},
  address = {Rio de Janeiro, RJ, Brazil},
  isbn = {978-85-07-01041-8},
  lang = {pt},
  pages = {18},
  title-en = {Digital terrestrial television -- Security issues -- Part 1: Copy control},
  url = {http://www.abntcolecao.com.br/norma.aspx?ID=51172}
}

@MISC{standard:abnt:15608-1:2008,
  author = {{ABNT}},
  title = {{ABNT} {NBR} 15608-1:2008 -- Televisão digital terrestre -- Guia de operação -- Parte 1: Sistema de transmissão - Guia para implementação da {ABNT} {NBR} 15601:2007},
  howpublished = standard,
  month = aug,
  year = {2008},
  abstract = {Esta parte da ABNT NBR 15608 consiste em um guia para a implementação da ABNT NBR 15601 e contém informações adicionais do sistema de codificação de canal e modulação e da sincronização das redes de radiofusão que empregam do sistema brasileiro de televisão digital terrestre (SBTVD).},
  address = {Rio de Janeiro, RJ, Brazil},
  isbn = {978-85-07-00924-4},
  lang = {pt},
  pages = {64},
  title-en = {Digital terrestrial television -- Operational guideline -- Part 1: Transmission system -- Guideline for ABNT NBR 15601:2007 implementation},
  url = {http://www.abntcolecao.com.br/norma.aspx?ID=1160}
}

@ARTICLE{abowd:1999,
  author = {G. D. Abowd},
  title = {{Classroom 2000}: An Experiment with the Instrumentation of a Living Educational Environment},
  volume = {38},
  number = {4},
  month = oct,
  year = {1999},
  pages = {508--530},
  journal = {IBM Systems Journal},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@INPROCEEDINGS{abowd-etal:1998:chi:2,
  author = {G. D. Abowd and C. G. Atkeson and J. A. Brotherton and T. Enqvist and P. Gully and J. Lemon},
  title = {Investigating the Capture, Integration and Access Problem of Ubiquitous Computing in an Educational Setting},
  pages = {440--447},
  address = {New York, USA},
  booktitle = {CHI 98},
  month = apr,
  owner = {magsilva},
  timestamp = {2008.07.30},
  year = {1998}
}

@INPROCEEDINGS{abowd-etal:1998:chi,
  author = {G. D. Abowd and C. G. Atkeson and J. Brotherton and T. Enqvist and P. Gully and J. Lemon},
  title = {{Classroom 2000}: A System for Capturing and Accessing Multimedia Classroom Experiences},
  address = {New York, USA},
  booktitle = {CHI 98},
  month = apr,
  owner = {magsilva},
  timestamp = {2008.07.30},
  year = {1998}
}

@INPROCEEDINGS{abowd-etal:1996,
  author = {G. D. Abowd and C. G. Atkeson and A. Feinstein and C. Hmelo and R. Kooper and S. Long and N. Sawhney and M. Tani},
  title = {Teaching and Learning as Multimedia Authoring: The {Classroom 2000} Project},
  pages = {187--198},
  booktitle = {Fourth ACM International Multimedia Conference (Multimedia 96)},
  month = nov,
  owner = {magsilva},
  timestamp = {2008.07.30},
  year = {1996}
}

@INPROCEEDINGS{Abowd-Beale:1991,
  author = {Gregory D. Abowd and Russel Beale},
  title = {Users, systems and interfaces: a unifying framework for interaction},
  pages = {73-87},
  abstract = {We introduce a basic framework for the analysis of existing interactive systems which wll aslo serve for the principled design of more usable systems. We present a simple yet effective model of an interactive system that extends previous interaction frameworks. Within our framework, the user, system and interface are all represented equally. We also present several notions of distance as qualitative measurements of the interactive features of a system based on specific tasks. These notions of distance can be formalised to give an understandable quantitative approach required for principled design and analysis.},
  keywords = {framework, analysis and design, formal methods},
  volume = {3},
  booktitle = {HCI91 People and Computers},
  isbn = {0521416949},
  publisher = {Cambridge University},
  year = {1991}
}

@INPROCEEDINGS{abowd-etal:1999:cscl,
  author = {G. D. Abowd and M. G. C. Pimentel and B. Kerimbaev and Y. Ishiguro and M. Guzdial},
  title = {Anchoring Discussions in Lecture: An Approach to Collaboratively Extending Classroom Digital Media},
  pages = {11--19},
  booktitle = {Computer Supported Collaborative Learning},
  month = dec,
  owner = {magsilva},
  timestamp = {2008.07.30},
  year = {1999}
}

@ARTICLE{Abran-etal:2003,
  author = {Alain Abran and Adel Khelifi and Witold Suryn and Ahmed Seffah},
  title = {Usability Meanings and Interpretations in {ISO} Standards},
  volume = {11},
  number = {4},
  year = {2003},
  pages = {325-338},
  doi = {10.1023/A:1025869312943},
  journal = {Software Quality Control},
  owner = {magsilva},
  timestamp = {2006.08.22}
}

@INPROCEEDINGS{Sampaio-Barbosa:2011,
  author = {Tales Borges de Abreu Sampaio and Ellen Francine Barbosa},
  title = {Estudo e Construção de Objetos de Aprendizado como Apoio ao Ensino de Matemática},
  pages = {1-1},
  address = {São Carlos, SP, } # Brazil,
  booktitle = {Simpósio Internacional de Iniciação Científica Universidade de São Paulo},
  location = {São Carlos, SP, #Brazil#},
  month = nov,
  title-en = {Study and Construction of Learning Objects to Support the Teaching of Mathematics},
  url = {https://sistemas.usp.br/siicusp/cdOnlineTrabalhoObter?numeroInscricaoTrabalho=3504&numeroEdicao=19&print=S},
  year = {2011}
}

@ARTICLE{achour:2005,
  author = {Mehdi Achour and Friedhelm Betz and Antony Dovgal and Nuno Lopes and Philip Olson and Georg Richter and Damien Seguy and Jakub Vrana},
  title = {PHP Manual: Using Register Globals},
  year = {2005},
  url = {http://www.php.net/register\_globals},
  comment = {16/06/2005},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@MISC{acm:1998,
  author = {{ACM}},
  title = {ACM Computing Classification System},
  year = {1998},
  owner = {magsilva},
  timestamp = {2006.12.10}
}

@TECHREPORT{acm-ieee:cs2013,
  author = {{ACM} and {IEEE-CS}},
  title = {Computer Science Curricula 2013},
  institution = {ACM Press and IEEE Computer Society Press},
  month = dec,
  year = {2013},
  doi = {10.1145/2534860}
}

@PHDTHESIS{Acree80MUTA,
  author = {A. T. Acree},
  title = {On Mutation},
  school = {Georgia Institute of Technology},
  year = {1980},
  address = {Atlanta, GA},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@TECHREPORT{Acree79MANA,
  author = {A. T. Acree and T. A. Budd and R. A. DeMillo and R. J. Lipton and F. G. Sayward},
  title = {Mutation Analysis},
  institution = {Georgia Institute of Technology, Atlanta, GA},
  month = sep,
  year = {1979},
  number = {GIT-ICS-79/08},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{Adar:2006,
  author = {Eytan Adar},
  title = {{GUESS}: A Language and Interface for Graph Exploration},
  pages = {791--800},
  doi = {10.1145/1124772.1124889},
  abstract = {As graph models are applied to more widely varying fields, researchers struggle with tools for exploring and analyzing these structures. We describe GUESS, a novel system for graph exploration that combines an interpreted language with a graphical front end that allows researchers to rapidly prototype and deploy new visualizations. GUESS also contains a novel, interactive interpreter that connects the language and interface in a way that facilities exploratory visualization tasks. Our language, Gython, is a domain-specific embedded language which provides all the advantages of Python with new, graph specific operators, primitives, and shortcuts. We highlight key aspects of the system in the context of a large user survey and specific, real-world, case studies ranging from social and knowledge networks to distributed computer network analysis.},
  keywords = {domain-specific embedded language, graph layout, graph visualization},
  series = {CHI '06},
  address = {New York, NY, USA},
  booktitle = {SIGCHI Conference on Human Factors in Computing Systems},
  isbn = {1-59593-372-7},
  location = {Montreal, Quebec, Canada},
  numpages = {10},
  publisher = {ACM},
  url = {http://graphexploration.cond.org/},
  year = {2006}
}

@MISC{standard:adl:scorm,
  author = {{ADL}},
  title = {SCORM 2004},
  howpublished = {Padrão},
  month = aug,
  year = {2009},
  timestamp = {2008.09.22},
  url = {http://www.adlnet.gov/scorm/},
  urlaccessdate = {20 fev 2012}
}

@MISC{standard:adl:scorm:cam,
  author = {{ADL}},
  title = {SCORM Content Aggregation Model (CAM)},
  howpublished = {Padrão},
  month = aug,
  year = {2009},
  note = {4ed, versão 1.1},
  lang = {en},
  timestamp = {2008.09.22},
  url = {http://www.adlnet.gov/scorm/}
}

@MISC{standard:adl:scorm:rte,
  author = {{ADL}},
  title = {SCORM Runtime Environment (RTE)},
  howpublished = {Padrão},
  month = aug,
  year = {2009},
  note = {4ed, versão 1.1},
  timestamp = {2008.09.27}
}

@MISC{project:tincan,
  author = {{ADL} and {AICC}},
  title = {Project Tin Can},
  howpublished = {Projeto de Pesquisa},
  month = jan,
  year = {2011},
  url = {http://scorm.com/tincan/}
}

@MISC{standard:w3c:xslt:2001,
  author = {Sharon Adler and Anders Berglund and Jeff Caruso and Stephen Deach and Tony Graham and Paul Grosso and Eduardo Gutentag and Alex Milowski and Scott Parnell and Jeremy Richman and Steve Zille},
  title = {Extensible Stylesheet Language (XSL)},
  howpublished = {W3C Recommendation},
  month = oct,
  year = {2001},
  comment = {24/05/2005},
  file = {Extensible Stylesheet Language (XSLT) 1.0.pdf:Extensible Stylesheet Language (XSLT) 1.0.pdf:PDF},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://www.w3.org/TR/xsl/}
}

@MISC{software:acrobat,
  author = {{Adobe Systems}},
  title = {Adobe Acrobat},
  howpublished = software,
  month = jun,
  year = {1993},
  url = {http://www.adobe.com/products/acrobat}
}

@MISC{standard:iso:32000:level3,
  author = {{Adobe Systems Incorporated}},
  title = {Adobe Supplement to the ISO 32000, Base Version 1.7, Extension Level 3},
  howpublished = {{Specification}},
  month = jun,
  year = {2009},
  url = {http://www.adobe.com/content/dam/Adobe/en/devnet/pdf/pdfs/adobe_supplement_iso32000.pdf}
}

@INPROCEEDINGS{Adriano99ICPC,
  author = {C. M. Adriano and A. L. N. Delgado and L. G. {Silveira Jr.} and R. C. Bosnardo and I. L. M. Ricarte and L. P. Magalhães},
  title = {Inquiring the Course Paradigm with {CALM}},
  address = {Rio de Janeiro, RJ},
  booktitle = {International Conference on Engineering and Computer Education (ICECE 99)},
  month = ago,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1999}
}

@MISC{standard:enhancedcontent,
  author = {{Advanced Television Enhancement Forum (ATVEF)}},
  title = {Enhanced Content Specification (ATVEF 1.1r26)},
  month = feb,
  year = {1999},
  timestamp = {2008.09.30},
  url = {http://www.atvef.com/library/spec1_1a.html}
}

@MISC{standard:atscA101,
  author = {{Advanced Television Systems Committee}},
  title = {Advanced Common Application Platform - ACAP (A/101)},
  howpublished = {Padrão},
  year = {2005},
  timestamp = {2008.10.07}
}

@MISC{standard:atscA100,
  author = {{Advanced Television Systems Committee}},
  title = {DTV Application Software Environment - Level 1 (DASE-1)},
  howpublished = {Padrão},
  year = {2003},
  timestamp = {2008.10.07}
}

@BOOK{Aebil:1982,
  title = {Práticas de ensino: Formas fundamentais de ensino elementar, médio e superior},
  publisher = {EPU (Editora Pedagógica e Universitária)},
  year = {1982},
  author = {Hans Aebil},
  isbn = {85-12-30250-x},
  pages = {387},
  address = {São Paulo, SP, Brasil},
  edition = {11},
  note = {Traduzido do original ``Grundformen des Lehrens'' por Edwino Aluysius Royer.},
  booktitle = {Práticas de ensino: Formas fundamentais de ensino elementar, médio e superior}
}

@MISC{Agarwal-Israni:2013,
  author = {Ayna Agarwal and Ellbora Israni},
  title = {{she++}: The Documentary -- Good Girl gone Geek},
  howpublished = {Documentário},
  year = {2013},
  timestamp = {2013-11-06},
  url = {http://sheplusplus.stanford.edu/film/}
}

@ARTICLE{RAS04IAE,
  author = {Rakesh Agarwal and Amrita Deo and Swati Das},
  title = {Intelligent agents in E-learning},
  volume = {29},
  number = {2},
  year = {2004},
  pages = {1--1},
  doi = {10.1145/979743.979755},
  address = {New York, NY, USA},
  issn = {0163-5948},
  journal = {SIGSOFT Softw. Eng. Notes},
  owner = {magsilva},
  publisher = {ACM},
  timestamp = {2008.07.30}
}

@MISC{anatel:2001,
  author = {{Agência Nacional de Telecomunicações}},
  title = {Relatório Integrador dos Aspectos Técnicos e Mercadológicos da TV Digital},
  howpublished = {Relatório},
  year = {2001},
  note = {Acesso em 28 de julho de 2003.},
  timestamp = {2008.10.07},
  url = {http://www.anatel.gov.br/acontece_anatel/Consulta/2001/consulta_291/Relatorio_Integrador.exe}
}

@INPROCEEDINGS{agrawal:1994,
  author = {Hira Agrawal},
  title = {Dominators, Super Blocks, and Program Coverage},
  pages = {25-34},
  abstract = {In this paper we present techniques to find subsets of nodes of a owgraph that satisfy the following property: A test set that exercises all nodes in a subset exercises all nodes in the owgraph. Analogous techniques to find subsets of edges are also proposed. These techniques may be used to significantly reduce the cost of coverage testing of programs. A notion of a super block consisting of one or more basic blocks is developed. If any basic block in a super block is exercised by an input then all basic blocks in that super block must be exercised by the same input. Dominator relationships among super blocks are used to identify a subset of the super blocks whose coverage implies that of all super blocks and, in turn, that of all basic blocks. Experiments with eight systems in the range of 1-75K lines of code show that, on the average, test cases targeted to cover just 29% of the basic blocks and 32% of the branches ensure 100% block and branch coverage, respectively.},
  address = {Portland, Oregon},
  booktitle = {The Conference Record of the 21st Annual ACM Symposium on Principles of Programming Languages (POPL'94)},
  month = jan,
  owner = {magsilva},
  timestamp = {2009.11.05},
  year = {1994}
}

@ARTICLE{Agrawal98MSTA,
  author = {H. Agrawal and J. Alberi and J. R. Horgan and J. Li and S. London and W. E. Wong and S. Ghosh and N. Wilde},
  title = {Mining System Tests to Aid Software Maintenance},
  month = jul,
  year = {1998},
  pages = {64--73},
  journal = ieeec,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@TECHREPORT{agrawal-etal:1989,
  author = {Hiralal Agrawal and Richard A. DeMillo and Bob Hathaway and William Hsu and Wynne Hsu and E. W. Krauser and R. J. Martin and Aditya P. Mathur and Eugene Spafford},
  title = {Design of Mutant Operators for the {C} Programming Language},
  institution = {Software Engineering Research Center, Purdue University},
  month = mar,
  year = {1989},
  number = {SERC-TR41-P},
  address = {West Lafayette, IN, } # USA,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{agrawal-horgan:1990,
  author = {Agrawal, Hiralal and Horgan, Joseph R.},
  title = {Dynamic program slicing},
  pages = {246--256},
  doi = {10.1145/93542.93576},
  address = {New York, NY, USA},
  booktitle = {ACM SIGPLAN 1990 Conference on Programming Language Design and Implementation},
  isbn = {0-89791-364-7},
  location = {White Plains, New York, United States},
  publisher = {ACM},
  year = {1990}
}

@BOOK{Ahem-etal:2001,
  title = {CMMI Distilled: A Practical Introduction to Integrated Process Improvement},
  publisher = {Addison-Wesley},
  year = {2001},
  author = {D. M. Ahem and R. Turner and A. Clouse},
  isbn = {978-0321186133},
  pages = {336},
  address = {EUA},
  month = jun,
  owner = {magsilva},
  timestamp = {2008.01.21}
}

@BOOK{Aho86CPTT,
  title = {Compilers: Principles, Techniques and Tools},
  publisher = {Addison Wesley},
  year = {1996},
  author = {A. V. Aho and R. Sethi and J. D. Ullman},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@MISC{standard:aicc:cmi001,
  author = {{AICC}},
  title = {{CMI} Guidelines for Interoperability},
  howpublished = {Standard},
  month = aug,
  year = {2004},
  lang = {en},
  url = {http://www.aicc.org/docs/tech/cmi001v4.pdf},
  urlaccessdate = {20 fev 2012}
}

@MISC{standard:aicc,
  author = {{AICC}},
  title = {{AICC/CMI} Compliance -- Web-Based Computer-Managed Instruction},
  howpublished = {Padrão},
  month = sep,
  year = {1998},
  url = {http://www.aicc.org/docs/AGRs/agr010v1.pdf},
  urlaccessdate = {20 fev 2012}
}

@MISC{standard:aicc:agr006,
  author = {{AICC}},
  title = {Computer-Managed Instruction},
  howpublished = {Standard},
  month = may,
  year = {1998},
  url = {http://www.aicc.org/docs/AGRs/agr006v2doc.zip},
  urlaccessdate = {20 fev 2012}
}

@ARTICLE{aiken-etal:2005,
  author = {Aiken, Robert M. and Bessagnet, Marie-Noelle and Israel, Judith},
  title = {Interaction and Collaboration Using an Intelligent Collaborative Learning Environment},
  volume = {10},
  number = {1-2},
  year = {2005},
  pages = {67--82},
  doi = {10.1007/s10639-005-6748-3},
  address = {Hingham, MA, USA},
  issn = {1360-2357},
  journal = {Education and Information Technologies},
  publisher = {Kluwer Academic Publishers}
}

@MISC{software:x264,
  author = {Laurent Aimar and Loren Merritt and Eric Petit and Min Chen and Justin Clay and Måns Rullgård and Radek Czyz and Christian Heine and Alex Izvorski and Alex Wright and Jason Garrett-Glaser and others},
  title = {{x264}},
  howpublished = software,
  year = {2004},
  abstract = {x264 is a free software library and application for encoding video streams into the H.264/MPEG-4 AVC format.},
  url = {http://www.videolan.org/developers/x264.html}
}

@ARTICLE{Ainsworth-etal:2008a,
  author = {Ainsworth, A. Barbara and Sheard, Judithe and Avram, Chris},
  title = {The {Monash} Museum of Computing History: part 1},
  volume = {40},
  number = {2},
  month = jun,
  year = {2008},
  pages = {31--34},
  doi = {10.1145/1383602.1383629},
  abstract = {The Monash Museum of Computing History, Monash University preserves the artifacts and the experiences of fifty years of computing education and research at one of Australia's top ten universities. In this first part of a two part paper, we describe the purpose, the development and the planned future for the museum. In Part Two, we will describe the collection and current display.},
  keywords = {Monash University, computer history, computer museum, ferranti sirius}
}

@BOOK{Albertin:2010,
  title = {Comércio eletrônico: modelo, aspectos e contribuiçãoes de sua aplicação},
  publisher = {Atlas},
  year = {2010},
  author = {Alberto Luiz Albertin},
  isbn = {978-85-224-5685-7},
  pages = {306},
  address = {São Paulo, SP, } # Brazil,
  edition = {6}
}

@TECHREPORT{Albright:2005,
  author = {Paul Albright},
  title = {Open Educational Resources Final Forum Report},
  institution = {UNESCO},
  month = dec,
  year = {2005},
  address = {Paris, França},
  url = {http://www.unesco.org/iiep/virtualuniversity/media/forum/oer_forum_final_report.pdf},
  note = {Internet Discussion Forum: Open Educational Resources - Open Content for Higher Education},
  organization = {{UNESCO}},
  timestamp = {2008.08.05},
  urlaccessdate = {20 fev 2012}
}

@PHDTHESIS{Alencar:2013,
  author = {Aretha Barbosa Alencar},
  title = {Visualization of the temporal evolution of scientific articles colletions},
  abstract = {Scientific articles are the major mechanism used by researchers to report their scientific results, and a collection of articles in a research area can reveal a lot about its evolution over time, such as the emergence of new topics and changes in topic vocabulary. However, given a broad collection of articles it is usually very difficult to extract important information that can help readers to globally interpret, navigate and then eventually focus on subjects relevant to their task. Document maps based on content are visual representations created to convey the similarity between documents, and have proven to be useful in helping users conducting exploratory tasks in this scenario. Documents are represented by graphical markers projected onto a two-dimensional space so that documents similar in content remain close. Although these maps allow visual identification of groups of related documents and boundaries between these groups, they do not explicitly convey the temporal evolution of a collection. In this thesis, we propose and validate a dynamic document map for collections of scientific articles capable of showing the temporal behavior to support analysis tasks, while simultaneously preserving the local accuracy of the map and the user global context. Changes in the similarity relationships, evidenced over time in this map, support the detection of the temporal evolution of topics. This evolution is characterized by transition events between groups such as the emergence of new groups and topics at specific moments and the specialization of a group, as well by detecting changes in the vocabulary of topics, using techniques that extract the most relevant terms (topics) in each group, at different times},
  keywords = {Dynamic multidimensional projection; Temporal evolution of topics; Topic extraction},
  school = {University of São Paulo},
  year = {2013},
  advisor = {Oliveira, Maria Cristina Ferreira de},
  address = {São Carlos, SP, } # Brazil,
  month = feb,
  url = {http://www.teses.usp.br/teses/disponiveis/55/55134/tde-11042013-155653},
  abstract-orig = {Artigos científicos são o principal mecanismo que pesquisadores usam para reportar suas descobertas científicas, e uma coleção de artigos em uma área de pesquisa pode revelar muito sobre sua evolução ao longo do tempo, como a emergência de novos tópicos e a evolução dos mesmos quanto ao seu conteúdo. No entanto, dada uma ampla coleção de artigos é geralmente muito difícil extrair informações importantes que possam ajudar leitores a interpretar globalmente, navegar e então eventualmente focar em itens relevantes para sua tarefa. Mapas de documentos baseados em conteúdo são representações visuais criadas para avaliar a similaridade entre documentos, e têm se mostrado úteis em auxiliar tarefas exploratórias neste cenário. Documentos são representados por marcadores visuais projetados em um espaço bidimensional de forma que documentos com conteúdo similar permaneçam próximos. Apesar de estes mapas permitirem a identificação visual de grupos de documentos relacionados e de fronteiras entre esses grupos, eles não transmitem explicitamente a evolução temporal de uma coleção. Nesta tese, propomos e validamos um mapa de documentos dinâmico interativo para coleções de artigos científicos capaz de evidenciar o comportamento temporal para apoiar tarefas de análise, preservando ao mesmo tempo a acurácia local do mapa e o contexto do usuário. As mudanças nas relações de similaridade, evidenciadas ao longo do tempo nesse mapa, oferecem suporte para detecção da evolução temporal dos tópicos. Essa evolução é caracterizada por meio de eventos de transição entre grupos, como a emergência de novos grupos e tópicos em momentos específicos e a especialização de um grupo, e pela detecção de mudanças no vocabulário dos tópicos, utilizando técnicas que extraem os termos mais relevantes (tópicos) em cada grupo, em diferentes momentos},
  keywords-orig = {Evolução temporal de tópicos; Extração de tópicos; Projeção multidimensional dinâmica},
  lang = {pt},
  owner = {magsilva},
  timestamp = {2014.06.04},
  title-orig = {Visualização da evolução temporal de coleções de artigos científicos}
}

@BOOK{Alencar:2007,
  title = {Televisão Digital},
  publisher = {Érica},
  year = {2007},
  author = {Marcelo Sampaio de Alencar},
  editor = {Marcelo Sampaio de Alencar},
  isbn = {978-85-365-0148-2},
  pages = {351},
  address = {São Paulo, SP, Brazil},
  edition = {1},
  abstract = {Televisão digital é uma discplina importante para a formação do engenheiro eletricista, como tambem para os profissionais de mídia e de comunicação social. Este livro tem o objetivo de servir como texto básico para o estudo de televisão digital nos cursos de Engenharia Elétrica, Eletrônica, Teleinformática ou Telecomunicações. Apresenta um histórico da televisão no Brasil, trata dos fundamentos da televisão, desde a digitalização e codificação dos sinais, pasando pela compressão de vídeo até a codificação para proteção contra erros. Discute técnias de modulação, os padrões ATSC, DVB, ISDB e o sistema brasileiro de televisão digital (ISDTV). Possui quatro apêndies que abordam os padrões de televisão analógica no mundo, tabelas úteis do espectro de radiofrequência, análise de Fourier, teoria de Processos Estocáticos, além de um glossário com as siglas e termos mais usados.},
  timestamp = {2008.10.07}
}

@BOOK{Alexander:1977,
  title = {A pattern language -- towns, buildings, construction},
  publisher = {Oxford University Press},
  year = {1977},
  author = {C. Alexander},
  address = {New York},
  owner = {magsilva},
  timestamp = {2007.11.22}
}

@ARTICLE{alexander:2003,
  author = {Ian Alexander},
  title = {Misuse Cases: Use Cases with Hostile Intent},
  volume = {20},
  number = {1},
  month = {jan},
  year = {2003},
  pages = {58-66},
  journal = {IEEE Software},
  owner = {Marco Aurélio Graciotto Silva},
  timestamp = {2008.07.30}
}

@MISC{Allert-etal:2001,
  author = {Heidrun Allert and Hadhami Dhraief and Wolfgang Nejdl},
  title = {How are Learning Objects Used in Learning Processes? Instructional Roles of Learning Objects in LOM},
  howpublished = {Artigo online.},
  month = dec,
  year = {2001},
  note = {Learning Lab Lower Saxony, University of Hanover.},
  abstract = {In order to reuse and exchange learning objects we need information about these learning objects. The LOM draft standard defines a set of more than 70 attributes, which specify learning object properties like author, title, subject, and many others, including the relationship of one learning object to other learning objects. However, even though the LOM draft includes a category educational, no information is included in the standard to specify, which instructional roles are played by a learning object within a course. In this paper, we show how to include this important didactic information using the concept of instructional roles and relations in a way, which is extensible and flexible enough to specify not only general didactic criteria, but rather specific criteria, as prescribed by different instructional theories.},
  keywords = {Metadata, Instructional Design, E-Learning, Standard for Learning Objects Metadata (LOM)},
  url = {http://www.kbs.uni-hannover.de/Arbeiten/Publikationen/2002/Modellierung-LOM.pdf}
}

@INPROCEEDINGS{Allowatt-Edwards:2005,
  author = {Allowatt, Anthony and Edwards, Stephen H.},
  title = {{IDE} Support for test-driven development and automated grading in both {Java} and {C++}},
  pages = {100--104},
  doi = {10.1145/1117696.1117717},
  abstract = {Students need to learn testing skills, and using test-driven development on assignments is one way to help students learn. We use a flexible automated grading system called Web-CAT to assess student assignments, including the validity and completeness of their own test cases. By building on existing educational plug-ins for Eclipse, and adding our own plug-ins for electronic submission and for unit testing support in C++, we are able to use Eclipse as a portal to all the services our students will need, allowing them to accomplish all their tasks entirely within the IDE, from their project's inception to its submission and evaluation. Further, we are able to carry students through the transition from Java programming to C++ programming within this same environment.},
  keywords = {Eclipse IDE, electronic assignment submission, electronic grading, extreme programming, test-driven development, test-first coding},
  booktitle = {2005 {OOPSLA Workshop} on Eclipse technology eXchange},
  isbn = {1-59593-342-5},
  location = {San Diego, California, #USA#},
  publisher = {ACM},
  timestamp = {2013-08-23},
  year = {2005}
}

@BOOK{Allworth81IRTS,
  title = {Introduction ro Real-Time Software Design},
  publisher = {McMillan},
  year = {1981},
  author = {S. T. Allworth},
  address = {London},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@MISC{software:ghtv,
  author = {Felipe Magno de Almeida},
  title = {Go {HTV} Middleware},
  howpublished = {Software},
  month = mar,
  year = {2010},
  url = {http://ghtv.com.br/}
}

@INPROCEEDINGS{almeida-barreto:2002,
  author = {Maria Aparecida Fernandes Almeida and Jorge Muniz Barreto},
  title = {Uso de Métodos Formais na construção de Programas Educacionais},
  booktitle = {WEI 2002},
  timestamp = {2008.08.01},
  year = {2002}
}

@ARTICLE{almendrosjimenez-iribarne:2009,
  author = {Almendros-Jiménez, Jesús M. and Iribarne, Luis},
  title = {UML Modeling of User and Database Interaction},
  volume = {52},
  month = {May},
  year = {2009},
  pages = {348--367},
  doi = {10.1093/comjnl/bxn028},
  abstract = {In this paper, we will present a design technique for user and database interaction based on UML. User interaction will be modeled by means of UML state diagrams, and database interaction by means of UML sequence diagrams. The proposed design technique establishes how to integrate both diagrams in order to describe the user interface and database interaction of a business software system. A case study of an Internet Book Shopping system will be shown to illustrate the proposal.},
  url = {http://portal.acm.org/citation.cfm?id=1536381.1536389},
  acmid = {1536389},
  address = {Oxford, UK},
  issn = {0010-4620},
  issue = {3},
  journal = {The Computer Journal},
  numpages = {20},
  publisher = {Oxford University Press}
}

@INPROCEEDINGS{Almendros-Jimenez:2009:EGT:1690559.1690604,
  author = {Almendros-Jiménez, Jesús M. and Iribarne, Luis and Asensio, José Andrés and Padilla, Nicolás and Vicente-Chicote, Cristina},
  title = {An Eclipse GMF Tool for Modelling User Interaction},
  pages = {405--416},
  doi = {10.1007/978-3-642-04754-1_42},
  abstract = {Model-Driven Development (MDD) has encouraged the use of automated software tools that facilitate the development process from modelling to coding. User Interfaces (UI), as a significant part of most applications, should also be modelled using a MDD perspective. This paper presents an Eclipse GMF tool for modelling user-interaction diagrams ---an specialization of the UML state-machines for UI design--- which can be used for describing the behaviour of user interfaces.},
  series = {WSKS '09},
  acmid = {1690604},
  address = {Berlin, Heidelberg},
  booktitle = {Proceedings of the 2nd World Summit on the Knowledge Society: Visioning and Engineering the Knowledge Society. A Web Science Perspective},
  isbn = {978-3-642-04753-4},
  location = {Chania, Crete, Greece},
  numpages = {12},
  publisher = {Springer-Verlag},
  year = {2009}
}

@BOOK{alonso:2004,
  title = {Web Services: Concepts, Architectures and Applications},
  publisher = {Springer},
  year = {2004},
  author = {G. Alonso},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@ARTICLE{alter:1993,
  author = {S. M. Alter},
  title = {Choosing the right software protection},
  volume = {10},
  number = {2},
  month = {mar},
  year = {1993},
  pages = {91-93},
  journal = {IEEE Software},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@MISC{xhtml11:2001,
  author = {Murray Altheim and Shane McCarron},
  title = {XHTML 1.1 - Module-based XHTML},
  howpublished = {W3C Recommendation},
  month = may,
  year = {2001},
  comment = {24/05/2005},
  file = {XHTML 1.1 - Module-based XHTML.pdf:XHTML 1.1 - Module-based XHTML.pdf:PDF},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://www.w3.org/TR/xhtml11}
}

@MISC{software:altova-uml,
  author = {{Altova}},
  title = {{UModel}},
  howpublished = {Programa de computador},
  year = {2005},
  url = {http://www.altova.com/umodel.html}
}

@MISC{software:jabref,
  author = {Morten O. Alver and other},
  title = {{JabRef}},
  howpublished = software,
  year = {2003},
  owner = {msilva},
  timestamp = {2006.02.24},
  url = {http://jabref.sourceforge.net/}
}

@ARTICLE{alves-etal:2009,
  author = {Alves, Luiz Gustavo Pacola and Silva, Fabio Santos Da and Bressan, Graca},
  title = {CollaboraTVware: a context-aware infrastructure with support for collaborative participation in an interactive digital TV environment},
  volume = {3},
  month = sep,
  year = {2009},
  pages = {365--382},
  doi = {10.1504/IJAMC.2009.028708},
  abstract = {The increasing number of TV programmes available to users, as well as the interactive services provided, resulting from the emergence of the Interactive Digital TV increases the difficulty of selecting relevant content. In this scenario, the user participation is important in a collaborative way. This paper presents a software infrastructure in an Interactive Digital TV environment &ndash; entitled CollaboraTVware &ndash; to guide, in a transparent way, users in the choice of TV programmes and interactive services through the collaborative participation of other users with similar profile and context. The classification task, from the theory of data mining, is the approach adopted in the infrastructure design. To demonstrate the functionalities in a usage scenario, it has developed an application (collaborative EPG) as a case study that uses the CollaboraTVware.},
  keywords = {classification task, collaborative participation, content selection, context awareness, data mining, digital television, interactive digital TV, metadata, social TV},
  acmid = {1628259},
  address = {Geneva, Switzerland},
  issn = {1462-4613},
  issue = {4},
  journal = {International Journal of Advanced Media and Communication},
  numpages = {18},
  publisher = {Inderscience}
}

@INPROCEEDINGS{amaral:2002,
  author = {Juliana Alves Amaral and Carlos Alberto Marques Pietrobon},
  title = {Using XML to Improve Frameworks Reuse},
  pages = {254-267},
  booktitle = {XVI Simpósio Brasileiro de Engenharia de Software},
  owner = {magsilva},
  timestamp = {2008.07.30},
  year = {2002}
}

@INPROCEEDINGS{amaral-etal:2006,
  author = {Lucas L. do Amaral and Thiago de A. Gomes and Maria de Fátima C. de Souza and José Aires de Castro Filho and Mauro C. Pequeno},
  title = {Um Aprimoramento do Modelo de Processo de Criação de Objetos de Aprendizagem do Projeto RIVED},
  pages = {373--376},
  address = {Campo Grande, MS, Brasil},
  booktitle = {XXVI Congresso da SBC - XII Workshop de Informática na Escola},
  location = {Campo Grande, MS, Brasil},
  month = jul,
  publisher = {SBC},
  timestamp = {2008.07.31},
  year = {2006}
}

@MISC{Amaral-etal:2013,
  author = {Marília Abrahão Amaral and others},
  title = {Compute Você Mesm@: Conexões de sabered e fazeres para inclusão digital},
  howpublished = {Projeto de Pesquisa},
  year = {2013},
  note = {Projeto aprovado na Chamada 03/2013 da Fundação Araucária},
  timestamp = {2013-11-17}
}

@MISC{software:alexa,
  author = {{Amazon.com}},
  title = {Alexa},
  howpublished = {Programa de computador},
  year = {1996},
  owner = {magsilva},
  timestamp = {2008.04.03},
  url = {http://www.alexa.com}
}

@BOOK{Ammann-Offutt:2008,
  title = {Introduction to software testing},
  publisher = {Cambridge University},
  year = {2008},
  author = {Paul Ammann and Jeff Offutt},
  isbn = {978-0521880381},
  pages = {344},
  address = {Cambridge, } # UK,
  edition = {1},
  month = feb,
  abstract = {Extensively class tested, this text takes an innovative approach to explaining the process of software testing: it defines testing as the process of applying a few well-defined, general-purpose test criteria to a structure or model of the software. The structure of the text directly reflects the pedagogical approach and incorporates the latest innovations in testing, including techniques to test modern types of software such as OO, web applications, and embedded software.},
  booktitle = {Introduction to software testing},
  owner = {magsilva},
  timestamp = {2009.08.12},
  url = {http://cs.gmu.edu/~offutt/softwaretest/}
}

@ARTICLE{Anacleto:2009,
  author = {Junia Coutinho Anacleto},
  title = {Opiniões - Sul},
  number = {11},
  month = oct # {-} # dec,
  year = {2009},
  pages = {18},
  journal = {Computação Brasil},
  owner = {magsilva},
  timestamp = {2010.09.13}
}

@ARTICLE{anacleto-etal:2007,
  author = {J. C. Anacleto and A. F. P. de Carvalho and A. Talarico Neto and V. P. A. Neris},
  title = {Cognitor: Um Framework Baseado na Linguagem de Padrões Cog-Learn},
  volume = {15},
  year = {2007},
  pages = {32-43},
  journal = {Revista Brasileira de Informática na Educação},
  timestamp = {2008.09.27}
}

@MISC{anderson:2007,
  author = {David J. Anderson},
  title = {Using MVC Pattern in Web Interactions},
  year = {2007},
  note = {http://www.uidesign.net/Articles/Papers/UsingMVCPatterninWebInter.html [06/01/2007]},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@MISC{software:chimera,
  author = {Ken Anderson},
  title = {Chimera Open Hypermedia System},
  howpublished = {Programa de Computador},
  month = oct,
  year = {2003},
  comment = {Visitado em 13/08/2005.},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://www-serl.cs.colorado.edu/chimera/}
}

@ARTICLE{anderson:1999,
  author = {Kenneth M. Anderson},
  title = {Supporting software engineering with open hypermedia},
  volume = {31},
  number = {4es},
  month = {dec},
  year = {1999},
  journal = {ACM Computing Surveys (CSUR)},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@ARTICLE{anderson-etal:2000,
  author = {Kenneth M. Anderson and Richard N. Taylor and E. James Whitehead, Jr.},
  title = {Chimera: Hypermedia for Heterogeneous Software Development Environments},
  volume = {18},
  number = {3},
  year = {2000},
  pages = {211 - 245},
  journal = {ACM Transactions on Information Systems (TOIS)},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@INPROCEEDINGS{anderson-felici:2000,
  author = {Stuart Anderson and Massimo Felici},
  title = {Controlling Requirements Evolution: An Avionics Case Study},
  pages = {361-370},
  address = {Rotterdam, The Netherlands},
  booktitle = {19th International Conference on Computer Safety, Reliability and Security},
  editor = {Floor Koornneef and Mein van der Meulen},
  month = oct,
  owner = {magsilva},
  timestamp = {2008.07.30},
  year = {2000}
}

@INPROCEEDINGS{Andreata-Montez:2006,
  author = {Jomar Alberto Andreata and Carlos Barros Montez},
  title = {InteraTV: Um Portal de Serviços Educacionais em TV Digital Interativa Baseado em Aplicações Colaborativas},
  pages = {223-230},
  abstract = {Neste artigo é proposto uso da TV Digital Interativa (TVDI) em aplicações de ensino a distância, permitindo atingir mais pessoas que seus similares da Internet. É introduzido um modelo portal de aplicações colaborativas para o ensino, e implementado através de um protótipo compatível com o sistema de TVDI europeu (DVB). As principais vantagens e características dessa abordagem também são discutidas neste texto.},
  abstract-en = {In this paper is proposed and implemented a portal of collaborative applications for education, using TV Digital Interactive terrestrial broadcast, compatible with the European DVB (Digital Video Broadcasting) system. The advantages and characteristics of this approach are discussed.},
  address = {Campo Grande, MS},
  booktitle = {XXVI Congresso da SBC - XII Workshop de Informática na Escola},
  location = {Campo Grande, MS, Brazil},
  month = jul,
  timestamp = {2008.07.31},
  year = {2006}
}

@MISC{software:xmlbeans,
  author = {Cezar Andrei and David Bau and Patrick Calahan and Ken Kress and Kevin Krouse and Laurence Moroney and Radu Preotiuc and Cliff Schmidt and Dutta Satadip and Eric Vasilik and David Waite and Scott Ziegler},
  title = {XMLBeans},
  howpublished = {Programa de Computador},
  year = {2005},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://xmlbeans.apache.org/}
}

@BOOK{andriole:1990,
  title = {Advanced Technology for Command and Control Systems Engineering},
  publisher = {AFCEA International Press},
  year = {1990},
  author = {Stephen J. Andriole},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@ARTICLE{AnidoRifon-etal:2001,
  author = {L. Anido-Rifón and M. J. Fernández-Iglesias and M. Llamas-Nistal and M. Caeiro-Rodríguez and J. Santos-Gago and J. S. Rodríguez-Estévez},
  title = {A Component Model for Standardized Web-Based Education},
  volume = {1},
  number = {2},
  year = {2001},
  pages = {1-21},
  doi = {10.1145/384055.384056},
  abstract = {We present a layered component model to support Web-based collaborative applications. We show how this model lets programmers focus on the particular logic of their applications, avoiding most of the issues related to collaboration, access control, and network management. The proposed model is organized into three layers on top of a foundation composed of commercial-off-the-shelf services and standard Internet protocols. The service level provides a network-transparent communications layer, database access, and distributed data interchange. The component level offers typical collaborative services, like user management, auditing, user-oriented messaging, higher-level events, project management, and a bulletin board. The application level supports actual applications constructed using the services offered by the underlying layers. A Web-based educational application has been developed over this framework to illustrate the process. This tele-education system, which follows the recommendations of the main institutions involved in the learning technology standardization process, is the second contribution presented by the authors.},
  journal = {Journal of Educational Resources in Computing},
  owner = {magsilva},
  publisher = {ACM},
  timestamp = {2008.09.02}
}

@PHDTHESIS{Ankerst:2000,
  author = {M. Ankerst},
  title = {Visual Data Mining},
  school = {Faculty of Mathematics and Computer Science, University of Munich},
  year = {2000},
  isbn = {3-89825-201-9}
}

@MISC{software:opennlp,
  author = {{Apache}},
  title = {{OpenNLP}},
  howpublished = {Programa de computador},
  year = {2010},
  url = {http://incubator.apache.org/opennlp}
}

@MISC{software:axis2,
  author = {{Apache Foundation}},
  title = {Axis2},
  howpublished = software,
  month = aug,
  year = {2004},
  owner = {magsilva},
  timestamp = {2010.08.24},
  url = {http://ws.apache.org/axis2/}
}

@MISC{software:tiles,
  author = {Apache Foundation, Apache},
  title = {Struts Tiles},
  howpublished = {Programa de computador},
  owner = {magsilva},
  timestamp = {2007.10.07},
  url = {http://tiles.apache.org/}
}

@MISC{software:maven,
  author = {{Apache Software Foundation}},
  title = {Maven},
  howpublished = software,
  year = {2003},
  owner = {magsilva},
  timestamp = {2010.09.01},
  url = {http://maven.apache.org/}
}

@MISC{software:ant,
  author = {{Apache Software Foundation}},
  title = {Ant},
  howpublished = {Programa de Computador},
  month = jan,
  year = {2000},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://ant.apache.org/}
}

@MISC{software:subversion,
  author = {{Apache Software Foundation}},
  title = {Subversion},
  howpublished = software,
  month = jun,
  year = {2000},
  owner = {Marco Aurélio Graciotto Silva},
  timestamp = {2008.07.30},
  url = {http://subversion.apache.org/}
}

@MISC{core1:1998,
  author = {Vidur Apparao and Steve Byrne and Mike Champion and Scott Isaacs and Ian Jacobs and Arnaud Le Hors and Gavin Nicol and Robert Sutor and Lauren Wood},
  title = {Document Object Model (DOM) Level 1 Specification},
  howpublished = {W3C Recommendation},
  month = oct,
  year = {1998},
  comment = {24/05/2005},
  file = {Document Object Model (DOM) Level 1 Specification.pdf:Document Object Model (DOM) Level 1 Specification.pdf:PDF},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://www.w3.org/TR/REC-DOM-Level-1}
}

@MISC{software:macos,
  author = {{Apple Computer}},
  title = {Mac OS},
  howpublished = {Programa de Computador},
  month = jan,
  year = {1984},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://www.apple.com/macosx/}
}

@MISC{appleton:2000,
  author = {B. Appleton},
  title = {Patterns and Software: Essential Concepts and Terminology},
  year = {2000},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@INPROCEEDINGS{april-etal:2006,
  author = {A. April and J.-M. Deshanais and R. Dumke},
  title = {A Formalism of Ontology to Support a Software Maintenance Knowledge-based System},
  pages = {331--336},
  address = {San Francisco, CA},
  booktitle = {International Conference on Software Engineering and Knowledge Engineering (SEKE)},
  month = jul,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {2006}
}

@INPROCEEDINGS{aquino-etal:2010,
  author = {Aquino, Nathalie and Vanderdonckt, Jean and Condori-Fernández, Nelly and Dieste, Óscar and Pastor, Óscar},
  title = {Usability evaluation of multi-device/platform user interfaces generated by model-driven engineering},
  pages = {1--10},
  doi = {10.1145/1852786.1852826},
  abstract = {Nowadays several Computer-Aided Software Engineering environments exploit Model-Driven Engineering (MDE) techniques in order to generate a single user interface for a given computing platform or multi-platform user interfaces for several computing platforms simultaneously. Therefore, there is a need to assess the usability of those generated user interfaces, either taken in isolation or compared to each other. This paper describes an MDE approach that generates multi-platform graphical user interfaces (e.g., desktop, web) that will be subject to an exploratory controlled experiment. The usability of user interfaces generated for the two mentioned platforms and used on multiple display devices (i.e., standard size, large, and small screens) has been examined in terms of satisfaction, effectiveness and efficiency. An experiment with a factorial design for repeated measures was conducted for 31 participants, i.e., postgraduate students and professors selected by convenience sampling. The data were collected with the help of questionnaires and forms and were analyzed using parametric and non-parametric tests such as ANOVA with repeated measures and Friedman's test, respectively. Efficiency was significantly better in large screens than in small ones as well as in the desktop platform rather than in the web platform, with a confidence level of 95%. The experiment also suggests that satisfaction tends to be better in standard size screens than in small ones. The results suggest that the tested MDE approach should incorporate enhancements in its multi-device/platform user interface generation process in order to improve its generated usability.},
  keywords = {effectiveness, efficiency, interaction with small and large screens, model-driven engineering, multi-device interface, multi-platform interface, satisfaction, usability evaluation},
  acmid = {1852826},
  address = {New York, NY, USA},
  articleno = {30},
  booktitle = {International Symposium on Empirical Software Engineering and Measurement},
  isbn = {978-1-4503-0039-1},
  location = {Bolzano-Bozen, Italy},
  numpages = {10},
  publisher = {ACM},
  year = {2010}
}

@BOOK{Ara-etal:2003,
  title = {Introdução à Estatística},
  publisher = {Edgard Blücher},
  year = {2003},
  author = {Amilton Braio Ara and Ana Villares Musetti and Boris Schneiderman},
  isbn = {85-212-0320-9},
  pages = {152},
  address = {São Paulo, SP, } # Brazil,
  edition = {1},
  booktitle = {Introdução à Estatística}
}

@INPROCEEDINGS{Araujo-etal:2009,
  author = {Rafael Viana Lopes Araújo and Caio Alves Carneiro and Robson Cavalcante Sousa and Fábio de Jesus Lima Gomes},
  title = {Um Objeto de Aprendizagem na {TV} Digital para o Ensino de Astronomia},
  pages = {1--6},
  abstract = {O presente artigo tem como foco o desenvolvimento de um objeto de aprendizagem interativo para o ensino de astronomia usando a TV Digital (TVD). Esse objeto de aprendizagem será uma aplicação interativa, que servirá de suporte ao ensino de astronomia para estudantes do 6o ano do ensino fundamental brasileiro. Espera-se que a TVD desperte um maior interesse dos alunos, tornando o ensino de astronomia mais simples e acessível. No processo de desenvolvimento da solução proposta, está sendo utilizado a biblioteca Java LWUIT, que possibilitou uma melhor experiência visual do aplicativo para os usuários.},
  address = {Parnaíba, PI, Brasil},
  booktitle = {III Escola Regional de Computação Ceará-Maranhão-Piauí (ERCEMAPI 2009)},
  location = {Parnaíba, PI, Brasil},
  publisher = {SBC},
  url = {http://www.ufpi.br/subsiteFiles/ercemapi/arquivos/files/artigos/graduacao/g6.pdf},
  year = {2009}
}

@MISC{standard:arib:b31,
  author = {{ARIB}},
  title = {{ARIB} {STD B.31} -- Transmission System for Digital Terrestrial Television Broadcasting},
  howpublished = standard,
  month = mar,
  year = {2011}
}

@MISC{standard:aribb24,
  author = {{ARIB}},
  title = {Data Coding and Transmission Specification for Digital Broadcasting},
  howpublished = {Padrão},
  year = {1999},
  timestamp = {2008.10.07}
}

@RESEARCH-PROJECT{project:arimoto,
  title = {Desenvolvimento ágil de recursos educacionais abertos},
  author = {Maurício Massaru Arimoto},
  institution = {Instituto de Ciências Matemáticas e de Computação, Universidade de São Paulo},
  number = {11/06204-1},
  funding = {FAPESP},
  month = jul,
  year = {2011},
  duration = {31-#oct#-2014},
  abstract-orig = {Em consequência da globalização e dos avanços proporcionados pela adoção de tecnologias deinformação e comunicação, tem-se uma crescente demanda por formação e qualificação de pessoalnas mais variadas áreas do conhecimento. Seguindo essa tendência, diversas iniciativas têmsido conduzidas no intuito de fornecer soluções que apoiem o processo de ensino e aprendizagem.No contexto de desenvolvimento de módulos educacionais, há uma preocupação eminentequanto à proposição de mecanismos adequados à sua elaboração e disponibilização. Além disso,evidencia-se a necessidade de mecanismos que propiciem o aumento da produtividade e da qualidade dos módulos educacionais gerados. Métodos ágeis de desenvolvimento inserem-se nessaperspectiva, abordando um novo enfoque para o desenvolvimento, centrado na agilidade, flexibilidade, habilidade de comunicação e na capacidade de entregar software e serviços com valores agregados ao mercado e em tempo hábil. Por outro lado, há também uma tendência para o desenvolvimento de módulos educacionais livres e compartilhados, assim como acontece no desenvolvimento de software. De fato, a adoção de produtos livres por parte das universidades, centros de pesquisa, indústrias e órgãos governamentais tem aumentado significativamente nos últimos anos, constituindo-se um elemento estratégico na geração e difusão de inovações tecnológicas. Neste cenário, o presente trabalho de doutorado visa a proposição de um método ágil para o desenvolvimento e disponibilização de módulos educacionais livres de qualidade, capazes de motivar os aprendizes e contribuir com o processo de construção do conhecimento. Aspectos referentes ao estabelecimento de ambientes de apoio para a construção dos módulos também deverão ser definidos e incorporados ao método. Entre os resultados esperados, ressalta-se o desenvolvimento de um ambiente piloto para o desenvolvimento e disponibilização de módulos educacionais livres e sua validação na elaboração de módulos para diferentes domínios de conhecimento.},
  lang = {pt},
  owner = {magsilva},
  timestamp = {2014.08.01}
}

@RESEARCH-PROJECT{project:Arimoto-Barbosa:2011,
  title = {Uma contribuição ao desenvolvimento de ágil de módulos educacionais livres},
  author = {Maurício Massaru Arimoto and Ellen Francine Barbosa},
  institution = {Institute of Mathematical Sciences and Computing -- University of São Paulo},
  number = {11/06204-1},
  funding = {FAPESP},
  month = jul,
  year = {2011},
  abstract = {Em consequência da globalização e dos avanços proporcionados pela adoção de tecnologias deinformação e comunicação, tem-se uma crescente demanda por formação e qualificação de pessoalnas mais variadas áreas do conhecimento. Seguindo essa tendência, diversas iniciativas têmsido conduzidas no intuito de fornecer soluções que apoiem o processo de ensino e aprendizagem.No contexto de desenvolvimento de módulos educacionais, há uma preocupação eminentequanto à proposição de mecanismos adequados à sua elaboração e disponibilização. Além disso,evidencia-se a necessidade de mecanismos que propiciem o aumento da produtividade e da qualidade dos módulos educacionais gerados. Métodos ágeis de desenvolvimento inserem-se nessaperspectiva, abordando um novo enfoque para o desenvolvimento, centrado na agilidade, flexibilidade, habilidade de comunicação e na capacidade de entregar software e serviços com valores agregados ao mercado e em tempo hábil. Por outro lado, há também uma tendência para o desenvolvimento de módulos educacionais livres e compartilhados, assim como acontece no desenvolvimento de software. De fato, a adoção de produtos livres por parte das universidades, centros de pesquisa, indústrias e órgãos governamentais tem aumentado significativamente nos últimos anos, constituindo-se um elemento estratégico na geração e difusão de inovações tecnológicas. Neste cenário, o presente trabalho de doutorado visa a proposição de um método ágil para o desenvolvimento e disponibilização de módulos educacionais livres de qualidade, capazes de motivar os aprendizes e contribuir com o processo de construção do conhecimento. Aspectos referentes ao estabelecimento de ambientes de apoio para a construção dos módulos também deverão ser definidos e incorporados ao método. Entre os resultados esperados, ressalta-se o desenvolvimento de um ambiente piloto para o desenvolvimento e disponibilização de módulos educacionais livres e sua validação na elaboração de módulos para diferentes domínios de conhecimento.}
}

@ARTICLE{armour:2001,
  author = {Armour, Phillip G.},
  title = {The business of software: the laws of software process},
  volume = {44},
  month = jan,
  year = {2001},
  pages = {15--17},
  doi = {10.1145/357489.357495},
  acmid = {357495},
  address = {New York, NY, USA},
  issn = {0001-0782},
  issue = {1},
  journal = {Communications of the ACM},
  numpages = {3},
  publisher = {ACM}
}

@MISC{arruda:2001,
  author = {C. R. E. {Arruda Jr.}},
  title = {Extensão e Integração de uma Ferramenta Colaborativa de Edição Tipo CoWeb},
  howpublished = {Monografia de Projeto de Graduação},
  month = jun,
  year = {2001},
  note = {ICMC/USP},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@ARTICLE{arruda-pimentel:2001:reic,
  author = {C. R. E. {Arruda Jr.} and M. G. C. Pimentel},
  title = {Projeto e implementação de um sistema colaborativo de edição},
  volume = {1},
  number = {2},
  year = {2001},
  journal = {Revista Eletrônica de Iniciação Científica (REIC)},
  owner = {magsilva},
  timestamp = {2006.10.11}
}

@BOOK{Ascencio-Campos:2008,
  publisher = {Pearson},
  year = {2008},
  author = {Ana Fernanda Gomes Ascencio and Edilene Aparecida Veneruchi de Campos},
  isbn = {978-85-7605-148-0},
  pages = {434},
  address = {São Paulo, SP, } # Brazil,
  edition = {2},
  booktitle = {Fundamentos da programação de computadores}
}

@INPROCEEDINGS{Asklund01CMOS,
  author = {U. Asklund and L. Bendix},
  title = {Configuration Management for Open Source Software},
  address = {Toronto, Canada},
  booktitle = {1st Workshop on Open Source Software Development (ICSE 2001)},
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {2001}
}

@BOOK{astels:2003,
  title = {Test-Driven Development: A Practical Guide},
  publisher = {Prentice Hall PTR},
  year = {2003},
  author = {D. Astels},
  month = jul,
  owner = {magsilva},
  timestamp = {2009.04.22}
}

@TECHREPORT{Atkins-etal:2007,
  author = {Daniel E. Atkins and John Seely Brown and Allen L. Hammond},
  title = {A Review of the Open Educational Resources (OER) Movement: Achievements, Challenges, and New Opportunities},
  institution = {The William and Flora Hewlett Foundation},
  month = feb,
  year = {2007},
  lang = {en},
  pages = {80}
}

@ARTICLE{atkins:2002,
  author = {David L. Atkins and Thomas Ball and Todd L. Graves and Audris Mockus},
  title = {Using Version Control Data to Evaluate the Impact of Software Tools: A Case Study of the Version Editor},
  volume = {28},
  number = {7},
  month = jul,
  year = {2002},
  pages = {625-637},
  journal = {IEEE Transactions on Software Engineering},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@MISC{software:hypercard,
  author = {Bill Atkinson},
  title = {Hypercard},
  howpublished = {Programa de Computador},
  month = aug,
  year = {1987},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://en.wikipedia.org/wiki/HyperCard}
}

@ARTICLE{Atkinson-Kuhne:2008,
  author = {Atkinson, Colin and Kühne, Thomas},
  title = {Reducing accidental complexity in domain models},
  volume = {7},
  year = {2008},
  pages = {345-359},
  doi = {10.1007/s10270-007-0061-0},
  abstract = {A fundamental principle in engineering, including software engineering, is to minimize the amount of accidental complexity which is introduced into engineering solutions due to mismatches between a problem and the technology used to represent the problem. As model-driven development moves to the center stage of software engineering, it is particularly important that this principle be applied to the technologies used to create and manipulate models, especially models that are intended to be free of solution decisions. At present, however, there is a significant mismatch between the two level modeling paradigm used to construct mainstream domain models and the conceptual information such models are required to represent -- a mismatch that makes such models more complex than they need be. In this paper, we identify the precise nature of the mismatch, discuss a number of more or less satisfactory workarounds, and show how it can be avoided.},
  affiliation = {University of Mannheim Mannheim Germany},
  issn = {1619-1366},
  issue = {3},
  journal = {Software and Systems Modeling},
  keyword = {Computer Science},
  publisher = {Springer Berlin / Heidelberg}
}

@MISC{software:phpbb,
  author = {James Atkinson and Nathan Codding and John Abela and others},
  title = {phpBB},
  howpublished = {Programa de Computador},
  month = jun,
  year = {2000},
  owner = {magsilva},
  timestamp = {2007.12.07},
  url = {http://www.phpbb.com/}
}

@ARTICLE{Atkinson-Wilson:1968,
  author = {Richard Chatham Atkinson and Harlalee Allen Wilson},
  title = {Computer-Assisted Instruction},
  volume = {162},
  number = {3849},
  month = oct,
  year = {1968},
  pages = {73--77},
  doi = {10.1126/science.162.3849.73},
  address = USA,
  issn = {0036-8075, 1095-9203},
  journal = {Science},
  publisher = {{AAAS}}
}

@MISC{standard:atsc:a52,
  author = {{ATSC}},
  title = {A/52:2010: Digital Audio Compression (AC-3) Standard},
  howpublished = {Padrão},
  month = nov,
  year = {2010},
  abstract = {This document specifies coded representation of audio information and the decoding process, as well as information on the encoding process. The coded representation specified is suitable for use in digital audio transmission and storage applications, and may convey from 1 to 5 full bandwidth audio channels, along with a low-frequency enhancement channel. A wide range of encoded bit-rates is supported by this specification. Typical applications of digital audio compression are in satellite or terrestrial audio broadcasting, delivery of audio over metallic or optical cables, or storage of audio on magnetic, optical, semiconductor, or other storage media. Revision B added a new annex, 'Enhanced AC-3 Bit Stream Syntax' which specifies an additional syntax that offers additional coding tools and features.},
  address = {EUA},
  timestamp = {2008.10.07},
  url = {http://www.atsc.org/cms/index.php/standards/published-standards/48-atsc-a52-standard},
  urlaccessdate = {20 fev 2012}
}

@INPROCEEDINGS{auinger-stary:2007,
  author = {Andreas Auinger and Christian Stary},
  title = {Ubiquitous Access to Learning Material in Engineering},
  pages = {481-490},
  doi = {10.1007/978-3-540-73283-9_54},
  volume = {4556},
  series = {Lecture Notes in Computer Science},
  booktitle = {HCI},
  date = {2007-08-30},
  description = {dblp},
  editor = {Constantine Stephanidis},
  isbn = {978-3-540-73282-2},
  publisher = {Springer},
  year = {2007}
}

@MISC{mathml:2003,
  author = {Ron Ausbrooks and Stephen Buswell and David Carlisle and Stéphane Dalmas and Stan Devitt and Angel Diaz and Max Froumentin and Roger Hunter and Patrick Ion and Michael Kohlhase and Robert Miner and Nico Poppelier and Bruce Smith and Neil Soiffer and Robert Sutor and Stephen Watt},
  title = {Mathematical Markup Language (MathML) Version 2.0},
  howpublished = {W3C Recommendation},
  month = oct,
  year = {2003},
  comment = {24/05/2005},
  file = {Mathematical Markup Language (MathML) Version 2.0.pdf:Mathematical Markup Language (MathML) Version 2.0.pdf:PDF},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://www.w3.org/TR/MathML/}
}

@BOOK{Ausubel:2000,
  title = {The Acquisition and Retention of Knowledge: A Cognitive View},
  publisher = {Springer},
  year = {2000},
  author = {David Paul Ausubel},
  isbn = {978-0-7923-6505-1,978-90-481-5536-1},
  pages = {232},
  abstract = {This is a college-level textbook that provides a comprehensive and credible theory of how humans can learn and retain substantial and growing bodies of potentially meaningful, organized subject-matter knowledge on an extended, long-term basis. It identifies explicitly the cognitive conditions under which such learning and retention occurs, and indicates how they are influenced by relevant cognitive structure, frequency, mental `set' and motivational variables, and, most importantly, by the probable underlying functional cognitive processes involved.},
  booktitle = {The Acquisition and Retention of Knowledge: A Cognitive View}
}

@BOOK{Ausubel:1968,
  title = {Educational Psychology: a Cognitive View},
  publisher = {Holt, Rinehart and Winston},
  year = {1968},
  author = {David Paul Ausubel},
  pages = {685},
  address = {New York, NY, EUA},
  edition = {1},
  booktitle = {Educational Psychology: a Cognitive View},
  lang = {en},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@BOOK{Ausubel-etal:1978,
  title = {Educational Psychology: a Cognitive View},
  publisher = {Holt, Rinehart and Winston},
  year = {1978},
  author = {David Paul Ausubel and Joseph Donald Novak and Helen Hanesian},
  pages = {733},
  address = {New York, NY, USA},
  edition = {2},
  month = jun,
  booktitle = {Educational Psychology: a Cognitive View},
  lang = {en},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@INCOLLECTION{Autebert-etal:1997,
  author = {Autebert, Jean-Michel and Berstel, Jean and Boasson, Luc},
  title = {Handbook of Formal Languages},
  publisher = {Springer-Verlag},
  year = {1997},
  editor = {Rozenberg, Grzegorz and Salomaa, Arto},
  volume = {1},
  chapter = {Context-free Languages and Pushdown Automata},
  pages = {111--174},
  address = {New York, NY, } # USA,
  abstract = {This chapter is devoted to context-free languages. Context-free languages and grammars were designed initially to formalize grammatical properties of natural languages. They subsequently appeared to be well adapted to the formal description of the syntax of programming languages. This led to a considerable development of the theory.},
  doi = {10.1007/978-3-642-59136-5_3},
  eisbn = {978-3-642-59136-5},
  isbn = {3-540-60420-0},
  owner = {magsilva},
  timestamp = {2014.01.26}
}

@MISC{software:nusoap,
  author = {Dietrich Ayala and Scott Nichol},
  title = {{NuSOAP} - {SOAP} Toolkit for {PHP}},
  howpublished = software,
  month = apr,
  year = {2002},
  owner = {magsilva},
  timestamp = {2006.08.01},
  url = {http://sourceforge.net/projects/nusoap/}
}

@MISC{smil:2001,
  author = {Jeff Ayars and Dick Bulterman and Aaron Cohen and Ken Day and Erik Hodge and Philipp Hoschka and Eric Hyche and Muriel Jourdan and Michelle Kim and Kenichi Kubota and Rob Lanphier and Nabil Layaïda and Thierry Michel and Debbie Newman and Jacco van Ossenbruggen and Lloyd Rutledge and Bridie Saccocio and Patrick Schmitz and Warner ten Kate and Thierry Michel},
  title = {Synchronized Multimedia Integration Language (SMIL 2.0)},
  howpublished = {W3C Recommendation},
  month = jan,
  year = {2005},
  comment = {24/05/2005},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://www.w3.org/TR/SMIL/}
}

@ARTICLE{azevedo:2000,
  author = {Wilson Azevêdo},
  title = {Panorama atual da educação a distância no Brasil},
  number = {2},
  month = sep,
  year = {2000},
  url = {http://www.revistaconecta.com/conectados/wilson_seminario.htm},
  journal = {Conect@ - Revista on-line de Educação a Distância},
  timestamp = {2008.09.15}
}

@INPROCEEDINGS{babar-zhang:2009,
  author = {Babar, Muhammad Ali and Zhang, He},
  title = {Systematic literature reviews in software engineering: Preliminary results from interviews with researchers},
  pages = {346--355},
  doi = {10.1109/ESEM.2009.5314235},
  abstract = {Systematic Literature Reviews (SLRs) have been gaining significant attention from software engineering researchers since 2004. Several researchers have reported their experiences of and lessons learned from applying systematic reviews to different subject matters in software engineering. However, there has been no attempt at independently exploring experiences and perceptions of the practitioners of systematic reviews in order to gain an in-depth understanding of various aspects of systemic reviews as a new research methodology in software engineering. We assert that there is a need of evidence-based body of knowledge about the application of systematic reviews in software engineering. To address this need, we have started an empirical research program that aims to contribute to the growing body of knowledge about systematic reviews in software engineering. This paper reports the design, logistics, and results of the first phase empirical study carried out in this program. The results provide interesting insights into different aspects of systematic reviews based on the analysis of the data gathered from 17 interviewees with varying levels of knowledge of and experiences in systematic reviews. The findings from this study are expected to contribute to the existing knowledge about using systematic reviews and help further improve the state-of-the-practice of this research methodology in software engineering.},
  address = {Washington, DC, USA},
  booktitle = {International Symposium on Empirical Software Engineering and Measurement (ESEM '09)},
  isbn = {978-1-4244-4842-5},
  publisher = {IEEE Computer Society},
  year = {2009}
}

@BOOK{Babbie:1990,
  title = {Survey Research Methods},
  publisher = {Wadsworth},
  year = {1990},
  author = {Earl R. Babbie},
  pages = {395},
  edition = {2}
}

@MISC{Bach:1995,
  author = {James Bach},
  title = {{SCRUM} Software Development Process: Building the Best Possible Software},
  howpublished = {http://www.controlchaos.com/scrumwp.htm},
  month = oct,
  year = {1995},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@INPROCEEDINGS{Bachmayer-etal:2009,
  author = {Bachmayer, Sabine and Lugmayr, Artur and Kotsis, Gabriele},
  title = {New social \& collaborative interactive TV program formats},
  pages = {121--128},
  doi = {10.1145/1821748.1821776},
  abstract = {TV goes rapidly digital, and more and more content formats are entering the consumer market. Currently there exist many approaches towards the development of more social, more collaborative, and interactive TV formats and systems. Within the scope of this paper we present latest case studies and provide a simple categorization according narration character, content types, and interactivity types of program formats. We also present systems supporting social and collaborative functionalities. The paper rounds up with a discussion sections, where an evaluation of the discussed projects can be found.},
  keywords = {collaborative television, interactive television, social television},
  address = {New York, NY, USA},
  booktitle = {7th International Conference on Advances in Mobile Computing and Multimedia},
  isbn = {978-1-60558-659-5},
  location = {Kuala Lumpur, #Malaysia#},
  publisher = {ACM},
  year = {2009}
}

@BOOK{BaezaYates-RibeiroNeto:1999,
  title = {Modern Information Retrieval},
  publisher = {Addison Wesley Longman},
  year = {1999},
  author = {Ricardo Baeza-Yates and Berthier Ribeiro-Neto},
  isbn = {020139829X},
  pages = {499},
  address = {New York, USA},
  edition = {1},
  abstract = {Information retrieval (IR) has changed considerably in recent years with the expansion of the World Wide Web and the advent of modern and inexpensive graphical user interfaces and mass storage devices. As a result., traditional IR textbooks have become quite out of date and this has led to the introduction of new IR books. Nevertheless, we believe that there is still great need for a book that approaches the field in a rigorous and complete way from a computer-science perspective (as opposed to a user-centered perspective). This book is an effort to partially fulfill this gap and should be useful for a first course on information retrieval as well as for a graduate course on the topic. The book comprises two portions which complement and balance each other. The core portion includes nine chapters authored or co-authored by the designers of the book. The second portion, which is fully integrated with the first, is formed by six state-of-the-art chapters written by leading researchers in their fields. The same notation and glossary are used in all the chapters. Thus, despite the fact that several people have contributed to the text, this book is really much more a textbook than an edited collection of chapters written by separate authors. Furthermore, unlike a collection of chapters, we have carefully designed the contents and organization of the book to present a cohesive view of all the important aspects of modern information retrieval. From IR models to indexing text, from IR visual tools and interfaces to the Web, from IR. multimedia to digital libraries, the book provides both breadth of coverage and richness of detail. It is our hope that, given the now clear relevance and significance of information retrieval to modern society. the book will contribute to further disseminate the study of the discipline at information science, computer science, and library science departments throughout the world.},
  url = {http://people.ischool.berkeley.edu/~hearst/irbook/}
}

@ARTICLE{baker-etal:2005,
  author = {Alex Baker and Emily Oh Navarro and André van der Hoek},
  title = {An experimental card game for teaching software engineering processes},
  volume = {75},
  number = {1-2},
  month = feb,
  year = {2005},
  pages = {3-16},
  journal = {Journal of Systems and Software},
  owner = {magsilva},
  timestamp = {2008.07.24}
}

@BOOK{baker:1985,
  title = {The Computer Security Handbook},
  publisher = {TAB Professional and Reference Books},
  year = {1985},
  author = {Richard H. Baker},
  edition = {1},
  owner = {magsilva},
  timestamp = {2006.07.11}
}

@ARTICLE{Balakrishnan:2010:WYS:1749608.1749612,
  author = {Balakrishnan, Gogul and Reps, Thomas},
  title = {{WYSINWYX}: What you see is not what you eXecute},
  volume = {32},
  number = {6},
  month = aug,
  year = {2010},
  pages = {23:1--23:84},
  doi = {10.1145/1749608.1749612},
  abstract = {Over the last seven years, we have developed static-analysis methods to recover a good approximation to the variables and dynamically allocated memory objects of a stripped executable, and to track the flow of values through them. The article presents the algorithms that we developed, explains how they are used to recover Intermediate Representations (IRs) from executables that are similar to the IRs that would be available if one started from source code, and describes their application in the context of program understanding and automated bug hunting. Unlike algorithms for analyzing executables that existed prior to our work, the ones presented in this article provide useful information about memory accesses, even in the absence of debugging information. The ideas described in the article are incorporated in a tool for analyzing Intel x86 executables, called CodeSurfer/x86. CodeSurfer/x86 builds a system dependence graph for the program, and provides a GUI for exploring the graph by (i) navigating its edges, and (ii) invoking operations, such as forward slicing, backward slicing, and chopping, to discover how parts of the program can impact other parts. To assess the usefulness of the IRs recovered by CodeSurfer/x86 in the context of automated bug hunting, we built a tool on top of CodeSurfer/x86, called Device-Driver Analyzer for x86 (DDA/x86), which analyzes device-driver executables for bugs. Without the benefit of either source code or symbol-table/debugging information, DDA/x86 was able to find known bugs (that had been discovered previously by source-code analysis tools), along with useful error traces, while having a low false-positive rate. DDA/x86 is the first known application of program analysis/verification techniques to industrial executables.},
  keywords = {Abstract interpretation, context-sensitive analysis, data structure recovery, interprocedural dataflow analysis, pointer analysis, reverse engineering, static analysis},
  acmid = {1749612},
  address = {New York, NY, USA},
  articleno = {23},
  issn = {0164-0925},
  issue = {6},
  issue_date = {August 2010},
  journal = {ACM Transactions on Programming Languages and Systems},
  numpages = {84},
  publisher = {ACM}
}

@INPROCEEDINGS{Baldassarre-etal:2008,
  author = {Baldassarre, Maria Teresa and Boffoli, Nicola and Caivano, Danilo and Visaggio, Giuseppe},
  title = {A Hands-On Approach for Teaching Systematic Review},
  pages = {415--426},
  doi = {10.1007/978-3-540-69566-0_33},
  number = {5089},
  series = {Lecture Notes in Computer Science},
  acmid = {1425937},
  address = {Monte Porzio Catone, Italy},
  booktitle = {International Conference on Product-Focused Software Process Improvement},
  isbn = {978-3-540-69564-6},
  location = {Monte Porzio Catone, Italy},
  month = jun,
  numpages = {12},
  publisher = {Springer-Verlag},
  year = {2008}
}

@INPROCEEDINGS{Baldi-etal:2006,
  author = {Baldi, M. and De Santis, A. and Falcone, D. and Gambi, E. and Spinsante, S.},
  title = {A T-Learning Platform based on Digital Terrestrial Television},
  pages = {347--351},
  doi = {10.1109/SOFTCOM.2006.329778},
  abstract = {The spreading of the digital video broadcasting terrestrial (DVB-T) technology makes it possible to address a large amount of end users, even those who are not familiar with the Internet, providing services and applications characterized by differentiated levels of interactivity. In this paper we propose an example of integration of different technologies, DVB-T and videoconference, in order to widen the spectrum of available interactive services, with specific reference to a T-learning environment. An experimental implementation of the proposed service is currently adopted by our University; due to the flexibility of this solution, in terms of low bit rate required by the video content and portability of the application, a further extension to generic educational contexts is easily conceivable},
  booktitle = {International Conference on Software in Telecommunications and Computer Networks},
  isbn = {953-6114-87-9},
  month = sep # {-} # oct,
  timestamp = {2012.02.10},
  year = {2006}
}

@BOOK{Baldwin-Clark,
  publisher = {MIT Press},
  year = {2000},
  author = {Carliss Y. Baldwin and Kim B. Clark},
  isbn = {0262024667, 978-0262024662},
  pages = {483},
  booktitle = {Design Rules: The Power of Modularity},
  timestamp = {2012.01.20}
}

@TECHREPORT{Baldwin79HDEP,
  author = {D. Baldwin and F. Sayward},
  title = {Heuristics for Determining Equivalence of Program Mutations},
  institution = {Department of Computer Science, Yale University},
  year = {1979},
  number = {276},
  owner = {magsilva},
  timestamp = {2008.07.31},
  type = {Research Report}
}

@INPROCEEDINGS{balushi-etal:2006,
  author = {T. H. Al Balushi and P. R. F. Sampaio and D. Dabhi and P. Loucopoulos},
  title = {Performing Requirements Elicitation Activities Supported by Quality Ontologies},
  pages = {343--348},
  address = {San Francisco, CA},
  booktitle = {International Conference on Software Engineering and Knowledge Engineering (SEKE)},
  month = jul,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {2006}
}

@INPROCEEDINGS{Barbosa-etal:2006,
  author = {Barbosa, David Falcão and Furtado, Elizabeth S. and Gomes, Albert Schilling},
  title = {Uma proposta de institucionalização da usabilidade alinhada com práticas do modelo {CMMI} e foco nas necessidades da organização},
  pages = {45--48},
  doi = {10.1145/1298023.1298060},
  abstract = {This paper presents a proposal to perform usability institutionalization in software development organizations, focusing on the association of existing practices in the field of Human Computer Interaction (HCI) with CMMI practices and organization needs. In this work, we intend to demonstrate (to usability professionals), that usability practices can be associated with some existing organizational practices, in an appropriate and collaborative manner. We also intend to demonstrate (this time, to the whole organization), that these practices can help to improve the quality of their products and, consequently, the maturity of the development process of the organization.},
  keywords = {CMMI, process improvement, usability},
  booktitle = {VII Brazilian Symposium on Human factors in computing systems},
  isbn = {1-59593-432-4},
  location = {Natal, RN, Brazil},
  publisher = {ACM},
  year = {2006}
}

@ARTICLE{Barbosa-etal:2007,
  author = {Daniel L Barbosa and Helton S. Lima and Patricia D. L. Machado and Jorge C. A. Figueiredo and Makelli A. Jucá and Wilkerson L. Andrade},
  title = {Automatic Functional Testing of Components from {UML} Specifications},
  volume = {17},
  number = {3},
  month = jun,
  year = {2007},
  pages = {339--358},
  doi = {10.1142/S0218194007003276},
  abstract = {A method of functional testing for software components according to model-based testing techniques is proposed. Test cases are generated from UML diagrams and OCL constraints that comprise a component interface and realization specification. The method uses a reduced set of UML artifacts that constitute the main requirements for its application along with a component development process, making use of development artifacts. Also, the set of generated test artifacts are packed together with the provided components to reduce the overall testing effort when clients assemble applications. A tool has been developed to automate the method with test cases generated as Java test components. Test execution and result analysis is also supported. For each component, the tool generates a test component that can be easily upgraded and configured for testing the services provided by a component throughout its life cycle.},
  keywords = {Component testing; model-based testing; test case generation; UML},
  editor = {Jerry Gao and Sami Beydeda},
  journal = {International Journal of Software Engineering and Knowledge Engineering}
}

@RESEARCH-PROJECT{project:Barbosa:2007,
  title = {Estudo, definição e estabelecimento de mecanismos de apoio ao desenvolvimento aberto, cooperativo e distribuído de módulos educacionais},
  author = {Ellen Francine Barbosa},
  institution = {Institute of Mathematics Science and Computing -- University of São Paulo},
  number = {07/52629-9},
  funding = {FAPESP},
  month = dec,
  year = {2007},
  abstract = {No decorrer das atividades associadas ao trabalho de doutorado de Barbosa (Processo FAPESP 98/16490-5) foram investigados e definidos mecanismos de apoio ao processo de desenvolvimento e modelagem de módulos educacionais. Os mecanismos estabelecidos propiciaram a reestruturação de materiais didáticos dentro da temática de Teste de Software. Em continuidade a esse trabalho, pretende-se agora investigar e definir mecanismos de apoio ao processo de desenvolvimento aberto, cooperativo e distribuído de tais módulos. A idéia é que os conteúdos construídos sejam flexíveis, customizáveis e reutilizáveis, intermultidisciplinares e, até certo ponto, "globalizados", como forma de estabelecer mecanismos apropriados para contribuir na melhoria do processo de ensino e aprendizado; tornando-o compatível com as novas demandas impostas pelas transformações educacionais em curso. Tanto o ensino presencial como a distância devem ser contemplados. Ainda, a longo prazo, pretende-se estabelecer um cenário para o desenvolvimento de módulos educacionais livres. Uma das linhas de atuação a ser explorada nesse contexto refere-se ao desenvolvimento de ferramental de apoio à aplicação dos mecanismos definidos, em especial ferramentas de suporte às atividades de modelagem e geração automática dos conteúdos educacionais associados aos módulos. Tal perspectiva deve ser explorada dentro do escopo do presente projeto de pesquisa.}
}

@PHDTHESIS{Barbosa:2004,
  author = {Ellen Francine Barbosa},
  title = {Uma Contribuição ao Processo de Desenvolvimento e Modelagem de Módulos Educacionais},
  school = {Instituto de Ciências Matemáticas e de Computação -- Universidade de São Paulo},
  year = {2004},
  advisor = {José Carlos Maldonado},
  address = {São Carlos, SP, } # Brazil,
  month = mar,
  pages = {253}
}

@PHDTHESIS{Barbosa:2000,
  author = {E. F. Barbosa},
  title = {Ensino, Aprendizado e Treinamento no Contexto de Teste e Validação de Software},
  school = {Instituto de Ciências Matemáticas e de Computação -- Universidade de São Paulo},
  year = {2000},
  address = {São Carlos, SP},
  note = {(Qualificação de Doutorado)},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@MASTERSTHESIS{Barbosa:1998,
  author = {E. F. Barbosa},
  title = {Uma Contribuição para a Determinação de um Conjunto Essencial de Operadores de Mutação no Teste de Programas {C}},
  school = {ICMC-USP},
  year = {1998},
  address = {São Carlos, SP},
  month = nov,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@TECHREPORT{Barbosa-GraciottoSilva:2009,
  author = {Ellen Francine Barbosa and Graciotto Silva, Marco Aurélio},
  title = {Guidelines for the creation of training materials},
  institution = {INCT-SEC},
  month = aug,
  year = {2009},
  address = {São Carlos, SP, } # Brazil,
  url = {http://www.inct-sec.org/sites/default/files/aim-cid/Guidelines%20-%20AIMCID.pdf},
  urlaccessdate = {20 fev 2012}
}

@INPROCEEDINGS{Barbosa-etal:2003:cseet,
  author = {E. F. Barbosa and R. LeBlanc and M. Guzdial and J. C. Maldonado},
  title = {Introducing Testing Practices into Objects and Design Course},
  pages = {279--285},
  doi = {10.1109/CSEE.2003.1191387},
  abstract = {Though software testing courses are commonly taught as part of Software Engineering curricula,software testing is still a challenging issue in Software Engineering education. Students frequentlysee testing only as something that happens at the end of the development process. Two challengescan be recognized: "How to make the students recognize the relevance of the testing activity?" and"How to motivate the students on using testing ideas in their projects?". In an attempt to explorethe impact of introducing testing practices throughout development, during the past Fall semesterwe modified the project requirements in a course on object-oriented analysis and design offeredto the undergraduate students in Computer Science at Georgia Institute of Technology. Our ideawas to require the students to start thinking about testing as early as possible, by including testing-relatedpractices in all phases of the development process. This paper presents the details of thetesting approach used in the course and discusses the results we obtained, in terms of the students'attitudes and learning.},
  address = {Madrid, Spain},
  booktitle = {16th Conference on Software Engineering Education and Training},
  month = mar,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {2003}
}

@INPROCEEDINGS{barbosa-etal:2003:wtst,
  author = {E. F. Barbosa and R. LeBlanc and M. Guzdial and J. C. Maldonado},
  title = {The Challenge of Teaching Software Testing Earlier into Design Courses},
  address = {Melbourne, FL},
  booktitle = {Workshop on the Teaching of Software Testing (WTST)},
  month = jan,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {2003}
}

@INPROCEEDINGS{Barbosa-Maldonado:2006:IFIP,
  author = {Barbosa, E. F. and Maldonado, José Carlos},
  title = {An Integrated Content Modeling Approach for Educational Modules},
  pages = {17-26},
  doi = {10.1007/978-0-387-34731-8_3},
  abstract = {Educational modules -- concise units of study capable of integrating theoretical/practical contents and supporting tools -- can be seen as relevant mechanisms to facilitate the student's apprenticeship. The establishment of processes and modeling approaches should ease the cooperative work to create, reuse and evolve educational modules, taking also into account the impact on the learning process. There are initiatives to address the problem of modeling educational contents, but none of them provides a complete set of features addressing the conceptual, instructional and didactic perspectives. Moreover, these initiatives do not consider a systematic process for developing educational modules. In this work we summarize the main aspects of a standardized process for developing educational modules we have proposed, focusing on the modeling activity for structuring the learning contents. An integrated modeling approach is presented and its application is illustrated by the development of an educational module for the software testing domain. The material produced has been applied and preliminarily evaluated in terms of the student's attitude toward content, usability and navigational aspects.},
  volume = {210},
  address = {Santiago, Chile},
  booktitle = {IFIP International Conference on Education for the 21st Century - 19th IFIP World Computer Congress (WCC 2006)},
  editor = {Kumar, Deepak and Turner, Joe},
  month = aug,
  owner = {magsilva},
  publisher = {Springer Boston},
  timestamp = {2007.10.10},
  year = {2006}
}

@INCOLLECTION{Barbosa-Maldonado:2011:incollection,
  author = {E. F. Barbosa and J. C. Maldonado},
  title = {Collaborative Development of Educational Modules: a Need for Lifelong Learning},
  booktitle = {E-Infrastructures and Technologies for Lifelong Learning: Next Generation Environments},
  publisher = {IGI Global},
  year = {2011},
  editor = {G. D. Magoulas},
  pages = {175--211},
  address = {London, UK},
  month = apr,
  owner = {magsilva}
}

@INPROCEEDINGS{Barbosa-Maldonado:2008:ISoLA,
  author = {Ellen Francine Barbosa and José Carlos Maldonado},
  title = {Specialization and Instantiation Aspects of a Standard Process for Developing Educational Modules},
  pages = {503--518},
  doi = {10.1007/978-3-540-88479-8_36},
  abstract = {Educational modules can be seen as relevant mechanisms to improve the learning processes in general. The goal is to produce quality educational products, capable of motivating the learners and effectively contribute to their knowledge construction process. Despite their relevance, none of the initiatives to address the problem of creating educational modules considers a systematic process for developing them. The establishment of a well-defined set of guidelines and supporting mechanisms should ease the distributed and cooperative work to create, reuse and evolve educational modules, taking also into account the impact on the learning process. In this work we present a standardized process we have established aiming at creating well-designed, highly flexible and configurable educational modules. We focus on the aspects of process specialization and instantiation, illustrating the practical application of the instantiated process by the development of an educational module for teaching the fundamentals of software testing. Particularly, the availability of learning facilities, allied to the development of testing tools, should facilitate the apprenticeship of specific testing theories and skills, promoting better dissemination conditions to the practical evaluation and application of testing strategies, both in academic and industrial sets. The produced module has been applied and preliminarily evaluated in terms of the learning effectiveness. The results obtained give us some evidences on the practical use of the standard process as a supporting mechanism to the development of effective educational modules.},
  volume = {17},
  series = {Communications in Computer and Information Science},
  address = {Porto Sani, } # Greece,
  booktitle = {International Symposium on Leveraging Applications of Formal Methods, Verification and Validation (ISoLA 2008)},
  editor = {T. Margaria and B. Steffen},
  month = oct,
  owner = {magsilva},
  publisher = {Springer Berlin Heidelberg},
  timestamp = {2010.08.04},
  year = {2008}
}

@INPROCEEDINGS{Barbosa-Maldonado:2006:FIE,
  author = {E. F. Barbosa and J. C. Maldonado},
  title = {Towards the Establishment of a Standard Process for Developing Educational Modules},
  pages = {5--10},
  doi = {10.1109/FIE.2006.322653},
  address = {San Diego, CA, EUA},
  booktitle = {36th Annual Frontiers in Education Conference (FIE 2006)},
  location = {San Diego, CA, EUA},
  month = oct,
  owner = {magsilva},
  publisher = {IEEE},
  timestamp = {2008.07.30},
  year = {2006}
}

@INPROCEEDINGS{Barbosa-Maldonado:2006:WMA,
  author = {Ellen Francine Barbosa and José Carlos Maldonado},
  title = {Establishing a Mutation Testing Educational Module based on {IMA-CID}},
  pages = {14},
  doi = {10.1109/MUTATION.2006.4},
  abstract = {Software testing is one of the most relevant activities regarding system development but, at the same time, it is a difficult topic to learn or teach without the appropriate supporting mechanisms. A learning process of software testing should involve the cooperation of theoretical and experimental knowledge with related tools in order to facilitate the apprenticeship of specific testing theories and skills. In previous works we investigated the establishment of supporting mechanisms for developing educational modules. The idea was contribute to the improvement of learning processes in general by producing quality educational products, capable of motivating the learners and effectively contribute to their knowledge construction process. In this paper we illustrate the application of our ideas in the context of software testing, more specifically by the development of an educational module for mutation testing. We consider mutation testing since it is a sound and powerful approach, but its use is still limited, mainly due to its high cost of application and, also, due to the need of an adequate learning process.},
  address = {Raleigh, NC, EUA},
  booktitle = {2nd Workshop on Mutation Analysis},
  location = {Raleigh, NC, EUA},
  month = nov,
  publisher = {IEEE Computer Society},
  timestamp = {2008.08.01},
  year = {2006}
}

@INPROCEEDINGS{Barbosa-Maldonado:2004,
  author = {Ellen Francine Barbosa and José Carlos Maldonado},
  title = {Mecanismos de apoio à modelagem de conteúdos: uma contribuição ao processo de desenvolvimento de módulos educacionais},
  pages = {339 -- 348},
  abstract = {Módulos educacionais correspondem a unidades de estudo, compostas por conteúdos teóricos integrados a atividades práticas e avaliações, cuja disponibilização aos aprendizes é apoiada por recursos tecnológicos e computacionais. Considerando o desenvolvimento de módulos educacionais, a modelagem dos conteúdos associados representa uma atividade essencial a ser conduzida. Este trabalho visa a investigar mecanismos de apoio à atividade de modela- gem, estabelecendo subsídios para identificação e estruturação de conceitos e informações re- levantes, possibilitando que os mesmos sejam disponibilizados de modo coerente e ordenado. Requisitos e perspectivas de modelagem, associados a um conjunto de modelos genéricos, são estabelecidos a fim de apoiar a construção e análise de modelos para representação de conteúdos. Uma abordagem integrada, reunindo os diversos aspectos de modelagem identi- ficados, também é proposta. A aplicação prática dos mecanismos investigados é ilustrada no desenvolvimento de um módulo educacional para o domínio de Teste de Software.},
  address = {Manaus, AM},
  booktitle = {VX Simpósio Brasileiro de Informática na Educação (SBIE 2004)},
  lang = {pt},
  month = nov,
  owner = {magsilva},
  timestamp = {2008.01.21},
  year = {2004}
}

@RESEARCH-PROJECT{project:Barbosa-Maldonado:1999,
  title = {Educação, treinamento e avaliação no contexto de teste e validação de software},
  author = {Ellen Francine Barbosa and José Carlos Maldonado},
  institution = {Institute of Mathematics Science and Computing -- University of São Paulo},
  number = {98/16490-5},
  funding = {FAPESP},
  month = sep,
  year = {1999},
  howpublished = project
}

@INPROCEEDINGS{Barbosa-etal:2003:CLEI,
  author = {Barbosa, E. F. and Maldonado, J. C. and Maidantchik, C. L. L.},
  title = {Padronização de processos para o desenvolvimento de módulos educacionais},
  pages = {CD-ROM},
  address = {La Paz, Bolívia},
  booktitle = {XXIX Latin-American Conference on Informatics (CLEI'2003)},
  month = sep,
  owner = {magsilva},
  timestamp = {2007.10.10},
  year = {2003}
}

@INPROCEEDINGS{Barbosa-etal:2003:PGLDB,
  author = {E. F. Barbosa and J. C. Maldonado and I. L. M. Ricarte},
  title = {Exploring Learning Objects under Conceptual, Instructional and Didactic Perspectives},
  pages = {33-39},
  abstract = {The idea of Learning Objects - 'any digital resource that can be reused to support learning' - is emerging as a way to reuse learning materials in different settings and contexts. Standardization efforts have also been conducted, especially related to the establishment of learning object metadata, describing the relevant characteristics that a learning object should present. This work aims at exploring learning objects according to the conceptual, instructional and didactic perspectives, which have been investigated in the context of domain modeling for the development of learning materials. Our goal is to investigate the impact of these perspectives into the set of characteristics specified by the standards for Learning Objects Metadata under development.},
  keywords = {Learning Object, Learning Object Metadata, Conceptual Object, Instructional Object, Didactic Object},
  address = {Rio de Janeiro, RJ},
  booktitle = {PGL Database Research Conference (PGL DB)},
  location = {Rio de Janeiro, RJ, Brazil},
  month = apr,
  owner = {magsilva},
  timestamp = {2008.07.30},
  year = {2003}
}

@INPROCEEDINGS{Barbosa-etal:2002,
  author = {Ellen Francine Barbosa and José Carlos Maldonado and Ivan L. M. Ricarte},
  title = {Learning materials: Towards the establishment of guidelines for domain modeling},
  pages = {192--206},
  address = {Florianópolis, SC, Brazil},
  booktitle = {Working Conference on Informatics Curricula, Teaching Methods and best practice (ICTEM)},
  location = {Florianópolis, SC, Brazil},
  month = jul,
  owner = {magsilva},
  timestamp = {2008.01.21},
  year = {2002}
}

@INPROCEEDINGS{barbosa-etal:2000:iwapatv,
  author = {E. F. Barbosa and J. C. Maldonado and A. M. R. Vincenzi},
  title = {Towards the Determination of Sufficient Mutant Operators for {C}},
  address = {Limerick, Ireland},
  booktitle = {First International Workshop on Automated Program Analysis, Testing and Verification},
  month = jun,
  note = {(Special issue of the Software Testing Verification and Reliability Journal, 11(2), 2001 -- To Appear)},
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {2000}
}

@MISC{barbosa-etal:2000:sbes,
  author = {E. F. Barbosa and J. C. Maldonado and A. M. R. Vincenzi and M. E. Delamaro and S. R. S. Souza and M. Jino},
  title = {Introdução ao Teste de Software},
  howpublished = {Minicurso apresentado no XIV Simpósio Brasileiro de Engenharia de Software (SBES 2000)},
  month = oct,
  year = {2000},
  address = {João Pessoa, PB},
  owner = {magsilva},
  pages = {330--378},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{barbosa-etal:2006:seke,
  author = {E. F. Barbosa and E. Y. Nakagawa and J. C. Maldonado},
  title = {Towards the Establishment of an Ontology of Software Testing},
  pages = {522--525},
  address = {San Francisco, CA},
  booktitle = {International Conference on Software Engineering and Knowledge Engineering (SEKE 2006)},
  month = jul,
  note = {Short Paper.},
  owner = {magsilva},
  timestamp = {2008.07.30},
  year = {2006}
}

@INPROCEEDINGS{Barbosa-etal:2008:cseet,
  author = {Ellen Francine Barbosa and Simone Souza and José Carlos Maldonado},
  title = {An Experience on Applying Learning Mechanisms for Teaching Inspection and Software Testing},
  pages = {189--196},
  doi = {10.1109/CSEET.2008.12},
  abstract = {Several initiatives on using new computing technologies have been investigated to facilitate the learning process. The challenge is to provide ways to establish quality educational products, capable of motivating the students and effectively contribute to their knowledge construction process in active learning environments. In this paper we discuss the establishment of mechanisms to ease the development of educational modules. We propose a Standard Process for Developing Educational Modules which takes into account issues of content modeling, practices from instructional design, and aspects of distributed and cooperative work. Also, we propose an Integrated Modeling Approach, introducing the idea of open specifications to provide support for the definition of dynamic contexts of learning. Depending on aspects such as audience, learning goals and course length, distinct ways for presenting and navigating through the same content can be required. An open specification allows representing all sequences of presentation in the same model. From a single model, several versions of the same content can be generated according to different pedagogical aspects. The process and the modeling approach have been applied into the reengineering of learning materials for testing domain. The material produced has been applied in a testing course, offered to undergraduate students in CS at ICMC/USP. To evaluate the effectiveness of learning, we replicate an extended version of the Basili & Selbi experiment, used for comparing testing techniques, into the educational context. The main contribution of our research is to motivate the use of systematic mechanisms for creating well-designed, highly flexible and configurable educational modules. As further work, we intend to provide a context for "open learning materials", which could facilitate the cooperation and use in different institutions and learning environments and effectively support new learning approaches. The establishment of "agile methodologies" for developing and evolving educational modules should also be further explored.},
  address = {Charleston, South Carolina, Unites States},
  booktitle = {Conference on Software Engineering Education and Training (CSEE\&T)},
  month = apr,
  organization = {IEEE-CS},
  timestamp = {2008.08.01},
  topics = {learning object, IMA-CID, software testing, education},
  year = {2008}
}

@INPROCEEDINGS{barbosa-etal:1998:sbes,
  author = {E. F. Barbosa and A. M. R. Vincenzi and J. C. Maldonado},
  title = {Uma Contribuição para a Determinação de um Conjunto Essencial de Operadores de Mutação no Teste de Programas {C}},
  pages = {103--120},
  address = {Maringá, PR},
  booktitle = {XII Simpósio Brasileiro de Engenharia de Software (SBES 98)},
  month = oct,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1998}
}

@TECHREPORT{baresi-young:2001,
  author = {Baresi, Luciano and Young, Michal},
  title = {Test Oracles},
  institution = {University of Oregon, Dept. of Computer and Information Science},
  month = aug,
  year = {2001},
  number = {CIS-TR-01-02},
  address = {Eugene, Oregon, } # USA,
  url = {http://www.cs.uoregon.edu/~michal/pubs/oracles.html},
  pages = {55},
  type = {Technical Report}
}

@INPROCEEDINGS{Barros-Zuffo:2008,
  author = {Barros, Gil and Zuffo, Marcelo K.},
  title = {Proposta de perfis de usuário para a TV interativa no Brasil},
  pages = {264--267},
  abstract = {Usability is based on the knowledge of the user and her tasks. A review of the literature demonstrated that there's little research on users of interactive TV in Brazil. Based on similar work done in foreign countries it was possible to formulate an initial classification, which was extended to incorporate specific requirements for the Brazilian population. The postulated profiles were presented to specialists from the field and the validated and complemented. As result four user profiles for interactive TV in Brazil are presented with their characteristics and usability requirements.},
  keywords = {Brasil, SBTVD, interface com o usuário, perfil de usuário, televisão interativa},
  series = {IHC '08},
  acmid = {1497503},
  address = {Porto Alegre, Brazil, Brazil},
  booktitle = {Proceedings of the VIII Brazilian Symposium on Human Factors in Computing Systems},
  isbn = {978-85-7669-203-4},
  location = {Porto Alegre, RS, Brazil},
  numpages = {4},
  publisher = {Sociedade Brasileira de Computação},
  url = {http://dl.acm.org/citation.cfm?id=1497470.1497503},
  year = {2008}
}

@ARTICLE{Baruque-Melo:2004,
  author = {Lúcia Blondet Baruque and Rubens Nascimento Melo},
  title = {Learning Theory and Instructional Design Using Learning Objects},
  volume = {13},
  number = {4},
  month = oct,
  year = {2004},
  pages = {343--370},
  abstract = {Instructional System Development (ISD) is a set of procedures for systematically designing and developing instruction. A solid foundation in learning theory is an essential element in the application of ISD. One question that one might ask is whether there is one best learning theory for instructional design using learning objects (LOs). Depending on the learners and the situation, different learning theories may apply. The authors do not recommended one particular theory for the design of instruction based on LOs, but rather the adoption of an eclectic approach to learning theory in the design of instruction using LOs. In this work, an overview of the ISD methodology that is based on e-learning Objects (ISDMeLO) is given. This proposed methodology, which incorporates principles from different learning schools, is currently being tested by K-12 teachers from public schools, as well as instructional designers from private companies in Brazil.},
  url = {http://editlib.org/p/7432},
  address = {Norfolk, VA, EUA},
  issn = {1055-8896},
  journal = {Journal of Educational Multimedia and Hypermedia},
  owner = {magsilva},
  publisher = {AACE}
}

@TECHREPORT{Basili:1992:GQM,
  author = {Victor R. Basili},
  title = {Software Modeling and Measurement: The Goal/Question/Metric Paradigm},
  institution = {University of Maryland},
  month = sep,
  year = {1992},
  number = {CS-TR-2956, UMIACS-TR-92-96},
  address = {College Park, MD, } # USA,
  url = {http://www.cs.umd.edu/~basili/publications/technical/T78.pdf},
  abstract = {This paper discusses the use of the Goal/Question/Metric paradigm as a mechanism for defining and interpreting software measurement. Templates are provided for defining goals and generating questions. Different types of metrics are discussed. Examples of both process and product goals are defined},
  pages = {24}
}

@INBOOK{basili-etal:1984,
  chapter = {The Experience Factory},
  pages = {469-476},
  title = {Encyclopedia of Software Engineering},
  publisher = {John Wiley \& Sons},
  year = {1984},
  editor = {John J. Marciniak},
  author = {V. R. Basili and G. Caldeira and H. D. Rombach},
  owner = {magsilva},
  timestamp = {2006.09.12}
}

@TECHREPORT{basili-caldiera:1995,
  author = {Basili, Victor R. and Caldiera, Gianluigi},
  title = {The experience factory: strategy and practice},
  institution = {University of Maryland},
  month = nov,
  year = {1995},
  address = {College Park, MD, USA},
  abstract = {The quality movement, that has had in recent years a dramatic impact on all industrial sectors, has recently reached the system and software industry. Although some concepts of quality management, originally developed for other product types, can be applied to software, its specificity as a product which is developed and not produced requires a special approach. This paper introduces a quality paradigm specifically tailored on the problem of the systems and software industry. Reuse of products, processes and experiences originating from the system life cycle is seen today as a feasible solution to the problem of developing higher quality systems at a lower cost. In fact, quality improvement is very often achieved by defining and developing an appropriate set of strategic capabilities and core competencies to support them. A strategic capability is, in this context, a corporate goal defined by the business position of the organization and implemented by key business processes. Strategic capabilities are supported by core competencies, which are aggregate technologies tailored to the specific needs of the organization in performing the needed business processes. Core competencies are non-transitional, have a consistent evolution, and are typically fueled by multiple technologies. Their selection and development requires commitment, investment and leadership. The paradigm introduced in this paper for developing core competencies is the Quality Improvement Paradigm which consists of six steps: (1) Characterize the environment, (2) Set the goals, (3) Choose the process, (4) Execute the process, (5) Analyze the process data, and (6) Package experience. The process must be supported by a goal oriented approach to measurement and control, and an organizational infrastructure, called Experience Factory. The Experience Factory is a logical and physical organization distinct from the project organizations it supports. Its goal is development and support of core competencies through capitalization and reuse of its cycle experience and products. The paper introduces the major concepts of the proposed approach, discusses their relationship with other approaches used in the industry, and presents a case in which those concepts have been successfully applied.},
  publisher = {University of Maryland at College Park},
  source = {Univ. of Maryland Institute for Advanced Computer Studies Report No. UMIACS-TR-95-67}
}

@INCOLLECTION{Basili-etal:1994,
  author = {Victor R. Basili and Gianluigi Caldiera and H. Dieter Rombach},
  title = {The Goal Question Metric Approach},
  booktitle = {Encyclopedia of Software Engineering},
  publisher = {Wiley},
  year = {1994}
}

@ARTICLE{Basili84SECE,
  author = {V. R. Basili and B. T. Perricone},
  title = {Software Errors and Complexity: An Empirical Study},
  volume = {27},
  number = {1},
  month = jan,
  year = {1994},
  pages = {42--52},
  journal = comacm,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@BOOK{basili-etal:2007,
  title = {Empirical Software Engineering Issues: Critical Assessment and Future Directions},
  publisher = {Springer},
  year = {2007},
  author = {Victor R. Basili and Dieter Rombach and Kurt Schneider and Barbara Kitchenham and Dietmar Pfahl and Richard W. Selby},
  volume = {4336},
  pages = {192},
  series = {Lecture Notes in Computer Science},
  address = {Dagstuhl Castle, Germany},
  month = jun,
  booktitle = {International Workshop},
  doi = {10.1007/978-3-540-71301-2},
  journal = {International Workshop}
}

@ARTICLE{basili-etal:1986,
  author = {Victor R. Basili and Richard W. Selby and David H. Hutchens},
  title = {Experimentation in Software Engineering},
  volume = {12},
  number = {7},
  month = jul,
  year = {1986},
  pages = {733--743},
  journal = {IEEE Transactions of Software Engineering},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@ARTICLE{Basili-etal:1999,
  author = {V. R. Basili and F. Shull and F. Lanubile},
  title = {Building knowledge through families of experiments},
  volume = {25},
  number = {4},
  month = jul,
  year = {1999},
  pages = {456-474},
  journal = {IEEE Transactions of Software Engineering},
  owner = {magsilva},
  timestamp = {2010.08.09}
}

@BOOK{Bass-etal:2003,
  title = {Software Architecture in Practice},
  publisher = {Addison-Wesley Professional},
  year = {2003},
  author = {Len Bass and Paul Clements and Rick Kazman},
  isbn = {0321154959},
  file = {C\:\\Documents and Settings\\Administrador\\Meus documentos\\USP\\documentos_jabref\\Addison Wesley - Software Architecture in Practice, 2nd.chm:C\:\\Documents and Settings\\Administrador\\Meus documentos\\USP\\documentos_jabref\\Addison Wesley - Software Architecture in Practice, 2nd.chm:PDF},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@MISC{batista:2005,
  author = {Jorge Chami Batista},
  title = {Efeitos econômicos, tecnológicos e sociais da TV Digital no Brasil: alternativas para transmissão terrestre},
  year = {2005},
  owner = {magsilva},
  timestamp = {2008.01.21}
}

@TECHREPORT{Baudry-Monperrus:2012,
  author = {Benoit Baudry and Martin Monperrus},
  title = {Towards Ecology Inspired Software Engineering},
  institution = {Informatics Mathematics (Inria)},
  month = may,
  year = {2012},
  number = {RR-7952},
  address = France,
  url = {http://arxiv.org/abs/1205.1102v2},
  abstract = {Ecosystems are complex and dynamic systems. Over billions of years, they have developed advanced capabilities to provide stable functions, despite changes in their environment. In this paper, we argue that the laws of organization and development of ecosystems provide a solid and rich source of inspiration to lay the foundations for novel software construction paradigms that provide stability as much as openness.},
  keywords = {software engineering, ecology, empirical study},
  issn = {0249-6399},
  owner = {magsilva},
  timestamp = {2014.02.22}
}

@INPROCEEDINGS{baxter:2002,
  author = {Ira D. Baxter},
  title = {Branch Coverage Tools for Arbitrary Languages Made Easy},
  address = {San Francisco, California, USA},
  booktitle = {Quality Week 2002},
  month = sep,
  owner = {magsilva},
  timestamp = {2010.05.14},
  url = {http://www.soft.com/QualWeek/QW2002/papers/8T1.html},
  year = {2002}
}

@MISC{bbc:2002,
  author = {{BBC}},
  title = {{BBC-i} Interactive Television Style Guide},
  howpublished = standard,
  month = aug,
  year = {2002},
  pages = {54},
  timestamp = {2012.02.10}
}

@BOOK{Beauchamp:1968,
  title = {Curriculum Theory},
  publisher = {Kagg},
  year = {1968},
  author = {George A. Beauchamp},
  pages = {186},
  address = {Wilmette, IL, USA},
  edition = {2},
  booktitle = {Curriculum Theory},
  timestamp = {2012.01.31}
}

@MISC{software:phpdocumentor,
  author = {Gregory Beaver and Joshua Eichorn},
  title = {phpDocumentor},
  howpublished = {Programa de computador},
  year = {2000},
  owner = {magsilva},
  timestamp = {2006.11.06},
  url = {http://www.phpdoc.org}
}

@INPROCEEDINGS{beck:2003,
  author = {H. Beck},
  title = {Fine-grained Representation of Educational Content based on Ontologies},
  pages = {105-110},
  address = {Rio de Janeiro, RJ},
  booktitle = {I PGL DB Research Conference (PGL DB 2003)},
  month = apr,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {2003}
}

@BOOK{Beck:2002,
  title = {Test-Driven Development: By Example},
  publisher = {Addison-Wesley Professional},
  year = {2002},
  author = {Kent Beck},
  isbn = {978-0321146533},
  pages = {240},
  address = USA,
  edition = {1},
  month = nov,
  abstract = {Quite simply, test-driven development is meant to eliminate fear in application development. While some fear is healthy (often viewed as a conscience that tells programmers to "be careful!"), the author believes that byproducts of fear include tentative, grumpy, and uncommunicative programmers who are unable to absorb constructive criticism. When programming teams buy into TDD, they immediately see positive results. They eliminate the fear involved in their jobs, and are better equipped to tackle the difficult challenges that face them. TDD eliminates tentative traits, it teaches programmers to communicate, and it encourages team members to seek out criticism However, even the author admits that grumpiness must be worked out individually! In short, the premise behind TDD is that code should be continually tested and refactored. Kent Beck teaches programmers by example, so they can painlessly and dramatically increase the quality of their work.}
}

@BOOK{Beck:1999,
  title = {{eXtreme Programming} Explained: Embrace Change},
  publisher = {Addison-Wesley},
  year = {1999},
  author = {Kent Beck},
  isbn = {978-0201616415},
  pages = {224},
  series = {XP Series},
  address = USA,
  edition = {1},
  month = oct,
  abstract = {The new concept of Extreme Programming (XP) is gaining more and more acceptance, partially because it is controversial, but primarily because it is particularly well-suited to help the small software development team succeed. This book serves as the introduction to XP that the market will need. XP is controversial, many software development sacred cows don't make the cut in XP; it forces practitioners to take a fresh look at how software is developed. The author recognizes that this "lightweight" methodology is not for everyone. However, anyone interested in discovering what this new concept can offer them will want to start with this book.}
}

@ARTICLE{Beck99ECEP,
  author = {K. Beck},
  title = {Embracing Change with Extreme Programming},
  volume = {32},
  number = {10},
  year = {1999},
  pages = {70--77},
  journal = ieeec,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@MISC{software:xvidcap,
  author = {Karl H. Beckers and others},
  title = {xvidcap},
  howpublished = software,
  month = sep,
  year = {2003},
  owner = {magsilva},
  timestamp = {2010.08.26},
  url = {http://sourceforge.net/projects/xvidcap/}
}

@INPROCEEDINGS{begosso:2003,
  author = {L. R. Begosso and L. V. L. Filgueiras},
  title = {{Resultados da Implantação do Ambiente de Desenvolvimento de Maturidade em Engenharia de Software}},
  pages = {51--59},
  booktitle = {{XI Workshop sobre Educação em Computação, XXIII Congresso da Sociedade Brasileira de Computação}},
  owner = {magsilva},
  timestamp = {2008.07.30},
  year = {2003}
}

@BOOK{Beizer:1990,
  title = {Software Testing Techniques},
  publisher = {International Thomson Computer},
  year = {1990},
  author = {Boris Beizer},
  isbn = {978-1850328803},
  pages = {580},
  address = USA,
  edition = {2},
  month = jun,
  timestamp = {2009.04.17}
}

@BOOK{Beizer84SSTQ,
  title = {Software System Testing and Quality Assurance},
  publisher = {Van Nostrand Reinhold Company},
  year = {1984},
  author = {B. Beizer},
  address = {New York},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@ARTICLE{Belda:2010,
  author = {Francisco Rolfsen Belda},
  title = {Estrutura de conteúdos educativos para TV Digital: um modelo de referência},
  volume = {5},
  number = {1},
  month = sep # {--} # dez,
  year = {2010},
  pages = {120--143},
  abstract = {O trabalho propõe um modelo estrutural de conteúdos educativos para televisão digital interativa, de modo a fornecer subsídios e referências para processos colaborativos de produção de conteúdos em redes e comunidades de aprendizagem associadas a canais universitários e educativos de televisão. São definidos termos, atores, eventos, ambientes, categorias, classes e atributos de conteúdo, com indicação de critérios para sua vinculação síncrona ou assíncrona numa programação, além de requisitos e funções computacionais básicas para sua veiculação seletiva, adaptativa e participativa através de mídias digitais. O modelo é apresentado de forma descritiva e também visual, por meio de mapas conceituais inter-relacionados. Os resultados indicam que o uso interativo da televisão digital na educação depende de modelos sistematizados de conteúdo, que contemplem a participação comunitária na produção e veiculação de mídias, superando a comunicação vertical, centralizada e hierarquizada, tradicional da radiodifusão.},
  keywords = {TV digital; Aprendizagem colaborativa; Modelagem de conteúdo; Educação a distância},
  abstract-en = {This paper proposes a model of educative content structuring for interactive digital television programs. Its intent was to provide references for collaborative production processes and content organization in learning networks associated with university and educative television broadcasting services. The model defines terms, actors, events, environments, as well as content categories, classes and attributes, indicating criteria for their synchronic or asynchronic association in a dynamic television schedule. The model is presented in both descriptive and visual formats, with the use of conceptual maps. The results indicate that interactive use of digital television in education requires systematic content models covering communitarian participation in both media production and distribution processes, in order to enhance learning instruments beyond vertical, hierarchical and centralized communication sustained by traditional broadcast channels.},
  issn = {2236-8000},
  journal = {Revista Comunicação Midiática},
  keywords-en = {Digital television; Collaborative learning; Content modeling; Distance education},
  publisher = {UNESP},
  title-en = {Educational content structuring for Digital Television: a reference model}
}

@PHDTHESIS{Belda:2009,
  author = {Francisco Rolfsen Belda},
  title = {Um modelo estrutural de conteúdos para televisão digital interativa},
  abstract = {O trabalho propõe um modelo de estrutura de conteúdos educativos para programas interativos de televisão digital. Seu propósito é fornecer referências para processos colaborativos de produção e organização de conteúdo em redes de aprendizagem coligadas a emissoras de televisão educativa e universitária. A elaboração do modelo teve por base uma revisão bibliográfica de teorias, conceitos e práticas, bem como uma pesquisa-ação com grupos de ensino médio e superior. Sua concepção toma como hipótese a carência de modelos de referência nessa área e contempla a coexistência de aspectos formais e informais de educação, a arquitetura e prática das redes sociais e ambientes de aprendizagem, bem como pontos de inovação em relação a modelos tradicionais de comunicação. São definidos termos, atores, eventos, ambientes, categorias, classes e atributos de conteúdo, com indicação de critérios para sua vinculação síncrona ou assíncrona numa programação, além de requisitos e funções computacionais básicas para sua veiculação seletiva, adaptativa e participativa através de mídias digitais. O modelo é apresentado em duas formas: descritiva, por meio de definições, sentenças e quadros de classificação; e visual, por meio de mapas conceituais inter-relacionados. Uma experiência para validação do modelo proposto foi feita mediante a prototipagem de um ambiente televisivo de ensino-aprendizagem de Engenharia de Produção, com emprego de linguagens que compõem o middleware Ginga (NCL e LUA). A aplicação simula uma fábrica virtual com ambientes em três dimensões que dão acesso a vídeos educativos e conteúdos associados. Os resultados das práticas de modelagem e de prototipagem são avaliados a partir de seus objetivos iniciais e perspectivas de aprimoramento. São propostas possíveis extensões e especificações do modelo com vistas a seu aprimoramento e aplicação. Sustenta-se, por fim, que esse uso interativo da televisão digital na educação depende de modelos sistematizados de conteúdo que contemplem a participação comunitária na produção e veiculação de mídias, com o fortalecimento dos instrumentos de aprendizagem para além da comunicação vertical, centralizada e hierarquizada dos canais tradicionais de radiodifusão.},
  keywords = {Televisão digital. Modelo de conteúdo. Interatividade. Redes de aprendizagem},
  school = {Universidade de São Paulo},
  year = {2009},
  address = {São Carlos, SP, } # Brazil,
  abstract-en = {This research proposes a model to educative content structuring for interactive digital television programs. The intent is to provide references for collaborative production processes and content organization in learning networks associated with university and educative television broadcast services. Modelling activity was preceded by critical literature review, considering theories, concepts and practices reported, in parallel with a collaborative action research. The research conception took as hypothesis the lack of reference models applied to this context and considers the coexistence of formal, informal and non-formal learning and educational aspects; architecture and daily practices in social networks and learning environments; and innovations over traditional communication models. The model defines terms, actors, events, environments, as well as content categories, classes and attributes, indicating criteria for their synchronic or asynchronic association in a dynamic television grid. Basic computational requirements and functions for selective, flexible and participative content distribution through convergent digital media were also indicated. The model is presented in two complementary frames. One is descriptive and uses definitions, sentences and structured tables. The other is visual and uses interconnected conceptual maps. An experimental validation of the proposed model was made through the prototyping of a television learning environment oriented to Industrial Engineering education, developed with the use of programming languages (NCL and LUA) according to the brazilian's middleware specifications (Ginga). This application simulates a factory in a virtual 3D enviroment leading to educative videos and their associated contents. Modeling and prototyping outcomes are evaluated considering initial objectives and improvement perspectives. Possible modeling extensions and specifications are proposed and discussed targeting its further developments and effective application. The results indicate that interactive use of digital television in education requires systematic content models covering communitarian participation in both media production and distribution processes, in order to enhance learning instruments beyond vertical, hierarchical and centralized communication sustained by traditional broadcast channels.},
  keywords-en = {Content modeling; Interactive television; Learning networks},
  note = Advisor # {: Edson Walmir Cazarini},
  title-en = {An educative content structure model for interactive television}
}

@MISC{software:ffmpeg,
  author = {Fabrice Bellard and Michael Niedermayer and others},
  title = {{FFmpeg}},
  howpublished = software,
  year = {2000},
  abstract = {FFmpeg is a complete, cross-platform solution to record, convert and stream audio and video. It includes libavcodec - the leading audio/video codec library. See the documentation for a complete feature list and the Changelog for recent changes.},
  url = {http://www.ffmpeg.org/}
}

@BOOK{belloni:2006,
  title = {Educação a Distância},
  publisher = {Autores Associados},
  year = {2006},
  author = {Maria Luiza Belloni},
  isbn = {978-85-85701-77-2},
  pages = {124},
  series = {Coleção Educação Contemporânea},
  address = {São Paulo, } # Brazil,
  edition = {5},
  month = apr,
  booktitle = {Educação a Distância},
  timestamp = {2008.09.18}
}

@ARTICLE{Bellotti-etal:2011,
  author = {F. Bellotti and R. Berta and A. De Gloria and A. Ozolina},
  title = {Investigating the added value of interactivity and serious gaming for educational {TV}},
  volume = {57},
  number = {1},
  year = {2011},
  pages = {1137--1148},
  doi = {10.1016/j.compedu.2010.11.013},
  abstract = {TV is a medium with high penetration rates and has been suited to deliver informal education in several aspects since years. Thus, interactive TV may play a significant role in the current Life-Long Learning challenges, provided that meaningful applications are implemented. In this research work, we have explored the added value of interactivity in digital TV, with a particular focus on Serious Games (SGs), given their growing relevance in technology-enhanced learning. We have followed an evolutionary rather than revolutionary approach, in particular given the still traditional use of TV by a large audience. The approach preserves a media-driven strategy and the role of the author/director in proposing contents (storytelling), as in the TV tradition. We argue that interactive SGs may help the viewer to better contextualize/understand the video stream and go more in depth about the touched items at the end of the stream. This also enables new iTV applications, in particular to support weaker users (i.e. users that could not view the video without a help). This paper presents the results from user tests based on an interactive enhancement of a clip from the Disney's Snow White movie, that challenged the authors in addressing a dynamic, high-value document. Qualitative and quantitative results show the potential of the system for informal education. The tests also stress the importance of good solutions (e.g., development languages, display modalities, metaphors) for synchronizing video and overlaid interactive elements. To the best of our knowledge, this research work is the first one discussing user test results about the usefulness of a class of iTV SG applications that can be instantiated serially in several different contexts.},
  keywords = {Interactive TV; Serious games; TV-based learning; t-Learning; User tests; User centered design; Television; Digital TV},
  issn = {0360-1315},
  journal = {Computers \& Education}
}

@INPROCEEDINGS{Bellotti-etal:2006,
  author = {Bellotti, F. and Mikulecka, J. and Napoletano, L. and Rohrova, H.},
  title = {Designing a constructionistic framework for t-learning},
  pages = {549-554},
  abstract = {iDTV is a promising platform for education, since it can reach a large number of people and provide computing and communication interactivity. However, a number of key issues have yet to be faced, in a variety of fields, such as pedagogy, digital signal processing, and Human-Computer Interaction. Starting from pedagogical principles rooted in the constructionism theory, the ELU IST project presents a t-learning framework where learners are involved in compelling educational games through iDTV and engaged in their actual construction as well. © Springer-Verlag Berlin Heidelberg 2006.},
  keywords = {Communication systems; Digital signal processing; Education; Human computer interaction; Project management, Constructionism; Gaming; iDTV; MHP; t-learning, Learning systems},
  volume = {4227},
  series = {Lecture Notes on Computer Science},
  booktitle = {1st European Conference on Technology Enhanced Learning},
  isbn = {9783540457770},
  issn = {03029743},
  lang = {en},
  location = {Crete, Greece},
  month = oct,
  publisher = {Springer},
  references = {Rizzo, A., Brunk, J., Molari, G., Napoletano, L., Toccafondi, G., Designing a knowledge building community (2005) The Passion for Learning and Knowing. Proc. 6th Int. Conf. Organizational Learning and Knowledge, 2, pp. 208-226. , Gherardi, S., Nicolini, D. (eds) Univ. of Trento e-books, Trento; Bates, P., (2003) T-learning Study - A Study into TV-based Interactive Learning to the Home, , Final Report, pjb Associates, UK; Salomon, G., The differential investment of mental effort in learning from different sources (1983) Educational Psychologist, 18 (1), pp. 42-50; http://www.elu-project.com/Masthoff, J., Pemberton, L., (2003) Adaptive Learning Via Interactive Television, , University of Brighton; Bruner, J., (1996) The Culture of Education, , Harvard University Press; Coombs, P.H., Presser, R.C., Ahmed, M., (1973) New Paths to Learning for Rural Children and Youth, , UNICEF Int. Council Educational Development; Atwere, D., Bates, P., (2003) Interactive TV: A Learning Platform with Potential, , Learning and Skills Development Agency; Lave, J., Wenger, E., (1991) Situated Learning: Legitimate Peripheral Participation, , Cambridge University Press, Cambridge; Bellotti, F., Berta, R., Ferretti, E., DeGloria, A., Margarone, M., (2003) VeGame: Field Exploration of Art and History in Venice, , IEEE Computer; Bellotti, F., De Gloria, A., Ferretti, E., Discovering the European heritage through the ChiKho educational web game (2005) INTETAIN 2005},
  year = {2006}
}

@ARTICLE{Bellotti-etal:2008a,
  author = {Francesco Bellotti and Stefanos Vrochidis and Eirini Parissi and Pascal Lhoas and Damien Mathevon and Matteo Pellegrino and Giancarlo Bo, Ioannis Kompatsiaris},
  title = {A T-learning Courses Development and Presentation Framework},
  volume = {3},
  number = {3},
  month = sep,
  year = {2008},
  pages = {69-76},
  issn = {1558-7908},
  journal = {IEEE Multidisciplinary Engineering Education Magazine},
  lang = {en},
  publisher = {IEEE Education Society},
  timestamp = {2012.02.03}
}

@INPROCEEDINGS{Bellotti-etal:2008b,
  author = {Bellotti, F. and Vrochidis, S. and Tsampoulatidis, I. and Bo, G. and Napoletano, L.},
  title = {A learning oriented technological framework for {iDTV}},
  pages = {79-86},
  doi = {10.1109/AXMEDIS.2008.30},
  abstract = {This paper proposes an open flexible learning oriented technological framework for interactive Digital TV (iDTV). The framework is designed to satisfy the pedagogical requirements and deal with the iDTV capabilities and constraints. The framework includes two main products: the authoring tool, where the course is prepared and the Course Multimedia Player, which is capable of presenting the course in an iDTV environment. The proposed approach has been validated in a simulation and real iDTV Set-Top Box (STB) environment.},
  keywords = {Digital television, Authoring tools; Digital TV; Technological frameworks, Television broadcasting},
  address = {Florença, } # Italy,
  booktitle = {4th International Conference on Automated Solutions for Cross Media Content and Multi-Channel Distribution},
  isbn = {9780769534060},
  publisher = {IEEE},
  references = {Multimedia Home Platform (MHP), , http://www.mhp.org, retrieved March, 2008 from; Digital Video Broadcasting, , http://www.dvb.org, retrieved March, 2008, from; Lytras, M., Lougos, C., Chozos, P., Pouloudi, A., Interactive Television and E-learning Convergence: Examining the Potential of T-learning (2002) ECEL2002, The European Conference on e-learning, , Brunel University, UK; Wathieu, L, & Zoglio, M. TiVo in 2002: Consumer Behavior, Harvard Business School Case 502-062, 2002Lekakos, G., Giaglis, G., Delivering personalized advertisements in digital television: A methodology and empirical evaluation (2002) Proceedings of the AH 2002 Workshop on Personalization in Future TV, , Malaga, Spain; Kenyon, B., Miles, A., Rose, J., Unscrambling Digital TV (2000) The McKinsey Quarterly; Wiley, D.A., Connecting learning objects to instructional design theory: A definition, a metaphor, and a taxonomy (2000) The Instructional Use of Learning Objects, , Wiley, D. A, Ed; Lopez-Nores, M., Elexpuru-Eguia, A., Blanco-Fernandez, Y., Pazos-Arias, J.J., Gil-Solla, A., Garcia-Duque, J., Barragans-Martinez, B., Ramos-Cabrer, M., A Technological Framework for TV-supported Collaborative Learning (2004) Proceedings of the IEEE Sixth International Symposium on Multimedia Software Engineering (ISMSE'04); Vrba, V., Cvrk, L., Sykora, M., Framework for digital TV applications (2006) Proceedings of the International Conference on Networking, International Conference on Systems and International Conference on Mobile Communications and Learning Technologies table of contents, p. 184. , Page:, ISBN:0-7695-2552-0; Composer, middleware Ginga - NCL, , http://www.ncl.org.br/index_.html; http://www.oratrix.com/Products/G2E, Grins Pro EditorL. Soares and G. Filho, Interactive Television in Brazil: System Software and the Digital Divide, EURO ITV 2007, Amsterdam, the Netherlands, May 24-25, 2007The Synchronized Multimedia Integration Language, , http://www.w3.org/AudioVideo; http://www.elu-project.com, Enhanced Learning Unlimited (ELU) project. Retrieved March, 2008, from},
  year = {2008}
}

@MISC{Bender98STES,
  author = {{BENDER \& Associates Inc.}},
  title = {{S}oft{T}est},
  year = {1998},
  owner = {magsilva},
  timestamp = {2008.07.31},
  url = {http://www.softtest.com/ftp/demo/st53demo.zip}
}

@INPROCEEDINGS{benitti:2008,
  author = {Fabiane Barreto Vavassori Benitti and Jefferson Seide Molléri},
  title = {Utilização de um RPG no Ensino de Gerenciamento e Processo de Desenvolvimento de Software},
  pages = {258-267},
  address = {Belém, Pará, Brasil},
  booktitle = {Workshop sobre Educação em Computação},
  month = jul,
  owner = {magsilva},
  timestamp = {2008.07.24},
  year = {2008}
}

@BOOK{Berard92EOOS,
  title = {Essays on Object-Oriented Software Engineering},
  publisher = {Prentice-Hall Inc},
  year = {1992},
  author = {E. V. Berard},
  volume = {1},
  address = {Englewood Cliffs, New Jersey},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@MISC{project:pedagogicalpatterns,
  author = {Joseph Bergin and Jutta Eckstein and Mary-Lynn Manns and Helen Sharp and Markus Voelter and Eugene Wallingford and Klaus Marquardt and Jane Chandler and Astrid Fricke},
  title = {The Pedagogical Patterns Projects},
  howpublished = {Projeto},
  year = {2000},
  owner = {magsilva},
  timestamp = {2007.10.10},
  url = {http://www.pedagogicalpatterns.org/}
}

@MISC{eduplop:2003,
  author = {Joseph Bergin and Fred Grossman and Jutta Eckstein and Eugene Wallingford},
  title = {Towards EduPLoP},
  howpublished = {Chamada de trabalhos},
  year = {2003},
  owner = {magsilva},
  timestamp = {2007.09.12},
  url = {http://csis.pace.edu/~bergin/towardEduPLoP/}
}

@ARTICLE{Berglund-etal:2006,
  author = {Berglund, Aseel and Berglund, Erik and Larsson, Anders and Bang, Magnus},
  title = {Paper remote: an augmented television guide and remote control},
  volume = {4},
  number = {4},
  month = may,
  year = {2006},
  pages = {300--327},
  doi = {10.1007/s10209-004-0108-8},
  abstract = {The television (TV) is one of the most common entertainment devices in homes. Searching and finding TV programs is a common task and using TV guides is one way of performing this. This paper presents three studies that are focused on examining audiences' TV habits and TV guide usage, evaluating a new concept based on linking paper and pen with TV technology, and studying the audiences' attitudes toward and anticipated interest in the future guide. The results of our first study emphasize the value of using paper based TV guides and also identify the deficiencies. We also found indications that the advantages and disadvantages of paper-based TV guides are related to the physical properties of paper. Thus, we suggest a solution that uses digital pen and paper technology to offer a new interaction method for TV. A research system 'Paper Remote', is developed and used in the two subsequent studies. Viewers tick designated areas on the paper-based guide to perform actions such as channel switching. However, this solution is not a substitute for the remote control device. We argue that these user studies on linking digital paper to the TV for everyday information navigation illuminate the possibilities of providing innovative solutions also for home information systems also.},
  keywords = {Electronic program guides, Home information system, Interactive Paper interfaces},
  address = {Berlin, } # Germany,
  issn = {1615-5289},
  journal = {Universal Access in the Information Society},
  publisher = {Springer-Verlag}
}

@ARTICLE{Berglund-Johansson:2004,
  author = {Berglund, Aseel and Johansson, Pontus},
  title = {Using speech and dialogue for interactive TV navigation},
  volume = {3},
  number = {3},
  month = oct,
  year = {2004},
  pages = {224--238},
  doi = {10.1007/s10209-004-0106-x},
  abstract = {Interaction techniques for interactive television (iTV) are currently complex and difficult to use for a wide-range of viewers. Few previous studies have dealt with the potential benefits of multimodal dialogue interaction in the context of iTV for the purpose of flexibility, usability, efficiency, and accessibility. This paper investigates the benefits of introducing speech and connected dialogue for iTV interaction, and presents a case study in which a prototype system was built allowing users to navigate the information space and control the operation of the TV by a speech-based natural language interface. The system was evaluated by analysing the user experience in five categories capturing essential aspects of iTV interaction: interaction style, information load, data access, effectiveness and initiative. Design considerations relevant for speech and dialogue information systems for TV interfaces also emerged from the analysis.},
  keywords = {Electronic program guide, Speech interaction, Universal access, iTV},
  address = {Berlin, } # Germany,
  issn = {1615-5289},
  journal = {Univers. Access Inf. Soc.},
  publisher = {Springer}
}

@BOOK{berlack:1992,
  title = {Software Configuration Managment},
  publisher = {John Wiley \& Sons},
  year = {1992},
  author = {H. Ronald Berlack},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@INPROCEEDINGS{Berlanga-Garcia:2005,
  author = {Adriana J. Berlanga and Francisco J. García},
  title = {Authoring tools for adaptive learning designs in computer-based education},
  pages = {190--201},
  doi = {10.1145/1111360.1111380},
  address = {New York, NY, USA},
  booktitle = {Latin American Conference on Human-computer Interaction},
  isbn = {1-59593-224-0},
  location = {Cuernavaca, Mexico},
  owner = {magsilva},
  publisher = {ACM},
  year = {2005}
}

@MISC{software:cvs,
  author = {Brian Berliner and Jim Kingdon},
  title = {Concurrent Versions System ({CVS})},
  howpublished = software,
  month = apr,
  year = {1989},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://cvshome.org}
}

@ARTICLE{berman:2008,
  author = {Sally D. Berman},
  title = {The Return of Educational Radio?},
  volume = {9},
  number = {2},
  month = jun,
  year = {2008},
  url = {http://www.irrodl.org/index.php/irrodl/article/view/563/1038},
  journal = {The International Review of Research in Open and Distance Learning},
  owner = {magsilva},
  timestamp = {2009.02.20}
}

@MISC{berners-lee:1989,
  author = {Timothy J. Berners-Lee},
  title = {Information Management: A Proposal},
  month = mar,
  year = {1989},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@ARTICLE{Berners01SWEB,
  author = {Timothy J. Berners-Lee and L. Hendler and O. Lassila},
  title = {The Semantic WEB},
  volume = {284},
  number = {5},
  month = may,
  year = {2001},
  pages = {34--43},
  journal = {Scientific American},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@INPROCEEDINGS{bernhaupt-etal:2010a,
  author = {Bernhaupt, Regina and Linard, Nicolas and Mirlacher, Thomas},
  title = {Integrating internet-based services in IPTV: an interaction concept},
  pages = {233--236},
  doi = {10.1145/1941007.1941050},
  abstract = {The integration of Internet-based services in interactive TV (iTV) has been a focus of research in human-computer interaction for the last 15 years. With new services like Twitter or Facebook there is again the trend to combine Internet and TV -- either directly on the TV or via a settop box (STB) supporting the Internet Protocol (IP). This demonstration shows an interaction concept, which allows users to easily access Internet services. The demonstration is based on a flash prototype in combination with a fully functional two-way infrared remote control including fingerprint recognition.s},
  keywords = {IPTV, interaction concept, web services},
  address = {New York, NY, USA},
  booktitle = {Conference Internationale Francophone sur I'Interaction Homme-Machine},
  isbn = {978-1-4503-0410-8},
  location = {Luxembourg, Luxembourg},
  publisher = {ACM},
  year = {2010}
}

@INPROCEEDINGS{bernhaupt-etal:2010b,
  author = {Bernhaupt, Regina and Weiss, Astrid and Pirker, Michael and Wilfinger, David and Tscheligi, Manfred},
  title = {Ethnographic insights on security, privacy, and personalization aspects of user interaction in interactive TV},
  pages = {187--196},
  doi = {10.1145/1809777.1809817},
  abstract = {User interaction for interactive TV (iTV) services becomes a critical aspect in the design of new iTV and Internet Protocol TV (IPTV) offers. New services like social TV, direct image and data up- and download from the set-top box, connectivity of the iTV system to the PC and other mobile media devices, pose the question on how to support security, privacy, and personalization. To investigate the (sometimes naïve) concepts of users of what changes an interactive TV system will bring in terms of security and privacy for their living room behaviors, and how to best support these aspects in the user interaction, an ethnographic study with 40 households (126 participants) was conducted. We investigated users' assumptions and ideas on the concepts of security, privacy and personalization using a combination of playful probing and an interview at the start and the end of the study. Findings show that households are not aware of possible problems in terms of security and privacy, before the introduction of interactive TV. This work presents user generated ideas on how to improve security aspects on the TV, user's perception on identification mechanisms for TV services, and summarizes ethnographic insights found in the study.},
  keywords = {ethnography, iPTV, iTV, living room, playful probing, privacy, remote control, security},
  address = {New York, NY, USA},
  booktitle = {8th international interactive conference on Interactive TV \& Video},
  isbn = {978-1-60558-831-5},
  location = {Tampere, Finland},
  numpages = {10},
  publisher = {ACM},
  year = {2010}
}

@INPROCEEDINGS{bertolino:2007,
  author = {Antonia Bertolino},
  title = {Software Testing Research: Achievements, Challenges, Dreams},
  pages = {1-19},
  booktitle = {Future of Software Engineering (FOSE'07)},
  owner = {magsilva},
  timestamp = {2009.08.18},
  year = {2007}
}

@MISC{bessani:2000,
  author = {Alysson Neves Bessani},
  title = {Uma Arquitetura Baseada na Web para um Ambiente de Engenharia de Software Orientado a Processos},
  howpublished = {Relatório de Iniciação Científica},
  year = {2000},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@INPROCEEDINGS{Betella-Lazzari:2007,
  author = {Betella, Alberto and Lazzari, Marco},
  title = {Podcast generator and pluriversiradio: an educational interactive experience},
  pages = {649--652},
  abstract = {This paper presents an open source podcast publishing application which has been implemented to create an educational podcasting service at the University of Bergamo (Italy) and has subsequently been adopted by several universities and other podcasters in Italy and abroad.},
  keywords = {distance education, distance learning, educational podcasting, free software, mobile learning, open source, podcast publishing},
  series = {INTERACT'07},
  acmid = {1778417},
  address = {Berlin, Heidelberg},
  booktitle = {11th IFIP TC 13 international conference on Human-computer interaction},
  isbn = {978-3-540-74799-4},
  location = {Rio de Janeiro, RJ, Brazil},
  numpages = {4},
  publisher = {Springer-Verlag},
  url = {http://portal.acm.org/citation.cfm?id=1778331.1778417},
  year = {2007}
}

@INPROCEEDINGS{Bethard-etal:2009,
  author = {Bethard, Steven and Wetzer, Philipp and Butcher, Kirsten and Martin, James H. and Sumner, Tamara},
  title = {Automatically characterizing resource quality for educational digital libraries},
  pages = {221--230},
  doi = {10.1145/1555400.1555436},
  abstract = {With the rise of community-generated web content, the need for automatic characterization of resource quality has grown, particularly in the realm of educational digital libraries. We demonstrate how identifying concrete factors of quality for web-based educational resources can make machine learning approaches to automating quality characterization tractable. Using data from several previous studies of quality, we gathered a set of key dimensions and indicators of quality that were commonly identified by educators. We then performed a mixed-method study of digital library curation experts, showing that our characterization of quality captured the subjective processes used by the experts when assessing resource quality for classroom use. Using key indicators of quality selected from a statistical analysis of our expert study data, we developed a set of annotation guidelines and annotated a corpus of 1000 digital resources for the presence or absence of these key quality indicators. Agreement among annotators was high, and initial machine learning models trained from this corpus were able to identify some indicators of quality with as much as an 18% improvement over the baseline.},
  keywords = {educational digital library, learning resource, machine learning, quality},
  series = {JCDL '09},
  booktitle = {9th ACM/IEEE-CS joint conference on Digital libraries},
  isbn = {978-1-60558-322-8},
  lang = {en},
  location = {Austin, TX, #USA#},
  publisher = {ACM},
  year = {2009}
}

@MISC{software:testng,
  author = {Cédric Beust},
  title = {TestNG},
  howpublished = {Programa de Computador},
  month = apr,
  year = {2004},
  owner = {magsilva},
  timestamp = {2006.10.03},
  url = {http://testng.org/}
}

@MISC{Bianchini-etal:2003,
  author = {S. L. Bianchini and E. F. Barbosa and J. C. Maldonado},
  title = {Disponibilização de Ferramentas de Teste de Software via {Web}},
  howpublished = {Trabalho de Iniciação Científica, ICMC-USP},
  year = {2003},
  address = {São Carlos, SP},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{bianco-etal:2010,
  author = {del Bianco, Vieri and Lavazza, Luigi and Morasca, Sandro and Taibi, Davide and Tosi, Davide},
  title = {The QualiSPo approach to OSS product quality evaluation},
  pages = {23--28},
  doi = {10.1145/1833272.1833277},
  address = {New York, NY, USA},
  booktitle = {3rd International Workshop on Emerging Trends in Free/Libre/Open Source Software Research and Development (FLOSS '10)},
  isbn = {978-1-60558-978-7},
  location = {Cape Town, South Africa},
  publisher = {ACM},
  year = {2010}
}

@INPROCEEDINGS{Bieman01TMJO,
  author = {J. M. Bieman and S. Ghosh and R. T. Alexander},
  title = {A Technique for Mutation of Java Objects},
  pages = {23--26},
  address = {San Diego, CA},
  booktitle = {16th IEEE Internation Conference on Automated Software Engineering},
  month = nov,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {2001}
}

@ARTICLE{bigelow:1988,
  author = {James Bigelow},
  title = {Hypertext and CASE},
  volume = {5},
  number = {2},
  month = mar,
  year = {1988},
  pages = {23 - 27},
  doi = {10.1109/52.2007},
  journal = {IEEE Software},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@BOOK{biggs-tang:2007,
  title = {Teaching for Quality Learning at University},
  publisher = {Open University Press},
  year = {2007},
  author = {John Biggs and Catherine Tang},
  pages = {360},
  edition = {3}
}

@BOOK{binder:1999,
  title = {Testing Object-Oriented Systems: Models, Patterns, and Tools},
  publisher = {Addison Wesley Longman, Inc.},
  year = {1999},
  author = {R. V. Binder},
  volume = {1},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@MISC{Binder96FATO,
  author = {R. V. Binder},
  title = {The {FREE} Approach to Testing Object-Oriented Software: An Overview},
  year = {1996},
  note = {http://www.rbsc.com/pages/FREE.html},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@ARTICLE{Binder96MTSO,
  author = {R. V. Binder},
  title = {Modal Testing Strategies for {OO} Software},
  volume = {29},
  number = {11},
  month = nov,
  year = {1996},
  pages = {97--99},
  journal = {Computer},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@ARTICLE{Binder95SBTE,
  author = {R. V. Binder},
  title = {State-Based Testing},
  volume = {5},
  number = {6},
  month = jul # {/} # aug,
  year = {1995},
  journal = {Object Magazine},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@ARTICLE{Binder94DTOO,
  author = {R. V. Binder},
  title = {Design for Testability in Object Oriented Systems},
  volume = {37},
  number = {9},
  month = sep,
  year = {1994},
  pages = {87--101},
  journal = comacm,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@ARTICLE{Binder94TOOS,
  author = {R. V. Binder},
  title = {Testing Object-Oriented Systems: A Status Report},
  volume = {7},
  number = {4},
  month = apr,
  year = {1994},
  pages = {22--28},
  journal = {American Programmer},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{Binkley99CAPS,
  author = {D. W. Binkley},
  title = {Computing Amorphous Program Slices Using Dependence Graphs and a Data-Flow Model},
  pages = {519--525},
  address = {New York, NY},
  booktitle = {ACM Symposium on Applied Computing},
  owner = {magsilva},
  publisher = {ACM Press},
  timestamp = {2008.07.31},
  year = {1999}
}

@TECHREPORT{Biolchini-etal:2005,
  author = {Jorge Biolchini and Paula Gomes Mian and Ana Candida Cruz Natali and Guilherme Horta Travassos},
  title = {Systematic Review in Software Engineering},
  institution = {COPPE/UFRJ},
  month = may,
  year = {2005},
  number = {RT-ES 679/05},
  address = {Rio de Janeiro, RJ, } # Brazil,
  url = {http://alarcos.inf-cr.uclm.es/doc/MetoTecInfInf/Articulos/es67905.pdf},
  owner = {magsilva},
  timestamp = {2007.08.20},
  type = {Technical Report}
}

@PHDTHESIS{Bird:2010,
  author = {Bird, Christian Alma},
  title = {Sociotechnical Coordination and Collaboration in Open Source Software},
  abstract = {Over the past decade, a new style of software development, termed open source software (OSS) has emerged and has yielded large, mature, stable, and widely used software projects. As software continues to grow in size and complexity, so do development teams. Consequently, coordination and communication within these teams play larger roles in productivity and software quality. This work focuses on the relationships between developers in large open source projects and how software affects and is affected by these relationships. Fortunately, source code repository histories, mailing list archives, and bug databases from OSS projects contain latent data from which we can reconstruct a rich view of a project over time and analyze these sociotechnical relationships. In this dissertation, we present methods of obtaining and analyzing this data as well as the results of empirical studies whose goal is to answer questions that can help software project leaders understand and make decisions about their own teams. (1) We present our research on mining OSS communication and coordination, and use properties of the communication social networks to characterize the relationship between participants social and development behavior. (2) We present methods for recovering artifacts such as patch contributions from project mailing lists and determining if they were accepted. (3) We perform a quantitative analysis of the important factors in uencing the immigration of an OSS participant from a bystander on the periphery to a full edged, core developer, with write access to the source. (4) We examine the social structure of a number of OSS projects. We find that much like large commercial software endeavors, there are teams of developers working together on common tasks. Further, the type of communication (highly technical versus policy related) is strongly related to the organization structure. (5) We show that collaboration history combined with technical relationships (such as dependencies within software) can be used to predict which components of a system will be the most failure prone, with higher accuracy than previous methods. (6) We study distributed development in three large projects: Windows Vista, Firefox, and Eclipse. We characterize the level of geographic and organizational distribution and examine the relationship between distributed development and software quality (7) We perform an analysis of code ownership on the same three projects and show how the relationship between ownership and quality is affected by the development style used. Taken together, these chapters provide an understanding of the collaboration processes at work in OSS (and in some cases commercial) projects and also give researchers tools and techniques that they can use to gather and analyze data to answer related questions.},
  school = {University of California at Davis},
  year = {2010},
  advisor = {Devanbu, Premkumar T.},
  address = {Davis, CA, } # USA,
  isbn = {978-1-124-31550-8},
  owner = {magsilva},
  publisher = {University of California at Davis},
  timestamp = {2014.08.01}
}

@MISC{bird,
  author = {Richard Bird},
  title = {Site de Richard Bird},
  year = {2002},
  note = {\url{http://web.comlab.ox.ac.uk/oucl/people/richard.bird.html} (19/09/2002)},
  organization = {Oxford University},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {\url{http://web.comlab.ox.ac.uk/oucl/people/richard.bird.html} (19/09/2002)}
}

@MISC{xmlschema-2:2004,
  author = {Paul V. Biron and Ashok Malhotra},
  title = {XML Schema Part 2: Datatypes},
  howpublished = {W3C Recommendation},
  month = oct,
  year = {2004},
  comment = {24/05/2005},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://www.w3.org/TR/xmlschema-2/}
}

@MISC{software:festival,
  author = {Alan W Black and Rob Clark and Korin Richmond and Volker Strom and Simon King and Heiga Zen and Paul Taylo and Richard Caley},
  title = {Festival},
  howpublished = {Programa de computador},
  month = {apr},
  year = {1996},
  owner = {magsilva},
  timestamp = {2007.08.13},
  url = {http://www.cstr.ed.ac.uk/projects/festival/, http://festvox.org/festival/}
}

@ARTICLE{BlancoFernandez-etal:2011,
  author = {Blanco-Fernández, Yolanda and López-Nores, Martín and Gil-Solla, Alberto and Ramos-Cabrer, Manuel and Pazos-Arias, José J.},
  title = {User-generated contents and reasoning-based personalization: Ingredients for a novel model of mobile TV},
  volume = {38},
  number = {5},
  month = may,
  year = {2011},
  pages = {5289--5298},
  doi = {10.1016/j.eswa.2010.10.029},
  abstract = {During the last years, we have witnessed the boom of the digital market due to the proliferation of emergent audiovisual services and the increasing number of broadband networks. In this scenario, users insistently demand innovative services for exchanging and sharing their own audiovisual contents. In order to meet these needs, in this paper we propose a system that broadcasts user-generated audiovisual contents for handheld devices in a mobile network based on the DVB-H broadcasting standard. Besides, our system offers diverse added-value services to these new active users, such as: (i) multi modal access (via Web or by client applications running locally in handheld devices) to digital contents, (ii) exploitation of return channels to transmit interactive contents that enhance the user's experience, and (iii) annotation, sharing and personalized distribution of audiovisual contents. To achieve these goals, our system adopts well-known technologies for broadcasting and semantic annotation of audiovisual contents, as well as emergent technology from the so-called Web 2.0. A prototype of our system has been experimentally evaluated with a group of students from the University of Vigo, who were enthusiastic about the personalization capabilities offered by our TV system for a mobile setting.},
  keywords = {Mobile TV, Personalization, User-driven content generation, Web 2.0},
  address = {Tarrytown, NY, USA},
  issn = {0957-4174},
  journal = {Expert Systems with Applications: An International Journal},
  publisher = {Pergamon}
}

@INPROCEEDINGS{BlancoFernandez-etal:2008a,
  author = {Blanco-Fernández, Yolanda and Pazos-Arias, José J. and Gil-Solla, Alberto and Ramos-Cabrer, Manuel and López-Nores, Martín},
  title = {ZapTV: Personalized User-Generated Content for Handheld Devices in DVB-H Mobile Networks},
  pages = {193--203},
  doi = {10.1007/978-3-540-69478-6_26},
  abstract = {During the last years, we had witnessed the boom of the digital market due to proliferation of emergent audiovisual services and increasing number of broadband networks. In this scenario, users insistently demand for innovative services for exchanging and sharing their own audiovisual contents and productions. In order to meet these needs, in this paper we propose the ZapTV system. Broadly speaking, this tool broadcasts user-generated audiovisual contents for handheld devices in a mobile network based on the DVB-H broadcasting standard. ZapTV offers diverse added-value services to these new active users, such as: (i) multi modal access (via Web and by handheld devices) to digital contents anywhere and anytime, (ii) availability of a return channel to transmit interactive contents that enhance the user's viewing experience, and (iii) annotation, sharing and personalized distribution of audiovisual contents. To achieve these goals, our system adopts both well-known technologies for broadcasting and semantic annotation of audiovisual contents (such as DVB-H and TV-Anytime), and emergent technology from the so-called Web 2.0, which permit the users to actively cooperate in tasks of generation, annotation and classification of digital contents.},
  address = {Berlin, Heidelberg},
  booktitle = {Proceedings of the 6th European conference on Changing Television Environments},
  isbn = {978-3-540-69477-9},
  location = {Salzburg, Austria},
  publisher = {Springer},
  year = {2008}
}

@ARTICLE{BlancoFernandez-etal:2008b,
  author = {Blanco-Fernández, Yolanda and Pazos-Arias, José J. and Gil-Solla, Alberto and Ramos-Cabrer, Manuel and López-Nores, Martín and García-Duque, Jorge and Fernández-Vilas, Ana and Díaz-Redondo, Rebeca P. and Bermejo-Muñoz, Jesús},
  title = {An MHP framework to provide intelligent personalized recommendations about digital TV contents},
  volume = {38},
  number = {9},
  month = jul,
  year = {2008},
  pages = {925--960},
  doi = {10.1002/spe.v38:9},
  abstract = {Digital Television will bring a significant increase in the amount of channels and programs available to end users, with many more difficulties to find contents appealing to them among a myriad of irrelevant information. Thus, automatic content recommenders should receive special attention in the following years to improve their assistance to users. The current content recommenders have important deficiencies that hamper their wide acceptance. In this paper, we present a new approach for automatic content recommendation that significantly reduces those deficiencies. This approach, based on Semantic Web technologies, has been implemented in the AdVAnced Telematic search of Audiovisual contents by semantic Reasoning tool, a hybrid content recommender that makes extensive use of well-known standards, such as Multimedia Home Platform, TV-Anytime and OWL. Also, we have carried out an experimental evaluation, the results of which show that our proposal performs better than other existing approaches.},
  keywords = {MHP, Semantic Web, automatic content recommenders, digital TV},
  address = {New York, NY, USA},
  issn = {0038-0644},
  journal = {Software Practice \& Experience},
  publisher = {John Wiley \& Sons}
}

@ARTICLE{Blevis-Stolterman:2009,
  author = {Blevis, Eli and Stolterman, Erik},
  title = {Transcending disciplinary boundaries in interaction design},
  volume = {16},
  number = {5},
  month = sep # {-} # oct,
  year = {2009},
  pages = {48--51},
  doi = {10.1145/1572626.1572636},
  address = {New York, NY, EUA},
  issn = {1072-5520},
  journal = {Interactions},
  publisher = {ACM}
}

@INPROCEEDINGS{blois-etal:2007,
  author = {M. Blois and Rafael Prikladnicki and Leticia Lopes Leite and Andreia Ferreira Ramos},
  title = {CaseLearn: A Web-based Tool to Support Case-based Corporate Training using Learning Objects},
  pages = {437-440},
  address = {Edinburg},
  booktitle = {International Conference on Web-based Learning},
  month = aug,
  note = {Poster session (207)},
  year = {2007}
}

@BOOK{Bloom-etal:1956,
  title = {Taxonomy of Educational Objectives: The Classification of Educational Goals (Handbook 1: Cognitive Domain)},
  publisher = {Longmans, Green and Co},
  year = {1956},
  author = {Benjamin S. Bloom and Max D. Engelhart and Edward J. Furst and Walker H. Hill and David R. Krathwohl},
  editor = {Benjamin S. Bloom},
  pages = {207},
  address = {Ann Arbor, Michigan, EUA},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@BOOK{Bloom-etal:1983,
  title = {Manual de Avaliação Formativa e Somativa do Aprendizado Escolar},
  publisher = {Livraria Pioneira},
  year = {1983},
  author = {Benjamin S. Bloom and J. Thomas Hastings and George F. Madaus},
  pages = {307},
  address = {São Paulo, SP, Brazil},
  note = {Traduzido do original ``Handbook on Formative and Summative Evaluation of Student Learning'' (1971) por Lilian. R. Quintão, Maria. C. F. Flores e Maria E. Vanzolini.},
  booktitle = {Manual de Avaliação Formativa e Somativa do Aprendizado Escolar}
}

@INCOLLECTION{Blumschein:2008,
  author = {Blumschein, Patrick},
  title = {Model-Centered Learning and Instructional Design},
  booktitle = {Understanding Models for Learning and Instruction},
  publisher = {Springer},
  year = {2008},
  editor = {Ifenthaler, Dirk and Pirnay-Dummer, Pablo and Spector, J. Michael},
  chapter = {13},
  pages = {247--275},
  address = USA,
  abstract = {This chapter discusses how the approach of mental models can be applied to Instructional Design (ID) and eventually leads to a theoretical concept of model-centered Instructional Design. The various critiques of Instructional Design which describe ID as too fixed, slow and which doubt that there is room for ID in the Information Society, will serve as the starting point for the discussion. This contribution takes up these critical views and opens up a look at ID from a modelcentered perspective. The argumentation starts out with a reference to the underlying epistemological foundations and is based on the fundamental understanding of human cognition as the construction of mental models when confronted with more or less complex challenges. Further-on the application of the concept of mental models to learning and Instruction is the 'building block' to ID. Thus ID is understood as a higher-order process of model construction. Thereby the approach of mental models can lead to a new perspective on Instructional Design, which can successfully defend against the critiques of Information Technologists. However, Model-Centered Instructional Design may help to see existing excellent layouts of ISD products from another perspective, which helps to understand the mystery of the human learning processes more precisely than other can do. The question if this leads to a paradigm shift in Educational Science hasn't been answered yet.},
  doi = {10.1007/978-0-387-76898-4_13},
  isbn = {978-0-387-76898-4},
  keyword = {Humanities, Social Sciences and Law}
}

@MISC{xquery:2005,
  author = {Scott Boag and Don Chamberlin and Mary F. Fernández and Daniela Florescu and Jonathan Robie and Jérôme Siméon},
  title = {XQuery 1.0: An XML Query Language},
  howpublished = {W3C Working},
  month = apr,
  year = {2005},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://www.w3.org/TR/xquery/}
}

@BOOK{Boehm:1981,
  title = {Software Engineering Economics},
  publisher = {Prentice-Hall},
  year = {1981},
  author = {Barry Boehm},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@ARTICLE{Boehm-Basili:2001,
  author = {B. Boehm and V. R. Basili},
  title = {Software defect reduction top 10 list},
  volume = {34},
  number = {1},
  year = {2001},
  pages = {135-137},
  doi = {10.1109/2.962984},
  journal = {Computer},
  owner = {magsilva},
  timestamp = {2009.04.22}
}

@INCOLLECTION{Boehm:1975,
  author = {Barry W. Boehm},
  title = {Software Design and Structuring},
  booktitle = {Practical Strategies for Developing Large Software Systems},
  publisher = {Addison-Wesley},
  year = {1975},
  pages = {103--128},
  owner = {magsilva},
  timestamp = {2014.10.23}
}

@INPROCEEDINGS{Boehm:1976,
  author = {B. W. Boehm and J. R. Brown and M. Lipow},
  title = {Quantitative evaluation of software quality},
  pages = {592-605},
  address = {Los Alamitos, CA, USA},
  booktitle = {ICSE '76: Proceedings of the 2nd international conference on Software engineering},
  owner = {magsilva},
  publisher = {IEEE Computer Society Press},
  timestamp = {2006.09.12},
  year = {1976}
}

@INPROCEEDINGS{boender-etal:2006,
  author = {Jaap Boender and Roberto Di Cosmo and Berke Durak and Xavier Leroy and Fabio Mancinelli and Mario Morgado and David Pinheiro and Ralf Treinen and Paulo Trezentos and Jérôme Vouillon},
  title = {News from the EDOS project: improving the maintenance of free software distributions},
  address = {Porto Alegre, RS, Brazil},
  booktitle = {Workshop de Software Livre},
  owner = {magsilva},
  timestamp = {2010.03.29},
  year = {2006}
}

@INPROCEEDINGS{Bohl-etal:2002,
  author = {Bohl, Oliver and Schellhase, Jörg and Sengler, Ruth and Winand, Udo},
  title = {The Sharable Content Object Reference Model (SCORM) -- A Critical Review},
  pages = {950-951},
  abstract = {Learning technology standards are increasingly gaining in importance in the field of Web-based teaching. At present, two standards dominating the market are taking shape. These are the SCORM standard of the ADL initiative and the AICC standard of the AICC organization. Based on the AICC and LOM meta data standards, the SCORM standard stands the chance to become the standard dominating the market. A number of restrictions are involved with the SCORM standard, though. The article shows general deficiencies of the SCORM standard that are critical concerning the market value of SCOs, the process of producing WBTs on the basis of different SCO providers, the maintenance of SCOs and WBTs (consisting of several SCOs), and the quality of WBTs based on SCOs of different providers.},
  series = {ICCE '02},
  acmid = {839253},
  address = {Washington, DC, USA},
  booktitle = {International Conference on Computers in Education (ICCE'02)},
  isbn = {0-7695-1509-6},
  location = {Auckland, New Zealand},
  month = dec,
  publisher = {IEEE},
  year = {2002}
}

@MISC{software:reload,
  author = {University of Bolton},
  title = {{RELOAD}},
  howpublished = {Programa de computador},
  month = oct,
  year = {2002},
  timestamp = {2008.09.27},
  url = {http://www.reload.ac.uk}
}

@INPROCEEDINGS{bompani:2000,
  author = {Luca Bompani and Paolo Ciancarini and Fabio Vitali},
  title = {Sophisticated hypertext functionalities for Software Engineering},
  pages = {67-79},
  address = {Limerick, Ireland},
  booktitle = {3rd International Workshop on Software Engineering over the Internet},
  owner = {magsilva},
  publisher = {ACM Press},
  timestamp = {2008.07.30},
  year = {2000}
}

@ARTICLE{Bond-etal:2008,
  author = {Stephen T. Bond and Caroline Ingram and Steve Ryan},
  title = {Reuse, repurposing and learning design - Lessons from the DART project},
  volume = {50},
  number = {2},
  month = feb,
  year = {2008},
  pages = {601 - 612},
  doi = {10.1016/j.compedu.2007.09.019},
  abstract = {Digital Anthropological Resources for Teaching (DART) is a major project examining ways in which the use of online learning activities and repositories can enhance the teaching of anthropology and, by extension, other disciplines. This paper reports on one strand of DART activity, the development of customisable learning activities that can be repurposed for use in multiple contexts. Three examples of these activities are described and, based on their use and reuse, some key lessons for the learning technology community are identified. In particular, it is argued that repurposing is a route to successful reuse, and that engaging the teacher in a participative design process is an essential part of the repurposing process.},
  keywords = {Authoring tools and methods, media in education, post-secondary education, simulations, teaching/learning strategies},
  issn = {0360-1315},
  journal = {Computers \& Education},
  lang = {en},
  publisher = {Springer}
}

@PHDTHESIS{Boot:2005,
  author = {Eduardus Willem Boot},
  title = {Building-block solutions for developing instructional software},
  school = {Open Universiteit Nederland},
  year = {2005},
  advisor = {Merriënboer, J. J. G. van},
  address = {Heerlen, } # Netherlands,
  month = dec,
  url = {http://www.ou.nl/documents/Promoties-en-oraties/Promoties/Promoties2005/Eddy_Boot_proefschrift.pdf},
  isbn = {9789090200583}
}

@ARTICLE{bordini2001fsm,
  author = {R. H. Bordini and R. Vieira and A. F. Moreira},
  title = {Fundamentos de sistemas multiagentes},
  volume = {2},
  year = {2001},
  pages = {3--41},
  journal = {Anais do XXI Congresso da Sociedade Brasileira de Computação (SBC2001)},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@MISC{borges:2008:qualimestrado,
  author = {Vanessa Araujo Borges},
  title = {Uma Contribuição ao Desenvolvimento de Ferramentas de Apoio à Modelagem e Geração de Conteúdos Educacionais},
  howpublished = {Monografia de Qualificação de Mestrado},
  month = mar,
  year = {2008},
  note = {Orientadora: Ellen Francine Barbosa},
  timestamp = {2008.08.06}
}

@MISC{borges:2007:projetomestrado,
  author = {Vanessa Araujo Borges},
  title = {Uma Contribuição ao Desenvolvimento de Ferramental de Apoio à Modelagem de Conteúdos Educacionais},
  howpublished = {Projeto de Mestrado},
  year = {2007},
  owner = {magsilva},
  timestamp = {2008.01.21}
}

@INPROCEEDINGS{Borges-etal:2011,
  author = {Vanessa Araujo Borges and José Carlos Maldonado and Ellen Francine Barbosa},
  title = {Towards the Establishment of Supporting Mechanisms for Modeling and Generating Educational Content},
  pages = {1202--1207},
  doi = {10.1145/1982185.1982448},
  abstract = {Content modeling plays a fundamental role in the development of educational modules, helping the author to determine the main concepts to be taught and providing a systematic way to structure the relevant parts of the knowledge domain. Despite its relevance, there are few approaches for modeling educational content. In this perspective, an integrated approach for content modeling, named IMA--CID, was proposed. IMA--CID is composed of a set of models, each one considering specific aspects of the development of educational content; however, applying it without an automated support can be an error-prone activity. Motivated by this scenario, in this paper we describe IMATool -- a supporting tool for content modeling, particularly designed for helping the open and distributed construction of the EMAIL@IMA--CID models. Mechanisms for content generation are also available. We illustrate our ideas by applying IMA--CID and IMATool in the development of an educational module for the software testing domain. The preliminary results obtained provide evidences on the practical use of such mechanisms for modeling and generating content.},
  address = {TaiChung, Taiwan},
  booktitle = {Symposium On Applied Computing},
  isbn = {978-1-4503-0113-8},
  publisher = {ACM},
  year = {2011}
}

@MISC{software:trac,
  author = {Jonas Borgstr\"om and Daniel Lundin and Rocky Burt and Christopher Lenz and Francois Harvey},
  title = {Trac},
  howpublished = {Programa de Computador},
  month = feb,
  year = {2004},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://www.edgewall.com/trac/}
}

@INPROCEEDINGS{bor:2000,
  author = {L. A. Bortoli and A. M. Price},
  title = {Um Método para Auxiliar a Definição de Requisitos},
  pages = {1-12},
  address = {Cancun-México},
  booktitle = {IDEAS 2000: Jornada Ibero Americana de Ingeneria de Requisitos Y Ambientes de Software},
  owner = {magsilva},
  publisher = {IDEAS 2000: Jornada Ibero Americana de Ingeneria de Requisitos Y Ambientes de Software},
  timestamp = {2008.07.30},
  year = {2000}
}

@MISC{css21:2004,
  author = {Bert Bos and Tantek Çelik and Ian Hickson and Håkon Wium Lie},
  title = {Cascading Style Sheets, level 2 revision 1},
  howpublished = {W3C Candidate Recommendation},
  month = feb,
  year = {2004},
  comment = {24/05/2005},
  file = {Cascading Style Sheets, level 2 revision 1.pdf:Cascading Style Sheets, level 2 revision 1.pdf:PDF},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://www.w3.org/TR/CSS21/}
}

@MANUAL{xml:1998,
  title = {Extensible Markup Language (XML) 1.0},
  author = {Jon Bosak and others},
  organization = {W3C},
  edition = {1},
  month = feb,
  year = {1998 },
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@BOOK{Bossuet:1982,
  title = {L'Ordinateur á I'École -- Le Système {LOGO}},
  publisher = {Presses Universitaires de France},
  year = {1982},
  author = {Gérard Bossuet},
  isbn = {2130384382},
  pages = {236},
  address = France,
  booktitle = {L'Ordinateur á I'École -- Le Système {LOGO}},
  lang = {fr}
}

@INPROCEEDINGS{Bottaci01GAFF,
  author = {L. Bottaci},
  title = {A Genetic Algorithm Fitness Function for Mutation Testing},
  address = {Toronto, Ontario, Canada},
  booktitle = {SEMINAL'2001 -- First International Workshop on Software Engineering using Metaheuristic INnovative ALgorithms},
  month = may,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {2001}
}

@ARTICLE{Botturi:2006,
  author = {Botturi, Luca},
  title = {E2ML: A Visual Language for the Design of Instruction},
  volume = {54},
  number = {3},
  year = {2006},
  pages = {265-293},
  doi = {10.1007/s11423-006-8807-x},
  abstract = {The last decade has brought about a major change in higher education. Course design has developed from a craftsmanship-like process to a structured production, which involves interdisciplinary teams and requires more complex communication skills. This conceptual article introduces E2ML -- Educational Environment Modeling Language -- a visual language for supporting complex instructional design processes. E2ML can be used for visualizing the intermediate and final results of design, thus providing documentation in a shared language that can enhance team communication, improve design, and contribute to the development of high-quality instruction. The language and its formal features are presented from a conceptual point of view and illustrated by examples. The main results of a first evaluation study are reported, and the exploitation of E2ML in practice as well as its costs and benefits are critically discussed.},
  keywords = {Instructional Design, visual language, conceptual language, notation system, design communication},
  affiliation = {University of Lugano NewMinE Lab and the e-Learning Applications Lab (eLab) Switzerland},
  issn = {1042-1629},
  issue = {3},
  journal = {Educational Technology Research and Development},
  keyword = {Humanities, Social Sciences and Law},
  lang = {en},
  note = {10.1007/s11423-006-8807-x},
  publisher = {Springer}
}

@ARTICLE{Bourda-etal:2010,
  author = {Yolaine Bourda and Gilles Gauthier and Rosa-Maria Gomez de Regil and Olivier Catteau},
  title = {Métadonnées derramar ressources d'apprentissage (MLR) -- Nouvelle norme {ISO} de description de ressources pédagogiques},
  volume = {17},
  year = {2010},
  pages = {1-11},
  abstract = {Cet article présente la nouvelle norme ISO de description de ressources pédagogiques et plus particulièrement sa partie 1 qui décrit la façon de spécifier les éléments de données ainsi que les profils d'application},
  keywords = {métadonnées, ressource pédagogique, standard, norme},
  url = {http://sticef.univ-lemans.fr/num/vol2010/08r-bourda/sticef_2010_bourda_08r.htm},
  abstract-en = {This paper presents the new ISO Standard for the description of learning resources and more particularly it's part 1 that describes how to specify data elements and application profiles.},
  issn = {1764-7223},
  journal = {Sciences et Techniques de l'Information et de la Communication pour l'Éducation et la Formation (STICEF)},
  keywords-en = {metadata, learning resource, standard},
  lang = {fr},
  title-en = {Metadata for Learning Resources (MLR) - New ISO standard for description of educational resources}
}

@ARTICLE{Bourque99GSEB,
  author = {P. Bourque and R. Dupuis and A. Abran and J. W. Moore and L. L. Tripp},
  title = {{The Guide to the Software Engineering Body of Knowledge}},
  volume = {16},
  month = nov # {--} # dec,
  year = {1999},
  pages = {35--44},
  journal = {IEEE Software},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@INPROCEEDINGS{Bouzeghoub-etal:2003,
  author = {Amel Bouzeghoub and Claire Carpentier and Bruno Defude and Freddy Duitama},
  title = {A Model of Reusable Educational Components for the Generation of Adaptive Courses},
  pages = {1-4},
  abstract = {In the last few years the problem of developing sequencing of course material has become an important research issue, particularly the standardization of metadata for educational resources. Our work aims at providing an environment of authoring and presentation of pedagogical multimedia contents adapted to the end-user. This environment must increase the productivity of the teacher by supporting the reuse of contents already developed in other contexts (by him/her or others). This goal is achieved by means of a model of educational components. In this paper, we define a set of operators used to build courses by assembly of components. The courses thus defined are then instantiated for each learner according to his/her profile. To classify component our approach uses an ontology to describe the domain model, where each node represents a concept. There exists several kinds of hierarchical and rhetorical relationships between concepts in the domain model.},
  booktitle = {First International Workshop on Semantic Web for Web-based Learning},
  timestamp = {2012.01.24},
  year = {2003}
}

@BOOK{Boyd-Apps:1980,
  title = {Redefining the discipline of adult education},
  publisher = {Proquest Info \& Learning},
  year = {1980},
  author = {Robert Dean Boyd and Jerold W. Apps},
  isbn = {978-0835749336},
  pages = {219},
  address = {EUA}
}

@ARTICLE{Boyle:2010,
  author = {Tom Boyle},
  title = {Layered learning design: Towards an integration of learning design and learning object perspectives},
  volume = {54},
  number = {3},
  year = {2010},
  pages = {661 - 668},
  doi = {10.1016/j.compedu.2009.09.026},
  abstract = {The use of ICT to enhance teaching and learning depends on effective design, which operates at many levels of granularity from the small to the very large. This reflects the range of educational problems from course design down to the design of activities focused on specific learning objectives. For maximum impact these layers of design need to be co-ordinated effectively. This paper delineates a reference model of 'layered learning design' where designs at one layer should use and incorporate designs from lower (more specific) layers in elegant and powerful ways. This would allow different designers, or tutors, to focus on different levels of abstraction in the learning design process, and to collaborate in combining designs to make a substantial impact on practice. The paper first delineates a model of the different layers of learning design. These layers range from the strategic structuring of learning activity (to achieve high-level goals) down to the design for basic learning activities. The paper then tackles the issue of the integration of this model with a major 'aggregation' model for learning objects. The essential insight is that learning objects should be viewed as instances of learning designs. This leads to a combined reference model where there is a correspondence between learning designs and learning object types at each layer. Finally, the paper applies the combined model to map some major contributions to learning design research and development.},
  keywords = {Learning design, Learning objects, Authoring tools and methods},
  issn = {0360-1315},
  journal = {Computers \& Education}
}

@ARTICLE{Boyle:2003,
  author = {T. Boyle},
  title = {Design principles for authoring dynamic, reusable learning objects},
  volume = {19},
  year = {2003},
  pages = {46-58},
  abstract = {The aim of this paper is to delineate a coherent framework for the authoring of re-purposable learning objects. The approach is orthogonal to the considerable work into learning object metadata and packaging conducted by bodies such as IMS, ADL and the IEEE. The 'learning objects' and standardisation work has been driven largely by adding packaging and metadata to pre-constructed learning artefacts. This work is very valuable. The argument of this paper, however, is that these developments must be supplemented by significant changes in the creation of learning objects. The principal aim of this paper is to delineate authoring principles for reuse and repurposing. The principles are based on a synthesis of ideas from pedagogy and software engineering. These principles are outlined and illustrated from a case study in the area of learning to program in Java.},
  url = {http://www.ascilite.org.au/ajet/ajet19/boyle.html},
  journal = {Australian Journal of Educational Technology},
  timestamp = {2008.09.26}
}

@ARTICLE{Boyle:2002,
  author = {Tom Boyle},
  title = {Towards a theoretical base for educational multimedia design},
  volume = {2},
  month = jul,
  year = {2002},
  pages = {1-16},
  journal = {Journal of Interactive Media in Education},
  timestamp = {2008.09.26}
}

@INPROCEEDINGS{Boyle-etal:2006,
  author = {Tom Boyle and John Cook and Richard Windle and Heather Wharrad and Dawn Leeder and Rob Alton},
  title = {An Agile method for developing learning objects},
  pages = {91-99},
  address = {Sidney, Austrália},
  booktitle = {Annual ASCIIlite Conference: Who's learning? Whose technology?},
  owner = {magsilva},
  timestamp = {2008.09.26},
  year = {2006}
}

@INPROCEEDINGS{bozzon-etal:2006:icwe,
  author = {Alessandro Bozzon and Sara Comai and Piero Fraternali and Giovanni Toffetti Carughi},
  title = {Conceptual modeling and code generation for rich internet applications},
  pages = {353-360},
  doi = {10.1145/1145581.1145649},
  address = {Palo Alto, California, EUA},
  booktitle = {International Conference on Web Engineering (ICWE)},
  publisher = {ACM},
  timestamp = {2009.02.05},
  year = {2006}
}

@INPROCEEDINGS{bozzon-etal:2006:www,
  author = {Alessandro Bozzon and Sara Comai and Piero Fraternali and Giovanni Toffetti Carughi},
  title = {Capturing RIA concepts in a web modeling language},
  pages = {907-908},
  doi = {10.1145/1135777.1135938},
  address = {Edinburgh, Scotland},
  booktitle = {International Conference on World Wide Web (WWW)},
  timestamp = {2009.02.05},
  year = {2006}
}

@ARTICLE{Bradley-Boyle:2004,
  author = {Claire Bradley and Tom Boyle},
  title = {The Design, Development, and Use of Multimedia Learning Objects},
  volume = {13},
  number = {4},
  month = oct,
  year = {2004},
  pages = {371--389},
  abstract = {This paper concerns the development and use of learning objects to address a real and urgent educational problem -- the teaching and learning of introductory programming. The paper outlines the design principles and development process involved in creating self-contained learning objects that are pedagogically rich. It describes how the objects were deployed within a blended-learning approach to course delivery and gives examples of objects developed and how they have been used by students and teaching staff. Full evaluation of the project has been undertaken; data is presented that shows an improvement in pass rates, and how the objects have been received. Finally, the paper discusses the contribution to building a model for well-designed learning objects.},
  url = {http://www.editlib.org/p/18905},
  address = {Norfolk, VA, USA},
  issn = {1055-8896},
  journal = {Journal of Educational Multimedia and Hypermedia},
  publisher = {AACE}
}

@INPROCEEDINGS{Bradley-etal:2003,
  author = {Claire Bradley and Tom Boyle and Richard Haynes},
  title = {Design and evaluation of multimedia learning objects},
  pages = {1239--1245},
  abstract = {This paper outlines a study of the design and evaluation of multimedia learning objects that have been incorporated into higher education courses. It outlines the design principles that underpin the development of a new set of learning objects that are pedagogically rich, and retain the cohesion and independence required for flexible use. Examples of some of the resulting learning objects are provided. The use of these objects by the first cohorts of students is being thoroughly evaluated. The evaluation framework and results from students' assessments of the learning objects are presented, which are positive and encouraging.},
  keywords = {Evaluation; Students; Learning Objects},
  booktitle = {World Conference on Educational Multimedia, Hypermedia and Telecommunications},
  editor = {David Lassner and Carmel McNaught},
  isbn = {1-880094-48-7},
  lang = {en},
  location = {Honolulu, Hawaii, USA},
  publisher = {AACE},
  url = {http://www.editlib.org/p/13984},
  year = {2003}
}

@INPROCEEDINGS{bragaetal:2007,
  author = {Rosana Teresinha Vaccare Braga and Edison Kicho Shimabukuro Junior and Paulo Cesar Masiero},
  title = {Easing the creation of domain-specific application generators with a configurable tool},
  owner = {magsilva},
  timestamp = {2007.09.11},
  year = {2007}
}

@INPROCEEDINGS{braga:2002,
  author = {Rosava T. V. Braga and Paulo Cesar Masiero},
  title = {GREN-Wizard: a Tool to Instantiate the GREN Framework},
  pages = {408-413},
  series = {Caderno de Ferramentas - Anais do SBES 2002},
  address = {Gramado - RS},
  booktitle = {Sessão de Ferramentas do XVI Simpósio Brasileiro de Engenharia de Software},
  month = oct,
  owner = {magsilva},
  timestamp = {2007.09.04},
  year = {2002}
}

@INPROCEEDINGS{braga:2007,
  author = {Rosana T. V. Braga and Reginaldo R\'E and Paulo Cesar Masiero},
  title = {A Process to Create Analysis Pattern Languages for Specific Domains},
  pages = {261-275},
  volume = {1},
  address = {Porto de Galinhas, PE, Brasil},
  booktitle = {Sexta Conferência Latino-americana em Linguagens de Padrões para Programação},
  month = may,
  owner = {magsilva},
  timestamp = {2007.08.15},
  year = {2007}
}

@TECHREPORT{Branson-etal:1975,
  author = {Branson, Robert K. and Rayner, Gail T. and Cox, J. L. and Furman, John P. and King, F. J.},
  title = {Interservice Procedures for Instructional Systems Development. Executive Summary and Model},
  institution = {Florida State University - Tallahassee Center for Educational Technology},
  month = aug,
  year = {1975},
  number = {ADA019486},
  address = {EUA},
  url = {http://handle.dtic.mil/100.2/ADA019486},
  abstract = {The report is a five volume set of procedures developed for the preparation of a curriculum when interservice training is called for. The procedures address five major phases, which are: analyze, design, develop, implement, and control. The procedures begin with methodology for conducting a job analysis for the curriculum subject area for which the instruction is to be developed and go through 18 additional steps suitable for the empirical development of interservice training. This volume contains a summary and model.},
  owner = {magsilva},
  timestamp = {2009.05.10}
}

@TECHREPORT{Branson-etal:1975:1,
  author = {Branson, Robert K. and Rayner, Gail T. and Cox, J. L. and Furman, John P. and King, F. J.},
  title = {Interservice Procedures for Instructional Systems Development: Phase 1 - Analyze},
  institution = {Florida State University - Tallahassee Center for Educational Technology},
  month = aug,
  year = {1975},
  number = {ADA019487},
  url = {http://handle.dtic.mil/100.2/ADA019487},
  abstract = {The analysis phase of interservice training curriculum development includes the establishment of job performance standards, task discrimination to separate important ones from the unimportant ones, construction of tests to determine ability to perform tasks, examination of existing courses for effectiveness, and selection of an optimum instructional setting for a given task.},
  owner = {magsilva},
  timestamp = {2009.05.10}
}

@TECHREPORT{Branson-etal:1975:2,
  author = {Branson, Robert K. and Rayner, Gail T. and Cox, J. L. and Furman, John P. and King, F. J.},
  title = {Interservice Procedures for Instructional Systems Development: Phase II - Design},
  institution = {Florida State University - Tallahassee Center for Educational Technology},
  month = aug,
  year = {1975},
  number = {ADA019488},
  url = {http://handle.dtic.mil/100.2/ADA019488},
  abstract = {The design phase of interservice training curriculum development involves the selection of tasks with regard to learning objectives, bridging the gap between performing a task and learning how to perform it, development of tests to screen personnel and to determine how much was learned, finding the ability levels of trainees, and setting of course sequences according to learning objectives.},
  owner = {magsilva},
  timestamp = {2009.05.10}
}

@TECHREPORT{Branson-etal:1975:3,
  author = {Branson, Robert K. and Rayner, Gail T. and Cox, J. L. and Furman, John P. and King, F. J.},
  title = {Interservice Procedures for Instructional Systems Development: Phase III - Develop},
  institution = {Florida State University - Tallahassee Center for Educational Technology},
  month = ago,
  year = {1975},
  number = {ADA019489},
  url = {http://handle.dtic.mil/100.2/ADA019489},
  abstract = {The volume outlines important procedures in developing interservice training effectiveness. Elements emphasized are setting guidelines for learning objectives, obtaining instructional cost effectiveness by mixing media, using existing proven materials or devising new ones, evaluating existing materials for appropriateness, developing new instruction where necessary, and validating all instructional materials.},
  owner = {magsilva},
  timestamp = {2009.05.10}
}

@TECHREPORT{Branson-etal:1975:4,
  author = {Branson, Robert K. and Rayner, Gail T. and Cox, J. L. and Furman, John P. and King, F. J.},
  title = {Interservice Procedures for Instructional Systems Development: Phase IV and V; Implement and Control},
  institution = {Florida State University - Tallahassee Center for Educational Technology},
  month = ago,
  year = {1975},
  number = {ADA019490},
  url = {http://handle.dtic.mil/100.2/ADA019490},
  abstract = {The implementation phase of interservice training involves providing guidelines for classroom management, designing teaching methods which include self-paced instruction, determining whether the instructional effort has accomplished the intended aims and providing good data upon which to base training decisions, external evaluation to find how well trained students are doing their jobs after course completion and job placement, and setting up a system for revising the training methodology in case of doctrine changes or discovery of instruction deficiencies.},
  owner = {magsilva},
  timestamp = {2009.05.10}
}

@MISC{brasil:decreto5820:2006,
  author = {{Brasil}},
  title = {Decreto nº 5820},
  howpublished = {Decreto},
  month = jun,
  year = {2006},
  timestamp = {2008.10.10},
  url = {https://www.planalto.gov.br/ccivil_03/_Ato2004-2006/2006/Decreto/D5820.htm}
}

@MISC{law:brazil:decreto5800,
  author = {{Brasil}},
  title = {Decreto nº 5.800},
  howpublished = {Decreto},
  month = jun,
  year = {2006},
  abstract = {Dispõe sobre o Sistema Universidade Aberta do Brasil (UAB)}
}

@MISC{decreto5622:2005,
  author = {Brasil},
  title = {Decreto 5.622},
  howpublished = {Decreto},
  month = dec,
  year = {2005},
  note = {Decreto que revoga o Decreto 2.494/98 e regulamenta o Artigo 80 da Lei 9394/96 (LDB).},
  timestamp = {2008.09.12},
  url = {http://www.planalto.gov.br/ccivil_03/_Ato2004-2006/2005/Decreto/D5622.htm}
}

@MISC{brasil:decreto4901:2003,
  author = {{Brasil}},
  title = {Decreto nº 4.901},
  howpublished = {Decreto},
  month = nov,
  year = {2003},
  timestamp = {2008.10.10},
  url = {http://www.mc.gov.br/tv-digital/tv-digital/decreto-no-4.901-de-26-de-novembro-de-2003}
}

@MISC{decreto2494:1998,
  author = {Brasil},
  title = {Decreto nº. 2.494},
  howpublished = {Decreto},
  month = feb,
  year = {1998},
  note = {Decreto que regulamente o artigo 80 da Lei de Diretrizes e Bases da Educação do Brasil.},
  timestamp = {2008.09.12},
  url = {http://www2.seduc.mt.gov.br/marcos_legais/word/Decreto%202494.pdf}
}

@ARTICLE{bravo-etal:2008,
  author = {Bravo, Crescencio and Redondo, Miguel A. and Verdejo, M. Felisa and Ortega, Manuel},
  title = {A framework for process-solution analysis in collaborative learning environments},
  volume = {66},
  month = nov,
  year = {2008},
  pages = {812--832},
  doi = {10.1016/j.ijhcs.2008.08.003},
  abstract = {One of the most challenging aspects of computer-supported collaborative learning (CSCL) research is automation of collaboration and interaction analysis in order to understand and improve the learning processes. It is particularly necessary to look in more depth at the joint analysis of the collaborative process and its resulting product. In this article, we present a framework for comprehensive analysis in CSCL synchronous environments supporting a problem-solving approach to learning. This framework is based on an observation-abstraction-intervention analysis life-cycle and consists of a suite of analysis indicators, procedures for calculating indicators and a model of intervention based on indicators. Analysis indicators are used to represent the collaboration and knowledge building process at different levels of abstraction, and to characterize the solution built using models of the application domain, the problems to solve and their solutions. The analysis procedures combine analysis of actions and dialogue with analysis of the solution. In this way, the process and the solution are studied independently as well as together, enabling the detection of correlations between them. In order to exemplify and test the framework, the methodological process underlying the framework was followed to guide the implementation of the analysis subsystems of two existing CSCL environments. In addition, a number of studies have been conducted to evaluate the framework's approach, demonstrating that certain modes of collaborating and working imply particular types of solutions and vice versa.},
  keywords = {CSCL, Collaboration and interaction analysis, Solution analysis, User and group modelling},
  url = {http://portal.acm.org/citation.cfm?id=1414101.1414382},
  acmid = {1414382},
  address = {Duluth, MN, USA},
  issn = {1071-5819},
  issue = {11},
  journal = {International Journal of Human-Computer Studies},
  numpages = {21},
  publisher = {Academic Press, Inc.}
}

@MISC{xml:2004,
  author = {Tim Bray and Jean Paoli and C. M. Sperberg-McQueen and Eve Maler and François Yergeau and John Cowan},
  title = {Extensible Markup Language (XML)},
  howpublished = {W3C Recommendation},
  month = apr,
  year = {2004},
  comment = {24/05/2005},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://www.w3.org/TR/xml11/}
}

@INPROCEEDINGS{breitman:2002,
  author = {Karin K. Breitman and Julio Cesar Sampaio do Prado Leite},
  title = {Managing User Stories},
  address = {Essen, Germany},
  booktitle = {Proceedings of the International Workshop on Time Constrained Requirements Engineering},
  editor = {Armin Eberlein and Julio Cesar Sampaio do Prado Leite},
  month = sep,
  owner = {magsilva},
  timestamp = {2008.07.30},
  year = {2002}
}

@BOOK{Brennand-SouzaFilho:2007,
  title = {Televisão Digital Interativa: Reflexões, Sistemas e Padrões},
  publisher = {Editora Mackenzie and Editora Horizonte},
  year = {2007},
  author = {Edna Brennand and Guido Lemos de {Souza Filho}},
  editor = {Eliane Alves de Oliveira},
  isbn = {978-85-99279-07-6},
  pages = {176},
  address = {São Paulo, SP, Brazil},
  edition = {1},
  abstract = {Discorrer sobre televisão digital interativa implica não apenas a convergência de dados ou questões técnicas. O tema é bem mais abrangente e envolve a problemática socioeconômica-cultural, que permeia todo o processo de mudança de padrão analógico para digital. Na esfera social, pensar uma TV de qualidade e aberta, orientada para a concepção people first (pessoas primeiro), deve ser uma meta não apenas na Europa, já que essa mídia colca-se como uma possiblidade revolucionária de apoio à aprendizagem social. TV digital interativa: reflexões, sistemas e padrões explica o que é TV digital interativa, suas implicações sociais, culturais, econômicas e técnicas, e apresenta a experiência internacional, com ênfase na experiência européia.},
  booktitle = {Televisão Digital Interativa: Reflexões, Sistemas e Padrões},
  lang = {pt},
  timestamp = {2008.10.07}
}

@ARTICLE{brereton-etal:2007,
  author = {Pearl Brereton and Barbara A. Kitchenham and David Budgen and Mark Turner and Mohamed Khalil},
  title = {Lessons from applying the systematic literature review process within the software engineering domain},
  volume = {80},
  number = {80},
  year = {2007},
  pages = {571-583},
  abstract = {A consequence of the growing number of empirical studies in software engineering is the need to adopt systematic approaches to assessing and aggregating research outcomes in order to provide a balanced and objective summary of research evidence for a particular topic. The paper reports experiences with applying one such approach, the practice of systematic literature review, to the published studies relevant to topics within the software engineering domain. The systematic literature review process is summarised, a number of reviews being undertaken by the authors and others are described and some lessons about the applicability of this practice to software engineering are extracted. The basic systematic literature review process seems appropriate to software engineering and the preparation and validation of a review protocol in advance of a review activity is especially valuable. The paper highlights areas where some adaptation of the process to accommodate the domain-specific characteristics of software engineering is needed as well as areas where improvements to current software engineering infrastructure and practices would enhance its applicability. In particular, infrastructure support provided by software engineering indexing databases is inadequate. Also, the quality of abstracts is poor; it is usually not possible to judge the relevance of a study from a review of the abstract alone.},
  journal = {The Journal of Systems and Software},
  owner = {magsilva},
  timestamp = {2007.11.12}
}

@INPROCEEDINGS{breuer-etal:2007,
  author = {Breuer, Henning and Baloian, Nelson and Sousa, Christian and Matsumoto, Mitsuji},
  title = {Interaction design patterns for classroom environments},
  pages = {163--172},
  abstract = {In our research, we synthesize two lines of development that have been dealt with independently so far: 1) the development and evaluation of educational technologies to support problem-oriented and collaborative learning activities inside and outside of the classroom, and 2) interaction design patterns as a means to document and generate design knowledge. Primary contributions are software prototypes for enhancing classroom interaction through interactive whiteboards, multiple clients with pen-tablets and PDAs, and a basic layout of a pattern language for formal and informal learning environments.},
  keywords = {PDAs, activity theory, classroom, educational technology, gesture-based interaction, interaction design patterns, learning theories, open space, pen-tablets, whiteboards},
  series = {HCI'07},
  acmid = {1769472},
  address = {Berlin, Heidelberg},
  booktitle = {Proceedings of the 12th international conference on Human-computer interaction: applications and services},
  isbn = {978-3-540-73109-2},
  location = {Beijing, China},
  numpages = {10},
  publisher = {Springer-Verlag},
  url = {http://portal.acm.org/citation.cfm?id=1769451.1769472},
  year = {2007}
}

@INPROCEEDINGS{breuer-etal:2008,
  author = {Breuer, Henning and Zurita, Gustavo and Baloian, Nelson and Matsumoto, Mitsuji},
  title = {Mobile Learning with Patterns},
  pages = {626--630},
  doi = {10.1109/ICALT.2008.300},
  abstract = {The identification and construction of patterns play a fundamental role in learning, but to date design patterns have been used for communication between professionals, rather than for learning purposes. We adapt the design pattern approach and develop software for mobile and other touch-sensitive devices in order to support design students to learn with patterns. We describe the multi-platform system and its gesture-based interaction for formal and informal environments, and present some application scenarios.},
  keywords = {Mobile Learning, Design Patterns, PDAs, Gesture-Based Interaction, Pattern Language, Construction},
  acmid = {1381548},
  address = {Washington, DC, USA},
  booktitle = {Proceedings of the 2008 Eighth IEEE International Conference on Advanced Learning Technologies},
  isbn = {978-0-7695-3167-0},
  numpages = {5},
  publisher = {IEEE Computer Society},
  url = {http://portal.acm.org/citation.cfm?id=1381300.1381548},
  year = {2008}
}

@ARTICLE{breuer:2006,
  author = {Peter T. Breuer and Marison García Valls},
  title = {Raiding the Noosphere: the open development of networked RAID support for the Linux kernel},
  volume = {36},
  year = {2006},
  pages = {365-395},
  journal = {Software -- Practice and Experience},
  owner = {magsilva},
  timestamp = {2007.04.28}
}

@ARTICLE{Breunig:2006,
  author = {Christian Breunig},
  title = {Mobile Fernsehen in Deutschland},
  number = {11},
  year = {2006},
  pages = {550-562},
  url = {http://www.media-perspektiven.de/uploads/tx_mppublications/11-2006_Breunig.pdf},
  journal = {Media Perspektiven},
  lang = {de}
}

@MISC{software:sizer,
  author = {{Brian Apps}},
  title = {Sizer},
  howpublished = software,
  month = feb,
  year = {1997},
  owner = {magsilva},
  timestamp = {2010.08.26},
  url = {http://www.brianapps.net/sizer/}
}

@ARTICLE{Briand-etal:1996,
  author = {L. C. Briand and K. El. Emam and S. Morasca},
  title = {On the Application of Measurement Theory in Software Engineering},
  volume = {1},
  number = {1},
  year = {1996},
  pages = {61-88},
  doi = {10.1007/BF00125812},
  journal = {Journal of Empirical Software Engineering}
}

@TECHREPORT{brickley:2000,
  author = {D. Brickley and R. V. Guha},
  title = {Resource Description Framework Schema Specification},
  institution = {W3C},
  year = {2000},
  url = {http://www.w3c.org/TR/rdf-schema},
  owner = {magsilva},
  timestamp = {2008.07.30},
  type = {W3C Candidate Recommendation}
}

@TECHREPORT{britain-liber:1999,
  author = {Sandy Britain and Oleg Liber},
  title = {A Framework for Pedagogical Evaluation of Virtual Learning Environments},
  institution = {Bangor University Centre for Learning Technology},
  month = oct,
  year = {1999},
  number = {31},
  url = {http://www.leeds.ac.uk/educol/documents/00001237.htm/},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@MASTERSTHESIS{brito-etal:2003,
  author = {L. S. F. Brito},
  title = {{WebScharts}: Uma ferramenta de desenvolvimento de aplicações Web baseada no {HMBS/M}},
  school = {UFMS},
  year = {2003},
  address = {Campo Grande, MS},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@ARTICLE{Britten-etal:2002,
  author = {Britten, Nicky and Campbell, Rona and Pope, Catherine and Donovan, Jenny and Morgan, Myfanwy and Pill, Roisin},
  title = {Using meta ethnography to synthesise qualitative research: a worked example},
  volume = {7},
  number = {4},
  month = oct,
  year = {2002},
  pages = {209-215},
  doi = {10.1258/135581902320432732},
  abstract = {Objectives: To demonstrate the benefits of applying meta ethnography to the synthesis of qualitative research, by means of a worked example. Methods: Four papers about lay meanings of medicines were arbitrarily chosen. Noblit and Hare's seven-step process for conducting a meta ethnography was employed: getting started; deciding what is relevant to the initial interest; reading the studies; determining how the studies are related; translating the studies into one another; synthesising translations; and expressing the synthesis. Results: Six key concepts were identified: adherence/compliance; self-regulation; aversion; alternative coping strategies; sanctions; and selective disclosure. Four second-order interpretations (derived from the chosen papers) were identified, on the basis of which four third-order interpretations (based on the key concepts and second-order interpretations) were constructed. These were all linked together in a line of argument that accounts for patients' medicine-taking behaviour and communication with health professionals in different settings. Third-order interpretations were developed which were not only consistent with the original results but also extended beyond them. Conclusions: It is possible to use meta ethnography to synthesise the results of qualitative research. The worked example has produced middle-range theories in the form of hypotheses that could be tested by other researchers.},
  url = {http://jhsrp.rsmjournals.com/cgi/content/abstract/7/4/209},
  eprint = {http://jhsrp.rsmjournals.com/cgi/reprint/7/4/209.pdf},
  journal = {Journal of Health Services Research \& Policy}
}

@BOOK{Brooks:1975,
  title = {The Mythical Man-Month},
  publisher = {Addison-Wesley},
  year = {1975},
  author = {Frderick P. Brooks},
  isbn = {0-201-00650-2},
  pages = {195},
  address = USA,
  edition = {1st}
}

@ARTICLE{brotherton-abowd:2004,
  author = {J. A. Brotherton and G. D. Abowd},
  title = {Lessons learned from {eClass}: Assessing automated capture and access in the classroom},
  volume = {11},
  number = {2},
  month = jun,
  year = {2004},
  pages = {121--155},
  journal = {ACM Transactions on Computer-Human Interaction},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@INPROCEEDINGS{brotherton-abowd:1998,
  author = {J. A. Brotherton and G. D. Abowd},
  title = {Rooms Take Note: Room Takes Notes!},
  booktitle = {Working Papers of AAAI 98 Spring Symposium},
  month = mar,
  owner = {magsilva},
  timestamp = {2008.07.30},
  year = {1998}
}

@INPROCEEDINGS{brotherton-etal:1998,
  author = {J. A. Brotherton and J. Bhalodia and G. D. Abowd},
  title = {Automated Capture, Integration and Visualization of Multiple Media Streams},
  pages = {54--63},
  booktitle = {IEEE Conference on Multimedia and Computing Systems},
  month = jul,
  owner = {magsilva},
  timestamp = {2008.07.30},
  year = {1998}
}

@INPROCEEDINGS{brunk-etal:2006,
  author = {Jevon Brunk and Maurizio Caporali and Antonio Rizzo and Elisa Rubegni},
  title = {3is Learning objects: organization of knowledge through the capture of narrative structures},
  pages = {25--32},
  doi = {10.1145/1274892.1274897},
  address = {New York, NY, USA},
  booktitle = {ECCE '06: Proceedings of the 13th Eurpoean conference on Cognitive ergonomics},
  isbn = {978-3-906509-23-5},
  location = {Zurich, Switzerland},
  publisher = {ACM},
  year = {2006}
}

@ARTICLE{Brusilovsky-etal:2004,
  author = {Peter Brusilovsky and Olena Shcherbinina and Sergey Sosnovsky},
  title = {Mini-languages for non-Computer Science Majors: What are the Benefits?},
  volume = {1},
  number = {1},
  year = {2004},
  pages = {21-28},
  doi = {10.1108/17415650480000009},
  abstract = {Mini-languages for teaching principles of programming - such as Karel the Robot - were once used in top computer science departments to provide a 'gentle introduction' to programming for computer science majors. The paper builds a case for the use of mini-languages in the context of introductory programming courses for non-computer science major. We present a study that explored the use of Karel to teach introductory programming for information science majors.},
  keywords = {Mini-language; Introductory programming; Learning environment; Information science},
  address = {Bingley, UK},
  issn = {1741-5659},
  journal = {Interactive Technology and Smart Education},
  lang = {en},
  publisher = {Emerald}
}

@ARTICLE{Buchinger-etal:2011,
  author = {Shelley Buchinger and Simone Kriglstein and Sabine Brandt and Helmut Hlavacs},
  title = {A survey on user studies and technical aspects of mobile multimedia applications},
  volume = {2},
  number = {3},
  year = {2011},
  pages = {175 - 190},
  doi = {10.1016/j.entcom.2011.02.001},
  abstract = {Some years ago, Mobile TV has been introduced in several countries all over the world. It was expected that it would play a major role among traditional TV services. Unfortunately, the success has been limited at the beginning. Since Mobile TV brings new aspects into television, like small screens, consumption in noisy surroundings, etc., it also represents a new challenge on how to create, transfer and present content that maximizes the consumer experience. Today, some of these issues have been solved. Due to the introduction of smart phones and the large amount of available applications customers are starting to use their mobile phones for several purposes including mobile multimedia services. As a consequence, the concept for Mobile TV has changed significantly. In the past, research has often been focusing on one particular aspect of this new TV scheme, as well as surveys on this research often neglected aspects that still might be of interest when trying to understand the dependencies of Mobile TV content and presentation to perceived quality. In this survey paper we want to discuss challenges and requirements in a comprehensive way, trying to shed light on all relevant aspects of Mobile TV. The aim of this paper is to give a good overview about the state of the art with the focus of users' need and experiences. A large collection of technical aspects and research results represents a special interest of this study. Finally, we want to discuss a framework for mobile multimedia applications which is relevant for further research work.},
  keywords = {Mobile TV, QoE, Human Centered Design, Survey},
  issn = {1875-9521},
  journal = {Entertainment Computing}
}

@INPROCEEDINGS{Buchinger-etal:2009,
  author = {Buchinger, Shelley and Kriglstein, Simone and Hlavacs, Helmut},
  title = {A comprehensive view on user studies: survey and open issues for mobile TV},
  pages = {179--188},
  doi = {10.1145/1542084.1542121},
  abstract = {In the future Mobile TV will play a major role amongst traditional TV services. However, since Mobile TV brings new aspects into television, like small screens, consumption in noisy surroundings, etc., it also represents a new challenge on how to create, transfer and present content that maximizes the consumer experience. In the past, research has been often focusing on one particular aspect of this new TV scheme, as well as surveys on this research often neglected aspects that still might be of interest when trying to understand the dependencies of Mobile TV content and presentation to perceived quality. In this survey paper we want to discuss challenges and requirements in a comprehensive way, trying to shed light on all relevant aspects of Mobile TV. The aim of this paper is to give a good overview about the state of the art with the focus of users' need and experiences. Furthermore, we want to point out interesting and open issues which are relevant for further research work.},
  keywords = {human centered design, mobile tv, qoe, survey},
  series = {EuroITV '09},
  acmid = {1542121},
  address = {New York, NY, USA},
  booktitle = {European Conference on European Interactive Television Conference},
  isbn = {978-1-60558-340-2},
  location = {Leuven, Belgium},
  numpages = {10},
  publisher = {ACM},
  status = {obsoleted(Buchinger-etal:2011)},
  year = {2009}
}

@INBOOK{budd:1981,
  chapter = {Computer Program Testing: Proceedings of the Summer School on Computer Program Testing held at {SOGESTA}, Urbino, Italy},
  pages = {129-148},
  title = {Mutation Analysis: Ideas, Example, Problems and Prospects},
  publisher = {North-Holand Publishing Company},
  year = {1981},
  editor = {B. Chandrasekaran and Sergio Radicchi},
  author = {T. A. Budd},
  address = {Amsterdam},
  month = jun # {-} # jul,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@PHDTHESIS{budd:1980,
  author = {T. A. Budd},
  title = {Mutation Analysis of Program Test Data},
  school = {Yale University},
  year = {1980},
  address = {New Haven, CT},
  month = may,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@ARTICLE{Budd82NCRT,
  author = {T. A. Budd and D. Angluin},
  title = {Two Notions of Correctness and their Relation to Testing},
  volume = {18},
  number = {1},
  month = nov,
  year = {1982},
  pages = {31--45},
  journal = {Acta Informatica},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{Budd80TESU,
  author = {T. A. Budd and R. A. DeMillo and R. J. Lipton and F. G. Sayward},
  title = {Theoretical and Empirical Studies on Using Program Mutation to Test the Functional Correctness of Programs},
  pages = {220--233},
  address = {New York, NY},
  booktitle = {7th {ACM} Symposium on Principles of Programming Languages},
  month = jan,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1980}
}

@ARTICLE{budgen-etal:2008,
  author = {Budgen, David and Kitchenham, Barbara A. and Charters, Stuart M. and Turner, Mark and Brereton, Pearl and Linkman, Stephen G.},
  title = {Presenting software engineering results using structured abstracts: a randomised experiment},
  volume = {13},
  number = {4},
  month = aug,
  year = {2008},
  pages = {435--468},
  doi = {10.1007/s10664-008-9075-7},
  abstract = {When conducting a systematic literature review, researchers usually determine the relevance of primary studies on the basis of the title and abstract. However, experience indicates that the abstracts for many software engineering papers are of too poor a quality to be used for this purpose. A solution adopted in other domains is to employ structured abstracts to improve the quality of information provided. This study consists of a formal experiment to investigate whether structured abstracts are more complete and easier to understand than non-structured abstracts for papers that describe software engineering experiments. We constructed structured versions of the abstracts for a random selection of 25 papers describing software engineering experiments. The 64 participants were each presented with one abstract in its original unstructured form and one in a structured form, and for each one were asked to assess its clarity (measured on a scale of 1 to 10) and completeness (measured with a questionnaire that used 18 items). Based on a regression analysis that adjusted for participant, abstract, type of abstract seen first, knowledge of structured abstracts, software engineering role, and preference for conventional or structured abstracts, the use of structured abstracts increased the completeness score by 6.65 (SE 0.37, p< 0.001) and the clarity score by 2.98 (SE 0.23, p < 0.001). 57 participants reported their preferences regarding structured abstracts: 13 (23%) had no preference; 40 (70%) preferred structured abstracts; four preferred conventional abstracts. Many conventional software engineering abstracts omit important information. Our study is consistent with studies from other disciplines and confirms that structured abstracts can improve both information content and readability. Although care must be taken to develop appropriate structures for different types of article, we recommend that Software Engineering journals and conferences adopt structured abstracts.},
  keywords = {Randomised controlled laboratory experiment, Structured abstract},
  url = {http://portal.acm.org/citation.cfm?id=1409479.1409483},
  acmid = {1409483},
  address = {Hingham, MA, USA},
  issn = {1382-3256},
  issue = {4},
  journal = {Empirical Software Engineering},
  numpages = {34},
  publisher = {Kluwer Academic Publishers}
}

@INPROCEEDINGS{Budkowsky-etal:1988,
  author = {S. Budkowski and P. Dembinski and M. Dias},
  title = {{ISO} Standardized Description Technique {Estelle}},
  pages = {1-28},
  abstract = {Estelle is a Formal Description Technique, defined within ISO (International Organization for Standardization) for specification of distributed, concurrent processing systems. In particular, Estelle can be used to describe the services and protocols of the layers of Open Systems Interconnection (OSI) architecture defined by ISO. Its present ISO status is Draft International Standard (DIS 9074). The International Standard status is expected before the end of 1988. The paper outlines basic concepts as well as syntactic and semantic aspects of this description technique.},
  keywords = {Estelle, Formal Description Technique, FDT, Distributed Systems, Concurent Systems, Specification Language, Comunication Protocols and Services, Open System Intrconnection, OSI},
  booktitle = {International Workshop on Software Engineering and its Applications},
  location = {Toulouse},
  year = {1988}
}

@INPROCEEDINGS{Bueno01ATDG,
  author = {P. M. S. Bueno and M. Jino},
  title = {Automated Test Data Generaton for Program Paths Using Genetic Algorithms},
  pages = {2--9},
  address = {Buenos Aires, Argentina},
  booktitle = {13th International Conference on Software Engineering \& Knowledge Engineering -- SEKE'2001},
  month = jun,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {2001}
}

@INPROCEEDINGS{Bulterman-etal:2006,
  author = {Bulterman, Dick C. A. and Cesar, Pablo and Jansen, A. J.},
  title = {An architecture for viewer-side enrichment of {TV} content},
  pages = {651--654},
  doi = {10.1145/1180639.1180775},
  abstract = {This paper presents a user interface model and implementation for exploiting next-generation interactive capabilities with the domain of television content. Our work studies capabilities that extend a user's potential impact over the consumption and sharing of television programs. The main capabilities of our environment include personalized viewing and navigation within a program fragment, and the ability to actively personalize content via various end-user content enrichments (such as line art, referrals and hyperlink insertions). In this paper, we present the implementation of a range of "couch-top" control and editing devices, including personal devices such as personal digital assistants and ad-hoc interactive devices. This paper also presents an architecture that decouples user actions into activators and handlers. We provide an overview of the interaction architecture and report on a series of deployment experiments on a wide range of consumer electronics devices.},
  keywords = {SMIL, content enrichment, personal digital recorder},
  series = {MULTIMEDIA '06},
  acmid = {1180775},
  address = {New York, NY, } # USA,
  booktitle = {Proceedings of the 14th annual ACM international conference on Multimedia},
  isbn = {1-59593-447-2},
  location = {Santa Barbara, CA, #USA#},
  numpages = {4},
  publisher = {ACM},
  year = {2006}
}

@MASTERSTHESIS{burge:1998,
  author = {Janet E. Burge},
  title = {Knowledge Elicitation for Design Task Sequencing Knowledge},
  abstract = {There are many types of knowledge involved in producing a design (the process of specifying a description of an artifact that satisfies a collection of constraints). Of these, one of the most crucial is the design plan: the sequence of steps taken to create the design (or a portion of the design). A number of knowledge elicitation methods can be used to obtain this knowledge from the designer. The success of the elicitation depends on the match between the knowledge elicitation method used and the information being sought. The difficulty with obtaining design plan information is that this information may involve implicit knowledge, i.e. knowledge that can not be expressed explicitly. In this thesis, an approach is used that combines two knowledge elicitation techniques: one direct, to directly request the design steps and their sequence, and one indirect, to refine this knowledge by obtaining steps and sequences that may be implicit. The two techniques used in this thesis were Forward Scenario Simulation (FSS), a technique where the domain expert describes how the procedure followed to solve it, and Card Sort, a technique where the domain expert is asked to sort items (usually entities in the domain) along different attributes. The Design Ordering Elicitation System (DOES) was built to perform the knowledge elicitation. This system is a web-based system designed to support remote knowledge elicitation: KE performed without the presence of the knowledge engineer. This system was used to administer knowledge elicitation sessions to evaluate the effectiveness of these techniques at obtaining design steps and their sequencing. The results indicate that using an indirect technique together with a direct technique obtains more alternative sequences for the design steps than using the direct technique alone.},
  school = {Worcester Polytechnic Institute},
  year = {1998},
  address = {Worcester, MA, United States},
  month = dec,
  url = {http://www.wpi.edu/Pubs/ETD/Available/etd-101399-123113/},
  owner = {magsilva},
  timestamp = {2011.03.13},
  type = {thesis}
}

@ARTICLE{Burgos-etal:2007,
  author = {Burgos, Daniel and Moreno-Ger, Pablo and Sierra, Jose Luis and Fernandez-Manjon, Baltasar and Koper, Rob},
  title = {Authoring game-based adaptive units of learning with IMS Learning Design and e-Adventure},
  volume = {3},
  number = {3},
  month = {October},
  year = {2007},
  pages = {252--268},
  doi = {10.1504/IJLT.2007.015444},
  abstract = {Electronic games and simulations (eGames) are a valuable support for adaptive learning. This adaptation can be based on different inputs, such as the user's performance, behaviour or cognitive load. Both adaptation and eGames can be modelled with IMS Learning Design (IMS LD) or integrated from an external resource. In this article we show the relation between IMS LD and the <e-Adventure> Project when it comes to authoring adaptive Units of Learning (UoLs) integrated with eGames. We first describe the challenges of this objective and the several different solutions on authoring and integration. We also describe the content-centred authoring approach in <e-Adventure>, and the need for a communication service with IMS LD that makes a bidirectional influence on the user's adaptive learning experience. At the end, we describe a practical example that illustrates how an adaptive IMS LD UoL with an integrated <e-Adventure> eGame is developed.},
  keywords = {IMS-LD, IMS Learning Design, adaptive learning, authoring, e-Adventure, eGames, electronic games, game-based learning, learning technology, simulation},
  acmid = {1360195},
  address = {Geneva, Switzerland},
  issn = {1477-8386},
  journal = {International Journal of Learning Technology},
  publisher = {Inderscience}
}

@MISC{software:checkstyle,
  author = {Oliver Burn},
  title = {CheckStyle},
  howpublished = {Programa de Computador},
  year = {2001},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://checkstyle.sourceforge.net/}
}

@BOOK{buschmann96pos,
  title = {Pattern-oriented software architecture: a system of patterns},
  publisher = {John Wiley \& Sons, Inc. New York, NY, USA},
  year = {1996},
  author = {F. Buschmann and R. Meunier and H. Rohnert and P. Sommerlad and M. Stal},
  isbn = {0471958697},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@ARTICLE{Bush:1945,
  author = {Vannevar Bush},
  title = {As We May Think},
  month = jul,
  year = {1945},
  url = {http://www.ps.uni-sb.de/~duchier/pub/vbush/vbush-all.shtml},
  journal = {The Atlantic Monthly},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@BOOK{Butcher:2011,
  title = {A Basic Guide to Open Educational Resources (OER)},
  publisher = {COL, UNESCO},
  year = {2011},
  author = {Neil Butcher},
  editor = {Asha Kanwar and Stamenka Uvalic-Trumbic},
  isbn = {9781894975414},
  pages = {133},
  address = {Vancouver, } # Canada,
  month = jul,
  abstract = {This Guide comprises three sections. The first -- a summary of the key issues -- is presented in the form of a set of 'Frequently Asked Questions'. Its purpose is to provide readers with a quick and user-friendly introduction to Open Educational Resources (OER) and some of the key issues to think about when exploring how to use OER most effectively. The second section is a more comprehensive analysis of these issues, presented in the form of a traditional research paper. For those who have a deeper interest in OER, this section will assist with making the case for OER more substantively. The third section is a set of appendices, containing more detailed information about specific areas of relevance to OER. These are aimed at people who are looking for substantive information regarding a specific area of interest.},
  booktitle = {A Basic Guide to Open Educational Resources (OER)}
}

@ARTICLE{Cabanac:2011,
  author = {Cabanac, Guillaume},
  title = {Accuracy of inter-researcher similarity measures based on topical and social clues},
  volume = {87},
  number = {3},
  month = jun,
  year = {2011},
  pages = {597--620},
  doi = {10.1007/s11192-011-0358-1},
  abstract = {Scientific literature recommender systems (SLRSs) provide papers to researchers according to their scientific interests. Systems rely on inter-researcher similarity measures that are usually computed according to publication contents (i.e., by extracting paper topics and citations). We highlight two major issues related to this design. The required full-text access and processing are expensive and hardly feasible. Moreover, clues about meetings, encounters, and informal exchanges between researchers (which are related to a social dimension) were not exploited to date. In order to tackle these issues, we propose an original SLRS based on a threefold contribution. First, we argue the case for defining inter-researcher similarity measures building on publicly available metadata. Second, we define topical and social measures that we combine together to issue socio-topical recommendations. Third, we conduct an evaluation with 71 volunteer researchers to check researchers' perception against socio-topical similarities. Experimental results show a significant 11.21% accuracy improvement of socio-topical recommendations compared to baseline topical recommendations.},
  keywords = {Experiment, Human perception, Literature review, Measurement, Recommendation, Similarity among researchers, Social clues, Topical clues},
  acmid = {1997242},
  address = {Secaucus, NJ, USA},
  issn = {0138-9130},
  issue = {3},
  issue_date = {June 2011},
  journal = {Scientometrics},
  numpages = {24},
  publisher = {Springer-Verlag}
}

@ARTICLE{CaeiroRodriguez-etal:2007,
  author = {M. Caeiro-Rodríguez and M. J. Marcelino and M. Llamas-Nistal and L. Anido-Rifón and A. J. Mendes},
  title = {Supporting the Modeling of Flexible Educational Units PoEML: A Separation of Concerns Approach},
  volume = {13},
  number = {7},
  year = {2007},
  pages = {980--990},
  doi = {10.3217/jucs-013-07-0980},
  abstract = {Educational Modeling Languages (EMLs) have been proposed to support the modeling of educational units. Currently, there are some EML proposals devoted to provide a computational base, enabling the software processing and execution of educational units' models. In this context, flexibility is a key requirement in order to support alternatives and changes . This paper presents a Perspective-oriented Educational Modeling Language (PoEML) that simplifies and facilitates the modeling of alternatives and the performance of changes. The key point of the proposal is the separation of the modeling in several concerns that can be managed almost independently. As a result, changes at each concern can be performed without affecting to other concerns, or affecting in controlled ways.},
  url = {http://www.jucs.org/jucs_13_7/supporting_the_modeling_of},
  journal = {Journal of Universal Computer Science},
  owner = {magsilva}
}

@ARTICLE{webcadet:2000,
  author = {Nicholas H. M. Caldwell and P. John Clarkson and Paul A. Rodgers and Avon P. Huxor},
  title = {Web-Based Knowledge Managment for Distributed Design},
  month = may,
  year = {2000},
  pages = {40-47},
  journal = {IEEE Intelligent Systems},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@BOOK{Calero-etal:2006,
  title = {Ontologies for Software Engineering and Software Technology},
  publisher = {Springer},
  year = {2006},
  author = {Calero, Coral and Ruiz, Francisco and Piattini, Mario},
  isbn = {978-3-540-34517-6},
  pages = {339},
  abstract = {Communication is one of the main activities in software projects, many such projects fail or encounter serious problems because the stakeholders involved have different understandings of the problem domain and/or they use different terminologies. Ontologies can help to mitigate these communication problems. Calero and her coeditors mainly cover two applications of ontologies in software engineering and software techonology: sharing knowledge of the problem domain and using a common terminology among all stakeholders; and filtering the knowledge when defining models and metamodels. The editors structured the contributions into three parts: first, a detailed introduction into the use of ontologies in software engineering and software technology in general; second, the use of ontologies to conceptualize different process-related domains such as software maintenance, software measurement, or SWEBOK, initiated by IEEE; third, the use of ontologies as artifacts in several software processes, like, for example, in OMG's MOF or MDA. By presenting the advanced use of ontologies in software research and software projects, this book is of benefit to software engineering researchers in both academia and industry.},
  booktitle = {Ontologies for Software Engineering and Software Technology},
  keywords = {Meta-Object Facility; Model Driven Architecture; Ontological Engineering; Ontologies; SWEBOK}
}

@MISC{project:merlot,
  author = {{California State University}},
  title = {Multimedia Educational Resource for Learning and Online Teaching ({MERLOT})},
  howpublished = {Projeto de Pesquisa},
  year = {1997},
  url = {http://www.merlot.org/},
  urlaccessdate = {20 fev 2012}
}

@ARTICLE{calverley:2006,
  author = {Gayle Calverley},
  title = {Considerations for producing re-usable and sustainable educational streaming materials},
  volume = {32},
  number = {1},
  year = {2006},
  url = {http://www.cjlt.ca/index.php/cjlt/article/view/57/54},
  journal = {Canadian Journal of Learning and Technology},
  owner = {magsilva},
  timestamp = {2009.02.20}
}

@MASTERSTHESIS{campos:1994,
  author = {F. C. A. Campos},
  title = {Hipermídia na Educação: Paradigmas e Avaliação da Qualidade},
  school = {COPPE -- UFRJ},
  year = {1994},
  address = {Rio de Janeiro, RJ},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{campos-etal:1999,
  author = {F. C. A. Campos and A. R. C. Rocha and G. H. B. Campos},
  title = {Qualidade de Software Educacional: Uma Proposta},
  address = {Florianópolis, SC},
  booktitle = {Workshop de Qualidade de Software (WQS 99), Simpósio Brasileiro de Engenharia de Software (SBES 99)},
  month = out,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1999}
}

@BOOK{CamposFilho:2007,
  publisher = {LTC},
  year = {2007},
  author = {Campos Filho, Frederico Ferreira},
  isbn = {978-85-216-1537-8},
  pages = {428},
  address = {Rio de Janeiro, RJ, } # Brazil,
  edition = {2},
  booktitle = {Algoritmos numéricos}
}

@INPROCEEDINGS{Canas-etal:2006,
  author = {Alberto J. Canas and Greg Hill and Larry Bunch and Roger Carff and Thomas Eskridge and Carlos Pérez},
  title = {{KEA}: A Knowledge Exchange Architecture Based on Web Services, Concept Maps and {CmapTools}},
  pages = {304-310},
  abstract = {The CmapTools program, and concept mapping in general, have seen a steady growth in usage in the last few years. With new users come new requirements and needs for the software that we can't always satisfy. Until now, the CmapTools architecture has been relatively closed to third party developers. In this paper we report on a new open architecture, KE (Knowledge Exchange Architecture), that provides the data and procedural framework to allow third party developers to design programs that interact with the CmapTools suite of programs. KEA consists of a portable, standard file format for data exchange (CXL), and a set of protocols for retrieving, storing, and manipulating Cmap information. We also describe how KEA was implemented and provide three sample client-server applications illustrating the steps we have taken toward the completion of this implementation.},
  volume = {1},
  address = {San José, Costa Rica},
  booktitle = {International Conference on Concept Mapping},
  editor = {A. J. Canãs and J. D. Novak},
  location = {San José, Costa Rica},
  publisher = {University of Malta},
  year = {2006}
}

@INPROCEEDINGS{Canas-etal:2004:cmaptools,
  author = {A. J. Canas and G. Hill and R. Carff and N. Suri and J. Lott and T. Eskridge and G. Gómez and M. Arroyo and R. Carvajal},
  title = {{CmapTools}: A Knowledge Modeling and Sharing Environment},
  pages = {125--133},
  volume = {1},
  address = {Pamplona Iruña, Navarra, Espanha},
  booktitle = {International Conference on Concept Mapping},
  location = {Pamplona Iruña, Navarra, Espanha},
  month = sep,
  owner = {magsilva},
  publisher = {Universidad Pública de Navarra},
  timestamp = {2008.07.30},
  year = {2004}
}

@INPROCEEDINGS{canas-etal:2004:cmap-education,
  author = {A. J. Canas and J. D. Novak and F. M. González},
  title = {Using Concept Maps as a Research Tool in Science Education Research},
  booktitle = {International Conference on Concept Mapping},
  owner = {magsilva},
  timestamp = {2008.07.30},
  year = {2004}
}

@MISC{software:ubuntu,
  author = {{Canonical Ltd}},
  title = {Ubuntu Linux},
  howpublished = {Programa de computador},
  month = oct,
  year = {2004},
  owner = {magsilva},
  timestamp = {2007.12.11},
  url = {http://www.ubuntu.com}
}

@INPROCEEDINGS{CantoFilho-etal:2011,
  author = {Alberto Bastos do Canto Filho and Alexandre Ribas Semeler and Liane Margarida Rockenbach Tarouco and Herik Zednik Rodrigues},
  title = {{UML} para Modelagem de Objetos de Aprendizado},
  booktitle = {Workshop Tecnología Informática aplicada en Educación (WTIAE), XVII Congresso Argentino de Ciencias de la Computatión},
  location = {La Plata, Argentina},
  month = oct,
  year = {2011}
}

@ARTICLE{Cao-etal:2008,
  author = {Cao, Jinwei and Crews, Janna M. and Lin, Ming and Burgoon, Judee K. and Nunamaker,Jr., Jay F.},
  title = {An empirical investigation of virtual Interaction in supporting learning},
  volume = {39},
  month = jul,
  year = {2008},
  pages = {51--68},
  doi = {10.1145/1390673.1390680},
  abstract = {This research investigates "virtual interaction," a special type of interaction between a learner and a rich media representation of an instructor. Guided by the Technology Mediated Learning (TML) research framework, the research investigates the impacts of different types of virtual interaction on the effectiveness of online learning based on a review of multiple learning theories and technologies, including theories about interactions in learning, types of knowledge, and learning outcomes, as well as technologies about video-based question answering (QA). An exploratory research study, in the form of a field experiment, has been conducted to explain the relationships among the types of interaction, types of knowledge being learned, and learning outcomes. Findings from this study indicate that QA-based virtual interaction increases learner satisfaction with interaction in learning conceptual knowledge; however, the influence of virtual interaction on actual learning performance is limited.},
  keywords = {e-learning, question answering, technology mediated learning (TML), virtual interaction},
  acmid = {1390680},
  address = {New York, NY, } # USA,
  issn = {0095-0033},
  issue = {3},
  journal = {SIGMIS Database},
  numpages = {18},
  publisher = {ACM}
}

@INPROCEEDINGS{capuano-etal:2003,
  author = {Capuano, N. and Gaeta, M. and Micarelli, A. and Sangineto, E.},
  title = {An Intelligent Web Teacher System for Learning Personalization and Semantic Web Compatibility},
  booktitle = {International PEG Conference},
  owner = {magsilva},
  timestamp = {2008.07.30},
  year = {2003}
}

@INPROCEEDINGS{Carey:1996,
  author = {John Carey},
  title = {Winky Dink To Stargazer: Five Decades Of Interactive Television},
  pages = {2--21},
  abstract = {Treatments of interactive television (ITV) in the popular press could easily lead readers to think that it is an entirely new phenomenon or, indeed, that it has yet to arrive on the scene. However, ITV has been tested in the marketplace under various guises in each decade since the 1950s. Our lack of historical perspective is unfortunate because there are many clues in the history of interactive television trials and services about what consumers want from ITV along with many lessons about how to overcome technological and marketplace obstacles. This presentation offers a review of ITV projects and services beginning in 1953. It provides an annotated history, drawing lessons about content, pricing, consumer appeal and user interfaces. No claim is made that the review is comprehensive. There are admitted gaps, particularly in covering European experiences with ITV. The presentation discusses an early ITV program, Winky Dink and You, during the 1950s; the introduction of videotelephones in the 1960s; twowayTV projects for health care and social services in the 1970s, along with the Qube interactive cable service in Columbus, Ohio; interactive game and text channels in the 1980s along with low-end educational applications of interactive television; and, the many trials and ITV services during the 1990s that have been provided via cable, telephone networks and hybrid transmission systems. Slides of many ITV services along with a videotape of the Qube system are used to illustrate the presentation.},
  address = {Edinburgh, Scotland, Reino Unido},
  booktitle = {UnivEd Conference on Interactive Television},
  location = {Edinburgh, Scotland, Reino Unido},
  month = sep,
  publisher = {University of Edinburgh},
  timestamp = {2012.02.04},
  year = {1996}
}

@ARTICLE{carliner,
  author = {Saul Carliner},
  title = {Designing and Developing E-learning Projects: A Three-Tiered Approach},
  month = mar,
  year = {2008},
  url = {http://www.elearnmag.org/subpage.cfm?section=tutorials&article=26-1},
  journal = {eLearn Magazine},
  owner = {magsilva},
  timestamp = {2008.07.07}
}

@ARTICLE{Carmichael-etal:2006,
  author = {Carmichael, Alex and Rice, Mark and Sloan, David and Gregor, Peter},
  title = {Digital switchover or digital divide: a prognosis for usable and accessible interactive digital television in the {UK}},
  volume = {4},
  number = {4},
  month = may,
  year = {2006},
  pages = {400--416},
  doi = {10.1007/s10209-005-0004-x},
  abstract = {The move toward digital switchover increases content and introduces interactive services available through the television. UK legislation advocates universal access and equitable provision of services, across all platforms and equipment, particularly for vulnerable groups. However, key aspects of usability and accessibility have been overlooked by those responsible for encouraging this new infrastructure's inclusive development. Aspects of previous interactive television provision and developments in web accessibility appear to have been ignored, along with findings from relevant user-centred research and even from specifically commissioned reports. This paper will identify these issues and discuss their impact on the inclusiveness of DTV.},
  keywords = {Communications act, Digital exclusion, Digital television action plan, Disability discrimination act, Ofcom},
  acmid = {1137588},
  address = {Berlin, } # Germany,
  issn = {1615-5289},
  journal = {Universal Access in the Information Society},
  numpages = {17},
  publisher = {Springer-Verlag}
}

@MASTERSTHESIS{Carnassale91GFMG,
  author = {M. Carnassale},
  title = {{GFC} -- Uma Ferramenta Multilinguagem para Gera\c c\~ao de Grafo de Programa},
  school = {DCA/FEE/UNICAMP},
  year = {1991},
  address = {Campinas, SP},
  month = feb,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@MASTERSTHESIS{Carnassale91MTPG,
  author = {M. Carnassale},
  title = {{GFC} -- A Multilanguage Tool for Program Graph Generation},
  school = {DCA/FEE/UNICAMP},
  year = {1991},
  address = {Campinas, SP},
  month = feb,
  note = {(in Portuguese)},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{Carter:2009:EOI:1536274.1536305,
  author = {Carter, Paul},
  title = {An experiment with online instruction and active learning in an introductory computing course for engineers: JiTT meets CS1},
  pages = {103--108},
  doi = {10.1145/1536274.1536305},
  abstract = {This paper describes an experiment with online instruction and active learning in an introductory computing course for engineering students. A series of online screencasts was developed to replace the traditional component of lectures for a one week period in the middle of the course. Students were asked to review the screencasts before coming to class and were assessed on that material at the beginning of class. A just in time lecture was provided in response to the assessment, as needed. The remaining class time was devoted to associated active learning exercises through peer instruction with formative assessment. Student feedback on this preliminary experiment was positive suggesting that further investigation is warranted.},
  keywords = {CS1, JiTT, active learning, online instruction, pedagogy, peer instruction, screencasts},
  series = {WCCCE '09},
  acmid = {1536305},
  address = {New York, NY, USA},
  booktitle = {Proceedings of the 14th Western Canadian Conference on Computing Education},
  isbn = {978-1-60558-415-7},
  location = {Burnaby, British Columbia, Canada},
  numpages = {6},
  publisher = {ACM},
  year = {2009}
}

@INPROCEEDINGS{carter-denoue:2008,
  author = {Carter, Scott and Denoue, Laurent},
  title = {PicNTell: a camcorder metaphor for screen recording},
  pages = {869--872},
  doi = {10.1145/1459359.1459508},
  abstract = {PicNTell is a new technique for generating compelling screencasts where users can quickly record desktop activities and generate videos that are embeddable on popular video sharing distributions such as YouTube®. While standard video editing and screen capture tools are useful for some editing tasks, they have two main drawbacks: (1) they require users to import and organize media in a separate interface, and (2) they do not support natural (or camcorder-like) screen recording, and instead usually require the user to define a specific region or window to record. In this paper we review current screen recording use, and present the PicNTell system, pilot studies, and a new six degree-of-freedom tracker we are developing in response to our findings.},
  keywords = {multimedia recording and playback, natural input, screencasting},
  series = {MM '08},
  acmid = {1459508},
  address = {New York, NY, USA},
  booktitle = {Proceeding of the 16th ACM international conference on Multimedia},
  isbn = {978-1-60558-303-7},
  location = {Vancouver, British Columbia, Canada},
  numpages = {4},
  publisher = {ACM},
  year = {2008}
}

@RESEARCH-PROJECT{project:openSE,
  title = {{openSE} -- Open educational framework for computer science Software Engineering},
  author = {José Carvalho},
  institution = {Sociedade Portuguesa de Inovação (SPI)},
  number = {503641-LLP-1-2009-1-PT-ERASMUS-ECUE},
  funding = {ERASMUS},
  month = oct,
  year = {2009},
  duration = {25},
  abstract = {The openSE brings together higher education institutions, open source projects and enterprises from different countries, across Europe and beyond, to collaboratively build up a common learning ecosystem. The openSE framework is an open approach to computer science Software Engineering, aiming at the continuous provision of up-to-date and relevant learning materials and opportunities that match students' interests and employers' demand; providing firms with better educated employees and allowing learners to acquire an enhanced set of skills in comparison to traditional education. The openSE framework will be open to any type of learner: students of partnering universities, learners from the enterprise community or 'free learners' outside of any type of formal educational context. It is the aim of the openSE Project to draw upon ongoing initiatives and prior experiences related to open educational provision or experiences of computer science education within open source projects. We cordially invite fellow educational institutions, practitioners and enterprises from the open source field, as well as all types of learners, to contribute to the development of openSE, be it in terms of structuring and shaping the openSE environment, providing learning resources and mentorship or support current opportunities.}
}

@INPROCEEDINGS{Carvalho-etal:2008,
  author = {Carvalho, Lucas A. M. C. and Guimarães, Adolfo P. and Macêdo, Hendrik T.},
  title = {Architectures for interactive vocal environment to Brazilian digital TV middleware},
  pages = {1--8},
  doi = {10.1145/1621087.1621109},
  abstract = {Brazil began in 2007 a new phase in the transmission of terrestrial television: the deployment of Digital TV. Since the beginning, the Brazilian proposal has made it clear its association with digital inclusion as it arose a need of ensuring full accessibility and usability for users of terrestrial TV, among them individuals with special needs. It is in that context that emerges as an alternative the use of voice commands as a means of integrating these users. Using technologies such as voice gateway and VoiceXML language for voice interaction and Ginga as a platform for Digital TV, this work presents two architecture proposals to integrate these two technologies.},
  keywords = {acessibility, digital interactive TV, voice gateway},
  series = {EATIS '08},
  acmid = {1621109},
  address = {New York, NY, EUA},
  articleno = {22},
  booktitle = {Euro American Conference on Telematics and Information Systems},
  isbn = {978-1-59593-988-3},
  lang = {pt},
  location = {Aracaju, #Brazil#},
  numpages = {8},
  publisher = {ACM},
  year = {2008}
}

@MASTERSTHESIS{carvalho-etal:1998,
  author = {M. R. Carvalho},
  title = {{HMBS/M} -- Um Método Orientado a Objetos para o Projeto e o Desenvolvimento de Aplicações Hipermídia},
  school = {ICMC-USP},
  year = {1998},
  address = {São Carlos, SP},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@INPROCEEDINGS{carvalho-etal:1999,
  author = {M. R. Carvalho and M. C. F. Oliveira and P. C. Masiero},
  title = {{HMBS/M} -- an Object Oriented Method for Hypermedia Design},
  pages = {43--62},
  address = {Goiânia, GO, Brazil},
  booktitle = {Simpósio Brasileiro de Multimídia e Sistemas Hipermídia},
  month = jun,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1999}
}

@MASTERSTHESIS{Casagrande01MAPS,
  author = {L. M. Casagrande},
  title = {Um Método para Análise e Projeto de Sistemas de Workflow Administrativo com Interface para a Web},
  school = {ICMC-USP},
  year = {2001},
  address = {São Carlos, SP},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{Casanova-etal:1991,
  author = {Casanova, Marco A. and Tucherman, Luiz and Lima, Maria Julia D. and Rangel Netto, José L. and Rodriquez, Noemi and Soares, Luiz F. G.},
  title = {The Nested Context Model for Hyperdocuments},
  pages = {193-201},
  doi = {10.1145/122974.122993},
  abstract = {This paper describes the nested context model, a conceptual framework for the definition, presentation and browsing of documents. The model carefully combines hypertext links with the concept of context nodes, used to group together sets of nodes. Context nodes can be nested to any depth and, thus, generalize the classical hierarchical organization of documents. The nested context model also defines an abstract and flexible application program interface that captures the idea that different applications may observe the same node in different ways. Finally, the model offers a rich set of operations to explore the double structure of a hyperdocument - that defined by the links and that induced by the nesting of context nodes.},
  series = {HYPERTEXT},
  address = {San Antonio, Texas, EUA},
  booktitle = {3rd ACM Conference on Hypertext},
  isbn = {0-89791-461-9},
  lang = {en},
  location = {San Antonio, Texas, #USA#},
  month = dec,
  publisher = {ACM},
  timestamp = {2012.02.07},
  year = {1991}
}

@ARTICLE{Pessoa-Benitti:2008,
  author = {Marcello de Castro Pessoa and Fabiane Barreto Vavassori Benitti},
  title = {Proposta de um Processo Para Produção de Objetos de Aprendizagem},
  volume = {32},
  number = {62},
  year = {2008},
  pages = {172-180},
  abstract = {Um aspecto importante relacionado a objetos de aprendizagem é o seu processo de produção. Assim como no desenvolvimento dos softwares aplicados as mais diversas áreas, os objetos de aprendizagem também necessitam seguir um cronograma de atividades bem definido e organizado, de forma a otimizar o trabalho de todas as equipes envolvidas.},
  abstract-en = {An important aspect related to learning objects is the production process, which should involve several experts. Just as in the development of software applied the most diverse areas, the learning objects also need follow a schedule of activities, well defined and organized in order to optimize the work of all the professional involved.},
  address = {Uruguaiana, RS, } # Brazil,
  issn = {1983-6511},
  journal = {Hífen},
  lang = {en},
  timestamp = {2009.02.02}
}

@BOOK{Velloso:2003,
  publisher = {Elsevier},
  year = {2003},
  author = {Fernando de Castro Velloso},
  isbn = {978-885-352-1536-6},
  pages = {407},
  address = {Rio de Janeiro, RJ, } # Brazil,
  edition = {7},
  booktitle = {Informática: conceitos básicos}
}

@ARTICLE{caswell-etal:2008,
  author = {Tom Caswell and Shelley Henson and Marion Jensen and David Wiley},
  title = {Open Educational Resources: Enabling universal education},
  volume = {9},
  number = {1},
  month = feb,
  year = {2008},
  url = {http://www.irrodl.org/index.php/irrodl/article/view/469/1001},
  journal = {The International Review of Research in Open and Distance Learning},
  owner = {magsilva},
  timestamp = {2009.02.20}
}

@BOOK{Catania:1998,
  title = {Learning},
  publisher = {Prentice-Hall},
  year = {1998},
  author = {A. Charles Catania},
  isbn = {978-0132352505},
  pages = {462}
}

@ARTICLE{Cattelan-etal:2008,
  author = {Cattelan, Renan G. and Teixeira, Cesar and Goularte, Rudinei and Pimentel, Maria Da Graça C.},
  title = {Watch-and-comment as a paradigm toward ubiquitous interactive video editing},
  volume = {4},
  month = oct,
  year = {2008},
  pages = {28:1--28:24},
  doi = {10.1145/1412196.1412201},
  abstract = {The literature reports research efforts allowing the editing of interactive TV multimedia documents by end-users. In this article we propose complementary contributions relative to end-user generated interactive video, video tagging, and collaboration. In earlier work we proposed the watch-and-comment (WaC) paradigm as the seamless capture of an individual's comments so that corresponding annotated interactive videos be automatically generated. As a proof of concept, we implemented a prototype application, the WaCTool, that supports the capture of digital ink and voice comments over individual frames and segments of the video, producing a declarative document that specifies both: different media stream structure and synchronization. In this article, we extend the WaC paradigm in two ways. First, user-video interactions are associated with edit commands and digital ink operations. Second, focusing on collaboration and distribution issues, we employ annotations as simple containers for context information by using them as tags in order to organize, store and distribute information in a P2P-based multimedia capture platform. We highlight the design principles of the watch-and-comment paradigm, and demonstrate related results including the current version of the WaCTool and its architecture. We also illustrate how an interactive video produced by the WaCTool can be rendered in an interactive video environment, the Ginga-NCL player, and include results from a preliminary evaluation.},
  keywords = {Annotation, Ginga-NCL, P2P collaboration, interactive digital video},
  address = {New York, NY, USA},
  issn = {1551-6857},
  issue = {4},
  journal = {ACM Transactions on Multimedia Computing, Communications and Applications},
  numpages = {24},
  publisher = {ACM}
}

@ARTICLE{caudill:2007,
  author = {Jason G. Caudill},
  title = {The Growth of m-Learning and the Growth of Mobile Computing: Parallel developments},
  volume = {8},
  number = {2},
  month = jun,
  year = {2007},
  url = {http://www.irrodl.org/index.php/irrodl/article/view/348/873},
  journal = {The International Review of Research in Open and Distance Learning},
  owner = {magsilva},
  timestamp = {2009.02.20}
}

@INPROCEEDINGS{Cavano-McCall:1978,
  author = {Joseph P. Cavano and James A. McCall},
  title = {A framework for the measurement of software quality},
  pages = {133-139},
  doi = {10.1145/800283.811113},
  abstract = {Research in software metrics incorporated in a framework established for software quality measurement can potentially provide significant benefits to software quality assurance programs. The research described has been conducted by General Electric Company for the Air Force Systems Command Rome Air Development Center. The problems encountered defining software quality and the approach taken to establish a framework for the measurement of software quality are described in this paper.},
  booktitle = {Software quality assurance workshop on functional and performance issues},
  location = {San Diego, CA, #USA#},
  month = nov,
  owner = {magsilva},
  publisher = {ACM},
  timestamp = {2006.08.22},
  year = {1978}
}

@ARTICLE{Cechinel-etal:2011,
  author = {Cechinel, Cristian and Sánchez-Alonso, Salvador and García-Barriocanal, Elena},
  title = {Statistical profiles of highly-rated learning objects},
  volume = {57},
  number = {1},
  month = aug,
  year = {2011},
  pages = {1255--1269},
  doi = {10.1016/j.compedu.2011.01.012},
  abstract = {The continuously growth of learning resources available in on-line repositories has raised the concern for the development of automated methods for quality assessment. The current existence of on-line evaluations in such repositories has opened the possibility of searching for statistical profiles of highly-rated resources that can be used as priori indicators of quality. In this paper, we analyzed 35 metrics in learning objects refereed inside the MERLOT repository and elaborated profiles for these resources regarding the different categories of disciplines and material types available. We found that some of the intrinsic metrics presented significant differences between highly rated and poorly-rated resources and that those differences are dependent on the category of discipline to which the resource belongs and on the type of the resource. Moreover, we found that different profiles should be identified according to the type of rating (peer-review or user) under evaluation. At last, we developed an initial model using linear discriminant analysis to evaluate the strength of relevant metrics when performing an automated quality classification task. The initial results of this work are promising and will be used as the foundations for the further development of an automated tool for contextualized quality assessment of learning objects inside repositories.},
  keywords = {Architectures for educational technology system, Evaluation methodologies, Learning communities},
  address = {Oxford, } # UK,
  issn = {0360-1315},
  journal = {Computers \& Education},
  publisher = {Elsevier}
}

@MISC{software:zotero,
  author = {{Center for History and New Media (George Mason University)}},
  title = {Zotero},
  howpublished = {Programa de computador},
  month = oct,
  year = {2006},
  abstract = {Zotero is an easy-to-use yet powerful research tool that helps you gather, organize, and analyze sources (citations, full texts, web pages, images, and other objects), and lets you share the results of your research in a variety of ways. An extension to the popular open-source web browser Firefox, Zotero includes the best parts of older reference manager software (like EndNote) - the ability to store author, title, and publication fields and to export that information as formatted references - and the best parts of modern software and web applications (like iTunes and del.icio.us), such as the ability to interact, tag, and search in advanced ways. Zotero integrates tightly with online resources; it can sense when users are viewing a book, article, or other object on the web, and - on many major research and library sites - find and automatically save the full reference information for the item in the correct fields. Since it lives in the web browser, it can effortlessly transmit information to, and receive information from, other web services and applications; since it runs on one's personal computer, it can also communicate with software running there (such as Microsoft Word). And it can be used offline as well (e.g., on a plane, in an archive without WiFi).},
  url = {http://www.zotero.org/}
}

@INPROCEEDINGS{Ceri00WMLW,
  author = {S. Ceri and P. Fraternali and A. Bongio},
  title = {{Web Modeling Language (WebML): A Modeling Language for Designing Web Sites}},
  booktitle = {Proceedings of the 9th international World Wide Web Conference},
  owner = {magsilva},
  publisher = {Elsevier},
  timestamp = {2008.07.30},
  year = {2000}
}

@BOOK{Cervo-etal:2007,
  title = {Metodologia científica},
  publisher = {Pearson Prentice Hall},
  year = {2007},
  author = {Amado Luiz Cervo and Pedro Alcino Bervian and Roberto da Silva},
  isbn = {978-85-7605-047-6},
  pages = {159},
  address = {São Paulo, SP, Brasil},
  edition = {6},
  booktitle = {Metodologia científica}
}

@INPROCEEDINGS{Cesar:2006:BSM:1166160.1166204,
  author = {Cesar, Pablo and Bulterman, D. C. A. and Jansen, A. J.},
  title = {Benefits of structured multimedia documents in {IDTV}: the end-user enrichment system},
  pages = {176--178},
  doi = {10.1145/1166160.1166204},
  abstract = {This paper presents a system that exploits the benefits of modelling multimedia presentations as structured documents within the context of interactive digital television systems. Our work permits end-users to easily enrich multimedia content at viewing time (e.g., add images and delete scenes). Because the document is structured, the system can expose to the user the possible enrichment alternatives depending on the current state of the presentation (e.g., current story). Moreover, because the base content is wrapped as a structured document, the enrichments can be modelled as overlying layers that do not alter the original content. Finally, the user can share the enriched content (or parts of it) to specific peers within a P2P network.},
  keywords = {SMIL, content enrichment, structured multimedia documents},
  address = {New York, NY, USA},
  booktitle = {Proceedings of the 2006 ACM symposium on Document engineering},
  isbn = {1-59593-515-0},
  location = {Amsterdam, The Netherlands},
  publisher = {ACM},
  year = {2006}
}

@INPROCEEDINGS{Cesar-etal:2007,
  author = {Cesar, Pablo and Bulterman, Dick C. A. and Obrenovic, Zeljko and Ducret, Julien and Cruz-Lara, Samuel},
  title = {An architecture for non-intrusive user interfaces for interactive digital television},
  pages = {11--20},
  doi = {10.1007/978-3-540-72559-6_2},
  abstract = {This paper presents an architecture for non-intrusive user interfaces in the interactive digital TV domain. The architecture is based on two concepts. First, the deployment of non-monolithic rendering for content consumption, which allows micro-level personalization of content delivery by utilizing different rendering components (e.g., sending video to the TV screen and extra information to a handheld device). Second, the definition of actions descriptions for user interaction, so that high-level user interaction intentions can be partitioned across a personalized collection of control components (e.g., handheld device). This paper introduces an over-all architecture to support micro-personalization and describes an implementation scenario developed to validate the architecture.},
  volume = {4471},
  series = {EuroITV},
  address = {Berlin, } # Germany,
  booktitle = {5th European conference on Interactive TV: a shared experience},
  isbn = {978-3-540-72558-9},
  location = {Amsterdam, #Netherlands#},
  publisher = {Springer},
  year = {2007}
}

@ARTICLE{Cesar-Chorianopoulos:2009,
  author = {Cesar, Pablo and Chorianopoulos, Konstantinos},
  title = {The Evolution of {TV} Systems, Content, and Users Toward Interactivity},
  volume = {2},
  number = {4},
  month = apr,
  year = {2009},
  pages = {373--95},
  doi = {10.1561/1100000008},
  abstract = {Interactive TV research spans across a rather diverse body of scientific subfields. Research articles have appeared in several venues, such as multimedia, HCI, CSCW, UIST, user modeling, media and communication sciences. In this study, we explore the state-of-the-art and consider two basic issues: What is interactive TV research? Can it help us reinvent the practices of authoring, delivering, and watching TV? For this purpose, we have reviewed the research literature, as well as the industrial developments and identified three concepts that provide a high-level taxonomy of interactive TV research: (1) content editing, (2) content sharing, and (3) content control. We propose this simple taxonomy (edit-share-control) as an evolutionary step over the established hierarchical produce-deliver-consume paradigm. Moreover, we demonstrate how each disciplinary effort has contributed to and why the full potential of interactive TV has not yet been fulfilled. Finally, we describe how interdisciplinary approaches could provide solutions to some notable contemporary research issues.},
  address = {Hanover, MA, USA},
  issn = {1551-3955},
  journal = {Foundations and Trends in Human-Computer Interaction},
  publisher = {Now}
}

@INPROCEEDINGS{Cesar-Chorianopoulos:2008,
  author = {Cesar, Pablo and Chorianopoulos, Konstantinos},
  title = {Interactivity and user participation in the television lifecycle: creating, sharing, and controlling content},
  pages = {125--128},
  doi = {10.1145/1453805.1453830},
  abstract = {Interactive TV research encompasses a rather diverse body of work (e.g. multimedia, HCI, CSCW, UIST, user modeling, media studies) that has accumulated over the past 20 years. In this article, we highlight the state-of-the-art and consider two basic issues: What is interactive TV research? Can it help us reinvent the practices of creating, sharing and watching TV? We survey the literature and identify three concepts that have been inherent in interactive TV research: 1) interactive TV as content creation, 2) interactive TV as a content and experience sharing process, and 3) interactive TV as control of audiovisual content. We propose this simple taxonomy (create-share-control) as an evolutionary step over the traditional hierarchical produce-distribute-consume paradigm. Moreover, we highlight the importance of sociability in all phases of the create-share-control model.},
  keywords = {interactive television, interactivity, research survey, social tv, taxonomy, user participation},
  series = {UXTV '08},
  acmid = {1453830},
  address = {New York, NY, EUA},
  booktitle = {1st International Conference on Designing Interactive User Experiences for TV and Video},
  isbn = {978-1-60558-100-2},
  location = {Silicon Valley, CA, EUA},
  month = oct,
  numpages = {4},
  publisher = {ACM},
  year = {2008}
}

@INPROCEEDINGS{Cesar-Chorianopoulos:2006,
  author = {Cesar, Pablo and Chorianopoulos, Konstantinos},
  title = {Interactive digital television and multimedia systems},
  pages = {7--7},
  doi = {10.1145/1180639.1180642},
  abstract = {Interactive digital television is an emerging field with a high impact in our societies: it offers interactive services to the masses. This tutorial aims to establish a common framework by summarizing the most significant results in this multidisciplinary field. The review includes topics such as content distribution, system software of the receivers, and user interaction. In addition, we will discuss current commercial events such as the next generation of optical discs (e.g., blue-ray), BBC peer-to-peer service, and mobile television. Based on this discussion, we will formulate an agenda for further research. The agenda includes, for example, end-user enrichment of television content and social television. This half-day tutorial will provide the attendee a solid understanding of the technologies currently in use and an introduction of the open questions in the field.},
  keywords = {interactive digital television, software architecture, tutorial projects},
  acmid = {1180642},
  address = {New York, NY, USA},
  booktitle = {14th Annual ACM International Conference on Multimedia},
  isbn = {1-59593-447-2},
  location = {Santa Barbara, CA, USA},
  publisher = {ACM},
  year = {2006}
}

@ARTICLE{Cesar-etal:2008:CIE,
  author = {Cesar, Pablo and Chorianopoulos, Konstantinos and Jensen, Jens F.},
  title = {Social television and user interaction},
  volume = {6},
  number = {1},
  month = may,
  year = {2008},
  pages = {1--10},
  doi = {10.1145/1350843.1350847},
  abstract = {At first glance, the notion of social interactive television seems to be a tautology. Television watching has always been a social activity. People watch television together in their living rooms, and outside their homes they talk about last night's football match; and even call each other to recommend an interesting program. Unfortunately, until recently, research on social interactive television has been scarce. One limiting factor for the development of innovative services for the home is the interactive technology behind user interaction, which was limited to the remote control. Fortunately, a number of studies concentrate on extending interactive methods, for example by using contextual information. This article reviews the state of the art in these two directions: the social aspects of television and user interaction. We conclude with a research agenda for further research, which might transform current interactive television services into shared experiences.},
  keywords = {interactive digital television, set-top box, social communications, social interactive television, user interaction},
  address = {New York, NY, } # USA,
  issn = {1544-3574},
  journal = {Computers in Entertainment},
  publisher = {ACM}
}

@ARTICLE{Cesar:2006:OGF:1164455.1164477,
  author = {Cesar, P. and Vierinen, J. and Vuorimaa, P.},
  title = {Open graphical framework for interactive {TV}},
  volume = {30},
  month = aug,
  year = {2006},
  pages = {189--203},
  doi = {10.1007/s11042-006-0019-1},
  abstract = {Multimedia end-user terminals are expected to perform advanced user interface related tasks. These tasks are carried out by user interface runtime tools and include, among others, the visualization of complex graphics and the efficient handling of user input. In addition, the terminal's graphical system is expected, for example, to be able to synchronize audio and video, and control different contexts on the same screen. Finally, the availability of high-level tools to simplify the user interface implementation and the adaptiveness of the user interfaces for a diversity of configurations are, as well, desirable features. This paper presents a layered model that meets the just mentioned requirements. The architecture is divided into five different layers: hardware abstraction layer, multimedia cross platform libraries, graphical environment, GUI toolkit and high-level languages. Moreover, this paper presents the experiences of developing a prototype system based on the architecture, targeted to digital television receivers. In order to evaluate the prototype, some already developed DVB-MHP compliant digital television applications were tested. Finally, the prototype was extended with a high-level profile (i.e., SMIL support) and a low-level one (i.e., access to the framebuffer memory).},
  keywords = {DVB-MHP, Digital television, Graphics architecture, XML},
  url = {http://portal.acm.org/citation.cfm?id=1164455.1164477},
  acmid = {1164477},
  address = {Hingham, MA, USA},
  issn = {1380-7501},
  issue = {2},
  journal = {Multimedia Tools Appl.},
  numpages = {15},
  publisher = {Kluwer Academic Publishers}
}

@MASTERSTHESIS{Chaim:1991,
  author = {Marcos Lordello Chaim},
  title = {{POKE-TOOL} -- Uma Ferramenta para Suporte ao Teste Estrutural de Programas Baseado em Análise de Fluxo de Dados},
  abstract = {Os principais aspectos da especificação e implementação de uma ferramenta multilinguagem para suporte ao teste estrutural de programas baseado em fluxo de dados são apresentados. Na versão atual a ferramenta, denominada POKE-TOOL, suporta o teste de programas escritos na linguagem C e automatiza a aplicação dos critérios Potenciais Usos (PU) [MAL88a, MAL88b]. Os pontos mais relevantes e os principais algoritmos da implementaçâo são apresentados em detalhe. São também descritos os passos do procedimento a ser realizado por um usuário configurador para gerar configurações desta ferramenta para outras linguagens procedurais. Os aspectos funcionais e de controle de atividades da POKE- TOOL são ilustrados através de uma sessão de trabalho completa, que mostra a aplicação da ferramenta em um programa; o programa exemplo foi extraído de um conjunto de programas utilizado para conduzir um "benchmark" dos critérios Potenciais Usos.},
  school = {DCA/FEEC/UNICAMP},
  year = {1991},
  address = {Campinas, SP, } # Brazil,
  month = apr,
  abstract-en = {The main aspects of the specification and implementation of a multilanguage tool for structural data flow testing of programs are presented. In the present version, the tool, named POKE- TOOL, supports the test of programs written in C; it automates the application of the Potential Uses Criteria [MAL88a, MAL88b]. The most relevant points and main algorithms of the implementation are presented in detail. We also describe the steps of the procedure to be carried out by a user-configurer to generate configurations of the tool for other procedural languages. Functional and activities control aspects of POKE- TOOL are ilustrated through a complete work session, showing the application of the tool on a program; the examp]e program was extracted from a set of programs used to conduct a benchmark of the Potential Uses criteria.},
  note = Advisor: # { Mario Jino}
}

@BOOK{chandrasekaran-radicchi:1981,
  title = {Computer program testing : proceedings of the Summer School on Computer Program Testing held at SOGESTA, Urbino, Italy, June 29-July 3, 1981 / edited by B. Chandrasekaran, S. Radicchi},
  publisher = {Elsevier},
  year = {1981},
  author = {B. Chandrasekaran and S.Radicchi},
  isbn = {0444862927},
  pages = {325},
  address = {Amsterdam},
  lan = {English},
  url = { http://nla.gov.au/nla.cat-vn1670018 }
}

@MISC{dom3validation:2004,
  author = {Ben Chang and Joe Kesselman and Rezaur Rahman},
  title = {Document Object Model (DOM) Level 3 Validation Specification},
  howpublished = {W3C Recommendation},
  month = feb,
  year = {2004},
  comment = {24/05/2005},
  file = {Document Object Model (DOM) Level 3 Validation Specification.pdf:Document Object Model (DOM) Level 3 Validation Specification.pdf:PDF},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://www.w3.org/TR/DOM-Level-3-Val}
}

@ARTICLE{Chang98TOOP,
  author = {K. H. Chang and S. -S. Liao and S. B. Sheidman and R. Chapman},
  title = {Testing Object-Oriented Programs: From Formal Specification to Test Scenario Generation},
  number = {42},
  year = {1998},
  pages = {141--151},
  journal = jss,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@MISC{Chappell97NWCS,
  author = {D. Chappell},
  title = {The Next Wave: Component Software Enters the Mainstream},
  howpublished = {White Paper},
  month = apr,
  year = {1997},
  owner = {magsilva},
  timestamp = {2008.07.31},
  url = {http://www.rational.com/sitewide/support/whitepapers/}
}

@BOOK{Chappell96UAOL,
  title = {Undestanding {A}ctive{X} and {OLE}},
  publisher = {Microsoft Press},
  year = {1996},
  author = {D. Chappell},
  address = {Redmond, WA},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{charters-etal:2009,
  author = {Charters, S. and Budgen, D. and Turner, M. and Kitchenham, B. and Brereton, O.P. and Linkman, S.},
  title = {Objectivity in Research: Challenges from the Evidence-Based Paradigm},
  pages = {73-80},
  doi = {10.1109/ASWEC.2009.25},
  abstract = {For other domains that have adopted the evidence-based paradigm, the impact has included research outcomes having greater influence in terms of informing and influencing practitioners and policy-makers. We examine how evidence-based practices are being adapted for use in software engineering and discuss how decision-making in our own discipline can be liberated from over-reliance on expert judgement. To support our arguments we discuss some outcomes from recent studies and present an example in which performing a systematic literature review demonstrates the unreliability of depending only upon the outcomes of individual studies. Finally, we identify six challenges that need to be addressed in order to provide software engineers with standards and practices that are underpinned by evidence.},
  keywords = {decision making, software engineeringdecision-making, evidence-based paradigm, software engineering},
  booktitle = {Software Engineering Conference, 2009. ASWEC '09. Australian},
  issn = {1530-0803},
  month = {April},
  year = {2009}
}

@BOOK{cheesman:2001,
  title = {UML Components - A Simple Process for Specifying Component-Based Software},
  publisher = {Addison-Wesley},
  year = {2001},
  author = {John Cheesman and John Daniels},
  editor = {Clemens Szyperski},
  series = {Component Software Series},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@ARTICLE{Chen-etal:2008,
  author = {Chaomei Chen and Il-Yeol Song and Xiaojun Yuan and Jian Zhang},
  title = {The thematic and citation landscape of Data and Knowledge Engineering (1985-2007)},
  volume = {67},
  number = {2},
  month = nov,
  year = {2008},
  pages = {234 - 259},
  doi = {10.1016/j.datak.2008.05.004},
  abstract = {The thematic and citation structures of Data and Knowledge Engineering (DKE) (1985-2007) are identified based on text analysis and citation analysis of the bibliographic records of full papers published in the journal. Temporal patterns are identified by detecting abrupt increases of frequencies of noun phrases extracted from titles and abstracts of DKE papers over time. Conceptual structures of the subject domain are identified by clustering analysis. Concept maps and network visualizations are presented to illustrate salient patterns and emerging thematic trends. A variety of statistics are reported to highlight key contributors and DKE papers that have made profound impacts.},
  keywords = {Structural and temporal patterns, Domain analysis, Scientometrics, CiteSpace, Thematic analysis, DKE},
  url = {http://www.sciencedirect.com/science/article/B6TYX-4SM629C-1/2/bef08cba26c4292236cd6b32aa16ab48},
  issn = {0169-023X},
  journal = {Data \& Knowledge Engineering},
  note = {Special Jubilee Issue: DKE 25 Years}
}

@MISC{software:clc4tts,
  author = {Charles L. Chen},
  title = {CLC-4-TTS Interface to FreeTTS for Firefox},
  howpublished = {Programa de computador},
  month = {jan},
  year = {2005},
  owner = {magsilva},
  timestamp = {2007.08.13},
  url = {http://www.firevox.clcworld.net/}
}

@MISC{Chen92DMTT,
  author = {Shu-Shing Chen},
  title = {Design of a Mutation Testing Tool for {C}},
  howpublished = {Department of Computer Sciences, Purdue University},
  month = apr,
  year = {1992},
  owner = {magsilva},
  pages = {1--30},
  timestamp = {2008.07.31}
}

@ARTICLE{cheng:2000,
  author = {Betty H. C. Cheng and David M. Welss},
  title = {Requirements Engineering: Integrating Technology},
  volume = {17},
  number = {3},
  month = {may},
  year = {2000},
  pages = {18-20},
  journal = {IEEE Software},
  owner = {Marco Aurélio Graciotto Silva},
  timestamp = {2008.07.30}
}

@MISC{jta:2002,
  author = {Susan Cheung and Vlada Matena},
  title = {Java Transaction API},
  howpublished = {JCP Specification},
  month = {nov},
  year = {2002},
  file = {Java Transaction API (JTA) Specification 1.0.1B.pdf:Java Transaction API (JTA) Specification 1.0.1B.pdf:PDF},
  owner = {Marco Aurélio Graciotto Silva},
  timestamp = {2008.07.30}
}

@INPROCEEDINGS{Chica-etal:2008,
  author = {Chica, Sebastian de la and Ahmad, Faisal and Martin, James H. and Sumner, Tamara},
  title = {Pedagogically useful extractive summaries for science education},
  pages = {177--184},
  abstract = {This paper describes the design and evaluation of an extractive summarizer for educational science content called COGENT. COGENT extends MEAD based on strategies elicited from an empirical study with science domain and instructional design experts. COGENT identifies sentences containing pedagogically relevant concepts for a specific science domain. The algorithms pursue a hybrid approach integrating both domain independent bottom-up sentence scoring features and domain-aware top-down features. Evaluation results indicate that COGENT outperforms existing summarizers and generates summaries that closely resemble those generated by human experts. COGENT concept inventories appear to also support the computational identification of student misconceptions about earthquakes and plate tectonics.},
  volume = {1},
  series = {COLING '08},
  acmid = {1599104},
  address = {Stroudsburg, PA, USA},
  booktitle = {International Conference on Computational Linguistics},
  isbn = {978-1-905593-44-6},
  location = {Manchester, United Kingdom},
  numpages = {8},
  publisher = {Association for Computational Linguistics},
  url = {http://dl.acm.org/citation.cfm?id=1599081.1599104},
  year = {2008}
}

@INPROCEEDINGS{Chica-etal:2008b,
  author = {Chica, Sebastian de la and Ahmad, Faisal and Martin, James H. and Sumner, Tamara},
  title = {Extractive summaries for educational science content},
  pages = {17--20},
  abstract = {This paper describes an extractive summarizer for educational science content called COGENT. COGENT extends MEAD based on strategies elicited from an empirical study with domain and instructional experts. COGENT implements a hybrid approach integrating both domain independent sentence scoring features and domain-aware features. Initial evaluation results indicate that COGENT outperforms existing summarizers and generates summaries that closely resemble those generated by human experts.},
  series = {HLT-Short '08},
  acmid = {1557696},
  address = {Stroudsburg, PA, USA},
  booktitle = {Annual Meeting of the Association for Computational Linguistics on Human Language Technologies},
  location = {Columbus, Ohio},
  numpages = {4},
  publisher = {Association for Computational Linguistics},
  url = {http://dl.acm.org/citation.cfm?id=1557690.1557696},
  year = {2008}
}

@ARTICLE{chillarege-etal:1992,
  author = {R. Chillarege and I. S. Bhandari and J. K. Chaar and M. J. Halliday and D. S. Moebus and B. K. Ray and M.-Y. Wong},
  title = {Orthogonal Defect Classification: A Concept for In-process Measurements},
  volume = {18},
  number = {11},
  month = nov,
  year = {1992},
  pages = {943-956},
  journal = {IEEE Transactions on Software Engineering},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@MISC{Chipchase-etal:2004,
  author = {Chipchase, Jan and Yanquing, Cui and Jung, Younghee},
  title = {Personal Television: A Qualitative Study of Mobile {TV} Users in {South Korea}},
  howpublished = {White-paper (blog post)},
  year = {2004},
  abstract = {This describes a qualitative user study of mobile phone TV usage undertaken during September 2005 and centered on the real world Mobile TV usage of subscribers of the recently launched live service in Seoul, South Korea. Data collection and reporting methods were optimized to inform and inspire future Nokia product development. The study identified four primary use cases: at home; during the evening commute; macro-breaks; and secret use. Both home and commuting use are likely to be significantly culturally dependent. Barriers to use include: battery life; screen size; lack of compelling content; poor coverage. Design implications are discussed. The study suggests that if the current barriers to use can be overcome Mobile TV is a viable competitor to existing forms of entertainment and media consumption. Mobile TV provides the user with a choice of content in a setting of the user's choosing. These and related findings led us to believe that Mobile TV is more about personal experiences, than the need for mobility itself and we therefore consider Personal TV to be a better descriptor of this service.},
  keywords = {asia, mobile, television},
  status = {obsoleted(Cui-etal:2007)},
  url = {http://research.nokia.com/people/jan_chipchase/PersonalTV_MobileTV.pdf}
}

@INPROCEEDINGS{choi-etal:1989a,
  author = {B. J. Choi and R. A. DeMillo and E. W. Krauser and A. P. Mathur and R. J. Martin and A. J. Offutt and H. Pan and E. H. Spafford},
  title = {The Mothra Toolset},
  address = {HI},
  booktitle = {Twenty-Second Annual Hawaii International Conference on System Sciences},
  month = jan,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1989}
}

@ARTICLE{Choi93HPMT,
  author = {B. J. Choi and A. P. Mathur},
  title = {High-Performance Mutation Testing},
  volume = {1},
  number = {20},
  month = feb,
  year = {1993},
  pages = {135--152},
  journal = jss,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{choi-etal:1989b,
  author = {B. J. Choi and A. P. Mathur and A. P. Pattison},
  title = {{pMothra}: Scheduling Mutants for Execution on a Hypercube},
  pages = {58--65},
  address = {Key West, FL},
  booktitle = {3rd Symposium on Software Testing, Analysis and Verification},
  month = dec,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1989}
}

@INCOLLECTION{Chorianopoulos-etal:2010,
  author = {Chorianopoulos, Konstantinos},
  title = {Scenarios of Use for Sociable Mobile {TV}},
  booktitle = {Mobile TV: Customizing Content and Experience},
  publisher = {Springer London},
  year = {2010},
  editor = {Marcus, Aaron and Sala, Riccardo and Roibás, Anxo Cereijo},
  series = {Human-Computer Interaction Series},
  pages = {243-254},
  abstract = {Mobile TVs have been available for many years, without ever becoming very popular. Moreover, the first wave of research has been mostly concerned with technology and standards, which are necessary to ensure interoperability and market acceptance. Although, there has been a significant body of computer-supported co-operative work (CSCW) and mobile human-computer interaction (HCI) research findings, there is limited investigation in the context of leisure activities, such as TV. In this article, we propose three concepts that drive the main paths for research and practice in mobile and social TV: (1) Mobile TV as a content format, (2) Mobile TV as user behavior, and (3) Mobile TV as interaction terminal. Finally, we provide particular directions to be considered in further research in social and mobile TV.},
  affiliation = {Ionian University, Ionian, Greece},
  doi = {10.1007/978-1-84882-701-1_18},
  isbn = {978-1-84882-701-1},
  keywords = {Computer-mediated communication; interactive TV; mobile TV; social aspects}
}

@ARTICLE{Chorianopoulos:2007,
  author = {Konstantinos Chorianopoulos},
  title = {Content-enriched communication supporting the social uses of {TV}},
  volume = {6},
  number = {1},
  month = jan # {-} # mar,
  year = {2007},
  pages = {23--30},
  abstract = {The technological difference between the broadcast and the telecommunications industries has imposed an artificial distinction between content distribution and interpersonal communication. As a result, content has to be distributed and consumed through broadband, unidirectional and inflexible TV channels, while interpersonal communication takes place over low-bandwidth bidirectional channels. The convergence of platforms offers many opportunities for integrated content and communication services, which we refer to as content-enriched communication.},
  journal = {Journal of the Communications Network}
}

@PHDTHESIS{Chorianopoulos:2004,
  author = {Chorianopoulos, Konstantinos},
  title = {Virtual television channels: conceptual model, user interface design and affective usability evaluation},
  abstract = {This doctoral dissertation aims to investigate user interface (UI) design, implementation and evaluation for interactive television (ITV) applications. Computer mediated entertainment (e.g. video-games, digital music, DVD movies, ITV) has emerged as a major economic factor in the media industry, taking-up a large portion of consumer spending and leisure time. Advances in set-top box technology made possible the digital video recorder (DVR) and Internet connectivity, thus making the television interactive. The objective of the present work is to evaluate the established human-computer interaction (HCI) theory against the requirements of ITV applications. Previous HCI research about ITV focused only on the design of the electronic program guide (EPG) and did not consider the enhancement of the TV content. Furthermore, previous research approached ITV from a single perspective (e.g. computer engineering, advertising, communication) and it did not consider the conflicts of interest between the broadcasters and the consumers, between the developers and the producers, and more crucially, it did not consider the ITV user as a TV viewer. For this purpose, the established TV watching behavior is identified in other scientific disciplines, such as advertising and communication, and it is combined with the Information Technology (IT) usability mentality. The design methodology involves two phases. The objective of the first design phase is to formulate a small set of principal elements that are generic to the design of ITV UIs, such as Virtual Channel conceptual model, UI principles, UI development toolkit, prototyping platform, and affective usability evaluation framework. The objective of the second design phase is to employ the elements identified in the previous stage into the development of an ITV application. The ITV application was evaluated by consumers and addressed three contemporary UI issues: video skipping, animated character, and dynamic advertisement insertion. Overall, the methodology employed a holistic design approach for ITV applications, in which the UI model and the business model were systematically mapped to and validated through an ITV music application. In brief, it was found that the track-skipping UI seamlessly enhanced consumer entertainment. Moreover, it was found that an animated character is preferred, when compared with the traditional transparent box for the presentation of related information. Consumers evaluated the dynamic advertisement insertion positively, thus, opening-up many opportunities for novel advertising formats. The employment of the proposed HCI elements made the design and the development of the ITV application a straightforward process and produced an entertainment experience that was liked by the consumers. The results entail significant implications for the TV industry. ITV is currently perceived as a set of decorative elements, which do not provide any actual improvement of the existing TV content. On the other hand, video-skipping is a familiar functionality that should be exploited, instead of neglected due to the fear of cannibalizing the fixed advertising of the broadcast schedules. The dynamic advertisement insertion in the TV content stream offers a novel advertising format. Finally, there are opportunities for a new mediating role in the media industry that combines the available broadcast transmission with additional elements (Internet resources, computer generated graphics) for the provision of personalized virtual television channels.},
  keywords = {Human - computer interaction; Interactive television; User interface; Design; Evaluation; Usability engineering; Animated character; Music TV},
  school = {Department of Management Science and Technology, Athens University of Economics and Business},
  year = {2004},
  address = {Athens, } # Greece,
  month = may,
  url = {http://www.mendeley.com/download/public/612711/3617146141/dc32b2673407c9afc4c44306cb3213dbf15869af/dl.pdf},
  lang = {en},
  pages = {165}
}

@ARTICLE{Chorianopoulos-Geerts:2011,
  author = {Konstantinos Chorianopoulos and David Geerts},
  title = {Introduction to user experience design for TV Apps},
  volume = {2},
  number = {3},
  year = {2011},
  pages = {149 - 150},
  doi = {10.1016/j.entcom.2011.03.009},
  abstract = {In this introduction to the special issue of Entertainment Computing on the new TV landscape, we introduce interactive television (iTV) research as one of the pillars in the field of entertainment computing. Although entertainment computing has been associated mainly with video-games, there is also more than a couple of decades' research in computer applications for television. Contemporary infrastructures have been converging towards mature development platforms, but there are still several user experience issues in TV applications (TV Apps). Here, we explore significant contributions to interactive TV, and we provide directions for further research in user experience design for TV Apps.},
  keywords = {TV Apps, iTV, User experience, Television, Mobile TV, Social TV},
  issn = {1875-9521},
  journal = {Entertainment Computing},
  note = {User experiences in the new TV landscape},
  publisher = {Springer}
}

@ARTICLE{Chorianopoulos-Lekakos:2007,
  author = {Chorianopoulos, Konstantinos and Lekakos, George},
  title = {Learn and play with interactive TV},
  volume = {5},
  number = {2},
  month = apr,
  year = {2007},
  pages = {9},
  doi = {10.1145/1279540.1279544},
  abstract = {Despite the criticism concerning the value of TV content, research reveals several worthwhile aspects -- one of them is the opportunity to learn. In this article we explore the characteristics of interactive TV applications that facilitate education and interactive entertainment. In doing so we analyze research methods and empirical results from experimental and field studies. The findings suggest that interactive TV applications provide support for education and entertainment for children and young people, as well as continuous education for all. In particular, interactive TV is especially suitable for (1) informal learning and (2) for engaging and motivating its audience. We conclude with an agenda for future interactive TV research in entertainment and education.},
  keywords = {interactive TV, interactive television, set-top box, study, user interface},
  address = {New York, NY, EUA},
  issn = {1544-3574},
  journal = {Computers in Entertainment},
  publisher = {ACM}
}

@ARTICLE{Chorianopoulos-Spinellis:2006,
  author = {Chorianopoulos, Konstantinos and Spinellis, Diomidis},
  title = {User interface evaluation of interactive TV: a media studies perspective},
  volume = {5},
  number = {2},
  month = jul,
  year = {2006},
  pages = {209--218},
  doi = {10.1007/s10209-006-0032-1},
  abstract = {A diverse user population employs interactive TV (ITV) applications in a leisure context for entertainment purposes. The traditional user interface (UI) evaluation paradigm involving efficiency and task completion may not be adequate for the assessment of such applications. In this paper, we argue that unless ITV applications are evaluated with consideration for the ordinary TV viewer, they are going to be appropriate only for the computer literate user, thus excluding the TV audience from easy access to information society services. The field of media studies has accumulated an extensive theory of TV and associated methods. We applied the corresponding findings in the domain of ITV to examine how universal access to ITV applications can be obtained. By combining these results with emerging affective quality theories for interactive products, we propose a UI evaluation framework for ITV applications.},
  keywords = {Affective quality, Evaluation, Interactive television, Media studies, Methodology, User interface},
  address = {Berlin, Germany},
  issn = {1615-5289},
  journal = {Universal Access in the Information Society},
  lang = {en},
  publisher = {Springer}
}

@ARTICLE{Chow78TSDM,
  author = {T. S. Chow},
  title = {Testing Software Design Modelled by Finite-State Machines},
  volume = {4},
  number = {3},
  year = {1978},
  pages = {178--187},
  journal = ieeese,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@MISC{christensen2001wsd,
  author = {E. Christensen and F. Curbera and G. Meredith and S. Weerawarana},
  title = {Web Services Description Language (WSDL)},
  year = {2001},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@MISC{wsdl:2001,
  author = {Erik Christensen and Francisco Curbera and Greg Meredith and Sanjiva Weerawarana},
  title = {Web Services Description Language (WSDL) 1.1},
  howpublished = {W3C Note},
  month = mar,
  year = {2001},
  comment = {24/05/2005},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://www.w3.org/TR/wsdl}
}

@ARTICLE{chung:1991,
  author = {Lawrence Chung and Panagiotis Katalagarianos and Manolis Marakakis and Michalis Mertikas and John Mylopoulos and Yannis Vassiliou},
  title = {From information system requirements to designs: a mapping framework},
  volume = {16},
  number = {4},
  year = {1991},
  pages = {429 - 461},
  journal = {Information Systems},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@ARTICLE{churchill:2008,
  author = {Daniel Churchill},
  title = {Learning Objects for Educational Applications via PDA Technology},
  volume = {19},
  number = { 1 },
  month = jan,
  year = {2008},
  pages = {5--20},
  abstract = { This article discusses an ongoing study into issues relevant to the design of learning objects for educational applications via portable digital assistant (PDA) technology... },
  url = { http://go.editlib.org/p/21990 },
  address = { Chesapeake, VA },
  issn = { 1093-023X },
  journal = {Journal of Interactive Learning Research},
  publisher = { AACE }
}

@ARTICLE{chusho:1987,
  author = {T. Chusho},
  title = {Test Data Selection and Quality Estimation Based on Concept of Essential Branches for Path Testing},
  volume = {13},
  number = {7},
  month = may,
  year = {1987},
  pages = {509-517},
  doi = {10.1109/TSE.1987.233196},
  journal = {IEEE Transactions on Software Engineering},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@MASTERSTHESIS{Cia:2006,
  author = {Thais Miranda Cia},
  title = {Evaluation model of software configuration management process},
  abstract = {The Configuration Management has been studied since the 70s. In the beginning it was applied in the same way for software and hardware, but in the late 70s there were some specific configuration management patterns defined for software. The demand for software quality has increased recently, this way the configuration management practices have been more used in software development, because the software configuration management is one of the most important processes to assess quality during software development or maintenance. Although its use is increasing, there is no consensus about the configuration management practices and the names applied to them. The objective of this work is to elaborate an evaluation model for configuration management process, to evaluate the practices and the fundamental processes to perform configuration management, based on the most important software development standards. This evaluation model can also be used to evaluate configuration management tools, identifying what practices and process it help to execute.},
  school = {Universidade de São Paulo},
  year = {2006},
  advisor = {Rosely Sanches},
  address = {São Carlos, SP, } # Brazil,
  month = may,
  url = {http://www.teses.usp.br/teses/disponiveis/55/55134/tde-24082006-163201/pt-br.php},
  abstract-original = {A gerência de configuração vem sendo estudada desde os anos sessenta. Inicialmente, era aplicada da mesma forma para software e hardware, sendo que no final dos anos setenta já havia padrões de gerência de configuração específicos para software. Com a crescente demanda por qualidade de software, as práticas de gerência de configuração vem sendo cada vez mais utilizadas no desenvolvimento de software, uma vez que a gerência de configuração de software é um dos processos fundamentais para se ter qualidade no desenvolvimento e manutenção de software. Embora cada vez mais amplamente utilizado, não existe um consenso de práticas e nomenclaturas sobre as práticas de gerência de configuração. Dessa forma, o objetivo deste trabalho é elaborar um modelo de avaliação do processo de Gerência de Configuração, que permite avaliar as práticas e processos fundamentais para a implantação da gerência de configuração, levando em consideração as práticas e processos descritos nas principais normas internacionais de desenvolvimento de software. Esse modelo de avaliação também permite que as ferramentas disponíveis para gerência de configuração sejam avaliadas, identificando quais práticas e processos elas auxiliam na execução.},
  lang = {pt},
  title-original = {Modelo de avaliação do processo de gerência de configuração de software}
}

@TECHREPORT{Cima97RSOO,
  author = {A. M. Cima and C. M. L. Werner},
  title = {A Reutilização de Software e a Orienta\c c\~ao a Objetos},
  institution = {Universidade Federal do Rio de Janeito -- {COPPE/UFRJ}},
  year = {1997},
  number = {{ES}-433/97},
  address = {Rio de Janeiro, RJ},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{Cirilo-etal:2010b,
  author = {Cirilo, Carlos E. and Prado, Antonio F. do and Souza, Wanderley L. de and Zaina, Luciana A. M.},
  title = {Model Driven RichUbi - A Model-Driven Process to Construct Rich Interfaces for Context-Sensitive Ubiquitous Applications},
  pages = {100--109},
  doi = {10.1109/SBES.2010.20},
  abstract = {Software development that meets the demand of Ubiquitous Computing, in which access to applications occurs anywhere, anytime and from different devices, has raised new challenges for Software Engineering. Among these challenges it stands out the development of context-sensitive ubiquitous applications. Much of the effort required for building such applications can be reduced through the reuse of the application's modeling. Different parts of a ubiquitous application can be reused, such as the user interface. Generate the interfaces' code so that they can self-adapt according to the different access contexts makes the application more dynamic and personalized. Therefore, by combining the conceptions of rich interfaces, domain-specific modeling, and context sensitivity, this paper presents a development process, called Model Driven RichUbi, to support the construction of rich interfaces for context-sensitive ubiquitous applications.},
  keywords = {software process, model-driven development, domain specific modeling, adaptive rich interfaces},
  series = {SBES '10},
  acmid = {1916021},
  address = {Washington, DC, USA},
  booktitle = {Proceedings of the 2010 Brazilian Symposium on Software Engineering},
  isbn = {978-0-7695-4273-7},
  numpages = {10},
  publisher = {IEEE Computer Society},
  year = {2010}
}

@MISC{Cisco:2001,
  author = {{Cisco Systems, Inc.}},
  title = {Reusable Learning Object Strategy: Designing Information and Learning Objects Through Concept, Fact, Procedure, Process and Principle Templates},
  howpublished = {CISCO Systems},
  month = nov,
  year = {2001},
  owner = {magsilva},
  timestamp = {2008.07.31},
  url = {http://www.cisco.com/warp/public/779/ibs/solutions/learning/whitepapers/el_cisco_rio.pdf}
}

@MISC{Clarifi00,
  author = {{CLARiFi Project Team}},
  title = {{CLARiFi} -- {CL}ear {A}nd {R}eliable {I}nformation {F}or {I}ntegration},
  howpublished = {Página na Web},
  owner = {magsilva},
  timestamp = {2008.07.31},
  url = {http://clarifi.eng.it/}
}

@TECHREPORT{clark:1999,
  author = {J. Clark},
  title = {Extensible Style Sheet Language Transformations (XSLT)},
  institution = {W3C},
  year = {1999},
  url = {http://www.w3c.org/TR/xslt/},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@MISC{xslt:1999,
  author = {James Clark},
  title = {XSL Transformations (XSLT)},
  howpublished = {W3C Recommendation},
  month = nov,
  year = {1999},
  comment = {24/05/2005},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://www.w3.org/TR/xslt}
}

@MISC{xpath:1999,
  author = {James Clark and Steve DeRose},
  title = {XML Path Language (XPath)},
  howpublished = {W3C Recommendation},
  month = nov,
  year = {1999},
  comment = {24/05/2005},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://www.w3.org/TR/xpath}
}

@ARTICLE{Clarke76SGTD,
  author = {L. A. Clarke},
  title = {A System to Generate Test Data and Symbolically Execute Programs},
  volume = {2},
  number = {3},
  month = sep,
  year = {1976},
  pages = {215--222},
  journal = ieeese,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@ARTICLE{clarke:2002,
  author = {Roger Clarke},
  title = {The Birth of Web Commerce},
  year = {2002},
  url = {http://www.anu.edu.au/people/Roger.Clarke/II/WCBirth.html},
  owner = {magsilva},
  timestamp = {2006.06.18}
}

@ARTICLE{clear:2010,
  author = {Tony Clear},
  title = {Diagnosing Your Teaching Style: How Interactive Are You?},
  volume = {1},
  number = {1},
  month = jun,
  year = {2010},
  pages = {34-41},
  journal = {ACM Inroads},
  owner = {magsilva},
  timestamp = {2010.06.17}
}

@ARTICLE{cleaveland:1988,
  author = {J. Craig Cleaveland},
  title = {Building Application Generators},
  volume = {4},
  number = {4},
  month = jul,
  year = {1988},
  pages = {25-33},
  doi = {10.1109/52.17799},
  journal = {IEEE Software},
  owner = {magsilva},
  timestamp = {2007.09.11}
}

@INPROCEEDINGS{cleland-huang:2004,
  author = {Jane Cleland-Huang and Grant Zemont and Wiktor Lukasik},
  title = {A Heterogeneous Solution for Improving the Return of Investment of Requirements Traceability},
  pages = {230-239},
  doi = {10.1109/ICRE.2004.1335680},
  address = {Kyoto, Japão},
  booktitle = {IEEE International Requirements Engineering Conference},
  month = {sep},
  owner = {Marco Aurélio Graciotto Silva},
  timestamp = {2008.07.30},
  year = {2004}
}

@BOOK{clements-northrop:2001,
  title = {Software Product Lines: Practices and Patterns},
  publisher = {Addison-Wesley},
  year = {2001},
  author = {Paul Clements and Linda Northrop},
  pages = {563},
  series = {SEI Series in Software Engineering},
  address = {USA},
  month = aug,
  owner = {magsilva},
  timestamp = {2010.07.09}
}

@TECHREPORT{standard:cmu:cmmi:1.3,
  author = {{CMMI Product Team}},
  title = {{CMMI} for Development version 1.3},
  institution = {Software Engineering Institute -- Carnegie Mellon University},
  month = nov,
  year = {2010},
  number = {CMU/SEI-2010-TR-033},
  address = USA,
  url = {http://www.sei.cmu.edu/library/abstracts/reports/10tr033.cfm},
  abstract = {CMMI (Capability Maturity Model Integration) models are collections of best practices that help organizations to improve their processes. Thesemodels are developed by product teams with members from industry, government, and the Carnegie Mellon Software Engineering Institute (SEI). This model, called CMMI for Development (CMMI-DEV), provides a comprehensive integrated set of guidelines for developing products and services.}
}

@TECHREPORT{standard:cmu:cmmi-1.3,
  author = {{CMMI Product Team}},
  title = {CMMI for Development version 1.3},
  institution = {Software Engineering Institute, Carnigie Mellon University},
  month = nov,
  year = {2010},
  number = {CMU/SEI-2010-TR-033},
  address = USA,
  url = {http://www.sei.cmu.edu/library/abstracts/reports/10tr033.cfm},
  pages = {468},
  publisher = {Carnegie Mellon University}
}

@TECHREPORT{standard:cmu:cmmi:1.2,
  author = {{CMMI Product Team}},
  title = {{CMMI} for Development version 1.2},
  institution = {Software Engineering Institute -- Carnegie Mellon University},
  month = aug,
  year = {2006},
  number = {CMU/SEI-2006-TR-008},
  address = USA,
  url = {http://www.sei.cmu.edu/library/abstracts/reports/06tr008.cfm},
  abstract = {CMMI for Development (CMMI-DEV), Version 1.2 is an upgrade of CMMI-SE/SW/IPPD/SS, Version 1.1. The focus of the CMMI Version 1.2 effort is on improving the quality of CMMI products and the consistency of how they are applied. This report represents the model portion of the CMMI Product Suite. Other portions of the CMMI Product Suite include the SCAMPI A appraisal method and the Introduction to CMMI training course. CMMI now includes the concept of CMMI "constellations." A constellation is a set of CMMI components designed to meet the needs of a specific area of interest. A constellation can produce one or more related CMMI models and related appraisal and training materials. CMMI for Development is the first of these constellations. This report contains the two models that comprise the CMMI for Development constellation: the CMMI for Development and CMMI for Development +IPPD models. The report consists of three parts. Part one is the overview, which describes CMMI concepts, model components, and guidance on using the CMMI Product Suite. Part two contains the generic goals and practices and process areas, which are used by organizations to improve their development processes. Part three contains references, acronyms, project participants, and a glossary.}
}

@TECHREPORT{standard:cmu:cmmi-1.2,
  author = {{CMMI Product Team}},
  title = {CMMI for Development version 1.2},
  month = aug,
  year = {2006},
  publisher = {Carnegie Mellon University}
}

@TECHREPORT{standard:cmu:cmmi:1.1-continuous,
  author = {{CMMI Product Team}},
  title = {{CMMI} for Development version 1.1 (Continuous Representation)},
  institution = {Software Engineering Institute -- Carnegie Mellon University},
  month = aug,
  year = {2002},
  number = {CMU/SEI-2002-TR-028},
  address = USA,
  url = {http://www.sei.cmu.edu/library/abstracts/reports/02tr028.cfm},
  abstract = {Capability Maturity Model Integration (CMMI) models have evolved the Capability Maturity Model (CMM) established by the Capability Maturity Model for Software (SW-CMM), to a new level that enables the continued growth and expansion of the CMM concept to multiple disciplines. Like the SW-CMM, EIA/IS 731, IPD-CMM, SA-CMM, and other process improvement models, CMMI models are tools that help organizations improve their processes. This CMMI model is designed to help organizations improve their product and service development, acquisition, and maintenance processes. Software engineering concepts are covered by this model, including traditional CMM concepts such as process management and project management. Each CMMI model is designed to be used in concert with other CMMI models, making it easier for organizations to pursue enterprise-wide process improvement at their own pace. This CMMI model has a continuous representation, which focuses on measuring process improvement using capability levels. Capability levels apply to process-improvement achievement within individual process areas such as Configuration Management or Verification.}
}

@TECHREPORT{standard:cmu:cmmi:1.1-staged,
  author = {{CMMI Product Team}},
  title = {{CMMI} for Development version 1.1 (Staged Representation)},
  institution = {Software Engineering Institute -- Carnegie Mellon University},
  month = aug,
  year = {2002},
  number = {CMU/SEI-2002-TR-029},
  address = USA,
  url = {http://www.sei.cmu.edu/library/abstracts/reports/02tr029.cfm},
  abstract = {Capability Maturity Model Integration (CMMI) models have evolved the Capability Maturity Model (CMM) concept, established by the Capability Maturity Model for Software (SW-CMM), to a new level that enables the continued growth and expansion of the CMM concept to multiple disciplines. Like the SW-CMM, EIA/IS 731, IPD-CMM, SA-CMM, and other process improvement models, CMMI models are tools that help organizations improve their processes. This CMMI model is designed to help organizations improve their product and service development, acquisition, and maintenance processes. Software engineering concepts are covered by this model, including traditional CMM concepts such as process management and project management. Each CMMI model is designed to be used in concert with other CMMI models, making it easier for organizations to pursue enterprise-wide process improvement at their own pace. This CMMI model has a staged representation, which focuses on measuring process improvement using maturity levels. Maturity levels apply to process-improvement achievement across the organizational unit using the model.}
}

@BOOK{standard:cmu:cmmi-1.1,
  title = {CMMI for Development v1.1},
  publisher = {Carnegie Mellon University},
  year = {2002},
  author = {CMMI Product Team, Software Engineering Institute},
  month = aug
}

@MISC{Coad02FDDG,
  author = {P. Coad and S. Palmer},
  title = {Feature-Driven Development: Guide},
  year = {2002},
  owner = {magsilva},
  timestamp = {2008.07.31},
  url = {http://www.nebulon.com/articles/fdd/latestfdd.html/}
}

@BOOK{Cockburn:2001,
  publisher = {Addison-Wesley Longman},
  year = {2001},
  author = {Cockburn, Alistair},
  isbn = {0201702258},
  pages = {270},
  series = {The Agile Software Development Series},
  address = {Boston, MA, } # USA,
  edition = {1},
  abstract = {Writing use cases as a means of capturing the behavioral requirements of software systems and business processes is a practice that is quickly gaining popularity. Use cases provide a beneficial means of project planning because they clearly show how people will ultimately use the system being designed. On the surface, use cases appear to be a straightforward and simple concept. Faced with the task of writing a set of use cases, however, practitioners must ask: "How exactly am I supposed to write use cases?" Because use cases are essentially prose essays, this question is not easily answered, and as a result, the task can become formidable. In Writing Effective Use Cases, object technology expert Alistair Cockburn presents an up-to-date, practical guide to use case writing. The author borrows from his extensive experience in this realm, and expands on the classic treatments of use cases to provide software developers with a "nuts-and-bolts" tutorial for writing use cases. The book thoroughly covers introductory, intermediate, and advanced concepts, and is, therefore, appropriate for all knowledge levels. Illustrative writing examples of both good and bad use cases reinforce the author's instructions. In addition, the book contains helpful learning exercises -- with answers -- to illuminate the most important points. Highlights of the book include: a thorough discussion of the key elements of use cases --actors, stakeholders, design scope, scenarios, and more; a use case style guide with action steps and suggested formats; an extensive list of time-saving use case writing tips; a helpful presentation of use case templates, with commentary on when and where they should be employed; a proven methodology for taking advantage of use cases. With this book as your guide, you will learn the essential elements of use case writing, improve your use case writing skills, and be well on your way to employing use cases effectively for your next development project.},
  booktitle = {Writing Effective Use Cases},
  timestamp = {2013-10-31}
}

@BOOK{Coffey:1977,
  title = {Educational technology courses for teachers in training},
  publisher = {Council for Educational Technology for the United Kingdom},
  year = {1977},
  author = {John Coffey},
  series = {CET discussion document},
  url = {http://books.google.com.br/books?id=Vwp5GwAACAAJ}
}

@ARTICLE{Coffey-etal:2006,
  author = {John W. Coffey and Robert Hoffman and Alberto Canas},
  title = {Concept map-based knowledge modeling: perspectives from information and knowledge visualization},
  volume = {5},
  month = jun,
  year = {2006},
  pages = {192-201},
  doi = {10.1057/palgrave.ivs.9500129},
  abstract = {This article explores the idea of knowledge modeling as defined at the Florida Institute for Human and Machine Cognition. The notion of knowledge modeling is described to illustrate a particular method by which concept maps might be employed to create a useful structure and organization of other information and knowledge resources. Knowledge model structuring and navigational schemes afforded by the approach are described and illustrated. An example of a knowledge model pertaining to weather forecasting on the Gulf coast of the United States is presented to illustrate these ideas. Examples of how information visualization techniques have been and might be applied to the knowledge modeling scheme are discussed. Ideas pertaining to how knowledge models might serve as learning resources are briefly presented throughout. The article concludes with additional discourse regarding specific ways in which the knowledge modeling approach might be employed to create, present, and organize effective electronic learning resources.},
  keywords = {Concept maps, knowledge modeling, knowledge visualization},
  eissn = {1473-8724},
  issn = {1473-8716},
  journal = {Information Visualization}
}

@INPROCEEDINGS{Coffey-etal:2002,
  author = {J. W. Coffey and R. Hoffman and A. J. Canas and K. M. Ford},
  title = {A Concept Map-Based Knowledge Modeling Approach to Expert Knowledge Sharing},
  pages = {212--217},
  address = {Virgin Islands, EUA},
  booktitle = {IASTED International Conference on Information and Knowledge Sharing (IKS)},
  month = nov,
  owner = {magsilva},
  publisher = {ACTA Press},
  timestamp = {2008.07.30},
  year = {2002}
}

@MISC{software:misa,
  author = {{COGIGRAPH Technologies INC (TCI)}},
  title = {{MISA}},
  howpublished = {Método de projeto instrucional},
  year = {1991},
  timestamp = {2008.10.05},
  url = {http://www.cogigraph.com/Produits/MISA/tabid/996/language/en-US/Default.aspx}
}

@MASTERSTHESIS{Colanzi99AIDT,
  author = {T. E. Colanzi},
  title = {Uma Abordagem Integrada de Desenvolvimento e Teste de Software Baseada na {UML}},
  school = {ICMC-USP},
  year = {1999},
  address = {S\~ao Carlos -- SP},
  month = jun,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@BOOK{Coleman94OODF,
  title = {Object-Oriented Development: The FUSION Method},
  publisher = {Prentice Hall International},
  year = {1994},
  author = {D. Coleman and P. Arnold and S. Bodoff and C. Dollin and H. Gilchrist and F. Hayes and P. Jeremaes},
  address = {Englewood Cliffs, New Jersey, USA},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@INPROCEEDINGS{Collazos:2002:ECL:646133.680293,
  author = {Collazos, C\ésar A. and Guerrero, Luis A. and Pino, José A. and Ochoa, Sergio F.},
  title = {Evaluating Collaborative Learning Processes},
  pages = {203--221},
  abstract = {Understanding and analyzing collaborative learning processes require a fine-grained sequential analysis of the group interaction in the context of learning goals. Several researchers in the area of cooperative work take as a success criterion the quality of the group outcome. Nevertheless, recent findings are giving importance to the quality of the cooperation process itself. This paper presents a set of indicators which main objective is to evaluate the collaborative learning process. We have defined an experiment with a tool instrumented to gather data from groups working in a simple task. This data is then useful to build the cooperation indicators, which in turn allow us to estimate the quality of the work process.},
  series = {CRIWG '02},
  acmid = {680293},
  address = {London, UK, UK},
  booktitle = {Proceedings of the 8th International Workshop on Groupware: Design, Implementation and Use},
  isbn = {3-540-44112-3},
  numpages = {19},
  publisher = {Springer-Verlag},
  url = {http://portal.acm.org/citation.cfm?id=646133.680293},
  year = {2002}
}

@BOOK{collins-sussman:2006,
  title = {Version Control with Subversion},
  publisher = {O'Reilly Media},
  year = {2006},
  author = {Ben Collins-Sussman and Brian W. Fitzpatrick and C. Michael Pilato},
  owner = {magsilva},
  timestamp = {2006.07.18},
  url = {http://svnbook.red-bean.com/}
}

@ARTICLE{collis-strijker:2003,
  author = {Betty Collis and Allard Strijker},
  title = {Re-Usable Learning Objects in Context},
  volume = { 2 },
  number = { 4 },
  year = {2003},
  pages = {5--16},
  abstract = {While the idea of reusing educational software is not new, a new wave of interest is occurring based on the idea of reusable learning objects...},
  url = { http://go.editlib.org/p/14507 },
  address = { Norfolk, VA },
  issn = { 1537-2456 },
  journal = { International Journal on E-Learning },
  publisher = { AACE }
}

@TECHREPORT{compressionru-x264:2008,
  author = {{Computer Graphics and Multimedia Laboratory}},
  title = {Options Analysis of MPEG-4 AVC/H.264 Codec x264},
  institution = {Computing Mathematics and Cybernetics Department - Moscow State University},
  month = dec,
  year = {2008},
  address = {Russia},
  url = {http://compression.ru/video/codec_comparison/x264_options_analysis_08_en.html}
}

@TECHREPORT{compressionru-lossless:2007,
  author = {{Computer Graphics and Multimedia Laboratory}},
  title = {Lossless Video Codecs Comparison '2007},
  institution = {Computing Mathematics and Cybernetics Department - Moscow State University},
  month = mar,
  year = {2007},
  address = {Russia},
  url = {http://compression.ru/video/codec_comparison/lossless_codecs_2007_en.html}
}

@BOOK{conallen:2002,
  title = {Building Web Applications with UML},
  publisher = {Addison Wesley},
  year = {2002},
  author = {Jim Conallen},
  edition = {2},
  month = oct,
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@INPROCEEDINGS{Cong-etal:2010,
  author = {Cong, Xiao and Zhang, Hongmei and Zhou, Dongdai and Lu, Peng and Qin, Ling},
  title = {A model-driven architecture approach for developing e-learning platform},
  pages = {111--122},
  abstract = {Currently, there are many problems of the application development of E-Learning platform such as the difficulty to use learning object from an LMS in another one, and the domain model reuse rate is low in various application systems, and hardness to ensure the consistency between designs and codes. These problems have constrained the development efficiency of E-Learning application software and its quality. In this paper, we proposed a model-driven development approach for E-Learning platform. First, establish the domain model (CIM) through the analysis of business logic, and then establish robustness diagram of the system after the robustness analysis. Then we stratified on the PIM under the J2EE framework, and proposed the method of transformation from PIM to PSM layer by layer. This approach not only effectively solves the above problems, but also improves the efficiency of software development through the automatically generated code.},
  keywords = {E-learning, J2EE, MDA, model transformation},
  series = {Edutainment'10},
  acmid = {1881776},
  address = {Berlin, Heidelberg},
  booktitle = {International Conference on Entertainment for education},
  isbn = {978-3-642-14532-2},
  location = {Changchun, China},
  numpages = {12},
  publisher = {Springer-Verlag},
  year = {2010}
}

@MISC{wcag2.0:2007,
  author = {World Wide Web Consortium},
  title = {Web Content Accessibility Guidelines 2.0},
  howpublished = {Working draft},
  month = {may},
  year = {2007},
  owner = {magsilva},
  timestamp = {2007.08.11},
  url = {http://www.w3.org/TR/WCAG20/}
}

@ARTICLE{Convertini-etal:2006,
  author = {Vito Nicola Convertini and Diego Albanese and Agostino Marengo and Vittorio Marengo and Michele Scalera},
  title = {The {OSEL} Taxonomy for the Classification of Learning Objects},
  volume = {2},
  year = {2006},
  pages = {125 - 138},
  abstract = {This project started from the necessity to create a taxonomic classification for the management of the Learning Objects (LO) repository used by the LCMS platforms. The classification obtained is now in use for the OSEL project (OSEL website - http://www.osel.it). The OSEL project is financed by the Statistics Department of the University of Bari. The aim is to analyze and to promote the introduction of blended e-learning in the academic world. Many LCMSs Open-source platforms have been studied, tested and put at users' disposal. The support to the ADL/SCORM (see http://www.adlnet.org) given by all the platforms has allowed the integration in the OSEL web of the repository service, along with the services already in use (forum, newsletter, glossary, database). The aim is to gather and to catalogue the LO products proposed in the various courses and managed by the learners on the web. Starting from Wiley's (2000) and Redeker's (2003) taxonomies, the research group studied the OSEL Taxonomy and presented the project of a web application able to classify the LO and to place them in order into the repository.},
  keywords = {taxonomy, learning objects, OSEL, repository, SCORM},
  editor = {Keith Harman},
  journal = {Interdisciplinary Journal of Knowledge and Learning Objects},
  timestamp = {2012.01.20}
}

@BOOK{Cook-Campbell:1979,
  title = {Quasi-Experimentation -- Design and Analysis Issues for Field Settings},
  publisher = {Houghton Miffin Company},
  year = {1979},
  author = {T. Cook and D. Campbell}
}

@BOOK{copeland:2004,
  title = {A Practitioner's Guide to Software Test Design},
  publisher = {Artech House Publishers},
  year = {2004},
  author = {L. Copeland},
  owner = {magsilva},
  timestamp = {2009.05.11}
}

@MISC{software:pmd,
  author = {Tom Copeland and others},
  title = {{PMD}},
  howpublished = {Programa de Computador},
  year = {2002},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@MISC{Cornelius97JC++,
  author = {B. Cornelius},
  title = {{J}ava versus {C++}},
  howpublished = {Documento on-line},
  month = apr,
  year = {1997},
  owner = {magsilva},
  timestamp = {2008.07.31},
  url = {http://www.dur.ac.uk/\char126dcl0bjc/Java/java.versus.c++/onefile/index.html}
}

@MISC{Cornett:2007,
  author = {Steve Cornett},
  title = {Minimum Acceptable Code Coverage},
  howpublished = whitepaper,
  year = {2007},
  timestamp = {2009.04.30},
  url = {http://www.bullseye.com/minimum.html}
}

@MISC{software:dotnet,
  author = {Microsoft Corporation},
  title = {.NET Framework},
  howpublished = {Programa de Computador},
  month = jan,
  year = {2002},
  owner = {magsilva},
  timestamp = {2006.07.26}
}

@MASTERSTHESIS{Corte:2006,
  author = {Camila Kozlowski Della Corte},
  title = {Ensino Integrado de Fundamentos de Programação e de Teste de Software},
  school = {Universidade de São Paulo},
  year = {2006},
  address = {São Carlos, SP, Brazil},
  month = feb,
  note = {Advisor: José Carlos Maldonado},
  owner = {magsilva},
  timestamp = {2007.10.10}
}

@MISC{software:progtest,
  author = {Camila Kozlowski Della Corte},
  title = {{ProgTest}},
  howpublished = {Programa de Computador},
  year = {2006},
  owner = {magsilva},
  timestamp = {2007.10.10}
}

@INPROCEEDINGS{Corte-etal:2006:IFIP,
  author = {C. K. D. Corte and E. F. Barbosa and J. C. Maldonado},
  title = {Integrated teaching of programming foundations and software testing},
  pages = {425},
  abstract = {Only a small portion of the Computer Science (CS) curriculum is allocated for teaching software testing. Experiences suggest that the teaching of testing should begin as early as possible so an adequate culture of testing could be created. In this paper we discuss the integration between the teaching of software testing along with the teaching of programming foundations. We discuss the development of an educational module for integrating such knowledge domains. We also present PROGTEST -- a Web-based environment for the submission and automatic evaluation of practical programming assignments based on testing activities.},
  address = {Santiago, Chile},
  booktitle = {IFIP 19th World Computer Congress -- International Conference on Education for the 21st Century (Sessão de Posters)},
  location = {Santiago, Chile},
  owner = {magsilva},
  publisher = {IEEE},
  timestamp = {2008.07.31},
  year = {2006}
}

@INPROCEEDINGS{Corte-etal:2006:ISSRE,
  author = {Camila Kozlowski Della Corte and Ellen Francine Barbosa and José Carlos Maldonado},
  title = {Integrated Teaching of Programming Foundations and Software Testing},
  pages = {1--2},
  abstract = {Only a small portion of the Computer Science (CS) curriculum is allocated for teaching software testing. Experiences suggest that the teaching of testing should begin as early as possible so an adequate culture of testing could be created. In this paper we discuss the integration between the teaching of software testing along with the teaching of programming foundations. We discuss the development of an educational module for integrating such knowledge domains. We also present PROGTEST -- a Web-based environment for the submission and automatic evaluation of practical programming assignments based on testing activities.},
  booktitle = {17th IEEE International Symposium on Software Reliability Engineering},
  location = {Raleigh, North Carolina, USA},
  month = nov,
  url = {http://www.issre2009.org/archive/2006_supplemental/fast_abstracts/Integrated_Teaching_of_Programming_Foundations_and_Software_Testing.pdf},
  year = {2006}
}

@INPROCEEDINGS{Corte-etal:2004,
  author = {C. K. D. Corte and E. F. Barbosa and J. C. Maldonado},
  title = {Ensino Integrado de Fundamentos de Programação e Teste de Software},
  pages = {1--14},
  abstract = {A importância do ensino de teste para o desenvolvimento de software é amplamente reconhecida, mas somente uma parte muito pequena dos currículos dos cursos de computação é alocada a esse tipo de ensino. O ensino de teste deve começar o mais cedo possível para que uma cultura adequada de teste de software seja criada. Uma maneira de alcançar isso é ensinar teste de software juntamente com fundamentos de programação em disciplinas introdutórias dos cursos de computação.Neste artigo propõe-se a integração do ensino de teste de software com o ensino de fundamentos de programação. Para isso, pretende-se elaborar material didático integrado de fundamentos de programação e de teste de software e ainda desenvolver um ambiente, baseado na Web para submissão e avaliação automática de trabalhos práticos baseados e atividades de teste de software para auxiliar os processos de ensino e aprendizagem.},
  abstract-en = {The importance of teaching software testing is widely recognized, but only a small portion of the computer science (CS) curriculum is allocated to it. The teaching of software testing must begin as earlier as possible so an adequate culture of software testing be created. One way to achieve this is to teach software testing in conjunction with programming foundations in introductory CS disciplines. In this paper is proposed to integrate the teaching of software testing along with the teaching of programming foundations. In this direction, we intend to elaborate integrated learning materials on programming foundations and software testing and to develop a Web-based environment for the submission and automatic evaluation of practical testing activities to aid the teaching and learning processes.},
  address = {Salvador, BA},
  booktitle = {XXIV Congresso da Sociedade Brasileira de Computação (SBC 2004) -- XII Workshop de Educação em Computação (WEI 2004)},
  lang = {pt},
  month = jul/aug,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {2004}
}

@INPROCEEDINGS{Corte-etal:2007,
  author = {Camila Kozlowski Della Corte and Ana Cláudia Riekstin and Marco Aurélio Graciotto Silva and Ellen Francine Barbosa and José Carlos Maldonado},
  title = {{ProgTest}: Ambiente para submissão e avaliação de trabalhos práticos},
  pages = {1--8},
  abstract = {Somente uma pequena parte dos currículos dos cursos de Ciências da Computação são alocados para o ensino de teste de software. Algumas experiências sugerem que o ensino de teste deveria comecar o mais cedo possível. Desta forma, uma cultura adequada de teste de software seria criada. Neste artigo, é explorado a integração do ensino de teste de software e fundamentos de programação. Para isso, é proposto um ambiente para submissão e avaliação automática de trabalhos práticos baseado em atividades de teste -- ProgTest -- fornecendo um feedback adequado para a avaliação da performance do aprendizado dos conceitos de programação e teste de software.},
  abstract-en = {Only a small portion of the Computer Science (CS) curriculum is allocated for teaching software testing. Some experiences have suggested that the teaching of testing should begin as early as possible so an adequate culture of testing could be created. In this paper we explore the integration between the teaching of software testing along with the teaching of programming foundations. For this, we propose PROGTEST -- a Web-based environment for the submission and automatic evaluation of practical programming assignments based on testing activities, aiming at providing an adequate feedback to evaluate the learners' performance concerning programming and testing.},
  address = {São Paulo, SP},
  booktitle = {Workshop sobre Ambientes de Apoio à Aprendizagem de Algoritmos e Programação},
  location = {São Paulo, SP, Brazil},
  month = nov,
  timestamp = {2008.10.05},
  year = {2007}
}

@INPROCEEDINGS{Costabile-etal:2008,
  author = {Maria F. Costabile and Antonella De Angeli and Rosa Lanzilotti and Carmelo Ardito and Paolo Buono and Thomas Pederson},
  title = {Explore! Possibilities and Challenges of Mobile Learning},
  pages = {145-154},
  doi = {10.1145/1357054.1357080},
  abstract = {This paper reports the experimental studies we have performed to evaluate Explore!, an m-learning system that supports middle school students during a visit to an archaeological park. It exploits a learning technique called excursion-game, whose aim is to help students to acquire historical notions while playing and to make archaeological visits more effective and exciting. In order to understand the potentials and limitations of Explore!, our studies compare the experience of playing the excursion-game with and without technological support. The design and evaluation of Explore! have provided knowledge on the advantages and pitfalls of m-learning that may be instrumental in informing the current debate on e-learning.},
  address = {Florence, Itália},
  booktitle = {CHI 2008 Proceedings - Learning Support},
  lang = {en},
  location = {Florence, Itália},
  publisher = {ACM},
  timestamp = {2008.10.01},
  year = {2008}
}

@INPROCEEDINGS{Costagliola-etal:2006,
  author = {Gennaro Costagliola and Filomena Ferrucci and Vittorio Fuccella},
  title = {{SCORM} Run-Time Environment As a Service},
  pages = {103--110},
  doi = {10.1145/1145581.1145604},
  abstract = {Standardization efforts in e-learning are aimed at achieving interoperability among Learning Management Systems (LMSs) and Learning Object (LO) authoring tools. Some of the specifications produced have reached quite a good maturity level and have been adopted in software systems. Some others, such as SCORM Run-Time Environment (RTE), have not reached the same success, probably due to their intrinsic difficulty in being understood adequately and implemented properly. The SCORM RTE defines a set of functionalities which allow LOs to be launched in the LMS and to exchange data with it. Its adoption is crucial in the achievement of full interoperability among LMSs and LO authoring tools. In order to boost the adoption of SCORM RTE in LMSs, we propose a Service Oriented Architecture (SOA)-based reference model for offering the SCORM RTE functionalities as a service, external to the LMS. By externalizing functionalities from LMSs, our model encourages the independent development of e-learning system components, allowing e-learning software producers to gain several benefits, such as better software re-use and easier integration and complexity management, with a consequent cost reduction. The proposed model is validated through a prototype system, in which a popular LMS, developed with PHP language, is enhanced with the support of SCORM RTE functionalities, provided by an external Web service based on Java technology.},
  keywords = {Service Oriented Architecture, SOA, SCORM Run-Time Environment, Computer Managed Instruction, CMI, Learning Objects},
  address = {New York, NY, EUA},
  booktitle = {International Conference on Web Engineering},
  isbn = {1-59593-352-2},
  lang = {en},
  location = {Palo Alto, California, #USA#},
  month = jul,
  publisher = {ACM},
  year = {2006}
}

@ARTICLE{oliveira-lucenafilho:2006,
  author = {Sheila da Costa Oliveira and Gentil José de {Lucena Filho}},
  title = {Animação de fóruns virtuais de discussão -- novo caminho para a aprendizagem em {EAD} via web},
  volume = {4},
  number = {2},
  month = dec,
  year = {2006},
  pages = {1-11},
  url = {http://www.cinted.ufrgs.br/renote/dez2006/artigosrenote/25159.pdf},
  journal = {Novas Tecnologias na Educação},
  timestamp = {2008.09.15}
}

@ARTICLE{Santos-etal:2007,
  author = {Cristina Mamédio da Costa Santos and Cibele Andrucioli de Mattos Pimenta and Moacyr Roberto Cuce Nobre},
  title = {A estratégia PICO para a construção da pergunta de pesquisa e busca de evidências},
  volume = {15},
  number = {3},
  month = may # {-} # jun,
  year = {2007},
  pages = {508-511},
  abstract = {Prática baseada em evidências é a utilização da melhor evidência científica para subsidiar a tomada de decisão clínica. Identificar a melhor evidência requer adequada construção da pergunta de pesquisa e de revisão da literatura e este artigo descreve o uso da estratégia PICO para a construção da pergunta de pesquisa e busca bibliográfica.},
  abstract-en = {Evidence based practice is the use of the best scientific evidence to support the clinical decision making. The identification of the best evidence requires the construction of an appropriate research question and review of the literature. This article describes the use of the PICO strategy for the construction of the research question and bibliographical search.},
  abstract-pt = {Prática baseada em evidências é a utilização da melhor evidência científica para subsidiar a tomada de decisão clínica. Identificar a melhor evidência requer adequada construção da pergunta de pesquisa e de revisão da literatura e este artigo descreve o uso da estratégia PICO para a construção da pergunta de pesquisa e busca bibliográfica.},
  journal = {Revista Latino-Americana de Enfermagem},
  owner = {magsilva},
  timestamp = {2007.11.13},
  title-en = {The PICO strategy for the research question construction and evidence search},
  title-pt = {A estratégia PICO para a construção da pergunta de pesquisa e busca de evidências}
}

@BOOK{coulouris-etal:2001,
  title = {Distributed Systems Concepts and Design},
  publisher = {Addison-Wesley},
  year = {2001},
  author = {George Coulouris and Jean Dollimore and Tim Kindber},
  series = {International Computer Sciente Series},
  edition = {3},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://www.cdk3.net}
}

@MISC{counterman:2004,
  author = {Craig Counterman and Glenn Golden and Rachel Gollub and Mark Norton and Charles Severance and Lance Speelmon},
  title = {{Technical Report Sakai Project}},
  howpublished = {http://www.sakaiproject.org/ [12/01/08]},
  month = {may},
  year = {2004},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@MISC{servlet:2003,
  author = {Danny Coward and Yutaka Yoshida},
  title = {Java Servlet Specification 2.4},
  howpublished = {JCP Specification},
  month = {nov},
  year = {2003},
  file = {Java Servlet Specificaton 2.4.pdf:home/magsilva/Artigos/Padrões/JCP/Java Servlet Specificaton 2.4.pdf:PDF},
  owner = {Marco Aurélio Graciotto Silva},
  timestamp = {2008.07.30}
}

@BOOK{craig-jaskiel:2002,
  title = {Systematic Software Testing},
  publisher = {Artech House Publishers},
  year = {2002},
  author = {Rick D. Craig and Stefan P. Jaskiel},
  month = may,
  owner = {magsilva},
  timestamp = {2009.04.17}
}

@BOOK{crispin-house:2002,
  title = {Testing Extreme Programming},
  publisher = {Addison Wesley},
  year = {2002},
  author = {L. Crispin and T. House},
  month = oct,
  owner = {magsilva},
  timestamp = {2009.04.22}
}

@MISC{software:hermes,
  author = {Colin Crist},
  title = {HermesJMS},
  howpublished = {Programa de computador},
  month = sep,
  year = {2002},
  owner = {magsilva},
  timestamp = {2006.08.30},
  url = {http://www.hermesjms.com/}
}

@INPROCEEDINGS{Crnkovic00CSDC,
  author = {I. Crnkovic and M. Larsson},
  title = {A Case Study: Demands on Component-based Development},
  pages = {23--31},
  address = {Limerick, Ireland},
  booktitle = {ICSE'2000 -- International Conference on Software Engineering},
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {2000}
}

@MISC{software:veryquickwiki,
  author = {Gareth Cronin},
  title = {VeryQuickWiki},
  howpublished = {Programa de Computador},
  year = {2000},
  owner = {Marco Aurélio Graciotto Silva},
  timestamp = {2008.07.30},
  url = {http://veryquickwiki.croninsolutions.com/}
}

@INPROCEEDINGS{crowston:2003,
  author = {Kevin Crowston and Hala Annabi and James Howison},
  title = {Defining Open Source Software Project Success},
  booktitle = {Proc. of International Conference on Information Systems ({ICIS 2003})},
  citeseerurl = {citeseer.ist.psu.edu/crowston03defining.html},
  owner = {magsilva},
  timestamp = {2008.07.30},
  year = {2003}
}

@INPROCEEDINGS{cruzes-dyba:2010,
  author = {Cruzes, Daniela S. and Dyb{\aa}, Tore},
  title = {Synthesizing evidence in software engineering research},
  pages = {1--10},
  doi = {10.1145/1852786.1852788},
  abstract = {Synthesizing the evidence from a set of studies that spans many countries and years, and that incorporates a wide variety of research methods and theoretical perspectives, is probably the single most challenging task of performing a systematic review. In this paper, we perform a tertiary review to assess the types and methods of research synthesis in systematic reviews in software engineering. Almost half of the 31 studies included in our review did not contain any synthesis; of the ones that did, two thirds performed a narrative or a thematic synthesis. The results show that, despite the focus on systematic reviews, there is, currently, limited attention to research synthesis in software engineering. This needs to change and a repertoire of synthesis methods needs to be an integral part of systematic reviews to increase their significance and utility for research and practice.},
  keywords = {evidence-based software engineering, mixed methods, qualitative, quantitative, research synthesis, systematic reviews},
  volume = {1},
  acmid = {1852788},
  address = {New York, NY, USA},
  articleno = {1},
  booktitle = {International Symposium on Empirical Software Engineering and Measurement},
  isbn = {978-1-4503-0039-1},
  location = {Bolzano-Bozen, Italy},
  numpages = {10},
  publisher = {ACM},
  year = {2010}
}

@INPROCEEDINGS{Cui-etal:2007,
  author = {Cui, Yanqing and Chipchase, Jan and Jung, Younghee},
  title = {Personal {TV}: a qualitative study of mobile {TV} users},
  pages = {195--204},
  keywords = {South Korea, mobile TV, personal TV, radio, seoul},
  series = {EuroITV'07},
  acmid = {1763044},
  address = {Berlin, Heidelberg},
  booktitle = {European Conference on Interactive TV},
  isbn = {978-3-540-72558-9},
  location = {Amsterdam, The Netherlands},
  numpages = {10},
  publisher = {Springer-Verlag},
  url = {http://dl.acm.org/citation.cfm?id=1763017.1763044},
  year = {2007}
}

@ARTICLE{cunha03aaa,
  author = {Leonardo Magela Cunha and Hugo Fuks and Carlos José Pereira de Lucena},
  title = {{A Adaptação do Ambiente AulaNet para Dar Suporte a Grupos de Aprendizagem e sua Formação Utilizando os Conceitos de Agentes de Software}},
  year = {2003},
  pages = {1414--5685},
  journal = {Revista Brasileira de Informática na Educação},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@MISC{software:wikiwikiweb,
  author = {Ward Cunnigham},
  title = {WikiWikiWeb},
  howpublished = {Programa de Computador},
  month = mar,
  year = {1995},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://c2.com/cgi/wiki}
}

@ARTICLE{cunningham:2005,
  author = {Ward Cunningham},
  title = {Wiki Design Principles},
  year = {2005},
  url = {http://c2.com/cgi/wiki?WikiDesignPrinciples},
  comment = {15/06/2005},
  owner = {magsilva},
  timestamp = {2008.07.30},
  urlaccessdate = {20 fev 2012}
}

@ARTICLE{Currier-etal:2004,
  author = {Currier, Sarah and Barton, Jane and O'Beirne, Rónán and Ryan, Ben},
  title = {Quality Assurance for Digital Learning Object Repositories: Issues for the Metadata Creation Process},
  volume = {12},
  number = {1},
  month = mar,
  year = {2004},
  pages = {5-20},
  abstract = {Metadata enables users to find the resources they require, therefore it is an important component of any digital learning object repository. Much work has already been done within the learning technology community to assure metadata quality, focused on the development of metadata standards, specifications and vocabularies and their implementation within repositories. The metadata creation process has thus far been largely overlooked. There has been an assumption that metadata creation will be straightforward and that where machines cannot generate metadata effectively, authors of learning materials will be the most appropriate metadata creators. However, repositories are reporting difficulties in obtaining good quality metadata from their contributors, and it is becoming apparent that the issue of metadata creation warrants attention. This paper surveys the growing body of evidence, including three UK-based case studies, scopes the issues surrounding human-generated metadata creation and identifies questions for further investigation. Collaborative creation of metadata by resource authors and metadata specialists, and the design of tools and processes, are emerging as key areas for deeper research. Research is also needed into how end users will search learning object repositories.},
  issn = {0968-7769, 1741-1629},
  journal = {Association for Learning Technology Journa},
  publisher = {Routledge},
  timestamp = {2012.01.24}
}

@ARTICLE{cusumano:1997,
  author = {M. A. Cusumano and R. W. Selby},
  title = {How {M}icrosoft Builds Software},
  volume = {40},
  number = {6},
  year = {1997},
  pages = {53-61},
  journal = {Communications of the ACM},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@INPROCEEDINGS{dag:2004,
  author = {Johan Natt och Dag and Vincenzo Gervasi and Sjaak Brinkkemper and Björn Regnell},
  title = {Speeding up Requirements Management in a Product Software Company: Linking Customers Wishes to Product Requirements through Linguistic Engineering},
  pages = {1-12},
  booktitle = {International Requirements Engineering Conference},
  owner = {Marco Aurélio Graciotto Silva},
  timestamp = {2008.07.30},
  year = {2004}
}

@ARTICLE{dag:2005,
  author = {Johan Natt och Dag and Björn Regnell and Vincenzo Gervasi and Sjaak Brinkkemper},
  title = {A Linguistic-Engineering Approach to Large-Scale Requirements Management},
  volume = {22},
  number = {1},
  month = {jan},
  year = {2005},
  pages = {32-39},
  journal = {IEEE Software},
  owner = {Marco Aurélio Graciotto Silva},
  timestamp = {2008.07.30}
}

@TECHREPORT{dahm:2001,
  author = {M. Dahm},
  title = {Byte code engeneering with the BCEL API},
  institution = {Freie Universität Berlin -- Institut für Informatik},
  month = apr,
  year = {2001},
  number = {B-17-98},
  address = {Berlin, German},
  owner = {magsilva},
  timestamp = {2010.08.20},
  type = {Technical Report}
}

@MISC{software:bcel,
  author = {Markus Dahm and Jason van Zyl and Enver Haase and Dave Brosius and Torsten Curdt and others},
  title = {Byte Code Engineering Library (BCEL)},
  howpublished = software,
  year = {2001},
  owner = {magsilva},
  timestamp = {2010.08.23},
  url = {http://jakarta.apache.org/bcel/}
}

@BOOK{dale:1969,
  title = {Audiovisual methods in teaching},
  publisher = {The Dryden Press},
  year = {1969},
  author = {Edgar Dale},
  edition = {3},
  owner = {magsilva},
  timestamp = {2008.01.24}
}

@ARTICLE{DallAlba-etal:1993,
  author = {Dall'Alba, Gloria and Walsh, Eleanor and Bowden, John and Martin, Elaine and Masters, Geofferey and Ramsden, Paul and Stephanou, Andrew},
  title = {Textbook treatments and students' understanding of acceleration},
  volume = {30},
  number = {7},
  month = aug,
  year = {1993},
  pages = {621--635},
  doi = {10.1002/tea.3660300703},
  abstract = {A single science textbook often provides the syllabus for courses at upper secondary and tertiary levels, and may be used as a principal source of information or explanation. The research reported in this article challenges such practices. The ways in which the concept, acceleration, is treated in physics textbooks is compared with understandings of the concept demonstrated by final-year secondary (Year 12) and first-year university students. Some students' understandings are shown to be incomplete in ways that parallel misleading or inaccurate textbook treatments of the concept. In addition to misleading or inaccurate statements, the limitations of some textbook treatments of acceleration were found to include: lack of attempts to make explicit relationships with other concepts, failure to point out when it is appropriate to use particular definitions or that an alternative definition might be more appropriate in specific situations, inclusion of operational definitions without conceptual explanations, and a focus on quantitative treatments while overlooking the development of qualitative understanding. Two principal aspects that distinguished the ways in which the students understood acceleration were identified: (a) the relation between acceleration and velocity; and (b) the relation between acceleration and force(s). The results of the study have implications for teaching and, in particular, for the use of textbooks in teaching. These implications are discussed in the article.},
  issn = {1098-2736},
  journal = {Journal of Research in Science Teaching},
  lang = {en},
  publisher = {Wiley}
}

@BOOK{Damas:2007,
  publisher = {LTC},
  year = {2007},
  author = {Luís Manuel Dias Damas},
  isbn = {978-85-216-1519-4},
  pages = {410},
  address = {Rio de Janeiro, RJ, } # Brazil,
  booktitle = {Linguagem C}
}

@INPROCEEDINGS{Damasevicius-Stuikys:2008,
  author = {Damasevicius, Robertas and Stuikys, Vytautas},
  title = {On the Technological Aspects of Generative Learning Object Development},
  pages = {337-348},
  doi = {10.1007/978-3-540-69924-8_31},
  abstract = {Learning Objects (LOs) are digital resources that can be used (and reused) to support the learning process. Generative Learning Objects (GLOs) are generic and reusable LOs from which the specific LO content can be generated on demand. We discuss the technological aspects required for implementing the GLOs: (1) variability modeling using feature diagrams, (2) multi-dimensional separation of the LO design concerns, (3) multiple languages for implementing a LO specification, (4) an external metalanguage for implementing parameterization, generalization and modification of a LO, and (5) heterogeneous metaprogramming techniques for generating LO instances from the generic LO specifications on demand. An example of a GLO for teaching array sorting algorithms in a programming curriculum is presented.},
  volume = {5090},
  series = {Lecture Notes in Computer Science},
  address = {Torun, Poland},
  booktitle = {International Conference on Informatics in Secondary Schools -- Evolution and Perspectives (ISSEP)},
  editor = {Mittermeir, Roland and Syslo, Maciej},
  isbn = {978-3-540-69923-1},
  location = {Torun, Poland},
  month = jul,
  publisher = {Springer},
  year = {2008}
}

@INPROCEEDINGS{Damasio-Quico:2004,
  author = {Damasio, M. and Quico, C.},
  title = {T-Learning and Interactive Television Edutainment: the Portuguese Case Study},
  pages = {4511--4518},
  abstract = {This paper presents a case study of Portugal's specific developments in the use of interactive television as a learning resource. The paper depicts the Digital Interactive Television evolution in Portugal since 2001 and discusses the T-Learning and iTV Edutainment implementation experiences developed in the country since that period. An exemplary project is used to discuss the shape of learning activities provided through Television. Consequences of this process are also presented and discussed, namely from the learner's point of view.},
  keywords = {experiencia, interatividade, tvdigital, usabilidade},
  booktitle = {World Conference on Educational Multimedia, Hypermedia and Telecommunications},
  location = {Chesapeake, VA, #USA#},
  publisher = {Advancement of Computing in Education},
  review = {O artigo faz um apanhado da experiência da adoção da TV Digital em Portugal. Inicialmente, em 2001, foram disponibilizagos apenas serviços de alto desempenho o que não provocou uma grande aderência. Posteriormente, em 2003, com o lançamento dos serviços de baixo desempenho, a adoção foi maior. Também é realizado um retrospecto de casos passados de ensino-aprendizagem via TV no pais, com destaque para Telescola. Em seguida, são apresentados argumentados a respeito da importância de t-learning e apresentados projetos e/ou programas (incipientes) desta área desenvolvidos no país (vale ressaltar que o artigo é de 2003), muitos dos quais voltados para crianças (Interactive Batatoon, Barra Panda, Disney Channel, Portugal dos Pequenitos). Finalmente, é apresentado o projeto WEMiTV cujo objetivo é estabelecer um modelo para testar e mensurar aplicações televisivas interativas quando usadas no ambiente educacional. O que motivou o projeto foi a seguinte hipótese: O uso de TV Interativa no ambiente educacional pode melhorar o nível de motivação e retenção do conhecimento dos estudantes?. Os principais tópicos envolvidos na pesquisa dizem respeito a impactos cognitivos e questões relativa à interação humano-computador. Neste sentido, é discutida uma interessante metodologia para avaliação destes quesitos, que vale a pena ver detalhes caso tal tema seja de interesse.},
  year = {2004}
}

@ARTICLE{damian:2000,
  author = {Daniela E. Herlea Damian and Armin Eberlein and Mildred L. G. Shaw and Brian R. Gaines},
  title = {Using Different Communication Media in Requirements Negotiation},
  volume = {17},
  number = {3},
  month = oct,
  year = {2000},
  pages = {28-36},
  journal = {IEEE Software},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@MISC{rdfschema:2004,
  author = {Dan Brickley, R.V. Guha, Brian McBride},
  title = {DF Vocabulary Description Language 1.0: RDF Schema},
  howpublished = {W3C Recommendation},
  month = feb,
  year = {2004},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://www.w3.org/TR/rdf-schema/}
}

@INPROCEEDINGS{daniel-mohan:2004,
  author = {Ben Kei Daniel and Permanand Mohan},
  title = {A Model for Evaluating Learning Objects},
  booktitle = {International Conference on Advanced Learning Technologies (ICALT'04)},
  publisher = {IEEE Computer Society},
  timestamp = {2008.09.26},
  year = {2004}
}

@ARTICLE{dardenne:1993,
  author = {Anne Dardenne and Axel van Lamsweerde and Stephen Fickas},
  title = {Goal-Directed Requirements Acquisition},
  volume = {20},
  number = {1-2},
  year = {1993},
  pages = {3--50},
  url = {http://citeseer.nj.nec.com/dardenne93goaldirected.html},
  journal = {Science of Computer Programming},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@ARTICLE{daughtry-etal:2009,
  author = {Daughtry, John and Burge, Janet and Carroll, John M. and Potts, Colin},
  title = {Creativity and rationale in software design},
  volume = {34},
  number = {1},
  month = jan,
  year = {2009},
  pages = {27--29},
  doi = {10.1145/1457516.1460354},
  address = {New York, NY, USA},
  issn = {0163-5948},
  journal = {SIGSOFT Softw. Eng. Notes},
  publisher = {ACM}
}

@MISC{rdfsyntax:2004,
  author = {Dave Beckett, Brian McBride},
  title = {RDF/XML Syntax Specification},
  howpublished = {W3C Recommendation},
  month = feb,
  year = {2004},
  comment = {24/05/2005},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://www.w3.org/TR/rdf-syntax-grammar/}
}

@ARTICLE{Davis:1988,
  author = {A. M. Davis},
  title = {A Comparison of Techniques for the Specification of External System Behavior},
  volume = {31},
  number = {9},
  month = sep,
  year = {1988},
  journal = {Communications of the ACM},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{davis:1993,
  author = {Hugh Davis and Wendy Hall and Ian Heath and Gary Hill and Rob Wilkins},
  title = {Towards an integrated information environment with open hypermedia systems},
  pages = {181-190},
  address = {Milão, Itália},
  booktitle = {Conference on Hypertext and Hypermedia},
  owner = {magsilva},
  timestamp = {2008.07.30},
  year = {1993}
}

@INPROCEEDINGS{davis:1996,
  author = {H. Davis and A. Lewis and A. Rizk},
  title = {{OHP}: A Draft Proposal for a Standard Open Hypermedia Protocol},
  pages = {27-53},
  address = {Washington DC},
  booktitle = {Hyptertext'96: the 2nd Workshop on Open Hypermedia Systems},
  owner = {magsilva},
  publisher = {ACM Press},
  timestamp = {2008.07.30},
  year = {1996}
}

@INPROCEEDINGS{Davis00LOSA,
  author = {M. Davis and W. O´Donovan and J. Fritz},
  title = {Linux and Open Source in the Academic Enterprise},
  address = {Richmond, VA},
  booktitle = {28th SIGUCCS Conference on User Services},
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {2000}
}

@ARTICLE{day1983orm,
  author = {J. D . Day and H. Zimmermann},
  title = {{The OSI reference model}},
  volume = {71},
  number = {12},
  year = {1983},
  pages = {1334--1340},
  journal = {Proceedings of the IEEE},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@MISC{standard:dublincore:2010,
  author = {{DCMI}},
  title = {Dublin Core Metadata Element Set},
  howpublished = Standard,
  month = oct,
  year = {2010},
  lang = {en},
  timestamp = {2008.09.22},
  url = {http://dublincore.org/documents/dces/},
  urlaccessdate = {20 fev 2012}
}

@INPROCEEDINGS{debaud-schmid:1999,
  author = {DeBaud, Jean-Marc and Schmid, Klaus},
  title = {A systematic approach to derive the scope of software product lines},
  pages = {34--43},
  doi = {10.1145/302405.302409},
  address = {Los Angeles, CA, USA},
  booktitle = {International Conference on Software engineering (ICSE)},
  isbn = {1-58113-074-0},
  location = {Los Angeles, California, United States},
  publisher = {ACM},
  year = {1999}
}

@INPROCEEDINGS{DeBra-etal:1999,
  author = {De Bra, Paul and Houben, Geert-Jan and Wu, Hongjing},
  title = {{AHAM}: a Dexter-based reference model for adaptive hypermedia},
  pages = {147--156},
  doi = {10.1145/294469.294508},
  abstract = {Hypermedia applications offer users the impression that there are many meaningful ways to navigate through a large body of information nodes. This rich link structure not only creates orientation problems, it may also be a source of comprehension problems when users follow paths through the information which the author did not foresee. Adaptive techniques have been used by a number of researchers in an attempt to offer guidance through and orientation support for rich link structures. The majority of these adaptive hypermedia systems (AHS) have been used in educational applications. The terminology used in this paper also has an educational 'flavor'. However, there are some adaptive on-line information systems (or 'kiosk'-systems), adaptive information retrieval systems, and other adaptive hypermedia applications. In this paper we describe a reference model for adaptive hypermedia applications, called AHAM, which encompasses most features supported by adaptive systems that exist today or that are being developed (and have been published about). Our description of AHS is based on the Dexter model, a widely used reference model for hypermedia. The description is kept somewhat informal in order to be able to explain AHAM rather than formally specify it. AHAM augments Dexter with features for doing adaptation based on a user model which persists beyond the duration of a session, Key aspects in AHAM are: The adaptation is based on a domain model, a user model and a teaching model which consists ofpedagogical rules. We give a formal definition of each of these (sub)models (but only describe the pedagogical rules informally through examples); We distinguish the notions of concept, page and fragment. In some AHS these notions are confused; We provide a formalism which lets authors write pedagogical rules (about concepts) in such a way that they can be applied automatically. We illustrate various aspects of AHAM by means of some features of some well-known AHS.},
  keywords = {adaptive hypermedia, hypermedia reference model, user modeling},
  series = {HYPERTEXT '99},
  acmid = {294508},
  address = {New York, NY, EUA},
  booktitle = {10th ACM Conference on Hypertext and hypermedia : returning to our diverse roots},
  isbn = {1-58113-064-3},
  lang = {en},
  location = {Darmstadt, Alemanha},
  numpages = {10},
  publisher = {ACM},
  year = {1999}
}

@ARTICLE{dedene2005ngl,
  author = {Guido Dedene and Monique Snoeck and Manu De Backer and Wilfried Lemahieu},
  title = {{New Generation E-Learning Technology by Web Services}},
  year = {2005},
  journal = {Professional Knowledge Management: Third Biennial Conference, WM 2005, Kaiserslautern, Germany, April 10-13, 2005: Revised Selected Papers},
  owner = {magsilva},
  publisher = {Springer},
  timestamp = {2008.07.30}
}

@INPROCEEDINGS{delahaye-etal:2010,
  author = {Delahaye, M. and Botella, B. and Gotlieb, A.},
  title = {Explanation-Based Generalization of Infeasible Path},
  pages = {215 -224},
  doi = {10.1109/ICST.2010.13},
  abstract = {Recent code-based test input generators based on dynamic symbolic execution increase path coverage by solving path condition with a constraint or an SMT solver. When the solver considers path condition produced from an infeasible path, it tries to show unsatisfiability, which is a useless time-consuming process. In this paper, we propose a new method that takes opportunity of the detection of a single infeasible path to generalize to a (possibly infinite) family of infeasible paths, which will not have to be considered in further path conditions solving. The method exploits non-intrusive constraint-based explanations, a technique developed in Constraint Programming to explain unsatisfiability. Experimental results obtained with our prototype tool IPEG show that, whatever is the underlying constraint solving procedure (IC, Colibri and the SMT solver Z3), this approach can save considerable computational time.},
  keywords = {IPEG;constraint programming;dynamic symbolic execution;explanation-based generalization;infeasible path;infeasible path detection;time consuming process;automatic test pattern generation;constraint handling;},
  booktitle = {International Conference on Software Testing, Verification and Validation (ICST)},
  month = apr,
  year = {2010}
}

@INPROCEEDINGS{Delamaro-etal:2011,
  author = {Delamaro, M.E. and Chaim, M.L. and Vincenzi, A.M.R. and Jino, M. and Maldonado, J.C.},
  title = {Twenty-Five Years of Research in Structural and Mutation Testing},
  pages = {40--49},
  doi = {10.1109/SBES.2011.16},
  abstract = {Research in software testing has been carried out for approximately forty years, but its importance has escalated very quickly in the last ten or fifteen years. In particular, structural and mutation testing are techniques which have received a large amount of investment in both academia and software development industry. In this paper, we draw a historical perspective on how they appeared and how they evolved. In particular, the main contributions on structural and mutation testing from two Brazilian researching groups - ICMC-USP and FEEC-UNICAMP - are described. We highlight the workproduced and published in these twenty-five years in the Brazilian Symposium on Software Engineering and elsewhere, as well its impact in the community of software testing.},
  booktitle = {25th Brazilian Symposium on Software Engineering (SBES)},
  month = sep,
  year = {2011}
}

@INPROCEEDINGS{Delamaro99IMAT,
  author = {M.E. Delamaro and J.C. Maldonado},
  title = {Interface Mutation: Assessing Testing Quality at Interprocedural Level},
  pages = {78--86},
  address = {Talca, Chile},
  booktitle = {19th International Conference of the Chilean Computer Science Society (SCCC'99)},
  month = nov,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1999}
}

@INPROCEEDINGS{Delamaro-Vincenzi:2003,
  author = {Delamaro, Márcio and Vincenzi, Auri},
  title = {Structural Testing of Mobile Agents},
  pages = {73--85},
  doi = {10.1007/978-3-540-24639-8_7},
  abstract = {Programs based on code mobility, in particular on Mobile Agents, are an alternative approach to conventional distributed systems. Many aspects of Mobile Agent development have been addressed. In special, languages and environments to support code mobility and Mobile Agents implementation have been proposed. The testing activity though, has practically not been addressed so far. In this paper we present an approach and a tool named JaBUTi/MA to aid the test of Mobile Agents based on structural testing criteria. The structural test of Mobile Agents introduces a series of new difficulties, in particular the problem of how to collect execution data on such a distributed environment.},
  keywords = {development and analysis tools; mobile agent; structural software testing; JaBUTi/MA},
  volume = {2952},
  series = {Lecture Notes in Computer Science},
  booktitle = {3rd International Workshop on Scientific Engineering of Distributed Java Applications},
  editor = {Guelfi, Nicolas and Astesiano, Egidio and Reggio, Gianna},
  isbn = {978-3-540-21091-7},
  location = {Kirchberg, #Luxembourg#},
  month = nov,
  publisher = {Springer},
  year = {2004}
}

@MISC{Delamaro:1998,
  author = {Márcio Eduardo Delamaro},
  title = {Introdução à Teoria da Computação},
  howpublished = {Notas de aula},
  year = {1998},
  timestamp = {2013-11-01}
}

@PHDTHESIS{Delamaro97IMIA,
  author = {M. E. Delamaro},
  title = {Interface Mutation: An Interprocedural Adequacy Criterion for Integration Testing},
  school = {Instituto de F\'isica de S\~ao Carlos -- Universidade de S\~ao Paulo},
  year = {1997},
  address = {S\~ao Carlos, SP},
  month = jun,
  note = {(in Portuguese)},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@PHDTHESIS{Delamaro97MICA,
  author = {M. E. Delamaro},
  title = {Muta\c c\~ao de Interface: Um Crit\'erio de Adequa\c c\~ao Inter-procedimental para o Teste de Integra\c c\~ao},
  school = {IFSC-USP},
  year = {1997},
  address = {S\~ao Carlos, SP},
  month = jun,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@MASTERSTHESIS{Delamaro93PATB,
  author = {M. E. Delamaro},
  title = {Proteum: Um Ambiente de Teste Baseado na An\'alise de Mutantes},
  school = {ICMC-USP},
  year = {1993},
  address = {S\~ao Carlos, SP},
  month = oct,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{Delamaro94TBMQ,
  author = {M. E. Delamaro and S. C. P. F. Fabbri and J. C. Maldonado and P. C. Masiero},
  title = {Teste Baseado em Muta\c c\~ao e Qualidade de Software},
  pages = {28--30},
  address = {Curitiba, PR},
  booktitle = {Workshop de Qualidade de Software},
  month = oct,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1994}
}

@INPROCEEDINGS{Delamaro97IMCS,
  author = {M. E Delamaro and J. C. Maldonado},
  title = {Interface Mutation: A Case Study},
  address = {\'Aguas de Lind\'oia -- SP},
  booktitle = {Workshop do Projeto de Valida\c c\~ao e Teste de Sistemas de Opera\c c\~ao},
  month = jan,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1997}
}

@INPROCEEDINGS{Delamaro97TIPO,
  author = {M. E. Delamaro and J. C. Maldonado},
  title = {Teste de Integra\c c\~ao: Projeto de Operadores para o Crit\'erio Muta\c c\~ao de Interface},
  address = {Fortaleza, CE},
  booktitle = {XI Brazilian Symposium on Software Engineering},
  month = oct,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1997}
}

@TECHREPORT{Delamaro93PMUV,
  author = {M. E. Delamaro and J. C. Maldonado},
  title = {Proteum -- Manual do Usuário Versão 1.1 -- {C}},
  institution = {ICMC-USP},
  year = {1993},
  number = {23},
  address = {São Carlos, SP}
}

@TECHREPORT{Delamaro93VSAA,
  author = {M. E. Delamaro and J. C. Maldonado},
  title = {Uma Vis\~ao Sobre a Aplica\c c\~ao da An\'alise de Mutantes},
  institution = {ICMC-USP},
  month = mar,
  year = {1993},
  number = {133},
  address = {S\~ao Carlos, SP},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@BOOK{delamaro-etal:2007,
  title = {Introdução ao Teste de Software},
  publisher = {Elsevier},
  year = {2007},
  author = {Márcio Eduardo Delamaro and José Carlos Maldonado and Mario Jino},
  editor = {Márcio Eduardo Delamaro},
  pages = {394},
  series = {Campus},
  owner = {magsilva},
  timestamp = {2009.07.16}
}

@INPROCEEDINGS{Delamaro93PFTB,
  author = {M. E. Delamaro and J. C. Maldonado and M. Jino and M. L. Chaim},
  title = {Proteum: Uma Ferramenta de Teste Baseada na An\'alise de Mutantes},
  pages = {31--33},
  address = {Rio de Janeiro, RJ},
  booktitle = {Software Tools Proceedings of the 7th Brazilian Symposium on Software Engineering},
  month = oct,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1993}
}

@TECHREPORT{Delamaro96IMCS,
  author = {M. E. Delamaro and J. C. Maldonado and A. P. Mathur},
  title = {Interface Mutation: A Case Study},
  institution = {ICMC-USP},
  year = {1996},
  number = {in preparation},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@TECHREPORT{Delamaro96ITUI,
  author = {M. E. Delamaro and J. C. Maldonado and A. P. Mathur},
  title = {{Integration Testing Using Interface Mutation}},
  institution = {Software Engineering Research Center, Purdue University},
  month = apr,
  year = {1996},
  number = {SERC-TR169-P},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@TECHREPORT{Delamaro96PTAT,
  author = {M. E. Delamaro and J. C. Maldonado and A. P. Mathur},
  title = {Proteum -- A Tool for the Assessment of Test Adequacy for {C} Programs -- User's Guide},
  institution = {Software Engineering Research Center, Purdue University},
  month = apr,
  year = {1996},
  number = {SERC-TR168-P},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{delamaro-etal:2007b,
  author = {Márcio Eduardo Delamaro and Paulo A. Nardi and Otávio Lemos and Paulo C. Masiero and Edmundo S. Spoto and José Carlos Maldonado and Auri M. R. Vincenzi},
  title = {Static analysis of Java Bytecode for Domain-specific Software Testing},
  pages = {325-341},
  booktitle = {XXI Simpósio Brasileiro de Engenharia de Software (SBES 2007)},
  owner = {magsilva},
  timestamp = {2010.08.22},
  year = {2007}
}

@TECHREPORT{Delamaro01MTMT,
  author = {M. E. Delamaro and M. Pèzze and A. M. R. Vincenzi and J. C. Maldonado},
  title = {Mutation Testing to Multi-Threaded {J}AVA Programs},
  institution = {Departamento de Inform\'atica -- Universidade de Maring\'a},
  year = {2001},
  address = {Maringá, PR},
  url = {http://www.din.uem.br/~delamaro/papers/relat.ps.gz},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INBOOK{Delamaro03STMA,
  pages = {73--85},
  title = {{Structural Testing of Mobile Agents}},
  publisher = {Springer},
  year = {2003},
  editor = {Nicolas Guelfi, Egidio Astesiano and Gianna Reggio},
  author = {M. E. Delamaro and A. M. R. Vincenzi},
  volume = {2952},
  series = {Lecture Notes on Computer Science},
  month = nov,
  booktitle = {International Workshop on Scientific Engineering of Java Distributed Applications (FIDJI 2003)},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{delamaro-etal:2006,
  author = {Delamaro, M. E. and Vincenzi, A. M. R. and Maldonado, J. C.},
  title = {A strategy to perform coverage testing of mobile applications},
  pages = {118--124},
  doi = {10.1145/1138929.1138952},
  abstract = {The development of wireless application has recently received more attention due to the increment in the number and in the power of mobile devices such as PDA's and cellular phones. Different methods and techniques have been developed to ease the design and development of applications for these kind of devices. Also, different languages have been proposed to provide support for such platform, such as J2ME and Brew. On the other hand, few attention has been given to testing activity in this scenario. Some works try to test the functional aspects of a given application, others try to perform load, usability and stress testing. In this article we present a strategy to support coverage testing for mobile device software in such a way that the applications can be tested not only on emulators, but also on their real target mobile devices with the aid of structural coverage assessment. We also present an environment which supports the proposed strategy. Such environment is implemented in a tool, named JaBUTi/ME. A simple case illustrating how JaBUTi/ME can be used is also presented.},
  address = {New York, NY, USA},
  booktitle = {International Workshop on Automation of Software Test (AST '06)},
  isbn = {1-59593-408-1},
  location = {Shanghai, China},
  publisher = {ACM},
  year = {2006}
}

@ARTICLE{delisle-schwartz:1987,
  author = {Norman M. Delisle and Mayer D. Schwartz},
  title = {Contexts - a partitioning concept for hypertext},
  volume = {5},
  number = {2},
  month = apr,
  year = {1987},
  pages = {168 - 186},
  doi = {10.1145/27636.27639},
  journal = {ACM Transactions on Information Systems (TOIS)},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@ARTICLE{DeLucia-etal:2008,
  author = {De Lucia, Andrea and Francese, Rita and Passero, Ignazio and Tortora, Genoveffa},
  title = {Migrating legacy video lectures to multimedia learning objects},
  volume = {38},
  month = {November},
  year = {2008},
  pages = {1499--1530},
  doi = {10.1002/spe.v38:14},
  abstract = {Video lectures are an old distance learning approach that offers only basic interaction and retrieval features to the user. Thus, to follow the new learning paradigms, we need to re-engineer the e-learning processes while preserving the investments made in the past. In this paper we present an approach for migrating video lectures to multimedia learning objects. Two essential problems are tackled: the detection of slide transitions and the generation of the learning objects. To this aim, the video of the lecture is scanned to detect the slide changes, while the learning object metadata and the slide pictures are extracted from the presentation document. A tool named VLMigrator (video lecture migrator) has been developed to support the migration of video lectures and the restructuring of their contents in terms of learning objects. Both the migration strategy and the tool have been experimented in a case study.},
  keywords = {SCORM, e-learning, learning object, slide change detection},
  url = {http://portal.acm.org/citation.cfm?id=1455466.1455469},
  acmid = {1455469},
  address = {New York, NY, USA},
  issn = {0038-0644},
  issue = {14},
  journal = {Software - Practice and Experience},
  numpages = {32},
  owner = {magsilva},
  publisher = {John Wiley \& Sons, Inc.}
}

@INPROCEEDINGS{DeLucia-etal:2006,
  author = {De Lucia, Andrea and Francese, Rita and Passero, Ignazio and Tortora, Genoveffa},
  title = {VLMigrator: a tool for migrating legacy video lectures to multimedia learning objects},
  pages = {171--174},
  doi = {10.1145/1133265.1133301},
  abstract = {In this paper we propose a tool, named VLMigrator, for interactively restructuring a lecture and the associated Powerpoint presentation into one or more multimedia Learning Objects. It also enables to fill the Learning Object metadata by automatically extracting information from the Powerpoint presentation. To easily perform these tasks, the VLMigrator interface exploits continuous semantic zooming and visual contextualization of information.},
  keywords = {E-learning, learning object, multimedia video lectures, reengineering, semantic zooming},
  series = {AVI '06},
  acmid = {1133301},
  address = {New York, NY, USA},
  booktitle = {Working Conference on Advanced Visual Interfaces},
  isbn = {1-59593-353-0},
  location = {Venezia, Italy},
  numpages = {4},
  owner = {magsilva},
  publisher = {ACM},
  year = {2006}
}

@INPROCEEDINGS{Demillo:1980,
  author = {R. A. Demillo},
  title = {Mutation Analysis as a Tool for Software Quality Assurance},
  pages = {390-393},
  address = {Chicago, IL, EUA},
  booktitle = {COMPSAC},
  editor = {William Bryan and Christopher Chadbourne and Stan Siegel},
  location = {Chicago, IL, USA},
  month = oct,
  owner = {magsilva},
  publisher = {IEEE},
  timestamp = {2008.07.31},
  year = {1980}
}

@BOOK{Demillo87STEV,
  title = {Software Testing and Evaluation},
  publisher = {The Benjamin/Cummings Publishing Company Inc.},
  year = {1987},
  author = {R. A Demillo},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{Demillo88EOMT,
  author = {R. A. DeMillo and D. S. Gwind and K. N. King and W. N. McKraken and A. J. Offutt},
  title = {An Extended Overview of the Mothra Testing Environment},
  pages = {142--151},
  address = {Banff, Canada},
  booktitle = {Software Testing, Verification and Analysis},
  month = jul,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1988}
}

@ARTICLE{demillo-etal:1978,
  author = {Richard A. DeMillo and Richard J. Lipton and Frederick G. Sayward},
  title = {Hints on Test Data Selection: Help for the Practicing Programmer},
  volume = {11},
  number = {4},
  month = apr,
  year = {1978},
  pages = {34-41},
  abstract = {In many cases tests of a program that uncover simple errors are also effective in uncovering much more complex errors. This so-called coupling effect can be used to save work during the testing process.},
  journal = {IEEE Computer},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@TECHREPORT{Demillo95GBFC,
  author = {R. A. DeMillo and A. P. Mathur},
  title = {A Grammar Based Fault Classification Scheme and its Application to the Classification of the Errors of {TeX}},
  institution = {Software Engineering Research Center, Purdue University},
  month = sep,
  year = {1995},
  number = {SERC-TR165-P},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@ARTICLE{Demillo95SCRH,
  author = {R. A. DeMillo and A. P. Mathur and W. E. Wong},
  title = {Some Critical Remarks on a Hierarchy of Fault-Detecting Abilities of Test Methods},
  volume = {SE-21},
  number = {10},
  month = oct,
  year = {1995},
  pages = {858--860},
  journal = ieeese,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@ARTICLE{Demillo93ERAT,
  author = {R. A. DeMillo and A. J. Offutt},
  title = {Experimental Results from an Automatic Test Case Generator},
  volume = {2},
  number = {2},
  year = {1993},
  pages = {109--127},
  journal = acmse,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@ARTICLE{Demillo91CBAT,
  author = {R. A. DeMillo and A. J. Offutt},
  title = {Constraint Based Automatic Test Data Generation},
  volume = {SE-17},
  number = {9},
  month = sep,
  year = {1991},
  pages = {900--910},
  journal = ieeese,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@ARTICLE{Demirezen-etal:2010,
  author = {Demirezen, Zekai and Sun, Yu and Gray, Jeff and Jouault, Frédéric},
  title = {Enabling tool reuse and interoperability through model-driven engineering},
  volume = {10},
  number = {1-2S2},
  month = sep,
  year = {2010},
  pages = {187--202},
  doi = {10.3233/JCM-2010-0278},
  abstract = {Software components provide a wide range of functionality that can be used across several domains. In some cases, reuse at a very coarse level of granularity (e.g., reusing functionality provided within an existing tool) is desirable, but challenging to realize due to the interface boundaries of the tool and the unanticipated level of reuse. This paper describes our results in applying model-driven engineering (e.g., domain-specific modeling and model transformation) to the tool reuse problem. Our approach captures the essence of each tool in a metamodel and uses model transformations to map between the tool representations. Specifically, we describe our results in reusing the graphical layout functionality provided by one tool (e.g., GraphViz) that does not exist natively in another tool (e.g., the Eclipse Graphical Modeling Framework).},
  keywords = {Domain-specific modeling, model transformation, tool interoperability},
  address = {Amsterdam, } # Netherlands,
  issn = {1472-7978},
  journal = {Journal of Computational Methods in Sciences and Engineering -- Special Supplement Issue in Section A and B: Selected Papers from the {ISCA} International Conference on Software Engineering and Data Engineering 2009},
  publisher = {{IOS}}
}

@ARTICLE{Denning-Riehle:2009,
  author = {Denning, Peter J. and Riehle, Richard D.},
  title = {The profession of IT: Is software engineering engineering?},
  volume = {52},
  number = {3},
  month = mar,
  year = {2009},
  pages = {24--26},
  doi = {10.1145/1467247.1467257},
  abstract = {Software engineering continues to be dogged by claims it is not engineering. Adopting more of a computer-systems view may help.},
  acmid = {1467257},
  address = {New York, NY, USA},
  issn = {0001-0782},
  issue = {3},
  issue_date = {March 2009},
  journal = {Communications of the ACM},
  numpages = {3},
  publisher = {ACM}
}

@MISC{milstd498:1994,
  author = {{Departament of Defense}},
  title = {MIL-STD-498 - DI-IPSC-81433 - Software Requirements Specification},
  month = dec,
  year = {1994},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@ARTICLE{derbentseva-etal:2007,
  author = {Natalia Derbentseva and Frank Safayeni and Alberto J. Canas},
  title = {Concept Maps: Experiments on Dynamic Thinking},
  volume = {44},
  number = {3},
  month = mar,
  year = {2007},
  pages = {448-465},
  doi = {10.1002/tea.20153},
  abstract = {Three experiments were conducted to examine the effects of map structure, concept quantification, and focus question on dynamic thinking during a Concept Map (CMap) construction task. The first experiment compared cyclic and hierarchical structures. The second experiment examined the impact of the quantification of the header concept in the map. The third experiment explored the effect of the focus question on the map. For all three experiments, the content of the CMaps was assessed for the number of dynamic propositions and the number of quantified concepts. The results show that the cyclic structure, the quantification of the header concept, and the focus question "How" significantly increased dynamic thinking. The studies, the theoretical background, and the implications of the findings are discussed.},
  issn = {1098-2736},
  journal = {Journal of Research in Science Teaching}
}

@ARTICLE{Derntl-etal:2010,
  author = {Michael Derntl and Patrick Parrish and Luca Botturi},
  title = {Beauty and Precision: Weaving Complex Educational Technology Projects with Visual Instructional Design Languages},
  volume = {9},
  number = { 2 },
  month = { April },
  year = {2010},
  pages = {185--202},
  abstract = {Instructional design and technology products result from many options and constraints. On the one hand, solutions should be creative, effective and flexible; on the other hand, developers and instructors need precise guidance and details on what to do during development and implementation. Communication of and about designs is supported by design languages, some of which are conceptual and textual, and others more formal and visual. In this paper we analyze a case in which both a creative solution (beauty) and clear-cut details (precision) are sought. To contribute to the final beauty of the product we apply a narrative approach that outlines the general structure of the design solution. To provide the necessary precision, we employ a more formal visual design language to specify design details for development and implementation. We claim that a mix of design languages at different layers of abstraction and formalization can be used effectively as complementary tools for creating aesthetic and successful design solutions through progressive refinement.},
  url = { http://www.editlib.org/p/29505 },
  address = { Chesapeake, VA },
  issn = {1537-2456},
  journal = {International Journal on E-Learning},
  publisher = { AACE }
}

@MISC{xmlpointer:2002,
  author = {Steven DeRose and Ron Daniel Jr. and Paul Grosso and Eve Maler and Jonathan Marsh and Norman Walsh},
  title = {XML Pointer Language (XPointer)},
  howpublished = {W3C Working Draft},
  month = aug,
  year = {2002},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://www.w3.org/TR/xptr/}
}

@TECHREPORT{derose:2001,
  author = {S. DeRose and E. Maler and D. Orchard},
  title = {XML Linking Language (XLink)},
  institution = {W3C},
  year = {2001},
  url = {http://www.w3c.org/TR/xlink},
  owner = {magsilva},
  timestamp = {2008.07.30},
  type = {W3C Recommendation}
}

@MISC{xlink:2001,
  author = {Steve DeRose and Eve Maler and David Orchard},
  title = {XML Linking Language (XLink) Version 1.0},
  howpublished = {W3C Recommendation},
  month = jun,
  year = {2001},
  comment = {24/05/2005},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://www.w3.org/TR/xlink/}
}

@BOOK{derose:1994,
  title = {Making Hypermedia Work: A User's Guide to HyTime},
  publisher = {Klewer Academic Publishers},
  year = {1994},
  author = {Steven J. DeRose and David G. Durand},
  address = {Estados Unidos},
  edition = {1},
  month = jun,
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@ARTICLE{deshpande2003,
  author = {{Deshpande}, Y. and {Murugesan}, S. and {Ginige}, A. and {Hansen}, S. and {Schwabe}, D. and {Gaedke}, M. and {White}, B.},
  title = {Web Engineering},
  month = jun,
  year = {2003},
  adsnote = {Provided by the Smithsonian/NASA Astrophysics Data System},
  adsurl = {http://adsabs.harvard.edu/cgi-bin/nph-bib_query?bibcode=2003cs6108D&db_key=PRE},
  eprint = {arXiv:cs/0306108},
  journal = {ArXiv Computer Science e-prints},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@INPROCEEDINGS{deursen:2002,
  author = {Deursen, A. van and E. Visser},
  title = {The {R}eengineering {W}iki},
  pages = {217--220},
  booktitle = {Proceedings 6th European Conference on Software Maintenance and Reengineering (CSMR)},
  owner = {magsilva},
  publisher = {IEEE Computer Society},
  timestamp = {2008.07.30},
  url = {http://www.program-transformation.org/re/},
  year = {2002}
}

@BOOK{Deutsch82SVVA,
  title = {Software Verification and Validation},
  publisher = {Prentice-Hall},
  year = {1982},
  author = {M. S. Deutsch},
  address = {Englewood Cliffs, New Jersey},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{Dholakia-etal:2007,
  author = {Utpal M. Dholakia and W. Joseph King and Richard Baraniuk},
  title = {What makes an open education program sustainable? The case of Connexions},
  pages = {1--25},
  booktitle = {Open Education 2006: Community, Culture, and Content},
  location = {Logan, UT, #USA#},
  month = sep,
  year = {2006}
}

@ARTICLE{diaz:1999,
  author = {I. Días and A. Metteo},
  title = {Objectory Process Stereotypes},
  month = jun,
  year = {1999},
  pages = {29-38},
  journal = {JOOP},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@INPROCEEDINGS{dia:2000,
  author = {J. S. Diaz and V. P. Ferragud and E. I. Pelozo},
  title = {Un Entorno de Generation de Protótipo de Interfaces de Usuário a Partir de Diagramas de Interacción},
  pages = {145-154},
  address = {Cancun-México},
  booktitle = {IDEAS 2000: Jornada Ibero Americana de Ingeneria de Requisitos Y Ambientes de Software},
  owner = {magsilva},
  publisher = {IDEAS 2000: Jornada Ibero Americana de Ingeneria de Requisitos Y Ambientes de Software},
  timestamp = {2008.07.30},
  year = {2000}
}

@ARTICLE{redondo-etal:2011,
  author = {Díaz Redondo, R. and Vilas, F. and Rodríguez Malmierca, M. J. and Pazos Arias, J. J. and Molares, S. B.},
  title = {Experiencia Piloto para la Provisión de Formación Personalizada en Televisión sobre la Plataforma T-Maestro},
  volume = {6},
  number = {1},
  month = feb,
  year = {2011},
  pages = {10-18},
  abstract = {This paper introduces a platform to support the provision of pedagogical units especially designed to Interactive Digital TV. We have developed an authoring tool to create the educative content according to both the technical and social peculiarities of this newmedia. Besides, a set of software modules were also set up to support the suitable broadcasting and visualization in the receiver device. As TV learning is mainly casual, personalization plays an essential role to provide particularized content offer to each student to support more appealing learning experiences.},
  abbrev_source_title = {Rev. Iberoam. Technol. Aprendizaje},
  affiliation = {Departamento de Ingeniería Telemática, Universidad de Vigo, Spain},
  author_keywords = {Adaptation; Idtv; Learning; Learning systems; Personalization},
  correspondence_address = {Díaz Redondo, R.; Departamento de Ingeniería Telemática, Universidad de VigoSpain; email: rebeca@det.uvigo.es},
  document_type = {Article},
  issn = {1932-8540},
  journal = {Revista Iberoamericana de Tecnologias del Aprendizaje},
  language = {Spanish},
  publisher = {Sociedad de la Educación del IEEE},
  source = {Scopus},
  title-native = {Providing personalized t-learning with T-Maestro: A pilot experience}
}

@BOOK{Dick-Carey:1990,
  title = {The Systematic Design of Instruction},
  publisher = {Scott, Foresman and Company},
  year = {1990},
  author = {W. Dick and L. Carey},
  address = {Glenview, IL},
  edition = {3},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@BOOK{Dick-etal:2005,
  title = {The Systematic Design of Instruction},
  publisher = {Pearson},
  year = {2005},
  author = {Walter Dick and Lou Carey and James O. Carey},
  pages = {376},
  address = {EUA},
  edition = {6},
  booktitle = {The Systematic Design of Instruction},
  owner = {magsilva},
  timestamp = {2008.09.20}
}

@BOOK{Dick-etal:2001,
  title = {The Systematic Design of Instruction},
  publisher = {Longman},
  year = {2001},
  author = {W. Dick and L. Carey and J. O. Carey},
  edition = {5},
  owner = {magsilva},
  timestamp = {2008.01.21}
}

@INPROCEEDINGS{Dickey:2006,
  author = {Dickey, Michele D.},
  title = {"Ninja Looting" for instructional design: the design challenges of creating a game-based learning environment},
  pages = {1-4},
  doi = {10.1145/1179295.1179313},
  abstract = {Computer and video games have become an increasingly prevalent form of entertainment. While the primary purpose of games is entertainment, the underlying design employs a variety of strategies and techniques which require players to analyze, synthesize, and to use critical thinking skills. Ironically, these are also many of the same types of critical thinking skills educators and instructional designers attempt to foster when creating educational materials and media. The purpose of this paper is to present an overview of a 3D game-based learning environment and to highlight some of the issues that arose during the design, development, and production. Specifically, this paper presents (a) game design elements which can be appropriated (looted) from game design, (b) cognitive research that supports the integration of the elements for instructional design, (c) a discussion of challenges encountered while creating a 3D game-based learning environment with limited resources, and (d) various low-cost and free resources (to avoid ninja looting).},
  keywords = {education, game design, instructional design},
  series = {SIGGRAPH '06},
  acmid = {1179313},
  address = {New York, NY, USA},
  articleno = {17},
  booktitle = {SIGGRAPH},
  isbn = {1-59593-364-6},
  location = {Boston, Massachusetts, USA},
  publisher = {ACM},
  year = {2006}
}

@MISC{software:lynx,
  author = {Thomas E. Dickey and others},
  title = {Lynx},
  howpublished = {Programa de computador},
  month = mar,
  year = {1998},
  owner = {magsilva},
  timestamp = {2007.08.13},
  url = {http://lynx.isc.org/}
}

@INCOLLECTION{Dijkstra:1972,
  author = {Dijkstra, Edsger W.},
  title = {Notes on structured programming},
  chapter = {1},
  pages = {1--82}
}

@BOOK{Dijkstra:1997,
  title = {A Discipline of Programming},
  publisher = {Prentice Hall PTR},
  year = {1997},
  author = {Dijkstra, Edsger Wybe},
  isbn = {013215871X},
  address = {Upper Saddle River, NJ, USA},
  edition = {1st}
}

@BOOK{Dijkstra:1982,
  title = {Selected Writings on Computing: A Personal Perspective},
  publisher = {Springer-Verlag},
  year = {1982},
  author = {Edsger W. Dijkstra},
  isbn = {0-387-90652-5},
  address = {New York, NY, } # USA,
  booktitle = {Selected Writings on Computing: A Personal Perspective}
}

@TECHREPORT{Dijkstra:1969,
  author = {Edsger W. Dijkstra},
  title = {Notes on Structured Programming},
  institution = {Technological University Eindhoven},
  month = aug,
  year = {1969},
  number = {70-WSK-03},
  address = Netherlands
}

@MASTERSTHESIS{diniz:2007,
  author = {Danielle Dornellas Diniz},
  title = {A interação no ensino a distância sob a ótica dos estilos de aprendizagem},
  school = {Universidade de São Paulo - Escola de Engenharia de São Carlos},
  year = {2007},
  address = {Sâo Carlos, SP},
  note = {Orientador: Renata Vairo Belhot},
  timestamp = {2008.09.15}
}

@MISC{ufrgs,
  author = {Tiarajú Asmuz Diverio and Paulo Blauth Menezes},
  title = {Site da disciplina de Teoria da Computação do Programa de Ensino à Distância da Universidade Federal do Rio Grande do Sul},
  year = {2002},
  note = {\url{http://www.inf.ufrgs.br/~hgmc/site/programa/programa.html} (19/09/2002)},
  organization = {University of California, Berkeley},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {\url{http://www.inf.ufrgs.br/~hgmc/site/programa/programa.html} (19/09/2002)}
}

@BOOK{Diverio,
  title = {Teoria da Computação - Máquinas Universais e Computalidade},
  publisher = {Editora Sagra-Luzzatto},
  year = {2000},
  author = {Tiarajú Asmuz Diverio and Paulo Blauth Menezes},
  pages = {205},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@BOOK{Dix-etal:1998,
  title = {Human-Computer Interaction},
  publisher = {Prentice Hall},
  year = {1998},
  author = {Alan J. Dix and Janet E. Finlay and Gregory D. Abowd and Russel Beale},
  isbn = {0-13-239864},
  pages = {638},
  address = {Inglaterra},
  edition = {2},
  booktitle = {Human-Computer Interaction}
}

@ARTICLE{Dixonwoods-etal:2005,
  author = {M. Dixon-Woods and S. Agarwal and D. Jones and B. Young and A. Sutton},
  title = {Synthesising qualitative and quantitative evidence: a review of possible methods},
  volume = {10},
  number = {1},
  month = jan,
  year = {2005},
  pages = {45-53},
  journal = {Journal of Health Services Research \& Policy},
  publisher = {Royal Society of Medicine Press}
}

@INPROCEEDINGS{Diziol:2010:LME:1854509.1854702,
  author = {Diziol, Dejana and Rummel, Nikol and Spada, Hans and Haug, Stephanie},
  title = {Learning in mathematics: effects of procedural and conceptual instruction on the quality of student interaction},
  pages = {370--371},
  series = {ICLS '10},
  acmid = {1854702},
  booktitle = {Proceedings of the 9th International Conference of the Learning Sciences - Volume 2},
  location = {Chicago, Illinois},
  numpages = {2},
  publisher = {International Society of the Learning Sciences},
  url = {http://portal.acm.org/citation.cfm?id=1854509.1854702},
  year = {2010}
}

@INPROCEEDINGS{Dodero-etal:2008,
  author = {Dodero, Juan and Tattersall, Colin and Burgos, Daniel and Koper, Rob},
  title = {Transformational Techniques for Model-Driven Authoring of Learning Designs},
  pages = {230-241},
  doi = {10.1007/978-3-540-78139-4_21},
  abstract = {Diverse authoring approaches and tools have been designed to assist the creation of units of learning compliant to current learning technology specifications. Although visual and pattern-based editors of Learning Designs (LD) can help to abstract the learning designer from the details of the specifications, they are still far from a high-level, integrated authoring environment. This paper analyzes the major approaches used to transform an abstract LD into a concrete unit of learning (UoL), according to three desired features: the use of patterns and other design techniques to abstract the specific representational details; the difference between the abstract source LD model and the concrete target UoL model; and the possibility of combining multiple models into a single environment. A classification is proposed for the LD techniques commonly found in the analyzed approaches, in order to underline its abstraction from the details of the underlying specifications. We have integrated such LD techniques in a unified Model-Driven Learning Design (MDLD) meta-modeling environment, which has been used to generate UoLs from a number of meta-models. The model-driven development process was studied on the creation of a IMS LD UoL for the Learning Networks' knowledge base.},
  volume = {4823},
  series = {Lecture Notes in Computer Science},
  address = {Edinburgh, } # UK,
  affiliation = {Universidad Carlos III de Madrid Av. Universidad 30 28911 Leganés Madrid Spain},
  booktitle = {International Conference on Advances in Web Based Learning},
  editor = {Leung, Howard and Li, Frederick and Lau, Rynson and Li, Qing},
  isbn = {978-3-540-78138-7},
  location = {Edinburgh, #UK#},
  month = aug,
  owner = {magsilva},
  publisher = {Springer},
  year = {2007}
}

@INPROCEEDINGS{Dodero-Diez:2006,
  author = {J. M. Dodero and D. Diez},
  title = {Model-Driven Instructional Engineering to Generate Adaptable Learning Materials},
  pages = {1188 - 1189},
  doi = {10.1109/ICALT.2006.1652686},
  abstract = {The application of software engineering approaches to generate learning material adapted to a specific instructional purpose presents some issues: the use of different models, different abstraction levels, different contexts and development concerns. These can be overcome by a model-driven development approach that provides different levels of automation for instructional engineering},
  address = {Kerkrade, Países Baixos},
  booktitle = {6th International Conference on Advanced Learning Technologies (ICALT 2006)},
  isbn = {0-7695-2632-2},
  location = {Kerkrade, #Netherlands#},
  month = jul,
  publisher = {IEEE Computer Society},
  timestamp = {2012.01.26},
  year = {2006}
}

@INPROCEEDINGS{doering-xiaoyan:2009,
  author = {Doering, Edward and Mu, Xiaoyan},
  title = {Circuits learned by example online ({CLEO}): video-based resource to support engineering circuit analysis courses},
  pages = {891--894},
  abstract = {The "Circuits Learned by Example Online" (CLEO) web-based repository of over 250 worked problems in engineering circuit analysis provides students with a video-based learning tool suitable for self-guided study, homework support, and exam preparation. Each problem offers the complete solution process embodied as a narrated video "screencast" of handwriting and drawings captured from a tablet device; the audio commentary explains each step of the multistep solution process. The searchable repository matches the organization of leading circuit textbooks, and can also be tailored to a specific course syllabus. Many examples of correct problem-solving strategies are presented, including explanations of why specific strategies are selected among competing approaches. Students report that they consider the CLEO system a useful resource to support their homework activities, as a tutorial to learn more about concepts presented in class, and as preparation materials for exams. Students also reported that the system helped them to better understand course concepts, make efficient use of study time, and improve their problem solving skills.},
  keywords = {circuit analysis, on-line educational resource, screencast video, tutorial},
  series = {FIE'09},
  acmid = {1733869},
  address = {Piscataway, NJ, USA},
  booktitle = {Proceedings of the 39th IEEE international conference on Frontiers in education conference},
  isbn = {978-1-4244-4715-2},
  location = {San Antonio, Texas, USA},
  numpages = {4},
  publisher = {IEEE Press},
  url = {http://portal.acm.org/citation.cfm?id=1733663.1733869},
  year = {2009}
}

@MASTERSTHESIS{pacheco04ARSI,
  author = {Marcelo Domingos},
  title = {Uma Arquitetura de Referência para Sistemas de Informação e Portais de Serviços de Governo Eletrônico},
  school = {Universidade Federal de Santa Catarina},
  year = {2004},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@MISC{Domingues00ATCF,
  author = {A. L. S. Domingues},
  title = {Avaliação de Técnicas, Critérios e Ferramentas de Teste para Programas {OO}},
  month = jun,
  year = {2000},
  note = {Qualificação de Mestrado, ICMC-USP},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@MISC{software:dotproject,
  author = {Adam Donnison and Karen Chisholm and Ray Dai and others},
  title = {DotProject},
  howpublished = {Programa de computador},
  month = feb,
  year = {2001},
  owner = {magsilva},
  timestamp = {2007.03.01}
}

@ARTICLE{Doong94AATO,
  author = {R. -K. Doong and P. G. Frankl},
  title = {The {ASTOOT} Approach to Testing Object-Oriented Programs},
  month = apr,
  year = {1994},
  pages = {101-130},
  journal = acmse,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@MASTERSTHESIS{Doria01REES,
  author = {E. S. Dória},
  title = {Replicação de Experimentos em Engenharia de Software},
  school = {ICMC-USP},
  year = {2001},
  address = {S\~ao Carlos, SP},
  month = may,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@MISC{software:moodle,
  author = {Martin Dougiamas and others},
  title = {Moodle (Modular Object-Oriented Dynamic Learning Environment)},
  howpublished = software,
  month = nov,
  year = {2001},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://www.moodle.org}
}

@INPROCEEDINGS{Dougiamas-Taylor:2003,
  author = {Martin Dougiamas and Peter C. Taylor},
  title = {{Moodle}: Using Learning Communities to Create an Open Source Course Management System},
  pages = {171-178},
  abstract = {This paper summarizes a PhD research project that has contributed towards the development of Moodle - a popular open-source course management system (moodle.org). In this project we applied theoretical perspectives such as "social constructionism" and "connected knowing" to the analysis of our own online classes as well as the growing learning community of other Moodle users. We used the mode of participatory action research, including techniques such as case studies, ethnography, learning environment surveys and design methodologies. This ongoing analysis is being used to guide the development of Moodle as a tool for improving processes within communities of reflective inquiry. At the time of writing (April 2003), Moodle has been translated into twenty-seven languages and is being used by many hundreds of educators around the world, including universities, schools and independent teachers.},
  address = {Honolulu, Hawaii, EUA},
  booktitle = {World Conference on Educational Multimedia, Hypermedia and Telecommunications},
  editor = {David Lassner and Carmel McNaught},
  isbn = {1-880094-48-7},
  journal = {World Conference on Educational Multimedia, Hypermedia and Telecommunications},
  location = {Honolulu, Hawaii, USA},
  month = apr,
  owner = {magsilva},
  publisher = {Advancement of Computing in Education},
  timestamp = {2008.07.30},
  url = {http://www.editlib.org/p/13739},
  year = {2003}
}

@INPROCEEDINGS{Douglas:2001,
  author = {Ian Douglas},
  title = {Instructional design based on reusable learning objects: applying lessons of object-oriented software engineering to learning systems design},
  pages = {F4E-1 -- F4E-5},
  doi = {10.1109/FIE.2001.963968},
  abstract = {There is currently a lot of interest in the concept of learning objects. Learning objects are discrete units of learning resources based on agreed standards. The idea behind learning objects is to promote greater reuse of resources within new instructional systems development. The main work in learning objects has primarily focussed on defining the technical requirements and standards for computer based learning objects. The technology itself is not likely to bring the benefits promised by reusable objects without a change in methods used by practicing instructional designers. The instructional design implications of the learning object approach is examined to determine the adaptation required in instructional design methodologies. Object-oriented software engineering is proposed as a useful basis for new thinking in instructional design methodology},
  keywords = {learning objects, reuse, instructional design, methodology},
  volume = {3},
  address = {Reno, Nevada, EUA},
  booktitle = {Frontiers in Education Conference},
  isbn = {0-7803-6669-7 },
  lang = {en},
  location = {Reno, Nevada, EUA},
  publisher = {IEEE},
  timestamp = {2012.01.26},
  year = {2001}
}

@INPROCEEDINGS{Dovrolis-etal:2009,
  author = {Dovrolis, N. and Konstantinidis, S.T. and Bamidis, P.D. and Kaldoudi, E.},
  title = {Depicting educational content re-purposing context and inheritance},
  pages = {1 - 4},
  doi = {10.1109/ITAB.2009.5394367},
  abstract = {Educational content is often shared among different educators and is enriched, adapted and in general repurposed so that it can be re-used in different contexts. This paper discusses educational content and content repurposing in medical education, presenting different repurposing contexts. Finally, it proposes a novel approach to content repurposing via Web 2.0 social networking of learning objects. The proposed social network is augmented by a graphical representation module in order to capture and depict the relationships amongst different re-purposed medical learning objects, based on educational content `families' and inheritance. The ultimate goal is to provide a conceptually different approach to learning object search and retrieval via `social' associations amongst learning objects.},
  keywords = {Web 2.0 social networking;educational content repurposing context;graphical representation module;medical education;object search learning;social association learning;Internet;biomedical education;computer aided instruction;social networking (online);},
  booktitle = {9th International Conference on Information Technology and Applications in Biomedicine (ITAB 2009)},
  isbn = {978-1-4244-5379-5, 978-1-4244-5379-5},
  location = {Larnaca, Cyprus},
  month = nov,
  year = {2009}
}

@ARTICLE{Downes:2007,
  author = {Stephen Downes},
  title = {Models for sustainable open educational resources},
  number = {3},
  month = feb,
  year = {2007},
  pages = {29--44},
  abstract = {This paper depicts the sustainability of Open Educational Resources (OERs) in terms of the three models: funding, technical, and content. Discussion and recommendations are focused on the sustainability of OERs and the requirement that we think of OERs as only part of a larger picture -- one that includes volunteers and incentives, community and partnerships, co-production and sharing, distributed management and control.},
  keywords = {learning, educational resources, open access, OER},
  journal = {Interdisciplinary Journal of Knowledge and Learning Objects}
}

@ARTICLE{Downes:2001,
  author = {Stephen Downes},
  title = {Learning objects: Resources for distance education worldwide},
  volume = {2},
  number = {1},
  year = {2001},
  abstract = {This article discusses the topic of learning objects in three parts. First, it identifies a need for learning objects and describes their essential components based on this need. Second, drawing on concepts from recent developments in computer science, it describes learning objects from a theoretical perspective. Finally, it describes learning objects in practice, first as they are created or generated by content authors, and second, as they are displayed or used by students and other client groups.},
  keywords = {learning objects; XML; meta data; SCORM; Dublin Core; IMS},
  url = {http://www.irrodl.org/index.php/irrodl/article/view/32/378},
  issn = {1492-3831},
  journal = {International Review of Research in Open and Distance Learning},
  owner = {magsilva},
  timestamp = {2008.02.01}
}

@ARTICLE{draheim2003iwp,
  author = {D. Draheim and E. Fehr and G. Weber},
  title = {{Improving the Web Presentation Layer Architecture}},
  year = {2003},
  journal = {Web Technologies and Applications: 5th Asia-Pacific Web Conference, Apweb 2003, Xian, China, April 23-25, 2002, Proceedings},
  owner = {magsilva},
  publisher = {Springer},
  timestamp = {2008.07.30}
}

@ARTICLE{drucker:1985,
  author = {Peter F. Drucker},
  title = {The Discipline of Inovation},
  month = may,
  year = {1985},
  pages = {149-157},
  journal = {Harvard Business Review},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@MISC{dsi:2005,
  author = {{DSI/CGSA}},
  title = {Qualidade e Produtividade no Setor de Software Brasileiro (2005)},
  year = {2005},
  note = {Tabela de tecnologias utilizadas, com dados de 2005 que não constam no documento principal: http://www.mct.gov.br/index.php/content/view/47820.html},
  timestamp = {2008.09.01},
  url = {http://www.mct.gov.br/index.php/content/view/3253.html}
}

@MISC{dsi:2002,
  author = {{DSI/CGSA}},
  title = {Qualidade e Produtividade no Setor de Software Brasileiro (2001)},
  howpublished = {Revista do SEPIN/MCT},
  year = {2002},
  address = {Brasília, DF},
  owner = {magsilva},
  timestamp = {2008.07.31},
  url = {http://www.mct.gov.br/index.php/content/view/3254.html}
}

@MISC{dsi:1997,
  author = {{DSI/CGSA}},
  title = {Qualidade no Setor de Software Brasileiro: 1997},
  howpublished = {Revista do SEPIN/MCT},
  year = {1998},
  note = {Brasília, DF},
  owner = {magsilva},
  timestamp = {2008.07.31},
  url = {http://www.mct.gov.br/index.php/content/view/3256.html}
}

@MISC{dsi:1999,
  author = {{DSI/CGSA}},
  title = {Qualidade no Setor de Software Brasileiro: 1999},
  howpublished = {Revista do SEPIN/MCT},
  year = {1998},
  note = {Brasília, DF},
  owner = {magsilva},
  timestamp = {2008.07.31},
  url = {http://www.mct.gov.br/index.php/content/view/3255.html}
}

@MISC{xforms:2003,
  author = {Micah Dubinko and Leigh L. Klotz Jr. and Roland Merrick and T. V. Raman},
  title = {XForms 1.0},
  howpublished = {W3C Recommendation},
  month = oct,
  year = {2003},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://www.w3.org/TR/xforms/}
}

@ARTICLE{Duitama-etal:2005,
  author = {Freddy Duitama and Bruno Defude and Amel Bouzeghoub and Claire Lecocq},
  title = {A Framework for the Generation of Adaptive Courses based on Semantic Metadata},
  volume = {25},
  number = {3},
  year = {2005},
  pages = {377-390},
  doi = {10.1007/s11042-005-6541-8},
  abstract = {This approach proposes the creation and management of adaptive learning systems by combining component technology, semantic metadata, and adaptation rules. A component model allows interaction among components that share consistent assumptions about what each provides and each requires of the other. It allows indexing, using, reusing, and coupling of components in different contexts powering adaptation. Our claim is that semantic metadata are required to allow a real reusing and assembling of educational component. Finally, a rule language is used to define strategies to rewrite user query and user model. The former allows searching components developing concepts not appearing in the user query but related with user goals, whereas the last allow inferring user knowledge that is not explicit in user model.},
  keywords = {adaptive learning system, semantic metadata, learning objects, composition of learning objects},
  issn = {1380-7501, 1573-7721},
  journal = {Multimedia Tools and Application},
  lang = {en},
  publisher = {Springer},
  timestamp = {2012.01.24}
}

@MISC{Dundan00TCDD,
  author = {I. Duncan and D. Robson and M. Munro},
  title = {Test Case Development During OO Life-Cycle and Evolution},
  howpublished = {Página WWW},
  month = feb,
  year = {2000},
  owner = {magsilva},
  timestamp = {2008.07.31},
  url = {http://beta.csd.anglia.ac.uk/~iduncan/tcd_joop.htm}
}

@TECHREPORT{Duncan97MMCC,
  author = {I. Duncan and D. Robson and M. Munro},
  title = {Mechanism and Measures for Class and Cluster Testing},
  institution = {Department of Computer Science, Anglia Polytechnic University},
  month = jan,
  year = {1997},
  number = {TR-9702},
  url = {http://beta.csd.anglia.ac.uk/~iduncan/APUTR_9702.htm},
  owner = {magsilva},
  timestamp = {2008.07.31},
  type = {Tech Report}
}

@MISC{Dupuis01SPGS,
  author = {R. Dupuis and P. Bourque and A. Abran and J. W. Moore and L. L. Tripp},
  title = {The {SWEBOK Project}: Guide to the Software Engineering Body of Knowledge},
  month = may,
  year = {2001},
  note = {Stone Man Trial Version 1.00, http://www.swebok.org/ [01/12/2003]},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@INPROCEEDINGS{duque-etal:2007,
  author = {Duque, Rafael and Bravo, Crescencio and Ortega, Manuel},
  title = {Towards an Ontology to Conceptualize Solution Analysis Tasks in CSCL Environments},
  pages = {509--512},
  doi = {10.1007/978-3-540-73681-3_46},
  abstract = {New technologies based on meta-models and ontology engineering allow the formalization and conceptualization of the components that take part in the process of collaboration and interaction analysis in CSCL (Computer-Supported Collaborative Learning) environments. In this article, a proposal to characterize the process of analysis of solutions in CSCL environments is made by means of an ontology. These solutions are built by the learners through a process of collaboration following a problem solving approach.s},
  series = {ICCS '07},
  acmid = {1420956},
  address = {Berlin, Heidelberg},
  booktitle = {Proceedings of the 15th international conference on Conceptual Structures: Knowledge Architectures for Smart Applications},
  isbn = {978-3-540-73680-6},
  location = {Sheffield, UK},
  numpages = {4},
  publisher = {Springer-Verlag},
  year = {2007}
}

@ARTICLE{duque-etal:2009,
  author = {Duque, Rafael and Noguera, Manuel and Bravo, Crescencio and Garrido, José Luis and Rodríguez, María Luisa},
  title = {Construction of interaction observation systems for collaboration analysis in groupware applications},
  volume = {40},
  number = {12},
  month = dec,
  year = {2009},
  pages = {1242--1250},
  doi = {10.1016/j.advengsoft.2009.01.028},
  abstract = {Interaction observation systems for groupware applications capture and process all the actions performed by users engaged in workgroups. These actions are then stored in log documents that enable the work process carried out by the users to be analyzed and the interaction between users to be studied. This article proposes an approach, based on ontological models, which is devised to help the developer of an observation system for a groupware application to structure and record user actions. In order to achieve this aim, we present a specific ontology that shapes the collaborative work process of the users so as to obtain an XML-based log document that stores all the actions carried out by the users and facilitates the subsequent analysis of the system usage and users' behavior. This approach has been used to improve communication and collaboration capabilities in the COLLECE groupware application.},
  keywords = {Groupware, Interaction and collaboration analysis, Ontologies},
  acmid = {1596235},
  address = {Oxford, UK, UK},
  issn = {0965-9978},
  issue = {12},
  journal = {Advances in Engineering Software},
  numpages = {9},
  publisher = {Elsevier Science}
}

@PHDTHESIS{duran:2000:1,
  author = {A. Dur\'an},
  title = {A Methodological Framework for Requirements Engineering of Information Systems},
  school = {University of Seville},
  year = {2000},
  note = {Em espanhol},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@INPROCEEDINGS{duran:2001,
  author = {Amador Dur\'an and Antonio Ruiz and Miguel Toro},
  title = {An Automated Approach for Verification of Software Requirements},
  address = {Seville},
  booktitle = {JIRA'2001 Proceedings},
  owner = {magsilva},
  timestamp = {2008.07.30},
  year = {2001}
}

@ARTICLE{duran-ntafos:1984,
  author = {Joe W. Duran and Simeon C. Ntafos},
  title = {An Evaluation of Random Testing},
  volume = {10},
  number = {4},
  month = jul,
  year = {1984},
  pages = {438-444},
  journal = ieeese,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{Durelli-etal:2011,
  author = {Durelli, Vinicius H. S. and Araujo, Rodrigo F. and Graciotto Silva, Marco Aurélio and Oliveira, Rafael A. P. and Maldonado, Jose C. and Delamaro, M\'{a}rcio E.},
  title = {What a Long, Strange Trip It's Been: Past, Present, and Future Perspectives on Software Testing Research},
  pages = {30--39},
  doi = {10.1109/SBES.2011.17},
  abstract = {Over the past 25 years the Brazilian Symposium on Software Engineering (SBES) has evolved to become the most important event on software engineering in Brazil. Throughout these years, SBES has gathered a large body of studies in software testing. Aimed at providing an insightful understanding of what has already been published in such event, we synthesized its rich 25-year history of research on software testing. Using information drawn from this overview we attempted to highlight which types of study have been the most applied for conveying software testing efforts. We also devised a co-authorship network to obtain a bird's-eye view of which research groups and scholars have been the most prolific ones. Moreover, by performing a citation analysis of the selected studies we set out to ascertain the importance of SBES in a wider scenario. Finally, borne out by the information extracted from the studies, we shed some light on the state-of-the-art of software testing in Brazil and provide an outlook on its foreseeable future.},
  keywords = {Software Testing, systematic mapping},
  series = {SBES '11},
  address = {São Paulo, SP, Brazil},
  booktitle = {Proceedings of the 2011 25th Brazilian Symposium on Software Engineering},
  isbn = {978-0-7695-4603-2},
  location = {São Paulo, SP, Brazil},
  month = sep,
  publisher = {IEEE Computer Society},
  year = {2011}
}

@INPROCEEDINGS{Durelli-etal:2011:poster,
  author = {Durelli, Vinicius H. S. and Araujo, Rodrigo F. and Graciotto Silva, Marco Aurélio and Oliveira, Rafael A. P. and Maldonado, Jose C. and Delamaro, Márcio E.},
  title = {What a Long, Strange Trip It's Been: Past, Present, and Future Perspectives on Software Testing Research},
  pages = {1--1},
  abstract = {Over the past 25 years the Brazilian Symposium on Software Engineering (SBES) has evolved to become the most important event on software engineering in Brazil. Throughout these years, SBES has gathered a large body of studies in software testing. Aimed at providing an insightful understanding of what has already been published in such event, we synthesized its rich 25-year history of research on software testing. Using information drawn from this overview we attempted to highlight which types of study have been the most applied for conveying software testing efforts. We also devised a co-authorship network to obtain a bird's-eye view of which research groups and scholars have been the most prolific ones. Moreover, by performing a citation analysis of the selected studies we set out to ascertain the importance of SBES in a wider scenario. Finally, borne out by the information extracted from the studies, we shed some light on the state-of-the-art of software testing in Brazil and provide an outlook on its foreseeable future.},
  keywords = {Software Testing, systematic mapping},
  series = {SBES '11},
  address = {São Paulo, SP, Brazil},
  booktitle = {Proceedings of the 2011 25th Brazilian Symposium on Software Engineering},
  isbn = {978-0-7695-4603-2},
  location = {São Paulo, SP, Brazil},
  month = sep,
  note = {Poster},
  publisher = {IEEE Computer Society},
  year = {2011}
}

@BOOK{Dustin99ASTI,
  title = {Automated Software Testing: Introduction, Management, and Performance},
  publisher = {Addison Wesley Longman},
  year = {1999},
  author = {E. Dustin and J. Rashka and J. Paul},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@MISC{standard:dvb:a153:2011,
  author = {{DVB}},
  title = {DVD Document A152: Digital Video Broadcasting (DVB); Globally Executable MHP (GEM) Specification 1.3 (including OTT and hybrid broadcast/broadband)},
  howpublished = standard,
  month = mar,
  year = {2011},
  abstract = {The present document defines the GEM platform. GEM is applicable for specifications and standards based on the GEM APIs, content formats, and semantic guarantees. The present document is firstly intended to be used by entities writing terminal specifications and/or standards based on GEM. Secondly it is intended for developers of applications that use the GEM functionality and APIs. The GEM specification aims to ensure interoperability between GEM applications and different implementations of platforms supporting GEM applications. This includes interoperability across different middleware specifications, e.g. MHP, Blu-ray, OCAP, ACAP, ARIB, and the Open IPTV Procedural Application Gateway [8]. Implementers should consult the publisher of specifications which reference GEM regarding conformance. NOTE: The present document defines the interfaces visible to applications. Application developers should not assume that any related interface is available unless it is specifically listed. Terminal standards or implementations may have other interfaces present. Since the current business models for delivery of DVB services via broadband IP networks are more operator controlled than was assumed for the original GEM, the present document extends GEM with support for operator supplied applications which run all the time that the GEM environment is running. There is also the possibility that where an operator has subsidised the GEM terminal, applications from that operator may have specially privileges not available to normal applications. Clauses 1 to 14 specify the applicable technologies and technical definitions in a generic way. Clause 15 provides detailed profile definitions for the following initial profiles: Enhanced Broadcasting. Interactive Broadcasting. Enhanced Packaged Media. Interactive Packaged Media, IPTV, OTT, which can be extended with future additional profile definitions. Clause 16 provides a registry of constants and clause 17 describes requirements for internet access clients. One of the primary goals of the present document is to minimize the number of divergences between GEM and MHP terminal specifications, wherever practical. Divergence is defined in clause 3.1. Where divergences are inescapable, the present document serves as a place to document and control the permitted divergences, so that they will be predictable to terminal manufacturers, broadcasters, and application authors.},
  pages = {860},
  timestamp = {2008.10.03},
  url = {http://www.mhp.org/specs/A153_GEM_v1_3.pdf},
  urlaccessdate = {20 fev 2012}
}

@INPROCEEDINGS{dyba-torgeir:2008,
  author = {Tore Dyb{\aa} and Torgeir Dings{\o}yr},
  title = {Strength of evidence in systematic reviews in software engineering},
  pages = {178--187},
  doi = {10.1145/1414004.1414034},
  abstract = {Systematic reviews are only as good as the evidence they are based on. It is important, therefore, that users of systematic reviews know how much confidence they can place in the conclusions and recommendations arising from such reviews. In this paper we present an overview of some of the most influential systems for assessing the quality of individual primary studies and for grading the overall strength of a body of evidence. We also present an example of the use of such systems based on a systematic review of empirical studies of agile software development. Our findings suggest that the systems used in other disciplines for grading the strength of evidence for and reporting of systematic reviews, especially those that take account of qualitative and observational studies are of particular relevance for software engineering.},
  acmid = {1414034},
  address = {New York, NY, USA},
  booktitle = {International Symposium on Empirical Software Engineering and Measurement},
  isbn = {978-1-59593-971-5},
  location = {Kaiserslautern, Germany},
  numpages = {10},
  publisher = {ACM},
  year = {2008}
}

@INPROCEEDINGS{Dyba-etal:2007,
  author = {Dyba, T. and Dingsoyr, T. and Hanssen, G.K.},
  title = {Applying Systematic Reviews to Diverse Study Types: An Experience Report},
  pages = {225 -234},
  doi = {10.1109/ESEM.2007.59},
  abstract = {Systematic reviews are one of the key building blocks of evidence-based software engineering. Current guidelines for such reviews are, for a large part, based on standard meta-analytic techniques. However, such quantitative techniques have only limited applicability to software engineering research. In this paper, therefore, we describe our experience with an approach to combine diverse study types in a systematic review of empirical research of agile software development.},
  address = {Washington, DC, EUA},
  booktitle = {International Symposium on Empirical Software Engineering and Measurement},
  issn = {1938-6451},
  location = {Washington, DC, EUA},
  month = sep,
  publisher = {IEEE Computer Society},
  year = {2007}
}

@BOOK{Easley-Kleinberg:2010,
  title = {Networks, Crowds and Markets: Reasoning about a Highly Connected World},
  publisher = {Cambridge University},
  year = {2010},
  author = {David Easley and Jon Kleinberg},
  isbn = {9780521195331},
  pages = {744},
  address = UK,
  edition = {1},
  month = sep,
  url = {http://www.cs.cornell.edu/home/kleinber/networks-book/}
}

@INPROCEEDINGS{eberlein:2002,
  author = {Armin Eberlein},
  title = {Agile Requirements Definition: A View from Requirements Engineering},
  address = {Essen, Alemanha},
  booktitle = {International Workshop on Time Constrained Requirements Engineering},
  month = sep,
  owner = {magsilva},
  timestamp = {2008.07.30},
  year = {2002}
}

@BOOK{ebersbachetal:2005,
  title = {Wiki Web Collaboration},
  publisher = {Springer-Verlag},
  year = {2005},
  author = {Anja Ebersbach and Markus Glaser and Richard Heigl},
  pages = {383},
  address = {Bergin, Alemanha},
  owner = {magsilva},
  timestamp = {2008.04.03}
}

@INPROCEEDINGS{eberspacher-etal:1999,
  author = {H. F. Eberspächer and C. D. Vasconcelos and J. H. Jamur and M. A. M. Eleutério},
  title = {Eureka: Um Ambiente de Aprendizagem Cooperativa baseado na Web para Educação à Distância},
  address = {Curitiba, PR},
  booktitle = {X Simpósio Brasileiro de Informática na Educação (SBIE 99)},
  month = nov,
  owner = {magsilva},
  timestamp = {2008.07.30},
  year = {1999}
}

@ARTICLE{ebner-etal:2007,
  author = {Martin Ebner and Andreas Holzinger and Hermann Maurer},
  title = {Universal Access in Human-Computer Interaction: Applications and Services},
  volume = {559},
  year = {2007},
  pages = {568},
  journal = {Lectures Notes on Computer Science},
  timestamp = {2008.10.02}
}

@MISC{software:mylyn,
  author = {{Eclipse Foundation}},
  title = {Mylyn},
  howpublished = {Programa de Computador},
  month = aug,
  year = {2004},
  owner = {magsilva},
  timestamp = {2007.10.29},
  url = {http://www.eclipse.org/mylyn/}
}

@MISC{software:eclipse,
  author = {{Eclipse Foundation}},
  title = {Eclipse},
  howpublished = {Programa de Computador},
  month = nov,
  year = {2001},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://www.eclipse.org}
}

@MISC{standard:ecma-262:1999,
  author = {{ECMA International}},
  title = {Standard ECMA-262 -- ECMAScript Language Specification},
  howpublished = {Padrão},
  month = dec,
  year = {1999},
  timestamp = {2008.09.27},
  url = {http://www.ecma-international.org/publications/standards/Ecma-262.htm}
}

@ARTICLE{edmonds:2006,
  author = {Kelly Edmonds},
  title = {Off with their heads! Copyright infringement in the Canadian online higher educational environment},
  volume = {32},
  number = {2},
  year = {2006},
  url = {http://www.cjlt.ca/index.php/cjlt/article/view/52/49},
  journal = {Canadian Journal of Learning and Technology},
  owner = {magsilva},
  timestamp = {2009.02.20}
}

@INPROCEEDINGS{Eguia-etal:2005,
  author = {Eguia, Andres Elexpuru and Nores, Martin Lopez and Fernandez, Yolanda Blanco and Arias, Jose Pazos and Martinez, Belen Barragans and Duque, Jorge Garcia and Solla, Alberto Gil and Cabrer, Manuel Ramos},
  title = {Collaborative T-learning: Bringing Greater Levels of Interactivity into the Home},
  pages = {588--591},
  doi = {10.1109/EEE.2005.49},
  abstract = {T-learning -the provision of educational services over Interactive Digital TV-is emerging as a important medium to create opportunities for learning at home. In this paper, we elaborate on a framework for the development and deployment of collaborative t-learning services, presenting an architecture that allows distributing the logic of a service, a way to define complex interaction patterns among users and a network infrastructure that provides adequate support for the communication needs.},
  series = {EEE '05},
  acmid = {1049577},
  address = {Washington, DC, USA},
  booktitle = {IEEE International Conference on e-Technology, e-Commerce and e-Service},
  isbn = {0-7695-2274-2},
  numpages = {4},
  publisher = {IEEE Computer Society},
  year = {2005}
}

@INPROCEEDINGS{eickelmann:1996,
  author = {N. S. Eickelmann and D. J. Richardson},
  title = {An evaluation of software test environment architectures},
  pages = {353-364},
  address = {Berlim, Alemanha},
  booktitle = {18th International Conference on Software Engineering},
  owner = {magsilva},
  publisher = {IEEE Computer Society Press},
  timestamp = {2006.11.13},
  year = {1996}
}

@MISC{Eis:2012,
  author = {Diego Eis},
  title = {Qual unidade utilizar -- Pixel, {EM} ou {REM}},
  howpublished = Webpage,
  month = sep,
  year = {2012},
  address = Brazil,
  url = {http://tableless.com.br/unidade-pixels-em-rem/}
}

@ARTICLE{eisenberg:1998,
  author = {Andrew Eisenberg and Jim Melton},
  title = {Standards in Practice},
  volume = {27},
  number = {3},
  year = {1998},
  pages = {53-58},
  doi = {10.1145/290593.290604},
  journal = {ACM SIGMOD Record},
  owner = {magsilva},
  timestamp = {2006.08.22}
}

@MISC{jdbc:2001,
  author = {Jon Ellis and Linda Ho and Maydene Fisher},
  title = {JDBC 3.0 Specification},
  howpublished = {Proposed Final Draft 4},
  month = {oct},
  year = {2001},
  file = {JDBC 3.0 Specification.pdf:JDBC 3.0 Specification.pdf:PDF},
  owner = {Marco Aurélio Graciotto Silva},
  timestamp = {2008.07.30}
}

@BOOK{Elmasri90FDSY,
  title = {Fundamental of Database Systems},
  publisher = {The Benjamim/Cummings Publishing Company},
  year = {1990},
  author = {R. Elmasri and S. Navate},
  edition = {2},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@BOOK{elmasri:2000,
  title = {Fundamentals of Database Systems},
  publisher = {Addison-Wesley},
  year = {2000},
  author = {Ramez Elmasri and Shamkant Navathe},
  edition = {3},
  month = jun,
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@INPROCEEDINGS{engelbart:1968,
  author = {Douglas Engelbart},
  title = {A research center for augmenting human intellect},
  pages = {395-410},
  volume = {33},
  address = {San Francisco, CA, USA},
  booktitle = {Fall Joint Computer Conference (FJCC)},
  month = dec,
  note = {Also known as 'The Mother of All Demos'.},
  owner = {magsilva},
  timestamp = {2011.01.14},
  url = {http://www.dougengelbart.org/firsts/dougs-1968-demo.html},
  year = {1968}
}

@TECHREPORT{project:qualipso,
  author = {{Engineering- Ingegneria Informatica} and others},
  title = {QualiPSo -- Quality Platform for Open Source Software},
  month = nov,
  year = {2006},
  url = {http://www.qualipso.org/},
  howpublished = {Projeto},
  note = {IST-FP6-034763},
  timestamp = {2009.02.02}
}

@INPROCEEDINGS{Eronen:2001,
  author = {Leena Eronen},
  title = {Combining quantitative and qualitative data in user research on digital television},
  pages = {51--56},
  abstract = {This paper presents user grouping for digital TV. First, eight user groups were formulated in a questionnaire study. Then a focus group study was conducted to reveal specific data on selected user groups' expectations and preferences. The resulting user profiles are a combination of these two data sets. The combination represents how the unchanging quantitative data is joined with the dynamic qualitative data. Use of the focus group study method makes the combined user profiles easy to update. In general, user profiles are a valuable source of information for developers of digital TV applications. Discussion at the end of the paper deals with user research issues on digital TV.},
  keywords = {digital television, user research, focus group studies},
  address = {Patras, Grécia},
  booktitle = {Panhellenic Conference with International Participation on Human-Computer Interaction},
  location = {Patras, Grécia},
  month = dec,
  publisher = {Typorama Publications},
  year = {2001}
}

@INPROCEEDINGS{Ertelt-etal:2006,
  author = {Ertelt, Anna and Renkl, Alexander and Spada, Hans},
  title = {Making a difference: exploiting the full potential of instructionally designed on-screen videos},
  pages = {154--160},
  abstract = {On-screen videos are a potentially powerful learning tool. However, their success depends on their instructional design. Videos allow the real-time demonstration of solution procedures and can yield fast and effective learning. Nonetheless, learning outcomes often cannot be maintained in the medium term. In order to foster deep and meaningful processing and thereby foster sustainable learning, the single actions of the solution process were segmented into small steps using labels (labeling) to indicate the learning content and/or an interactive push button (pacing) emphasizing the key feature of each step. 101 university students took part in this study. They examined an unknown computer application with on-screen videos. The results showed a clear advantage of videos with respect to declarative and procedural knowledge in comparison to a standard introduction of the computer application. Videos with labeling and without pacing supported the acquisition of declarative knowledge, whereas videos with pacing improved procedural knowledge.},
  acmid = {1150057},
  address = {Bloomington, Indiana, EUA},
  booktitle = {International Conference on Learning Sciences},
  isbn = {0-8058-6174-2},
  location = {Bloomington, Indiana},
  numpages = {7},
  publisher = {International Society of the Learning Sciences},
  year = {2006}
}

@ARTICLE{VanEs-Koper:2006,
  author = {René Van Es and Rob Koper},
  title = {Testing the pedagogical expressiveness of IMS LD},
  volume = {9},
  number = {1},
  month = jan,
  year = {2006},
  pages = {229--249},
  abstract = {The IMS Learning Design specification (LD) was introduced as an answer to the shortcomings of existing learning technology specifications. The main difference with existing specifications is that LD is an abstract, conceptual model that is able to express various pedagogical approaches whereby content can be adapted to personal needs and assessments can be integrated. In this article we evaluate the pedagogical expressiveness of LD by taking a set of 16 lesson plans and expressing them in LD. We use three different methods to identify difficulties in expressing the lesson plans in LD. Difficulties identified included circulating a document within a group, giving instructions prior to the start of an activity, random assignment of a group member to a role, group formation at runtime, creation of an inventory to map pre-knowledge, learning objectives and learning achievements, and a way to communicate information on how to deliver a lesson to a teacher. We did not find situations that were impossible to express with LD. The difficulties found are elaborated and suggestions to handle them are given. The methods used are compared and suggestions are given for further research.},
  issn = {1436-4522},
  journal = {Journal of Educational Technology \& Society},
  publisher = {International Forum of Educational Technology \& Society}
}

@MISC{software:kde,
  author = {Matthias Ettrich and others},
  title = {K Destop Environment},
  howpublished = {Programa de Computador},
  year = {1996},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://www.kde.org}
}

@ARTICLE{Euler:1741,
  author = {Leonhard Euler},
  title = {The solution of a problem relating to the geometry of position},
  volume = {8},
  year = {1736},
  pages = {12--140},
  url = {http://eulerarchive.maa.org/pages/E053.html},
  address = Russai,
  journal = {Commentarii academiae scientiarum imperialis Petropolitanae},
  lang = {latin},
  publisher = {St. Petersburg Academy},
  timestamp = {2013-09-24},
  title-original = {Solutio problematis ad geometriam situs pertinentis}
}

@MISC{EuropeanComission:2003,
  author = {{European Commission}},
  title = {Implementation of ``Education \& Training 2010'' Work Programme},
  howpublished = {Relatório de progresso},
  month = nov,
  year = {2003},
  timestamp = {2008.10.02}
}

@MISC{software:ezpublish,
  author = {{eZ Systems}},
  title = {ezPublish},
  howpublished = {Programa de Computador},
  owner = {magsilva},
  timestamp = {2007.12.07},
  url = {http://ez.no/ezpublish}
}

@PHDTHESIS{fabbri:1996:thesis,
  author = {S. C. P F. Fabbri},
  title = {A Análise de Mutantes no Contexto de Sistemas Reativos: Uma Contribuição para o Estabelecimento de Estratégias de Teste e Validação},
  school = {IFSC-USP},
  year = {1996},
  address = {São Carlos, SP, Brasil},
  month = oct,
  note = Advisor # {: José Carlos Maldonado}
}

@INPROCEEDINGS{Fabbri-etal:1994:SBRC,
  author = {S. C. P. F. Fabbri and M. E. Delamaro and J. C. Maldonado and P. C. Masiero},
  title = {{Proteum/FSM} -- Especificação de uma Ferramenta para Apoiar a Validação de Máquinas de Estado Finito pelo Critério Análise de Mutantes},
  pages = {284--304},
  address = {Curitiba -- PR},
  booktitle = {12th Brazilian Symposium on Computer Networks},
  location = {Curitiba, PR, #Brazil#},
  month = may,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1994}
}

@INPROCEEDINGS{Fabbri-etal:1999:CCSS,
  author = {S. C. P. F. Fabbri and J. C. Maldonado and M. E. Delamaro and P. C. Masiero},
  title = {{Proteum/FSM}: A Tool to Support Finite State Machine Validation Based on Mutation Testing},
  pages = {96--104},
  doi = {10.1109/SCCC.1999.810159},
  abstract = {The quality of the VV&T-Verification, Validation and Testing-activity is extremely relevant to the software development process. Testing techniques and criteria have been investigated in the context of VV&T of reactive systems specifications, providing mechanisms to the VV&T activity quality assessment. The establishment of a low-cost, effective testing and validation strategy and the development of supporting tools have been pursued by many researchers for coding and specification as well. This paper discusses the main architectural and operational aspects of a tool, named Proteum/FSM, that supports the application of mutation testing for validating reactive systems specifications based on finite state machines (FSM). Further improvements and research issues are briefly discussed},
  booktitle = {XIX International Conference of the Chilean Computer Science Society (SCCC 99)},
  location = {Talca, #Chile#},
  month = nov,
  year = {1999}
}

@INPROCEEDINGS{Fabbri97MACR,
  author = {S. C. P. F. Fabbri and J. C. Maldonado and P. C. Masiero},
  title = {Mutation Analysis in the Context of Reactive System Specification and Validation},
  pages = {247--258},
  address = {Bath, UK},
  booktitle = {5th Annual International Conference on Software Quality Management},
  month = mar,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1997}
}

@INPROCEEDINGS{Fabbri-etal:1994:ISSRE,
  author = {Sandra C. Pinto Ferraz Fabbri and José Carlos Maldonado and Paulo Cesar Masiero and Marcio Eduardo Delamaro},
  title = {Mutation Analysis Testing for Finite State Machines},
  pages = {220--229},
  doi = {10.1109/ISSRE.1994.341378},
  abstract = {The application of the Mutation Analysis criterion in the context of specifiation based on Finite State Machine is proposed. The main concepts of Finite State Machine and of Mutation Analysis are briefly introduced. An experiment is reported which manually applied Mutation Analysis to a finite state machine modeling a Class 0 ISO Transport Protocol Specification, using two test sequence generator criteria -- the W Method and the TT Method. The results obtained are presented and evidences are given that the use of Mutation Analysis is effective in this context. Finally, the lines of evolution of the work presented in this paper are briefly discussed.},
  booktitle = {5th International Symposium on Software Reliability Engineering (ISSRE)},
  isbn = {0-8186-6665-X},
  location = {Monterey, CA, #USA#},
  month = nov,
  year = {1994}
}

@INPROCEEDINGS{Fabbri93AMBM,
  author = {S. C. P. F. Fabbri and J. C. Maldonado and P. C. Masiero and M. E. Delamaro},
  title = {An\'alise de Mutantes Baseada em M\'aquinas de Estado Finito},
  pages = {407--425},
  address = {Campinas, SP},
  booktitle = {XI Simpósio Brasileiro de Redes de Computadores (SBRC 93)},
  month = may,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1993}
}

@INPROCEEDINGS{Fabbri-etal:1999:ISSRS,
  author = {S. C. P. F. Fabbri and J. C. Maldonado and T. Sugeta and P. C. Masiero},
  title = {Mutation Testing Applied to Validate Specifications Based on Statecharts},
  pages = {210--219},
  abstract = {The establishment of a low-cost, effective testing and validation strategy has been pursued by many researchers at the program level as well as at the specification level. The application of mutation testing for validating specifications based on statecharts is proposed. A mutation operator set for statecharts, one of the crucial points for effectively applying mutation testing is defined; in this scope these operators can be taken as a fault model. We also provide strategies to abstract the statechart components according to different statechart features that may comprise the testing and validation activity aims, providing in this way mechanisms for the establishment of an incremental, hierarchical, mutation-based testing strategy. Implementation and functional aspects of PROTEUM/ST, a tool under development are also presented.},
  booktitle = {International Symposium on Software Reliability Systems},
  location = {Boca Raton, FL, #USA#},
  month = nov,
  year = {1999}
}

@ARTICLE{Fadde:2009:EVO:1595385.1555195,
  author = {Fadde, Peter J.},
  title = {Evolution of a Video-Learning Object Format},
  volume = {2009},
  number = {3},
  month = mar,
  year = {2009},
  doi = {10.1145/1595385.1555195},
  abstract = {In a previous article, Peter J. Fadde emphasized the value of creating an identifiable format for video-learning objects. Developing such a format requires an investment of time and creativity, yet the return-on-investment is significant. In addition, viewers (or learners) know what to expect from each video-learning object -- of key importance with video objects because they can't be perused in a glance. Here, I analyze a series of mini-lecture video-learning objects called 'Real Time Minutes' (RTMs) produced by Jonathan Finkelstein, the creator/curator of Learning Times, an online community for teachers.},
  address = {New York, NY, USA},
  issn = {1535-394X},
  journal = {eLearn},
  publisher = {ACM}
}

@ARTICLE{Fadde:2008,
  author = {Fadde, Peter J.},
  title = {Producing video learning objects for e-learning},
  volume = {2008},
  month = apr,
  year = {2008},
  pages = {1--1},
  doi = {10.1145/1373281.1373283},
  acmid = {1373283},
  address = {New York, NY, USA},
  articleno = {1},
  issn = {1535-394X},
  issue = {4},
  issue_date = {April 2008},
  journal = {eLearn},
  numpages = {1},
  publisher = {ACM}
}

@BOOK{Fairley:2009,
  title = {Managing and Leading Software Projects},
  publisher = {John Wiley \& Sons},
  year = {2009},
  author = {Richard E. Fairley},
  isbn = {978-0-470-29455-0},
  pages = {492},
  address = {Hoboken, NJ, } # USA,
  owner = {magsilva},
  timestamp = {2014.09.26}
}

@INPROCEEDINGS{falbo:2004,
  author = {R. A. Falbo},
  title = {Experiences in Using a Method for Building Domain Ontologies},
  pages = {474--477},
  address = {Alberta, Canada},
  booktitle = {International Workshop on Ontology in Action (OIA)},
  month = jun,
  note = {Joint event of International Conference on Software Engineering and Knowledge Engineering (SEKE 2004)},
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {2004}
}

@PHDTHESIS{Falbo98ICAD,
  author = {R. A. Falbo},
  title = {Integração de Conhecimento em um Ambiente de Desenvolvimento de Software},
  school = {COPPE/UFRJ},
  year = {1998},
  address = {Rio de Janeiro, RJ},
  month = dec,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{falbo-etal:2002,
  author = {R. A. Falbo and G. Guizzardi and K. C. Duarte},
  title = {An ontological approach to domain engineering},
  pages = {351--358},
  doi = {10.1145/568760.568822},
  address = {New York, NY, USA},
  booktitle = {International Conference on Software Engineering and Knowledge Engineering (SEKE)},
  isbn = {1-58113-556-4},
  location = {Ischia, Italy},
  owner = {magsilva},
  publisher = {ACM Press},
  timestamp = {2008.07.31},
  year = {2002}
}

@INPROCEEDINGS{falbo-etal:1998:iberamia,
  author = {R. A. Falbo and C. S. Menezes and A. R. Rocha},
  title = {A Systematic Approach for Building Ontologies},
  address = {Lisboa, Portugal},
  booktitle = {Ibero-American Conference on AI (IBERAMIA)},
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1998}
}

@INPROCEEDINGS{falbo-etal:1998:isas,
  author = {R. A. Falbo and C. S. Menezes and A. R. Rocha},
  title = {Using Ontologies to Improve Knowledge Integration in Software Engineering Environments},
  pages = {1--8},
  address = {Orlando, USA},
  booktitle = {International Conference on Information Systems Analysis and Synthesis (ISAS)},
  month = jul,
  note = {Joint event of World Multiconference on Systemic, Cybernetics and Informatics (SCI)},
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1998}
}

@INPROCEEDINGS{falbo-etal:2003,
  author = {R. A. Falbo and A. C. C. Natali and P. G. Mian and G. Bertollo and F. B. Ruy},
  title = {ODE: Ontology-based software Development Environment},
  pages = {931--940},
  address = {La Plata, Argentina},
  booktitle = {IX Congreso Argentino de Ciencias de la Computación},
  month = oct,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {2003}
}

@INPROCEEDINGS{Fallahkhai:2007,
  author = {Sanaz Fallahkhair and Lyn Pemberton},
  title = {Learner-centred Development of Learning Objects for Interactive Television},
  pages = {3877--3883},
  abstract = {TAMALLE is a system that provides "just in time" on-screen comprehension support for informal learners of English as a Foreign Language (EFL), coupled with more extensive help accessible on the TV or via a learner's mobile phone. The development of this facility involved answering the question of exactly which aspects of the broadcast soundtrack are most in need of this type of explication. We describe a study aimed at developing user-centred heuristics for selecting learning objects to support viewers of broadcast television in a foreign language. Three TV genres were shown to advanced learners of EFL, who were asked to annotate a soundtrack of the programmes to indicate items they found difficult or would have liked to pursue. The most frequently chosen categories were names of unknown places, references to UK culture, references to western references, figurative expressions and slang. We suggest that further studies exploring in more depth, using different genres and learner types, may eventually lead to the possibility of automated and personalised generation of language-oriented learning objects from audio-visual material.},
  booktitle = {World Conference on Educational Multimedia, Hypermedia and Telecommunications},
  editor = {Craig Montgomerie and Jane Seale},
  lang = {en},
  location = {Vancouver, Canada},
  month = jul,
  publisher = {AACE},
  url = {http://www.editlib.org/p/25937},
  year = {2007}
}

@MISC{xmlschema-0:2004,
  author = {David C. Fallside and Priscilla Walmsley},
  title = {XML Schema Part 0: Primer Second Edition},
  howpublished = {W3C Recommendation},
  month = oct,
  year = {2004},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://www.w3.org/TR/xmlschema-0/}
}

@ARTICLE{fan-etal:2011,
  author = {Fan, Xiaoming and Wang, Jianyong and Pu, Xu and Zhou, Lizhu and Lv, Bing},
  title = {On Graph-Based Name Disambiguation},
  volume = {2},
  number = {2},
  month = feb,
  year = {2011},
  pages = {1--23},
  doi = {10.1145/1891879.1891883},
  abstract = {Name ambiguity stems from the fact that many people or objects share identical names in the real world. Such name ambiguity decreases the performance of document retrieval, Web search, information integration, and may cause confusion in other applications. Due to the same name spellings and lack of information, it is a nontrivial task to distinguish them accurately. In this article, we focus on investigating the problem in digital libraries to distinguish publications written by authors with identical names. We present an effective framework named GHOST (abbreviation for GrapHical framewOrk for name diSambiguaTion), to solve the problem systematically. We devise a novel similarity metric, and utilize only one type of attribute (i.e., coauthorship) in GHOST. Given the similarity matrix, intermediate results are grouped into clusters with a recently introduced powerful clustering algorithm called Affinity Propagation. In addition, as a complementary technique, user feedback can be used to enhance the performance. We evaluated the framework on the real DBLP and PubMed datasets, and the experimental results show that GHOST can achieve both high precision and recall.},
  keywords = {Name disambiguation, clustering, graph, similarity},
  acmid = {1891883},
  address = {New York, NY, USA},
  articleno = {10},
  issn = {1936-1955},
  issue = {2},
  issue_date = {February 2011},
  journal = {Journal of Data and Information Quality},
  numpages = {23},
  publisher = {ACM}
}

@BOOK{Faria:1989,
  title = {Aprendizagem e Planejamento de Ensino},
  publisher = {Ática},
  year = {1989},
  author = {Wilson de Faria},
  pages = {84},
  address = {São Paulo, SP, Brasil},
  edition = {1},
  abstract = {Exposição dos conceitos e princípios da teoria da aprendizagem significativa e teoria de ensino de David P. Ausubel, cuja culminância é uma proposta de planejamento instrucional. Básico para educadores e estudantes universitários interessados em questões de aprendizagem e planejamento escolar.},
  booktitle = {Aprendizagem e Planejamento de Ensino},
  lang = {pt},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@ARTICLE{farmer-dolphin:2005,
  author = {James Farmer and Ian Dolphin},
  title = {Sakai: eLearning and More},
  year = {2005},
  journal = {EUNIS 2005-Leadership and Strategy in a Cyber-Infrastructure World},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@INPROCEEDINGS{farmer-hughes:2006,
  author = {Roderick A. Farmer and Baden Hughes},
  title = {Pattern-Based End-User Development with Learning Objects},
  booktitle = {International Conference on Advanced Learning Technologies (ICALT'06)},
  timestamp = {2008.09.26},
  year = {2006}
}

@INPROCEEDINGS{Farrell-etal:2004,
  author = {Farrell, Robert G. and Liburd, Soyini D. and Thomas, John C.},
  title = {Dynamic assembly of learning objects},
  pages = {162--169},
  doi = {10.1145/1013367.1013394},
  abstract = {This paper describes one solution to the problem of how to select sequence, and link Web resources into a coherent, focused organization for instruction that addresses a user's immediate and focused learning need. A system is described that automatically generates individualized learning paths from a repository of XML Web resources. Each Web resource has an XML Learning Object Metadata (LOM) description consisting of General, Educational, and Classification metadata. Dynamic assembly of these learning objects is based on the relative match of the learning object content and metadata to the learner's needs, preferences, context, and constraints. Learning objects are connected into coherent paths based on their LOM topic classifications and the proximity of these topics in a Resource Description Framework (RDF) graph. An instructional sequencing policy specifies how to arrange the objects on the path into a particular learning sequence. The system has been deployed and evaluated within a corporate setting.},
  keywords = {LOM, RDF, assembly, content management, data retrieval, information retrieval, instruction, learning object, linking, metadata, organization, semantic web},
  address = {New York, NY, USA},
  booktitle = {International World Wide Web Conference},
  isbn = {1-58113-912-8},
  location = {New York, NY, USA},
  publisher = {ACM},
  year = {2004}
}

@INPROCEEDINGS{Souza-etal:2008:WTES,
  author = {Maria de Fátima C. de Souza and Rossana M. C. Andrade and José Aires de Castro Filho},
  title = {Aplicando Engenharia de Software Orientado a Modelos ao Desenvolvimento de Objetos de Aprendizagem},
  pages = {62-69},
  abstract = {Objetos de Aprendizagem (OA) são recursos digitais desenvolvidos como ferramenta de apoio ao processo de aquisição de conhecimento. O grau de complexidade dos requisitos envolvidos na produção de OA exige o suporte de uma equipe multidisciplinar no seu desenvolvimento, o que resulta em uma série de problemas relacionados à integração das atividades desses profissionais. Apresentamos nesse trabalho, uma abordagem orientada a modelos que fornece as abstrações necessárias para que o processo de desenvolvimento de OA possibilite a atuação efetiva dos diferentes tipos de profissionais envolvidos nesse processo, facilitando a comunicação e permitindo um melhor aproveitamento dos conhecimentos específicos de cada um.},
  keywords = {objetos de aprendizagem, engenharia de software orientada a modelos, modelo de processo},
  address = {Campinas, SP, Brasil},
  booktitle = {Workshop de Teses e Dissertações em Engenharia de Software -- Simpósio Brasileiro de Engenharia de Software},
  location = {Campinas, SP, Brazil},
  month = oct,
  owner = {magsilva},
  publisher = {SBC},
  timestamp = {2009.01.29},
  year = {2008}
}

@ARTICLE{Souza-etal:2007,
  author = {Maria de Fátima Costa de Souza and Danielo G. Gomes and Giovanni Cordeiro Barroso and Cidcley Teixeira de Souza and José Aires de Castro Filho and Mauro Cavalcante Pequeno and Rossana Andrade},
  title = {{LOCPN}: Redes de {Petri} Coloridas na Produção de Objetos de Aprendizagem},
  volume = {15},
  number = {3},
  month = sep,
  year = {2007},
  pages = {39--52},
  abstract = {Objetos de Aprendizagem (OAs) são recursos digitais desenvolvidospara serem utilizados dentro do contexto educacional como ferramenta deapoio ao processo de aquisição de conhecimento do indivíduo. Tais recursos,evidenciados no Brasil por esforços como o do RIVED (Rede Interativa Virtualde Educação), têm mostrado a importância dos OAs, e, particularmente, dassimulações e animações, como artefatos de software capazes de auxiliar aprática pedagógica. Contudo, em virtude do grau de complexidade dosrequisitos envolvidos na produção desses artefatos, há a necessidade de secontar com diferentes tipos de profissionais, que possam responder, de formacoerente, pelo caráter tanto pedagógico quanto técnico. Entretanto, essecaráter multidisciplinar afeta o processo de desenvolvimento em virtude dasimprecisões na comunicação dos diferentes tipos de requisitos entre essesprofissionais. Nesse sentido, propomos nesse trabalho, a adoção de um modeloformal, denominado LOCPN (Learning Objects production with Colored PetriNets), desenvolvido especificamente para auxiliar o processo dedesenvolvimento de OAs. A eficácia da utilização de LOCPN é comprovadaneste trabalho pela qualidade das implementações e pela reduçãosignificativa do tempo de produção de OAs.},
  keywords = {Objetos de Aprendizagem, Modelo de Processo, Redes de Petri Colorida, Especificação formal},
  url = {http://bibliotecadigital.sbc.org.br/download.php?paper=1024},
  abstract-en = {Leaning Objects (LOs) are digital resources developed to be used inthe educational setting as a tool to support one´s learning acquisition process.Such resources, made notorious in Brazil by efforts such as RIVED (VirtualInteractive Educational Network), have proved the significance of LOs, andparticularly of simulations and animations, as software artifacts able to helpthe pedagogical practice. However, due to the high degree of complexityinvolved in the production of these artifacts, different types of professionalsare needed to answer, in a coherent manner, both the pedagogical and technicalconcerns. In addition, this multidisciplinary characteristic affects thedevelopment process due to imprecision in communication among theseprofessionals about the different types of requirements. Therefore, we proposein this work the adoption of a formal model, named LOCPN (Learning Objectsproduction with Colored Petri Nets), specially developed to aid thedevelopment process of LOs. The usage efficiency of LOCPN is demonstratedin this work by the quality of implementations and the significant time reductionin the production of LOs.},
  issn = {1414-5685},
  journal = {Revista Brasileira de Informática na Educação},
  publisher = {CEIE-SBC}
}

@ARTICLE{fayad:1997,
  author = {Mohamed Fayad and Douglas C. Schmidt},
  title = {Object-Oriented Application Frameworks},
  volume = {40},
  number = {10},
  month = oct,
  year = {1997},
  pages = {32-38},
  journal = {Communications of the ACM},
  owner = {magsilva},
  timestamp = {2007.08.21}
}

@MISC{standard:atscA53,
  author = {{FCC}},
  title = {ATSC Digital Television Standard A/53},
  howpublished = {Padrão},
  year = {1996},
  timestamp = {2008.10.07}
}

@MISC{fedchak:1996,
  author = {Elaine Fedchak and Robert Vienneau},
  title = {A History of Software Measurement at Rome Laboratory},
  howpublished = {Relatório},
  month = {nov},
  year = {1996},
  owner = {magsilva},
  timestamp = {2006.08.22},
  url = {http://www.dacs.dtic.mil/techs/history/toc.html}
}

@BOOK{Feiler96EODO,
  title = {Essential {O}pen{D}oc},
  publisher = {Addison-Wesley},
  year = {1996},
  author = {J. Feiler and A. Meadow},
  address = {Reading, MA},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@INPROCEEDINGS{felicissimo:2004,
  author = {Carolina Howard Felic\'issimo and Julio Cesar Sampaio do Prado Leite and Karin Koogan Breitman},
  title = {C\&L: Um Ambiente para Edição e Visualização de Cenários e Léxicos},
  pages = {43 - 48},
  address = {Brasília, Brasil},
  booktitle = {Sessão de Ferramentas do Simpósio Brasileiro de Engenharia de Software},
  editor = {Rodrigo Quites Reis},
  month = {oct},
  organization = {Universidade de Brasília},
  owner = {Marco Aurélio Graciotto Silva},
  timestamp = {2008.07.30},
  year = {2004}
}

@INPROCEEDINGS{feltrim:1998,
  author = {V. D. Feltrim and R. P. M. Fortes},
  title = {Requisitos de Hiperdocumentos de suporte ao domínio de Engenharia Reversa de Software},
  pages = {159-167},
  address = {Maringá, PR},
  booktitle = {Workshop de Engenharia de Requisitos},
  month = oct,
  note = {in conjunction with the XII Brazilian Symposium on Software Engineering (SBES'98)},
  owner = {magsilva},
  timestamp = {2008.07.30},
  year = {1998}
}

@INPROCEEDINGS{feltrim:1999,
  author = {V. D. Feltrim and R. P. M. Fortes and W. F. Silva},
  title = {Aspectos de Validação do Método de Engenharia Reversa FusionRE/I apliado a um Sistema Hipermídia},
  pages = {257-272},
  address = {Florianópolis, SC},
  booktitle = {XIII Brazilian Symposium of Software Engineering (SBES'99)},
  month = oct,
  owner = {magsilva},
  timestamp = {2008.07.30},
  year = {1999}
}

@ARTICLE{feng07riw,
  author = {N. Feng and Y. Dong and A. Zhang and Z. Guo},
  title = {{Research on Intelligent Web-Learning Based on Multi-agents}},
  volume = {4681},
  year = {2007},
  pages = {190},
  journal = {Lecture Notes in Computer Science},
  owner = {magsilva},
  publisher = {Springer},
  timestamp = {2008.07.30}
}

@ARTICLE{Fenton:1994,
  author = {N. Fenton},
  title = {Software Measurement: A Necessary Scientific Basis},
  volume = {3},
  number = {20},
  month = mar,
  year = {1994},
  pages = {199-206},
  doi = {10.1109/32.268921},
  abstract = {Software measurement, like measurement in any other discipline, must adhere to the science of measurement if it is to gain widespread acceptance and validity. The observation of some very simple, but fundamental, principles of measurement can have an extremely beneficial effect on the subject. Measurement theory is used to highlight both weaknesses and strengths of software metrics work, including work on metrics validation. We identify a problem with the well-known Weyuker properties, but also show that a criticism of these properties is invalid. We show that the search for general software complexity measures is doomed to failure. However, the theory does help us to define and validate measures of specific complexity attributes. Above all, we are able to view software measurement in a very wide perspective, rationalising and relating its many diverse activities.},
  journal = {IEEE Transactions on Software Engineering}
}

@BOOK{Fenton-Pfleeger:1998,
  title = {Software Metrics: A Rigorous \& Practical Approach},
  publisher = {Course Technology},
  year = {1998},
  author = {Norman Fenton and Sharl Lawrence Pfleeger},
  pages = {656},
  edition = {2},
  month = feb
}

@INPROCEEDINGS{Fernandes99PAED,
  author = {C. T. Fernandes and M. R. F. Santibañez and D. M. H. Zuasnábar},
  title = {A Pre-Authoring Environment for the Development of Hypermedia Courses},
  booktitle = {ED-MEDIA'99},
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1999}
}

@INPROCEEDINGS{fernandez-etal:1997,
  author = {M. Fernández and A. Gómez-Pérez and N. Juristo},
  title = {{METHONTOLOGY}: From Ontological Art to Ontological Engineering},
  pages = {33--40},
  address = {Mellow Park, CA},
  booktitle = {Workshop on Knowledge Engineering: Spring Symposium Series (AAAI97)},
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1997}
}

@TECHREPORT{Ferrari-Maldonado:2007,
  author = {Fabiano Cutigi Ferrari and José Carlos Maldonado},
  title = {Teste de Software Orientado a Aspectos: Uma Revisão Sistemática},
  institution = {Instituto de Ciências Matemáticas e de Computação -- Universidade de São Paulo},
  month = jan,
  year = {2007},
  number = {291},
  address = {São Carlos, SP, Brazil},
  abstract = {Aspect-Oriented Programming has brought several benefits to the software development process. However, as well as other development methodologies, it has also brought new challenges to the testing activity. This paper describes details of the process and results of a systematic review performed aiming at identifying works regarding software testing techniques and criteria applied to aspect-oriented software. The results show that a variety of works have been defining testing criteria and characterising specific fault types. Moreover, we could also observe that most of these approaches lack validation. The systematic review will serve as a basis for new research related to aspect-oriented software testing, including the definition and evaluation of testing criteria, automated support tools and empirical studies.},
  keywords = {software testing, testing techniques, testing criteria, Aspect-Oriented software, systematic review},
  issn = {0103-2569},
  abstract-en = {Aspect-Oriented Programming has brought several benefits to the software development process. However, as well as other development methodologies, it has also brought new challenges to the testing activity. This paper describes details of the process and results of a systematic review performed aiming at identifying works regarding software testing techniques and criteria applied to aspect-oriented software. The results show that a variety of works have been defining testing criteria and characterising specific fault types. Moreover, we could also observe that most of these approaches lack validation. The systematic review will serve as a basis for new research related to aspect-oriented software testing, including the definition and evaluation of testing criteria, automated support tools and empirical studies.},
  abstract-pt = {A Programação Orientada a Aspectos trouxe benefícios para o desenvolvimento de sofware e, como toda nova metodologia de desenvolvimento, novos desafios para a atividade de teste. Neste relatório são apresentados detalhes da condução e dos resultados de uma revisão sistemática cujo objetivo foi identificar os trabalhos que abordam a aplicação de técnicas e critérios de teste no contexto de software Orientado a Aspectos. Os resultados mostram que diversos trabalhos têm enfatizado a definição de critérios e a caracterização de tipos de defeitos específicos a esse tipo de software. Além disso, pode-se observar que existe pouca validação dos trabalhos propostos. Os resultados servirão de base para a condução de novos trabalhos relacionados, incluindo a definição e avaliação de critérios de teste, ferramentas de apoio automatizado e estudos experimentais.},
  keywords-en = {software testing, testing techniques, testing criteria, Aspect-Oriented software, systematic review},
  keywords-pt = {teste de software, técnicas de teste, critérios de teste, software Orientado a Aspectos, Revisão sistemática},
  owner = {magsilva},
  pages = {50},
  timestamp = {2006.10.13},
  title-pt = {Teste de Software Orientado a Aspectos: Uma Revisão Sistemática}
}

@INPROCEEDINGS{Ferrari-etal:2010,
  author = {Ferrari, Fabiano Cutigi and Nakagawa, Elisa Yumi and Rashid, Awais and Maldonado, Jos{\'e} Carlos},
  title = {Automating the mutation testing of aspect-oriented Java programs},
  pages = {51--58},
  doi = {10.1145/1808266.1808274},
  abstract = {Aspect-Oriented Programming has introduced new types of software faults that may be systematically tackled with mutation testing. However, such testing approach requires adequate tooling support in order to be properly performed. This paper addresses this issue, introducing a novel tool named Proteum/AJ. Proteum/AJ realises a set of requirements for mutation-based testing tools and overcomes some limitations identified in previous tools for aspect-oriented programs. Through an example, we show how Proteum/AJ was designed to support the main steps of mutation testing. This preliminary use of the tool in a full test cycle provided evidences of the feasibility of using it in real software development processes and helped us to reason about the current functionalities and to identify future needs.},
  keywords = {aspect-oriented programming, mutation testing, test automation, testing tools},
  booktitle = {5th Workshop on Automation of Software Test},
  isbn = {978-1-60558-970-1},
  location = {Cape Town, #South Africa#},
  month = may,
  publisher = {ACM},
  year = {2010}
}

@BOOK{Ferreira:2005,
  publisher = {Axcel},
  year = {2005},
  author = {Silvio Ferreira},
  isbn = {85-7323-247-1},
  pages = {1060},
  booktitle = {Hardware: montagem, configuração \& manutenção de micros}
}

@ARTICLE{FerreiraSantos-MuchaluatSaade:2011,
  author = {Ferreira dos Santos, Joel André and Muchaluat Saade, Débora Christina},
  title = {{XTemplate} 3.0: spatio-temporal semantics and structure reuse for hypermedia compositions},
  year = {2011},
  pages = {1--29},
  doi = {10.1007/s11042-011-0732-2},
  abstract = {The use of declarative languages in digital TV systems, as well as IPTV systems, facilitates the creation of interactive applications. However, when an application becomes more complex, with many user interactions, for example, the hypermedia document that describes that application becomes bigger, having many lines of XML code. Thus, specification reuse is crucial for an efficient application development process. This paper proposes the XTemplate 3.0 language, which allows the creation of NCL hypermedia composite templates. Templates define generic structures of nodes and links to be added to a document composition, providing spatio-temporal synchronization semantics to it. The use of hypermedia composite templates aims at facilitating the authoring work, allowing the reuse of hypermedia document common specifications. Using composite templates, hypermedia documents become simpler and easier to be created. The 3.0 version of XTemplate adds new facilities to the XTemplate language, such as the possibility of specifying presentation information, the attribution of values to variables and connector parameters during template processing time and the template ability to extend other templates. As an application of XTemplate, this work extends the NCL 3.0 declarative language with XTemplate, adding semantics to NCL contexts and providing document structure reuse. In addition, this paper also presents two authoring tools: the template processor and the wizard to create NCL documents using templates. The wizard tool allows the author to choose a template included in a template base and create an NCL document using that template. The template processor transforms an NCL document using templates into a standard NCL 3.0 document according to digital TV and IPTV standards.},
  affiliation = {MídiaCom Lab, Computer Science Department, Universidade Federal Fluminense, Rua Passo da Pátria, 156 - Bloco E - Sala 408, Niterói, RJ Brazil},
  issn = {1380-7501},
  journal = {Multimedia Tools and Applications},
  keyword = {Computer Science},
  publisher = {Springer Netherlands}
}

@INPROCEEDINGS{FerreiraSantos-MuchaluatSaade:2010,
  author = {Ferreira dos Santos, Joel André and Muchaluat Saade, Débora Christina},
  title = {{XTemplate} 3.0: adding semantics to hypermedia compositions and providing document structure reuse},
  pages = {1892--1897},
  doi = {10.1145/1774088.1774490},
  abstract = {Hypermedia composite templates define generic structures of nodes and links that can be reused in different document compositions. The XTemplate language is an XML-based solution for defining composite templates for hypermedia documents in order to embed semantics into a composition that does not have it in prior. The use of templates intend to facilitate the authoring of interactive applications in Digital TV systems, as long as IPTV systems. XTemplate 3.0 extends the previous XTemplate versions, incorporating new features to the language and increasing its expressiveness. As an application of XTemplate, this work extends NCL (Nested Context Language) with XTemplate, adding semantics to NCL contexts and providing document structure reuse.},
  keywords = {NCL, XTemplate, composite templates, composition semantics, interactive TV, reuse},
  series = {SAC},
  booktitle = {Symposium on Applied Computing},
  isbn = {978-1-60558-639-7},
  location = {Sierre, Switzerland},
  publisher = {ACM},
  year = {2010}
}

@INPROCEEDINGS{Feuvre-etal:2011,
  author = {Feuvre, Jean Le and Concolato, Cyril and Dufourd, Jean-Claude and Bouqueau, Romain and Moissinac, Jean-Claude},
  title = {Experimenting with multimedia advances using GPAC},
  pages = {715--718},
  doi = {10.1145/2072298.2072427},
  abstract = {Multimedia applications are challenging software and require collaboration of very different components such as networking, rendering, or scripting to provide a nice user experience. GPAC is an open source multimedia framework that implements a vast number of components and helps experimenting with different types of multimedia applications. It provides a multimedia packager, some servers and a player for dynamic and interactive multimedia content. In this paper, we present the recent additions to the project which allow experimenting with new applications such as dynamic home networking or rich broadcasting of interactive content on the latest devices, including with 3D displays. Such experiments can be useful in research work and, as illustrated, in academic environment for educational purposes.},
  keywords = {BIFS, MPEG, SVG, Web3D, broadcasting, home networking, interactivity, multimedia, stereoscopy, streaming},
  series = {MM },
  address = {New York, NY, USA},
  booktitle = {19th ACM International Conference on Multimedia},
  isbn = {978-1-4503-0616-4},
  location = {Scottsdale, Arizona, #USA#},
  publisher = {ACM},
  year = {2011}
}

@INPROCEEDINGS{Feuvre-etal:2007,
  author = {Feuvre, Jean Le and Concolato, Cyril and Moissinac, Jean-Claude},
  title = {GPAC: open source multimedia framework},
  pages = {1009--1012},
  doi = {10.1145/1291233.1291452},
  abstract = {GPAC is a multimedia framework for research and academic purposes in different aspects of multimedia, with a focus on presentation technologies (graphics, animation and interactivity). The project started in 2003 with the initial goal to develop from scratch, in ANSI C, clean software compliant to the MPEG-4 Systems standard, a small and flexible alternative to the MPEG-4 reference software. Since then, the project has evolved into an advanced multimedia player, a multimedia packager and several servers. The project is intended to a wide audience ranging from end-users or content creators with development skills who want to experiment the new standards for interactive technologies or want to convert files for mobile devices, to developers who need players and/or server for multimedia streaming applications.},
  keywords = {MPEG-4, Multimedia, SVG, VRML, X3D, broadcasting, interactivity, streaming},
  series = {MULTIMEDIA},
  address = {New York, NY, USA},
  booktitle = {15th International Conference on Multimedia},
  isbn = {978-1-59593-702-5},
  lang = {en},
  location = {Augsburg, #Germany#},
  publisher = {ACM},
  year = {2007}
}

@MISC{jaxb:2003,
  author = {Joseph Fialli and Sekhar Vajjhala},
  title = {Java Architecture for XML Binding (JAXB) Specification 1.0},
  howpublished = {Specification},
  month = {jan},
  year = {2003},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://www.jcp.org/en/jsr/detail?id=31}
}

@INPROCEEDINGS{fickas-etal:1991,
  author = {S. Fickas and A. van Lamsweerde and A. Dardenne},
  title = {Goal-directed concept Acquisition in Requirements Elicitation},
  pages = {14-21},
  address = {Como, Italy},
  booktitle = {International Workshop on Software Specification and Design},
  owner = {magsilva},
  timestamp = {2008.07.30},
  year = {1991}
}

@MISC{http:1999,
  author = {R. Fielding and J. Gettys and J. Mogul and H. Frystyk and L. Masinter and P. Leach and Timothy J. Berners-Lee},
  title = {Hypertext Transfer Protocol -- HTTP/1.1},
  howpublished = {Request for Comments},
  month = jun,
  year = {1999},
  file = {Hypertext Transfer Protocol - HTTP 1.1.pdf:Hypertext Transfer Protocol - HTTP 1.1.pdf:PDF},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@INPROCEEDINGS{Figueiredo-etal:2007,
  author = {Eduardo Magno Lages Figueiredo and Cidiane Aracaty Lobato and Klessis Lopes Dias and Julio Cesar Sampaio do Prado Leite and Carlos José Pereira de Lucena},
  title = {Um Jogo para o Ensino de Engenharia de Software Centrado na Perspectiva de Evolução},
  pages = {37-46},
  address = {Rio de Janeiro},
  booktitle = {XV Workshop sobre Educação em Computação (WEI)},
  month = jul,
  owner = {magsilva},
  timestamp = {2008.07.24},
  year = {2007}
}

@TECHREPORT{figueiredo-etal:2006,
  author = {Eduardo Magno Lages Figueiredo and Cidiane Aracaty Lobato and Klessis Lopes Dias and Julio Cesar Sampaio do Prado Leite and Carlos José Pereira de Lucena},
  title = {SimulES: Um Jogo para o Ensino de Engenharia de Software},
  institution = {Pontifícia Universidade Católica do Rio de Janeiro},
  month = oct,
  year = {2006},
  number = {MCC 34/06},
  owner = {magsilva},
  timestamp = {2008.07.24}
}

@MISC{fhs:2003,
  author = {{Filesystem Hierarchy Standard Group}},
  title = {Filesystem Hierarchy Standard},
  month = jan,
  year = {2003},
  owner = {magsilva},
  timestamp = {2007.12.11},
  url = {http://www.pathname.com/fhs/}
}

@INPROCEEDINGS{Fincher-Utting:2002,
  author = {Fincher, Sally and Utting, Ian},
  title = {Pedagogical patterns: their place in the genre},
  pages = {199--202},
  doi = {10.1145/544414.544482},
  abstract = {This paper describes some constituents of patterns and pattern languages and examines the Pedagogical Patterns endeavour against them. Some observations are made with regard to how pattern languages are developed and some suggestions as to how these might be applied to pedagogical patterns are made.},
  keywords = {pattern languages},
  series = {ITiCSE},
  address = {New York, NY, USA},
  booktitle = {7th Annual Conference on Innovation and Technology in Computer Science Education},
  isbn = {1-58113-499-1},
  lang = {en},
  location = {Aarhus, #Denmark#},
  month = jun,
  publisher = {ACM},
  year = {2002}
}

@INPROCEEDINGS{Finkelstein-etal:1990,
  author = {A. Finkelstein and J. Kramer and J. K. Goedicke},
  title = {Viewpoints Oriented Software Specification},
  pages = {337-351},
  address = {Toulouse, France},
  booktitle = {3rd International Workshop on Software Engineering and its Applications},
  organization = {IEEE Computer Society},
  owner = {magsilva},
  timestamp = {2008.07.30},
  year = {1990}
}

@ARTICLE{Finkelstein-Sommerville:1996,
  author = {Anthony Finkelstein and Ian Sommerville},
  title = {The Viewpoints {FAQ}},
  volume = {11},
  number = {1},
  year = {1996},
  pages = {2--4},
  journal = {Software Engineering Journal: Special Issue on Viewpoints for Software Engineering},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@ARTICLE{finkelstein:1984,
  author = {L. Finkelstein},
  title = {A review of the fundamental concepts of measurement},
  volume = {2},
  number = {1},
  month = jan,
  year = {1984},
  pages = {25-34},
  doi = {10.1016/0263-2241(84)90020-4},
  journal = {Measurement},
  owner = {magsilva},
  timestamp = {2010.08.25}
}

@MISC{fitzpatrick:2005,
  author = {Brad Fitzpatrick},
  title = {OpenID support},
  howpublished = {Anúncio público},
  month = jun,
  year = {2005},
  owner = {msilva},
  timestamp = {2007.06.01},
  url = {http://news.livejournal.com/86532.html?mode=reply}
}

@INPROCEEDINGS{Florez-etal:2004,
  author = {Flórez, Julián and García, Igor and Aizpurua, Iker and Paloc, Céline and Ugarte, Alejandro and Jainaga, Igor and Colet, Jesús and Zubiaur, Xabier},
  title = {{SEITV} -- Interactive Multimedia Leisure/Educational Services for Digital {TV} in {MHP}},
  pages = {109--119},
  doi = {10.1007/978-3-540-28643-1_32},
  abstract = {Interactive TV is expected to revolutionize the TV market, providing a host of new services to the consumer homes. While being theoretically a promising technology, the design and implementation of interactive TV platforms are bringing new challenges to the IT society, due to the fundamental differences between TV sets and PCs environments. The SEITV project is presented in this paper, where a set of design considerations for interactive digital TV have been analyzed and applied to the creation of interactive services for entertainment and education.},
  volume = {3166},
  series = {Lecture Notes in Computer Science},
  address = {Cambridge, Reino Unido},
  booktitle = {Third International Conference on Entertainment Computing},
  editor = {Rauterberg, Matthias},
  isbn = {978-3-540-22947-6},
  location = {Cambridge, Reino Unido},
  publisher = {Springer},
  year = {2004}
}

@INPROCEEDINGS{Floyd:1967,
  author = {R. W. Floyd},
  title = {Assigning meaning to programs},
  pages = {19--32},
  volume = {19},
  booktitle = {Symposium in Applied Mathematics},
  editor = {J. T. Schwartz},
  location = {New York, NY, #USA#},
  month = apr,
  publisher = {American Mathematical Society},
  year = {1967}
}

@INPROCEEDINGS{folstad-etal:2010,
  author = {Folstad, Asbjorn and Law, Effie Lai-Chong and Hornb\aek, Kasper},
  title = {Analysis in usability evaluations: an exploratory study},
  pages = {647--650},
  doi = {10.1145/1868914.1868995},
  abstract = {While the planning and implementation of usability evaluations are well described in the literature, the analysis of the evaluation data is not. We present interviews with 11 usability professionals on how they conduct analysis, describing the resources, collaboration, creation of recommendations, and prioritization involved. The interviews indicate a lack of structure in the analysis process and suggest activities, such as generating recommendations, that are unsupported by existing methods. We discuss how to better support analysis, and propose four themes for future research on analysis in usability evaluations.},
  keywords = {analysis, interview, thinking aloud, usability evaluation, usability inspection, usability professionals},
  address = {New York, NY, USA},
  booktitle = {6th Nordic Conference on Human-Computer Interaction: Extending Boundaries},
  isbn = {978-1-60558-934-3},
  location = {Reykjavik, Iceland},
  publisher = {ACM},
  year = {2010}
}

@MASTERSTHESIS{Fonseca93STEP,
  author = {R. P. Fonseca},
  title = {Suporte ao Teste Estrutural de Programas FORTRAN no Ambiente POKE-TOOL},
  school = {DCA/FEE/UNICAMP},
  year = {1993},
  address = {Campinas, SP},
  month = jan,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@BOOK{Forbellone-Eberspacher:2005,
  publisher = {Pearson},
  year = {2005},
  author = {André Luiz Villar Forbellone and Henri Frederico Eberspächer},
  isbn = {978-85-7605-024-7},
  pages = {218},
  address = {São Paulo, SP, } # Brazil,
  edition = {3},
  booktitle = {Lógica de programação: a construção de algoritmos e estruturas de dados}
}

@ARTICLE{Ford-etal:1991,
  author = {Kenneth Ford and Alberto Canas and Jeremy Jones and Howard Stahl and Joseph Novak and Jack Adams-Webber},
  title = {{ICONKAT}: an integrated constructivist knowledge acquisition tool},
  volume = {3},
  number = {2},
  month = jun,
  year = {1991},
  pages = {215 - 236},
  doi = {10.1016/1042-8143(91)90005-8},
  abstract = {In this paper, we report on a continuing research effort aimed at the development of an integrated knowledge acquisition system, ICONKAT. We describe the components of the tool and discuss how they may be used to facilitate the design, construction, testing, maintenance and explanation of knowledge bases. ICONKAT's knowledge elicitation subsystem, based on both personal construct theory and assimilation theory, interactively assists the domain expert in the task of building a model of his or her expertise. ICONKAT employs a collection of modeling primitives (i.e. the glue) as the material basis for the construction of a conceptual domain model. The maintenance subsystem provides support tools for use by the knowledge engineering team, as well as the domain expert, when testing the system's performance, refining the knowledge base, and maintaining the overall system. The components of the maintenance subsystem employ a variety of mediating representations (e.g. concept maps, repertory grids) to furnish various perspectives of the evolving domain model as embodied in the modeling primitives. Moreover, the domain model that emerges from the knowledge acquisition process is subsequently exported from the development environment to the delivery environment where it serves as the foundation of the explanation capability for the deployed system. ICONKAT is currently employed in the design and construction of an expert system for the diagnosis of first pass functional cardiac images.},
  issn = {1042-8143},
  journal = {Knowledge Acquisition}
}

@ARTICLE{Forte-etal:1997,
  author = {Eddy N. Forte and Maria H. K. Wentland Forte and Erik Duval},
  title = {The ARIADNE Project (Part 1): Knowledge Pools for Computer-based and Telematics-supported Classical, Open and Distance Education},
  volume = {22},
  number = {1},
  year = {1997},
  pages = {61-74},
  doi = {10.1080/03043799708923438},
  abstract = {ARIADNE is a concept of computer-based and telematics-supported educational schemes. It relies primarily on a number of interconnected knowledge pools and suitable strategies for using them, in academic education -- either classical or at a distance -- and for certain types of corporate continuing training. In ARIADNE, the term 'knowledge pool' refers to a large, indexed, storage of pedagogical elements and the set of tools, methodologies and infrastructures necessary for maintaining and exploiting it, to build and distribute structured curricula. This concept is meant to address the weaknesses of many 'open' training schemes advocating the usefulness of unlimited and free access to the World Wide Web (WWW). In our view, this immense -- but scarcely structured -- document repository can all too easily become a maze and offers, in itself, little incentive to serious learning. On the other hand, ARIADNE will use a WWW based net-interface, suitable for -- and inter-operable with -- most platforms commonly in use by would-be learners. ARIADNE addresses two categories of users: those who contribute to the knowledge pool system and develop training curricula (professors and pedagogical engineers) and those who may enlist in and follow these curricula (students and trainees). The system's design accounts for the need for collaboration and communication between (a) trainers, to create, customize, share and reuse pedagogical documents; (b) trainers and learners, for coaching/tutoring activities and supervision of learning; and (c) students/trainees, in peer-supported learning or group work. Long-term survival of any such technology-supported education system depends primarily on motivated participants: teachers and trainers, students and trainees, academic institutions and corporations should all find some practical advantage in its use. In this paper (Part 1), we present an overview of the ARIADNE concept, describing its pragmatic educational approach and its specific approach to authoring of pedagogical material and construction of usable curricula. In a forthcoming paper (Part 2), we will address its technological approach and present a brief review of the tools needed to implement the concept as a viable computer-based and telematics-supported distance -- but also open or even classical -- educational system.},
  issn = {0304-3797, 1469-5898},
  journal = {European Journal of Engineering Education}
}

@INPROCEEDINGS{fortes:2002,
  author = {R. P. M. Fortes and E. A. Silva and D. B. Paiva},
  title = {Utilizando a Norma ISO/IEC 14598-5 na Avaliação de Qualidade de Hiperdocumentos Web},
  pages = {128-142},
  address = {Gramado, RS},
  booktitle = {I Simpósio Brasileiro de Qualidade de Software},
  month = oct,
  note = {in conjunction with the XVI Brazilian Symposium on Software Engineering (SBES'2002)},
  owner = {magsilva},
  timestamp = {2008.07.30},
  year = {2002}
}

@MISC{software:tomahawk,
  author = {Apache Foundation},
  title = {Tomahawk},
  howpublished = {Programa de computador},
  year = {2004},
  owner = {magsilva},
  timestamp = {2007.10.07},
  url = {http://myfaces.apache.org/tomahawk}
}

@MISC{software:myfaces,
  author = {Apache Foundation},
  title = {MyFaces},
  howpublished = {Programa de computador},
  year = {2003},
  owner = {magsilva},
  timestamp = {2007.10.07},
  url = {http://myfaces.apache.org/index.html}
}

@MISC{software:commons-dbcp,
  author = {Apache Foundation},
  title = {Jakarta-Commons Database Connection Pool},
  howpublished = {Programa de computador},
  month = ago,
  year = {2002},
  owner = {magsilva},
  timestamp = {2008.03.06},
  url = {http://commons.apache.org/dbcp/}
}

@MISC{software:tobago,
  author = {Apache Foundation},
  title = {Tobago},
  howpublished = {Programa de computador},
  year = {2002},
  owner = {magsilva},
  timestamp = {2007.10.07},
  url = {http://myfaces.apache.org/tobago/index.html}
}

@MISC{software:trinidad,
  author = {Apache Foundation},
  title = {Trinidad},
  howpublished = {Programa de computador},
  year = {2001},
  owner = {magsilva},
  timestamp = {2007.10.07},
  url = {http://myfaces.apache.org/trinidad/}
}

@MISC{openid:1.0,
  author = {OpenID Foundation},
  title = {OpenID 1.0},
  howpublished = {Especificação de organização de juri},
  owner = {msilva},
  timestamp = {2007.06.01},
  url = {http://openid.net/specs/specs-1.0.bml}
}

@MISC{openid:1.1,
  author = {OpenID Foundation},
  title = {OpenID 1.1},
  howpublished = {Especificação},
  owner = {msilva},
  timestamp = {2007.06.01},
  url = {http://openid.net/specs/specs-1.1.bml}
}

@MISC{openid:2.0,
  author = {OpenID Foundation},
  title = {OpenID 2.0},
  howpublished = {Especificação},
  owner = {msilva},
  timestamp = {2007.06.01},
  url = {http://openid.net/specs/openid-authentication-2_0-11.html}
}

@ARTICLE{FournierViger-etal:2006,
  author = {Philippe Fournier-Viger and Mehdi Najjar and André Mayers and Roger Nkambou},
  title = {A Cognitive and Logic Based Model for Building Glass-Box Learning Objects},
  volume = {2},
  year = {2006},
  pages = {77-94},
  abstract = {In the field of e-learning, a popular solution to make teaching material reusable is to represent it as learning object (LO). However, building better adaptive educational software also takes an explicit model of the learner's cognitive process related to LOs. This paper presents a three layers model that explicitly connect the description of learners' cognitive processes to LOs. The first layer describes the knowledge from a logical and ontological perspective. The second describes cognitive processes. The third builds LOs upon the two first layers. The proposed model has been successfully implemented in an intelligent tutoring system for teaching Boolean reduction that provides highly tailored instruction thanks to the model.},
  keywords = {learning objects, cognitive modelling, tutoring systems, description logics},
  journal = {Interdisciplinary Journal of Knowledge and Learning Objects},
  owner = {magsilva},
  timestamp = {2008.09.26}
}

@INPROCEEDINGS{Fowler-etal:2000,
  author = {Lynne Fowler and Maurice Allen and Jocelyn Armarego and Judith Mackenzie},
  title = {Learning styles and {CASE} tools in {S}oftware {E}ngineering},
  abstract = {Software Engineering is a new discipline aimed at the improvement of the production of large, quality software systems. Interest in the adoption of CASE tools has escalated because of the important role they play in supporting the software development process. However, these automated tools are sophisticated and complex. While studies show that CASE tools have a positive impact on quality and productivity, it is also shown that they have been slow to be adopted by industry. This phenomenon is partially explained by the effort in learning to use the tool. Ultimately, knowing the factors that favourably influence the rate of learning will lead to improved approaches to teaching software packages, particularly CASE tools and hence the uptake of these tools within industry. The correlation between learning styles and our methods of teaching CASE tools must be established to investigate where conflicts exist. This paper discusses an initial study examining the learning styles of engineering students, based on the work of both Kolb and Soloman. This will then be used as a foundation for comparison between student learning styles and use of our CASE tool, Rational Rose. Monitoring online use will be achieved by automated tracing of student navigation within the package. Our results will be used as a basis to develop an online learning methodology whereby learner characteristics can be used to establish the environment to support the construction of knowledge in our students.},
  booktitle = {Annual Teaching Learning Forum},
  editor = {A. Hermann and M. M. Kulski},
  month = feb,
  owner = {magsilva},
  timestamp = {2010.12.09},
  url = {http://otl.curtin.edu.au/tlf/tlf2000/fowler.html},
  year = {2000}
}

@BOOK{fowler:2002,
  title = {Patterns of Enterprise Application Architecture},
  publisher = {Addison-Wesley Professional},
  year = {2002},
  author = {Martin Fowler},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@BOOK{Fowler:2000,
  title = {{UML} distilled: a brief guide to the standard object modeling language},
  publisher = {Addison Wesley Longman},
  year = {2000},
  author = {Martin Fowler},
  series = {Object Technology},
  edition = {2},
  month = jan,
  booktitle = {{UML} distilled: a brief guide to the standard object modeling language},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@BOOK{fowler:1997,
  title = {UML Distilled: Applying the Standard Object Modeling Language},
  publisher = {Addison Wesley},
  year = {1997},
  author = {M. Fowler and K. Scott},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@MISC{francisco:2002,
  author = {Simone Domingues Francisco},
  title = {Uma Ferramenta para Suporte a Design Rationale em Documentos de Engenharia de Software},
  howpublished = {Monografia de Qualificação de Mestrado},
  month = {may},
  year = {2002},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@INPROCEEDINGS{francisco-etal:2003,
  author = {Simone D. Francisco and Claudia A. Izeki and Débora M. B. Paiva and Renata P. M. Fortes},
  title = {{DocRationale}: Um Auxílio a Design Rationale na Documentacão de Software},
  pages = {61-66},
  address = {Manaus, Brasil},
  booktitle = {Sessão de Ferramentas do XVII Simpósio Brasileiro de Engenharia de Software},
  month = oct,
  owner = {magsilva},
  timestamp = {2008.07.30},
  year = {2003}
}

@INPROCEEDINGS{Franco-Oliveira:2007,
  author = {Franco, Barbara Bernadini de and Oliveira, Hilda Carvalho de},
  title = {Adaptação de sistemas de e-Learning baseados na Web para {TV} Digital Interativa no {B}rasil: Estudos de Viabilidade},
  pages = {1--8},
  abstract = {O principal objetivo deste artigo é apresentar considerações sobre a viabilidade de se reutilizar sistemas de e-Learning já desenvolvidos para a Web no ambiente da TV Digital interativa, segundo o padrão adotado no Brasil. Considerando a popularidade dos sistemas de ensino à distância Moodle no meio acadêmico, tais sistemas serviram de apoio ao levantamento de propriedades para a especificação de uma Interface de Programação de Aplicativos (API) para convergência ao ambiente de t-Learning.},
  abstract-en = {The aim of this paper is to present factors on the viability on reusing e-Learning systems already developed for Web for interactive digital TV environment according to standard adopted in Brazil. Considering the popularity of long-distance education system Moodle in the academic environment, such system supported a survey for the specification properties of an Application Programming Interface (API) for convergence to of t-Learning environment.},
  address = {Poços de Caldas, MG, Brasil},
  booktitle = {V Fórum de Oportunidades em Televisão Digital Interativa},
  location = {Poços de Caldas, MG, Brasil},
  year = {2007}
}

@ARTICLE{halasz:1988,
  author = {Frank,G. Halasz},
  title = {Reflections on NoteCards: seven issues for the next generation of hypermedia systems},
  volume = {31},
  number = {7},
  year = {1988},
  pages = {836 - 852},
  doi = {10.1145/48511.48514},
  journal = {Communications of the ACM},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@PHDTHESIS{Frankl87UDFI,
  author = {F. G. Frankl},
  title = {The Use of Data Flow Information for the Selection and Evaluation of Software Test Data},
  school = {University of New York},
  year = {1987},
  address = {NY},
  month = oct,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{Frankl85DFTT,
  author = {F. G. Frankl and E. J. Weyuker},
  title = {Data Flow Testing Tools},
  pages = {46--53},
  address = {San Francisco, CA},
  booktitle = {Softfair II},
  month = dec,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1985}
}

@ARTICLE{Frankl00TSDR,
  author = {Phillys G. Frankl and Elaine J. Weyuker},
  title = {Testing Software to Detect and Reduce Risk},
  year = {2000},
  journal = jss,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@ARTICLE{Frankl95RSCR,
  author = {Phillys G. Frankl and Elaine J. Weyuker},
  title = {Reply to Some Critical Remarks on a Hierarchy of Fault-Detecting Abilities of Test Methods},
  volume = {SE-21},
  number = {10},
  month = oct,
  year = {1995},
  pages = {861--863},
  journal = ieeese,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{Frankl93ACFD,
  author = {P. G. Frankl and E. J. Weyuker},
  title = {An Analytical Comparison of the Fault-Detecting Ability of Data Flow Testing Techniques},
  pages = {415--424},
  booktitle = {XV International Conference on Software Engineering},
  month = may,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1993}
}

@ARTICLE{Frankl93FAFD,
  author = {P. G. Frankl and E. J. Weyuker},
  title = {A Formal Analysis of the Fault-Detecting Ability of Testing Methods},
  volume = {19},
  number = {3},
  month = mar,
  year = {1993},
  pages = {202--213},
  journal = ieeese,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@ARTICLE{Frankl93PIBT,
  author = {P. G. Frankl and E. J. Weyuker},
  title = {Provable Improvements on Branch Testing},
  volume = {19},
  number = {10},
  month = oct,
  year = {1993},
  pages = {962--975},
  journal = {IEEE Transactions on Software Engineering},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@MISC{rdfprimer:2004,
  author = {Frank Manola, Eric Miller, Brian McBride},
  title = {RDF Primer},
  howpublished = {W3C Recommendation},
  month = feb,
  year = {2004},
  comment = {24/05/2005},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://www.w3.org/TR/rdf-primer/}
}

@TECHREPORT{Frate95EICB,
  author = {F. D. Frate and P. Garg and A. P. Mathur and A. Pasquini},
  title = {Experiments to Investigate the Correlation Between Code Coverage and Software Reliability},
  institution = {Software Engineering Research Center, Purdue University},
  month = apr,
  year = {1995},
  number = {SERC-TR162-P},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@MISC{software:eudibamus,
  author = {{Frauhofer Institute}},
  title = {Eudibamus},
  howpublished = {Programa de Computador},
  year = {2003},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://www.first.fraunhofer.de/eudibamus}
}

@MISC{project:kogito,
  author = {{Fraunhofer FIRST} and {FUJITSU Enabling Software Technology GmbH} and {IT Service Omikron GmbH} and {Softlab GmbH} and {Technische Universität München}},
  title = {KOGITO - Knowledge Based Requirements Engineering in Software Development},
  howpublished = {Projeto},
  year = {2003},
  note = {Patrocinado pelo Federal Ministry of Education and Research da Alemanha (código do patrocínio: 01ISB01)},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://www.kogito.org}
}

@INPROCEEDINGS{brooks:1986,
  author = {Frederick P. Brooks, Jr.},
  title = {No Silver Bullet --- Essence and Accidents of Software Engineering},
  pages = {1069-1076},
  address = {Dublin, Irlanda},
  booktitle = {International Federation of Information Processing (IFIP) Congress '86},
  month = sep,
  owner = {magsilva},
  timestamp = {2008.07.30},
  year = {1986}
}

@ARTICLE{Freedman91TSCO,
  author = {R. S. Freedman},
  title = {Testability of Software Components},
  volume = {17},
  number = {6},
  month = jun,
  year = {1991},
  pages = {553--564},
  journal = ieeese,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@MISC{license:gpl,
  author = {{Free Software Foundation}},
  title = {{GNU General Public License}},
  year = {2007},
  note = {http://www.gnu.org/copyleft/gpl.html [17/12/2007]},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@MISC{software:tar,
  author = {{Free Software Foundation}},
  title = {tar},
  howpublished = {Programa de computador},
  year = {1992},
  owner = {msilva},
  timestamp = {2006.02.23},
  url = {http://www.gnu.org/software/tar/}
}

@MISC{Freire-Donegan:2006,
  author = {André Pimenta Freire and Paula Marques Donegan},
  title = {Uma Visão Geral da Norma {ISO/IEC} 12207},
  howpublished = class # assignment,
  year = {2006},
  abstract = {Organizacoes têm direcionado cada vez mais seus esforcos para o desenvolvimento de software com qualidade. A grande diversidade de processos elaborados pelas organizações, de forma independente, dificulta a padronização e a assimilação de lições adquiridas com experiência acumulada pelas organizações. A ISO/IEC criou a norma 12207 com o objetivo de estabelecer um framework uniforme para auxiliar a definição de processos de ciclo de vida de software. Neste artigo, são apresentadas as principais características da norma, as classes de processos, e relações entre ela e outras normas interligadas, como a ISO 9001, a ISO/IEC 15504 e a IEEE/EIA 12207. A partir dos estudos realizados, nota-se que a ISO/IEC 12207 possui grande importância para a fundamentação, apoio e organização de processos de ciclo de vida, servindo como ponto de referência para o estudo e a definição de processos no contexto de Engenharia de Software.}
}

@BOOK{Freire:1996,
  title = {Pedagogia da autonomia: saberes necessárias à prática educativa},
  publisher = {Paz e Terra},
  year = {1996},
  author = {Paulo Reglus Neves Freire},
  isbn = {978-85-7753-015-1},
  pages = {148},
  series = {Coleção Leitura},
  address = {São Paulo, SP, } # Brazil,
  edition = {39},
  booktitle = {Pedagogia da autonomia: saberes necessárias à prática educativa}
}

@BOOK{Freire-Guimaraes:2003,
  title = {Sobre Educação (Diálogos)},
  publisher = {Paz e Terra},
  year = {2003},
  author = {Paulo Reglus Neves Freire and Sérgio Guimar{\~a}es},
  isbn = {85-219-0682-X},
  volume = {2},
  pages = {196},
  address = {São Paulo, SP, Brazil},
  edition = {3},
  booktitle = {Sobre Educação (Diálogos)}
}

@INPROCEEDINGS{Freitas02AAWC,
  author = {V. Freitas and V. Marçal and I. Gasparini and M. A. Amaral and M. L. Proença Jr. and M. A. C. Brunetto and M. S. Pimenta and C. H. F. P. Ribeiro and J. V. Lima and J. P. M. Oliveira},
  title = {{AdaptWeb}: an Adaptive Web-based Courseware},
  address = {Badajoz, Spain},
  booktitle = {International Conference on Information and Communication Technologies in Education (ICTE 2002)},
  month = nov,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {2002}
}

@BOOK{friedman:1975,
  title = {Logical Design of Digital Systems},
  publisher = {W. H. Freeman \& Co},
  year = {1975},
  author = {Arthur D. Friedman},
  pages = {278},
  address = New # York # {, } # USA,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@ARTICLE{Fujiwara91TSBF,
  author = {S. Fujiwara and G. V. Bochmann and F. Khendek and M. Amalou and A. Ghedamsi},
  title = {Test Selection Based on Finite State Models},
  volume = {17},
  number = {6},
  month = jun,
  year = {1991},
  journal = ieeese,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@ARTICLE{Fuks00ATCA,
  author = {H. Fuks},
  title = {Aprendizagem e Trabalho Cooperativo no Ambiente {AulaNet}},
  volume = {1},
  number = {6},
  year = {2000},
  pages = {53--73},
  journal = {Revista Brasileira de Informática na Educação},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@MISC{lisandra:2003,
  author = {Lisandra Cazassa Fumagalli},
  title = {Investigação sobre Recuperação de Design Rationale de Documentos de Software},
  howpublished = {Monografia de Qualificação de Mestrado},
  month = mar,
  year = {2003},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@MISC{project:telecurso,
  author = {{Fundação Roberto Marinho} and {FIESP}},
  title = {Telecurso 2000},
  howpublished = {Sistema de educação brasileiro por televisão},
  year = {1994},
  timestamp = {2008.09.12}
}

@BOOK{Fuoco:2002,
  title = {Guia valor econômico de comércio eletrônico},
  publisher = {Globo},
  year = {2002},
  author = {Taís Fuoco},
  isbn = {85-250-3627-7},
  pages = {123},
  address = {São Paulo, SP, } # Brazil,
  edition = {1},
  keywords = {comércio eletrônico; Internet}
}

@ARTICLE{Dror-Feitelson:2012,
  author = {Dror G. and Feitelson},
  title = {Perpetual development: A model of the Linux kernel life cycle},
  volume = {85},
  number = {4},
  month = apr,
  year = {2012},
  pages = {859 - 875},
  doi = {10.1016/j.jss.2011.10.050},
  abstract = {Software evolution is widely recognized as an important and common phenomenon, whereby the system follows an ever-extending development trajectory with intermittent releases. Nevertheless there have been only few lifecycle models that attempt to portray such evolution. We use the evolution of the Linux kernel as the basis for the formulation of such a model, integrating the progress in time with growth of the codebase, and differentiating between development of new functionality and maintenance of production versions. A unique element of the model is the sequence of activities involved in releasing new production versions, and how this has changed with the growth of Linux. In particular, the release follow-up phase before the forking of a new development version, which was prominent in early releases of production versions, has been eliminated in favor of a concurrent merge window in the release of 2.6.x versions. We also show that a piecewise linear model with increasing slopes provides the best description of the growth of Linux. The perpetual development model is used as a framework in which commonly recognized benefits of incremental and evolutionary development may be demonstrated, and to comment on issues such as architecture, conservation of familiarity, and failed projects. We suggest that this model and variants thereof may apply to many other projects in addition to Linux.},
  keywords = {Software evolution; software release; maintenance; Linux kernel},
  url = {http://www.sciencedirect.com/science/article/pii/S0164121211002822},
  issn = {0164-1212},
  journal = {Journal of Systems and Software}
}

@ARTICLE{Gonenc70MDFD,
  author = {G. G\"{o}nen\c{c}},
  title = {A Method for Design of Fault-Detection Experiments},
  volume = {19},
  number = {6},
  month = jun,
  year = {1970},
  pages = {551--558},
  journal = {IEEE Transactions on Computers},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@ARTICLE{Gaeta-etal:2009,
  author = {M. Gaeta and F. Orciuoli and P. Ritrovato},
  title = {Advanced ontology management system for personalised e-Learning},
  volume = {22},
  number = {4},
  month = may,
  year = {2009},
  pages = {292 - 301},
  doi = {10.1016/j.knosys.2009.01.006},
  abstract = {The use of ontologies to model the knowledge of specific domains represents a key aspect for the integration of information coming from different sources, for supporting collaboration within virtual communities, for improving information retrieval, and more generally, it is important for reasoning on available knowledge. In the e-Learning field, ontologies can be used to model educational domains and to build, organize and update specific learning resources (i.e. learning objects, learner profiles, learning paths, etc.). One of the main problems of educational domains modeling is the lacking of expertise in the knowledge engineering field by the e-Learning actors. This paper presents an integrated approach to manage the life-cycle of ontologies, used to define personalised e-Learning experiences supporting blended learning activities, without any specific expertise in knowledge engineering.},
  keywords = {Knowledge representation, Knowledge modeling, Knowledge maintenance, Knowledge reuse, Distance learning},
  url = {http://www.sciencedirect.com/science/article/B6V0P-4VGPS8Y-4/2/4ec83c66535a608f5741d2dd724c0d1f},
  issn = {0950-7051},
  journal = {Knowledge-Based Systems},
  note = {Artificial Intelligence (AI) in Blended Learning - (AI) in Blended Learning}
}

@BOOK{gagne:1985,
  title = {The Conditions of Learning and the Theory of Instruction},
  publisher = {Holt, Rinehart, and Winston},
  year = {1985},
  author = {Robert Mills Gagné},
  address = {New York},
  edition = {4th},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@MISC{software:gzip,
  author = {Jean-loup Gailly and Mark Adler},
  title = {gzip},
  howpublished = {Programa de computador},
  year = {1992},
  owner = {msilva},
  timestamp = {2006.02.23},
  url = {http://www.gzip.org/}
}

@ARTICLE{Gaines-Shaw:1995,
  author = {B. R. Gaines and M. L. G. Shaw},
  title = {Concept Maps as Hypermedia Components},
  volume = {43},
  number = {3},
  month = sep,
  year = {1995},
  pages = {323--361},
  doi = {10.1006/ijhc.1995.1049},
  abstract = {Concept mapping has a history of use in many disciplines as a formal or semi-formal diagramming technique. Concept maps have an abstract structure as typed hypergraphs, and computer support for concept mapping can associate visual attributes with node types to provide an attractive and consistent appearance. Computer support can also provide interactive interfaces allowing arbitrary actions to be associated with nodes such as hypermedia links to other maps and documents. This article describes a general concept mapping system that is open architecture for integration with other systems, scriptable to support arbitrary interactions and computations, and cutomizable to emulate many styles of map. The system supports collaborative development of concept maps across local area and wide area networks, and integrates with World-Wide Web in both client helper and server gateway roles. A number of applications are illustrated ranging through education, artificial intelligence, active documents, hypermedia indexing and concurrent engineering. It is proposed that concept maps be regarded as basic components of any hypermedia system, complementing text and images with formal and semi-formal active diagrams.},
  address = {Duluth, MN, } # USA,
  issn = {1071-5819},
  journal = {International Journal of Human-Computer Studies},
  lang = {en},
  owner = {magsilva},
  publisher = {Elsevier},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{gaines-shaw:1994,
  author = {Gaines, Brian R. and Shaw, Mildred L. G.},
  title = {Using knowledge acquisition and representation tools to support scientific communities},
  pages = {707--714},
  abstract = {Widespread access to the Internet has led to the formation of geographically dispersed scientific communities collaborating through the network. The tools supporting such collaboration currently are based primarily on electronic mail through mailing list servers, and access to archives of research reports through ftp, gopher and world wide web. However, electronic communication can support the knowledge processes of scientific communities more directly through overtly represented knowledge structures. This paper describes some experiments in the use of knowledge acquisition (KA) and representation (KR) tools to define and analyze major policy and technical issues in an international research community responsible for one of the test cases in the Intelligent Manufacturing Systems (IMS) research program. It is concluded that distributed knowledge support systems in routine use by world-class scientific communities collaborating through the Internet will provide a major impetus to artificial intelligence research.},
  volume = {1},
  series = {AAAI '94},
  acmid = {199374},
  address = {Menlo Park, CA, USA},
  booktitle = {National Conference on Artificial intelligence},
  isbn = {0-262-61102-3},
  location = {Seattle, Washington, United States},
  numpages = {8},
  publisher = {American Association for Artificial Intelligence},
  year = {1994}
}

@INPROCEEDINGS{Gallant-Mahmoud:2008,
  author = {Gallant, Randy J. and Mahmoud, Qusay H.},
  title = {Using {Greenfoot} and a {Moon} Scenario to teach {Java} programming in {CS1}},
  pages = {118--121},
  doi = {10.1145/1593105.1593135},
  abstract = {In this paper we describe a novel concept for teaching introductory Java programming to post-secondary students in their first year of higher education. The concept includes labs and a capstone project all linked together and all utilizing the Java-based Greenfoot programming environment. The concept is designed with two goals in mind: to improve the students experience in their first computer programming course by making it more entertaining; and to increase retention in the diploma or degree programs by peaking the student's interest early in their studies. This is accomplished through a Going to the Moon scenario we have designed and implemented into the Greenfoot programming environment.},
  keywords = {Greenfoot, Moon Scenario, programming environments, programming for fun, simple data types},
  series = {ACM-SE 46},
  acmid = {1593135},
  address = {New York, NY, USA},
  booktitle = {Annual Southeast Regional Conference on XX},
  isbn = {978-1-60558-105-7},
  location = {Auburn, Alabama},
  numpages = {4},
  publisher = {ACM},
  year = {2008}
}

@INPROCEEDINGS{Gallardo-etal:2008,
  author = {Gallardo, Jesús and Bravo, Crescencio and Redondo, Miguel Á.},
  title = {Developing Collaborative Modeling Systems Following a Model-Driven Engineering Approach},
  pages = {442--451},
  doi = {10.1007/978-3-540-88875-8_66},
  abstract = {Collaborative modeling systems are useful and promising tools for many tasks. However, they are difficult to build and are domain-specific. In response to this situation, we propose a model-driven process for the development of this kind of systems. This process is based on the use of some ontologies which characterize the concepts used in a software architecture to support collaborative modeling systems. These ontologies, from which the meta-models used in the generation process are derived, are explained in detail. In order to emphasize the utility of the proposal, an example of how the concepts in the ontologies are instantiated in a specific system, SPACE-DESIGN, is shown. It is also explained how by means of this approach it is possible to obtain reconfigurable systems, even at a level of application domain, by means of the use of model specifications and transformations.},
  acmid = {1484512},
  address = {Berlin, Heidelberg},
  booktitle = {Proceedings of the OTM Confederated International Workshops and Posters on On the Move to Meaningful Internet Systems: 2008 Workshops: ADI, AWeSoMe, COMBEK, EI2N, IWSSA, MONET, OnToContent + QSI, ORM, PerSys, RDDS, SEMELS, and SWWS},
  isbn = {978-3-540-88874-1},
  location = {Monterrey, Mexico},
  numpages = {10},
  publisher = {Springer-Verlag},
  url = {http://portal.acm.org/citation.cfm?id=1484422.1484512},
  year = {2008}
}

@ARTICLE{gallardo-etal:2011,
  author = {Gallardo, Jesús and Molina, Ana I. and Bravo, Crescencio and Redondo, Miguel A. and Collazos, César A.},
  title = {An ontological conceptualization approach for awareness in domain-independent collaborative modeling systems: Application to a model-driven development method},
  volume = {38},
  number = {2},
  month = feb,
  year = {2011},
  pages = {1099--1118},
  doi = {10.1016/j.eswa.2010.05.005},
  abstract = {One of the most important aspects of collaborative systems is the concept of awareness, which refers to the perception and knowledge of the group and its activities. Support for the design and automatic development of awareness mechanisms within collaborative systems is hard to find. Furthermore, awareness conceptualizations are usually partial and differ greatly between the proposals of different authors. In response to these problems, we propose an awareness ontology that conceptualizes some of the most important aspects of awareness in a specific kind of system: collaborative systems for carrying out modeling activities. The awareness ontology brings together and extends a series of ontologies we have developed in the past. The ontology is prepared to better meet the specific implementation needs of a model-driven development approach. In order to validate the usefulness of this ontology, we relate its concepts to the awareness dimensions set out in Gutwin and Greenberg's framework, and we apply the ontology to two systems presently in use.},
  keywords = {Awareness, CSCW, Collaborative modeling, Collaborative systems development, Ontologies},
  acmid = {1865005},
  address = {Tarrytown, NY, USA},
  issn = {0957-4174},
  issue = {2},
  journal = {Expert Systems with Applications: An International Journal},
  numpages = {20},
  publisher = {Pergamon}
}

@INPROCEEDINGS{gallego-etal:2010,
  author = {Gallego, Fernando and Molina, Ana I. and Bravo, Crescencio and Giraldo, William J.},
  title = {A proposal for model-based design and development of group work tasks in a shared context},
  pages = {11--18},
  abstract = {The design and development of groupware systems is a difficult task, especially due to their multidisciplinary nature and the technical complexity of these kinds of systems (e.g. distribution, data sharing, multi-user interfaces). A model-driven development approach could help to deal with this research problem. This paper presents an approach to tackling the design and development of groupware applications. This approach is part of a framework for the model-based user interface development of collaborative applications (called CIAF; Collaborative Interactive Application Framework), which includes issues of particular relevance based on the use of several models and notations for representing the collaborative and interactive aspects of this kind of systems.},
  keywords = {groupware design, groupware production, model-based design},
  series = {CDVE'10},
  acmid = {1887318},
  address = {Berlin, Heidelberg},
  booktitle = {Proceedings of the 7th international conference on Cooperative design, visualization, and engineering},
  isbn = {978-3-642-16065-3},
  location = {Calvia, Mallorca, Spain},
  numpages = {8},
  publisher = {Springer-Verlag},
  year = {2010}
}

@MISC{software:junit,
  author = {Erich Gamma and Kent Beck},
  title = {JUnit},
  howpublished = {Programa de Computador},
  year = {2001},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://www.junit.org}
}

@BOOK{Gamma-etal:1995,
  title = {Design patterns -- elements of reusable object-oriented software},
  publisher = {Addison-Wesley},
  year = {1995},
  author = {E. Gamma and R. Helm and R. Johnson and J. Vlissides},
  address = {Reading, MA},
  owner = {magsilva},
  timestamp = {2007.11.22}
}

@INPROCEEDINGS{Gannod-etal:2008,
  author = {Gannod, Gerald C. and Burge, Janet E. and Helmick, Michael T.},
  title = {Using the inverted classroom to teach software engineering},
  pages = {777-786},
  doi = {10.1145/1368088.1368198},
  abstract = {An inverted classroom is a teaching environment that mixes the use of technology with hands-on activities. In an inverted classroom, typical in-class lecture time is replaced with laboratory and in-class activities. Outside class time, lectures are delivered over some other medium such as video on-demand. In a three credit hour course for instance, contact hours are spent having students actively engaged in learning activities. Outside of class, students are focused on viewing 3-6 hours of lectures per week. Additional time outside of class is spent completing learning activities. In this paper we present the inverted classroom model in the context of a software engineering curriculum. The paper motivates the use of the inverted classroom and suggests how different courses from the Software Engineering 2004 Model Curriculum Volume can incorporate the use of the inverted classroom. In addition, we present the results of a pilot course that utilized the inverted classroom model at Miami University and describe courses that are currently in process of piloting its use.},
  keywords = {inverted classroom, podcasting, technology in education},
  address = {New York, NY, USA},
  booktitle = {International Conference on Software Engineering},
  isbn = {978-1-60558-079-1},
  location = {Leipzig, Germany},
  publisher = {ACM},
  year = {2008}
}

@TECHREPORT{Gao99TCBSO,
  author = {J. Gao},
  title = {Tracking Component-Based Software},
  institution = {San Jose State University},
  year = {1999},
  address = {San Jose, CA},
  url = {http://www.engr.sjsu.edu/gaojerry/report/main.htm},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@MISC{kleene,
  author = {GAP},
  title = {Site sobre Stephen Cole Kleene},
  year = {2002},
  note = {\url{http://www-gap.dcs.st-and.ac.uk/~history/Mathematicians/Kleene.html} (19/09/2002)},
  organization = {University of St Andrews},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {\url{http://www-gap.dcs.st-and.ac.uk/~history/Mathematicians/Kleene.html} (19/09/2002)}
}

@MISC{post,
  author = {GAP},
  title = {Site sobre Emil Leon Post},
  year = {2002},
  note = {\url{http://www-gap.dcs.st-and.ac.uk/~history/Mathematicians/Post.html} (19/09/2002)},
  organization = {University of St Andrews},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {\url{http://www-gap.dcs.st-and.ac.uk/~history/Mathematicians/Post.html} (19/09/2002)}
}

@INPROCEEDINGS{GarciaFrey:2010,
  author = {García Frey, Alfonso},
  title = {Self-explanatory user interfaces by model-driven engineering},
  pages = {341--344},
  doi = {10.1145/1822018.1822076},
  abstract = {Modern User Interfaces (UI) must deal with the increasing complexity of applications in terms of functionality as well as new properties as plasticity. The plasticity of a UI denotes its capacity of adaptation to the context of use preserving its quality. The efforts in plasticity have focused on the (meta) modeling of the UI, but the quality remains uncovered. We suggest a method for improving the quality of the UIs by providing explanations about the design of the UI itself: this is, by the use of the Self-Explanation. Self-Explanatory User Interfaces (SEUI) makes reference to the capacity of a UI to supply the end-user with all the information on the rational of the UI, about its constitution (for example, what is the purpose of this button?), its current state (why is the menu disabled?) as well as its evolution (how can I enable this feature?). This thesis investigates the SEUI by Model Driven Engineering (MDE), where models are kept at run-time allowing the necessary techniques that maintain this link between design and execution.},
  keywords = {design rationale, help, model transformation, model-driven engineering, self-explanatory user interfaces, ui quality},
  address = {New York, NY, USA},
  booktitle = {2nd ACM SIGCHI symposium on Engineering interactive computing systems},
  isbn = {978-1-4503-0083-4},
  location = {Berlin, Germany},
  publisher = {ACM},
  year = {2010}
}

@INPROCEEDINGS{Garlan00SARO,
  author = {David Garlan},
  title = {Software Architecture: a Roadmap},
  pages = {91--101},
  address = {New York, NY},
  booktitle = {22th International Conference on Software Engineering (ICSE 2000)},
  location = {Limerick, Ireland},
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {2000}
}

@ARTICLE{Garzotto:1993,
  author = {Franca Garzotto and Paolo Paolini and Daniel Schwabe},
  title = {{HDM}: a model-based approach to hypertext application design},
  volume = {11},
  number = {1},
  month = jan,
  year = {1993},
  pages = {1 - 26},
  doi = {10.1145/151480.151483},
  abstract = {Hypertext development should benefit from a systematic, structured development, especially in the case of large and complex applications. A structured approach to hypertext development suggests the notion of authoring-in-the-large. Authoring-in-the-large allows the description of overall classes of information elements and navigational structures of complex applications without much concern with implementation details, and in a system-independent manner. The paper presents HDM (Hypertext Design Model), a first step towards defining a general purpose model for authoring-in-the-large. Some of the most innovative features of HDM are: the notion of perspective; the identification of different categories of links (structural links, application links, and perspective links) with different representational roles; the distinction between hyperbase and access structures; and the possibility of easily integrating the structure of a hypertext application with its browsing semantics. HDM can be used in different manners: as a modeling device or as an implementation device. As a modeling device, it supports producing high level specifications of existing or to-be-developed applications. As an implementation device, it is the basis for designing tools that directly support application development. One of the central advantages of HDM in the design and practical construction of hypertext applications is that the definition of a significant number of links can be derived automatically from a conceptual-design level description. Examples of usage of HDM are also included.},
  address = {New York, NY, EUA},
  file = {HDM - A model-based approach to hypertext application design.pdf:HDM - A model-based approach to hypertext application design.pdf:PDF},
  journal = {ACM Transactions on Information Systems},
  owner = {magsilva},
  publisher = {ACM Press},
  timestamp = {2008.07.30}
}

@BOOK{Gavesic-etal:2006,
  title = {Model Driven Architecture and Ontology Development},
  publisher = {Springer},
  year = {2006},
  author = {Dragan Gasevic and Dragan Djuric and Vladan Devedzic},
  isbn = {978-3-540-32180-4},
  pages = {311},
  address = {Germany}
}

@BOOK{Gawlinski:2003,
  title = {Interactive Television Production},
  publisher = {Focal/Elsevier Science},
  year = {2003},
  author = {Mark Gawlinski},
  isbn = {9780080522111},
  pages = {277},
  edition = {1},
  booktitle = {Interactive Television Production}
}

@INPROCEEDINGS{Geerts:2006:CVC:1182475.1182537,
  author = {Geerts, David},
  title = {Comparing voice chat and text chat in a communication tool for interactive television},
  pages = {461--464},
  doi = {10.1145/1182475.1182537},
  abstract = {Talking during the course of a television program is something that has been done almost since the introduction of the television in the household, and is one of the most important social uses of television. Interactive television extends this concept beyond the family household, making it possible to talk with family and friends at remote households. This particular study looks at two modes of communication, more specifically voice chat and text chat, and what the advantages and disadvantages are of these systems when communicating while watching television. The results show that voice chat is considered more natural and direct, and makes it easier to keep on following the program. Text chat is more preferred by younger users and users having more experience with chatting on computers, and is therefore interesting to use in interactive services specifically aimed at youngsters. In both cases, our study shows that such systems should be carefully designed to divide attention between watching and communicating in such a way that distraction from the television program is minimized.},
  keywords = {backchannel, interactive television, text chat, voice chat},
  address = {New York, NY, USA},
  booktitle = {4th Nordic conference on Human-computer interaction: changing roles},
  isbn = {1-59593-325-5},
  location = {Oslo, Norway},
  publisher = {ACM},
  year = {2006}
}

@INPROCEEDINGS{Geerts:2009:SSU:1518701.1518793,
  author = {Geerts, David and De Grooff, Dirk},
  title = {Supporting the social uses of television: sociability heuristics for social tv},
  pages = {595--604},
  doi = {10.1145/1518701.1518793},
  abstract = {Various social television systems and applications, enabling remote communication and interaction between viewers, are currently in development. Although usability guidelines exist for interactive television to ensure a usable system, there are no sociability guidelines for designing or evaluating the social interaction these systems enable. In this paper we present twelve sociability heuristics for evaluating social TV, based on several user studies with social TV systems.},
  keywords = {evaluation, heuristics, sociability, social television},
  address = {New York, NY, USA},
  booktitle = {27th international conference on Human factors in computing systems},
  isbn = {978-1-60558-246-7},
  location = {Boston, MA, USA},
  publisher = {ACM},
  year = {2009}
}

@MISC{software:mplayer,
  author = {Árpád Gereöffy and others},
  title = {MPlayer},
  howpublished = software,
  month = nov,
  year = {2000},
  abstract = {MPlayer is a movie player for Linux (runs on many other Unices, and non-x86 CPUs, see Ports). It plays most MPEG, VOB, AVI, Ogg/OGM, VIVO, ASF/WMA/WMV, QT/MOV/MP4, FLI, RM, NuppelVideo, yuv4mpeg, FILM, RoQ, PVA, Matroska files, supported by many native, XAnim, RealPlayer, and Win32 DLL codecs. You can watch Video CD, SVCD, DVD, 3ivx, RealMedia, Sorenson, Theora, and MPEG-4 (DivX) movies, too. Another big feature of MPlayer is the wide range of supported output drivers. It works with X11, Xv, DGA, OpenGL, SVGAlib, fbdev, AAlib, libcaca, DirectFB, but you can use GGI and SDL (and this way all their drivers) and some low level card-specific drivers (for Matrox, 3Dfx and Radeon, Mach64, Permedia3) too! Most of them support software or hardware scaling, so you can enjoy movies in fullscreen. MPlayer supports displaying through some hardware MPEG decoder boards, such as the DVB and DXR3/Hollywood+. And what about the nice big antialiased shaded subtitles (14 supported types) with European/ISO 8859-1,2 (Hungarian, English, Czech, etc), Cyrillic, Korean fonts, and the onscreen display (OSD)? The player is rock solid playing damaged MPEG files (useful for some VCDs), and it plays bad AVI files which are unplayable with the famous Windows Media Player. Even AVI files without index chunk are playable, and you can temporarily rebuild their indexes with the -idx option, or permanently with MEncoder, thus enabling seeking! As you see, stability and quality are the most important things, but the speed is also amazing. There is also a powerful filter system for video and audio manipulation. MEncoder (MPlayer's Movie Encoder) is a simple movie encoder, designed to encode MPlayer-playable movies AVI/ASF/OGG/DVD/VCD/VOB/MPG/MOV/VIV/FLI/RM/NUV/NET/PVA to other MPlayer-playable formats (see below). It can encode with various codecs, like MPEG-4 (DivX4) (one or two passes), libavcodec, PCM/MP3/VBR MP3 audio.},
  url = {http://www.mplayerhq.hu}
}

@ARTICLE{gerosa2004adf,
  author = {Gerosa, M.A. and Raposo, A.B. and Fuks, H. and Lucena, CJP},
  title = {{Uma Arquitetura para o Desenvolvimento de Ferramentas Colaborativas para o Ambiente de Aprendizagem AulaNet}},
  year = {2004},
  pages = {168--177},
  journal = {XV Simp{\'o}sio Brasileiro de Inform{\'a}tica na Educa{\c{c}}{\~a}o-SBIE},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@INPROCEEDINGS{Gery-etal:2002,
  author = {Gery, Eran and Harel, David and Palachi, Eldad},
  title = {Rhapsody: A Complete Life-Cycle Model-Based Development System},
  pages = {1--10},
  abstract = {We discuss Rhapsody, a UML based software development tool, designed to support complete model-based iterative life-cycle. First, we identify several key inhibiting factors that prevent model-based approaches from being adopted as a mainstream practice.We then examine the requirements for allowing complete life-cycle model-based development and discuss how they are met by Rhapsody through its key enabling technologies, which include: - model-code associativity - automated implementation generation - implementation framework - model execution - model-based testingWe explain why each of these features is instrumental to an effective development of production systems, based on a key observation that the modeling language does not replace the implementation platform, but should be integrated with it in a synergistic manner. This allows the use of modeling for expressing requirements and design abstractions, along with the use of the full power of an implementation language and its supporting platform to specify implementation details. While allowing this flexibility, Rhapsody facilitates full consistency of the modeling and implementation artifacts throughout the life-cycle, and it also supports a high level of automation in the implementation and validation of the developed system.},
  volume = {2335},
  series = {Lecture Notes in Computer Science},
  address = {London, UK, UK},
  booktitle = {3rd International Conference on Integrated Formal Methods},
  editor = {Michael J. Butler and Luigia Petre and Kaisa Sere},
  isbn = {3-540-43703-7},
  location = {Turku, #Finland#},
  month = may,
  publisher = {Springer-Verlag},
  url = {http://dl.acm.org/citation.cfm?id=647983.757281},
  year = {2002}
}

@BOOK{ghezzi-jazayeri:1987,
  title = {Programming Languages Concepts},
  publisher = {John Wiley and Sons},
  year = {1987},
  author = {C. Ghezzi and M. Jazayeri},
  address = {New York},
  edition = {2},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@BOOK{Ghezzi91FSEN,
  title = {Fundamentals of Software Engineering},
  publisher = {Prentice-Hall Inc},
  year = {1991},
  author = {C. Ghezzi and M. Jazayeri and D. Mandrioli},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{ghezzi-mandrioli:2005,
  author = {Carlo Ghezzi and Dino Mandrioli},
  title = {The challenges of software engineering education},
  pages = {637--638},
  doi = {10.1145/1062455.1062578},
  address = {St. Louis, MO, USA},
  booktitle = {ICSE '05: Proceedings of the 27th international conference on Software engineering},
  owner = {magsilva},
  publisher = {ACM},
  timestamp = {2008.01.20},
  year = {2005}
}

@ARTICLE{ghosh-mathur:2001,
  author = {S. Ghosh and A. P. Mathur},
  title = {Interface Mutation},
  volume = {11},
  number = {4},
  month = dec,
  year = {2001},
  pages = {227-247},
  abstract = {Applications that utilize a broker-based architecture are often composed of components that need to be tested individually and in combination. Furthermore, adequacy assessment of tests of components is useful in that it assists testers in identifying weaknesses in the tests generated so far and in offering hints on what the new tests must be. Traditional test adequacy criteria have limitations for commercial use, especially when tests for large components are to be assessed for their adequacy. This paper describes a test adequacy criterion based on interface mutation and a method, based on the criterion, to test components. This method requires the mutation of elements only from within a component's interface and not from within the code that implements the interface. The adequacy criterion based on interface mutation was evaluated empirically and compared with coverage criteria based on control flow for its relative effectiveness in revealing errors and in the cost incurred in developing test sets that satisfy the criterion.},
  journal = {Software Testing, Verification and Reliability},
  note = {(to appear)},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{Ghosh00IMUT,
  author = {S. Ghosh and A. P. Mathur},
  title = {Interface Mutation},
  pages = {227--247},
  address = {San Jose, CA},
  booktitle = {Mutation 2000 Symposium},
  month = oct,
  owner = {magsilva},
  publisher = {Kluwer Academic Publishers},
  timestamp = {2008.07.31},
  year = {2000}
}

@ARTICLE{gibbons:2001,
  author = {Andrew S. Gibbons},
  title = {Model-Centered Instruction},
  volume = {14},
  year = {2001},
  pages = {511-540},
  journal = {Journal of Structural Learning and Intelligent Systems}
}

@BOOK{Gill62ITFS,
  title = {Introduction to the Theory of Finite State Machines},
  publisher = {McGraw-Hill},
  year = {1962},
  author = {A. Gill},
  address = {New York},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{giraffa-etal:2005,
  author = {L Giraffa and S. Marczak and R. Prikladnicki},
  title = {PDS-E: Em Direção a um processo para o desenvolvimento de Software Educacional},
  address = {São Leopoldo, RS},
  booktitle = {Workshop sobre Informática na Escola},
  organization = {UNISINOS/SBC},
  timestamp = {2008.09.28},
  year = {2005}
}

@INPROCEEDINGS{Giraffa-etal:2006,
  author = {Lucia M. M. Giraffa and Rafael V. de Souza and Sabrina Marczak and Rafael Prikladnicki},
  title = {Uma Ferramenta para a Modelagem de Software Educacional voltada a Professores de Escolas},
  pages = {291-299},
  address = {Campo Grande, MS},
  booktitle = {XXVI Congresso da SBC - XII Workshop de Informática na Escola},
  month = jul,
  timestamp = {2008.07.31},
  year = {2006}
}

@INPROCEEDINGS{giraldo-etal:2010,
  author = {Giraldo, Faber D. and Collazos, Cesar A. and Ochoa, Sergio F. and Zapata, Sergio and de Clunie, Gisela Torres},
  title = {Teaching Software Engineering from a Collaborative Perspective: Some Latin-American Experiences},
  pages = {97--101},
  doi = {10.1109/DEXA.2010.39},
  abstract = {Teaching software engineering has been recognized as an important challenge for computer science undergraduate programs. Instruction in such area requires not only to deliver theoretical knowledge, but also to perform practical experiences that allow students to assimilate and apply such knowledge. This paper presents some results of two Computer-Supported Collaborative Learning (CSCL) experiences that involved students of software engineering courses from four Latin American Universities. The obtained results were satisfactory and indicate the reported collaborative activity could be appropriate to address teaching software engineering.},
  keywords = {Collaborative Activity, Computer Supported Collaborative Learning, Software Engineering, Collaborative Work, Collaborative Groups},
  series = {DEXA '10},
  acmid = {1901649},
  address = {Washington, DC, USA},
  booktitle = {Proceedings of the 2010 Workshops on Database and Expert Systems Applications},
  isbn = {978-0-7695-4174-7},
  numpages = {5},
  publisher = {IEEE Computer Society},
  year = {2010}
}

@INBOOK{Giraldo:2009:MBA:1532688.1532726,
  chapter = {A Model Based Approach for GUI Development in Groupware Systems},
  pages = {324--339},
  title = {Groupware: Design, Implementation, and Use},
  publisher = {Springer-Verlag},
  year = {2008},
  editor = {Briggs, Robert O. and Antunes, Pedro and Vreede, Gert-Jan and Read, Aaron S.},
  author = {Giraldo, William J. and Molina, Ana I. and Collazos, César A. and Ortega, Manuel and Redondo, Miguel Á.},
  address = {Berlin, Heidelberg},
  abstract = {This paper proposes a methodological approach for Model Based User Interface Development of Collaborative Applications. This proposal is based on the use of several models for representing collaborative and interactive issues. Therefore, several techniques and notations are used. We describe the integration process of two notations: CIAN, which involves collaboration and human-computer interaction aspects; and UML, which specifies groupware systems functionality. In addition, we describe how this model is integrated into the Software Engineering Process. Both integration processes are developed by using software tools like CIAT and EPFC.},
  doi = {10.1007/978-3-540-92831-7_27},
  isbn = {978-3-540-92830-0},
  keywords = {Groupware design, Interaction design, Model Based Design and Development, Software Engineering}
}

@INPROCEEDINGS{giraldo-etal:2009,
  author = {Giraldo, William J. and Molina, Ana I. and Gallardo, Jesus and Collazos, Cesar A. and Ortega, Manuel and Redondo, Miguel A.},
  title = {Classification of {CSCW} proposals based on a taxonomy},
  pages = {119--124},
  doi = {10.1109/CSCWD.2009.4968045},
  abstract = {In this paper we propose a conceptual framework for the design the groupware user interface. It supports the interface design enabling integration with software development processes through UML notation. We studied relevant proposals in the domain of CSCW and HCI. Taxonomy is defined in order to classify concepts from those proposals. Finally, the taxonomy is populated for defining main concepts of the conceptual framework.},
  acmid = {1579076},
  address = {Washington, DC, USA},
  booktitle = {Proceedings of the 2009 13th International Conference on Computer Supported Cooperative Work in Design},
  isbn = {978-1-4244-3534-0},
  numpages = {6},
  publisher = {IEEE Computer Society},
  url = {http://portal.acm.org/citation.cfm?id=1578024.1579076},
  year = {2009}
}

@INPROCEEDINGS{giraldo-etal:2008,
  author = {Giraldo, William J. and Molina, Ana I. and Ortega, Manuel and Collazos, Cesar A.},
  title = {Integrating Groupware Notations with UML},
  pages = {142--149},
  doi = {10.1007/978-3-540-85992-5_13},
  abstract = {In this paper we introduce a notation integration proposal. This proposal supports the user interface design of groupware applications enabling integration with software processes through UML notation. We introduce our methodological approach to deal with the conceptual design of applications for supporting group work, called CIAM. A study case (the design of a <em>Conference Resiew System</em>) is presented to describe our proposal. The integration process proposed is supported by a software tool called CIAT.},
  keywords = {GUI development, groupware design, interaction design},
  series = {HCSE-TAMODIA '08},
  acmid = {1459865},
  address = {Berlin, Heidelberg},
  booktitle = {Proceedings of the 2nd Conference on Human-Centered Software Engineering and 7th International Workshop on Task Models and Diagrams},
  isbn = {978-3-540-85991-8},
  location = {Pisa, Italy},
  numpages = {8},
  publisher = {Springer-Verlag},
  year = {2008}
}

@INPROCEEDINGS{Girgis86ECEE,
  author = {M. R. Girgis and M. R. Woodward},
  title = {An Experimental Comparison of the Error Exposing Ability of Program Testing Criteria},
  pages = {64--71},
  address = {Banff -- Canada},
  booktitle = {Workshop on Software Testing},
  month = jul,
  owner = {magsilva},
  publisher = {Computer Science Press},
  timestamp = {2008.07.31},
  year = {1986}
}

@INPROCEEDINGS{Girgis85ISPT,
  author = {M. R. Girgis and M. R. Woodward},
  title = {An Integrated System for Program Testing Using Weak Mutation and Data Flow Analysis},
  pages = {313--319},
  booktitle = {8th International Conference on Software Engineering},
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1985}
}

@MASTERSTHESIS{Gladcheff:2000,
  author = {A. P. Gladcheff},
  title = {Um Instrumento de Avaliação da Qualidade para Software Educacional de Matemática},
  school = {IME-USP},
  year = {2000},
  address = {São Paulo, SP},
  month = dec,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@ARTICLE{Glass:1976,
  author = {G. V. Glass},
  title = {Primary, secondary,, and meta-analysis},
  volume = {5},
  year = {1976},
  pages = {3-8},
  journal = {Educational Researcher}
}

@BOOK{Glass-etal:1981,
  title = {Meta-Analysis in Social Research},
  publisher = {SAGE},
  year = {1981},
  author = {G. V. Glass and B. McGaw and M. L. Smith},
  pages = {280},
  address = {Beverly Hill, California, United States}
}

@ARTICLE{Glass:2000,
  author = {Robert L. Glass},
  title = {An assessment of systems and software engineering scholars and institutions (1995-1999)},
  volume = {54},
  number = {1},
  year = {2000},
  pages = {77 - 82},
  doi = {10.1016/S0164-1212(00)00027-3},
  abstract = {This paper presents the findings of a five-year study of the top scholars and institutions in the Systems and Software Engineering field, as measured by the quantity of papers published in the journals of the field. The top scholar is Richard Lai of La Trobe University in Australia, and the top institution is Carnegie Mellon University and its Software Engineering Institute. The paper lists the top 15 scholars and institutions.},
  url = {http://www.sciencedirect.com/science/article/B6V0N-419BHWH-9/2/7ddef79e1fca9675719cfee65e691699},
  issn = {0164-1212},
  journal = {Journal of Systems and Software}
}

@ARTICLE{Glass:2000:1,
  author = {Robert L. Glass},
  title = {Corrigendum to: An assessment of systems and software engineering scholars and institutions (1994-1998)},
  volume = {51},
  number = {3},
  year = {2000},
  pages = {275 - 275},
  doi = {10.1016/S0164-1212(00)00008-X},
  url = {http://www.sciencedirect.com/science/article/B6V0N-4007R6S-9/2/504d6a811b64671f1ce5ef0c0e2515fd},
  issn = {0164-1212},
  journal = {Journal of Systems and Software}
}

@ARTICLE{Glass:1999,
  author = {Robert L. Glass},
  title = {An assessment of systems and software engineering scholars and institutions (1994-1998)},
  volume = {49},
  number = {1},
  year = {1999},
  pages = {81 - 86},
  doi = {10.1016/S0164-1212(99)00068-0},
  url = {http://www.sciencedirect.com/science/article/B6V0N-3Y9RCX5-8/2/7d2645007751ff2ab2ad9667da2c9fd6},
  issn = {0164-1212},
  journal = {Journal of Systems and Software},
  note = {See also Corrigendum to: An assessment of systems and software engineering scholars and institutions (1994-1998).}
}

@ARTICLE{Glass:1998,
  author = {Robert L. Glass},
  title = {An assessment of systems and software engineering scholars and institutions (1993-1997)},
  volume = {43},
  number = {1},
  year = {1998},
  pages = {59 - 64},
  doi = {10.1016/S0164-1212(98)10037-7},
  url = {http://www.sciencedirect.com/science/article/B6V0N-3VN3C8N-7/2/32a6b1aac34ad34bec1c7faeabae809c},
  issn = {0164-1212},
  journal = {Journal of Systems and Software}
}

@ARTICLE{Glass:1997,
  author = {Robert L. Glass},
  title = {An assessment of systems and software engineering scholars and institutions (1993-1996)},
  volume = {39},
  number = {1},
  year = {1997},
  pages = {83 - 88},
  doi = {10.1016/S0164-1212(97)00001-0},
  url = {http://www.sciencedirect.com/science/article/B6V0N-3SP2DCS-K/2/a4ebcfcb78ac8dcef67fe2af3f3eb49c},
  issn = {0164-1212},
  journal = {Journal of Systems and Software}
}

@ARTICLE{Glass:1996,
  author = {Robert L. Glass},
  title = {An assessment of Systems and Software Engineering Scholars and Institutions (1993-1995)},
  volume = {35},
  number = {1},
  year = {1996},
  pages = {85 - 89},
  doi = {10.1016/S0164-1212(96)00105-7},
  abstract = {Who are the most published scholars in the field of Systems and Software Engineering (SSE)? Which are the most published institutions? This paper is the third in an annual series whose goal is to answer those questions. The first two such papers were [Glass 1994; 1995]. This article reports on the top scholars and institutions for the three-year period of 1993-1995. The methodology of the study, including the journals surveyed, and its limitations will be discussed later in this article. It is important to note, however, that this study focuses on systems and software engineering, and not, for example, on computer science or information systems. Here are the findings.},
  url = {http://www.sciencedirect.com/science/article/B6V0N-3VTB04S-J/2/f425b15e95b9e1b458d84c4bbdc46467},
  issn = {0164-1212},
  journal = {Journal of Systems and Software}
}

@ARTICLE{Glass:1995:28,
  author = {Robert L. Glass},
  title = {A structure-based critique of contemporary computing research},
  volume = {28},
  number = {1},
  year = {1995},
  pages = {3 - 7},
  doi = {10.1016/0164-1212(94)00077-Z},
  url = {http://www.sciencedirect.com/science/article/B6V0N-3YGV297-K/2/8e9216c77711e3d85d79fd235b399cf1},
  issn = {0164-1212},
  journal = {Journal of Systems and Software}
}

@ARTICLE{Glass:1995:31,
  author = {Robert L. Glass},
  title = {An assessment of systems and software engineering scholars and institutions, 1993 and 1994},
  volume = {31},
  number = {1},
  year = {1995},
  pages = {3 - 6},
  doi = {10.1016/0164-1212(95)00058-9},
  abstract = {This paper is the second in an annual series whose goal is to answer the questions Who are the most published authors in the field of systems and software engineering (SSE)? From which institutions do the most systems and software engineering published papers emerge? The first paper (Glass, 1994) in the series was published a year ago. The current study reports on the top scholars and institutions for the years 1993 and 1994. The methodology of the study (including the journals surveyed) and its limitations are discussed later in the paper. This study focuses on systems and software engineering and not, for example, on computer science or information systems. The findings are as follows.},
  url = {http://www.sciencedirect.com/science/article/B6V0N-404RP1T-K/2/e882ce9aa69893440885f8a93b36dafc},
  issn = {0164-1212},
  journal = {Journal of Systems and Software}
}

@ARTICLE{Glass:1994,
  author = {Robert L. Glass},
  title = {The Software Research Crisis},
  volume = {11},
  month = nov,
  year = {1994},
  pages = {42-47},
  doi = {10.1109/52.329400},
  journal = {IEEE Software},
  owner = {magsilva},
  timestamp = {2010.08.11}
}

@ARTICLE{Glass:1991,
  author = {Robert L. Glass},
  title = {The (Solved, Unsolved) Problem of Literature Searches},
  volume = {15},
  year = {1991},
  pages = {203-204},
  journal = {Journal of Systems and Software}
}

@ARTICLE{Glass-Chen:2005,
  author = {Robert L. Glass and T.Y. Chen},
  title = {An assessment of systems and software engineering scholars and institutions (1999-2003)},
  volume = {76},
  number = {1},
  year = {2005},
  pages = {91 - 97},
  doi = {10.1016/j.jss.2004.08.018},
  abstract = {This paper presents the findings of a five-year study of the top scholars and institutions in the Systems and Software Engineering field, as measured by the quantity of papers published in the journals of the field. The top scholar is Khaled El Emam of the Canadian National Research Council, and the top institution is Carnegie Mellon University and its Software Engineering Institute. This paper is part of an ongoing study, conducted annually, that identifies the top 15 scholars and institutions in the most recent five-year period.},
  url = {http://www.sciencedirect.com/science/article/B6V0N-4DCMP5X-1/2/83cd4d2592fef6678870a3451046e77a},
  issn = {0164-1212},
  journal = {Journal of Systems and Software}
}

@ARTICLE{Glass-Chen:2003,
  author = {R. L. Glass and T. Y. Chen},
  title = {An assessment of systems and software engineering scholars and institutions (1998-2002)},
  volume = {68},
  number = {1},
  year = {2003},
  pages = {77--84},
  doi = {10.1016/S0164-1212(03)00232-2},
  abstract = {This paper presents the findings of a five-year study of the top scholars and institutions in the Systems and Software Engineering field, as measured by the quantity of papers published in the journals of the field. The top scholar is Khaled El Emam of the Canadian National Research Council, and the top institution is Carnegie Mellon University and its Software Engineering Institute. This paper is part of an ongoing study, conducted annually, that identifies the top 15 scholars and institutions in the most recent five-year period.},
  url = {http://www.sciencedirect.com/science/article/B6V0N-491RV6C-2/2/9b3c21b6ef4263e926f57fbfb6371459},
  issn = {0164-1212},
  journal = {Journal of Systems and Software}
}

@ARTICLE{Glass-Chen:2002,
  author = {R. L. Glass and T. Y. Chen},
  title = {An assessment of systems and software engineering scholars and institutions (1997-2001)},
  volume = {64},
  number = {1},
  year = {2002},
  pages = {79 - 86},
  doi = {10.1016/S0164-1212(02)00023-7},
  abstract = {This paper presents the findings of a five-year study of the top scholars and institutions in the systems and software engineering field, as measured by the quantity of papers published in the journals of the field. The top scholar is Richard Lai of LaTrobe University in Australia, and the top institution is Carnegie Mellon University and its Software Engineering Institute. The paper lists the top 15 scholars and institutions.},
  url = {http://www.sciencedirect.com/science/article/B6V0N-47T8NBW-1/2/62bdfc63328f61e66f443128035769c2},
  issn = {0164-1212},
  journal = {Journal of Systems and Software}
}

@ARTICLE{Glass-Chen:2001,
  author = {Robert L. Glass and T. Y. Chen},
  title = {An assessment of systems and software Engineering scholars and institutions (1996-2000)},
  volume = {59},
  number = {1},
  year = {2001},
  pages = {107 - 113},
  doi = {10.1016/S0164-1212(01)00052-8},
  keywords = {Top scholars},
  url = {http://www.sciencedirect.com/science/article/B6V0N-449THV4-9/2/2cfd3945ff1bcb5a7278fce91fa3d3d8},
  issn = {0164-1212},
  journal = {Journal of Systems and Software}
}

@ARTICLE{Glinz:14,
  author = {M. Glinz},
  title = {Systematically combining specifications of internal and external system behavior using statecharts},
  volume = {2004},
  number = {905},
  year = {2004},
  pages = {14-20},
  doi = {10.1049/ic:20040232},
  abstract = {n contemporary model-based specifications, we typically find a naive combination of models of the externally visible behavior of a system (typically expressed as scenarios or use cases) and of the internal system behavior (partially represented in explicit state models and partially expressed as data). However, a systematic combination and integration of the two behavior aspects has not yet been investigated. We sketch a systematic approach for modeling both external and internal behavior of a system with statecharts in an integrated, nonredundant way. The main idea is to start with statecharts that model external behavior in the form of use cases or type scenarios and then add statecharts that model internal behavior only where the scenario/use case statecharts do not suffice for expressing the behavior of the system.},
  keywords = {internal system behavior specifications; external system behavior specifications; model-based specifications; use cases statecharts; type scenarios},
  isbn = {0 86341 420 6},
  journal = {IEE Seminar Digests},
  publisher = {IEE}
}

@INPROCEEDINGS{gohn:2006,
  author = {Maria da Glória Gohn},
  title = {Educação não-formal na pedagogia social},
  booktitle = {I Congresso Internacional de Pedagogia Social},
  timestamp = {2008.10.10},
  year = {2006}
}

@MISC{glosiene:2004,
  author = {Audrone Glosiene and Zinaida Manzuch},
  title = {Usability of ICT-based systems: State-of-the-Art review},
  howpublished = {Entregável de projeto de pesquisa},
  month = {aug},
  year = {2004},
  note = {CALIMERA Deliverable 9 (Calimera Project, Vilnius University, Lithuania)},
  owner = {magsilva},
  timestamp = {2006.08.22},
  url = {http://www.kf.vu.lt/site_files_doc/usability_final.doc}
}

@INPROCEEDINGS{gnatz:2003,
  author = {Michael Gnatz and Leonid Kof and Franz Prilmeier and Tilman Seifert},
  title = {A Practial Approach of Teaching Software Engineering},
  pages = {120-128},
  booktitle = {Conference of Software Engineering Education and Training (CSEET'03)},
  owner = {magsilva},
  publisher = {IEEE},
  timestamp = {2008.07.30},
  year = {2003}
}

@TECHREPORT{goland:1999,
  author = {Y. Goland and E. Whitehead and A. Faizi and S. Carter and D. Jensen},
  title = {HTTP Extensions for Distributed Authoring - WebDAV},
  year = {1999},
  owner = {magsilva},
  timestamp = {2008.07.30},
  type = {Internet Proposed Standard - RFC 2518}
}

@BOOK{Goldberg-Robson:1983,
  title = {Smalltalk-80: the language and its implementation},
  publisher = {Addison-Wesley Longman},
  year = {1983},
  author = {Goldberg, Adele and Robson, David},
  isbn = {0-201-11371-6},
  pages = {714},
  address = {Boston, MA, USA}
}

@MISC{software:webct,
  author = {Murray Goldberg and others},
  title = {{WebCT}},
  howpublished = {Programa de computador},
  year = {1996},
  owner = {magsilva},
  timestamp = {2010.08.03}
}

@INPROCEEDINGS{Goldberg-etal:2006:iw3cc,
  author = {M. Goldberg and S. Salari and P. Swoboda},
  title = {{World Wide Web - Course Tool: An} Environment for Building {WWW}-Based Courses},
  address = {Paris, France},
  booktitle = {V International World Wide Web Conference},
  month = may,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1996}
}

@ARTICLE{Goldberg-etal:1996:cnis,
  author = {M. W. Goldberg and S. Salari and P. Swoboda},
  title = {{World Wide Web - Course Tool}: An Environment for Building {WWW}-Based Courses},
  volume = {28},
  number = {7--11},
  month = may,
  year = {1996},
  pages = {1219 -- 1231},
  journal = {Computer Networks and ISDN Systems},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@ARTICLE{gomezperes-corcho:2002,
  author = {A. Gómez-Pérez and O. Corcho},
  title = {Ontology languages for the semantic web},
  volume = {17},
  number = {1},
  year = {2002},
  pages = {54--60},
  journal = {IEEE Intelligent Systems},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@BOOK{gomezperez-etal:2004,
  title = {Ontological Engineering: with examples from the areas of Knowledge Management, e-Commerce and the Semantic Web},
  publisher = {Springer},
  year = {2004},
  author = {A. Gómez-Pérez and O. Corcho and M. Fernandez-Lopez},
  edition = {1},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@ARTICLE{gong-yao:2010,
  author = {Gong, D. and Yao, X.},
  title = {Automatic detection of infeasible paths in software testing},
  volume = {4},
  number = {5},
  month = oct,
  year = {2010},
  pages = {361 -370},
  doi = {10.1049/iet-sen.2009.0092},
  abstract = {A challenging problem in path-oriented test data generation is the presence of infeasible paths. Timely detecting these infeasible paths cannot only save test resources but also improve test efficiency. A popular method of detecting infeasible paths is to determine branch correlations, which is a difficult task and usually cannot be done timely and exactly. In this study, the authors propose a method of automatically determining the branch correlations of different conditional statements, therefore detecting infeasible paths. First, some theorems are given to determine branch correlations based on the probabilities of the conditional distribution corresponding to different branches' outcome (i.e. true or false); then, the maximum likelihood estimation is employed to obtain the values of these probabilities; finally, infeasible paths are detected according to branch correlations. The authors apply the proposed method in some typical programs, and the results show that the proposed method can accurately detect infeasible paths. The achievement provides an effective and automatic method of detecting infeasible paths, which is significant in improving the efficiency of software testing.},
  keywords = {branch correlations;conditional distribution;infeasible paths automatic detection;maximum likelihood estimation;path oriented test data generation;software testing;maximum likelihood estimation;program testing;statistical distributions;},
  issn = {1751-8806},
  journal = {Software, IET}
}

@BOOK{Good-Brophy:1990,
  title = {Educational Psychology. A Realistic Approach},
  publisher = {Addison Wesley},
  year = {1990},
  author = {Good, Thomas L. and Brophy, Jere E.},
  isbn = {0-8013-0351-6},
  pages = {836},
  abstract = {The purpose of this book is to improve instruction by helping future teachers understand the realities of teaching, understand and organize relevant psychological theory, and become competent at tasks instructors perform. There are 29 chapters which deal with the following topics: (1) teacher decision making; (2) student physical development; (3) basics of cognitive development; (4) cognitive development and education; (5) social and personal development; (6) psychology of learning; (7) the behavioral approach to learning; (8) the cognitive structural view of learning; (9) the information-processing view of learning; (10) skills for learning; (11) instructional design; (12) approaches to classroom instruction; (13) basic instructional skills; (14) basic concepts of motivation; (15) cognitive viewpoints; (16) guidelines for motivating students; (17) communicating appropriate expectations to low achievers; (18) the humanistic perspective; (19) overview of classroom management; (20) establishing and maintaining a good learning environment; (21) principles and techniques of behavior modification; (22) humanistic approaches to counseling disturbed students; (23) socioeconomic status, IQ, and gender differences among students; (24) cognitive styles and creativity; (25) educating students with special needs; (26) principles of educational measurement; (27) statistical concepts; (28) test construction; and (29) assigning grades.}
}

@ARTICLE{goodenough-gerhart:1975,
  author = {John B. Goodenough and Susan L. Gerhart},
  title = {Toward a theory of test data selection},
  volume = {1},
  number = {2},
  month = jun,
  year = {1975},
  pages = {156-173},
  journal = {IEEE Transactions on Software Engineering},
  owner = {magsilva},
  timestamp = {2009.05.13}
}

@MISC{goodger:2001,
  author = {Ben Goodger and Ian Hickson and David Hyatt and Chris Waterson},
  title = {XML User Interface Language (XUL) 1.0},
  howpublished = {Mozilla Specification},
  year = {2001},
  comment = {25/05/2005},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://www.mozilla.org/projects/xul/xul.html}
}

@MISC{software:googleapi,
  author = {Google, Inc.},
  title = {Google SOAP Search API},
  howpublished = {Programa de computador},
  year = {2002},
  owner = {magsilva},
  timestamp = {2006.08.03},
  url = {http://www.google.com/apis/}
}

@MISC{software:youtube,
  author = {{Google Inc.}},
  title = {YouTube},
  howpublished = {Programa de Computador},
  month = feb,
  year = {2005},
  owner = {magsilva},
  timestamp = {2008.04.03},
  url = {http://www.youtube.com}
}

@PHDTHESIS{Goularte:2003,
  author = {Rudinei Goularte},
  title = {Personalização e adaptação de conteúdo baseadas em contexto para TV Interativa},
  school = {Instituto de Ciências Matemáticas e de Computação -- Universidade de São Paulo},
  year = {2003},
  address = {São Carlos, SP, Brasil},
  month = sep,
  note = {Orientador: Edson dos Santos Moreira},
  timestamp = {2008.09.28}
}

@PHDTHESIS{Rudinei:2003,
  author = {Goularte, Rudinei},
  title = {Personalização e adaptação de conteúdo baseadas em contexto para {TV} Interativa},
  abstract = {O trabalho apresentado nesta tese trata do desenvolvimento de técnicas com suporte à ciência de contexto, baseadas nos padrões MPEG-4 e MPEG-7, para personalizar e adaptar conteúdo em TV Interativa. Um dos desafios dessa área é desenvolvimento de programas personalizados com rico conteúdo multimídia, com alta interatividade e que, além disso, sejam acessíveis a partir de uma variedade de dispositivos (fixos ou móveis), atendendo às expectativas de interação e de acesso dos usuários. Grande parte do problema está no fato de que os modos encontrados na literatura para representar, descrever e compor programas de TV Interativa não oferecem suporte a contexto, não permitem a separação entre descrições de programas e descrições de objetos e possuem baixa granulosidade de segmentação. Essas características dificultam e, em alguns casos, impedem o desenvolvimento de aplicações avançadas em TV Interativa. As técnicas desenvolvidas neste trabalho são baseadas em esquemas de descrição, compatíveis com o padrão MPEG-7, e na segmentação de programas em objetos MPEG-4. Os esquemas são utilizados para descrever a estrutura, a composição e a semântica de programas e de seus objetos componentes. Também foi definida e implantada uma infra-estrutura para produção, distribuição e consumo de programas. A utilização conjunta da infra-estrutura e das técnicas permite o desenvolvimento de aplicações avançadas em TV Interativa. Como um exemplo dessas aplicações, foi desenvolvido um serviço automático para personalizar e adaptar programas de TV Interativa, permitindo que um usuário possa acessar, sob demanda, programas especialmente produzidos para ele, contendo apenas assuntos de seu interesse e permitindo que o acesso possa ser realizado por dispositivos fixos ou móveis.},
  keywords = {adaptação de conteúdo, MPEG-4, MPEG-7, personalização, TV Interativa},
  school = {Instituto de Ciências Matemáticas e de Computação -- Universidade de São Paulo},
  year = {2003},
  advisor = {Edson dos Santos Moreira},
  address = {São Carlos, SP, } # Brazil,
  month = nov,
  abstract-en = {The work presented in this thesis developed techniques with context-awareness support, based on the MPEG-4 and MPEG-7 standards, in order to personalize and to adapt Interactive TV content. One of the challenges in this area is the development of personalized programs with rich multimedia content, high interactivity and accessibility through a variety of devices (mobile and non-mobile). Most part of the problem is that the approaches found in literature do not provide context support, do not allow separation between programs and objects descriptions and have low level of segmentation granularity. These features make difficult or impossible, in some cases, the development of Interactive TV applications. The techniques developed in this work are based on MPEG-7 compliant schemes and on programs segmentation into MPEG-4 objects. The schemes are used to describe structure, composition and semantics of programs and component objects. An infra-structure to creation, delivery and consumption of Interactive TV programs was also defined. The joint utilization of infra-structure and techniques allows for the development of Interactive TV advanced applications. As an example of these applications, this work developed an automatic Interactive TV personalization and adaptation service. This service allows a user to access, on-demand, a program specially designed to match his interests and allowing content access through devices with mobile and non-mobile features.},
  keywords-en = {content adaptation, Interactive TV, MPEG-4, MPEG-7, personalization},
  title-en = {Context-based content personalization and adaptation for Interactive {TV}}
}

@INPROCEEDINGS{Goularte-etal:2004,
  author = {Goularte, Rudinei and Cattelan, Renan G. and Camacho-Guerrero, José A. and Inácio,Jr., Valter R. and da Pimentel, Maria da Graça C.},
  title = {Interactive multimedia annotations: enriching and extending content},
  pages = {84--86},
  doi = {10.1145/1030397.1030414},
  abstract = {This paper discusses an approach to the problem of annotating multimedia content. Our approach provides annotation as metadata for indexing retrieval and semantic processing as well as content enrichment. We use an underlying model for structured multimedia descriptions and annotations allowing the establishment of spatial temporal and linking relationships. We discuss aspects related with documents and annotations used to guide the design of an application that allows annotations to be made with pen-based interaction with Tablet PCs. As a result a video stream can be annotated during the capture. The annotation can be further edited extended or played back synchronously.},
  keywords = {MPEG-7, annotation, multimodal interfaces},
  address = {New York, NY, USA},
  booktitle = {2004 ACM symposium on Document engineering},
  isbn = {1-58113-938-1},
  location = {Milwaukee, Wisconsin, #USA#},
  publisher = {ACM},
  year = {2004}
}

@MASTERSTHESIS{Rocha:1986,
  author = {Maria da Graça Brasil Rocha},
  title = {Projeto de um sistema operacional multiprogramado para ensino e aplicações didáticas},
  school = {Universidade de São Paulo -- Instituto de Ciências Matemáticas e de Computação},
  year = {1986},
  advisor = {João Antonio Zuffo},
  address = {São Carlos, SP, } # Brazil
}

@PHDTHESIS{GraciottoSilva:2012,
  author = {Graciotto Silva, Marco Aurélio},
  title = {{LOD}: uma abordagem para desenvolvimento de objetos de aprendizagem multimídias e interativos},
  school = {Universidade de São Paulo},
  year = {2012},
  advisor = {José Carlos Maldonado and Ellen Francine Barbosa},
  address = {São Carlos, SP, } # Brazil,
  month = mar,
  lang = {pt}
}

@TECHREPORT{GraciottoSilva:2011:SRP,
  author = {Graciotto Silva, Marco Aurélio},
  title = {Processo de Revisão Sistemática},
  institution = {Universidade de São Paulo -- Instituto de Ciências Matemáticas e de Computação},
  month = feb,
  year = {2011},
  address = {São Carlos, SP, } # Brazil,
  url = {http://www.icmc.usp.br/~magsilva/publications/GraciottoSilva-SRP-2011.pdf},
  note = {Relatório técnico em desenvolvimento.}
}

@MISC{GraciottoSilva:2009:PhdQual,
  author = {Graciotto Silva, Marco Aurélio},
  title = {Investigação sobre o processo de desenvolvimento de módulos educacionais para a televisão digital},
  howpublished = {Monografia de qualificação de doutorado},
  month = feb,
  year = {2009},
  abstract = {A computação há muito é vista como um importante recurso para a educação e, com os recentes avanços da área, como a popularização de computadores acessíveis e rápidos, conexões à Internet por meio de alta velocidade e televisão digital, vislumbra-se a disseminação de novas práticas pedagógicas, com ênfase na interação e colaboração entre os aprendizes, e modalidades educacionais, como educação a distância e híbrida. Em contrapartida a essa nova realidade, o processo educacional torna-se mais complexo, envolvendo questões de interatividade, comunicação, computação, pedagogia, entre outros. Uma estratégia para minimizar essa crescente complexidade é a componentização dos conteúdos educacionais e a sistematização de sua produção. Uma linha de pesquisa no sentido da componentização concentra-se nos objetos de aprendizagem: unidades instrucionais auto-suficientes, reutilizáveis em diferentes contextos formativos. A sistematização da produção é estudada com a definição de processos de referência e de modelos de qualidade, com a subseqüente especialização e instanciação do processo para a geração de conteúdo didático. Este projeto propõe a investigação de um processo padrão para o desenvolvimento de objetos de aprendizagem passíveis de utilização em plataformas multimídia e interativas, como a televisão digital e a Web, com a finalidade de ensino e treinamento. Espera-se, com a adoção de um modelo colaborativo de desenvolvimento, o devido controle do processo e de suas atividades e a produção e o uso de objetos de aprendizagem interativos para o ensino e treinamento a distância, assegurando-se a qualidade dos processos e dos produtos gerados.},
  address = {São Carlos, SP, } # Brazil,
  keywords = {objeto de aprendizagem, processo, modelo de qualidade, ensino, treinamento, multimídia, interatividade},
  lang = {pt},
  owner = {magsilva},
  pages = {96},
  timestamp = {2010.09.13},
  url = {http://www.labes.icmc.usp.br/~magsilva/publications/GraciottoSilva-2009.pdf}
}

@TECHREPORT{GraciottoSilva:2007:SysRev:PPP,
  author = {Graciotto Silva, Marco Aurélio},
  title = {Revisão sistemática sobre padrões pedagógicos},
  institution = {Laboratório de Engenharia de Software -- Instituto de Ciências Matemáticas e de Computação -- Universidade de São Paulo},
  month = nov,
  year = {2007},
  address = {São Carlos, SP, } # Brazil,
  url = {http://www.labes.icmc.usp.br/~magsilva/publications/GraciottoSilva-SysRev-PPP.pdf},
  lang = {en},
  pages = {25}
}

@MISC{GraciottoSilva:seminario:pp:2007,
  author = {Graciotto Silva, Marco Aurélio},
  title = {Padrões Educacionais},
  howpublished = {Seminário},
  month = sep,
  year = {2007},
  address = {São Carlos, SP, } # Brazil,
  owner = {magsilva},
  timestamp = {2007.11.21},
  url = {http://www.ironiacorp.com/system/files/magsilva-seminario-padroes-aprendizado.pdf}
}

@TECHREPORT{GraciottoSilva-etal:2012:LOD,
  author = {Graciotto Silva, Marco Aurélio and Ellen Francine Barbosa and José Carlos Maldonado},
  title = {Transformation rules and guidelines for learning objects generation},
  institution = {Laboratory of Software Enginering -- Institute of Mathematical Sciences and Computing -- University of São Paulo},
  year = {2012},
  address = {São Carlos, SP, } # Brazil,
  url = {http://www.icmc.usp.br/~magsilva/publications/GraciottoSilva-LOD-2011.pdf}
}

@TECHREPORT{GraciottoSilva-etal:2011:LatexMovie,
  author = {Graciotto Silva, Marco Aurélio and Ellen Francine Barbosa and José Carlos Maldonado},
  title = {Movie support for {PDF} using {LaTeX}},
  institution = {Laboratório de Engenharia de Software -- Instituto de Ciências Matemáticas e de Computação -- Universidade de São Paulo},
  month = nov,
  year = {2011},
  address = {São Carlos, SP, } # Brazil,
  url = {http://www.labes.icmc.usp.br/~magsilva/publications/GraciottoSilva-LatexMovie.pdf},
  lang = {en},
  pages = {31}
}

@TECHREPORT{GraciottoSilva-etal:2011:Screencast,
  author = {Graciotto Silva, Marco Aurélio and Ellen Francine Barbosa and José Carlos Maldonado},
  title = {Screencast recording},
  institution = {Laboratory of Software Engineering, Institute of Mathematical Sciences and Computing, University of São Paulo},
  year = {2011},
  address = {São Carlos, SP, } # Brazil,
  url = {http://www.labes.icmc.usp.br/~magsilva/publications/GraciottoSilva-ScreencastRecording.pdf},
  issn = {0103-2569},
  lang = {en}
}

@TECHREPORT{GraciottoSilva-etal:2011:SysRevCriticalFactors,
  author = {Graciotto Silva, Marco Aurélio and Ellen Francine Barbosa and José Carlos Maldonado},
  title = {Systematic review on critical factors for distance learning and e-learning (distance e-learning)},
  institution = {Laboratório de Engenharia de Software -- Instituto de Ciências Matemáticas e de Computação -- Universidade de São Paulo},
  month = nov,
  year = {2011},
  address = {São Carlos, SP, } # Brazil,
  url = {http://www.labes.icmc.usp.br/~magsilva/publications/GraciottoSilva-SysRev-ElearningCriticalFactors.pdf},
  lang = {en},
  pages = {25}
}

@TECHREPORT{GraciottoSilva-etal:2011:SysRevILO,
  author = {Graciotto Silva, Marco Aurélio and Ellen Francine Barbosa and José Carlos Maldonado},
  title = {Revisão sistemática sobre interatividade em objetos de aprendizagem},
  institution = {Universidade de São Paulo -- Instituto de Ciências Matemáticas e de Computação},
  month = may,
  year = {2011},
  address = {São Carlos, SP, } # Brazil,
  url = {http://www.icmc.usp.br/~magsilva/publications/GraciottoSilva-SysRev-ILO-2011.pdf}
}

@TECHREPORT{GraciottoSilva-etal:2010:PUCRS,
  author = {Graciotto Silva, Marco Aurélio and Ellen Francine Barbosa and José Carlos Maldonado},
  title = {Educação a Distância na {PUCRS}},
  institution = {Laboratório de Engenharia de Software -- Universidade de São Paulo -- Instituto de Ciências Matemáticas e de Computação},
  month = jun,
  year = {2010},
  address = {São Carlos, SP, } # Brazil,
  url = {http://www.icmc.usp.br/~magsilva/publications/GraciottoSilva-PUCRS-2010.pdf},
  pages = {38}
}

@INPROCEEDINGS{GraciottoSilva-Fortes:2006:wtidia,
  author = {Graciotto Silva, Marco Aurélio and Renata Pontin Mattos Fortes},
  title = {Projeto CoTeia - um auxílio à edição colaborativa na Web},
  pages = {11--14},
  booktitle = {III Workshop TIDIA},
  location = {São Paulo, SP, #Brazil#},
  year = {2006}
}

@ARTICLE{grade:2004,
  author = {{GRADE Working Group.}},
  title = {Grading quality of evidence and strength of recommendations},
  volume = {328},
  number = {7454},
  month = jun,
  year = {2004},
  pages = {1490},
  url = {http://www.ncbi.nlm.nih.gov/pubmed/15205295},
  journal = {British Medical Journal}
}

@BOOK{graham:1998,
  title = {Requirements Engineering and Rapid Development},
  publisher = {Addison-Wesley},
  year = {1998},
  author = {Ian Graham},
  edition = {1},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@MISC{rdfconcept:2004,
  author = {Graham Klyne, Jeremy J. Carroll, Brian McBride},
  title = {Resource Description Framework (RDF): Concepts and Abstract Syntax},
  howpublished = {W3C Recommendation},
  month = feb,
  year = {2004},
  comment = {24/05/2005},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://www.w3.org/TR/rdf-concepts/}
}

@MISC{software:movie15,
  author = {Alexander Grahn},
  title = {movie15},
  howpublished = software,
  url = {http://www.ctan.org/tex-archive/macros/latex/contrib/movie15/}
}

@MISC{grammatech:2000,
  author = {{GrammaTech, Inc.}},
  title = {Dependence Graphs and Program Slicing},
  howpublished = {White paper},
  month = mar,
  year = {2000},
  url = {http://www.grammatech.com/research/papers/slicing/slicingWhitepaper.html}
}

@MISC{Grammatech99JPDS,
  author = {{GRAMMATECH, Inc.}},
  title = {{JP}robe {D}eveloper {S}uite},
  year = {1999},
  owner = {magsilva},
  timestamp = {2008.07.31},
  url = {http://www.pts.com/downloads/klgroup/jprobe/JProbeSuite25.exe}
}

@MISC{gravena:2000,
  author = {Juliana Pelandré Gravena},
  title = {Aspectos importantes de uma metodologia para desenvolvimento de software com objetos distribuídos},
  howpublished = {Monografia final de curso},
  year = {2000},
  address = {Maringá-PR},
  owner = {magsilva},
  school = {Universidade Estadual de Maringá},
  timestamp = {2008.07.30}
}

@BOOK{greenhalgh,
  title = {How to Read a Paper: The Basics of Evidence-Based Medicine},
  publisher = {Wiley-Blackwell (BMJ Books)},
  year = {2010},
  author = {Trisha Greenhalgh},
  pages = {238},
  edition = {4}
}

@MISC{Gremba00IPMP,
  author = {J. Gremba},
  title = {The {IDEAL} Process Model: A Practical Guide for Improvement},
  year = {2000},
  owner = {magsilva},
  timestamp = {2008.07.31},
  url = {http://www.sei.cmu.edu/activities/ideal/ideal.bridge.html}
}

@INPROCEEDINGS{Griffiths:2000:PLI:633292.633510,
  author = {Griffiths, Richard and Pemberton, Lyn and Borchers, Jan and Stork, Adam},
  title = {Pattern languages for interaction design: building momentum},
  pages = {363--363},
  doi = {10.1145/633292.633510},
  abstract = {The potential of pattern languages as a vehicle for the dissemination of human-computer interaction design knowledge has been recognized within the CHI community (e.g. [4]), stemming from the ideas of the architect Christopher Alexander, for recording the designs of 'living buildings' [1-2]. Patterns record the invariant property that must exist in a design detail which resolves the conflicting social, cognitive, and technological forces which are ubiquitiously present in constructions of that type. Patterns are interlinked into a network (a pattern language) so that details that are required to complete a design may be identified, and the larger issues surrounding a particular design decision may be recognized.These ideas have been taken up by the object-oriented computing community [5], developments there being recorded in the series of Pattern Language of Programing (PLoP) conferences. In that community it is the usefulness of patterns as a way of recording reusable design that has dominated. However, as Alexander pointed out in an invited address to OOPSLA '96, there are other, deeper aspects to patterns. As he envisaged pattern language, it records an aesthetic of design which makes for liveness, that 'quality without a name' which supports human well-being. Alexander has challenged the computing community to explore this aspect, and clearly, there is most scope for this exploration within the CHI community. Thus this workshop will: promote the development of pattern languages for interaction design; refine and develop the application of pattern languages in this area; develop understanding of the relationship between interaction design and software engineering patterns; extend the community of pattern writers.},
  keywords = {interaction design, pattern language, patterns},
  address = {New York, NY, USA},
  booktitle = {CHI '00 extended abstracts on Human factors in computing systems},
  isbn = {1-58113-248-4},
  location = {The Hague, The Netherlands},
  publisher = {ACM},
  year = {2000}
}

@BOOK{kaj:1999,
  title = {From Web to Workplace: Designing Open Hypermedia Systems},
  publisher = {The MIT Press},
  year = {1999},
  author = {Kaj Gronbaek and Randall H. Trigg},
  editor = {Edward Barret},
  series = {Digital Communication},
  address = {Cambridge, Massachusetts},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@ARTICLE{grosso:2002,
  author = {Andrew Grosso},
  title = {Why the Digital Millenium Copyright Act Is a Failure of Reason},
  volume = {45},
  number = {2},
  month = feb,
  year = {2002},
  pages = {19-23},
  journal = {Communications of the ACM},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@INPROCEEDINGS{grosso-etal:1999,
  author = {William E. Grosso and Henrik Eriksson and Ray W. Fergerson and John H. Gennari and Samson W. Tu and Mark A. Musen},
  title = {Knowledge Modeling at the Milennium (The Design and Evolution of {Protégé-2000})},
  pages = {16-21},
  address = {Banff, Canada},
  booktitle = {Workshop on Knowledge Acquisition, Modeling and Management},
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1999}
}

@MISC{software:corba,
  author = {Object Management Group},
  title = {Common Object Request Broker Architecture (CORBA/IIOP)},
  howpublished = {Especificação},
  year = {1997},
  owner = {magsilva},
  timestamp = {2006.07.26}
}

@ARTICLE{gruber:1995,
  author = {T. R. Gruber},
  title = {Towards Principles for the Design of Ontologies used for Knowledge Sharing},
  volume = {43},
  number = {5/6},
  year = {1995},
  journal = {International Journal of Human-Computer Studies},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{gruninger-fox:1995,
  author = {M. Grüninger and M. S. Fox},
  title = {Methodology for the Design and Evaluation of Ontologies},
  booktitle = {Workshop on Basic Ontological Issues in Knowledge Sharing},
  note = {Joint event of International Joint Conference on Artificial Inteligence (IJCAI95)},
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1995}
}

@ARTICLE{gruninger-lee:2002,
  author = {M. Grüninger and J. Lee},
  title = {Ontology: Applications and Design},
  volume = {45},
  number = {2},
  year = {2002},
  pages = {39-41},
  journal = {Communications of the ACM},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@MISC{software:cel,
  author = {{Grupo de Engenharia de Requisitos (PUC-RJ)}},
  title = {C\&L: Cenários e Léxicos},
  howpublished = {Programa de Computador},
  year = {2004},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://sl.les.inf.puc-rio.br/cel/}
}

@ARTICLE{guarino:1997,
  author = {N. Guarino},
  title = {Understanding, Building and Using Ontologies},
  volume = {45},
  number = {2/3},
  year = {1997},
  journal = {International Journal of Human-Computer Studies},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@MISC{gudgeirsson:2000,
  author = {Gardar Gudgeirsson},
  title = {Requirements engineering and XML},
  month = sep,
  year = {2000},
  owner = {magsilva},
  timestamp = {2003.07.30},
  url = {http://www.raqoon.is/rqml/rqml-spec.htm}
}

@MISC{soap-1:2003,
  author = {Martin Gudgin and Marc Hadley and Noah Mendelsohn and Jean-Jacques Moreau and Henrik Frystyk Nielsen},
  title = {SOAP Version 1.2 Part 1: Messaging Framework},
  howpublished = {W3C Recommendation},
  month = jun,
  year = {2003},
  comment = {24/05/2005},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://www.w3.org/TR/soap12-part1/}
}

@MISC{soap-2:2003,
  author = {Martin Gudgin and Marc Hadley and Noah Mendelsohn and Jean-Jacques Moreau and Henrik Frystyk Nielsen},
  title = {SOAP Version 1.2 Part 2: Adjuncts},
  howpublished = {W3C Recommendation},
  month = jun,
  year = {2003},
  comment = {24/05/2005},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://www.w3.org/TR/soap12-part2/}
}

@BOOK{guezzi:1991,
  title = {Fundamentals of Software Engineering},
  publisher = {Prentice Hall},
  year = {1991},
  author = {C. Guezzi and M. Jazayeri e D. N. Mandroli},
  address = {Englewood Cliffs},
  owner = {magsilva},
  timestamp = {2006.09.20}
}

@ARTICLE{guizzardi-etal:2002,
  author = {G. Guizzardi and R. A. Falbo and J. G. Pereira Filho},
  title = {Using Objects and Patterns to Implement Domain Ontologies},
  volume = {8},
  number = {1},
  month = jul,
  year = {2002},
  journal = {Journal of the Brazilian Computer Society},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@ARTICLE{gunter:2000,
  author = {Carl A. Gunter and Elsa L. Gunter and Michael Jackson and Pamela Zave},
  title = {A Reference Model for Requirements and Specifications},
  volume = {17},
  number = {3},
  month = {may},
  year = {2000},
  pages = {37 - 43},
  doi = {10.1109/52.896248},
  journal = {IEEE Software},
  owner = {Marco Aurélio Graciotto Silva},
  timestamp = {2008.07.30}
}

@INPROCEEDINGS{gupta:2003,
  author = {Satish Chandra Gupta and Tien Nhut Nguyen and Ethan V. Munson},
  title = {The Software Concordance: Using a Uniform Document Model to Integrate Program Analysis and Hypermedia},
  pages = {164 - 173},
  address = {Chiang Mai, Thailand},
  booktitle = {Proceedings of 10th Asia-Pacific Software Engineering Conference},
  month = dec,
  owner = {magsilva},
  publisher = {IEEE Computer Society},
  timestamp = {2008.07.30},
  year = {2003}
}

@PHDTHESIS{Guttag:1975,
  author = {Guttag, John Vogel},
  title = {The specification and application to programming of abstract data types},
  school = {University of Toronto},
  year = {1975},
  address = {Toronto, } # Canada,
  publisher = {University of Toronto}
}

@ARTICLE{Guzdial:2009,
  author = {Guzdial, Mark},
  title = {Education: Teaching computing to everyone},
  volume = {52},
  number = {5},
  month = may,
  year = {2009},
  pages = {31--33},
  doi = {10.1145/1506409.1506420},
  abstract = {Studying the lessons learned from creating high-demand computer science courses for non-computing majors.}
}

@ARTICLE{guzdial:2001:sigcse,
  author = {M. Guzdial},
  title = {Using Squeak for Teaching User Interface Software},
  volume = {33},
  number = {1},
  month = feb,
  year = {2001},
  pages = {219-223},
  journal = {ACM SIGCSE 2001},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@BOOK{Guzdial01SOOD,
  title = {Squeak -- Object-Oriented Design with Multimedia Applications},
  publisher = {Prentice Hall},
  year = {2001},
  author = {M. Guzdial},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{Guzdial01UCMC,
  author = {M. Guzdial},
  title = {Use of Collaborative Multimedia in Computer Science Classes},
  pages = {17--20},
  address = {Canterbury, United Kingdom},
  booktitle = {6th Annual Conference on Innovation and Technology in Computer Science Education (ACM ITICSE 2001)},
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {2001}
}

@INPROCEEDINGS{guzdial:1999,
  author = {M. Guzdial},
  title = {Teacher and Student Authoring on the Web for Shifting Agency},
  booktitle = {AERA 99 Session: How can CSCL (Computer Supported Collaborative Learning) change classroom culture and patterns of interaction among participants?},
  comment = {19/07/2005},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://coweb.cc.gatech.edu:8888/csl/uploads/24/default.html},
  year = {1999}
}

@ARTICLE{Guzdial99SLUS,
  author = {M. Guzdial},
  title = {Supporting Learners as Users},
  volume = {23},
  number = {2},
  year = {1999},
  pages = {3--13},
  journal = {The Journal of Computer Documentation},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@MISC{software:coweb,
  author = {Mark Guzdial},
  title = {Swiki/CoWeb},
  howpublished = {Programa de Computador},
  year = {1999},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://minnow.cc.gatech.edu/swiki}
}

@INPROCEEDINGS{guzdial:1997:cscl,
  author = {M. Guzdial},
  title = {Information Ecology of Collaborations in Educational Settings: Influence of a Tool},
  pages = {83--90},
  address = {Toronto, Ontario, Canadá},
  booktitle = {Computer-Supported Colaborative Learning (CSCL 1997)},
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1997}
}

@ARTICLE{guzdial-kehoe:1998:jilr,
  author = {M. Guzdial and C. Kehoe},
  title = {Apprenticeship-based Learning Environments: A Principled Approach to Providing Software-realized Scaffolding through Hypermedia},
  volume = {9},
  number = {3/4},
  year = {1998},
  journal = {Journal of Interactive Learning Research},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@ARTICLE{guzdial-etal:2002:jls,
  author = {M. Guzdial and J. Rick and C. Kehoe},
  title = {Beyond Adoption to Invention: Teacher-Created Collaborative Activities in Higher Education},
  year = {2002},
  journal = {Journal of the Learning Sciences},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@INPROCEEDINGS{guzdial:2000,
  author = {M. Guzdial and J. Rick and B. Kerimbaev},
  title = {Recognizing and Supporting Roles in CSCW},
  pages = {261-268},
  doi = {10.1145/358916.358997},
  address = {Philadelphia, PA},
  booktitle = {ACM conference on Computer supported cooperative work},
  file = {cscw2000.1.pdf:http\://coweb.cc.gatech.edu\:8888/csl/uploads/cscw2000.1.pdf:PDF},
  owner = {magsilva},
  publisher = {ACM Press},
  timestamp = {2008.07.30},
  year = {2000}
}

@BOOK{Guzdial02SOPC,
  title = {Squeak -- Open Personal Computing and Multimedia},
  publisher = {Prentice Hall},
  year = {2002},
  author = {M. Guzdial and K. Rose},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@ARTICLE{hagge:2005,
  author = {Lars Hagge and Kathrin Lappe},
  title = {Sharing Requirements Engineering Experience Using Patterns},
  volume = {22},
  number = {1},
  month = {jan},
  year = {2005},
  pages = {24 - 31},
  journal = {IEEE Software},
  owner = {Marco Aurélio Graciotto Silva},
  timestamp = {2008.07.30}
}

@ARTICLE{hahn:2000,
  author = {Jungpil Hahn and Jinwoo Kim},
  title = {Why Are Some Diagrams Easier to Work With? Effects of Diagrammatic Representation on the Cognitive Integration Process of System Analysis and Design},
  volume = {6},
  number = {3},
  month = sep,
  year = {1999},
  pages = {181-213},
  journal = {ACM Transations on Computer-Human Interaction},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@PHDTHESIS{Haines:1965,
  author = {Haines, Leonard Harold},
  title = {Generation and recognition of formal languages},
  school = {Dept. of Mathematics -- Massachusetts Institute of Technology},
  year = {1965},
  advisor = {Noam Chomsky},
  month = jun,
  owner = {magsilva},
  timestamp = {2014.07.15}
}

@INPROCEEDINGS{Halasz-Schwartz:1990,
  author = {Frank G. Halasz and Mayer Schwartz},
  title = {The {Dexter} Hypertext Reference Model},
  pages = {30--39},
  address = {New York, NY, EUA},
  booktitle = {NIST Hypertext Standardization Workshop},
  location = {New York, NY, #USA#},
  month = jan,
  owner = {Marco Aurélio Graciotto Silva},
  publisher = {ACM},
  timestamp = {2008.07.30},
  year = {1990}
}

@ARTICLE{Haley84DAWB,
  author = {A. Haley and S. Zweben},
  title = {Development and Application of a White Box Approach to Integration Testing},
  volume = {4},
  year = {1984},
  pages = {309--315},
  journal = jss,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@ARTICLE{Hamel-RyanJones:2002,
  author = {C. J. Hamel and D. Ryan-Jones},
  title = {Designing Instruction with Learning Objects},
  volume = {3},
  number = {1},
  month = nov,
  year = {2002},
  abstract = {Discussion of online learning and standards for web-based and computer-based courseware focuses on learning objects, defined here as small, stand-alone units of instruction that can be tagged with descriptors and stored for reuse in various instructional contexts. Presents principles of learning object design and guidelines for assuring that instructional content is modular and reusable.},
  url = {http://www.ed.uiuc.edu/ijet/v3n1/hamel/index.html},
  journal = {International Journal of Educational Technology},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{Hamlet88PTIC,
  author = {D. Hamlet and R. Taylor},
  title = {Partition Testing does not Inspire Confidence},
  pages = {206--215},
  address = {Banff, Canadá},
  booktitle = {II Workshop on Software Testing, Verification and Analysis},
  month = jul,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1998}
}

@ARTICLE{Hamlet77TPAC,
  author = {R. G. Hamlet},
  title = {Testing Programs with the Aid of a Compiler},
  volume = {SE-3},
  number = {4},
  month = jul,
  year = {1977},
  pages = {279--290},
  journal = ieeese,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{hand:2004,
  author = {Tim Hand},
  title = {Learning Objects: User Perspectives on the Conditions Surrounding Their Use},
  pages = { 66--72 },
  address = { Lugano, Switzerland },
  booktitle = {Proceedings of World Conference on Educational Multimedia, Hypermedia and Telecommunications 2004},
  editor = { Lorenzo Cantoni and Catherine McLoughlin },
  publisher = { AACE },
  url = { http://go.editlib.org/p/12912 },
  year = {2004}
}

@ARTICLE{hannay-etal:2007,
  author = {Jo E. Hannay and Dag I. K. Sjøberg and Tore Dybå},
  title = {A Systematic Review of Theory Use in Software Engineering Experiments},
  volume = {33},
  number = {2},
  month = feb,
  year = {2007},
  pages = {87-107},
  abstract = {Empirically based theories are generally perceived as foundational to science. However, in many disciplines, the nature, role and even the necessity of theories remain matters for debate, particularly in young or practical disciplines such as software engineering. This article reports a systematic review of the explicit use of theory in a comprehensive set of 103 articles reporting experiments, from of a total of 5,453 articles published in major software engineering journals and conferences in the decade 1993-2002. Of the 103 articles, 24 use a total of 40 theories in various ways to explain the cause-effect relationship(s) under investigation. The majority of these use theory in the experimental design to justify research questions and hypotheses, some use theory to provide post hoc explanations of their results, and a few test or modify theory. A third of the theories are proposed by authors of the reviewed articles. The interdisciplinary nature of the theories used is greater than that of research in software engineering in general. We found that theory use and awareness of theoretical issues are present, but that theory-driven research is, as yet, not a major issue in empirical software engineering. Several articles comment explicitly on the lack of relevant theory. We call for an increased awareness of the potential benefits of involving theory, when feasible. To support software engineering researchers who wish to use theory, we show which of the reviewed articles on which topics use which theories for what purposes, as well as details of the theories' characteristics.},
  journal = {IEEE Transactions on Software Engineering}
}

@ARTICLE{hansen2003cae,
  author = {R. Hansen and S. C. C. S. Pinto},
  title = {{Construindo Ambientes de Educação Baseada na Web Através de Web Services Educacionais}},
  year = {2003},
  journal = {XIV Simpósio Brasileiro de Informática na Educação (SBIE)},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@ARTICLE{Harasim96VNLE,
  author = {L. Harasim and T. Calvert and T. Collings},
  title = {{Virtual-U}: A Networked Learning Environment for Continuing Engineering Education},
  volume = {47},
  number = {2},
  year = {1996},
  journal = {The BC Professional Engineer},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{Harel:1997,
  author = {Harel, David},
  title = {Some thoughts on statecharts, 13 years later},
  pages = {226--231},
  doi = {10.1007/3-540-63166-6_23},
  volume = {1254},
  series = {Lecture Notes in Computer Science},
  affiliation = {The Weizmann Institute of Science Rehovot Israel Rehovot Israel},
  booktitle = {Computer Aided Verification},
  editor = {Grumberg, Orna},
  publisher = {Springer Berlin / Heidelberg},
  year = {1997}
}

@INBOOK{Harel:1996,
  pages = {285-285},
  title = {Statecharts: Past, present, future},
  publisher = {Springer},
  year = {1996},
  editor = {Jeffery, Keith and Král, Jaroslav and Bartosek, Miroslav},
  author = {David Harel},
  volume = {1175},
  series = {Lecture Notes in Computer Science},
  affiliation = {The Weizmann Institute of Science Rehovot Israel Rehovot Israel},
  booktitle = {SOFSEM'96: Theory and Practice of Informatics},
  doi = {10.1007/BFb0037410}
}

@ARTICLE{Harel:2009,
  author = {Harel, David},
  title = {Statecharts in the making: a personal account},
  volume = {52},
  number = {3},
  year = {2009},
  pages = {67--75},
  doi = {10.1145/1467247.1467274},
  address = {New York, NY, USA},
  issn = {0001-0782},
  journal = {Communications of the ACM},
  publisher = {ACM}
}

@INPROCEEDINGS{Harel:2007,
  author = {Harel, David},
  title = {Statecharts in the making: a personal account},
  pages = {5-1--5-43},
  doi = {10.1145/1238844.1238849},
  address = {New York, NY, USA},
  booktitle = {HOPL III: Proceedings of the third ACM SIGPLAN conference on History of programming languages},
  isbn = {978-1-59593-766-X},
  location = {San Diego, California},
  publisher = {ACM},
  year = {2007}
}

@ARTICLE{Harel:1992,
  author = {D. Harel},
  title = {Bitting the Silver Bullet -- Toward a Brighter Future for Systems Development},
  month = jan,
  year = {1992},
  pages = {8--20},
  journal = {IEEE Computer},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@ARTICLE{Harel:1988,
  author = {Harel, David},
  title = {On visual formalisms},
  volume = {31},
  number = {5},
  month = may,
  year = {1988},
  pages = {514--530},
  doi = {10.1145/42411.42414},
  abstract = {The higraph, a general kind of diagramming object, forms a visual formalism of topological nature. Higraphs are suited for a wide array of applications to databases, knowledge representation, and, most notably, the behavioral specification of complex concurrent systems using the higraph-based language of statecharts.},
  address = {New York, NY, USA},
  issn = {0001-0782},
  journal = {Commun. ACM},
  publisher = {ACM}
}

@ARTICLE{Harel:1987,
  author = {D. Harel},
  title = {Statecharts: A Visual Formalism for Complex Systems},
  volume = {8},
  number = {3},
  month = jun,
  year = {1987},
  pages = {231--274},
  journal = {Science of Computer Programming},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@INPROCEEDINGS{Harel-Gery:1996,
  author = {Harel, D. and Gery, E.},
  title = {Executable object modeling with statecharts},
  pages = {246 -257},
  doi = {10.1109/ICSE.1996.493420},
  abstract = {This paper reports on an effort to develop an integrated set of diagrammatic languages for modeling object-oriented systems, and to construct a supporting tool. The goal is for models to be intuitive and well-structured, yet fully executable and analyzable, enabling automatic synthesis of usable and efficient code in object-oriented languages such as C++. At the heart of the modeling method is the language of statecharts for specifying object behavior, and a hierarchical OMT-like language for describing the structure of classes and their inter-relationships, that we call O-charts. Objects can interact by event generation, or by direct invocation of operations. In the interest of keeping the exposition manageable, we leave out some technically involved topics, such as multiple-thread concurrency and active objects },
  keywords = {C++;O-charts;active objects;diagrammatic languages;direct invocation;executable object modeling;hierarchical OMT-like language;integrated set;multiple-thread concurrency;object-oriented languages;object-oriented systems;statecharts;object-oriented languages;object-oriented programming;software tools;},
  booktitle = {18th International Conference on Software Engineering},
  location = {Berlin, #Germany#},
  month = mar,
  publisher = {IEEE},
  year = {1996}
}

@ARTICLE{Harel-GordonKiwkowitz:2009,
  author = {Harel, D. and Gordon-Kiwkowitz, M.},
  title = {On Teaching Visual Formalisms},
  volume = {26},
  number = {3},
  month = may,
  year = {2009},
  pages = {87 -95},
  doi = {10.1109/MS.2009.76},
  abstract = {In the spring semester of the 2004-2005 academic year at the Weizmann Institute of Science, coauthor David Harel delivered the graduate course Executable Visual Languages for System Development. It is a course on visual formalisms for reactive systems emphasized using such languages for not only specification and requirements but also (and predominantly) actual execution.},
  keywords = {Executable Visual Languages for System Development;Weizmann Institute of Science;formal specification;graduate course;interobject approach;intraobject approach;reactive systems;system requirements;teaching;visual formalism;computer science education;educational courses;formal specification;object-oriented programming;teaching;visual languages;},
  issn = {0740-7459},
  journal = {Software, IEEE}
}

@INPROCEEDINGS{Harel-etal:1988,
  author = {David Harel and Hagi Lachover and Amnon Naamad and Amir Pnueli and Michal Politi and Rivi Sherman and Aharon Shtull-Trauring},
  title = {{STATEMATE}: a working environment for the development of complex reactive systems},
  pages = {396--406},
  abstract = {This paper provides a brief overview of the STATEMATE system, constructed over the past three years by i-Logix Inc., and Ad Cad Ltd. STATEMATE is a graphical working environment, intended for the specification, analysis, design and documentation of large and complex reactive systems, such as real-time embedded systems, control and communication systems, and interactive software. It enables a user to prepare, analyze and debug diagrammatic, yet precise, descriptions of the system under development from three inter-related points of view, capturing, structure, functionality and behavior. These views are represented by three graphical languages, the most intricate of which is the language of statecharts used to depict reactive behavior over time. In addition to the use of state-charts, the main novelty of STATEMATE is in the fact that it `understands` the entire descriptions perfectly, to the point of being able to analyze them for crucial dynamic properties, to carry out rigorous animated executions and simulations of the described system, and to create running code automatically. These features are invaluable when it comes to the quality and reliability of the final outcome.},
  address = {Los Alamitos, CA, USA},
  booktitle = {10th International Conference on Software Engineering},
  isbn = {0-89791-258-6},
  location = {Singapore},
  month = apr,
  publisher = {IEEE Computer Society},
  year = {1988}
}

@ARTICLE{Harel-etal:1990,
  author = {D. Harel and H. Lachover and A. Naamad and A. Pnueli and M. Politi and R. Sherman and A. Shtull-Trauting and M. Trakhtenbrot},
  title = {{STATEMATE}: A Working Environment for the Development of Complex Reactive Systems},
  volume = {16},
  number = {4},
  month = apr,
  year = {1990},
  pages = {403--414},
  doi = {10.1109/32.54292},
  abstract = {STATEMATE is a set of tools, with a heavy graphical orientation, intended for the specification, analysis, design, and documentation of large and complex reactive systems. It enables a user to prepare, analyze, and debug diagrammatic, yet precise, descriptions of the system under development from three interrelated points of view, capturing structure, functionality, and behavior. These views are represented by three graphical languages, the most intricate of which is the language of statecharts, used to depict reactive behavior over time. In addition to the use of statecharts, the main novelty of STATEMATE is in the fact that it understands the entire descriptions perfectly, to the point of being able to analyze them for crucial dynamic properties, to carry out rigorous executions and simulations of the described system, and to create running code automatically. These features are invaluable when it comes to the quality and reliability of the final outcome.},
  journal = {IEEE Transactions on Software Engineering},
  owner = {magsilva},
  publisher = {IEEE Computer Society},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{Harel-etal:1987,
  author = {David Harel and Amir Pnueli and Jeanette P. Schmidt and Rivi Sherman},
  title = {On the Formal Semantics of Statecharts},
  pages = {54--64},
  booktitle = {Symposium on Logic in Computer Science},
  isbn = {0-8186-0793-6},
  location = {Ithaca, NY, #USA#},
  month = jun,
  publisher = {IEEE Computer Society},
  year = {1987}
}

@BOOK{Harman-Koohang:2007,
  title = {Learning Objects: Applications, Implications, \& Future Directions},
  publisher = {Informing Science},
  year = {2007},
  author = {Keith Harman and Alex Koohang},
  editor = {Keith Harman and Alex Koohang},
  isbn = {83-922337-8-6},
  pages = {483},
  series = {Learning Objects},
  address = {Santa Rosa, California, USA},
  booktitle = {Learning Objects: Applications, Implications, \& Future Directions}
}

@INPROCEEDINGS{Harman-Danicic:1997,
  author = {M. Harman and S. Danicic},
  title = {Amorphous Program Slicing},
  pages = {70--79},
  address = {Dearborn, Michigan},
  booktitle = {5th IEEE International Workshop on Program Comprehesion (IWPC'97)},
  month = may,
  owner = {magsilva},
  publisher = {IEEE Computer Society Press},
  timestamp = {2008.07.31},
  year = {1997}
}

@INPROCEEDINGS{Harman-etal:1999b,
  author = {M. Harman and C. Fox and R. M. Hierons and D. Binkley and S. Danicic},
  title = {Program Simplification as a Means of Approximating Undecidable Propositions},
  pages = {208--217},
  address = {Pittsburgh, Pennsylvania},
  booktitle = {7th IEEE International Workshop on Program Comprehesion (IWPC'99)},
  month = may,
  owner = {magsilva},
  publisher = {IEEE Computer Society Press},
  timestamp = {2008.07.31},
  year = {1999}
}

@INPROCEEDINGS{Harman-etal:2000,
  author = {M. Harman and R. Hierons and S. Danicic},
  title = {The Relationship Between Program Dependence and Mutation Analysis},
  pages = {5--12},
  address = {San Jose, CA},
  booktitle = {Mutation 2000 Symposium},
  month = oct,
  owner = {magsilva},
  publisher = {Kluwer Academic Publishers},
  timestamp = {2008.07.31},
  year = {2000}
}

@INPROCEEDINGS{Harman-etal:1999a,
  author = {M. Harman and R. Hierons and M. Holcombe and B. Jones and S. Reid and M. Roper and M. Woodward},
  title = {Towards a Maturity Model for Empirical Studies of Software Testing},
  address = {Keble College, Oxford, UK},
  booktitle = {Fifth Workshop on Empirical Studies of Software Maintenance (WESS'99)},
  month = sep,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1999}
}

@INPROCEEDINGS{Harper-etal:2005,
  author = {Barry Harper and Sue Bennett and Jason Lukasiak and Lori Lockyer},
  title = {Learning Designs to Support Educationally Effective E-learning Using Learning Objects},
  pages = {4732--4738},
  abstract = {This paper describes a design approach for integrating learning objects based on a strong pedagogical framework, the Smart Learning Design Framework (SLDF). The framework is based on the assumptions that good learning settings focus on pedagogically sound design and that reusable learning objects can be effectively located and incorporated into learning settings. This paper describes a tool developed to illustrate the framework through metadata tagging of learning objects using an application profile which incorporates a pedagogical vocabulary, and development of units of study based on high quality learning designs and the inclusion of learning objects.},
  address = { Montreal, Canada },
  booktitle = {World Conference on Educational Multimedia, Hypermedia and Telecommunications},
  editor = {Piet Kommers and Griff Richards},
  month = {June},
  owner = {magsilva},
  publisher = {AACE},
  url = { http://go.editlib.org/p/20825 },
  year = {2005}
}

@INPROCEEDINGS{Harrold:2000,
  author = {Mary Jean Harrold},
  title = {Testing: A Roadmap},
  pages = {61--72},
  doi = {10.1145/336512.336532},
  abstract = {Testing is an important process that is performed to support quality assurance. Testing activities support quality assurance by gathering information about the nature of the software being studied. These activities consist of designing test cases, executing the software with those test cases, and examining the results produced by those executions. Studies indicate that more than fifty percent of the cost of software development is devoted to testing, with the percentage for testing critical software being even higher. As software becomes more pervasive and is used more often to perform critical tasks, it will be required to be of higher quality. Unless we can find efficient ways to perform effective testing, the percentage of development costs devoted to testing will increase significantly. This report briefly assesses the state of the art in software testing, outlines some future directions in software testing, and gives some pointers to software testing resources.},
  series = {ICSE},
  address = {New York, NY, USA},
  booktitle = {International Conference on Software Engineering},
  isbn = {1-58113-253-0},
  location = {Limerick, Ireland},
  month = jun,
  owner = {magsilva},
  publisher = {ACM},
  timestamp = {2009.04.22},
  year = {2000}
}

@INPROCEEDINGS{Harrold99AATC,
  author = {M. J. Harrold and D. Liang and S. Sinha},
  title = {An Approach To Analyzing and Testing Component-Based Systems},
  address = {Los Angeles, CA},
  booktitle = {First International ICSE Workshop on Testing Distributed Component-Based Systems},
  month = may,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1999}
}

@INPROCEEDINGS{Harrold92ITOO,
  author = {M. J. Harrold and J. D. McGregor and K. J. Fitzpatrick},
  title = {Incremental Testing of Object-oriented Class Structures},
  pages = {68--80},
  address = {Los Alamitos, CA},
  booktitle = {14th International Conference on Software Engineering},
  month = may,
  owner = {magsilva},
  publisher = {IEEE Computer Society Press},
  timestamp = {2008.07.31},
  year = {1992}
}

@INPROCEEDINGS{harrold-rothermel:1994,
  author = {M. J. Harrold and G. Rothermel},
  title = {Performing Data Flow Testing on Classes},
  pages = {154--163},
  address = {New York},
  booktitle = {ACM SIGSOFT Symposium on Foundations of Software Engineering},
  month = dec,
  owner = {magsilva},
  publisher = {ACM Press},
  timestamp = {2008.07.31},
  year = {1994}
}

@ARTICLE{Harrold91SUDI,
  author = {M. J. Harrold and M. L. Soffa},
  title = {Selecting and Using Data for Integration Test},
  volume = {8},
  number = {2},
  month = mar,
  year = {1991},
  pages = {58--65},
  journal = ieees,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{Harrold89IDFT,
  author = {M. J. Harrold and M. L. Soffa},
  title = {Interprocedural Data Flow Testing},
  pages = {158--167},
  booktitle = {Third Testing, Analysis, and Verification Symposium},
  month = dec,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1989}
}

@ARTICLE{Hartmann90TSRE,
  author = {J. Hartmann and D. J. Robson},
  title = {Techniques for Selective Revalidation},
  month = jan,
  year = {1990},
  pages = {31--36},
  journal = ieees,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@MISC{software:flashmovie,
  author = {Timo Hartmann},
  title = {flashmovie},
  howpublished = software,
  month = dec,
  year = {2009},
  url = {http://tug.ctan.org/tex-archive/macros/latex/contrib/flashmovie/}
}

@ARTICLE{Hasheminejad-Jalili:2012,
  author = {Seyed Mohammad Hossein Hasheminejad and Saeed Jalili},
  title = {Design patterns selection: An automatic two-phase method},
  volume = {85},
  number = {2},
  year = {2012},
  pages = {408 - 424},
  doi = {10.1016/j.jss.2011.08.031},
  abstract = {Over many years of research and practices in software development, hundreds of software design patterns have been invented and published. Now, a question which naturally arises is how software developers select the right design patterns from all relevant patterns to solve design problems in the software design phase. To address this issue, in this paper, we propose a two-phase method to select a right design pattern. The proposed method is based on a text classification approach that aims to show an appropriate way to suggest the right design pattern(s) to developers for solving each given design problem. There are two advantages of the proposed method in comparison to previous works. First, there is no need for semi-formal specifications of design patterns and second, the suitable design patterns are suggested with their degree of similarity to the design problem. To evaluate the proposed method, we apply it on real problems and several case studies. The experimental results show that the proposed method is promising and effective.},
  keywords = {Software design pattern, Text classification, Machine learning, Automatic pattern selection},
  issn = {0164-1212},
  journal = {Journal of Systems and Software},
  lang = {en}
}

@ARTICLE{Hassenzahl-Tractinsky:2006,
  author = {M. Hassenzahl and N. Tractinsky},
  title = {User experience -- a research agenda},
  volume = {25},
  number = {2},
  year = {2006},
  pages = {91-97},
  doi = {10.1080/01449290500330331},
  abstract = {Over the last decade, 'user experience' (UX) became a buzzword in the field of human - computer interaction (HCI) and interaction design. As technology matured, interactive products became not only more useful and usable, but also fashionable, fascinating things to desire. Driven by the impression that a narrow focus on interactive products as tools does not capture the variety and emerging aspects of technology use, practitioners and researchers alike, seem to readily embrace the notion of UX as a viable alternative to traditional HCI. And, indeed, the term promises change and a fresh look, without being too specific about its definite meaning. The present introduction to the special issue on 'Empirical studies of the user experience' attempts to give a provisional answer to the question of what is meant by 'the user experience'. It provides a cursory sketch of UX and how we think UX research will look like in the future. It is not so much meant as a forecast of the future, but as a proposal - a stimulus for further UX research.},
  journal = {Behaviour \& Information Technology}
}

@INPROCEEDINGS{Hatala-etal:2004,
  author = {Hatala, Marek and Richards, Griff and Eap, Timmy and Willms, Jordan},
  title = {The interoperability of learning object repositories and services: standards, implementations and lessons learned},
  pages = {19--27},
  doi = {10.1145/1013367.1013371},
  abstract = {Interoperability is one of the main issues in creating a networked system of repositories. The eduSource project in its holisticapproach to building a network of learning object repositories in Canada is implementing an open network for learning services. Itsopenness is supported by a communication protocol called theeduSource Communications Layer (ECL) which closely implements the IMS Digital Repository Interoperability (DRI)specification and architecture. The ECL in conjunction withconnection middleware enables any service providers to join thenetwork. EduSource is open to external initiatives as it explicitlysupports an extensible bridging mechanism between eduSource and other major initiatives. This paper discusses interoperability in general and then focuses on the design of ECL as animplementation of IMS DRI with supporting infrastructure andmiddleware. The eduSource implementation is in the mature stateof its development as being deployed in different settings withdifferent partners. Two applications used in evaluating ourapproach are described: a gateway for connecting betweeneduSource and the NSDL initiative, and a federated searchconnecting eduSource, EdNA and SMETE.},
  keywords = {interoperability, learning object repositories},
  address = {New York, NY, USA},
  booktitle = {International World Wide Web conference},
  isbn = {1-58113-912-8},
  location = {New York, NY, USA},
  publisher = {ACM},
  year = {2004}
}

@INPROCEEDINGS{Hattori:2011,
  author = {Hattori, Takashi},
  title = {Wikigramming: a wiki-based training environment for programming},
  pages = {7--12},
  doi = {10.1145/1984701.1984703},
  abstract = {Wiki is one of the most successful technologies in Web 2.0 because it is so simple that anyone can start using it instantly. The main aim of this research is to realize a collaborative programming environment that is as simple as Wiki. Each Wiki page contains source code of a Scheme function which is executed on the server. Users can edit any function at any time without complicated procedure, and see the results of their changes instantly. In order to avoid intentional or unintentional destruction of working programs, when users attempt to modify existing functions, the modified version must pass unit tests written by other users. Though changes are made anonymously, we can have some confidence if test cases are written by many users.},
  keywords = {programming environment, training, unit test, wiki},
  series = {Web2SE '11},
  acmid = {1984703},
  address = {New York, NY, USA},
  booktitle = {International workshop on Web 2.0 for Software Engineering},
  isbn = {978-1-4503-0595-2},
  location = {Waikiki, Honolulu, HI, USA},
  numpages = {6},
  publisher = {ACM},
  year = {2011}
}

@ARTICLE{Hawthorne:2009,
  author = {Hawthorne, Elizabeth K.},
  title = {Exploring CAP-space: the next frontier in curricula, assessment and pedagogy},
  volume = {41},
  number = {2},
  month = jun,
  year = {2009},
  pages = {76--77},
  doi = {10.1145/1595453.1595472}
}

@INPROCEEDINGS{hayes:2004,
  author = {Jane Huffman Hayes and Alex Dekhtyar and Senthil Karthikeyan Sundaram and Sarah Howard},
  title = {Helping Analysts Trace Requirements: An Objective Look},
  pages = {249-259},
  address = {Kyoto, Japão},
  booktitle = {International Requirements Engineering Conference},
  owner = {Marco Aurélio Graciotto Silva},
  publisher = {IEEE Computer Society},
  timestamp = {2008.07.30},
  year = {2004}
}

@INPROCEEDINGS{hazzan-etal:2006,
  author = {Orit Hazzan and Yael Dubinsky and Larisa Eidelman and Victoria Sakhnini and Mariana Teif},
  title = {Qualitative Research in Computer Science Education},
  pages = {408-412},
  booktitle = {SIGSSE},
  timestamp = {2008.09.23},
  year = {2006}
}

@BOOK{Hecht77FACP,
  title = {Flow Analysis of Computer Programs},
  publisher = {North Holland},
  year = {1977},
  author = {M. S. Hecht},
  address = {New York},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{Hedberg-Iivari:2009,
  author = {Hedberg, Henrik and Iivari, Netta},
  title = {Integrating HCI Specialists into Open Source Software Development Projects},
  pages = {251--263},
  doi = {10.1007/978-3-642-02032-2_22},
  abstract = {Typical open source software (OSS) development projects are organized around technically talented developers, whose communication is based on technical aspects and source code. Decision-making power is gained through proven competence and activity in the project, and non-technical end-user opinions are too many times neglected. In addition, also human-computer interaction (HCI) specialists have encountered difficulties in trying to participate in OSS projects, because there seems to be no clear authority and responsibility for them. In this paper, based on HCI and OSS literature, we introduce an extended OSS development project organization model that adds a new level of communication and roles for attending human aspects of software. The proposed model makes the existence of HCI specialists visible in the projects, and promotes interaction between developers and the HCI specialists in the course of a project.},
  volume = {299},
  series = {IFIP Advances in Information and Communication Technology},
  booktitle = {IFIP WG2.12 International Conference on Open Source Systems},
  editor = {Boldyreff, Cornelia and Crowston, Kevin and Lundell, Björn and Wasserman, Anthony},
  isbn = {978-3-642-02031-5},
  publisher = {Springer},
  year = {2009}
}

@MISC{software:doxygen,
  author = {Dimitri van Heesch and others},
  title = {Doxygen},
  year = {1997},
  owner = {magsilva},
  timestamp = {2006.11.07},
  url = {http://www.doxygen.org}
}

@MISC{software:listings,
  author = {Carsten Heinz and Brooks Moses},
  title = {listings},
  howpublished = software,
  note = {Typset source code listings using LaTeX},
  owner = {magsilva},
  timestamp = {2010.08.31},
  url = {http://tug.ctan.org/tex-archive/macros/latex/contrib/listings/}
}

@INPROCEEDINGS{Heiyanthuduwage-Karunaratne:2007,
  author = {Heiyanthuduwage, S. R. and Karunaratne, D. D.},
  title = {A Learner Oriented Ontology to Make Effective Learning Management Systems},
  pages = {476 -481},
  doi = {10.1109/ICDIM.2007.369239},
  abstract = {An ontology has been proposed in this paper, which arranges metadata, and defines the relationships of metadata on learning objects belong to academic courses and user profiles. This ontology has been incorporated with proposed architecture, as a critical part of this architecture what consists of a set of components which synergies to achieve a higher usability to the learner. The ontology is utilized for effective retrieval of learning content, customizing learning management systems (LMS), and an integrating learning content to reuse them. It has been specified in ontology inference language (OIL) and in resource description framework (RDF) for exchange of ontology. The ontology and user profile management components have been introduced into a typical open sourced LMS. Proposed ontology maps user preferences with learning content in searching learning object and amalgamates them to build new course objects. Hence it increases the learner- orientation and usability of e-learning systems.},
  keywords = {academic course;e-learning system usability;learner oriented ontology;learning content retrieval;learning management system;learning object;meta data;ontology inference language;resource description framework;user preference mapping;user profile management;computer aided instruction;educational courses;human factors;meta data;ontologies (artificial intelligence);},
  booktitle = {International Conference on Digital Information Management},
  location = {Lyon, France},
  month = dec,
  year = {2007}
}

@INPROCEEDINGS{helferich-etal:2005,
  author = {Andreas Helferich and Georg Herzwurm and Sixten Schockert},
  title = {QFD-PPP: Product Line Portfolio Planning Using Quality Function Deployment},
  pages = {162-173},
  doi = {10.1007/11554844_19},
  abstract = {In today's competitive business environment, it is extremely important to offer customers exactly the products they want. Software product lines have the potential to enable companies to offer a large variety of products while still being able to manage the complexity caused by this increased number of products. But offering a large range of variants does not necessarily mean increased profits, as many manufacturing companies had to notice in the early 1990ies. The task of Product Portfolio Planning is the development of a product portfolio that optimally satisfies customer demands and at the same time restricts the number of products offered. Quality Function Deployment (QFD) is a well-known and successfully used Quality Management method that can help companies to identify true customer needs and the features needed to fulfil these needs. This paper demonstrates how QFD can be used for Product Portfolio Planning, thus offering potentially great benefits.},
  volume = {3714},
  series = {Lecture Notes on Computer Science},
  booktitle = {International Conference on Software Product Lines (SPLC)},
  owner = {magsilva},
  publisher = {Springer},
  timestamp = {2010.07.13},
  year = {2005}
}

@ARTICLE{henderson:2000,
  author = {Lisa G. R. Henderson},
  title = {Requirements Elicitation in Open-Source Programs},
  volume = {7},
  month = jul,
  year = {2000},
  url = {http://www.stsc.hill.af.mil/crosstalk/2000/07/henderson.html},
  journal = {CrossTalk: The Journal of Defense Software Engineering},
  owner = {Marco Aurélio Graciotto Silva},
  timestamp = {2008.07.30}
}

@INPROCEEDINGS{Herigstad-Wichansky:1998,
  author = {Herigstad, Dale and Wichansky, Anna},
  title = {Designing user interfaces for television},
  pages = {165--166},
  doi = {10.1145/286498.286645},
  keywords = {Internet appliance, UI design, World Wide Web, kiosk, remote control, television, usability evaluation},
  booktitle = {Conference on Human Factors in Computing Systems},
  isbn = {1-58113-028-7},
  location = {Los Angeles, California, #USA#},
  month = apr,
  publisher = {ACM},
  year = {1998}
}

@ARTICLE{Herman:1976,
  author = {P. M. Herman},
  title = {A Data Flow Analysis Approach to Program Testing},
  volume = {8},
  number = {3},
  month = nov,
  year = {1976},
  pages = {347-354},
  journal = {Australian Computer Journal}
}

@MISC{software:moinmoin,
  author = {Juergen Hermann},
  title = {MoinMoin},
  howpublished = {Programa de Computador},
  year = {2000},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://moinmoin.wikiwikiweb.de/MoinMoin}
}

@INPROCEEDINGS{HernandezLeo-etal:2004,
  author = {D. Hernández-Leo and J. I. A. Perez and Y. A. Dimitriadis},
  title = {IMS learning design support for the formalization of collaborative learning patterns},
  pages = {350-354},
  keywords = {computer aided instruction, groupware CSCL, IMS learning design support, collaborative learning pattern, computer-supported collaborative learning, group-based learning, pedagogical approach},
  booktitle = {International Conference on Advanced Learning Technologies},
  owner = {magsilva},
  timestamp = {2008.07.30},
  year = {2004}
}

@ARTICLE{HernandezLeo-etal:2006,
  author = {D. Hernández-Leo and E. D. Villasclaras-Fernández and J. I. Asensio-Pérez and Y. Dimitriadis and I. M. Jorrín-Abellán and I. Ruiz-Requies and B. Rubia-Avi},
  title = {{COLLAGE}, a Collaborative Learning Design Editor Based on Patterns},
  volume = {9},
  number = {1},
  year = {2006},
  journal = {Educational Technology \& Society},
  owner = {magsilva},
  timestamp = {2008.09.26}
}

@TECHREPORT{Hicks-Foster:2010:maryland,
  author = {Michael Hicks and Jeffrey S. Foster},
  title = {Adapting {Scrum} to Managing a Research Group},
  institution = {Department of Computer Science, University of Maryland},
  month = sep,
  year = {2010},
  number = {CS-TR-4966},
  address = USA,
  url = {http://www.cs.umd.edu/~mwh/papers/score.pdf},
  review = {Some how, SCORE brings separation of concerns to Ph.D. educational process: status and research. These two do not mix: either a meeting is for status; either it is for research. Research meetings also only take place after a status meeting. Thus, every research meeting is focuses on a specific problem, which provides a better fullfillement of the time spent.},
  type = {Technical report}
}

@ARTICLE{Hierholzer-Wiener:1873,
  author = {Hierholzer, Carl and Wiener, Chr},
  title = {Ueber die Möglichkeit, einen Linienzug ohne Wiederholung und ohne Unterbrechung zu umfahren},
  volume = {6},
  number = {1},
  year = {1873},
  pages = {30--32},
  doi = {10.1007/BF01442866},
  abstract = {Die folgende Untersuchung trug der leider so früh dem Dienste der Wissenschaft durch den Tod entrissene Privatdocent Dr. Hierholzer dahier (gest. 13. Sept. 1871) einem Kreise befreundeter Mathematiker vor. Um sie vor Vergessenheit zu bewahren, musste sie bei dem Mangel jeder schriftlichen Aufzeichnung aus dem Gedächtniss wieder hergestellt werden, was ich unter Beihilfe meines verehrten Collegen Lüroth durch das Folgende möglichst getreu auszuführen suchte.},
  issn = {0025-5831},
  journal = {Mathematische Annalen},
  language = {German},
  publisher = {Springer-Verlag},
  timestamp = {2013-09-24}
}

@ARTICLE{Hierons-etal:1999,
  author = {R. M. Hierons and M. Harman and S. Danicic},
  title = {Using Program Slicing to Assist in the Detection of Equivalent Mutants},
  volume = {9},
  number = {4},
  year = {1999},
  pages = {233--262},
  journal = stvr,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@TECHREPORT{hefce:05:2008,
  author = {Centre for Higher Education Research and Information (CHERI, The Open University)},
  title = {Interim evaluation of Lifelong Learning Networks},
  institution = {HEFCE},
  month = apr,
  year = {2008},
  owner = {magsilva},
  timestamp = {2009.08.24},
  type = {Research and evaluation report}
}

@INPROCEEDINGS{Hilburn-Townhidnejad:2000,
  author = {Hilburn, Thomas B. and Townhidnejad, Massood},
  title = {Software quality: a curriculum postscript?},
  pages = {167--171},
  doi = {10.1145/330908.331848},
  abstract = {This paper addresses a central and critical issue in the development of computer software - its quality. The main thesis of the paper is that computer science faculty, in their design and implementation of curricula, do not devote sufficient attention to teaching their students how to develop high-quality software. As in industry, the most common and popular way of assuring the quality of programs is through software testing. In other words, quality is treated as an afterthought or as postscript in program development. The paper presents and discusses a quality model that can be used to incorporate a wide variety of quality assurance techniques within a curriculum. The model also presents a structured approach for introducing software testing into the educational environment. Finally, there is a discussion of how the model has been implemented using two current software process technologies, the PSP and the TSP.},
  booktitle = {Proceedings of the thirty-first SIGCSE technical symposium on Computer science education},
  isbn = {1-58113-213-1},
  location = {Austin, Texas, United States},
  publisher = {ACM},
  year = {2000}
}

@INPROCEEDINGS{hodgins:2000,
  author = {H. W. Hodgins},
  title = {The Future of Learning Objects},
  booktitle = {The Instructional Use of Learning Objects},
  owner = {magsilva},
  publisher = {D. A. Wiley},
  timestamp = {2008.07.31},
  year = {2000}
}

@INPROCEEDINGS{Vanderhoek00CMOS,
  author = {A. Van der Hoek},
  title = {Configuration Management and Open Source Projects},
  address = {Limerick, Ireland},
  booktitle = {3nd Workshop on Software Engineering over the Internet at ICSE 2000},
  month = jun,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {2000}
}

@ARTICLE{Hoffman97CFAC,
  author = {D. Hoffman and P. Strooper},
  title = {{ClassBrench}: A Framework for Automated Class Testing},
  month = may,
  year = {1997},
  pages = {573--597},
  journal = spe,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{Hoffman93CSCT,
  author = {D. Hoffman and P. Strooper},
  title = {A Case Study In Class Testing},
  pages = {472--482},
  address = {IBM Toronto Laboratory},
  booktitle = {CASCON 93},
  month = oct,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1993}
}

@INPROCEEDINGS{hoffman-berger:2000,
  author = {J. Hoffman and S. Berger},
  title = {Strategic Product Family Development by Extending the House of Quality},
  pages = {287-296},
  abstract = {Frequently, the market demands products provided with equal or similar functionality, that should be available for different customer groups. This market behaviour appears e.g. in the image processing field, where scanners, editing equipment, etc. are sold both to professional and amateur users. Because the product functions don't differ much from each other, or they are even the same, it is suitable to apply the same operating principles with variably, scaled specifications. However, the planning of such a product family occurs insufficient systematically in many companies and the products belonging to a determinate family grow without any co-ordination between themselves. The lack of delimitation of each single product and the non-using of synergy effects through model range design lead into loss of competition capability and market share. Initiated by this problem, a QFD-assisted instrument for defining a structured product family was developed. The benefit from using thisinstrument consists of an integrating view of all products belonging to a family on the one hand, and a strict customer orientation on the other hand. Moreover, this procedure offers the possibility of systematically defining and developing a complete product family corresponding to a company's objective, e.g. cost reduction, technology leadership or adaptation to a niche market. The instrument derives from the QFD-Quality plan and the House of Quality. Outstanding feature is the extension of the House of Quality by several specification classes as well as subsystems. It is possible, by the introduction of specification classes instead of the simple, classic target value, to analyse the specifications of different products within a family at a glance and define them in a coordinated, interactive way. The extension by subsystems offers beyond the possibility of defining the specifications corresponding to the company's objective. The developed instrument was proved on an exposer forthe printing preliminary stage at a German company as an example.},
  booktitle = {International Symposium on QFD},
  owner = {magsilva},
  timestamp = {2010.07.13},
  year = {2000}
}

@ARTICLE{Hoffman-etal:2008,
  author = {Hoffman, R.R. and Ziebell, D. and Fiore, S.M. and Becerra-Fernandez, I.},
  title = {Knowledge Management Revisited},
  volume = {23},
  number = {3},
  month = may # {-} # jun,
  year = {2008},
  pages = {84 -88},
  doi = {10.1109/MIS.2008.51},
  abstract = {A number of social, economic, technological, and scientific trends have led to the emergence of communities of practice centered on the notion of the knowledge-based organization. However, the scientific foundation (knowledge elicitation methodology) and the commercial growth of knowledge management (KM) have largely developed in parallel. So, the creation of human-centered systems faces lingering challenges. In the KM process, company management establishes a program whereby experts who possess valuable knowledge collaborate with a knowledge engineer. Working together, they elicit the expert's wisdom for inclusion in the organization's knowledge base.},
  keywords = {expert system;groupware;human-centered system;knowledge management;knowledge-based organization;expert systems;groupware;knowledge management;},
  issn = {1541-1672},
  journal = {IEEE Intelligent Systems},
  publisher = {IEEE}
}

@INPROCEEDINGS{hoffmann:2004,
  author = {Matthias Hoffmann and Nikolaus Kühn and Matthias Weber and Margot Bittner},
  title = {Requirements for Requirements Management Tools},
  pages = {301-308},
  address = {Kyoto, Japão},
  booktitle = {International Requirements Engineering Conference (RE'04)},
  month = sep,
  owner = {magsilva},
  publisher = {IEEE Computer Society},
  timestamp = {2008.07.30},
  year = {2004}
}

@INPROCEEDINGS{hogeboom-etal:2005,
  author = {Hogeboom, M. and Fuhua Lin and Esmahi, L. and Chunsheng Yang},
  title = {Constructing knowledge bases for e-learning using Protege 2000 and Web services},
  pages = {215-220},
  doi = {10.1109/AINA.2005.141},
  abstract = { This paper presents an approach to designing and developing knowledge bases in e-learning systems. We explore the use of Protege 2000 as a knowledge editor for course material, with the addition of Web service interfaces on top of it to facilitate retrieval of the content. Protege 2000 provides an extensible infrastructure and allows the easy construction of domain ontologies, customized data entry forms, and provides an API that can easily be extended by Web services for the purpose of dynamic course material creation. The use of ontology and Web services makes the knowledge bases for e-learning sharable, reusable, and interoperable with other technologies, such as .Net, which have standard Web service implementations.},
  keywords = { Internet, Java, application program interfaces, courseware, distance learning, information retrieval, knowledge based systems, ontologies (artificial intelligence) .Net, API, Protege 2000, Web services, course material, data entry form, e-learning systems, knowledge base construction, knowledge editor, ontology},
  volume = {1},
  booktitle = {International Conference on Advanced Information Networking and Applications (AINA)},
  issn = {1550-445X },
  owner = {magsilva},
  timestamp = {2008.07.30},
  year = {2005}
}

@MASTERSTHESIS{hohn:2003,
  author = {Erika Nina Höhn},
  title = {Técnicas de leitura de especificação de requisitos de software: estudos empíricos e gerência de conhecimento em ambientes acadêmico e industrial},
  school = {Universidade de São Paulo},
  year = {2003},
  address = {São Carlos, Brasil},
  owner = {magsilva},
  timestamp = {2008.01.31}
}

@BOOK{aurelio:1999,
  title = {Aurélio Século XXI: O Dicionário da Língua Portuguesa},
  publisher = {Nova Fronteira},
  year = {1999},
  author = {Aurélio Buarque de Holanda Ferreira and others},
  editor = {Editora Nova Fronteira},
  edition = {3},
  owner = {Marco Aurélio Graciotto Silva},
  timestamp = {2008.07.30}
}

@ARTICLE{Holzinger-Errath:2004,
  author = {Andreas Holzinger and Maximilian Errath},
  title = {Designing Web-Applications for Mobile Computers: Experiences with Applications to Medicine},
  volume = {3196},
  year = {2004},
  pages = {262-267},
  doi = {10.1007/978-3-540-30111-0_22},
  abstract = {Designing Web-applications is considerably different for handhelds than for desktop computers. Screen size is limited, browsers further limit the visible content area and users interact differently. Detecting handheld-browsers on the server side and delivering pages optimized for a small client form factor is inevitable. The authors discuss their experiences during the design and development of an application for medical research which was designed for both handhelds and desktops. It is important to include mobile computing design considerations into 'User Interfaces for All'.},
  keywords = {Information Interfaces and Representation; Life and Medical Sciences; Internet Applications; Mobile Computing},
  address = {Berlin},
  journal = {User-Centered Interaction Paradigms for Universal Access in the Information Society, Lecture Notes in Computer Science},
  publisher = {Springer-Verlag},
  timestamp = {2008.10.02}
}

@ARTICLE{Holzinger-etal:2006,
  author = {Andreas Holzinger and Alexander Nischelwitzer and Matthias Meisenberger},
  title = {Lifelong-learning support by m-learning: example scenarios},
  volume = {11},
  month = nov,
  year = {2005},
  pages = {2},
  doi = {10.1145/1125280.1125284},
  journal = {eLearn Magazine},
  publisher = {ACM},
  timestamp = {2008.10.01}
}

@INPROCEEDINGS{hood-hood:2005,
  author = {Cynthia S. Hood and Dennis J. Hood},
  title = {Toward integrating computing concepts into the K-12 curriculum},
  pages = {375--375},
  doi = {10.1145/1067445.1067576},
  address = {New York, NY, USA},
  booktitle = {Annual SIGCSE Conference on Innovation and Technology in Computer Science Education (ITiCSE)},
  isbn = {1-59593-024-8},
  location = {Caparica, Portugal},
  owner = {magsilva},
  publisher = {ACM},
  timestamp = {2008.07.30},
  year = {2005}
}

@BOOK{Hopcroft-Ullman:1969,
  title = {Formal Languages and Their Relation to Automata},
  publisher = {Addison-Wesley},
  year = {1969},
  author = {Hopcroft, John E. and Ullman, Jeffrey D.},
  series = {Computer Science and Information Processing},
  address = {Boston, MA, } # USA,
  owner = {magsilva},
  timestamp = {2014.07.15}
}

@INPROCEEDINGS{horgan-london:1991,
  author = {J. R. Horgan and S. London},
  title = {Data Flow Coverage and the {C} Language},
  pages = {87--97},
  address = {Victoria, Canada},
  booktitle = {International Symposium on Software Testing and Analysis},
  month = oct,
  owner = {magsilva},
  publisher = {ACM},
  timestamp = {2008.07.31},
  year = {1991}
}

@MISC{software:atac,
  author = {J. R. Horgan and S. A. London},
  title = {{ATAC} -- Automatic Test Coverage Analysis for C Programs},
  howpublished = software,
  year = {1992},
  comment = {BellCore},
  url = {http://invisible-island.net/atac/atac.html}
}

@ARTICLE{Horgan92ATTR,
  author = {J. R. Horgan and P. Mathur},
  title = {Assessing Testing Tools in Research and Education},
  volume = {9},
  number = {3},
  month = may,
  year = {1992},
  pages = {61--69},
  journal = ieees,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@BOOK{Horn:1989,
  title = {Mapping Hypertext: The Analysis, Organization, and Display of Knowledge for the Next Generation of On-Line Text and Graphics},
  publisher = {Lexington Institute},
  year = {1989},
  author = {Robert E. Horn},
  isbn = {978-0962556500},
  pages = {283},
  booktitle = {Mapping Hypertext: The Analysis, Organization, and Display of Knowledge for the Next Generation of On-Line Text and Graphics},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@MISC{project:ideaisRHAE,
  author = {Yvone Maria Mascarenhas Hornos},
  title = {Criar um processo de gestão e ferramentas para empresas de base tecnológica, organizadas em um cluster, visando o trabalho integrado, colaborativo no desenvolvimento de solução, envolvendo software, hardware e serviços},
  howpublished = {Plano},
  year = {2004},
  owner = {magsilva},
  timestamp = {2006.05.30}
}

@MISC{dom2view:2000,
  author = {Arnaud Le Hors and Laurence Cable},
  title = {Document Object Model (DOM) Level 2 Views Specification},
  howpublished = {W3C Recommendation},
  month = nov,
  year = {2000},
  file = {Document Object Model (DOM) Level 2 Views Specification.pdf:Document Object Model (DOM) Level 2 Views Specification.pdf:PDF},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://www.w3.org/TR/DOM-Level-2-Views/}
}

@MISC{dom2core:2000,
  author = {Arnaud Le Hors and Philippe Le Hégaret and Lauren Wood and Gavin Nicol and Jonathan Robie and Mike Champion and Steve Byrne},
  title = {Document Object Model (DOM) Level 2 Core Specificatio},
  howpublished = {W3C Recommendation},
  month = nov,
  year = {2000},
  comment = {24/05/2005},
  file = {Document Object Model (DOM) Level 2 Core Specification.pdf:Document Object Model (DOM) Level 2 Core Specification.pdf:PDF},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://www.w3.org/TR/DOM-Level-2-Core/}
}

@MISC{dom3core:2004,
  author = {Arnaud Le Hors and Philippe Le Hégaret and Lauren Wood and Gavin Nicol and Jonathan Robie and Mike Champion and Steve Byrve},
  title = {Document Object Model (DOM) Level 3 Core Specification},
  howpublished = {W3C Recommendation},
  month = apr,
  year = {2004},
  comment = {24/05/2005},
  file = {Document Object Model (DOM) Level 3 Core Specification.pdf:Document Object Model (DOM) Level 3 Core Specification.pdf:PDF},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://www.w3.org/TR/DOM-Level-3-Core/}
}

@BOOK{howden:1987,
  title = {Functional Program Testing and Analysis},
  publisher = {McGrall-Hill},
  year = {1987},
  author = {William E. Howden},
  series = {Software Engineering and Technology},
  address = {New York, NY},
  owner = {magsilva},
  timestamp = {2009.04.29}
}

@ARTICLE{howden:1985,
  author = {William E. Howden},
  title = {The Theory and Practice of Foundation Testing},
  volume = {2},
  number = {5},
  month = sep,
  year = {1985},
  pages = {6-17},
  doi = {10.1109/MS.1985.231754},
  abstract = {Viewing programs as syntheses of requirements, design, and programming functions allows programmers to address a wide variety of errors -- even subtle and difficult-to-find missing code faults.},
  issn = {0740-7459},
  journal = {IEEE Software}
}

@ARTICLE{howden:1982,
  author = {William E. Howden},
  title = {Weak Mutation Testing and Completeness of Test Sets},
  volume = {8},
  number = {4},
  month = jul,
  year = {1982},
  pages = {371--379},
  journal = {IEEE Transactions on Software Engineering},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@ARTICLE{howden:1978,
  author = {William E. Howden},
  title = {Theoretical and Empirical Studies of Program Testing},
  volume = {4},
  number = {4},
  month = jul,
  year = {1978},
  pages = {293--298},
  doi = {10.1109/TSE.1978.231514},
  abstract = {Two approaches to the study of program testing are described. One approach is theoretical and the other empirical. In the theoretical approach situations are characterized in which it is possible to use testing to formally prove the correctness of programs or the correctness of properties of programs. In the empirical approach statistics are collected which record the frequency with which different testing strategies reveal the errors in a collection of programs. A summary of the results of two research projects which investigated these approaches are presented. The differences between the two approaches are discussed and their relative advantages and disadvantages are compared.},
  journal = {IEEE Transactions on Software Engineering},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@ARTICLE{howden:1976,
  author = {William E. Howden},
  title = {Reliability of the Path Analysis Testing Strategy},
  volume = {2},
  number = {3},
  month = sep,
  year = {1976},
  pages = {208--214},
  journal = {IEEE Transactions on Software Engineering},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@ARTICLE{howden:1975,
  author = {William E. Howden},
  title = {Methodology for the Generation of Program Test Data},
  volume = {24},
  number = {5},
  month = may,
  year = {1975},
  pages = {554-560},
  journal = ieeec,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@ARTICLE{Hu:2011,
  author = {Hu, Chenglie},
  title = {When to inherit a type: what we do know and what we might not},
  volume = {2},
  number = {2},
  month = jun,
  year = {2011},
  pages = {52--58},
  doi = {10.1145/1963533.1963550},
  abstract = {Meaningful applications of inheritance are critical in devising good object-oriented solutions. Yet, not being able to use effectively and correctly inheritance in problem solving is perhaps the most significant impediment for students to become competitive object-oriented thinkers. This article provides a summary of common uses of type inheritance. It also describes the situations where type inheritance can be inappropriate or, at least, subject to reevaluation. More importantly, it brings an attention to the distinction between the mechanics and the semantics of inheritance. The article closes with an example that illustrates the use of inheritance in light of other alternatives. Finally, the article briefly discusses the implications.},
  keywords = {Object-orientation, object aggregation, type inheritance},
  acmid = {1963550},
  issue = {2},
  issue_date = {June 2011},
  lang = {en},
  numpages = {7}
}

@INPROCEEDINGS{Huang-etal:2007,
  author = {Huang, Shihong and Gohel, Vaishali and Hsu, Sam},
  title = {Towards interoperability of UML tools for exchanging high-fidelity diagrams},
  pages = {134--141},
  doi = {10.1145/1297144.1297172},
  abstract = {In today's global software engineering projects, where development activities are distributed geographically and temporally, it is increasingly important for CASE tools to maintain the information (both syntactic and semantic) captured in the design models. The Unified Modeling Language (UML) is the de facto standard for modeling software applications and UML diagrams serve as graphical documentations of the software system. The interoperability of UML modeling tools is important in supporting the model exchange. Tool interoperability is often implemented using XML Metadata Interchange (XMI). Unfortunately, there is a loss of fidelity of the design documentation when transforming between UML and XMI due to the compatibility of different versions of UML, XMI and add-on proprietary information, which hinder reuse. This paper reports on an ongoing study evaluating the interoperability of UML modeling tools by assessing the quality of XMI documents representing the design. Case studies in the paper demonstrate a framework of preserving the fidelity of UML models data when importing and exporting different UML models in a distributed heterogeneous environment.},
  keywords = {design reuse, graphical documentation, interoperability, model exchange, uml, xmi},
  address = {New York, NY, USA},
  booktitle = {25th International Conference on Design of Communication},
  isbn = {978-1-59593-588-5},
  location = {El Paso, Texas, #USA#},
  month = oct,
  publisher = {ACM},
  year = {2007}
}

@INPROCEEDINGS{Hulsen-etal:2004,
  author = {Hulsen, P and Kim, J. G. and Lee, H. K and Kang, K. O.},
  title = {Delivering {T}-learning with {TV}-anytime through packaging},
  pages = {614-619},
  doi = {10.1109/ISCE.2004.1376021},
  abstract = {Computer and Web-based learning applications are becoming more important. This paper describes fhe problems with today's so-called E-learning systems: they are not capable of delivering true high-quality video, they lack interactivity and control of the video, and they are not capable of adjusting to user's preferences and consuming environments. Packaging, which is part of the TV-Anytime Specifications, is introduced to solve these problems.},
  keywords = {personal digital recorder, interactive television, learning, removable media},
  address = {Reading, } # UK,
  booktitle = {International Symposium on Consumer Electronics},
  isbn = {0-7803-8527-6},
  location = {Reading, #UK#},
  month = sep,
  publisher = {IEEE},
  timestamp = {2012.02.10},
  year = {2004}
}

@TECHREPORT{standard:cmu:cmm:1.0,
  author = {Humphrey, Watts and Sweet, William},
  title = {A Method for Assessing the Software Engineering Capability of Contractors},
  institution = {Software Engineering Institute -- Carnegie Mellon University},
  month = sep,
  year = {1987},
  number = {CMU/SEI-87-TR-023},
  address = USA,
  url = {http://www.sei.cmu.edu/library/abstracts/reports/87tr023.cfm},
  abstract = {This document provides guidelines and procedures for assessing the ability of potential DoD contractors to develop software in accordance with modern software engineering methods. It includes specific questions and a method for evaluating the results.}
}

@BOOK{Humphrey:2005,
  title = {{PSP}: A Self-Improvement Process for Software Engineering},
  publisher = {Addison-Wesley},
  year = {2005},
  author = {Watts S. Humphrey},
  isbn = {0-321-30549-3},
  pages = {346},
  address = USA,
  edition = {1},
  owner = {magsilva},
  timestamp = {2014.09.28}
}

@BOOK{Humphrey:1995,
  title = {A Discipline for Software Engineering},
  publisher = {Addison-Wesles Longman},
  year = {1995},
  author = {Humphrey, Watts S.},
  isbn = {0201546108},
  pages = {816},
  series = {SEI Series in Software Engineering},
  address = {Boston, MA, } # USA,
  edition = {1},
  abstract = {This new work from Watts Humphrey, author of the influential book, Managing the Software Process, broadens his orderly view of software process management, and lays the foundation for a disciplined approach to software engineering. In his earlier book, the author developed concrete methods for managing software development and maintenance. These methods, now commonly practiced in industry, provide programmers and managers with specific steps they can take to evaluate and improve their software capabilities. In this new book, Humphrey scales those methods down to a personal level, helping software engineers develop the skills and habits needed to plan, track, and analyze large, complex projects. Humphrey and others have used material from this book to train professionals and students around the world in a projects-oriented software engineering course. First establishing the need for discipline in software engineering, and the benefits to practitioners of learning how to manage their personal software process, Humphrey then develops a model that they can use to monitor, test, and improve their work. Examples drawn from industry enhance the practical focus of the book, while project exercises give readers the opportunity to practice software process management as they learn it. Features: presents concepts and methods for a disciplined software engineering process; scales down industrial practices for planning, tracking, analysis, and defect management to fit the needs of small-scale program development; and shows how small project disciplines provide a solid base for larger projects.}
}

@BOOK{Humphrey:1989,
  title = {Managing the Software Process},
  publisher = {Addison-Wesley},
  year = {1989},
  author = {Watts S. Humphrey},
  isbn = {978-0201180954},
  pages = {512},
  address = {Boston, MA, } # USA,
  month = jan,
  abstract = {The author, drawing on years of experience at IBM and the SEI, provides here practical guidance for improving the software development and maintenance process. He focuses on understanding and managing the software process because this is where he feels organizations now encounter the most serious problems, and where he feels there is the best opportunity for significant improvement. Both program managers and practicing programmers, whether working on small programs or large-scale projects, will learn how good their own software process is, how they can make their process better, and where they need to begin.},
  booktitle = {Managing the Software Process}
}

@INPROCEEDINGS{hunt:2001,
  author = {James J. Hunt and Jurgen Reuter},
  title = {Using the Web for Document Versioning: An Implementation Report for Delta V},
  pages = {507-513},
  booktitle = {International Conference on Software Engineering},
  owner = {magsilva},
  timestamp = {2008.07.30},
  year = {2001}
}

@ARTICLE{hunter:2002,
  author = {Bob Hunter and Martin Fowler and Gregor Hohpe},
  title = {Agile EAI Methods: Minimizing Risk, Maximizing ROI},
  month = jul,
  year = {2002},
  pages = {32-35},
  journal = {Resource Magazine},
  owner = {magsilva},
  timestamp = {2006.04.19}
}

@INPROCEEDINGS{Huo03MASE,
  author = {Q. Huo and H. Zhu and S. Greenwood},
  title = {A Multi-Agent Software Environment for Testing Web-based Applications},
  booktitle = {27th Annual International Computer Software and Applications Conference (COMPSAC03)},
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {2003}
}

@INPROCEEDINGS{hurst-etal:2007,
  author = {Hürst, Wolfgang and Welte, Martina and Jung, Sabine},
  title = {An evaluation of the mobile usage of e-lecture podcasts},
  pages = {16--23},
  doi = {10.1145/1378063.1378067},
  abstract = {Distributing recorded classroom lectures via podcasting for replay on mobile devices is gaining increasing popularity. However, few insights exist regarding the actual usage and usefulness of such files, especially in situations where high-quality recordings of those lectures are available for non-mobile replay as well. In this paper, we compare the results of two surveys done with local students who had access to podcasts as well as high-quality files for replay on laptops and desktop PCs on the one hand and external users who just subscribed to the podcasts on the other hand. We compare the usage of the different versions, address the motivations of the two different user groups, and discuss general issues such as perception of the quality of the audio and video signals. Based on our observations we conclude that the added value of such "e-lecture podcasts" is mainly in its potential for mobile usage, whereas most of the other arguments given in favor of such an e-lecture delivery are rather due to the better visibility and "advertisement" of podcasts then justifiable by the technology involved.},
  keywords = {apple iPod, e-lectures, e-lectures podcasts, educational multimedia, lecture casting, lecture recordings, mobile media players, user study},
  series = {Mobility '07},
  acmid = {1378067},
  address = {New York, NY, USA},
  booktitle = {Proceedings of the 4th international conference on mobile technology, applications, and systems and the 1st international symposium on Computer human interaction in mobile technology},
  isbn = {978-1-59593-819-0},
  location = {Singapore},
  numpages = {8},
  publisher = {ACM},
  year = {2007}
}

@INPROCEEDINGS{HurtadoAlegria-etal:2011,
  author = {Hurtado Alegría, Julio A. and Bastarrica, María Cecilia and Quispe, Alcides and Ochoa, Sergio F.},
  title = {An {MDE} approach to software process tailoring},
  pages = {43--52},
  doi = {10.1145/1987875.1987885},
  abstract = {Defining organizational processes is essential for enhancing maturity. However the best process depends on the particularities of each project. Typically a process engineer defines a specific process for each project in an ad-hoc fashion, which is expensive, unrepeatable and error prone. Trying to deal with this challenge we propose a model-based approach to software process tailoring that generates project specific processes based on the organizational process and the project context. The approach is systematic, repeatable and it does not depend on the people using it. The proposal has been applied for tailoring the Requirements Engineering process of a medium size company. The obtained results were validated by process engineers of the company. Processes obtained using the proposed approach matched the ones used in the company for planned contexts and also they were reasonable for non-expected situations.},
  keywords = {model-driven engineering, software process lines, tailoring},
  series = {ICSSP},
  address = {Honolulu, HI, } # USA,
  booktitle = {2011 International Conference on Software and Systems Process},
  isbn = {978-1-4503-0730-7},
  lang = {en},
  publisher = {ACM},
  year = {2011}
}

@ARTICLE{hussain2005sol,
  author = {Hussain, N. and Khan, MK},
  title = {{Service-Oriented E-Learning Architecture Using Web Service-Based Intelligent Agents}},
  year = {2005},
  pages = {137--143},
  journal = {Information and Communication Technologies, 2005. ICICT 2005. First International Conference on},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@BOOK{Husted04JACT,
  title = {JUnit in Action},
  publisher = {Manning Publications},
  year = {2004},
  author = {T. Husted and V. Massol},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@INPROCEEDINGS{Hutchinson-etal:2011,
  author = {Hutchinson, John and Whittle, Jon and Rouncefield, Mark and Kristoffersen, Steinar},
  title = {Empirical assessment of MDE in industry},
  pages = {471--480},
  doi = {10.1145/1985793.1985858},
  abstract = {This paper presents some initial results from a twelve-month empirical research study of model driven engineering (MDE). Using largely qualitative questionnaire and interview methods we investigate and document a range of technical, organizational and social factors that apparently influence organizational responses to MDE: specifically, its perception as a successful or unsuccessful organizational intervention. We then outline a range of lessons learned. Whilst, as with all qualitative research, these lessons should be interpreted with care, they should also be seen as providing a greater understanding of MDE practice in industry, as well as shedding light on the varied, and occasionally surprising, social, technical and organizational factors that affect success and failure. We conclude by suggesting how the next phase of the research will attempt to investigate some of these issues from a different angle and in greater depth.},
  keywords = {empirical software engineering, model driven engineering},
  series = {ICSE '11},
  acmid = {1985858},
  address = {New York, NY, USA},
  isbn = {978-1-4503-0445-0},
  lang = {en},
  numpages = {10}
}

@MISC{huzita:1995,
  author = {Elisa Hatsue Moriya Huzita},
  title = {Uma Metodologia para Auxiliar o Desenvolvimento de Aplicações para Processamento Paralelo},
  howpublished = {Tese de doutorado},
  year = {1995 },
  address = {São Paulo-SP},
  owner = {magsilva},
  school = {Universidade de São Paulo},
  timestamp = {2008.07.30}
}

@MISC{huzita:1999,
  author = {Elisa Hatsue Moriya Huzita},
  title = {Uma Metodologia de Desenvolvimento Baseado em Objetos Distribuídos Inteligentes},
  howpublished = {Projeto de Pesquisa},
  year = {1999},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@MISC{software:poppler,
  author = {Kristian Høgsberg and Albert Astals Cid and others},
  title = {Poppler},
  howpublished = software,
  year = {2005},
  url = {http://poppler.freedesktop.org/}
}

@MISC{ibge:2009,
  author = {{IBGE}},
  title = {Síntese de Indicadores Sociais: Uma Análise das Condições de Vida da População Brasileira},
  year = {2009},
  address = {Rio de Janeiro, RJ, } # Brazil,
  isbn = {978-85-240-4089-4},
  organization = {IBGE},
  url = {http://biblioteca.ibge.gov.br/visualizacao/monografias/GEBIS%20-%20RJ/sintese_indic/indic_sociais2009.pdf},
  urlaccessdate = {20 fev 2012}
}

@MISC{standard:bpel4ws,
  author = {{IBM} and {BEA Systems} and {Microsoft} and {SAP AG} and {Siebel Systems}},
  title = {Business Process Execution Language for Web Services version 1.1},
  howpublished = {Padrão},
  month = feb,
  year = {2007},
  timestamp = {2009.02.05},
  url = {http://www.ibm.com/developerworks/library/specification/ws-bpel/}
}

@MISC{software:requisitepro,
  author = {{IBM Rational}},
  title = {RequisitePro},
  howpublished = {Programa de Computador},
  month = jun,
  year = {2003},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://www-306.ibm.com/software/awdtools/reqpro/}
}

@BOOK{Swebok:2014,
  title = {Guide to the Software Engineering Body of Knowledge ({SWEBOK}) V3.0},
  publisher = {IEEE Computer Society},
  year = {2004},
  author = {{IEEE}},
  editor = {Pierre Bourque and Richard E. Fairley},
  isbn = {978-0-7695-5166-1},
  address = USA,
  url = {http://www.swebok.org/}
}

@TECHREPORT{IeeeISVL,
  author = {IEEE},
  title = {{IEEE Standard VHDL Language Reference Manual}},
  institution = {IEEE Press},
  year = {-},
  number = {-},
  owner = {magsilva},
  timestamp = {2008.07.31},
  type = {Standard}
}

@MISC{standard:ieee:828:2012,
  author = {{IEEE}},
  title = {{IEEE} 828-2012 -- {IEEE} standard for configuration management in systems and software engineering},
  howpublished = standard,
  month = mar,
  year = {2012},
  doi = {10.1109/IEEESTD.2012.6170935},
  isbn = {978-0-7381-7232-3},
  pages = {71}
}

@MISC{standard:ieee:1484.20.1:2007,
  author = {{IEEE}},
  title = {IEEE Standard for Learning Technology - Data Model for Reusable Competency Definitions ({IEEE} 1484.20.1-2007)},
  howpublished = {Standard},
  year = {2008},
  abstract = {This Standard defines a data model for describing, referencing, and sharing competency definitions, primarily in the context of online and distributed learning. This Standard provides a way to represent formally the key characteristics of a competency, independently of its use in any particular context. It enables interoperability among learning systems that deal with competency information by providing a means for them to refer to common definitions with common meanings.},
  doi = {10.1109/IEEESTD.2008.4445693},
  isbn = {978-0-7381-5695-8, 978-0-7381-5696-5},
  pages = {26}
}

@MISC{standard:ieee:1484.12.3:2005,
  author = {{IEEE}},
  title = {{IEEE} Standard for Learning Technology -- Extensible Markup Language ({XML}) Schema Definition Language Binding for Learning Object Metadata ({IEEE} 1484.12.3)},
  howpublished = Standard,
  month = nov,
  year = {2005},
  number = {1484.12.1},
  owner = {magsilva},
  timestamp = {2008.07.31},
  type = {Draft Standard}
}

@MISC{standard:ieee:1484.11.1:2004,
  author = {{IEEE}},
  title = {{IEEE} Standard for Learning Technology -- Data Model for Content to Learning Management System Communication ({IEEE} 1484.11.1-2004)},
  howpublished = {Standard},
  year = {2004},
  timestamp = {2008.09.27}
}

@MISC{standard:ieee:1484.11.2:2003,
  author = {{IEEE}},
  title = {{IEEE} Standard for Learning Technology - {ECMAScript} application programming interface for content to runtime services communication ({IEEE} 1484.11.2)},
  howpublished = {Standard},
  year = {2004},
  timestamp = {2008.09.27}
}

@MISC{standard:ieee:1484.12.1:2002,
  author = {{IEEE}},
  title = {{IEEE} Standard for Learning Object Metadata ({IEEE} 1484.12.1)},
  month = jun,
  year = {2002},
  doi = {10.1109/IEEESTD.2002.94128},
  e-isbn = {0-7381-3297-7},
  isbn = {0-7381-3298-5},
  number = {1484.12.1},
  owner = {magsilva},
  timestamp = {2008.07.31},
  type = {Draft Standard}
}

@MISC{standard:ieee:1484.12.2:2002,
  author = {{IEEE}},
  title = {{IEEE} Standard for {ISO/IEC} 11404 binding for Learning Object Metadata data model},
  month = jun,
  year = {2002},
  number = {1484.12.1},
  owner = {magsilva},
  timestamp = {2008.07.31},
  type = {Draft Standard}
}

@MISC{standard:ieee:829:1998,
  author = {{IEEE}},
  title = {{IEEE} 829-1998 -- {IEEE} standard for software test documentation},
  howpublished = {Standard},
  month = sep,
  year = {1998},
  owner = {magsilva},
  timestamp = {2009.04.22}
}

@MISC{standard:ieee:830:1998,
  author = {{IEEE}},
  title = {IEEE Recommended Practice for Software Requirements Specifications (IEEE Std 830-1998)},
  howpublished = {Standard},
  month = jun,
  year = {1998},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@MISC{standard:ieee:610.12:1990,
  author = {{IEEE}},
  title = {{IEEE} Standard Glossary of Software Engineering Terminology},
  howpublished = {Standard},
  month = sep,
  year = {1990},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@MISC{ieeeiea:1998,
  author = {IEEE and IEA},
  title = {Industry Implementation of Internacional Standard ISO/IEC 12207:1995},
  howpublished = {IEEE/EIA Guide},
  month = apr,
  year = {1998},
  owner = {Marco Aurélio Graciotto Silva},
  timestamp = {2008.07.30}
}

@BOOK{swebok:2004,
  title = {Software Engineering Body of Knowledge (SWEBOK)},
  publisher = {Angela Burgess},
  year = {2004},
  author = {{IEEE Computer Society}},
  editor = {Pierre Bourque and Robert Dupuis},
  address = {EUA},
  owner = {Marco Aurélio Graciotto Silva},
  timestamp = {2008.07.30},
  url = {http://www.swebok.org/}
}

@MISC{Ieee03CCSE,
  author = {{IEEE Computer Society and Association for Computing Machinery}},
  title = {{Computing Curricula -- Software Engineering, Draft Version}},
  month = jul,
  year = {2003},
  owner = {magsilva},
  timestamp = {2008.07.31},
  url = {http://www.computer.org/education/cc2001/}
}

@INPROCEEDINGS{im-etal:2006,
  author = {Im, SeungHyun and Lee, SiHwa and Wu, XiaoLi and Lee, ManHyoung and Hwang, DaeHoon},
  title = {Design and Implementation of SCORM Content Conversion System for DiTV},
  pages = {679--684},
  doi = {10.1109/ICHIT.2006.107},
  abstract = {Recently, the main topic in e-learning domain and industry is called digital convergence whose core demand is OSMU (One Source Multi Use). However, there exists so many learning contents in Web, and with the development of new learning content which must adapt the new learning environment, the problem about cost and time appears. So in this paper we design and implement a JAVA based content conversion system which has the ability of interoperability, reuse and highly-use to convert the SCORM-based learning content into MHP-based DiTV content in order to adapt t-learning environment using DiTV. Using this system, the problem about the e-learning content which has been mentioned above can be solved well. Moreover, it is possible for a person who is not familiar with computer to study using DiTV but not PC.},
  volume = {2},
  series = {ICHIT '06},
  acmid = {1193601},
  address = {Washington, DC, USA},
  booktitle = {International Conference on Hybrid Information Technology},
  isbn = {0-7695-2674-8},
  numpages = {6},
  publisher = {IEEE Computer Society},
  year = {2006}
}

@MISC{standard:ims:cc,
  author = {{IMS}},
  title = {Common Cartridge},
  howpublished = Standard,
  month = oct,
  year = {2011},
  timestamp = {2008.09.27},
  url = {http://www.imsglobal.org/cc/},
  urlaccessdate = {20 fev 2012}
}

@MISC{standard:ims:cp,
  author = {{IMS}},
  title = {Content Package Specification},
  howpublished = Standard,
  month = mar,
  year = {2007},
  timestamp = {2008.09.27},
  url = {http://www.imsglobal.org/content/packaging/},
  urlaccessdate = {20 fev 2012}
}

@MISC{standard:ims:dr,
  author = {{IMS}},
  title = {Digital Repositories Specification},
  howpublished = {Standard},
  month = jan,
  year = {2003},
  timestamp = {2008.09.27},
  url = {http://www.imsglobal.org/digitalrepositories/},
  urlaccessdate = {20 fev 2012}
}

@MISC{standard:ims:ld,
  author = {{IMS}},
  title = {Learning Design Specification},
  howpublished = Standard,
  month = jan,
  year = {2003},
  timestamp = {2008.09.27},
  url = {http://www.imsglobal.org/learningdesign/},
  urlaccessdate = {20 fev 2012}
}

@MISC{standard:ims:ss,
  author = {{IMS}},
  title = {Simple Sequencing Specification},
  howpublished = Standard,
  month = mar,
  year = {2003},
  timestamp = {2008.09.27},
  url = {http://www.imsglobal.org/simplesequencing/},
  urlaccessdate = {20 fev 2012}
}

@MISC{ims:2004,
  author = {{IMS Global Learning Consortium}},
  title = {IMS Project},
  howpublished = {Projet},
  year = {2004},
  owner = {magsilva},
  timestamp = {2008.02.01},
  url = {http://www.imsproject.org/}
}

@INPROCEEDINGS{Inaba-etal:2002,
  author = {Inaba, A. and Ohkubo, R. and Ikeda, M. and Mizoguchi, R.},
  title = {An interaction analysis support system for CSCL: an ontological approach to support instructional design process},
  pages = {358 - 362},
  doi = {10.1109/CIE.2002.1185946},
  abstract = {We can observe various kinds of interaction among members of a learning group during a collaborative learning session. It is difficult for even human users to analyze them in order to clarify what types of collaboration have occurred in the session and what educational benefits have been expected for the members through the session. So, we propose an interaction analysis support system that helps users to abstract the essence of interaction from raw protocol data, and to understand what types of collaboration have occurred in the session, and then infers educational benefits expected to be gained by the members through the interaction process.},
  volume = {1},
  booktitle = {International Conference on Computers in Education},
  isbn = {0-7695-1509-6},
  location = {Auckland, New Zealand},
  month = dec,
  year = {2002}
}

@MISC{software:jboss,
  author = {JBoss Inc},
  title = {JBoss},
  howpublished = {Programa de computador},
  year = {2002},
  owner = {msilva},
  timestamp = {2006.02.24},
  url = {http://www.jboss.com}
}

@MISC{blackboard:2002,
  author = {Inc., Blackboard},
  title = {Blackboard Learning System (Release 6): Product Overview},
  howpublished = {White Paper},
  year = {2002},
  note = {http://www.blackboard.com [08/04/2007]},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@MISC{bell:1994,
  author = {Bell Canada Inc.},
  title = {Trillium: Model for Telecom Product Development and Support Process Capability, release 3.0},
  month = {dec},
  year = {1994},
  owner = {magsilva},
  timestamp = {2006.09.12}
}

@INPROCEEDINGS{Indzhov-etal:2009,
  author = {Indzhov, Hristo and Blagoev, Dimitar and Totkov, George},
  title = {Executable Petri Nets: towards modelling and management of e-learning processes},
  pages = {1-6},
  doi = {10.1145/1731740.1731782},
  abstract = {Many tools for online collaboration, information and file sharing are currently employed to facilitate the process of online education. However, as stated in [14] the existing E-learning environments are not mature enough and only a small set of them provide functionality for defining reusable learning entities, reliable publishing and republishing mechanisms and possibilities for the teachers to give feedback to or receive feedback from the E-students. In order to improve E-learning experience [14] presents PeU 2.0, a system that enables the graphical representation and editing of the learning workflow without the execution environment of a workflow management system. The present paper examines the current executability of Petri Nets and gives a mapping of the visual elements in the PeU 2.0 graphs onto Petri Net structures. An interesting approach is introduces for the physical execution of the Petri Nets.},
  keywords = {Petri Nets, computer systems and technologies, e-learning, workflow management},
  address = {New York, NY, USA},
  booktitle = {International Conference on Computer Systems and Technologies and Workshop for PhD Students in Computing},
  isbn = {978-1-60558-986-2},
  location = {Ruse, Bulgaria},
  publisher = {ACM},
  year = {2009}
}

@INPROCEEDINGS{Ingalls-etal:1997,
  author = {Ingalls Jr, Daniel Henry Holmes and T. Kaehler and J. Maloney and S. Wallace and A. Kay},
  title = {Back to the Future: The Story of Squeak, A Practical Smalltalk Written in Itself},
  pages = {318-326},
  address = {Atlanta, GA},
  booktitle = {OOPSLA'97},
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1997}
}

@MISC{software:inspiration,
  author = {{Inspiration Software Inc.}},
  title = {Inspiration Tool},
  howpublished = {Programa de computador},
  year = {2003},
  note = {http://www.inspiration.com/vlearning [08/12/2003]},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@BOOK{Pmbok:2013,
  title = {{PMBOK} Guide -- A Guide To The Project Management Body of Knowledge},
  publisher = {PMI},
  year = {2013},
  author = {Project Management Institute},
  isbn = {978-1-935589-67-9},
  owner = {magsilva},
  timestamp = {2014.09.22}
}

@MISC{sei:2005,
  author = {Software Engineering Institute},
  title = {How do you definee software architecture},
  howpublished = {Online (Web)},
  year = {2005},
  owner = {magsilva},
  timestamp = {2006.11.13},
  url = {http://www.sei.cmu.edu/architecture/definitions.html}
}

@MISC{ieee1362:1998,
  author = {{Institute of Electrical and Electronics Engineers}},
  title = {IEEE recommended practice for software acquisition (IEEE Std 1362-1998)},
  month = dec,
  year = {1998},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@MISC{ieeeeia12207:1998,
  author = {{Institute of Electrical and Electronics Engineers} and {Electronics Industry Association}},
  title = {IEEE/EIA 12207 - Industry Implementation of International Standard ISO/IEC 12207 : 1995},
  howpublished = {Standard},
  month = {mar},
  year = {1998},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@MISC{jstd016:1995,
  author = {{Institute of Electrical and Electronics Engineers} and {Electronics Industry Association (EIA)}},
  title = {Trial-use standard standard for information technology software life cycle processes software development acquirer-supplier agreement (J-STD-016-1995)},
  howpublished = {Standard},
  month = {sep},
  year = {1995},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@MISC{software:cognitor,
  author = {Laboratório de Interação Avançada (UFScar)},
  title = {Cognitor},
  howpublished = {Programa de computador},
  month = ago,
  year = {2006},
  timestamp = {2008.09.27}
}

@MISC{letsi:2008,
  author = {{International Federation for Learning-Education-Training Systems Interoperability (LETSI)}},
  title = {Frequently Asked Questions About the White Papers and the SCORM 2.0 Process},
  howpublished = {Página na Internet (FAQ)},
  month = jul,
  year = {2008},
  timestamp = {2008.09.22},
  url = {http://www.letsi.org/letsi/display/nextscorm/SCORM+2.0+FAQ}
}

@TECHREPORT{Iso96PEVA,
  author = {{International Organization for Standardization}},
  title = {{DIS 14598-5 Process for Evaluators}},
  institution = {ISO/IEC},
  month = may,
  year = {1996},
  number = {ISO/IEC 14598-5},
  owner = {magsilva},
  timestamp = {2008.07.31},
  type = {Padrão}
}

@MISC{Isa99PANC,
  author = {{INTERNATIONAL SOFTWARE AUTOMATION (ISA)}},
  title = {{P}anorama {C}/{C}++},
  year = {1999},
  owner = {magsilva},
  timestamp = {2008.07.31},
  url = {http://www.softwareautomation.com/p2cpp_nt/p2cpp_nt.exe}
}

@MISC{Isa99PANJ,
  author = {{INTERNATIONAL SOFTWARE AUTOMATION (ISA)}},
  title = {{P}anorama for {J}ava},
  year = {1999},
  owner = {magsilva},
  timestamp = {2008.07.31},
  url = {http://www.softwareautomation.com/panojava/PJ_inst.exe}
}

@INPROCEEDINGS{Iribarne:2010:IMC:1948509.1948573,
  author = {Iribarne, Luis and Padilla, Nicolas and Criado, Javier and Vicente-Chicote, Cristina},
  title = {An interaction meta-model for cooperative component-based user interfaces},
  pages = {259--268},
  abstract = {Model Driven Engineering (MDE) aims to help software developers to abstract the system implementations by means of models and meta-models. In Web-based Collaborative Information Systems (WCIS) modelling plays an important role, especially in the user-interface field. In this kind of systems, where groups of users (with different roles) cooperate through distributed user interfaces, and the complexity of interaction between different elements involved in the system (e.g., actors, roles, tasks, interaction rules, etc.) is usually high, MDE could represent a good solution to model evolvable user interfaces. This paper describes a proposal for an interaction meta-model, as a part of a model-evolution methodology for cooperative Graphical User Interfaces (GUI) through Component-Based Development (CBD) approaches. The paper also presents a case study based on an Environmental Management Information Systems (EMIS), where three actors (a politician, a GIS expert, and a technician) cooperate for assessing natural disasters.},
  keywords = {MDE, collaborative systems, interaction, user interfaces},
  series = {OTM'10},
  acmid = {1948573},
  address = {Berlin, Heidelberg},
  booktitle = {Proceedings of the 2010 international conference on On the move to meaningful internet systems},
  isbn = {978-3-642-16960-1},
  location = {Hersonissos, Crete, Greece},
  numpages = {10},
  publisher = {Springer-Verlag},
  url = {http://portal.acm.org/citation.cfm?id=1948509.1948573},
  year = {2010}
}

@ARTICLE{isaacs:2002,
  author = {Ellen Isaacs and Alan Walendowski e Dipti Ranganathan},
  title = {Mobile Instant Messaging Through Hubbub},
  volume = {45},
  number = {9},
  month = sep,
  year = {2002},
  pages = {68-72},
  journal = {Communications of the ACM},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@MISC{standard:iso:15836:2009,
  author = {{ISO}},
  title = {ISO 15836:2009 - Information and documentation - The Dublin Core metadata element set},
  howpublished = Standard,
  year = {2009},
  timestamp = {2008.09.22},
  url = {http://www.iso.org/iso/iso_catalogue/catalogue_ics/catalogue_detail_ics.htm?csnumber=52142}
}

@MISC{iso:13818-1,
  author = {{ISO/IEC}},
  title = {{ISO/IEC} 13818-1},
  timestamp = {2008.09.02}
}

@MISC{standard:iso:11172-5:1998-cor1:2007,
  author = {{ISO/IEC}},
  title = {ISO/IEC TR 11172-5:1998/Cor 1:2007},
  howpublished = {Relatório técnico},
  timestamp = {2008.09.28}
}

@MISC{standard:iso:13818-4:2004,
  author = {{ISO/IEC}},
  title = {ISO/IEC 13818-4:2004 - Information technology -- Generic coding of moving pictures and associated audio information -- Part 4: Conformance testing},
  timestamp = {2008.09.28}
}

@MISC{standard:iso:13818-4:2004-am2:2005-cor1:2007,
  author = {{ISO/IEC}},
  title = {ISO/IEC 13818-4:2004/Amd 2:2005/Cor 1:2007},
  timestamp = {2008.09.28}
}

@MISC{standard:iso:24748,
  author = {{ISO/IEC}},
  title = {ISO/IEC CD TR 24748 - Systems and Software engineering -- Life cycle management -- Guide for life cycle management},
  howpublished = {Padrão},
  year = unpublished,
  timestamp = {2008.10.07}
}

@STANDARD{standard:iso:15504-9:2011,
  title = {Information technology -- Process assessment -- Part 9: Target process profiles},
  author = {{ISO/IEC}},
  number = {15504-9:2011},
  year = {2011},
  note = {19},
  abstract = {ISO/IEC TS 15504-9:2011 documents guidelines for target process profiles for capability determination and improvement purposes. It provides guidance for establishing target process profiles for the following purposes: by or on behalf of an organization with the objective of specifying a target process profile to meet specified needs; by or on behalf of an organization with the objective of specifying a target process profile against which to assess the actual ability of the organization to meet that target; by or on behalf of an organization with the objective of specifying a target process profile against which to assess the actual ability of another organization to meet that target; by or on behalf of an organization with the objective of determining the need for improvement based upon any capability gap between the actual capability and the target process profile.},
  pages = {16}
}

@MISC{standard:iso:14496-10:2010,
  author = {{ISO/IEC}},
  title = {ISO/IEC 14496-10:2010 -- Information technology -- Coding of audio-visual objects -- Part 10: Advanced Video Coding},
  howpublished = standard,
  year = {2010},
  abstract = {ISO/IEC 14496-10:2010 specifies advanced video coding for the coding of audio-visual objects. ISO/IEC 14496-10:2010 was developed in response to a growing need for higher compression of moving pictures for various applications such as digital storage media, television broadcasting, Internet streaming, and real-time audiovisual communication. ISO/IEC 14496-10:2010 specifies a coded video representation syntax and an associated decoding process that are suitable for use in a wide variety of applications and network environments. ISO/IEC 14496-10:2010 includes the specification of advanced video coding (AVC) and associated extensions to enable scalable video coding (SVC) and multiview video coding (MVC).},
  pages = {693},
  timestamp = {2008.09.28}
}

@MISC{standard:iso:14496-3:2009,
  author = {{ISO/IEC}},
  title = {ISO/IEC 14496-3:2009 -- Information technology -- Coding of audio-visual objects -- Part 3: Audio},
  howpublished = standard,
  year = {2009},
  abstract = {ISO/IEC 14496-3:2009 integrates many different types of audio coding: natural sound with synthetic sound, low bitrate delivery with high-quality delivery and lossless coding, speech with music, complex soundtracks with simple ones, and traditional content with interactive and virtual-reality content. By standardizing individually sophisticated coding tools - as well as a novel, flexible framework for audio synchronization, mixing and downloaded post-production - ISO/IEC 14496-3:2009 creates adequate technology for a new, interactive world of digital audio. ISO/IEC 14496-3:2009, unlike previous audio standards created by ISO/IEC and other groups, does not target a single application such as real-time telephony or high-quality audio compression. Rather, it applies to every application requiring the use of advanced sound compression, synthesis, manipulation or playback. ISO/IEC 14496-3:2009 specifies state-of-the-art coding tools in several domains. As these tools are integrated with the other parts of ISO/IEC 14496, new possibilities for object-based audio coding, interactive presentation, dynamic soundtracks, and other sorts of new media are enabled. Since a single set of tools is used to cover the needs of a broad range of applications, interoperability is a natural feature of systems that build on ISO/IEC 14496-3:2009.},
  pages = {1381},
  timestamp = {2012.02.05}
}

@MISC{standard:iso:12207:2008,
  author = {{ISO/IEC}},
  title = {{ISO/IEC 12207} -- Standard for Information Technology - Software life cycle processes},
  howpublished = standard,
  year = {2008},
  abstract = {ISO/IEC 12207:2008 establishes a common framework for software life cycle processes, with well-defined terminology, that can be referenced by the software industry. It contains processes, activities, and tasks that are to be applied during the acquisition of a software product or service and during the supply, development, operation, maintenance and disposal of software products. Software includes the software portion of firmware. ISO/IEC 12207:2008 applies to the acquisition of systems and software products and services, to the supply, development, operation, maintenance, and disposal of software products and the software portion of a system, whether performed internally or externally to an organization. Those aspects of system definition needed to provide the context for software products and services are included. ISO/IEC 12207:2008 also provides a process that can be employed for defining, controlling, and improving software life cycle processes. The processes, activities and tasks of ISO/IEC 12207:2008 - either alone or in conjunction with ISO/IEC 15288 - may also be applied during the acquisition of a system that contains software.},
  doi = {10.1109/IEEESTD.2008.4475826},
  isbn = {978-0-7381-5664-4, 978-0-7381-5663-7},
  owner = {Marco Aurélio Graciotto Silva},
  pages = {123},
  timestamp = {2008.07.30},
  url = {http://www.iso.org/iso/catalogue_detail?csnumber=43447}
}

@MISC{standard:iso:13818-1:2007-cor1:2008,
  author = {{ISO/IEC}},
  title = {ISO/IEC 13818-1:2007/Cor 1:2008},
  howpublished = {Padrão},
  year = {2008},
  timestamp = {2008.09.28}
}

@MISC{standard:iso:15288:2008,
  author = {{ISO/IEC}},
  title = {{ISO/IEC 15288} -- Systems and software engineering -- System life cycle processes},
  howpublished = standard,
  year = {2008},
  abstract = {ISO/IEC 15288:2008 establishes a common framework for describing the life cycle of systems created by humans. It defines a set of processes and associated terminology. These processes can be applied at any level in the hierarchy of a system's structure. Selected sets of these processes can be applied throughout the life cycle for managing and performing the stages of a system's life cycle. This is accomplished through the involvement of all interested parties, with the ultimate goal of achieving customer satisfaction. ISO/IEC 15288:2008 also provides processes that support the definition, control and improvement of the life cycle processes used within an organization or a project. Organizations and projects can use these life cycle processes when acquiring and supplying systems. ISO/IEC 15288:2008 concerns those systems that are man-made and may be configured with one or more of the following: hardware, software, data, humans, processes (e.g., processes for providing service to users), procedures (e.g., operator instructions), facilities, materials and naturally occurring entities. When a system element is software, the software life cycle processes documented in ISO/IEC 12207:2008 may be used to implement that system element. ISO/IEC 15288:2008 and ISO/IEC 12207:2008 are harmonized for concurrent use on a single project or in a single organization.},
  doi = {10.1109/IEEESTD.2008.4475826},
  isbn = {978-0-7381-5664-4, 978-0-7381-5663-7},
  owner = {Marco Aurélio Graciotto Silva},
  pages = {123},
  timestamp = {2008.07.30},
  url = {http://www.iso.org/iso/catalogue_detail?csnumber=43447}
}

@STANDARD{standard:iso:15504-7:2008,
  title = {Information technology -- Process assessment -- Part 7: Assessment of organizational maturity},
  author = {{ISO/IEC}},
  number = {TR 15504-7:2008},
  year = {2008},
  abstract = {ISO/IEC 15504 provides a framework for the assessment of processes. This framework can be used by organizations involved in planning, managing, monitoring, controlling, and improving the acquisition, supply, development, operation, evolution and support of products and services. ISO/IEC TR 15504-7:2008 defines the conditions for an assessment of organizational maturity; it defines a framework for determining organizational maturity, based upon profiles of process capability derived from process assessment, and defines the conditions under which such assessments are valid. ISO/IEC TR 15504-7:2008, organizational maturity is an expression of the extent to which an organization consistently implements processes within a defined scope that contributes to the achievement of its business goals (current or projected). An Organizational Maturity Model is based upon one or more specified Process Assessment Model(s), and addresses the domains and contexts for use of the Process Reference Model(s) from which the Process Assessment Model(s) are derived. The assessment of organizational maturity is undertaken through the performance of process assessment as specified in ISO/IEC 15504-2. Specific conditions are defined in ISO/IEC TR 15504-7:2008 relating to the process scope of the organizational maturity assessment, the organizational scope of the assessment (which has to be specified as representing the elements characterised by the organizational maturity rating), and the data collection strategy (which needs to ensure that the results of the assessment are representative of the organizational scope). On completion of the assessment, the set of process profiles established for the organization determine the rating of the level of organizational maturity based on the framework defined in ISO/IEC 15504-7, as specified in the relevant Organizational Maturity Model. ISO/IEC TR 15504-7:2008 also contains guidance on implementing the requirements for constructing an Organizational Maturity Model; on performing assessments of organizational maturity; and on the application of organizational maturity ratings for process improvement and capability determination.},
  pages = {36}
}

@MISC{standard:iso:11172-4:1995-cor1:2007,
  author = {{ISO/IEC}},
  title = {ISO/IEC 11172-4:1995/Cor 1:2007},
  howpublished = {Padrão},
  year = {2007},
  timestamp = {2008.09.28}
}

@MISC{standard:iso:13818-1:2007,
  author = {{ISO/IEC}},
  title = {ISO/IEC 13818-1:2007 - Information technology -- Generic coding of moving pictures and associated audio information: Systems},
  howpublished = standard,
  year = {2007},
  abstract = {ISO/IEC 13818-1:2007 specifies the system layer of the coding. It was developed principally to support the combination of the video and audio coding methods defined in ISO/IEC 13818-2 and ISO/IEC 13818-3. The system layer supports six basic functions: the synchronization of multiple compressed streams on decoding; the interleaving of multiple compressed streams into a single stream; the initialization of buffering for decoding start up; continuous buffer management; time identification; multiplexing and signalling of various components in a system stream. An ISO/IEC 13818-1:2007 multiplexed bit stream is either a Transport Stream or a Program Stream. Both streams are constructed from PES packets and packets containing other necessary information. Both stream types support multiplexing of video and audio compressed streams from one program with a common time base. The Transport Stream additionally supports the multiplexing of video and audio compressed streams from multiple programs with independent time bases. For almost error-free environments the Program Stream is generally more appropriate, supporting software processing of program information. The Transport Stream is more suitable for use in environments where errors are likely. An ISO/IEC 13818-1:2007 multiplexed bit stream, whether a Transport Stream or a Program Stream, is constructed in two layers: the outermost layer is the system layer, and the innermost is the compression layer. The system layer provides the functions necessary for using one or more compressed data streams in a system. The video and audio parts of ISO/IEC 13818-1:2007 define the compression coding layer for audio and video data. Coding of other types of data is not defined by ISO/IEC 13818-1:2007, but is supported by the system layer provided that the other types of data adhere to the constraints defined in 2.7.},
  pages = {174},
  timestamp = {2008.09.28}
}

@MISC{standard:iso:13818-2:2000-amd2:2007,
  author = {{ISO/IEC}},
  title = {ISO/IEC 13818-2:2000/Amd 2:2007},
  howpublished = {Padrão},
  year = {2007},
  timestamp = {2008.09.28}
}

@MISC{standard:iso:13818-2:2000-cor2:2007,
  author = {{ISO/IEC}},
  title = {ISO/IEC 13818-2:2000/Cor 2:2007},
  howpublished = {Padrão},
  year = {2007},
  timestamp = {2008.09.28}
}

@MISC{standard:iso:13818-4:2004-cor1:2007,
  author = {{ISO/IEC}},
  title = {ISO/IEC 13818-4:2004/Cor 1:2007},
  howpublished = {Padrão},
  year = {2007},
  timestamp = {2008.09.28}
}

@MISC{standard:iso:13818-7:2006-amd1:2007,
  author = {{ISO/IEC}},
  title = {ISO/IEC 13818-7:2006/Amd 1:2007 - Transport of MPEG Surround in AAC},
  howpublished = {Padrão},
  year = {2007},
  timestamp = {2008.09.28}
}

@MISC{standard:iso:13818-7:2006,
  author = {{ISO/IEC}},
  title = {ISO/IEC 13818-7:2006 - Information technology -- Generic coding of moving pictures and associated audio information -- Part 7: Advanced Audio Coding (AAC)},
  howpublished = standard,
  year = {2006},
  abstract = {ISO/IEC 13818-7:2006 specifies MPEG-2 Advanced Audio Coding (AAC), a multi-channel audio coding standard that delivers higher quality than is achievable when requiring MPEG-1 backwards compatibility. It provides ITU-R "indistinguishable" quality at a data rate of 320 kbit/s for five full-bandwidth channel audio signals. ISO/IEC 13818-7:2006 also supplements information on how to utilize the bandwidth extension technology (SBR) specified in ISO/IEC14496-3 in conjunction with MPEG-2 AAC.},
  pages = {194},
  timestamp = {2008.09.28}
}

@MISC{standard:iso:13818-4:2004-amd1:2005,
  author = {{ISO/IEC}},
  title = {ISO/IEC 13818-4:2004/Amd 1:2005},
  howpublished = {Padrão},
  year = {2005},
  timestamp = {2008.09.28}
}

@MISC{standard:iso:13818-4:2004-amd2:2005,
  author = {{ISO/IEC}},
  title = {ISO/IEC 13818-4:2004/Amd 2:2005},
  howpublished = {Padrão},
  year = {2005},
  timestamp = {2008.09.28}
}

@MISC{standard:iso:13818-5:2005,
  author = {{ISO/IEC}},
  title = {ISO/IEC TR 13818-5:2005 - Information technology -- Generic coding of moving pictures and associated audio information -- Part 5: Software simulation},
  howpublished = {Padrão},
  year = {2005},
  timestamp = {2008.09.28}
}

@MISC{standard:iso:11172-2:1993-cor4:2004,
  author = {{ISO/IEC}},
  title = {ISO/IEC 11172-2:1993/Cor 4:2004},
  howpublished = {Padrão},
  year = {2004},
  timestamp = {2008.09.28}
}

@MISC{standard:iso:13818-11:2004,
  author = {{ISO/IEC}},
  title = {ISO/IEC 13818-11:2004 - Information technology -- Generic coding of moving pictures and associated audio information -- Part 11: IPMP on MPEG-2 systems},
  howpublished = {Padrão},
  year = {2004},
  timestamp = {2008.09.28}
}

@MISC{standard:iso:14496-2:2004,
  author = {{ISO/IEC}},
  title = {ISO/IEC 14496-2:2004 -- Information technology -- Coding of audio-visual objects -- Part 2: Visual},
  howpublished = standard,
  year = {2004},
  abstract = {ISO/IEC 14496-2:2004 provides the following elements related to the encoded representation of visual information: - Specification of video coding tools, object types and profiles, including capability to encode rectangular-based and arbitrary-shaped video objects, capability to define scalable bitstreams and error-resilient encoding tools; - Specification of coding tools, object types and profiles for mapping of still textures into visual scenes; - Specification of coding tools, object types and profiles for human face and body animation based on face/body models and additional semantic parameters; and - Specification of coding tools, object types and profiles for animation of 2D warping grids with uniform and irregular topology. The Visual specification contains definitions of the bitstream syntax, bitstream semantics and the related decoding process. It does not specify the encoders, which can be optimized in different implementations.},
  pages = {706},
  timestamp = {2008.09.28}
}

@STANDARD{standard:iso:15504-1:2004,
  title = {Information Technology -- Process assessment -- Part 1: Concepts and vocabulary},
  author = {{ISO/IEC}},
  number = {15504-1:2004},
  year = {2004},
  note = {19},
  abstract = {This part of ISO/IEC 15504:2004 provides overall information on the concepts of process assessment and its use in the two contexts of process improvement and process capability determination. It describes how the parts of the suite fit together, and provides guidance for their selection and use. It explains the requirements contained within ISO/IEC 15504, and their applicability to performing assessments. Readers of this guide should familiarize themselves with the terminology and structure of the document suite, and then reference the appropriate parts of the suite for the context in which they propose to conduct an assessment. A more detailed description of the use of ISO/IEC 15504 is given in clause 4.},
  pages = {19}
}

@STANDARD{standard:iso:15504-4:2004,
  title = {Information technology -- Process assessment -- Part 4: Guidance on use for process improvement and process capability determination},
  author = {{ISO/IEC}},
  number = {15504-4:2004},
  year = {2004},
  note = {19},
  abstract = {ISO/IEC 15504 provides a framework for the assessment of processes. This framework can be used by organizations involved in planning, managing, monitoring, controlling, and improving the acquisition, supply, development, operation, evolution and support of products and services. ISO/IEC 15504-4:2004 provides guidance on how to utilize a conformant process assessment within a process improvement programme or for process capability determination. Within a process improvement (PI) context, process assessment provides a means of characterizing an organizational unit in terms of the capability of selected processes. Analysis of the output of a conformant process assessment against an organizational unit's business goals identifies strengths, weaknesses and risks related to the processes. This, in turn, can help determine whether the processes are effective in achieving business goals, and provide the drivers for making improvements. Process capability determination (PCD) is concerned with analysing the output of one or more conformant process assessments to identify the strengths, weaknesses and risks involved in undertaking a specific project using the selected processes within a given organizational unit. A process capability determination can provide a fundamental input to supplier selection, in which case it is often termed a "supplier capability determination". ISO/IEC 15504-4:2004 describes the PI and PCD processes and how to deploy them, and provides guidance on utilizing process assessment, selecting Process Reference Model(s), setting target capability, defining the assessment input, inferring process-related risk from assessment output, steps of process improvement, steps of process capability determination, comparability of assessment output analysis.},
  pages = {33}
}

@STANDARD{standard:iso:15504-5:2012,
  title = {Information technology -- Process assessment -- Part 5: An exemplar software life cycle process assessment model},
  author = {{ISO/IEC}},
  number = {15504-5:2012},
  year = {2004},
  note = {19},
  abstract = {ISO/IEC 15504-5:2012 provides an example of a Process Assessment Model for use in performing a conformant assessment in accordance with the requirements of ISO/IEC 15504-2. ISO/IEC 15504-5:2012 provides a detailed description of the structure and key components of the Process Assessment Model, which includes two dimensions: a process dimension and a capability dimension. It also introduces assessment indicators. ISO/IEC 15504-5:2012 uses process definitions from ISO/IEC 12207:2008 to identify a Process Reference Model. The processes of the Process Reference Model are described in the Process Assessment Model in terms of purpose and outcomes and are grouped in three process categories. The Process Assessment Model expands the Process Reference Model process definitions by including a set of process performance indicators called base practices for each process. The Process Assessment Model also defines a second set of indicators of process performance by associating work products with each process. ISO/IEC 15504-5:2012 duplicates the definitions of the capability levels and process attributes from ISO/IEC 15504-2, and expands each of the nine attributes through the inclusion of a set of generic practices. These generic practices belong to a set of indicators of process capability, in association with generic resource indicators, and generic work product indicators. ISO/IEC 15504-5:2012 also provides the following: a statement of conformance of the Process Assessment Model to the requirements defined in ISO/IEC 15504-2; selected characteristics for typical work products to assist the assessor in evaluating the capability level of processes; style guides for defining base practices, work products and generic practices for adjusting the Process Assessment Model, and guidance explaining how to expand or adapt the model; some processes supplementary to the Process Assessment Model.},
  pages = {196}
}

@MISC{standard:iso:11172-2:1993-cor3:2003,
  author = {{ISO/IEC}},
  title = {ISO/IEC 11172-2:1993/Cor 3:2003},
  howpublished = {Padrão},
  year = {2003},
  timestamp = {2008.09.28}
}

@STANDARD{standard:iso:15504-2:2003,
  title = {Information technology -- Process assessment -- Part 2: Performing an assessment},
  author = {{ISO/IEC}},
  number = {15504-2:2003},
  year = {2003},
  note = {19},
  abstract = {ISO/IEC 15504-2:2003 defines the requirements for performing process assessment as a basis for use in process improvement and capability determination. Process assessment is based on a two dimensional model containing a process dimension and a capability dimension. The process dimension is provided by an external process reference model, which defines a set of processes characterized by statements of process purpose and process outcomes. The capability dimension consists of a measurement framework comprising six process capability levels and their associated process attributes. The assessment output consists of a set of process attribute ratings for each process assessed, termed the process profile, and may also include the capability level achieved by that process. ISO/IEC 15504-2:2003 identifies the measurement framework for process capability and the requirements for: performing an assessment; process reference models; process assessment models; verifying conformity of process assessment. The requirements for process assessment defined in ISO/IEC 15504-2:2003 form a structure which: facilitates self-assessment; provides a basis for use in process improvement and capability determination; takes into account the context in which the assessed process is implemented; produces a process rating; addresses the ability of the process to achieve its purpose; is applicable across all application domains and sizes of organization; and may provide an objective benchmark between organizations. The minimum set of requirements defined in ISO/IEC 15504-2:2003 ensures that assessment results are objective, impartial, consistent, repeatable and representative of the assessed processes. Results of conformant process assessments may be compared when the scopes of the assessments are considered to be similar; for guidance on this matter, refer to ISO/IEC 15504-4.},
  pages = {16}
}

@MISC{standard:iso:13818-2:2000-cor1:2002,
  author = {{ISO/IEC}},
  title = {ISO/IEC 13818-2:2000/Cor 1:2002},
  howpublished = {Padrão},
  year = {2002},
  timestamp = {2008.09.28}
}

@MISC{standard:iso:13818-6:1998-amd1:2000-cor1:2002,
  author = {{ISO/IEC}},
  title = {ISO/IEC 13818-6:1998/Amd 1:2000/Cor 1:2002},
  howpublished = {Padrão},
  year = {2002},
  timestamp = {2008.09.28}
}

@MISC{standard:iso:13818-6:1998-cor2:2002,
  author = {{ISO/IEC}},
  title = {ISO/IEC 13818-6:1998/Cor 2:2002},
  howpublished = {Padrão},
  year = {2002},
  timestamp = {2008.09.28}
}

@MISC{standard:iso:13818-2:2000-amd1:2001,
  author = {{ISO/IEC}},
  title = {ISO/IEC 13818-2:2000/Amd 1:2001},
  howpublished = {Padrão},
  year = {2001},
  timestamp = {2008.09.28}
}

@MISC{standard:iso:13818-6:1998-amd3:2001,
  author = {{ISO/IEC}},
  title = {ISO/IEC 13818-6:1998/Amd 3:2001},
  howpublished = {Padrão},
  year = {2001},
  timestamp = {2008.09.28}
}

@MISC{standard:iso:13818-2:2000,
  author = {{ISO/IEC}},
  title = {ISO/IEC 13818-2:2000 - Information technology -- Generic coding of moving pictures and associated audio information: Video},
  howpublished = standard,
  year = {2000},
  pages = {208},
  timestamp = {2008.09.28}
}

@MISC{standard:iso:13818-6:1998-amd1:2000,
  author = {{ISO/IEC}},
  title = {ISO/IEC 13818-6:1998/Amd 1:2000},
  howpublished = {Padrão},
  year = {2000},
  timestamp = {2008.09.28}
}

@MISC{standard:iso:13818-6:1998-amd2:2000,
  author = {{ISO/IEC}},
  title = {ISO/IEC 13818-6:1998/Amd 2:2000},
  howpublished = {Padrão},
  year = {2000},
  timestamp = {2008.09.28}
}

@MISC{standard:iso:11172-1:1993-cor2:1999,
  author = {{ISO/IEC}},
  title = {ISO/IEC 11172-1:1993/Cor 2:1999},
  howpublished = {Padrão},
  year = {1999},
  timestamp = {2008.09.28}
}

@MISC{standard:iso:11172-2:1993-cor2:1999,
  author = {{ISO/IEC}},
  title = {ISO/IEC 11172-2:1993/Cor 2:1999},
  howpublished = {Padrão},
  year = {1999},
  timestamp = {2008.09.28}
}

@MISC{standard:iso:13818-10:1999,
  author = {{ISO/IEC}},
  title = {ISO/IEC 13818-10:1999 - Information technology -- Generic coding of moving pictures and associated audio information -- Part 10: Conformance extensions for Digital Storage Media Command and Control (DSM-CC)},
  howpublished = {Padrão},
  year = {1999},
  timestamp = {2008.09.28}
}

@MISC{standard:iso:13818-6:1998-cor1:1999,
  author = {{ISO/IEC}},
  title = {ISO/IEC 13818-6:1998/Cor 1:1999},
  howpublished = {Padrão},
  year = {1999},
  timestamp = {2008.09.28}
}

@MISC{standard:iso:11172-5:1998,
  author = {{ISO/IEC}},
  title = {ISO/IEC TR 11172-5:1998 - Information technology -- Coding of moving pictures and associated audio for digital storage media at up to about 1,5 Mbit/s -- Part 5: Software simulation},
  howpublished = {Relatório técnico},
  year = {1998},
  timestamp = {2008.09.28}
}

@MISC{standard:iso:13818-3:1998,
  author = {{ISO/IEC}},
  title = {ISO/IEC 13818-3:1998 - Information technology -- Generic coding of moving pictures and associated audio information -- Part 3: Audio},
  howpublished = {Padrão},
  year = {1998},
  timestamp = {2008.09.28}
}

@MISC{standard:iso:13818-6:1998,
  author = {{ISO/IEC}},
  title = {ISO/IEC 13818-6:1998 - Information technology -- Generic coding of moving pictures and associated audio information -- Part 6: Extensions for DSM-CC},
  howpublished = {Padrão},
  year = {1998},
  timestamp = {2008.09.28}
}

@MISC{standard:iso:15504:1998,
  author = {{ISO/IEC}},
  title = {Information Technology -- Software Process Assessment},
  year = {1998},
  institution = {ISO/IEC},
  number = {ISO/IEC 15504}
}

@MISC{standard:iso:11172-1:1993-cor1:1996,
  author = {{ISO/IEC}},
  title = {ISO/IEC 11172-1:1993/Cor 1:1996},
  howpublished = {Padrão},
  year = {1996},
  timestamp = {2008.09.28}
}

@MISC{standard:iso:11172-2:1993-cor1:1996,
  author = {{ISO/IEC}},
  title = {ISO/IEC 11172-2:1993/Cor 1:1996},
  howpublished = {Padrão},
  year = {1996},
  timestamp = {2008.09.28}
}

@MISC{standard:iso:11172-3:1993-cor1:1996,
  author = {{ISO/IEC}},
  title = {ISO/IEC 11172-3:1993/Cor 1:1996},
  howpublished = {Padrão},
  year = {1996},
  timestamp = {2008.09.28}
}

@MISC{standard:iso:13818-9:1996,
  author = {{ISO/IEC}},
  title = {ISO/IEC 13818-9:1996 - Information technology -- Generic coding of moving pictures and associated audio information -- Part 9: Extension for real time interface for systems decoders},
  howpublished = {Padrão},
  year = {1996},
  timestamp = {2008.09.28}
}

@MISC{standard:iso:11172-4:1995,
  author = {{ISO/IEC}},
  title = {ISO/IEC 11172-4:1995 - Information technology -- Coding of moving pictures and associated audio for digital storage media at up to about 1,5 Mbit/s -- Part 4: Compliance testing},
  howpublished = {Padrão},
  year = {1995},
  timestamp = {2008.09.28}
}

@MISC{standard:iso:12207:1995,
  author = {{ISO/IEC}},
  title = {{ISO/IEC 12207} -- Standard for Information Technology - Software life cycle processes},
  howpublished = Standard,
  month = {aug},
  year = {1995},
  owner = {Marco Aurélio Graciotto Silva},
  timestamp = {2008.07.30}
}

@MISC{standard:iso:11172-1:1993,
  author = {{ISO/IEC}},
  title = {ISO/IEC 11172-1:1993 -- Information technology -- Coding of moving pictures and associated audio for digital storage media at up to about 1,5 Mbit/s -- Part 1: Systems},
  howpublished = {Padrão},
  year = {1993},
  timestamp = {2008.09.28}
}

@MISC{standard:iso:11172-2:1993,
  author = {{ISO/IEC}},
  title = {ISO/IEC 11172-1:1993 - Information technology -- Coding of moving pictures and associated audio for digital storage media at up to about 1,5 Mbit/s -- Part 2: Video},
  howpublished = {Padrão},
  year = {1993},
  timestamp = {2008.09.28}
}

@MISC{standard:iso:11172-3:1993,
  author = {{ISO/IEC}},
  title = {ISO/IEC 11172-3:1993 - Information technology -- Coding of moving pictures and associated audio for digital storage media at up to about 1,5 Mbit/s -- Part 3: Audio},
  howpublished = {Padrão},
  year = {1993},
  timestamp = {2008.09.28}
}

@RESEARCH-PROJECT{project:spice:1995,
  title = {{SPICE}},
  author = {{ISO/IEC} {JTC 1}/{SC 7}, {WG 10}},
  month = jun,
  year = {1995},
  url = {http://www.sqi.gu.edu.au/spice/}
}

@MISC{standard:itu:bt.1306,
  author = {{ITU}},
  title = {{ITU} {BT.1306} -- Error correction, data framing, modulation and emission methods for digital terrestrial television broadcasting},
  howpublished = standard,
  month = dez,
  year = {2011},
  url = {http://www.itu.int/rec/R-REC-BT.1306/en}
}

@MISC{standard:itu:j200,
  author = {{ITU}},
  title = {{J.200}: Worldwide common core -- Application environment for digital interactive television services},
  howpublished = standard,
  month = apr,
  year = {2010},
  abstract = {Recommendation ITU-T J.200 identifies the structure, the origins and the specification sources for a harmonized environment, including a set of application programming interfaces (APIs) for interactive television services.},
  lang = {en},
  url = {http://www.itu.int/rec/T-REC-J.200-201004-I/en},
  urlaccessdate = {20 fev 2012}
}

@MISC{standard:itu:j202,
  author = {{ITU}},
  title = {{J.202}: Harmonization of procedural content formats for interactive {TV} applications},
  howpublished = standard,
  month = aug,
  year = {2010},
  abstract = {Recommendation ITU-T J.202 defines APIs, semantic guarantees and system aspects of platform behaviour for harmonized procedural content formats for interactive TV applications. Since this Recommendation was approved in 2003, several procedural content formats for interactive TV applications developed by other standardization bodies have been updated or newly developed. Updated specifications include: DVB-GEM, DVB-MHP 1.0, DVB-MHP 1.1, DVB-MHP 1.2, OCAP-1.0, OCAP-1.1 and ARIB STD-B23. Also, ATSC developed ACAP and ABNT has now developed GINGA-J. The purpose of the third revision of this Recommendation is to harmonize the specifications with a wider variety of standards including GEM 1.2, ARIB-J, GINGA-J, DVB-MHP, ACAP and OCAP. To achieve this, the common core defined in this Recommendation consists of two sets of APIs; one related to core Java technology and another for broadcast extensions, to conform to either DVB-GEM, from which several specifications are derived, or JavaDTV specification, which is the core of GINGA-J and functionally equivalent to DVB-GEM. Additional APIs specific to the standards listed above are included for information in the appendices, which are not included in the harmonized common core.},
  lang = {en},
  url = {http://www.itu.int/rec/T-REC-J.202-201008-I/en},
  urlaccessdate = {20 fev 2012}
}

@MISC{standard:itu:j201,
  author = {{ITU}},
  title = {{J.201}: Harmonization of declarative content format for interactive television applications},
  howpublished = standard,
  month = dez,
  year = {2009},
  abstract = {Recommendation ITU-T J.201 is intended to harmonize the application environment for declarative content for interactive television. It specifies common elements, media types and APIs at the syntactic level of the declarative application environment. This edition harmonizes the specifications with the newly developed standard, GINGA-NCL. GINGA-NCL is included in this Recommendation as a framework to bind content authored in multiple formats into a single content, as well as conformity of its XHTML-related capability to the common core defined in this Recommendation.},
  lang = {en},
  url = {http://www.itu.int/rec/T-REC-J.201-200912-I/en},
  urlaccessdate = {20 fev 2012}
}

@MISC{iwt:2008,
  author = {{IWT}},
  title = {{Intelligent Web Teacher}},
  year = {2006},
  note = {http://www.didatticaadistanza.com/default.asp [15/02/2008]},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@MISC{Javasoft96JBAS,
  author = {{J}ava{S}oft},
  title = {{J}ava{B}eans 1.0 {API} {S}pecification},
  howpublished = {Sun Microsystems, Inc.},
  month = dec,
  year = {1996},
  note = {(versão 1.00-A)},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@TECHREPORT{Jackson94CGSL,
  author = {D. Jackson and E. J. Rollins},
  title = {Chopping: A Generalization of Slicing},
  institution = {School of Computer Science -- Carnegie Mellon University},
  month = jul,
  year = {1994},
  number = {CMU-CS-94-169},
  address = {Pittsburgh, PA},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{Jackson00PFMJ,
  author = {D. Jackson and M. Woodward},
  title = {Parallel Firm Mutation of {J}ava Programs},
  address = {San Jose, CA},
  booktitle = {Mutation 2000 Symposium},
  month = oct,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {2000}
}

@ARTICLE{jackson:1999,
  author = {Michael Jackson},
  title = {Specializing in Software Engineering},
  volume = {16},
  number = {6},
  month = nov,
  year = {1999},
  pages = {119-121},
  journal = {IEEE Software},
  owner = {magsilva},
  timestamp = {2008.07.24}
}

@BOOK{Jacobson-etal:1999:book,
  title = {The Unified Software Development Process},
  publisher = {Addison-Wesley},
  year = {1999},
  author = {Ivar Jacobson and Grady Booch and James Rumbaugh},
  isbn = {978-0201571691},
  pages = {512},
  address = USA,
  edition = {1},
  month = feb,
  abstract = {This landmark book provides a thorough overview of the Unified Process for software development, with a practical focus on modeling using the Unified Modeling Language. The Unified Process goes beyond mere object-oriented analysis and design to spell out a proven family of techniques that supports the complete software development life cycle. The result is a component-based process that is use-case driven, architecture-centric, iterative, and incremental. The Unified Process takes full advantage of the industry-standard Unified Modeling Language. This book demonstrates how the notation and process complement one another, using UML models to illustrate the new process in action. The authors clearly describe the semantics and notation of the different higher-level constructs used in the models. Constructs such as use cases, actors, subsystems, classes, interfaces, active classes, processes, threads, nodes, and most relations are described in the context of a model. Object technology practitioners and software engineers familiar with the authors' past work will appreciate The Unified Software Development Process as a useful means of learning the current best practices in software development.},
  booktitle = {The Unified Software Development Process}
}

@BOOK{Jacobson:1992,
  title = {Object-Oriented Software Engineering: A Use Case Driven Approach},
  publisher = {Addison-Wesley},
  year = {1992},
  author = {Ivar Jacobson and Magnus Christerson and Patrik Jonsson and Gunnar Övergaard},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@ARTICLE{jacyntho2002sas,
  author = {M. D. Jacyntho and D. Schwabe and G. Rossi},
  title = {{A Software Architecture for Structuring Complex Web Applications}},
  volume = {1},
  number = {1},
  year = {2002},
  pages = {37--60},
  journal = {Journal of Web Engineering},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@MISC{software:jspwiki,
  author = {Janne Jalkanen},
  title = {JSPWiki},
  howpublished = {Programa de Computador},
  month = jul,
  year = {2001},
  owner = {Marco Aurélio Graciotto Silva},
  timestamp = {2008.07.30},
  url = {http://www.jspwiki.org/}
}

@BOOK{Jannach-etal:2011,
  publisher = {Cambridge},
  year = {2011},
  author = {Dietmar Jannach and Markus Zanker and Alexander Felfernig and Gerhard Friedrich},
  isbn = {978-0-521-49336-9},
  pages = {335},
  address = {New York, NY, } # USA,
  edition = {1},
  booktitle = {Recommender systems: an introduction},
  timestamp = {2013-09-26}
}

@ARTICLE{Jansen-Bulterman:2009,
  author = {Jansen, Jack and Bulterman, Dick C.},
  title = {{SMIL State}: an architecture and implementation for adaptive time-based web applications},
  volume = {43},
  month = jul,
  year = {2009},
  pages = {203--224},
  doi = {10.1007/s11042-009-0270-3},
  abstract = {In this paper we examine adaptive time-based web applications (or presentations). These are interactive presentations where time dictates which parts of the application are presented (providing the major structuring paradigm), and that require interactivity and other dynamic adaptation. We investigate the current technologies available to create such presentations and their shortcomings, and suggest a mechanism for addressing these shortcomings. This mechanism, SMIL State, can be used to add user-defined state to declarative time-based languages such as SMIL or SVG animation, thereby enabling the author to create control flows that are difficult to realize within the temporal containment model of the host languages. In addition, SMIL State can be used as a bridging mechanism between languages, enabling easy integration of external components into the web application. Finally, SMIL State enables richer expressions for content control. This paper defines SMIL State in terms of an introductory example, followed by a detailed specification of the State model. Next, the implementation of this model is discussed. We conclude with a set of potential use cases, including dynamic content adaptation and delayed insertion of custom content such as advertisements.},
  keywords = {Declarative languages, Delayed ad viewing, Multimedia web applications, SMIL},
  acmid = {1553310},
  address = {Hingham, MA, USA},
  issn = {1380-7501},
  issue = {3},
  journal = {Multimedia Tools Appl.},
  numpages = {22},
  publisher = {Kluwer Academic Publishers}
}

@INPROCEEDINGS{Jansen-etal:2010,
  author = {Jansen, Jack and Cesar, Pablo and Bulterman, Dick C.A.},
  title = {A model for editing operations on active temporal multimedia documents},
  pages = {87--96},
  doi = {10.1145/1860559.1860579},
  abstract = {Inclusion of content with temporal behavior in a structured document leads to such a document gaining temporal semantics. If we then allow changes to the document during its presentation, this brings with it a number of fundamental issues that are related to those temporal semantics. In this paper we study modifications of active multimedia documents and the implications of those modifications for temporal consistency. Such modifications are becoming increasingly important as multimedia documents move from being primarily a standalone presentation format to being a building block in a larger application. We present a categorization of modification operations, where each category has distinct consistency and implementation implications for the temporal semantics. We validate the model by applying it to the SMIL language, categorizing all possible editing operations. Finally, we apply the model to the design of a teleconferencing application, where multimedia composition is only a small component of the whole application, and needs to be reactive to the rest of the system. The primary contribution of this paper is the development of a temporal editing model and a general analysis which we feel can help application designers to structure their applications such that the temporal impact of document modification can be minimized.},
  keywords = {application design, declarative languages, dynamic transformations, multimedia},
  series = {DocEng},
  booktitle = {10th ACM Symposium on Document Engineering},
  isbn = {978-1-4503-0231-9},
  location = {Manchester, #UK#},
  publisher = {ACM},
  year = {2010}
}

@INPROCEEDINGS{jantke-etal:2005,
  author = {Jantke, Klaus P. and Knauf, Rainer},
  title = {Didactic design through storyboarding: standard concepts for standard tools},
  pages = {20--25},
  abstract = {The current state of affair in e-learning world-wide shows a reluctance to didactic design. Learners frequently complain and scientists discuss about insufficient adaptivity of e-learning offers to the learners' needs. Didactics is badly underestimated.High quality didactic design is seen as a crucial aspect of dissemination. E-learning content and services need to reach their audience properly. Learners with different prerequisites, with different needs, with different expectations and under varying context conditions have to be addressed appropriately. Didactic design is seen as an issue of quality assurance in e-learning.As well-known from quality management, high quality requirements and related measures towards quality assurance may turn out to be obstacles to dissemination, because quality may turn out to be expensive. The related answer are solutions frequently called quick and dirty. This does apply to e-learning as well.The authors' own storyboard concept is introduced. Its reach goes far beyond the limits of current practices in e-learning systems and service development. The modeling concepts required are standard: annotated graphs. The software in use is standard as well: Visio. Emphasis is put on the investigation of how a suitable usage of the concepts allows for an expressive didactic design.To sum up, the authors' intended contribution is twofold. First, they want to encourage didactic design through storyboarding in e-learning. Concepts are introduced and applications are demonstrated. Second, with the dissemination problem in mind, they want to show that concepts are crucial, but not tools. One can exploit advanced concepts toward sophisticated didactic design without an urgent need for costly software.},
  series = {WISICT '05},
  acmid = {1071757},
  booktitle = {Proceedings of the 4th international symposium on Information and communication technologies},
  isbn = {1-59593-169-4},
  location = {Cape Town, South Africa},
  numpages = {6},
  publisher = {Trinity College Dublin},
  url = {http://portal.acm.org/citation.cfm?id=1071752.1071757},
  year = {2005}
}

@INPROCEEDINGS{Jensen:2008a,
  author = {Jensen, Jens F.},
  title = {The concept of interactivity -- revisited: four new typologies for a new media landscape},
  pages = {129--132},
  doi = {10.1145/1453805.1453831},
  abstract = {In this paper definitions, classifications and typologies of the concept of interactivity in the context of the new media landscape will be discussed. The paper takes its point of departure in the evaluation of two typologies of interactive media and interactivity introduced some 10 years ago. In the remainder of the paper, four new typologies or matrices concerning interactive media and the new media landscape are introduced. In this sense the paper can be seen as the concept of interactivity -- revisited.},
  keywords = {interactivity, isocial media, mainstream media, user-generated content},
  series = {UXTV '08},
  acmid = {1453831},
  address = {New York, NY, USA},
  booktitle = {1st International Conference on Designing Interactive User Experiences for TV and Video},
  isbn = {978-1-60558-100-2},
  location = {Silicon Valley, California, USA},
  numpages = {4},
  publisher = {ACM},
  year = {2008}
}

@INPROCEEDINGS{Jensen:2005,
  author = {Jensen, Jens F.},
  title = {Interactive television: new genres, new format, new content},
  pages = {89--96},
  abstract = {The aim of this paper is to discuss some of the main issues associated with interactive genres, formats and content in the context of interactive television (ITV). First, a set of new forms or categorizations of ITV will be presented. Second, the suite of interactive genres, formats and applications that currently constitutes ITV will be introduced and discussed. And third, some general conclusions concerning interactivity, television and the interactive user/viewer will be drawn.},
  series = {IE},
  address = {Sydney, } # Australia,
  booktitle = {2nd Australasian Conference on Interactive Entertainment},
  isbn = {0-9751533-2-3},
  location = {Sydney, #Australia#},
  publisher = {Creativity \& Cognition Studios},
  year = {2005}
}

@ARTICLE{Jensen:1998,
  author = {Jens F. Jensen},
  title = {Interactivity: Tracing a New Concept in Media and Communication Studies},
  volume = {19},
  month = jul,
  year = {1998},
  pages = {185--204},
  journal = {Nordicom Review}
}

@INPROCEEDINGS{Jensen97BICP,
  author = {K. Jensen},
  title = {A Brief Introduction to Coloured Petri Nets},
  pages = {201--208},
  volume = {1217},
  booktitle = {Lecture Notes in Computer Science: Tools and Algorithms for the Construction and Analysis of Systems. Proceedings of the TACAS'97 Workshop, Enschede, The Netherlands 1997},
  editor = {Brinksma, E.},
  owner = {magsilva},
  publisher = {Springer-Verlag},
  timestamp = {2008.07.31},
  year = {1997}
}

@BOOK{jensen:1997:cpn:concepts,
  title = {Coloured petri nets: Basic concepts},
  publisher = {Springer},
  year = {1997},
  author = {K. Jensen},
  address = {Berlim, Alemanha},
  edition = {2},
  timestamp = {2009.01.30}
}

@INPROCEEDINGS{Gomes-etal:2009:sbie,
  author = {Fábio de Jesus Lima Gomes and José Valdeni de Lima and Rosane Aragon de Nevado},
  title = {Gangorra Interativa: um Objeto de Aprendizagem para {TV} Digital},
  pages = {1-10},
  abstract = {Este artigo apresenta os resultados de testes com um objeto de aprendizagem (OA) para TV Digital (TVD). Através da TVD, o t-learning surge como uma oportunidade para promover a aprendizagem para um maior número de pessoas não alcançadas pelo tradicional e-learning. Após a implementação de um OA para TVD e a realização de testes, os resultados analisados mostraram que há a possibilidade de se utilizar OAs na TVD.},
  abstract-en = {This paper shows the results of the use of a learning object (LO) for the Digital TV (DTV). With the DTV, t-learning arises as an opportunity in order to promote the learning to a major amount of people than the traditional e-learning doesn't reach. A LO was finished, and tests were carried out. The results show that LOs can be used in the DTV.},
  booktitle = {II Workshop de Modelos Pedagógicos em Educação a Distância},
  url = {http://www.niee.ufrgs.br/eventos/SBIE/2009/conteudo/artigos/ws3/63571_1.pdf}
}

@ARTICLE{Gomes-etal:2009:renote,
  author = {Fábio de Jesus Lima Gomes and José Valdeni Lima and Rosane Aragon Nevado},
  title = {Avaliando um Objeto de Aprendizagem para TV Digital},
  volume = {7},
  number = {3},
  year = {2009},
  abstract = {Este artigo apresenta os resultados de testes com um objeto de aprendizagem (OA) para TV Digital (TVD). Através da TVD, o t-learning surge como uma oportunidade para promover a aprendizagem para um maior número de pessoas não alcançadas pelo tradicional e-learning. Após a implementação de um OA para TVD e a realização de testes, os resultados analisados mostraram que há a possibilidade de se utilizar OAs na TVD.},
  journal = {Revista {RENOTE}}
}

@INPROCEEDINGS{Gomes-etal:2008,
  author = {Fábio de Jesus Lima Gomes and José Valdeni de Lima and Rosane Aragon de Nevado},
  title = {Uma interface multimodal para objetos de aprendizagem visualizados na TV digital},
  pages = {284--287},
  abstract = {This paper proposes a paper interface, with the use of a barcode reader as Digital TV (DTV) interaction device. With the DTV, t-learning arises as an opportunity in order to promote the learning to a major amount of people than the traditional e-learning doesn't reach. But, the use of remote control in the DTV has resulted a complex viewer interaction that may cause the user's frustration and irritation and the ease of use is one of the most important factors in the DTV. This paper aims linking the common paper with DTV, in order to get better usabilility and promote more conditions to t-learning. A prototype was finished, and usability tests were carried out. The results show that the barcode reader can be used as DTV interaction device.},
  keywords = {digital TV, distance learning, paper interface, usability},
  abstract-pt = {Este artigo propõe uma interface baseada em papel, com a utilização de uma leitora de código de barras, como dispositivo de interação com a TV Digital (TVD). Através da TVD, o t-learning surge como uma oportunidade para promover a aprendizagem para um maior número de pessoas não alcançadas pelo tradicional e-learning. Mas, o uso do controle remoto na TVD resulta em uma complexa interação que pode causar frustração e irritação do usuário e a facilidade de uso é um dos principais fatores para a TVD. Este artigo propõe a ligação do papel comum com a TVD, com os objetivos de tornar a TVD mais usável e de proporcionar melhores condições para o t-learning. Após a implementação de um protótipo e a realização de testes de usabilidade, os resultados analisados mostraram que há a possibilidade de se utilizar a leitora de código de barras como dispositivo de interação com a TV.},
  address = {Porto Alegre, } # Brazil,
  booktitle = {VIII Brazilian Symposium on Human Factors in Computing Systems},
  isbn = {978-85-7669-203-4},
  lang = {pt},
  location = {Porto Alegre, RS, Brazil},
  publisher = {SBC},
  year = {2008}
}

@ARTICLE{Gomes-etal:2007,
  author = {Fábio de Jesus Lima Gomes and José Valdeni de Lima and Rosane Aragón de Nevado},
  title = {Definindo Orientações de Usabilidade para o Desenvolvimento de Objetos de Aprendizagem para {TV} Digital},
  volume = {5},
  number = {2},
  year = {2007},
  pages = {1--9},
  abstract = {O objetivo desta pesquisa é produzir orientações de usabilidade para ajudar no desenvolvimento de objetos de aprendizagem fáceis de uso que serão utilizados na TV Digital (TVD). Para a definição das orientações, os seguintes passos estão sendo e serão realizados: (a) identificação de problemas de interface de aplicações para TVD; (b) projeto e desenvolvimento de objetos de aprendizagem (protótipos) para TVD; (c) avaliação heurística dos protótipos desenvolvidos; (d) testes de usabilidade para os protótipos desenvolvidos. As orientações serão baseadas nos resultados dos testes de usabilidade realizados em laboratório.},
  keywords = {TV Digital, Usabilidade, Objetos de Aprendizagem, T-learning},
  url = {http://seer.ufrgs.br/renote/article/view/14203},
  abstract-en = {The aim of this research is to produce usability guidelines that support the development of easy to use Digital TV (DTV) learning objects. To define the guidelines the following steps are being and will be conducted: (a) identification of recurring DTV interface design problems; (b) design and development of DTV learning objects (prototypes); (c) heuristic evaluation of the developed DTV prototypes; (d) usability tests of the developed DTV prototypes. The guidelines are based upon empirical lab-based usability test results for DTV prototypes.},
  address = {Porto Alegre, RS, Brazil},
  issn = {1679-1916},
  journal = {Revista {RENOTE}},
  keywords-en = {Digital TV, Usability, Learning Objects, T-learning},
  publisher = {CINTED/UFRGS},
  title-en = {Defining Usability Guidelines to Develop Digital TV Learning Objects}
}

@INPROCEEDINGS{Gomes-etal:2006,
  author = {Fábio de Jesus Lima Gomes and José Valdeni de Lima and Rosane Aragon de Nevado},
  title = {O papel comum como interface para TV digital},
  pages = {29--32},
  doi = {10.1145/1298023.1298056},
  abstract = {This paper considers the use of a barcode reader as Digital TV (DTV) interaction device. With the DTV, t-learning arises as an opportunity in order to promote the learning to a major amount of people than the traditional e-learning doesn't reach. But, the use of remote control in the DTV has resulted a complex viewer interaction that may cause the user's frustration and irritation and the ease of use is one of the most important factors in the DTV. This paper aims linking the common paper with DTV, in order to get better usabilility and promote more conditions to t-learning. Moreover, this paper also considers a card, a keyboard and commercial product catalogue, using the same technology.},
  keywords = {digital TV, distance learning, paper interface, usability},
  series = {IHC '06},
  acmid = {1298056},
  address = {Natal, RN, Brasil},
  booktitle = {VII Brazilian symposium on Human factors in computing systems},
  isbn = {1-59593-432-4},
  lang = {pt},
  location = {Natal, RN, Brasil},
  numpages = {4},
  publisher = {ACM},
  year = {2006}
}

@INPROCEEDINGS{Jin95ITBS,
  author = {Z. Jin and A. J. Offut},
  title = {Integration Testing Based on Software Couplings},
  pages = {13--23},
  address = {Gaithersburg, Maryland},
  booktitle = {X Annual Conference on Computer Assurance (COMPASS 95)},
  month = jan,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1995}
}

@INPROCEEDINGS{john-eisenbarth:2009,
  author = {Isabel John and Michael Eisenbarth},
  title = {A decade of scoping: a survey},
  pages = {31-40},
  volume = {446},
  series = {ACM International Conference Proceeding Series},
  address = {San Francisco, California},
  booktitle = {International Software Product Line Conference},
  owner = {magsilva},
  publisher = {Carnegie Mellon University (Pittsburgh, PA, USA)},
  timestamp = {2010.07.08},
  year = {2009}
}

@INPROCEEDINGS{john-etal:2006,
  author = {John, Isabel and Knodel, Jens and Lehner, Theresa and Muthig, Dirk},
  title = {A Practical Guide to Product Line Scoping},
  pages = {3--12},
  address = {Washington, DC, USA},
  booktitle = {International on Software Product Line Conference (SPLC)},
  isbn = {0-7695-2599-7},
  publisher = {IEEE Computer Society},
  year = {2006}
}

@INPROCEEDINGS{john-villela:2009,
  author = {John, Isabel and Villela, Karina},
  title = {Evolutionary product line requirements engineering},
  pages = {319--319},
  volume = {446},
  series = {ACM International Conference Proceeding Series},
  address = {San Francisco, California},
  booktitle = {International Software Product Line Conference (SPLC)},
  location = {San Francisco, California},
  publisher = {Carnegie Mellon University (Pittsburgh, PA, USA)},
  year = {2009}
}

@BOOK{Johnson96GATT,
  title = {Graphical Applications with Tcl \& Tk},
  publisher = {M\&T Books},
  year = {1996},
  author = {E. F. Johnson},
  address = {New York},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@MISC{software:spring,
  author = {Rod Johnson and others},
  title = {Spring Framework},
  howpublished = software,
  month = feb,
  year = {2003},
  url = {http://www.springsource.org}
}

@ARTICLE{Johnson88DRCL,
  author = {R. E. Johnson and B. Foote},
  title = {Designing Reusable Classes},
  volume = {1},
  number = {2},
  month = jun # {/} # jul,
  year = {1988},
  pages = {22--35},
  journal = joop,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@ARTICLE{Jonassen:1991,
  author = {Jonassen, David},
  title = {Objectivism versus constructivism: Do we need a new philosophical paradigm?},
  volume = {39},
  number = {3},
  year = {1991},
  pages = {5-14},
  doi = {10.1007/BF02296434},
  abstract = {Many scholars in the instructional systems field have addressed the paradigm shift in the field of learning psychology and its implications for instructional systems technology (IST). This article analyzes the philosophical assumptions underlying IST and its behavioral and cognitive foundations, each of which is primarily objectivistic, which means that knowing and learning are processes for representing and mirroring reality. The philosophical assumptions of objectivism are then contrasted with constructivism, which holds that knowing is a process of actively interpreting and constructing individual knowledge representations. The implications of constructivism for IST provide a context for asking the reader to consider to what extent our field should consider this philosophical paradigm shift.},
  affiliation = {the University of Colorado USA USA},
  issn = {1042-1629},
  issue = {3},
  journal = {Educational Technology Research and Development},
  keyword = {Humanities, Social Sciences and Law},
  note = {10.1007/BF02296434},
  publisher = {Springer Boston}
}

@ARTICLE{Jonassen:1994,
  author = {Jonassen, David H.},
  title = {Thinking Technology: Toward a Constructivist Design Model},
  volume = {34},
  number = {4},
  month = apr,
  year = {1994},
  pages = {34-37},
  abstract = {Discussion of constructivism and instructional design focuses on the development of a design model for constructivist environments that supports the construction of knowledge, a meaningful context for learning, and collaboration among learners and with the teacher. Differences between constructivist and objectivist approaches are considered.},
  issn = {0013-1962},
  journal = {Educational Technology}
}

@ARTICLE{Jones98SUGA,
  author = {B. F. Jones and D. E. Eyres and H. -H. Sthamer},
  title = {A Strategy for Using Genetic Algorithms to Automate Branch and Fault-Based Testing},
  volume = {41},
  number = {2},
  year = {1998},
  pages = {98--107},
  journal = {{The Computer Journal}},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@ARTICLE{Jones-etal:1992,
  author = {M. K. Jones and Z. Li and M. D. Merrill},
  title = {Rapid Prototyping in Automated Instructional Design},
  volume = {40},
  number = {4},
  year = {1992},
  pages = {95-100},
  abstract = {In this article the impact of the tools being developed as part of the Second Generation Instructional Design (ID2) Research Program on the processo of instructional design is described. ID2 supports rapid prototyping as a design and development process. Rapid prototyping is described and contrasted with the instructional system development (ISD) process.},
  journal = {Education Technology Research and Development},
  owner = {magsilva},
  timestamp = {2008.09.21}
}

@MISC{svg:2003,
  author = {Jon Ferraiolo, Fujisawa Jun, Dean Jackson},
  title = {Scalable Vector Graphics (SVG) 1.1 Specification},
  howpublished = {W3C Recommendation},
  month = jan,
  year = {2003},
  comment = {24/05/2005},
  file = {Scalable Vector Graphics (SVG) 1.1 Specification.pdf:Scalable Vector Graphics (SVG) 1.1 Specification.pdf:PDF},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://www.w3.org/TR/SVG/}
}

@MISC{Jorge00TMSR,
  author = {R. F. Jorge},
  title = {Teste de Mutação: Subsídios para a Redução do Custo de Aplicação},
  month = jun,
  year = {2000},
  note = {Qualificação de Mestrado -- ICMC-USP.},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{Jorge01TMEB,
  author = {R. F. Jorge and A. M. R. Vincenzi and M. E. Delamaro and J. C. Maldonado},
  title = {Teste de Muta\c c\~ao: Estrat\'egias Baseadas em Equival\^encia de Mutantes para Redu\c c\~ao do Custo de Aplica\c c\~ao},
  address = {Merida, Venezuela},
  booktitle = {XXVII Latin-American Conference on Informatics (CLEI 2001)},
  month = sep,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {2001}
}

@ARTICLE{Jorgensen94OOIT,
  author = {P. C. Jorgensen and C. Erickson},
  title = {Object Oriented Integration Testing},
  volume = {37},
  number = {9},
  month = sep,
  year = {1994},
  pages = {30--38},
  journal = comacm,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{Jovanovic:2008:EGD:1434390.1434416,
  author = {Jovanovic, Mladjan and Starcevic, Dusan and Stavljanin, Velimir and Minovic, Miroslav},
  title = {Educational Games Design Issues: Motivation and Multimodal Interaction},
  pages = {215--224},
  doi = {10.1007/978-3-540-87781-3_24},
  abstract = {In this paper we present an approach to identifying and constructing profiles of user interfaces for educational games. Our approach is based on framing games as educational tools that incorporate fun and learning through motivation as the key ingredient in the learning process, and multimodal interaction as the medium for conveying educational material. To date, there is no common standard to design this kind of games and individual solutions are usually carried out by an <em>ad hoc</em>process. Proposed solution formalizes design process describing educational games in terms of estimated effects they produce on players. Building upon research on learning and motivation theory, we are connecting these effects with player learning preferences and motivation states. Our main contribution is to suggest design issues that should be taken into account when designing educational games. We exemplify the approach through our ongoing VStrat project, framework for designing educational games.},
  keywords = {Educational game, Fun, Learning, Motivation, Multimodal Interaction},
  series = {WSKS '08},
  acmid = {1434416},
  address = {Berlin, Heidelberg},
  booktitle = {Proceedings of the 1st world summit on The Knowledge Society: Emerging Technologies and Information Systems for the Knowledge Society},
  isbn = {978-3-540-87780-6},
  location = {Athens, Greece},
  numpages = {10},
  publisher = {Springer-Verlag},
  year = {2008}
}

@INPROCEEDINGS{whitehead:2001:1,
  author = {E. James Whitehead Jr.},
  title = {WebDAV and DeltaV: collaborative authoring, versioning, and configuration management for the Web},
  pages = {259-260},
  address = {Denmark},
  booktitle = {Twelfth ACM Conference on Hypertext and Hypermedia},
  owner = {magsilva},
  timestamp = {2008.07.30},
  year = {2001}
}

@MISC{standard:java:jsr927,
  author = {{JSR}},
  title = {{JSR} 927: Java TV API 1.1},
  howpublished = {Java Specification Request (JSR)},
  month = aug,
  year = {2008},
  organization = {{Sun Microsystems}},
  url = {http://jcp.org/en/jsr/detail?id=927},
  urlaccessdate = {20 fev 2012}
}

@MISC{standard:java:jsr216,
  author = {{JSR}},
  title = {{JSR} 216: Personal Profile 1.1},
  howpublished = {Java Specification Request (JSR)},
  month = aug,
  year = {2006},
  abstract = {Personal Profile provides a J2ME environment for those devices with a need for a high degree of Internet connectivity and web fidelity. Version 1.0 of Personal Profile (JSR-62) served as the next generation of the PersonalJavaTM environment; as such, it provided a path for applications written to the PersonalJava Application Environment Specification to migrate to J2ME. Additionally, Personal Profile 1.0 was derived from the J2SE 1.3.1 API specification. APIs in this specification would therefore run on J2SE 1.3.1. This JSR proposes to update the Personal Profile specification to reflect the latest J2SE APIs. The result, Personal Profile version 1.1, will be backward-compatible to its 1.0 counterpart Note that while new APIs may be adopted from J2SE 1.4, no new, non-J2SE APIs are planned for definition in this JSR.},
  url = {http://jcp.org/en/jsr/detail?id=216},
  urlaccessdate = {20 fev 2012}
}

@MISC{standard:java:jsr217,
  author = {{JSR}},
  title = {{JSR} 217: Personal Basis Profile 1.1},
  howpublished = {Java Specification Request (JSR)},
  month = aug,
  year = {2006},
  abstract = {Personal Basis Profile provides a J2ME application environment for network-connected devices supporting a basic level of graphical presentation. Version 1.0 of Personal Basis Profile (JSR-129) served as the conceptual basis of Personal Profile 1.0: it is a subset of and upward-compatible to the more complete functionality of Personal Profile. Additionally, Personal Basis Profile 1.0 was derived from the J2SE 1.3.1 API specification. APIs in this specification would therefore run on J2SE 1.3.1. This JSR proposes to update the Personal Basis Profile specification to reflect the J2SE 1.4 APIs. The result, Personal Basis Profile version 1.1, will be backward-compatible to its 1.0 counterpart. Note that while new APIs may be adopted from J2SE 1.4, no new, non-J2SE APIs are planned for definition in this JSR.},
  url = {http://jcp.org/en/jsr/detail?id=217},
  urlaccessdate = {20 fev 2012}
}

@MISC{standard:java:jsr218,
  author = {{JSR}},
  title = {{JSR} 218: Connected Device Configuration (CDC) 1.1},
  howpublished = {Java Specification Request (JSR)},
  month = aug,
  year = {2006},
  note = {Substituído por \cite{standard:java:jsr218}.},
  abstract = {The J2ME CDC is a Configuration of the Java 2 Platform, Micro Edition suitable for types of devices that will supply a network-enabled Java environment. It provides a basis for J2ME Profiles that build upon the CDC by adding a graphical user interface or other functionality. The J2ME CDC targets small, resource-constrained devices (such as high-end PDAs, cell phones, TV set-top boxes, auto telematics, and so on) by supporting the following features: Java virtual machine, Java language, Networking, I/O, Java 2 Security, Text input and display. This new JSR will: update APIs already present in the J2ME CDC 1.0 to the definitions in J2SE, v1.4; update APIs already present in the J2ME CDC 1.0, at the discretion of the expert group, to the definitions in J2ME CLDC 1.1; add carefully selected additional features or APIs, at the discretion of the expert group, taken from J2SE, v1.4. Note that while new APIs may be adopted from J2SE, v1.4, no new, non-J2SE APIs are planned for definition in this JSR. J2ME CDC 1.1 will be backward compatible with J2ME CDC 1.0.},
  url = {http://jcp.org/en/jsr/detail?id=218},
  urlaccessdate = {20 fev 2012}
}

@MISC{standard:java:jsr62,
  author = {{JSR}},
  title = {{JSR} 62: Personal Profile Specification},
  howpublished = {Java Specification Request (JSR)},
  month = mar,
  year = {2006},
  note = {Replaced by \cite{standard:java:jsr217}.},
  abstract = {The J2ME Personal Profile provides the J2ME environment for those devices with a need for a high degree of Internet connectivity and web fidelity. This Profile is intended to provide the next generation of Sun's PersonalJavaTM environment, and as such has the explicit requirement of providing compatibility with applications developed for versions 1.1.x and 1.2.x of the PersonalJava Application Environment Specification. The J2ME Personal Profile provides a profile of the JavaTM 2 Platform, Micro Edition in devices characterized as follows: 2.5 M minimum ROM available, 1 M minimum RAM available (application and localization memory requirements are additional ), robust connectivity to some type of network, graphical user interface, providing a high degree of web fidelity and the capability of running Java web applets, supporting a complete implementation of the J2ME Foundation Profile (see JSR-46 J2ME Foundation Profile), and the J2ME Connected Device Configuration (see JSR-36 J2ME Connected Device Configuration).},
  organization = {{Sun Microsystems}},
  url = {http://jcp.org/en/jsr/detail?id=62},
  urlaccessdate = {20 fev 2012}
}

@MISC{standard:java:jsr129,
  author = {{JSR}},
  title = {{JSR} 129: Personal Basis Profile Specification},
  howpublished = {Java Specification Request (JSR)},
  month = dec,
  year = {2005},
  note = {Replaced by \cite{standard:java:jsr216}.},
  abstract = {The J2ME Personal Basis Profile provides a J2ME application environment for network-connected devices supporting a basic level of graphical presentation. This Profile will serve as the basis for the Profile defined by JSR-62, which has the additional requirements of full web fidelity and legacy PersonalJava application support. The J2ME Personal Basis Profile provides a profile of the JavaTM 2 Platform, Micro Edition in devices characterized as follows: 2 M minimum ROM available; 1 M minimum RAM available; Robust connectivity to some type of network; Basic graphical user interface, permitting AWT applications written using only lightweight components; Supporting a complete implementation of the J2ME Foundation Profile (see JSR-46 J2ME Foundation Profile), and the J2ME Connected Device Configuration (see JSR36 J2ME Connected Device Configuration).},
  url = {http://jcp.org/en/jsr/detail?id=129},
  urlaccessdate = {20 fev 2012}
}

@MISC{standard:java:jsr219,
  author = {{JSR}},
  title = {{JSR} 219: Foundation Profile 1.1},
  howpublished = {Java Specification Request (JSR)},
  month = dec,
  year = {2005},
  abstract = {The J2ME Foundation Profile serves two purposes. First, it provides a Profile of the Java 2 Platform, Micro Edition suitable for devices that are a network-enabled Java environment, but do not require a graphical user interface. Second, it provides the base Profile for inclusion by other J2ME Profiles that need to build upon this functionality with the addition of a graphical user interfaces or other functionality. The J2ME Foundation Profile targets small, resource-constrained devices (such as high-end PDAs, cell phones, TV set-top boxes, auto telematics, and so on) by supporting the following features: Java virtual machine, Java language, Networking, I/O, Java 2 Security, Text input and display. This new JSR will: update APIs already present in the J2ME Foundation Profile 1.0 to the definitions in J2SE, v1.4; add carefully selected additional features or APIs, at the discretion of the expert group, taken from J2SE, v1.4. Note that while new APIs may be adopted from J2SE, v1.4, no new, non-J2SE APIs are planned for definition in this JSR. J2ME Foundation Profile 1.1 will be backward compatible with J2ME Foundation Profile 1.0. As part of this JSR, the expert group will also define an optional package comprising the Java Secure Socket Extension (JSSE), Java Cryptography Extension (JCE), and Java Authentication and Authorization Service (JAAS) APIs for use in conjunction with Foundation Profile implementations. The definition of this optional package will be performed in the context of the J2ME Foundation Profile expert group, since its specification will require close coordination with the specification of J2ME Foundation Profile 1.1. The expert group will also consider a subset of JCE as a possible separate optional package that will support both CLDC and CDC.},
  url = {http://jcp.org/en/jsr/detail?id=219},
  urlaccessdate = {20 fev 2012}
}

@MISC{standard:java:jsr36,
  author = {{JSR}},
  title = {{JSR} 36: Connected Device Configuration},
  howpublished = {Java Specification Request (JSR)},
  month = dec,
  year = {2005},
  note = {Replaced by \cite{standard:java:jsr218}.},
  abstract = {The J2ME Connected Device Configuration provides the basis of the Java 2 Platform, Micro Edition in devices characterized as follows: 512K minimum ROM available, 256K minimum RAM available, connectivity to some type of network, supporting a complete implementation of the Java Virtual Machine as defined in the Java Virtual Machine Specification (2nd Edition), user interfaces with varying degrees of sophistication down to and including none may be supported by this configuration specification. TV set-top boxes, web enabled phones, and car entertainment/navigation systems are some, but not all, of the devices that may be supported by this configuration specification. The J2ME Connected Device Configuration will define the minimum required complement of Java Technology components and API's for connected devices. Supported APIs, application life-cycle, security model, and code installation are the primary topics to be addressed by this specification.},
  url = {http://jcp.org/en/jsr/detail?id=36},
  urlaccessdate = {20 fev 2012}
}

@MISC{standard:java:jsr46,
  author = {{JSR}},
  title = {{JSR} 46: Foundation Profile},
  howpublished = {Java Specification Request (JSR)},
  month = dec,
  year = {2005},
  note = {Replaced by \cite{standard:java:jsr219}.},
  abstract = {The J2ME Foundation Profile will serve two purposes. First, it will provide a profile of the Java 2 Platform suitable for devices that need support for a rich network enabled Java environment, but do not require a graphical user interface. Second, it will provide a base profile for inclusion by other profiles that need to build on the functionality it provides by adding graphical user interfaces or other functionality. The J2ME Foundation Profile provides a profile of the Java 2 Platform, Micro Edition in devices characterized as follows: 1024k minimum ROM available (application memory requirements are additional); 512k minimum RAM available (application memory requirements are additional); connectivity to some type of network; no graphical user interface, unless the GUI functionality is provided by an additional profile.},
  url = {http://jcp.org/en/jsr/detail?id=46},
  urlaccessdate = {20 fev 2012}
}

@MASTERSTHESIS{jubileu:1999,
  author = {Andrea Padovan Jubileu},
  title = {{Aquisição de Conhecimento como Apoio ao Método de Engenharia Reversa FUSION-RE/I}},
  school = {Universidade de São Paulo},
  year = {1999},
  address = {São Carlos, SP},
  owner = {magsilva},
  timestamp = {2006.09.13}
}

@MISC{software:snipsnap,
  author = {Matthias L. Jugel and Stephan J. Schmidt},
  title = {Snipsnap},
  howpublished = {Programa de Computador},
  month = sep,
  year = {2002},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://snipsnap.org}
}

@MISC{software:colourcontrast,
  author = {{Juicy Studio}},
  title = {Colour Constrast},
  howpublished = {Programa de computador},
  month = feb,
  year = {2006},
  owner = {magsilva},
  timestamp = {2007.08.13},
  url = {http://juicystudio.com/article/colour-contrast-analyser-firefox-extension.php}
}

@INPROCEEDINGS{JumiskoPyykko-etal:2008,
  author = {Jumisko-Pyykkö, Satu and Weitzel, Mandy and Strohmeier, Dominik},
  title = {Designing for User Experience: What to Expect from Mobile {3D} {TV} and Video?},
  pages = {183--192},
  doi = {10.1145/1453805.1453841},
  abstract = {A long process has been undertaken to develop the technology of 3D video for consumer products, but studies to determine the needs and expectations of actual users have been disregarded. The object of this study is to examine users' needs, expectations and requirements for mobile 3D television and video. We conducted three user studies applying triangulation methodology of the extensive survey, focus groups and probe studies to identify the requirements. The results are presented in the form of guidelines which highlight the characteristics of users, the system and service required including what content is interesting and the context in which it will be used. Both academia and industry can benefit from knowledge of these requirements when designing the further studies and development work concerning the user experience of 3D television and video.},
  keywords = {3d tv, methods, mobile 3d tv, mobile tv, user experience, user requirements},
  series = {UXTV '08},
  acmid = {1453841},
  address = {New York, NY, EUA},
  booktitle = {International conference on Designing interactive user experiences for TV and video},
  isbn = {978-1-60558-100-2},
  location = {Silicon Valley, California, EUA},
  numpages = {10},
  publisher = {ACM},
  year = {2008}
}

@INPROCEEDINGS{Jurado-etal:2008a,
  author = {Jurado, Francisco and Molina, Ana I. and Giraldo, William J. and Redondo, Miguel A. and Ortega, Manuel},
  title = {Using CIAN for Specifying Collaborative Scripts in Learning Design},
  pages = {204--211},
  doi = {10.1007/978-3-540-88011-0_28},
  abstract = {The standardization of eLearning environments and the design of collaboration scripts are two research areas that are acquiring a greater attention within the Computer Supported Collaborative Learning (CSCL) community. IMS Learning Design (IMS-LD) is the specification used to describe instructional strategies. In this paper we analyse the suitability and lacks of IMS-LD for modelling collaborative learning processes. Based on this result, we propose a reference model inside the IMS specifications core and the use of a graphical notation called CIAN (Collaborative Interactive Applications Notation) as CSCL scripting language. Using these specifications of a high level of abstraction and mappable to a computer-interpretable notation such as IMS-LD, allows hiding the particularities of the standard to instructional designers.},
  keywords = {CSCL, Learning design, methodological approach, model-driven development},
  series = {CDVE '08},
  acmid = {1432412},
  address = {Berlin, Heidelberg},
  booktitle = {Proceedings of the 5th international conference on Cooperative Design, Visualization, and Engineering},
  isbn = {978-3-540-88010-3},
  location = {Calvia, Mallorca, Spain},
  numpages = {8},
  owner = {magsilva},
  publisher = {Springer-Verlag},
  year = {2008}
}

@INPROCEEDINGS{Jurado-etal:2008b,
  author = {Jurado, Francisco and Santos, Olga C. and Redondo, Miguel A. and Boticario, Jesús G. and Ortega, Manuel},
  title = {Providing Dynamic Instructional Adaptation in Programming Learning},
  pages = {329--336},
  doi = {10.1007/978-3-540-87656-4_41},
  abstract = {This paper describes an approach to create an Intelligent Tutoring System that provides dynamic personalization and learning activities sequencing adaptation by combining eLearning standards and Artificial Intelligent techniques. The work takes advantage of the functionalities provided by an open source Learning Management System, dotLRN, which supports eLearning standards such as IMS-LD, and generates personalized sequences of learning activities. Moreover, the user model draws on standards such as IMS-LIP and IMS-AccLIP and the personalized learning path provided to the user is enriched with feedback coming from various Agents. In turn, the agents apply Fuzzy Logic to evaluate the students' assignments and to update the user model with their preferences by means of machine learning techniques.},
  series = {HAIS '08},
  acmid = {1434177},
  address = {Berlin, Heidelberg},
  booktitle = {Proceedings of the 3rd international workshop on Hybrid Artificial Intelligence Systems},
  isbn = {978-3-540-87655-7},
  location = {Burgos, Spain},
  numpages = {8},
  owner = {magsilva},
  publisher = {Springer-Verlag},
  year = {2008}
}

@MISC{juric:2005,
  author = {Matjaz B. Juric},
  title = {BPEL and Java},
  howpublished = {Artigo},
  month = apr,
  year = {2005},
  owner = {magsilva},
  timestamp = {2008.01.28},
  url = {http://www.theserverside.com/tt/articles/article.tss?l=BPELJava}
}

@ARTICLE{Juristo-etal:2009,
  author = {Natalia Juristo and Ana Moreno and Sira Vegas and Forrest Shull},
  title = {A Look at 25 Years of Data},
  volume = {26},
  number = {1},
  month = jan,
  year = {2009},
  pages = {15-17},
  doi = {10.1109/MS.2009.2},
  abstract = {Is 25 years enough time to build up a coherent body of knowledge that can help point to useful principles? As a testbed for helping us answer this question, software testing techniques are a good place to start. Few software practices are as important as testing, and testing techniques are amenable to measurement and reasoning about their effectiveness. Because they're aimed at removing faults, measuring the number and type of such removed faults seems like a natural part of applying these techniques. To make sense of this data, Universidad Politecnica de Madrid researchers have spent some time worrying about how to put 25 years' worth of work together usefully.},
  url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=4721175},
  journal = {IEEE Software},
  publisher = {IEEE Computer Society}
}

@BOOK{Juristo-Moreno:2001,
  title = {Basics of Software Engineering Experimentation},
  publisher = {Kluwer Academic Publishers},
  year = {2001},
  author = {Natalia Juristo and Ana M. Moreno},
  editor = {1},
  pages = {395},
  owner = {magsilva},
  timestamp = {2010.08.10}
}

@INPROCEEDINGS{Kacer-Mannova:2008,
  author = {M. Kacer and B. Mannová},
  title = {{PCSS3}: Programming Contest Scoring System},
  abstract = {Programming Contest Scoring System v3 (PCSS3) is a piece of software developed at the Czech Technical University. It can be used to run and evaluate programming competitions, such as ACM ICPC. This paper describes the system architecture and features that distinguish it from other existing evaluation systems. The main goal is to provide a possible source of inspiration to other authors. It is not our intention to make comparisons or to claim some of the systems being ``the best one''.},
  address = {Banff, Alberta, } # Canada,
  booktitle = {Competitive Learning Institute Symposium},
  location = {Banff, Alberta, #Canada#},
  month = apr,
  timestamp = {2013-08-23},
  year = {2008}
}

@INPROCEEDINGS{Kaelber-Martin:2011,
  author = {Kaelber, Claus and Märtin, Christian},
  title = {From structural analysis to scenarios and patterns for knowledge sharing applications},
  pages = {258--267},
  doi = {10.1007/978-3-642-21602-2_29},
  abstract = {In this paper we present a pragmatic development approach for knowledge sharing applications that encompasses both design and software engineering aspects. It starts from scenarios and leads to patterns that help application developers and user interface designers on the one hand to separate relevant content from unimportant data and on the other hand propose techniques for qualitatively structuring knowledge management and knowledge sharing tasks for enterprises and individuals.},
  keywords = {GUI generation, HCI patterns, design strategy, domain patterns, knowledge management, knowledge sharing, pattern-based modeling, structural patterns},
  volume = {6761},
  series = {Lecture Notes in Computer Science},
  acmid = {2022416},
  address = {Berlin, Heidelberg},
  booktitle = {14th International Conference on Human-Computer Interaction},
  isbn = {978-3-642-21601-5},
  lang = {en},
  location = {Orlando, FL, #USA#},
  numpages = {10},
  publisher = {Springer},
  year = {2011}
}

@INPROCEEDINGS{kaindl:2004,
  author = {Hermann Kaindl},
  title = {Active Tool Support for Requirements Engineering Through RETH},
  pages = {362 - 363},
  booktitle = {International Requirements Engineering Conference},
  owner = {magsilva},
  timestamp = {2008.07.30},
  year = {2004}
}

@INPROCEEDINGS{kaindl:2003,
  author = {Hermann Kaindl},
  title = {Structuring Business Models in a Web Representation},
  booktitle = {36th Annual Hawaii International Conference on System Sciences (HICSS'03)},
  owner = {magsilva},
  publisher = {IEEE Computer Society},
  timestamp = {2008.07.30},
  year = {2003}
}

@ARTICLE{kaindl:2002,
  author = {Hermann Kaindl},
  title = {Using hypermedia in requirements engineering practice},
  volume = {7},
  number = {1},
  month = {jul},
  year = {2002},
  pages = {185 - 205},
  abstract = {In the literature, proposals can be found to use hypermedia for requirements engineering. The major technical and commercial constraints for wide-spread application are removed now, but there is little knowledge generally available yet on how exactly such approaches can be usefully applied in industrial practice, or what the advantages and issues to be solved are. So, we report on a case study of using hypermedia 'real-time' in the requirements phase of an important real-world project inside our environment, where several ways of applying hypermedia were tried with varying success. Since the resulting hypermedia repository can be fully automatically exported into a Web representation, several versions were made available on the intranet at different stages. While this case study may serve as a data point in the space of such applications, we also discuss reflections on this experience with the motivation of helping practitioners apply hypermedia successfully in requirements engineering. In a nutshell, this paper presents some experience from using hypermedia in requirements engineering practice, and a critical discussion of advantages and issues involved.},
  journal = {The New Review of Hypermedia and Multimedia},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@MISC{kaindl:1995,
  author = {Hermann Kaindl and Stefan Kramer},
  title = {Semiautomatic Generation of Dictionary Links in Hypertext},
  year = {1995},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@ARTICLE{Kaldoudi-etal:2011,
  author = {Kaldoudi, E. and Dovrolis, N. and Konstantinidis, S. and Bamidis, P.D.},
  title = {Depicting Educational Content Repurposing Context and Inheritance},
  volume = {15},
  number = {1},
  month = jan,
  year = {2011},
  pages = {164 -170},
  doi = {10.1109/TITB.2010.2092442},
  abstract = {Educational content is often shared among different educators and is enriched, adapted, and, in general, repurposed so that it can be reused in different contexts. This paper discusses educational content and content repurposing in medical education, presenting different repurposing contexts. Finally, it proposes a novel approach to content repurposing via Web 2.0 social networking of learning resources. The proposed social network is augmented by a graphical representation module in order to capture and depict the relationships among different repurposed medical educational resources, based on educational resource families and inheritance. The ultimate goal is to provide a conceptually different approach to educational resource organization and retrieval via social associations among learning resources.},
  keywords = {Web 2.0 social networking;content repurposing;educational content;educational resource families;educational resource organization;graphical representation module;information retrieval;inheritance;learning resources;medical educational resources;Internet;biomedical education;computer aided instruction;content management;information resources;information retrieval;inheritance;medical computing;social networking (online);Biomedical Research;Health Educators;Humans;Information Dissemination;Internet;Social Support;Software;},
  issn = {1089-7771},
  journal = {IEEE Transactions on Information Technology in Biomedicine},
  lang = {en},
  publisher = {IEEE}
}

@BOOK{kan:1995,
  title = {Metrics and Models in Software Quality Engineering},
  publisher = {Addison-Wesley},
  year = {1995},
  author = {Stephen H. Kan},
  owner = {magsilva},
  timestamp = {2006.08.21}
}

@MISC{software:svk,
  author = {Chia-Liang Kao},
  title = {SVK},
  howpublished = {Programa de computador},
  year = {2003},
  owner = {magsilva},
  timestamp = {2006.07.17},
  url = {http://svk.elixus.org/}
}

@MASTERSTHESIS{Kawasaki:1996,
  author = {Evelise Izumi Kawasaki},
  title = {Modelo e metodologia para projeto de cursos hipermídia},
  abstract = {Uma educação adequada à realidade atual é aquela que capacita o indivíduo a encontrar as soluções para seus problemas. Nesse contexto, o professor passará a ser um facilitador do processo, cabendo-lhe propor desafios aos aprendizes e motivá-los. Atualmente existe um grande número de softwares educativos disponíveis no mercado, abordando diversas áreas do conhecimento. No entanto, a utilização desses programas nas escolas de forma integrada ao currículo não ocorre com freqüência. Para que o computador se torne efetivamente um instrumento capaz de melhorar a qualidade da educação oferecida nas escolas, é necessário que os professores se proponham a usá-los como tal e disponham de meios para isso. Os modelos e ferramentas de autoria para hipermídia existentes mostram-se insuficientes para a modelagem de cursos, principalmente no que se refere aos aspectos pedagógicos. Neste trabalho apresenta-se um modelo para a caracterização de cursos hipermídia, chamado Daphne, seguido de uma metodologia que descreve a aplicação do modelo e visa permitir que professores de qualquer área, mesmo leigos em informática, projetem seus cursos. Um protótipo na área de Harmonia Musical ilustrando o uso do modelo e da metodologia foi implementado.},
  school = {Instituto Tecnológico de Aeronáutica (ITA)},
  year = {1996},
  address = {São José dos Campos, SP, } # Brazil,
  month = nov,
  url = {http://www.bd.bibl.ita.br/tesesdigitais/000373683.pdf},
  abstract-en = {Nowadays, a suitable edueation must enable people to find the right answers to their questions. In this eontext, a teaeher beeomes a proeess moderator whose goaI is to motivate students to leam by themselves. A great number of eurrent edueational software in almost every knowledge domain ean be found. Nevertheless, they are hardly explored at sehools. Computers can effectively become instruments for the improvement ofthe educacional process since the teachers are committed to use them. This work presents a model for characterizing hipennedia courses, called Daphne, and a methodology which descrihes how to apply the model. This methodology must allow teachers of any subject, even those not acquainted to computers, to design their own courses.},
  note = {Orientador: Clovis Torres Fernandes},
  timestamp = {2012.01.23}
}

@INPROCEEDINGS{Kawasaki-Fernandes:1996,
  author = {Evelise Izumi Kawasaki and Clovis Torres Fernandes},
  title = {Modelo para Projeto de Cursos Hipermídia},
  pages = {227-240},
  address = {Belo Horizonte, MG, } # Brazil,
  booktitle = {VII Simpósio Brasileiro de Informática na Educação (SBIE 96)},
  location = {Belo Horizonte, MG, #Brazil#},
  month = nov,
  owner = {magsilva},
  publisher = {SBC},
  timestamp = {2008.07.31},
  year = {1996}
}

@INCOLLECTION{Kay:1996,
  author = {Kay, Alan C.},
  title = {History of programming languages II},
  publisher = {ACM},
  year = {1996},
  editor = {Bergin,Jr., Thomas J. and Gibson,Jr., Richard G.},
  chapter = {The early history of Smalltalk},
  pages = {511--598},
  address = {New York, NY, USA},
  abstract = {Most ideas come from previous ideas. The sixties, particularly in the ARPA community, gave rise to a host of notions about ``human-computer symbiosis'' through interactive time-shared computers, graphics screens, and pointing devices. Advanced computer languages were invented to simulate complex systems such as oil refineries and semi-intelligent behavior. The soon to follow paradigm shift of modern personal computing, overlapping window interfaces, and object-oriented design came from seeing the work of the sixties as something more than a ``better old thing.'' That is, more than a better way: to do mainframe computing; for end-users to invoke functionality; to make data structures more abstract. Instead the promise of exponential growth in computing/$/volume demanded that the sixties be regarded as "almost a new thing" and to find out what the actual "new things" might be. For example, one would compute with a handheld "Dynabook" in a way that would not be possible on a shared main-frame; millions of potential users meant that the user interface would have to become a learning environment along the lines of Montessori and Bruner; and needs for large scope, reduction in complexity, and end-user literacy would require that data and control structures be done away with in favor of a more biological scheme of protected universal cells interacting only through messages that could mimic any desired behavior.Early Smalltalk was the first complete realization of these new points of view as parented by its many predecessors in hardware, language, and user interface design. It became the exemplar of the new computing, in part, because we were actually trying for a qualitative shift in belief structures -- a new Kuhnian paradigm in the same spirit as the invention of the printing press -- and thus took highly extreme positions that almost forced these new styles to be invented.},
  doi = {10.1145/234286.1057828},
  isbn = {0-201-89502-1}
}

@INPROCEEDINGS{Kay:1993,
  author = {Kay, Alan C.},
  title = {The early history of {Smalltalk}},
  pages = {69--95},
  doi = {10.1145/154766.155364},
  abstract = {Most ideas come from previous ideas. The sixties, particularly in the ARPA community, gave rise to a host of notions about ``human-computer symbiosis'' through interactive time-shared computers, graphics screens and pointing devices. Advanced computer languages were invented to simulate complex systems such as oil refineries and semi-intelligent behavior. The soon to follow paradigm shift of modern personal computing, overlapping window interfaces, and object-oriented design came from seeing the work of the sixties as something more than a ``better old thing''. That is, more than a better way: to do mainframe computing; for end-users to invoke functionality; to make data structures more abstract. Instead the promise of exponential growth in computing/$/volume demanded that the sixties be regarded as ``almost a new thing'' and to find out what the actual ``new things'' might be. For example, one would compute with a handheld ``Dynabook'' in a way that would not be possible on a shared mainframe; millions of potential users meant that the user interface would have to become a learning environment along the lines of Montessori and Bruner; and needs for large scope, reduction in complexity, and end-user literacy would require that data and control structures be done away with in favor of a more biological scheme of protected universal cells interacting only through messages that could mimic any desired behavior. Early Smalltalk was the first complete realization of these new points of view as parented by its many predecessors in hardware, language and user interface design. It became the exemplar of the new computing, in part, because we were actually trying for a qualitative shift in belief structures -- a new Kuhnian paradigm in the same spirit as the invention of the printing press -- and thus took highly extreme positions which almost forced these new styles to be invented.},
  series = {HOPL-II},
  address = {New York, NY, USA},
  booktitle = {SIGPLAN Conference on History of Programming Languages},
  isbn = {0-89791-570-4},
  location = {Cambridge, MA, #USA#},
  publisher = {ACM},
  year = {1993}
}

@INPROCEEDINGS{Kay:1972,
  author = {Alan C. Kay},
  title = {A Personal Computer for Children of All Ages},
  pages = {1-11},
  doi = {10.1145/800193.1971922},
  abstract = {This note speculates about the emergence of personal, portable information manipulators and their effects when used by both children and adults. Although it should be read as science fiction, current trends in miniaturization and price reduction almost guarantee that many of the notions discussed will actually happen in the near future.},
  volume = {1},
  address = {Boston, MA, EUA},
  booktitle = {ACM National Conference},
  location = {Boston, MA, EUA},
  month = aug,
  publisher = {ACM},
  timestamp = {2008.10.01},
  year = {1972}
}

@ARTICLE{kay-knaack:2007,
  author = {Robin H. Kay and Liesel Knaack},
  title = {Evaluating the learning in learning objects},
  volume = {22},
  number = {1},
  year = {2007},
  pages = {5-28},
  journal = {Open Learning},
  timestamp = {2008.09.27}
}

@ARTICLE{Kazman-etal:1996,
  author = {Kazman, R. and Abowd, G. and Bass, L. and Clements, P.},
  title = {Scenario-based analysis of software architecture},
  volume = {13},
  number = {6},
  year = {1996},
  pages = {47-55},
  doi = {10.1109/52.542294},
  keywords = {software development management, software quality, software reliability, systems analysisSoftware Architecture Analysis Method, anticipated system uses, case study report, developer views, high level design needs, quality attributes, quality criteria, scenario based analysis, software architecture, use contexts},
  issn = {0740-7459},
  journal = {Software, IEEE},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@MISC{kearsley:2002,
  author = {G. Kearsley},
  title = {Explorations in Learning \& Instruction: The Theory into Practice Database},
  url = {http://tip.psychology.org}
}

@MISC{software:phpmyadmin,
  author = {Tobias Ratschiller \and Marc Delisle \and Olivier MÃ¼ller \and Robin Johnson \and Alexander M. Turek \and Michal Cihar \and Garvin Hicking \and Michael Keck},
  title = {phpMyAdmin},
  howpublished = {Programa de computador},
  year = {1998},
  owner = {msilva},
  timestamp = {2006.02.24},
  url = {http://www.phpmyadmin.net}
}

@MISC{kegel:2004,
  author = {Dan Kegel},
  title = {Contributing to Open Source Projects HOWTO},
  howpublished = {Artigo publicado na Web},
  year = {2004},
  owner = {magsilva},
  timestamp = {2006.09.01},
  url = {http://www.kegel.com/academy/opensource.html}
}

@INPROCEEDINGS{keller-suzuki:1988,
  author = {J. M. Keller and K. Suzuki},
  title = {Use of the {ARCS} Motivation Model in Courseware Design},
  address = {Hillsdale, NJ},
  booktitle = {Instructional Designs for Microcomputer Courseware},
  owner = {magsilva},
  publisher = {Lawrence Erlbaum},
  timestamp = {2008.07.31},
  year = {1988}
}

@ARTICLE{Kennard-Leaney:2011,
  author = {Richard Kennard and John Leaney},
  title = {Is there convergence in the field of UI generation?},
  volume = {84},
  number = {12},
  year = {2011},
  pages = {2079 - 2087},
  doi = {10.1016/j.jss.2011.05.034},
  abstract = {For many software projects, the construction of the User Interface (UI) consumes a significant proportion of their development time. Any degree of automation in this area therefore has clear benefits. But it is difficult to achieve such automation in a way that will be widely adopted by industry because of the diversity of UIs, software architectures, platforms and development environments. In a previous article, the authors identified five key characteristics any UI generator would need in order to address this diversity. We asserted that, without these characteristics, a UI generator should not expect wide industry adoption or standardisation. We supported this assertion with evidence from industry adoption studies. A further source of validation would be to see if other research teams, who were also conducting industry field trials, were independently converging on this same set of characteristics. Conversely, it would be instructive if they were found to be converging on a different set of characteristics. In this article, the authors look for such evidence of convergence by interviewing the team behind one of the research community's most significant UI generators: Naked Objects. We observe strong signs of convergence, which we believe signal the beginning of a general purpose architecture for UI generation, one that both industry and the research community could standardise upon.},
  keywords = {User Interface Generation, Convergence, Naked Objects, Metawidget, Interview},
  issn = {0164-1212},
  journal = {Journal of Systems and Software}
}

@INPROCEEDINGS{Kernal:1999,
  author = {Kernal, Hadyn K.},
  title = {Effects of computer/television convergence on users' perception of content, equipment and affect},
  pages = {248--249},
  doi = {10.1145/632716.632869},
  abstract = {This 2 x 2 between subjects experiment examined the effects of label (computer or television) on users' evaluation of identical equipment and content (comedy show or web page). Content was evaluated more positively on key traits (humor and intelligence) when viewed via the traditional medium. The "computer" was perceived as superior on picture clarity, competence, and quality. "Computer" participants reported greater feelings of involvement, while "television" participants reported greater feelings of ease. "Television" participants demonstrated better memory for traditional television content than "computer" participants. These results extend prior research on labels and technology showing that there are important psychological implications for digital convergence.},
  keywords = {PC/TV, convergence, human-computer interaction, labels, social responses to communication technology},
  booktitle = {Conference on Human Factors in Computing Systems -- Extended Abstracts},
  isbn = {1-58113-158-5},
  location = {Pittsburgh, Pennsylvania, #USA#},
  month = may,
  publisher = {ACM},
  year = {1999}
}

@BOOK{Kernighan-Pike:1999,
  title = {The Practice of Programming},
  publisher = {Addison-Wesley},
  year = {1999},
  author = {Brian W. Kernighan and Rob Pike},
  isbn = {0-201-61586-X},
  pages = {267},
  booktitle = {The Practice of Programming}
}

@MISC{kersten:2007,
  author = {Mik Kersten and Robert Elves and Brian Steele and others},
  title = {Mylyn Integrator Reference},
  owner = {magsilva},
  timestamp = {2007.10.29},
  url = {http://wiki.eclipse.org/index.php/Mylyn_Integrator_Reference}
}

@INPROCEEDINGS{Khadraoui:2008:SDE:1501750.1501872,
  author = {Khadraoui, Momouh and Hirsbrunner, Beat},
  title = {SMO (smart multimedia object) for distance education: learning via interactive digital TV - requirement and specification},
  pages = {422--422},
  doi = {10.1145/1501750.1501872},
  abstract = {This paper reports the implementation of the concepts of the Smart Multimedia Object model (SMO) as a simple IDTV application for distance education.},
  keywords = {IDTV, MHP emulator, Osmosys SDK, SMO, T-learning},
  address = {New York, NY, USA},
  booktitle = {2008 International Conference on Advances in Computer Entertainment Technology},
  isbn = {978-1-60558-393-8},
  location = {Yokohama, Japan},
  publisher = {ACM},
  year = {2008}
}

@INPROCEEDINGS{khadraoui-etal:2007,
  author = {Khadraoui, Momouh and Lorenz, P. and Hirsbrunner, B. and Khadraoui, D.},
  title = {A {SMO} interaction and management model for {iDTV} applications},
  pages = {277--279},
  doi = {10.1109/ICAT.2007.13},
  abstract = {This paper deals with interactive multimedia applications design whose main function is growing due to the users' needs that expect increasingly complex scenarios under a high level of interactivity. Digital media technology is becoming an integral part of our daily activities.Using multimedia objects in building rich and interactive content for iDTV (Interactive TV) is a complex task. In order to facilitate the way in which the user can freely interact with those multimedia objects makes the applications have to know how to adapt for the situations in order to improve the interaction. In such a context, we believe that the fact to converge on the principles of the smart multimedia objects is the right solution. Then we suggest, by the means of new approach,* the modelling of adaptable and reusable multimedia content called smart multimedia object (SMO) approach.},
  address = {Washington, DC, USA},
  booktitle = {17th International Conference on Artificial Reality and Telexistence},
  isbn = {0-7695-3056-7},
  publisher = {IEEE Computer Society},
  year = {2007}
}

@MISC{project:kham-academy,
  author = {Salman Khan and others},
  title = {{Khan Academy}},
  howpublished = project,
  month = sep,
  year = {2006},
  url = {http://www.khanacademy.org},
  urlaccessdate = {20 fev 2012}
}

@INPROCEEDINGS{Kim96CTTB,
  author = {H. Kim and C. Wu},
  title = {A Class Testing Technique Based on Data Bindings},
  pages = {104--109},
  booktitle = {Asia-Pacific Software Engineering Conference},
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1996}
}

@INPROCEEDINGS{Kim-etal:2005,
  author = {Kwang-Hoon Kim and Hyuk-Jae Yoo and Hak-Sung Kim},
  title = {A Process-Driven e-Learning Content Organization Model},
  pages = {328--333},
  doi = {10.1109/ICIS.2005.15},
  address = {Washington, DC, USA},
  booktitle = {ICIS '05: Proceedings of the Fourth Annual ACIS International Conference on Computer and Information Science},
  isbn = {0-7695-2296-3},
  publisher = {IEEE Computer Society},
  year = {2005}
}

@MISC{Kim92DMTT,
  author = {M. Kim},
  title = {Design of a Mutation Testing Tool for {C}},
  howpublished = {Department of Computer Sciences, Purdue University},
  month = apr,
  year = {1992},
  owner = {magsilva},
  pages = {1--8},
  timestamp = {2008.07.31}
}

@MISC{Kim98TOOP,
  author = {S. Kim},
  title = {Testing Object-Oriented Programs Using Mutation Techniques},
  howpublished = {Qualifying Dissertation},
  month = jun,
  year = {1998},
  address = {Department of Computer Science, University of York, UK},
  owner = {magsilva},
  timestamp = {2003.07.31},
  url = {http://www.cs.york.ac.uk/testsig/publications/index.html}
}

@INPROCEEDINGS{Kim00ATSA,
  author = {S. Kim and J. A. Clark and J. A. Mcdermid},
  title = {Assessing Test Set Adequacy for Object-Oriented Programs Using Class Mutation},
  pages = {72--83},
  booktitle = {Symposium on Software Technology ({SoST}'99)},
  mounth = {#sep#},
  note = {{D}isponível em http://www-users.cs.york.ac.uk/~jac/},
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {2000}
}

@INPROCEEDINGS{Kim00IATT,
  author = {S. Kim and J. A. Clark and J. A. Mcdermid},
  title = {Investigating the Applicability of Traditional Test Adequacy Criteria for Object-Oriented Programs},
  address = {Madrid, Spain},
  booktitle = {FESMA-AEMES'2000: The European Software Measurement Conference},
  month = oct,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {2000}
}

@INPROCEEDINGS{Kim00IEOO,
  author = {S. Kim and J. A. Clark and J. A. Mcdermid},
  title = {Investigating the Effectiveness of Object-Oriented Testing Strategies with the Mutation Method},
  pages = {4},
  address = {San Jose, CA},
  booktitle = {Symposium on Mutation Testing},
  month = oct,
  owner = {magsilva},
  publisher = {Kluwer Academic Publishers},
  timestamp = {2008.07.31},
  year = {2000}
}

@TECHREPORT{Kim99RGJM,
  author = {S. Kim and J. A. Clark and J. A. Mcdermid},
  title = {The Rigorous Generation of {J}ava Mutation Operators Using {HAZOP}},
  institution = {Department of Computer Science -- University of York},
  month = aug,
  year = {1999},
  address = {Heslington, York},
  note = {{D}isponível em http://www-users.cs.york.ac.uk/~jac/, Último acesso: 12/2003},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{kim-etal:1999,
  author = {Sunwoo Kim and John A. Clark and John A. McDermid},
  title = {The Rigorous Generation of {J}ava Mutation Operators Using {HAZOP}},
  booktitle = {12th International Conference on Software \& Systems Engineering and their Applications (ICSSEA 99)},
  month = dec,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1999}
}

@INPROCEEDINGS{Kim-etal:2004,
  author = {Kim, Sang-Hwan and Ok, Joonho and Kang, Hyun Joo and Kim, Min-Chul and Kim, Mijeong},
  title = {An interaction and product design of gesture based TV remote control},
  pages = {1548--1548},
  doi = {10.1145/985921.986124},
  keywords = {TV remote control, gesture, interaction, product design},
  address = {New York, NY, EUA},
  booktitle = {CHI '04 extended abstracts on Human factors in computing systems},
  isbn = {1-58113-703-6},
  location = {Vienna, Austria},
  publisher = {ACM},
  year = {2004}
}

@INPROCEEDINGS{Kim-etal:2000,
  author = {Sun-Woo Kim and John A. Clark and John A. McDermid},
  title = {Class Mutation: Mutation Testing for Object-Oriented Programs},
  pages = {9--12},
  abstract = {The program mutation is a testing technique that assesses the quality dof test input data by examining whether the test data can distinguish a set of alternate programs (representing specific types of faults) from the program under test. We have extended the conventional mutation method to be applicable for object-oriented (OO) programs. The method, termed Class Mutation, is a form of OO-directed selective mutation testing that focuses on plausible flaws related to the unique features in OO (Java) programming. This paper introduces the Class Mutation technique and describes the results of the case study performed to investigate the applicability of the technique.},
  booktitle = {{OOSS}: Object-Oriented Software Systems},
  month = oct,
  mounth = {#oct#},
  note = {{D}isponível em http://www-users.cs.york.ac.uk/~jac/, Último acesso: 12/2003},
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {2000}
}

@MISC{software:gimp,
  author = {Spencer Kimball and Peter Mattis and others},
  title = {GIMP},
  howpublished = {Programa de computador},
  month = {jan},
  year = {1996},
  owner = {magsilva},
  timestamp = {2007.08.14},
  url = {http://www.gimp.org}
}

@MISC{hibernateapi:2005,
  author = {Gavin King and Steve Ebersole and Anton van Straaten and Mikheil Kapanadze and Greg Luck and Emmanuel Bernard and Mathias Bogaert and Jason Carreira and Doug Currie and Gabe Hicks and David Channon and Helge Schulz and Steve Molitor and Colm O' Flaherty and etc},
  title = {Hibernate API Documentation},
  howpublished = {Web},
  month = {jun},
  year = {2005},
  comment = {04/06/2005},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://www.hibernate.org/hib\_docs/v3/api/}
}

@MISC{hibernate:2005,
  author = {Gavin King and Steve Ebersole and Anton van Straaten and Mikheil Kapanadze and Greg Luck and Emmanuel Bernard and Mathias Bogaert and Jason Carreira and Doug Currie and Gabe Hicks and David Channon and Helge Schulz and Steve Molitor and Colm O' Flaherty and others},
  title = {Hibernate - Relational Persistence for Idiomatic Java},
  howpublished = {Software},
  month = {may},
  year = {2005},
  owner = {Marco Aurélio Graciotto Silva},
  timestamp = {2008.07.30},
  url = {http://www.hibernate.org}
}

@ARTICLE{King76SEPT,
  author = {J. King},
  title = {Symbolic Execution and Program Testing},
  volume = {19},
  number = {7},
  year = {1976},
  journal = cacm,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@ARTICLE{King91FLSM,
  author = {K. N. King and A. J. Offutt},
  title = {A Fortran Language System for Mutation Based Software Testing},
  volume = {21},
  number = {7},
  month = jul,
  year = {1991},
  pages = {685--718},
  journal = spe,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@MISC{kitchenham:2005,
  author = {Barbara Kitchenham},
  title = {Evidence-Based Software Engineering and Systematic Reviews},
  howpublished = {Keynote Speech},
  year = {2005},
  owner = {magsilva},
  timestamp = {2006.11.09}
}

@TECHREPORT{Kitchenham:2004,
  author = {Barbara Kitchenham},
  title = {Procedures for Performing Systematic Reviews},
  institution = {Departament of Computer Science, Keele University},
  month = jul,
  year = {2004},
  number = {TR/SE-0401},
  address = {Keele, Reino Unido},
  url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.122.3308&rep=rep1&type=pdf},
  abstract = {The objective of this report is to propose a guideline for systematic reviews appropriate for software engineering researchers, including PhD students. A systematic review is a means of evaluating and interpreting all available research relevant to a particular research question, topic area, or phenomenon of interest. Systematic reviews aim to present a fair evaluation of a research topic by using a trustworthy, rigorous, and auditable methodology. The guideline presented in this report was derived from three existing guidelines used by medical researchers. The guideline has been adapted to reflect the specific problems of software engineering research. The guideline covers three phases of a systematic review: planning the review, conducting the review and reporting the review. It is at a relatively high level. It does not consider the impact of question type on the review procedures, nor does it specify in detail mechanisms needed to undertake meta-analysis.},
  issn = {1353-7776},
  owner = {magsilva},
  timestamp = {2007.08.20}
}

@INPROCEEDINGS{kitchenham-etal:2010:ease,
  author = {Barbara A. Kitchenham and David Budgen and O. Pearl Brereton},
  title = {The value of mapping studies -- A participant-observer case study},
  abstract = {We are strong advocates of evidence-based software engineering (EBSE) in general and systematic literature reviews (SLRs) in particular. We believe it is essential that the SLR methodology is being used constructively to support software engineering research. Aim: This study aims to assess the value of mapping studies which are a form of SLR that aims to identify and categorise the available research on a specific topic. Methods: We use a multi-case, participant observer case study using five examples of studies that were based on preceding mapping studies. Results: We identified 13 unique benefits that can accrue from basing research on a preceding mapping study of which only 2 were case specific. We also identified 9 problems associated with using preceding mapping studies of which two were case specific. Conclusions: Mapping studies can save time and effort for researchers and provide baselines to assist new research efforts. However, they must be of high quality in terms of completeness and rigour if they are to be a reliable basis for follow-on research.},
  address = {Keele University, UK},
  booktitle = {International Conference on Evaluation and Assessment in Software Engineering (EASE)},
  url = {http://www.bcs.org/content/conWebDoc/34782},
  year = {2010}
}

@ARTICLE{kitchenham-etal:2008,
  author = {Kitchenham, B.A. and Brereton, O.P. and Owen, S. and Butcher, J. and Jefferies, C.},
  title = {Length and readability of structured software engineering abstracts},
  volume = {2},
  number = {1},
  month = feb,
  year = {2008},
  pages = {37 -45},
  doi = {10.1049/iet-sen:20070044},
  abstract = {Attempts to perform systematic literature reviews have identified a problem with the quality of software engineering abstracts for papers describing empirical studies. Structured abstracts have been found useful for improving the quality of abstracts in many other disciplines. However, there have been no studies of the value of structured abstracts in software engineering. Therefore this paper aims to assess the comparative length and readability of unstructured abstracts and structured versions of the same abstract. Abstracts were obtained from all empirical conference papers from the Evaluation and Assessment in Software Engineering Conference (EASE04 and EASE06) that did not have a structured abstract (23 in total). Two novice researchers created structured versions of the abstracts, which were checked by the papers' authors (or a surrogate). Web tools were used to extract the length in words and readability in terms of the Flesch reading ease index and automated readability index (ARI) for the structured and unstructured abstracts. The structured abstracts were on average 142.5 words longer than the unstructured abstracts (p lt; 0.001). The readability of the structured abstracts was better by 8.5 points on the Flesch index (p lt; 0.001) and 1.8 points on the ARI (p lt; 0.003). The results are consistent with previous studies, although the increase in length and the increase in readability are both greater than the previous studies. Future work will consider whether structured abstracts increase the content and quality of abstracts.},
  keywords = {Flesch reading ease index;Web tools;abstracts quality;automated readability index;structured software engineering abstracts;Internet;data structures;software engineering;},
  issn = {1751-8806},
  journal = {IET Software}
}

@INPROCEEDINGS{kitchenham-etal:2010:icse,
  author = {Kitchenham, Barbara and Brereton, Pearl and Budgen, David},
  title = {The educational value of mapping studies of software engineering literature},
  pages = {589--598},
  doi = {10.1145/1806799.1806887},
  abstract = {We identify three challenges related to the provenance of the material we use in teaching software engineering. We suggest that these challenges can be addressed by using evidence-based software engineering (EBSE) and its primary tool of systematic literature reviews (SLRs). This paper aims to assess the educational and scientific value of undergraduate and postgraduate students undertaking a specific form of SLR called a mapping study. Using a case study methodology, we asked three postgraduate students and three undergraduates and their supervisor to complete a questionnaire concerning the educational value of mapping studies and any problems they experienced. Students found undertaking a mapping study to be a valuable experience providing both reusable research skills and a good overview of a research topic. Postgraduates found it useful as a starting point for their studies. Undergraduates reported problems undertaking the study in the required timescales. Searching and classifying the literature was difficult.},
  address = {Cape Town, South Africa},
  booktitle = {International Conference on Software Engineering (ICSE)},
  isbn = {978-1-60558-719-6},
  location = {Cape Town, South Africa},
  note = {SESSION: Software engineering in education: Effect of context in software engineering education},
  publisher = {ACM},
  year = {2010}
}

@INPROCEEDINGS{kitchenham-etal:isesem:2009,
  author = {Kitchenham, Barbara and Brereton, Pearl and Turner, Mark and Niazi, Mahmood and Linkman, Stephen and Pretorius, Rialette and Budgen, David},
  title = {The impact of limited search procedures for systematic literature reviews A participant-observer case study},
  pages = {336--345},
  doi = {10.1109/ESEM.2009.5314238},
  abstract = {This study aims to compare the use of targeted manual searches with broad automated searches, and to assess the importance of grey literature and breadth of search on the outcomes of SLRs. We used a participant-observer multi-case embedded case study. Our two cases were a tertiary study of systematic literature reviews published between January 2004 and June 2007 based on a manual search of selected journals and conferences and a replication of that study based on a broad automated search. Broad searches find more papers than restricted searches, but the papers may be of poor quality. Researchers undertaking SLRs may be justified in using targeted manual searches if they intend to omit low quality papers; if publication bias is not an issue; or if they are assessing research trends in research methodologies.},
  acmid = {1671280},
  address = {Washington, DC, USA},
  booktitle = {International Symposium on Empirical Software Engineering and Measurement},
  isbn = {978-1-4244-4842-5},
  numpages = {10},
  publisher = {IEEE Computer Society},
  year = {2009}
}

@TECHREPORT{Kitchenham-Charters:2007,
  author = {Barbara Kitchenham and Stuart Charters},
  title = {Guidelines for performing Systematic Literature Reviews in Software Engineering},
  institution = {Keele University and Durham University},
  year = {2007},
  number = {EBSE 2007-001},
  type = {Joint Report}
}

@ARTICLE{kitchenham-etal:1995,
  author = {B. Kitchenham and L. Pickard and S. L. Pfleeger},
  title = {Case Studies for Method and Tool Evaluation},
  volume = {12},
  month = jul,
  year = {1995},
  pages = {52-62},
  doi = {10.1109/52.391832},
  abstract = {Case studies help industry evaluate the benefits of methods and tools and provide a cost-effective way to ensure that process changes provide the desired results. However, unlike formal experiments and surveys, case studies do not have a well-understood theoretical basis. This article provides guidelines for organizing and analyzing case studies so that they produce meaningful results.},
  journal = {IEEE Software}
}

@ARTICLE{Kitchenham-etal:1999,
  author = {B. Kitchenham and G. H. Travassos and A. Maryhauser},
  title = {Towards an Ontology of Software Maintenance},
  volume = {11},
  number = {6},
  year = {1999},
  pages = {365--389},
  journal = {Journal of Sofware Maintenance: Research and Practice},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@ARTICLE{kleinberger-etal:2008,
  author = {Thomas Kleinberger and Andreas Holzinger and Paul Müller},
  title = {Adaptive multimedia presentations enabling universal access in technology enhanced situational learning},
  number = {(online first)},
  month = apr,
  year = {2008},
  doi = {10.1007/s10209-008-0122-3},
  journal = {Universal Access in the Information Society},
  owner = {magsilva},
  timestamp = {2008.09.03}
}

@MISC{software:fckeditor,
  author = {Frederico Caldeira Knabben},
  title = {FCKEditor},
  howpublished = {Programa de Computador},
  year = {2005},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://fckeditor.wikiwikiweb.de}
}

@BOOK{knapik:1998,
  title = {Developing Intelligent Agents for Distributed System: Exploring Architecture, Technologies and Applications},
  publisher = {McGraw Hill},
  year = {1998},
  author = {M. Knapik and J. Johnson},
  address = {EUA},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@ARTICLE{knight-etal:2006,
  author = {Colin Knight and Dragan Gasevic and Griff Richards},
  title = {An Ontology-Based Framework for Bridging Learing Design and Learning Content},
  volume = {9},
  number = {1},
  year = {2006},
  pages = {23-37},
  journal = {Educational Technology \& Society},
  timestamp = {2008.09.26}
}

@MISC{software:ontolingua,
  author = {{Knowledge Systems Laboratory}},
  title = {Ontolingua Server},
  howpublished = {Programa de Computador},
  year = {2003},
  note = {http://www.ksl.stanford.edu/software/ontolingua},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@ARTICLE{Knuth:1989,
  author = {D. Knuth},
  title = {The Errors of {TeX}},
  volume = {19},
  number = {7},
  month = jul,
  year = {1989},
  pages = {607--685},
  journal = spe,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@BOOK{Knuth:1997,
  title = {The Art of Computer Programming: Fundamental Algorithms},
  publisher = {Addison-Wesley},
  year = {1997},
  author = {D. E. Knuth},
  isbn = {0-201-89683-4},
  pages = {650},
  address = {Reading, Massachusetts, } # USA,
  edition = {3},
  booktitle = {The Art of Computer Programming: Fundamental Algorithms}
}

@MISC{software:sharinga,
  author = {Martin Kompf and others},
  title = {Sharinga},
  howpublished = {Programa de Computador},
  month = jun,
  year = {2002},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://skaringa.sourceforge.net/}
}

@BOOK{Koohang-Harman:2007:theory,
  title = {Learning Objects: Theory, Praxis, Issues, and Trends},
  publisher = {Informing Science},
  year = {2007},
  author = {Alex Koohang and Keith Harman},
  editor = {Alex Koohang and Keith Harman},
  isbn = {83-922337-6-X},
  pages = {626},
  series = {Learning Objects},
  address = {Santa Rosa, California, USA},
  booktitle = {Learning Objects: Theory, Praxis, Issues, and Trends}
}

@BOOK{Koontz-ODonnel:1972,
  title = {Principles of Management: An Analysis of Managerial Functions},
  publisher = {McGraw-Hill},
  year = {1972},
  author = {Harold Koontz and Cyril O'Donnel},
  isbn = {978-0070353329},
  pages = {748},
  address = USA,
  owner = {magsilva},
  timestamp = {2014.09.24}
}

@ARTICLE{koper:2006,
  author = {Rob Koper},
  title = {Current Research in Learning Design},
  volume = {9},
  number = {1},
  year = {2006},
  pages = {13-22},
  abstract = {A 'learning design' is defined as the description of the teaching-learning process that takes place in a unit of learning (eg, a course, a lesson or any other designed learning event). The key principle in learning design is that it represents the learning activities and the support activities that are performed by different persons (learners, teachers) in the context of a unit of learning. The IMS Learning Design specification aims to represent the learning design of units of learning in a semantic, formal and machine interpretable way. Since its release in 2003 various parties have been active to develop tools, to experiment with Learning Design in practice, or to do research on the further advancement of the specification. The aim of this special issue is to provide an overview of current work in the area. This papers introduces Learning Design, analyses the different papers and provides an overview of current research in Learning Design. The major research issues are at the moment: a) the use of ontologies and semantic web principles & tools related to Learning Design; b) the use of learning design patterns; c) the development of learrning design authoring and content management systems, and d) the development of learning design players, including the issues how to use the integrated set of learning design tools in a variety of settings.},
  journal = {Educational Technology \& Society},
  timestamp = {2008.09.26}
}

@INPROCEEDINGS{Koper:2002,
  author = {R. Koper},
  title = {Educational Modelling Language: adding instructional design to existing specifications},
  booktitle = {Workshop Standardisierung im eLearning},
  owner = {magsilva},
  timestamp = {2008.07.30},
  year = {2002}
}

@MISC{Koper:2001,
  author = {R. Koper},
  title = {Modeling Units of Study from a Pedagogical Perspective: The Pedagogical Meta-Model behind {EML}},
  howpublished = {White paper (Open University of The Netherlands).},
  month = jun,
  year = {2001},
  abstract = {This text is a short summary of the work on pedagogical analysis carried out when EML (Educational Modelling Language) was being developed. Because we address pedagogical meta-models the consequence is that I must justify the underlying pedagogical models it describes. I have included a (far from complete) list with literature used in the pedagogical analysis. I am sorry for its length, but for every pedagogical meta-model it is crucial to define the space of models where it is 'meta' to. As an aid to comprehension, I will use UML diagrams to express static and dynamic relationships when appropriate. All diagrams are drawn from a conceptual perspective and not from an implementation perspective. This paper is provided as input for the IMS Learning Design group.},
  owner = {magsilva},
  timestamp = {2008.07.31},
  url = {http://hdl.handle.net/1820/36}
}

@ARTICLE{Koper-Manderveld:2004,
  author = {R. Koper and J. Manderveld},
  title = {Educational modelling language: modelling reusable, interoperable, rich and personalised units of learning},
  volume = {35},
  number = {5},
  month = sep,
  year = {2004},
  pages = {537--551},
  doi = {10.1111/j.0007-1013.2004.00412.x},
  abstract = {Nowadays there is a huge demand for flexible, independent learning without the constraints of time and place. Various trends in the field of education and training are the bases for the development of new technologies for education. This article describes the development of a learning technology specification, which supports these new demands for learning challenging the new technological possibilities. This specification is named Educational Modelling Language (EML) and is developed by the Open University of the Netherlands.},
  journal = {British Journal of Educational Technology},
  owner = {magsilva},
  publisher = {Blackwell Synergy},
  timestamp = {2008.07.30}
}

@ARTICLE{koper-etal:2003,
  author = {R. Koper and B. Olivier and T. Anderson},
  title = {{IMS Learning Design Information Model}},
  year = {2003},
  journal = {IMS Global Learning Consortium},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@INPROCEEDINGS{Korel85TDFO,
  author = {B. Korel and J. W. Laski},
  title = {A Tool for Data Flow Oriented Program Testing},
  pages = {34--38},
  address = {San Francisco, CA},
  booktitle = {Softfair II},
  month = dec,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1985}
}

@INPROCEEDINGS{kostur:2002,
  author = {Pamela Kostur},
  title = {Connecting learners with content: a unified content strategy for learning materials},
  pages = {100--103},
  doi = {10.1145/584955.584970},
  address = {New York, NY, USA},
  booktitle = {SIGDOC '02: Proceedings of the 20th annual international conference on Computer documentation},
  isbn = {1-58113-543-2},
  location = {Toronto, Ontario, Canada},
  publisher = {ACM},
  year = {2002}
}

@INPROCEEDINGS{koto-etal:2010,
  author = {Koto, H. and Hiehata, Y. and Uemura, S. and Nakamura, H.},
  title = {Analysis of control accuracy for access control method based on sample monitoring in interactive TV services},
  pages = {991--998},
  doi = {10.1109/INDIN.2010.5549605},
  abstract = {With the widespread of terminals, such as mobile phones, equipped with both Digital TV reception capability and Internet connectivity, interactive TV services are becoming more popular and useful. This paper analyses the control accuracy of the access control method proposed for interactive TV services. The proposed method performs access control by utilizing random sampling and estimation. Therefore, error during control is somewhat inevitable and the accuracy of control becomes a problem. This paper analyses the cause of the various types of error expected while adopting the proposed method. The control accuracy and the volume of error of the proposed method are evaluated through numerical calculation. The obtained results quantitatively demonstrate the maximum values and the range of the control error when the proposed method is applied. Based on the obtained insights and results, adequate settings of control parameters and capacity planning of the system providing interactive TV services are illustrated.},
  keywords = {Internet connectivity;access control method;capacity planning;control accuracy analysis;digital TV reception capability;interactive TV services;mobile phones;monitoring;numerical calculation;random estimation;random sampling;interactive television;monitoring;telecommunication congestion control;},
  booktitle = {Industrial Informatics (INDIN), 2010 8th IEEE International Conference on},
  month = jul,
  year = {2010}
}

@INPROCEEDINGS{koto-etal:2008,
  author = {Koto, H. and Hoshino, H. and Hiehata, Y. and Uemura, S. and Nakamura, H.},
  title = {Access Control Method Based on Sample Monitoring for Volatile Traffic in Interactive TV Services},
  pages = {1-6},
  doi = {10.1109/GLOCOM.2008.ECP.267},
  abstract = {This paper proposes an access control method based on sample monitoring for volatile traffic in interactive TV services. The proposed method controls the access of interactive TV users by utilizing the following functions. Firstly, the total volume of access induced by all users is accurately estimated by measuring the volume of access induced by sample users. Then, based on the estimated results, access from other non-sample users is controlled so that they are induced within the system capacity. By applying the proposed method, congestion and overload expected during interactive TV services is effectively avoided, even when the volume of induced access momentarily exceeds the system capacity. The performance of the proposed method is evaluated through experiments on a test bed where a vast number of access is generated. The obtained results quantitatively demonstrate its effectiveness.},
  keywords = {access control method;congestion avoidance;digital television broadcasting;interactive TV service;volatile traffic sample monitoring;digital television;interactive television;telecommunication congestion control;telecommunication traffic;television broadcasting;},
  booktitle = {IEEE Global Telecommunications Conference (IEEE GLOBECOM 2008)},
  issn = {1930-529X},
  month = dec,
  year = {2008}
}

@BOOK{kotonya:1998,
  title = {Requirements engineering : processes and techniques},
  publisher = {J. Wiley},
  year = {1998},
  author = {Gerald Kotonya and Ian Sommerville},
  series = {Worldwide series in computer science},
  address = {New York: EUA},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@BOOK{kotonya:1997,
  title = {Requirements Engineering: process and techniques},
  publisher = {John Wiley \& Sons},
  year = {1997},
  author = {Gerald Kotonya and Ian Sommerville},
  address = {Inglaterra},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@TECHREPORT{kotonya:1995,
  author = {Gerald Kotonya and Ian Sommerville},
  title = {Requirements Engineering With Viewpoints},
  institution = {Lancaster University, Computing Departament},
  year = {1995},
  address = {Reino Unido},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@INBOOK{kovse-harder:2002,
  pages = {183-190},
  title = {Generic {XMI}-Based {UML} Model Transformations},
  publisher = {Springer Berlin / Heidelberg},
  year = {2002},
  editor = {Bellahsène, Zohra and Patel, Dilip and Rolland, Colette},
  author = {Kovse, Jernej and Härder, Theo},
  volume = {2425},
  series = {Lecture Notes in Computer Science},
  abstract = {XML-based Metadata Interchange (XMI) is an interchange format for metadata defined in terms of the MOF standard. In addition to supporting the exchange of complete models, XMI supports the exchange of models in differential form. Our paper builds on this feature to examine the possibility of XMI-based generic transformations of UML models. A generic transformation can be configured to generate (via XSLT) a specialized transformation that will be used to transform a UML model. The approach promotes model reuse, speeds up the modeling process and can be used to assure that only predefined semantics (as specialized by an agent) is included in the transformed model.},
  booktitle = {Object-Oriented Information Systems},
  doi = {10.1007/3-540-46102-7_24}
}

@INPROCEEDINGS{kozak-etal:2000,
  author = {Dalton Vinicius Kozak and Flávio Bortolozzi and Henri Frederico Eberspächer and Marco Antonio Eleuterio},
  title = {Produção de Mídias Educacionais no Laboratório de Mídias Interativas da PUCPR},
  booktitle = {Workshop de Educação em Informática},
  timestamp = {2008.08.01},
  year = {2000}
}

@MISC{software:fangs,
  author = {Peter Krantz},
  title = {Fangs},
  howpublished = {Programa de computador},
  month = {nov},
  year = {2004},
  owner = {magsilva},
  timestamp = {2007.08.13},
  url = {http://sourceforge.net/projects/fangs}
}

@ARTICLE{krasner:1988,
  author = {Glenn E. Krasner and Stephen T. Pope},
  title = {A cookbook for using the model-view controller user interface paradigm in Smalltalk-80},
  volume = {1},
  number = {3},
  month = {aug},
  year = {1988},
  pages = {26 - 49},
  journal = {Journal of Object-Oriented Programming},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@BOOK{Krathwohl-etal:1964,
  title = {Taxonomy of Educational Objectives: The Classification of Educational Goals (Handbook 2: Affective Domain)},
  publisher = {Longmans, Green and Co},
  year = {1964},
  author = {David R. Krathwohl and Benjamin S. Bloom and Bertram B. Masia},
  address = {EUA},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@ARTICLE{Krauser88HPST,
  author = {E. W. Krauser and A. P. Mathur and V. J. Rego},
  title = {High Performance Software Testing on SIMD Machines},
  volume = {SE-17},
  number = {5},
  month = may,
  year = {1991},
  pages = {403--422},
  journal = ieeese,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@ARTICLE{Krauss-Ally:2005,
  author = {Ferdinand Krauss and Mohamed Ally},
  title = {A Study of the Design and Evaluation of a Learning Object and Implications for Content Development},
  volume = {1},
  year = {2005},
  pages = {1-22},
  journal = {Interdisciplinary Journal of Knowledge and Learning Objects},
  owner = {magsilva},
  timestamp = {2008.09.28}
}

@ARTICLE{kreger:2001,
  author = {H. Kreger},
  title = {Web Services Conceptual Architecture (WSCA 1.0)},
  volume = {5},
  year = {2001},
  pages = {6--7},
  journal = {IBM Software Group},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@INPROCEEDINGS{Kreuzberger:2008:EIA:1453805.1453818,
  author = {Kreuzberger, Gunther and Hoppe, Imke and Dunker, Peter},
  title = {Entertaining iTV applications for local communities},
  pages = {59--62},
  doi = {10.1145/1453805.1453818},
  abstract = {Through evolving technical conditions, television offers rising possibilities to interact with programs. Hence, it might become some kind of individualized mass medium. At the same time the media choice changes. Interactive media like digital games or Web 2.0 applications rise significantly. This paper therefore deals with the systematic design of interactive TV applications and sug-gests a design-process model. Local communities are focused as an ideal target group for such applications, as they soonest meet the technical and social conditions for interactive TV applications.},
  keywords = {conception, entertainment, interactive tv, local community},
  address = {New York, NY, USA},
  booktitle = {1st international conference on Designing interactive user experiences for TV and video},
  isbn = {978-1-60558-100-2},
  location = {Silicon Valley, California, USA},
  publisher = {ACM},
  year = {2008}
}

@ARTICLE{Kroeker:2011,
  author = {Kroeker, Kirk L.},
  title = {A breakthrough in algorithm design},
  volume = {54},
  month = {September},
  year = {2011},
  pages = {13--15},
  doi = {10.1145/1995376.1995382},
  abstract = {Computer scientists at Carnegie Mellon University have devised an algorithm that might be able to solve a certain class of linear systems much more quickly than today's fastest solvers.},
  acmid = {1995382},
  address = {New York, NY, USA},
  issn = {0001-0782},
  issue = {9},
  issue_date = {September 2011},
  journal = {Communications of the ACM},
  numpages = {3},
  publisher = {ACM}
}

@BOOK{kruchten:1999,
  title = {The Rational Unified Process},
  publisher = {Addison Wesley},
  year = {1999},
  author = {Philippe Kruchten},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@BOOK{Kruse:2007,
  title = {Data Structures And Program Design In {C}},
  publisher = {Pearson Education},
  year = {2007},
  author = {Robert L. Kruse},
  isbn = {9788177584233},
  pages = {624},
  booktitle = {Data Structures And Program Design In {C}}
}

@INPROCEEDINGS{Kuijk-etal:2009,
  author = {Kuijk, Fons and Guimarães, Rodrigo Laiola and Cesar, Pablo and Bulterman, Dick C.A.},
  title = {Adding dynamic visual manipulations to declarative multimedia documents},
  pages = {149--152},
  doi = {10.1145/1600193.1600227},
  abstract = {The objective of this work is to define a document model extension that enables complex spatial and temporal interactions within multimedia documents. As an example we describe an authoring interface of a photo sharing system that can be used to capture stories in an open, declarative format. The document model extension defines visual transformations for synchronized navigation driven by dynamic associated content. Due to the open declarative format, the presentation content can be targeted to individuals, while maintaining the underlying data model. The impact of this work is reflected in its recent standardization in the W3C SMIL language. Multimedia players, as Ambulant and the RealPlayer, support the extension described in this paper.},
  keywords = {animation, content enrichment, declarative language, media annotation, pan and zoom, photo sharing, smil},
  series = {DocEng},
  booktitle = {9th ACM Symposium on Document Engineering},
  isbn = {978-1-60558-575-8},
  location = {Munich, #Germany#},
  publisher = {ACM},
  year = {2009}
}

@MISC{software:wink,
  author = {Satish Kumar},
  title = {Wink},
  howpublished = software,
  year = {2009},
  owner = {magsilva},
  timestamp = {2010.08.26},
  url = {http://www.debugmode.com/wink/}
}

@ARTICLE{Kung95DOOS,
  author = {D. Kung and J. Gao and P. Hsia and Y. Toyoshima and C. Chen and T. -S. Kim},
  title = {Developing Object-Oriented Software Testing and Maintenance Environment},
  month = oct,
  year = {1995},
  pages = {75--87},
  journal = comacm,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@ARTICLE{Kung96RTOO,
  author = {D. Kung and J.Gao and P. Hsia and Y. Toyoshima and C. Chen},
  title = {On Regression Testing of Object-Oriented Programs},
  volume = {32},
  year = {1996},
  pages = {21--40},
  journal = jss,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{Kung94OSTF,
  author = {D. Kung and Y. Lu and N. Venugopalan and P. Hsia and Y. Toyoshima and C. Chen and J. Gao},
  title = {Object State Testing and Fault Analysis for Reliable Software Systems},
  booktitle = {7th International Symposium on Software Reliability Engineering},
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1996}
}

@BOOK{Kung98TOOS,
  title = {Testing Object-Oriented Software},
  publisher = {IEEE Computer Society Press},
  year = {1998},
  author = {D. C. Kung and P. Hsia and J. Gao},
  address = {Los Alamitos, CA},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@ARTICLE{Kwan:1962,
  author = {Mei-Ko Kwan},
  title = {Graphic programming using odd or even points},
  volume = {1},
  year = {1962},
  pages = {273--277},
  journal = {Chinese Mathematics},
  timestamp = {2013-09-24}
}

@ARTICLE{LopezNores-etal:2009a,
  author = {L\ópez-Nores, Martín and Blanco-Fernández, Yolanda and Pazos-Arias, José J. and García-Duque, Jorge and Ramos-Cabrer, Manuel and Gil-Solla, Alberto and Díaz-Redondo, Rebeca P. and Fernández-Vilas, Ana},
  title = {Receiver-side semantic reasoning for digital {TV} personalization in the absence of return channels},
  volume = {41},
  month = feb,
  year = {2009},
  pages = {407--436},
  doi = {10.1007/s11042-008-0239-7},
  abstract = {Experience has proved that interactive applications delivered through Digital TV must provide personalized information to the viewers in order to be perceived as a valuable service. Due to the limited computational power of DTV receivers (either domestic set-top boxes or mobile devices), most of the existing systems have opted to place the personalization engines in dedicated servers, assuming that a return channel is always available for bidirectional communication. However, in a domain where most of the information is transmitted through broadcast, there are still many cases of intermittent, sporadic or null access to a return channel. In such situations, it is impossible for the servers to learn who is watching TV at the moment, and so the personalization features become unavailable. To solve this problem without sacrificing much personalization quality, this paper introduces solutions to run a downsized semantic reasoning process in the DTV receivers, supported by a pre-selection of material driven by audience stereotypes in the head-end. Evaluation results are presented to prove the feasibility of this approach, and also to assess the quality it achieves in comparison with previous ones.},
  keywords = {Digital TV, Ontologies, Personalization, Semantic reasoning, Stereotypes},
  acmid = {1499073},
  address = {Hingham, MA, USA},
  issn = {1380-7501},
  issue = {3},
  journal = {Multimedia Tools Appl.},
  numpages = {30},
  publisher = {Kluwer Academic Publishers}
}

@ARTICLE{Laender-etal:2008,
  author = {Laender, Alberto H. F. and de Lucena, Carlos J. P. and Maldonado, José Carlos and de Souza e Silva, Edmundo and Ziviani, Nivio},
  title = {Assessing the research and education quality of the top Brazilian Computer Science graduate programs},
  volume = {40},
  number = {2},
  month = jun,
  year = {2008},
  pages = {135--145},
  doi = {10.1145/1383602.1383654},
  abstract = {This article reports about a study conducted to assess the quality of the top Brazilian Computer Science graduate programs. The study is based on data from DBLP and considers the scientific production of these programs in the triennial 2004--2006. A comparison of the scientific production of the Brazilian programs against that of reputable programs in North America and Europe indicates that the former compares well with these programs, both in terms of publication rate and number of graduates. The study also shows that the Brazilian programs follow international publication ratios of more than two conference papers per journal article. These results are a clear indication that the Computer Science field has reached maturity in Brazil.},
  keywords = {Brazil, computer science, evaluation process, graduate program},
  acmid = {1383654},
  address = {New York, NY, USA},
  issn = {0097-8418},
  issue = {2},
  issue_date = {June 2008},
  journal = {SIGCSE Bulletin},
  numpages = {11},
  publisher = {ACM}
}

@ARTICLE{Lage-etal:2001,
  author = {Lage, Maureen J. and Platt, Glenn J. and Treglia, Michael},
  title = {Inverting the Classroom: A Gateway to Creating an Inclusive Learning Environment},
  volume = {31},
  number = {1},
  year = {2001},
  pages = {30-43},
  url = {http://econpapers.repec.org/RePEc:jee:journl:v:31:y:2000:i:1:p:30-43},
  journal = {Journal of Economic Education}
}

@MISC{software:latex,
  author = {Leslie Lamport and others},
  title = {LaTeX},
  howpublished = software,
  year = {1986},
  url = {http://www.latex-project.org}
}

@INPROCEEDINGS{lamsweerde:2001,
  author = {Axen van Lamsweerde},
  title = {Goal-Oriented Requirements Engineering: A Guided Tour},
  pages = {249-263},
  address = {Toronto, EUA},
  booktitle = {5th International Symposium on Requirements Engineeing},
  owner = {Marco Aurélio Graciotto Silva},
  timestamp = {2008.07.30},
  year = {2001}
}

@INPROCEEDINGS{lamsweerde:2000,
  author = {Axel van Lamsweerde},
  title = {Requirements engineering in the year 00: a research perspective},
  pages = {5-19},
  booktitle = {International Conference on Software Engineering},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://citeseer.nj.nec.com/vanlamsweerde00requirements.html},
  year = {2000}
}

@INPROCEEDINGS{landes:1995,
  author = {D. Landes and R. Studer},
  title = {The treatment of non-functional requirements in {MIKE}},
  pages = {294-306},
  booktitle = {European Software Engineering Conference},
  editor = {W. Sch{\"a}fer and P. Botella},
  owner = {magsilva},
  publisher = {Springer-Verlag},
  timestamp = {2008.07.30},
  year = {1995}
}

@ARTICLE{Landis-Koch:1977,
  author = {Landis, J. Richard and Koch, Gary G.},
  title = {The Measurement of Observer Agreement for Categorical Data},
  volume = {33},
  number = {1},
  month = mar,
  year = {1977},
  pages = {159-174},
  abstract = {This paper presents a general statistical methodology for the analysis of multivariate categorical data arising from observer reliability studies. The procedure essentially involves the construction of functions of the observed proportions which are directed at the extent to which the observers agree among themselves and the construction of test statistics for hypotheses involving these functions. Tests for interobserver bias are presented in terms of first-order marginal homogeneity and measures of interobserver agreement are developed as generalized kappa-type statistics. These procedures are illustrated with a clinical diagnosis example from the epidemiological literature.},
  url = {http://www.jstor.org/stable/2529310},
  copyright = {Copyright © 1977 International Biometric Society},
  issn = {0006341X},
  journal = {Biometrics},
  jstor_articletype = {research-article},
  jstor_formatteddate = {Mar., 1977},
  language = {English},
  publisher = {International Biometric Society}
}

@ARTICLE{lang:2005,
  author = {Michael Lang and Brian Fitzgerald},
  title = {Hypermedia Systems Development Practices: A Survey},
  volume = {22},
  number = {2},
  month = mar,
  year = {2005},
  pages = {68- 75},
  journal = {IEEE Software},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@INPROCEEDINGS{Lange94OODM,
  author = {D. B. Lange},
  title = {An Object-Oriented Design Method for Hypermedia Information Systems},
  pages = {366--375},
  address = {New York, NY},
  booktitle = {International Conference on System Sciences},
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1994}
}

@BOOK{Langsam-etal:1996,
  title = {Data Structure Using {C} and {C++}},
  publisher = {Prentice Hall},
  year = {1996},
  author = {Yedidyah Langsam and Moshe J. Augenstein and Aaron M. Tenenbaum},
  isbn = {0-13-036997-7},
  pages = {672},
  address = {Upper Saddle River, NJ, } # USA,
  edition = {2},
  booktitle = {Data Structure Using {C} and {C++}}
}

@BOOK{Larman:2007,
  title = {Utilizando {UML} e Padrões},
  publisher = {Bookman},
  year = {2007},
  author = {Craig Larman},
  isbn = {0-13-148906-2},
  pages = {695},
  address = {Porto Alegre, RS, } # Brazil,
  edition = {3},
  note = {Tradução por Rosana T. Vaccare Braga et al.},
  booktitle = {Utilizando {UML} e Padrões},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@BOOK{Larman:2001,
  title = {Applying {UML} and Patterns: An Introduction to Object-Oriented Analysis and Design and the Unified Process},
  publisher = {Prentice Hall},
  year = {2001},
  author = {Craig Larman},
  isbn = {0130925691},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@ARTICLE{larsson:unknow,
  author = {Magnus Larsson and Ivica Crnkovic},
  title = {New Challenges for Configuration Managment},
  pages = {232-243},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@TECHREPORT{lassila:1999,
  author = {O. Lassila and R. R. Swick},
  title = {Resource Description Framework (RDF) Model and Syntax Specification},
  institution = {W3C},
  year = {1999},
  url = {http://www.w3c.org/TR/REC-rdf-syntax},
  howpublished = {W3C Recommendation},
  owner = {magsilva},
  timestamp = {2008.07.30},
  type = {W3C Recommendation}
}

@INPROCEEDINGS{Law:2008:TSD:1358628.1358693,
  author = {Law, Effie and Roto, Virpi and Vermeeren, Arnold P.O.S. and Kort, Joke and Hassenzahl, Marc},
  title = {Towards a shared definition of user experience},
  pages = {2395--2398},
  doi = {10.1145/1358628.1358693},
  abstract = {User experience (UX) is still an elusive notion with many different definitions, despite some recent attempts to develop a unified view on UX. The lack of a shared definition of UX not only confuses or even misleads customers of a product/service but also undermines the effectiveness of researching, managing and teaching UX. Diverse ideas have been generated in scientific activities that aim to develop a common understanding about the meaning and scope of UX. It is plausible, with sound methodologies, to converge these divergences, driving the UX community closer to a common definition and integrated views of UX. This SIG tackles this challenge by systematically assembling a set of existing definitions and viewpoints of UX and collecting opinions on them from known UX experts/researchers and general CHI'08 attendees.},
  keywords = {definition, usability, user experience},
  address = {New York, NY, USA},
  booktitle = {CHI '08 extended abstracts on Human factors in computing systems},
  isbn = {978-1-60558-012-8},
  location = {Florence, Italy},
  publisher = {ACM},
  year = {2008}
}

@INPROCEEDINGS{Lazzari:2007:TGE:1766591.1766637,
  author = {Lazzari, Marco and Betella, Alberto},
  title = {Towards guidelines on educational podcasting quality: problems arising from a real world experience},
  pages = {404--412},
  abstract = {This paper presents an experience of educational podcasting set up at the University of Bergamo (Italy), and derives from that experience some remarks upon the quality of podcasting services, in order to promote the definition of guidelines on podcasting quality. We discuss three main attributes of a podcasting environment: quality of the production environment (recording and editing), quality of the product (content and communication style), quality of the distribution environment (paratext and management).},
  keywords = {collaborative learning, computer science education, distance education, distance learning, educational podcasting, experimentation, freeware/shareware, mobile learning, open source, podcast, quality of podcasting},
  acmid = {1766637},
  address = {Berlin, Heidelberg},
  booktitle = {Proceedings of the 2007 conference on Human interface: Part II},
  isbn = {978-3-540-73353-9},
  location = {Beijing, China},
  numpages = {9},
  publisher = {Springer-Verlag},
  url = {http://portal.acm.org/citation.cfm?id=1766591.1766637},
  year = {2007}
}

@ARTICLE{Leacock-Nesbit:2007,
  author = {Tracey L. Leacock and John C. Nesbit},
  title = {A Framework for Evaluating the Quality of Multimedia Learning Resources},
  volume = {10},
  number = {2},
  year = {2007},
  pages = {44-59},
  abstract = {This article presents the structure and theoretical foundations of the Learning Object Review Instrument (LORI), an evaluation aid available through the E-Learning Research and Assessment Network at http://www.elera.net. A primary goal of LORI is to balance assessment validity with efficiency of the evaluation process. The instrument enables learning object users to create reviews consisting of ratings and comments on nine dimensions of quality: content quality, learning goal alignment, feedback and adaptation, motivation, presentation design, interaction usability, accessibility, reusability, and standards compliance. The article presents research and practices relevant to these dimensions and describes how each dimension can be interpreted to evaluate multimedia learning resources.},
  keywords = {eLera, Learning resource, quality, LORI, learning object},
  issn = {1436-4522, 1176-3647},
  journal = {Educational Technology \& Society},
  lang = {en},
  publisher = {IFETS},
  timestamp = {2008.09.28}
}

@INPROCEEDINGS{lee:1998,
  author = {Heeseok Lee and Choongseok Lee and Cheonsoo Yoo},
  title = {A scenario-based object-oriented methodology for developing hypermedia information systems},
  pages = {47 - 56},
  volume = {2},
  booktitle = {Proceedings of the Thirty-First Hawaii International Conference on System Sciences},
  file = {A scenario-based object-oriented methodology for developing hypermedia information systems.pdf:A scenario-based object-oriented methodology for developing hypermedia information systems.pdf:PDF},
  month = jan,
  owner = {magsilva},
  timestamp = {2008.07.30},
  year = {1998}
}

@ARTICLE{lee:2008,
  author = {Lee, Joonghoon},
  title = {Exploring global terrorism data: a web-based visualization of temporal data},
  volume = {15},
  month = dec,
  year = {2008},
  pages = {7--14},
  doi = {10.1145/1519390.1519393},
  acmid = {1519393},
  address = {New York, NY, USA},
  issn = {1528-4972},
  issue = {2},
  journal = {Crossroads},
  numpages = {8},
  publisher = {ACM}
}

@INBOOK{Lee-Baik:2004,
  pages = {437-440},
  title = {A Model for Extracting Keywords of Document Using Term Frequency and Distribution},
  publisher = {Springer},
  year = {2004},
  editor = {Gelbukh, Alexander},
  author = {Lee, Jae-Woo and Baik, Doo-Kwon},
  volume = {2945},
  series = {Lecture Notes in Computer Science},
  note = {5th International Conference on Computational Linguistics and Intelligent Text Processing. Seoul, South Korea, February, 2004.},
  abstract = {In information retrieval systems, it is very important that indexing is defined very well by appropriate terms about documents. In this paper, we propose a simple retrieval model based on terms distribution characteristics besides term frequency in documents. We define the keywords distribution characteristics using a statistics, standard deviation. We can extract document keywords that term frequency is great and standard deviation is great. And if term frequency is great and standard deviation is small, the terms can be defined as paragraph keywords. Applying our proposed retrieval model we can search many documents or knowledge using the document keywords and paragraph keywords.},
  affiliation = {Software System Lab., Dept. of Computer Science &amp; Engineering, Korea University, 1, 5-ka, Anam-dong, SungBuk-ku, 136-701 Seoul, Korea},
  booktitle = {Computational Linguistics and Intelligent Text Processing},
  doi = {10.1007/978-3-540-24630-5_53}
}

@ARTICLE{Lee:2007,
  author = {Lee, Newton},
  title = {Interview with Konstantinos Chorianopoulos},
  volume = {5},
  number = {2},
  month = apr-jun,
  year = {2007},
  doi = {10.1145/1279540.1279542},
  abstract = {Konstantinos Chorianopoulos is an European Community (EC) Marie Curie Fellow at the Department of Architecture at the Bauhaus University of Weimar. Konstantinos is also an Adjunct Lecturer at the Department of Product and Systems Design Engineering at the University of the Aegean. He has participated in many EC-funded research projects in the field of human-computer interaction for information, communication and entertainment applications in TV, mobile, and situated computing devices. He is the founder of UITV.INFO, a newsletter and web portal for interactive television research resources (papers, theses), news and events. In the video interview, you will hear Konstantinos' answers to the following questions: 1. What is interactive TV? 2. What is the role of ITV in learning and entertainment? 3. What is one of the most successful applications of ITV so far? 4. What are some of the major research areas in ITV? 5. How do you envision the future growth of ITV?},
  address = {New York, NY, USA},
  issn = {1544-3574},
  journal = {Computers in Entertainment},
  publisher = {ACM}
}

@BOOK{lee-owens:2000,
  title = {Multimedia-Based Instructional Design: Computer-Based Training, Web-Based Training, Distance Broadcast Training},
  publisher = {Pfeiffer},
  year = {2000},
  author = {W. W. Lee and D. L. Owens},
  pages = {384},
  address = {San Francisco, CA},
  month = jun,
  owner = {magsilva},
  timestamp = {2008.01.21}
}

@INPROCEEDINGS{Leiba-Nachmias:2006,
  author = {Leiba, M. and Nachmias, R.},
  title = {A Knowledge Building Community -- Constructing a Knowledge Model Using Online Concept Maps},
  pages = {147-151},
  doi = {10.1109/ITRE.2006.381552},
  abstract = {Knowledge models are structured representations of knowledge using symbols to represent components of knowledge and relationships between them while a knowledge building community involves a collection of individuals sharing a mutual interest - the construction of knowledge. This study examines a knowledge building community involved in constructing a knowledge model through the process of concept mapping in academic instruction in a Web-based learning environment. The study aimed to explore students' usage, their attitudes and limitations in using concept maps as an online collaborative knowledge model. Results suggest that when using concept maps as a shared knowledge model in a Web-based learning environment, one should consider three limitations: the subjective nature of the concept maps, technological aspects and the scalability of the model.},
  keywords = {Concept Maps , Higher Education , Knowledge Building Community , Knowledge Models , Web Based Learning Environment},
  series = {International Conference on Information Technology},
  address = {Tel-Aviv},
  booktitle = {International Conference on Information Technology: Research and Education},
  editor = {Ron Shmueli},
  isbn = {1-4244-0858-X},
  issn = {2006938369},
  location = {Tel Aviv, Israel},
  month = oct,
  publisher = {IEEE Communication Society},
  year = {2006}
}

@INPROCEEDINGS{leigh-etal:2007,
  author = {Elyssebeth Leigh and Wendy Meyers and Elizabeth Rosser},
  title = {Learning design discussions: A conversation tool},
  booktitle = {Ascilite Singapure 2007},
  timestamp = {2008.09.26},
  year = {2007}
}

@MASTERSTHESIS{Leitao92STEP,
  author = {P. S. J. Leitão},
  title = {Suporte ao Teste Estrutural de Programas Cobol no Ambiente POKE-TOOL},
  school = {DCA/FEE/UNICAMP},
  year = {1992},
  address = {Campinas, SP},
  month = aug,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@ARTICLE{Leite-etal:2005,
  author = {Luiz Eduardo Cunha Leite and Carlos Eduardo Coelho Freire Batista and Guido Lemos de Souza Filho and Raoni Kulesza and Luiz Gustavo Pacola Alves and Graça Bressan and Rogerio Ferreira Rodrigues and Luiz Fernando Gomes Soares},
  title = {{FlexTV} -- Uma Proposta de Arquitetura de Middleware para o Sistema Brasileiro de {TV} Digital},
  number = {2},
  month = nov,
  year = {2005},
  pages = {29-50},
  abstract = {As diversas propostas de Sistema de Televisão Digital trazem consigo a especificação de middlewares que possibilitam a execução de programas de televisão interativos nos Receptores Digitais ou Terminais de Acesso, escondendo dos mesmos a complexidade dos mecanismos definidos pelos protocolos de comunicação, do sistema operacional e do hardware do equipamento. É o middleware que define a interface para tais programas e, por conseguinte, quais funcionalidades poderão ser oferecidas pelos aparelhos de televisão para seus usuários. Visando promover a inclusão social e digital da população brasileira, é extremamente importante que o middleware a ser adotado no Sistema Brasileiro de Televisão Digital permita o desenvolvimento de programas mais adequados à realidade desse público. Realidade esta diferente daquela encontrada em outros países que já definiram seus Sistemas de Televisão Digital. Não obstante, esse middleware também deve possuir alinhamento com padrões internacionais, de forma a possibilitar a exportação do conteúdo televisivo produzido no país, bem como a exibição de conteúdo produzido por outros países nos televisores do Brasil, promovendo, dessa forma, o desenvolvimento econômico e o intercâmbio cultural no país. Este trabalho apresenta a arquitetura do middleware FlexTV, que está sendo desenvolvido no contexto do projeto do Sistema Brasileiro de Televisão Digital. A arquitetura, que se baseia fortemente no uso de componentes de software, permite que o middleware adapte-se a diferentes tipos de aparelhos receptores e infra-estruturas de comunicação, através da adição ou remoção de componentes de software, de forma a torná-lo o mais adequado possível à realidade brasileira. A mesma característica também simplifica a tarefa de tornar o FlexTV compatível com os sistemas de televisão digital já em operação em outros países.},
  keywords = {TV Digital Interativa, Middleware, SBTVD},
  url = {http://www.pcs.poli.usp.br/revista/n2/r002a003.pdf},
  address = {São Paulo, SP, } # Brazil,
  issn = {1678-8435},
  journal = {Revista de Engenharia de Computação e Sistemas Digitais},
  publisher = {PCS-POLI-USP}
}

@PHDTHESIS{Leiva:2003,
  author = {Willie Dresler Leiva},
  title = {Um Modelo de Hipertexto para Apoio ao Ensino Mediado pela Web},
  abstract = {Atualmente há uma demanda crescente por aplicações hipermídia baseadas na WWW (World Wide Web), conhecidas como WIS (Web Information Systems). Esse novo tipo de aplicação apresenta requisitos adicionais aos sistemas de software clássicos, o que resulta na necessidade de investigar modelos mais adequados para apoiar o seu desenvolvimento. Em especial, os sistemas para apoio ao EaD (Ensino a Distância) baseados na Web apresentam características e requisitos ainda mais específicos. Os modelos atuais para modelagem e especificação de hiperdocumentos não são completamente adequados para representar características deste domínio, como a necessidade de acompanhamento dos aprendizes e a realização de avaliações diagnósticas e formativas. Isso motivou a proposta de um modelo para apoiar WISs voltados especificamente para EaD, denominado MDE (Modelo para Documentos Educacionais), que estende o modelo HMBS (Hyperdocument Model Based on Statecharts) para a descrição de conteúdo nesse domínio. O MDE adota como modelo formal subjacente uma variante da técnica Statecharts, cuja estrutura e semântica operacional possibilitam especificar a estrutura organizacional e a semântica navegacional de hiperdocumentos complexos. Adicionalmente, foi integrada ao MDE a técnica de mapeamento conceitual, que acrescenta um significado educacional aos grafos hierárquicos. Dessa forma, o modelo apresenta como pontos fortes a possibilidade de captar várias informações relevantes do comportamento do usuário no estudo do material disponível on-line e a disponibilização desses dados ao instrutor, como importante apoio à avaliação formativa. Como prova de conceito, foi desenvolvido o protótipo de um ambiente para autoria e oferecimento de cursos denominado ATEnA (Ambiente para Treinamento, Ensino e Aprendizagem). Esta tese apresenta também avaliações conceituais e práticas do modelo e do protótipo desenvolvidos.},
  keywords = {autoria hipermídia em ponto grande; CSS; cursos on-line; ensino a distância; especificação de hiperdocumentos; estadogramas; hipermídia adaptativa; HTML; JavaScript; modelo navegacional; MySQL; PHP; Sistema de Informação na WWW},
  school = {ICMC-USP},
  year = {2003},
  address = {São Carlos, SP, Brasil},
  month = jul,
  url = {http://www.teses.usp.br/teses/disponiveis/55/55134/tde-17112003-071043/},
  abstract-en = {here is an increasing demand for hypermedia applications based on the WWW (World Wide Web), known as Web Information Systems (WIS). These applications present specific requirements in addition to those of traditional software systems, thus fostering the need for investigating suitable models to support their development. In particular, systems for Distance Education based on the Web present very specific characteristics and requirements. Current models for hyperdocument modeling and specification are not completely suitable for representing domain specific characteristics such as the need of tracking student progress and evaluating their learning process through diagnostic and formative assessments. This scenario motivated the proposal of a model to support WISs targeted at distance education, called MDE (Model for Distance Education). MDE extends the HMBS (Hyperdocument Model Based on Statecharts) hyperdocument model to describe hypertext content in the educational domain. It adopts as its underlying model a variant of the Statecharts formal specification technique, whose organizational structure and operational semantics allows defining the organizational structure and navigational semantics of complex hyperdocuments. MDE also incorporates the technique of conceptual mapping, that adds educational meaning to hierarchical graphs. MDE's major strengths are thus the ability to capture relevant information about user behavior when studying on-line educational material and make such information available to the teacher / instructor in order to support formative assessment of students. As a proof of concept, the prototype of an environment for authoring and offering distance courses based on MDE has been developed, called ATEnA (Adaptive Training Environment with Support for Assessment). The results of practical and conceptual evaluations of the model and system developed are also presented in this thesis.},
  keywords-en = {adaptive hypermedia; CSS; Distance Teaching; HTML; hyperdocuments specification; hypermedia authoring in the large; JavaScript; MySQL; navigational model; on-line courses; PHP; statecharts; Web Information System},
  lang = {pt},
  outcomes = {Advisor: Paulo Cesar Masiero. Coadvidor: Maria Cristina Ferreira de Oliveira.},
  owner = {magsilva},
  timestamp = {2008.07.31},
  title-en = {A hypertext model to support Web-mediated teaching}
}

@MASTERSTHESIS{Lemos05TPOA,
  author = {O. A. L. Lemos},
  title = {Teste de programas orientados a aspectos: uma abordagem estrutural para {AspectJ}},
  school = {ICMC-USP},
  year = {2005},
  address = {São Carlos, SP, Brazil},
  month = feb,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{Lemos-etal:2006,
  author = {Lemos, Otávio Augusto Lazzarini and Ferrari, Fabiano Cutigi and Masiero, Paulo Cesar and Lopes, Cristina Videira},
  title = {Testing aspect-oriented programming Pointcut Descriptors},
  pages = {33--38},
  doi = {10.1145/1146374.1146380},
  abstract = {Pointcut Descriptors (PCDs) are used to specify sets of program join points with a common property where additional behavior should be applied. If PCDs are wrongly formulated, faults are injected into the program, because additional behavior will be applied to unintended join points or will fail to be applied to intended join points. In this paper we classify the types of faults that can occur in PCDs -- in terms of selected join points -- and present a two-step strategy to: 1) help the tester identifying extra join points selected by PCDs; and 2) help the tester identifying neglected join points that should be selected by PCDs in the first place. We focus on the first step but provide motivating examples and directions for both.},
  booktitle = {2nd Workshop on Testing Aspect-Oriented Programs},
  isbn = {1-59593-415-4},
  location = {Portland, ME, #USA#},
  month = jul,
  publisher = {ACM},
  year = {2006}
}

@INPROCEEDINGS{lemos:2006,
  author = {Otávio Augusto Lazzarini Lemos and Daniel Carnio Junqueira and Marco Aurélio Graciotto Silva and Renata Pontin de Mattos Fortes and John Stamey},
  title = {Using Aspect-Oriented PHP to Implement Crosscutting Concerns in a Collaborative Web System},
  booktitle = {ACM SigDoc},
  owner = {magsilva},
  timestamp = {2006.10.04},
  year = {2006}
}

@INPROCEEDINGS{Lemos-Masiero:2008,
  author = {Lemos, O.A.L. and Masiero, P.C.},
  title = {Using Structural Testing to Identify Unintended Join Points Selected by Pointcuts in Aspect-Oriented Programs},
  pages = {84 - 93},
  doi = {10.1109/SEW.2008.11},
  address = {Kassandra, Greece},
  booktitle = {Software Engineering Workshop (SEW '08)},
  month = oct,
  organization = {IEEE},
  owner = {magsilva},
  timestamp = {2010.08.22},
  year = {2008}
}

@BOOK{lennon:1997,
  title = {Hypermedia Systems and Applications: World Wide Web and Beyond},
  publisher = {Springer},
  year = {1997},
  author = {Jennifer A. Lennon},
  address = {Alemanha},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@ARTICLE{leo-etal:2004,
  author = {D. H. Leo and J. I. A. Perez and Y. A. Dimitriadis},
  title = {IMS learning design support for the formalization of collaborative learning patterns},
  year = {2004},
  pages = {350-354},
  keywords = {computer aided instruction, groupware CSCL, IMS learning design support, collaborative learning pattern, computer-supported collaborative learning, group-based learning, pedagogical approach},
  journal = {Advanced Learning Technologies, 2004. Proceedings. IEEE International Conference on},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@BOOK{leuf-cunningham:2001,
  title = {The Wiki way: quick collaboration on the Web},
  publisher = {Addison-Wesley},
  year = {2001},
  author = {Bo Leuf and Ward Cunningham},
  pages = {435},
  owner = {magsilva},
  timestamp = {2008.04.03}
}

@INPROCEEDINGS{Leung90SITS,
  author = {H. K. N. Leung and L. White},
  title = {A Study of Integration Testing and Software Regression at the Integration Level},
  pages = {290--301},
  address = {San Diego, CA},
  booktitle = {Conference on Software Maintenance-90},
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1990}
}

@ARTICLE{Levin:1973,
  author = {Levin, Leonid},
  title = {Universal search problem},
  volume = {9},
  number = {3},
  year = {1973},
  pages = {115--116},
  journal = {Problems of Information Transmission},
  owner = {magsilva},
  timestamp = {2014.03.05}
}

@ARTICLE{levin:1983,
  author = {Roy Levin and David D. Redell},
  title = {An Evalution of the Ninth SOSP Submissions - or - How (and How Not) to Write a Good Systems Paper},
  volume = {17},
  number = {3},
  month = jul,
  year = {1983},
  pages = {35-40},
  journal = {ACM SIGOPS Operating Systems Review},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@BOOK{lewis,
  title = {Elementos de Teoria da Computação},
  publisher = {Bookman},
  year = {2000},
  author = {Harry R. Lewis and Christos H. Papadimitrion},
  isbn = {0201895390},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@ARTICLE{Lewis:2006,
  author = {Lewis, James R.},
  title = {Sample sizes for usability tests: mostly math, not magic},
  volume = {13},
  number = {6},
  month = nov,
  year = {2006},
  pages = {29--33},
  doi = {10.1145/1167948.1167973},
  acmid = {1167973},
  address = {New York, NY, USA},
  issn = {1072-5520},
  issue = {6},
  journal = {interactions},
  numpages = {5},
  publisher = {ACM}
}

@INPROCEEDINGS{Lewis-Sauro:2009,
  author = {Lewis, James R. and Sauro, Jeff},
  title = {The Factor Structure of the System Usability Scale},
  pages = {94--103},
  doi = {10.1007/978-3-642-02806-9_12},
  abstract = {Since its introduction in 1986, the 10-item System Usability Scale (SUS) has been assumed to be unidimensional. Factor analysis of two independent SUS data sets reveals that the SUS actually has two factors --- Usable (8 items) and Learnable (2 items --- specifically, Items 4 and 10). These new scales have reasonable reliability (coefficient alpha of .91 and .70, respectively). They correlate highly with the overall SUS (<em>r</em> = .985 and .784, respectively) and correlate significantly with one another (<em>r</em> = .664), but at a low enough level to use as separate scales. A sensitivity analysis using data from 19 tests had a significant Test by Scale interaction, providing additional evidence of the differential utility of the new scales. Practitioners can continue to use the current SUS as is, but, at no extra cost, can also take advantage of these new scales to extract additional information from their SUS data. The data support the use of "awkward" rather than "cumbersome" in Item 8.},
  keywords = {SUS, System Usability Scale, factor analysis, learnability, learnable, psychometric evaluation, subjective usability measurement, usability, usable},
  address = {Berlin, Heidelberg},
  booktitle = {1st International Conference on Human Centered Design},
  isbn = {978-3-642-02805-2},
  location = {San Diego, CA, USA},
  publisher = {Springer},
  year = {2009}
}

@ARTICLE{Ley:2009,
  author = {Ley, Michael},
  title = {{DBLP}: some lessons learned},
  volume = {2},
  month = aug,
  year = {2009},
  pages = {1493--1500},
  abstract = {The DBLP Computer Science Bibliography evolved from an early small experimental Web server to a popular service for the computer science community. Many design decisions and details of the public XML-records behind DBLP never were documented. This paper is a review of the evolution of DBLP. The main perspective is data modeling. In DBLP persons play a central role, our discussion of person names may be applicable to many other data bases. All DBLP data are available for your own experiments. You may either download the complete set, or use a simple XML-based API described in an online appendix.},
  issn = {2150-8097},
  issue = {2},
  journal = {Proceedings of the VLDB Endowment},
  publisher = {VLDB Endowment}
}

@INPROCEEDINGS{luyi-etal:2004,
  author = {Luyi Li and Yanlin Zheng and Ogata, H. and Yano, Y.},
  title = {A framework of ubiquitous learning environment},
  pages = {345 - 350},
  doi = {10.1109/CIT.2004.1357219},
  abstract = { In the past years, during the research on ubiquitous learning, we have completely or partially explored three kinds of e-learning systems, PC-based (ECLUE), PDA-based (CLUE+), and mobile phone-based (CLUE+1). Based on these research backgrounds, we explore the concept and the construction of ubiquitous learning environment (ULE). ULE is established on the combinations between real world and virtual space, personal space and shared space. Learning in ULE is conducted in the interactions among three essential communicative elements: social human, object in real world, and artifact in virtual space. Learning process is social transfer process between tacit and explicit knowledge. Human-based social network and broad context-awareness are very important for various interactions and social knowledge building in ULE. This paper proposes a five-dimension representation method for context-awareness information description. Additionally, this paper also gives a simple discussion to related learning terms, including blending learning (BL), social and emotional learning (SEL), and service learning (SL), which are contributive to our deeper understanding to learning in ULE. On practical dimension, this paper presents an example model for ULE implementation by integrating three background learning systems.},
  keywords = { background learning systems; blending learning; context-awareness information description; emotional learning; five-dimension representation method; service learning; social learning; ubiquitous learning environment; computer aided instruction; distance learning; ubiquitous computing;},
  booktitle = {International Conference on Computer and Information Technology (CIT)},
  issn = { },
  month = sep,
  year = {2004}
}

@ARTICLE{li-etal:2008,
  author = {Qing Li and Rynson W. H. Lau and Timothy K. Shih and Frederick W. B. Li},
  title = {Technology supports for distributed and collaborative learning over the internet},
  volume = {8},
  number = {2},
  year = {2008},
  pages = {1--24},
  doi = {10.1145/1323651.1323656},
  address = {New York, NY, USA},
  issn = {1533-5399},
  journal = {ACM Trans. Interet Technol.},
  publisher = {ACM}
}

@MISC{css1:1999,
  author = {Håkon Wium Lie and Bert Bos},
  title = {Cascading Style Sheets, level 1},
  howpublished = {W3C Recommendation},
  month = jan,
  year = {1999},
  comment = {24/05/2005},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://www.w3.org/TR/CSS1}
}

@ARTICLE{Lilly:1996,
  author = {Susan Lilly},
  title = {Education Training: Patterns for pedagogy},
  volume = {5},
  number = {8},
  month = jan,
  year = {1996},
  pages = {93-96},
  issn = {10553614},
  journal = {Object Magazine},
  owner = {magsilva},
  timestamp = {2007.11.21}
}

@INPROCEEDINGS{lima-etal:2006,
  author = {Adailton Lima and Breno França and Heribert Schlebbe and Marcelo Silva and Rodrigo Quites Reis and Carla Lima Reis},
  title = {{WebAPSEE}: Um Ambiente Livre e Flexível para Gerência de Processos de Software},
  address = {Porto Alegre, RS, Brazil},
  booktitle = {Workshop de Software livre},
  month = apr,
  owner = {magsilva},
  review = {Legal ver a proposta e, principalmente, a implementação de um ambiente para gerenciar o processo de software. O WebAPSEE tem umas características legais, das quais destaco o suporte automático para modificações ah-hoc. Ele permite a execução de três tipos de mudanças: 1) Em um fragmento do processo em execução que ainda não foi alcançado pelo fluxo de execução. 2) Em um fragmento do processo que foi alcançado pelo fluxo de execução, mas que a modificação não interfere no estado atual do processo (mante-o coerente com o modelo de processo original). 3) Em um fragmento do processo depois ou durante sua execução, necessitando-o executá-lo. Uma coisa que acho muito legal no processo de software livre é a liberdade para execução das coisas. Digo, nada o impede de fazer o código antes de detalhar os requisitos. Ou deixar a documentação em segundo (terceiro, quarto plano) enquanto que os mecanismos para instalação são sempre bem definidos e documentados. De fato, software livre possui várias facetas contraditórios. Não estou dizendo que isso é o certo, que o caos deve imperar. Não. O que digo é que você não pode impedir o desenvolvedor de fazer algo simplesmente porque não existe uma coisa, supostamente requerida para esse algo, pronta. Deixe-o fazer, depois ele arruma. Melhor ter algo do que nada. Não li sobre como o processo é definido no WebAPSEE, precisaria ler a bibliografia dele, mas é legal isso de tentar flexibilizar as coisas, mudar o processo durante o jogo. Essas coisas estão no âmago do software livre, a liberdade para mudanças em qualquer ponto do desenvolvimento, de experimentar. Se a engenharia de software fosse algo muito maduro e estabelecido, essas coisas não fariam sentido, mas o fato é que ainda não temos uma receita universal para o desenvolvimento de software. Essa liberdade é vital para verificar os caminhos alternativos e trçar aquilo que é melhor para _o_ processo de enge},
  timestamp = {2010.03.29},
  year = {2006}
}

@INPROCEEDINGS{Lin-etal:2005,
  author = {H. W. Lin and Wen-Chih Chang and George Yee and Thimothy K. Shih and Chun-Chia Wang and Hsuan-Che Yang},
  title = {Applying Petri Nets to Model SCORM Learning Sequence Specification in Collaborative Learning},
  pages = {203-208},
  abstract = {With the rapid development of Internet technology and Web-based education, distance learning provides a novel learning style, which is different from traditional education. In order to adapt different teaching strategies in accordance to individual studentsý abilities in a distance learning environment, system directed navigation of students was proposed in a distance learning standard called SCORM (Sharable Content Object Reference Model). We introduce the Distance-learning Color Petri Net (DCPN), applying the features of Petri nets, to decrease the complexity of the sequencing definition model in the SCORM 2004 specification. We thus construct a sequencing framework for various instructional strategies by piecing DPCN subnets together.},
  volume = {1},
  address = {Washington, DC, EUA},
  booktitle = {International Conference on Advanced Information Networking and Applications},
  isbn = {0-7695-2249-1},
  issn = {1550-445X},
  month = mar,
  publisher = {IEEE},
  timestamp = {2009.01.31},
  year = {2005}
}

@INPROCEEDINGS{Lin-etal:2004,
  author = {H. W. Lin and Timothy K. Shih and Wen-Chih Chang and Chao-Hsun Yang and Chun-Chia Wang},
  title = {A Petri Nets-based Approach to Modeling SCORM Sequence},
  pages = {1247-1250},
  doi = {10.1109/ICME.2004.1394448},
  abstract = {In order to adapt teaching in accordance with the abilities of individual students in the distance learning environment, more research emphasis is needed on constructing personalised courseware. The new version of SCORM 1.3 (scalable content object reference model) attempts to add the sequence concept into this course standard. The concept describes how the sequencing process is invoked, what occurs during the sequencing process and the potential outputs of the sequencing process. As a result, we apply the valuable features of Petri nets to decrease the complexity of the sequencing definition model in the SCORM 1.3 specification and construct a framework within various instructional strategies by piecing subnets together},
  address = {Taipei, Taiwan},
  booktitle = {IEEE International Conference on Multimedia and Expo (ICME)},
  isbn = {0-7803-8603-5},
  month = jun,
  publisher = {IEEE},
  timestamp = {2009.01.31},
  year = {2004}
}

@BOOK{lindholm-yellin:1999,
  title = {The Java Virtual Machine Specification},
  publisher = {Prentice Hall},
  year = {1999},
  author = {Tim Lindholm and Frank Yellin},
  pages = {496},
  edition = {2},
  month = apr,
  owner = {magsilva},
  timestamp = {2009.11.09},
  url = {http://java.sun.com/docs/books/jvms/}
}

@INPROCEEDINGS{Linnenkugel90TDSC,
  author = {U. Linnenkugel and M. M{\"u}llerburg},
  title = {Test Data Selection Criteria for (Software) Integration Testing},
  pages = {709--717},
  address = {Morristown, NJ},
  booktitle = {First International Conference on Systems Integration},
  month = apr,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1990}
}

@BOOK{linthicum:2003,
  title = {Next Generation Application Integration: From Simple Information to Web Services},
  publisher = {Addison-Wesley Professional;},
  year = {2003},
  author = {David S. Linthicum},
  edition = {1},
  month = aug,
  owner = {magsilva},
  timestamp = {2006.05.30}
}

@BOOK{Linz:2000,
  publisher = {Jones and Bartlett Publishers},
  year = {2000},
  author = {Peter Linz},
  isbn = {0-7637-1422},
  pages = {410},
  address = {Sudbury, MA, } # USA,
  edition = {3},
  booktitle = {An Introduction to Formal Languages and Automata},
  timestamp = {2013-12-03}
}

@INPROCEEDINGS{Liskov-Zilles:1974,
  author = {Liskov, Barbara and Zilles, Stephen},
  title = {Programming with abstract data types},
  pages = {50--59},
  doi = {10.1145/800233.807045},
  abstract = {The motivation behind the work in very-high-level languages is to ease the programming task by providing the programmer with a language containing primitives or abstractions suitable to his problem area. The programmer is then able to spend his effort in the right place; he concentrates on solving his problem, and the resulting program will be more reliable as a result. Clearly, this is a worthwhile goal. Unfortunately, it is very difficult for a designer to select in advance all the abstractions which the users of his language might need. If a language is to be used at all, it is likely to be used to solve problems which its designer did not envision, and for which the abstractions embedded in the language are not sufficient. This paper presents an approach which allows the set of built-in abstractions to be augmented when the need for a new data abstraction is discovered. This approach to the handling of abstraction is an outgrowth of work on designing a language for structured programming. Relevant aspects of this language are described, and examples of the use and definitions of abstractions are given.},
  booktitle = {ACM SIGPLAN Symposium on Very high level languages},
  location = {Santa Monica, California, #USA#},
  publisher = {ACM},
  year = {1974}
}

@ARTICLE{Lister:2008,
  author = {Raymond Lister},
  title = {CS research: We are what we cite -- so where are we?},
  volume = {40},
  number = {4},
  month = dec,
  year = {2008},
  pages = {16--18},
  doi = {10.1145/1473195.1473203},
  acmid = {1473203},
  address = {New York, NY, EUA},
  issn = {0097-8418},
  journal = {SIGCSE Bulletin},
  publisher = {ACM}
}

@BOOK{Litto-Formiga:2009,
  title = {Educação a distância: o estado da arte},
  publisher = {Pearson Education},
  year = {2009},
  author = {Fredric Michael Litto and Marcos Formiga},
  editor = {Fredric Michael Litto and Marcos Formiga},
  isbn = {978-85-7605-197-8},
  volume = {1},
  pages = {461},
  address = {São Paulo, SP, } # Brazil,
  edition = {1},
  month = oct,
  abstract = {Idealizado pela Associação Brasileira de Educação a Distância (Abed), organizado por dois especialistas renomados no tema e composto por 61 capítulos escritos pelos maiores profissionais brasileiros em EAD, este livro transmite ao leitor o mais alto e expressivo grau de desenvolvimento atingido pelas abordagens de educação a distância no país até o momento, considerando o contexto dos cenários nacional e internacional de aprendizagem. Os textos constituem um rico e abrangente apanhado de idéias, tendências e estatísticas indispensáveis para todo profissional que se dedida à educação a distância -- quer no âmbito acadêmico, quer no corporativo -- e apresentam a visão de pesquisadores especializados nas mais diversas áreas, incluindo: aprendizagem por correspondência, aprendizagem por rádio, aprendizagem por meio de comunidades virtuais, educação corporativa e muitas outras. Além disso, aborda aspectos pedagógicos e andragógicos da EAD, as tecnologias associadas, o cenário internacional, a educação pelo trabalho, história, estatísticas da EAD no Brasil e muitos outros assuntos. Este livro, além de uma poderosa ferramente de consulta sobre os mais diversos temas e áreas de EAD, é uma fonte de informação confiável que certamente será muito útil para alunos de graduação e pós-graduação, bem como para profissionais que utilizam a EAD como recurso para produção de suas atividades. Com tudo isso, Educação a distância: o estado da arte é referência para todos aqueles que estão preocupados com os rumos da educação no país e que vêem a educação a distância como uma maneira adicional e indispensável para levar o aprendizado às pessoas.},
  booktitle = {Educação a distância: o estado da arte}
}

@ARTICLE{chengchung-etal:2005,
  author = {Chen-Chung Liu and Ping-Hsing Don and Chun-Ming Tsai},
  title = {Assessment Based on Linkage Patterns in Concept Maps},
  volume = {21},
  year = {2005},
  pages = {873-890},
  abstract = {Concept maps have been adopted extensively in teaching and assessment. Assessment schemes, including the closeness index and the N-G method, have also been widely applied to evaluate the quality of students' concept maps. Teachers must make great efforts to evaluate students' concept maps, because present concept map assessment schemes do not reveal ways to help them improve such maps. Additionally, teachers cannot easily provide constructive suggestions to students to improve their learning, particularly when concept maps incorporate many concepts and links. This work presents linkage algorithms that can be used to discover the patterns (such as confused concepts, substitute concepts, and hidden wrong concepts) in concept maps to support assessment. Teachers can use the discovered patterns not only to become aware of the conceptions of students, but also to improve students' conceptions efficiently.},
  keywords = {assessment, computer-based concept maps, personal construction psychology, data mining, linkage analysis},
  journal = {Journal of Information Science and Engineering}
}

@INPROCEEDINGS{Liu-etal:2002,
  author = {Xiao-Qiang Liu and Min Wu and Jia-Xun Chen},
  title = {Knowledge aggregation and navigation high-level Petri nets-based in e-learning},
  pages = {420 - 425},
  doi = {10.1109/ICMLC.2002.1176788},
  abstract = {With the wide application of the Internet in e-learning, the requirement of reusable, sharable learning objects and adaptive learning strategies is becoming common. This paper discusses a meta-data structure, which makes a base for reusing and aggregating learning resources in e-learning, and provides an aggregation model - Teach net based on high-level Petri nets. Teach net uses a formal description for authoring and navigation in e-learning. Colored tokens are used to model the learner and learning objects. Teach net is a base to facilitate authoring in visual and adaptive navigation in e-learning. Analysis and application show that e-learning can benefit from the modeling features of high-level Petri nets.},
  volume = {1},
  booktitle = {International Conference on Machine Learning and Cybernetics},
  issn = { },
  year = {2002}
}

@INPROCEEDINGS{loconsole:2004,
  author = {Annabella Loconsole},
  title = {Empirical Studies on Requirements Management Measures},
  pages = {42-44},
  booktitle = {Doctoral Symposium, International Conference on Software Engineering},
  owner = {Marco Aurélio Graciotto Silva},
  publisher = {IEEE Computer Society},
  timestamp = {2008.07.30},
  year = {2004}
}

@ARTICLE{Loi-Roibas:2007,
  author = {Loi, Daria and Roibas, Anxo Cereijo},
  title = {{DIY} {i-TV} producers: emerging nomadic communities},
  volume = {3},
  month = nov,
  year = {2007},
  pages = {416--426},
  doi = {10.1504/IJWBC.2007.015867},
  abstract = {This article reflects on emerging communities of nomadic users, which employ handhelds to create and share multimedia content. More specifically, authors explore new scenarios of pervasive i-TV by illustrating new user-experience models and new forms of content for convergent media. These new scenarios look at how mobile phones as personal interfaces interconnected with other nearby interfaces will contribute to create communication ubiquity a ubiquity that refers to a system of pervasive communication without spatial and temporal constraints. This article shows how relevant applications of pervasive i-TV can be related to the creation and sharing of new forms of content and, more specifically, to the production and broadcast or narrowcast of multimedia content.},
  keywords = {broadcast, cell phones, communication ubiquity, handheld devices, mobile communications, mobile phones, mobile technologies, multimedia content, multimedia content producers, narrowcast, new scenarios, nomadic communities, pervasive i\&\#45;TV},
  url = {http://portal.acm.org/citation.cfm?id=1359054.1359058},
  acmid = {1359058},
  address = {Inderscience Publishers, Geneva, SWITZERLAND},
  issn = {1477-8394},
  issue = {4},
  journal = {Int. J. Web Based Communities},
  numpages = {11},
  publisher = {Inderscience Publishers}
}

@BOOK{Lopes-Garcia:2002,
  publisher = {Elsevier},
  year = {2002},
  author = {Anita Lopes and Guto Garcia},
  isbn = {85-352-1019-9},
  pages = {469},
  address = {Rio de Janeiro, RJ, } # Brazil,
  booktitle = {Introdução à Programação: 500 algoritmos resolvidos}
}

@INPROCEEDINGS{Lopes-etal:2011,
  author = {Lopes, Giseli Rabello and da Silva, Roberto and de Oliveira, J. Palazzo M.},
  title = {Applying Gini coefficient to quantify scientific collaboration in researchers network},
  pages = {68:1--68:6},
  doi = {10.1145/1988688.1988767},
  abstract = {Some of the metrics more commonly used for Social Networks Analysis (SNA) do not consider the weights of relationships between the actors of the analyzed Social Network, if it exists. These weights aim to measure the importance of the relational ties between actors and also are important to be considered in a SNA. This paper purposes the Gini Coefficient to be applied on Social Networks Analysis. Our initial results demonstrate the validity and applicability of this approach for a collaboration of Brazilian network scientists.},
  keywords = {Gini coefficient, co-author social networks, social networks analysis},
  series = {WIMS '11},
  acmid = {1988767},
  address = {New York, NY, USA},
  articleno = {68},
  booktitle = {International Conference on Web Intelligence, Mining and Semantics},
  isbn = {978-1-4503-0148-0},
  location = {Sogndal, Norway},
  numpages = {6},
  publisher = {ACM},
  year = {2011}
}

@INPROCEEDINGS{LopezNores-etal:2010b,
  author = {López-Nores, M. and Blanco-Fernández, Y. and Pazos-Arias, J. J.},
  title = {Architecting multimedia-rich collaborative learning services over interactive digital {TV}},
  pages = {1-6},
  abstract = {Distance learning has developed greatly in recent years, and several major technological approaches have been defined. One of these is t-learning, that is, the provision of educational services over Interactive Digital TV. In this paper, we present a Java-based software architecture for the development of distributed t-learning applications and services, based on freely available technologies. The proposed framework provides convenient support for the specific needs of t-learning with strong emphasis on interactivity, promoting the creation of student communities and shared workspaces on a peer-to-peer basis. We also introduce a CASE tool for visual development of such services, distributing their functionality among a number of sceneries that provide for differentiated roles among those in a community.},
  keywords = {Collaborative t-learning; Interactive digital TV; MHP; P2P; Virtual communities},
  address = {Santiago de Compostela, Espanha},
  booktitle = {5th Iberian Conference on Information Systems and Technologies},
  isbn = {9789899624733},
  language = {English},
  location = {Santiago de Compostela, Spain},
  month = jun,
  publisher = {IEEE},
  references = {Horton, W., Horton, K., (2003) E-learning Tools and Technologies, , Wiley; (2003) T-learning and M-learning Studies, , http://www.pjb.co.uk, (June 6th, 2007); Pazos-Arias, J.J., Lopez-Nores, M., Garcia-Duque, J., Diaz-Redondo, R.P., Blanco-Fernandez, Y., Ramos-Cabrer, M., Gil-Solla, A., Fernandez-Vilas, A., Provision of distance learning services over Interactive Digital TV with MHP (2008) Computers and Education, 50 (3), pp. 927-949. , DOI 10.1016/j.compedu.2006.09.008, PII S036013150600145X; Blomquist, T., Hällgren, M., Nilsson, A., Development of virtual teams and learning communities (2005) Proceedings of the International Conference on Multimedia and Information & Communication Technologies in Education, , Formatex, Cáceres (Spain); (2007) Multimedia Home Platform Specification 1.2, , http://www.mhp.org, DVB, (June 6th, 2007); Lytras, M., Lougos, C., Chozos, P., Pouloudi, A., Interactive television and e-learning convergence: Examining the potential of t-learning (2002) Proceedings of the European Conference on E-Learning, , CETIS, Brunel University (UK); Caudill, B., Banks, D., (2006) Instructional Designer's Pocket Guide to SCORM, , JCA Solutions; Harman, K., Koohang, A., Learning objects: Standards, metadata, repositories, and LCMS (2006) Informing Science; Gil-Solla, A., Pazos-Arias, J., López-García, C., López-Ardao, J., Rodríguez-Rubio, R., Ramos-Cabrer, M., Exploring t-learning in the MHP context (2002) Proceedings of the International Conference on WWW/Internet, , IADIS, Lisbon (Portugal); Morris, S., Smith-Chaigneau, A., (2005) Interactive TV Standards, , Focal Press; Qu, C., Nejdl, W., Interacting the Edutella/JXTA peer-to-peer network with Web services (2004) Proceedings of the International Symposium on Applications and the Internet, pp. 67-73. , IEEE Computer Society, Tokyo (Japan); (2006) 'Extensible Markup Language (XML) 1.0, , http://www.w3.org/TR/REC-xml/, (4th edition), (June 6th, 2007); (1998) The JavaBeans Specification, , http://java.sun.com/products/javabeans, (June 6th, 2007); (2005) JXTA Technology: Creating Connected Communities, , http://www.jxta.org, Sun Microsystems, (June 6th, 2007); Juric, M., Rozman, I., Brumen, B., Colnaric, M., Hericko, M., Comparison of performance of Web services, WS-Security, RMI, and RMI-SSL (2006) Journal of Systems and Software, 79 (5), pp. 689-700. , Elsevier; Boudreau, T., Tulach, J., Wielenga, G., (2007) Rich Client Programming: Plugging into the NetBeans Platform, , Prentice Hall},
  year = {2010}
}

@INPROCEEDINGS{LopezNores-etal:2004,
  author = {Lopez-Nores, M. and Elexpuru-Eguia, A. and Blanco-Fernandez, Y. and Pazos-Arias, J.J. and Gil-Solla, A. and Garcia-Duque, J. and Barragans-Martinez, B. and Ramos-Cabrer, M.},
  title = {A technological framework for TV-supported collaborative learning},
  pages = {72 - 79},
  doi = {10.1109/MMSE.2004.17},
  abstract = {Interactive digital TV is emerging as a potentially important medium to create opportunities for learning at home. To date, the offer has been mostly based on the contents available through broadcast, but this is expected to change in the near future. The increasing availability of high-quality bidirectional networks, together with the fact that IDTV users are abandoning their passive habits, envisages a new range of highly interactive services that may enhance greatly the prospects of distance education. This paper introduces a technological framework for the development and deployment of distributed and collaborative educational services for IDTV, proposing an extension to the multimedia home platform standard. The framework is based on a selection of freely available technologies, which we integrate into a CASE tool that bridges the gap between course-authoring and programming tasks. We also discuss the possible market implications of our approach, because the ideas presented here contribute to openness in the field of IDTV services, so far monopolised by mainstream broadcasters.},
  keywords = {Interactive Digital TV, collaborative learning, distributed multimedia services, authoring tools},
  booktitle = {IEEE Sixth International Symposium on Multimedia Software Engineering},
  isbn = {0-7695-2217-3},
  location = {Miami, FL, USA},
  month = dec,
  publisher = {IEEE},
  year = {2004}
}

@INPROCEEDINGS{LopezNores-etal:2003,
  author = {M. Lopez-Nores and A. Fernandez-Vilas and R. P. Diaz-Redondo and A. Gil-Solla and J. J. Pazos-Arias and M. Ramos-Cabrer and J. García-Duque},
  title = {A Mixed XML-JavaBeans Approach to Developing T-learning Applications for the Multimedia Home Platform},
  pages = {376-387},
  abstract = {E-learning technologies have developed greatly in recent years, with considerable success, which has suggested extending distance education to other mediums. This paper studies the possibilities of Interactive Digital TV to provide educational services (t-learning) and analyzes the support offered by the Multimedia Home Platform standard (MHP). We also present an approach to developing interactive t-learning courses and a tool, based on public and well-known technologies, that implements our proposal over the MHP technological framework. Our approach is remarkable for being flexible, extensible and easy to integrate with existing standards for the management of learning content, thus promoting interoperability and content reuse. In addition, applications can be developed with no need of programming knowledge. This is essential to free designers from technological details, so that they can concentrate on the broadcast contents, their sequence, interrelations and every aspect that makes up a value-added application.},
  volume = {2899},
  booktitle = {Interactive Multimedia on Next Generation Networks},
  isbn = {3540205349},
  publisher = {Springer},
  year = {2003}
}

@ARTICLE{LopezNores-etal:2006a,
  author = {López-Nores, Martín and Pazos-Arias, José and García-Duque, Jorge and Blanco-Fernández, Yolanda and Ramos-Cabrer, Manuel and Gil-Solla, Alberto and Fernández-Vilas, Ana and Díaz-Redondo, Rebeca},
  title = {Formal specification applied to multiuser distributed services: experiences in collaborative t-learning},
  volume = {79},
  number = {8},
  month = aug,
  year = {2006},
  pages = {1141--1155},
  doi = {10.1016/j.jss.2005.12.019},
  abstract = {The development of multiuser and distributed software systems faces the difficulty to program the applications correctly, in a way that guarantees the desired interaction among the users. Motivated by experiences with collaborative t-learning services (i.e. multiuser educational services over Interactive TV), this paper presents a solution to that problem, based on supplementing visual development with formal specification techniques. As a contribution to the development of interactive systems, a software process is introduced that helps defining the separate and the conjoint behavior of different users, incrementally and using highly-accessible formalisms.},
  keywords = {formal specification, interaction patterns, multiuser systems},
  address = {New York, NY, USA},
  issn = {0164-1212},
  journal = {Journal of Systems and Software},
  publisher = {Elsevier}
}

@INPROCEEDINGS{LopezNores-etal:2008,
  author = {López-Nores, Martín and Pazos-Arias, José Juan and Blanco-Fernández, Yolanda and García-Duque, Jorge and Tubío-Pardavila, Ricardo and Casquero-Villacorta, Esther},
  title = {{MiSPOT}: Enhanced Availability and Quality in Delivering Personalized M-Learning Linked to TV Programs},
  pages = {617--619},
  doi = {10.1109/ICALT.2008.12},
  abstract = {The development of digital television for mobile devices brings in new possibilities for informal learning, by means of interactive educational services linked to the TV programs. Some systems exist in the m-learning literature that may automatically discover the most valuable services for each viewer at any time, matching information about his/her interests, context and needs, about the services available and about the TV programs that those services may be linked to. Most commonly, however, the reasoning process is performed by remote servers, which implies that the personalization features become unavailable in the frequent cases of sporadic or null access to a bidirectional communication channel. The alternative exists to do local reasoning in the mobile devices, but their limited computational power results in low personalization quality. In this paper, we solve these problems with a scalable approach to perform semantic reasoning in mobile devices, backed up by the bandwidth and robustness of the same broadcast networks that deliver the TV programs.},
  keywords = {Personalization, semantic reasoning, m-learning},
  booktitle = {Eighth IEEE International Conference on Advanced Learning Technologies},
  isbn = {978-0-7695-3167-0},
  location = {Santander, Cantabria, Spain},
  month = jul,
  publisher = {IEEE},
  year = {2008}
}

@INPROCEEDINGS{Lopez-Nores2006,
  author = {Lopez-Nores, Martin and Pazos-Arias, Jose Juan and Garcia-Duque, Jorge and Blanco-Fernandez, Yolanda and Gil-Solla, Alberto},
  title = {A Core of Standards to Support T-learning},
  pages = {13--15},
  doi = {10.1109/ICALT.2006.1652352},
  abstract = {The possibility of transmitting interactive applications along with the audiovisual contents will turn the television into a universal platform to access the information society. Nowadays, there is growing interest in exploiting that potential to develop distance learning policies, to supplement the facilities offered by the current e-learning technologies. This short paper describes the implementation of a software module that enables the provision of educational services over interactive digital TV (T-learning). This module has been designed according to the technical peculiarities of an IDTV receiver, and resorts to existing standards to favor the convergence of all distance learning mediums.},
  series = {ICALT '06},
  acmid = {1156192},
  address = {Washington, DC, USA},
  booktitle = {Sixth IEEE International Conference on Advanced Learning Technologies},
  isbn = {0-7695-2632-2},
  lang = {en},
  location = {Kerkrade, Netherlands},
  month = jul,
  numpages = {3},
  publisher = {IEEE},
  year = {2006}
}

@INPROCEEDINGS{LopezNores-etal:2006:ICALT,
  author = {Martín López-Nores and José Juan Pazos-Arias and Jorge García-Duque and Yolanda Blanco-Fernández and Alberto Gil-Solla},
  title = {A Core of Standards to Support T-learning},
  abstract = {The possibility of transmitting interactive applications along with the audiovisual contents will turn the television into a universal platform to access the Information Society. Nowadays, there is growing interest in exploiting that potential to develop distance learning policies, to supplement the facilities offered by the current e-learning technologies. This short paper describes the implementation of a software module that enables the provision of educational services over Interactive Digital TV (t-learning). This module has been designed according to the technical peculiarities of an IDTV receiver, and resorts to existing standards to favor the convergence of all distance learning mediums.},
  address = {Washington, DC, EUA},
  booktitle = {Sixth IEEE International Conference on Advanced Learning Technologies},
  isbn = {0-7695-2632-2},
  location = {Kerkrade, Netherlands},
  month = jul,
  publisher = {IEEE},
  year = {2006}
}

@ARTICLE{LopezNores-etal:2009b,
  author = {López-Nores, Martín and Rey-López, Marta and Pazos-Arias, José J. and García-Duque, Jorge and Blanco-Fernández, Yolanda and Gil-Solla, Alberto and Díaz-Redondo, Rebeca P. and Fernández-Vilas, Ana and Ramos-Cabrer, Manuel},
  title = {Spontaneous interaction with audiovisual contents for personalized e-commerce over Digital TV},
  volume = {36},
  number = {3},
  month = apr,
  year = {2009},
  pages = {4192--4197},
  doi = {10.1016/j.eswa.2008.04.007},
  abstract = {The development of the Interactive Digital TV technologies has the potential to open new possibilities for e-commerce, linked to the broadcasting of audiovisual contents. To cater for the advertising needs, the early initiatives are resorting to the techniques traditionally employed by the television industry, which have proven deficiencies related to targeting and viewers' comfort. In response to that, we have developed a new advertising model, based on identifying products semantically related to the things that draw the viewer's attention on the screen. Thereupon, a personalization engine selects the products which are potentially interesting for the viewer, and assembles interactive services that provide him/her with tailor-made commercial functionalities. This paper provides guidelines on how to support the proposed model over the technological basis of the modern Digital TV receivers (either domestic or mobile ones), and describes a sample scenario of personalized advertising.},
  keywords = {E-commerce, Interactive Digital TV, Personalization, Spontaneous advertising},
  address = {Tarrytown, NY, USA},
  issn = {0957-4174},
  journal = {Expert Systems with Applications: An International Journal},
  publisher = {Pergamon}
}

@BOOK{lorenz-kidd:1994,
  title = {Object-Oriented Software Metrics},
  publisher = {Prentice Hall},
  year = {1994},
  author = {Mark Lorenz and Jeff Kidd},
  pages = {146},
  series = {Prentice-Hall Object-Oriented Series},
  address = {New Jersey, USA},
  edition = {1},
  abstract = {Project progress and quality: these are the bootm-line factors in any software engineering effort. Written with OO developers and managers in mind, this timely volume identifies a set of meaningful metrics that will help you to foster better designs, develop more reusable code, and prepare better estimates. Authors Mark Lorenz and Jeff Kidd draw on a number of actual projects that have successfully used object technology to deliver products. The metrics were chosen for their ability to identify anomalies as well as to measure progress. Focusing on project metrics and design metrics, Object-Oriented Software Metrics includes coverage of: management process, development process, project metrics (application size, staffing size, scheduling), and design metrics (method size, method internals, class size, class inheritance, method inheritance, class internals, class externals). In short, Object-Oriented Software Metrics offers practical advice for anyone involved in ongoing OO projects to effectively develop software systems.},
  owner = {magsilva},
  timestamp = {2010.07.12}
}

@INPROCEEDINGS{losavio:2003,
  author = {Francisca Losavio and Dinarle Ortega and María Pérez},
  title = {Towards a Standard EAI Quality Terminology},
  pages = {119- 129},
  booktitle = {XXIII International Conference of the Chilean Computer Science Society (SCCC'03)},
  month = nov,
  owner = {magsilva},
  timestamp = {2006.12.11},
  year = {2003}
}

@MASTERSTHESIS{coelho:2002,
  author = {Maria de Lourdes Coelho},
  title = {A evasão nos cursos de formação continuada de professores universitários na modalidade de educação a distância via {Internet}},
  school = {UFMG},
  year = {2002},
  address = {Belo Horizonte, UFMG},
  timestamp = {2008.09.15},
  type = {Mestrado em Educação}
}

@INPROCEEDINGS{Lovatt:2005:PEC:1082276.1082285,
  author = {Lovatt, Howard C. and Sloane, Anthony M. and Verity, Dominic R.},
  title = {A pattern enforcing compiler (PEC) for Java: using the compiler},
  pages = {69--78},
  abstract = {A PEC is a Pattern Enforcing Compiler, which is like a conventional compiler only extended to include the extra checks needed to enforce design patterns. PECs are currently a research project and the PEC written is targeted at the Java programming language. This paper describes the PEC, describes how to use the PEC, demonstrates how the PEC combines static testing, dynamic testing (unit testing), and code generation synergistically into one utility, shows that the user of the PEC can write their own design patterns and have the compiler enforce them. The PEC is believed to be unique in statically testing, dynamically testing, generating code and being user extendable. The PEC is stable enough for production code and is available for free download under the Lesser GNU General Public License. The PEC makes extensive use of reflection (runtime type identification); both when testing that a class conforms to pattern and also to allow the compiler to be user extendable.},
  keywords = {PEC, compilers, design patterns, dynamic checking, extendable compiler, pattern enforcing compiler, static checking, unit testing},
  volume = {43},
  series = {Conferences in Research and Practice in Information Technology},
  acmid = {1082285},
  address = {Darlinghurst, Australia},
  booktitle = {Asia-Pacific Conference on Conceptual Modelling},
  editor = {Sven Hartmann and Markus Stumptner},
  isbn = {1-920-68225-2},
  location = {Newcastle, New South Wales, Australia},
  numpages = {10},
  publisher = {Australian Computer Society},
  url = {http://portal.acm.org/citation.cfm?id=1082276.1082285},
  year = {2005}
}

@INPROCEEDINGS{Loveland:2011,
  author = {Loveland, Susan},
  title = {Human computer interaction that reaches beyond desktop applications},
  pages = {595--600},
  doi = {10.1145/1953163.1953328},
  abstract = {Recently, several frameworks have been developed for writing mobile and web applications in Java, making the development of web and mobile applications accessible to HCI students with only a CS1 Java background. In this paper we describe using student projects based on the Google Android mobile platform and Google's Web Toolkit to provide students with experience designing and implementing user interfaces for mobile and web applications. Specific examples demonstrate how programming on these platforms reinforces standard HCI topics. As a result of being able to learn mobile device programming in the context of "cool" Google platforms, students expressed increased interest in studying HCI.},
  keywords = {Google web toolkit, android, human computer interaction, mobile},
  series = {SIGCSE '11},
  acmid = {1953328},
  address = {New York, NY, USA},
  booktitle = {Technical symposium on Computer science education},
  isbn = {978-1-4503-0500-6},
  location = {Dallas, TX, USA},
  numpages = {6},
  publisher = {ACM},
  year = {2011}
}

@MASTERSTHESIS{Lu-etal:2005,
  author = {Karyn Y. Lu},
  title = {Interaction Design Principles for Interactive Television},
  abstract = {Interactive television (iTV) is an umbrella term used to cover the convergence of television with digital media technologies such as computers, personal video recorders, game consoles, and mobile devices, enabling user interactivity. Increasingly, viewers are moving away from a "lean back" model of viewing to a more active "lean forward" one. When fully realized on a widespread scale in the United States, our current experience of watching television will be dramatically transformed. Because iTV is a new medium in its own right, however, standards for iTV programming and interaction in the United States remain undefined. This document identifies and articulates interaction design principles for interactive television programming in the United States. Chapter one presents a brief survey of the field as it stands in 2005. In chapters two and three, I categorize iTV by platforms and by persistent television genres, and present representative examples for each category. In chapter four, I provide an overview of existing design standards in related areas. Insights from chapters two, three, and four all serve to inform chapter five, in which I propose principles for iTV interaction design by looking closely at existing designs (both deployed and prototyped), conventions, and patterns of interaction. My analyses are rooted in visual culture and human-computer interaction design principles, and the design principles I offer are abstracted from the applications I analyze within this framework. Finally, in chapter six, I offer some conclusions and thoughts for future directions.},
  school = {Georgia Institute of Technology},
  year = {2005},
  advisor = {Janet Horowitz Murray},
  address = USA,
  month = may,
  url = {http://hdl.handle.net/1853/6962},
  lang = {en}
}

@INPROCEEDINGS{Lucena00ADIT,
  author = {C. J. P. Lucena and H. Fuks and C. Laufer and M. B. Ribeiro and R. Choren and V. T. Silva and R. L. Assis and F. Ferraz and G. R. Carvalho},
  title = {Appying Digital Information Technology to Education: a Web-based Course},
  address = {São Paulo, SP},
  booktitle = {International Conference on Engineering and Computer Education (ICECE 2000)},
  owner = {magsilva},
  timestamp = {2008.07.30},
  year = {2000}
}

@INPROCEEDINGS{Lucena99AAPF,
  author = {C. J. P. Lucena and H. Fuks and R. Milidiu and C. Laufer and M. B. Ribeiro and R. C. Noya and V. T. Silva and F. Ferraz and G. R. Carvalho and L. Daflon},
  title = {{AulaNet} -- Ajudando os Professores a Fazerem seu Dever de Casa},
  pages = {105-117},
  address = {Rio de Janeiro, RJ},
  booktitle = {XXVI Seminário Integrado de Software e Hardware (SEMISH 99)},
  owner = {magsilva},
  timestamp = {2008.07.30},
  year = {1999}
}

@INPROCEEDINGS{lucena-etal:1998,
  author = {C. J. P. Lucena and H. Fuks and R. Milidiu and L. Macedo and N. Santos and C. Laufer and M. B. Ribeiro and M. F. Fontoura and R. C. Noya and S. Crespo and V. Torres and L. Daflon and L. Lukowiecki},
  title = {{AulaNet} -- An Environment for the Development and Maintenance of Courses on the Web},
  address = {Rio de Janeiro, RJ},
  booktitle = {International Conference on Engineering in Education (ICECE 98)},
  owner = {magsilva},
  timestamp = {2008.07.30},
  year = {1998}
}

@INPROCEEDINGS{Lucy:2007,
  author = {Lucy},
  title = {Inside the {Mac OS X} Kernel: Debunking {Mac OS} Myths},
  pages = {1--5},
  abstract = {Many buzzwords are associated with Mac OS X: Mach kernel, microkernel, FreeBSD kernel, C++, 64 bit, UNIX... and while all of these apply in some way, "XNU", the Mac OS X kernel is neither Mach, nor FreeBSD-based, it's not a microkernel, it's not written in C++ and it's not 64 bit - but it is UNIX... but just since recently. This talk intends to clear up the confusion by presenting details of the Mac OS X kernel architecture, its components Mach, BSD and I/O-Kit, what's so different and special about this design, and what the special strengths of it are.},
  booktitle = {24th Chaos Communication Congress},
  location = {Berlin, #Germany#},
  month = dec,
  publisher = {Chaos Computer Club},
  url = {http://events.ccc.de/congress/2007/Fahrplan/events/2303.en.html},
  year = {2007}
}

@INPROCEEDINGS{ludi:2004,
  author = {Stephanie Ludi},
  title = {Teaching Software Testing as a Problem-Based Learing Course},
  address = {Melbourne, FL},
  booktitle = {3rd Annual Workshop on the Teaching of Software Testing (WTST)},
  month = feb,
  timestamp = {2008.07.31},
  year = {2004}
}

@ARTICLE{Lukasiak-etal:2004,
  author = {Jason Lukasiak and Shirley Agostinho and Ian Burnett and Gerrard Drury and Jason Goodes and Sue Bennett and Lori Lockyer and Barry Harper},
  title = {A Framework for the Flexible Content Packaging of Learning Objects and Learning Designs},
  volume = {13},
  number = {4},
  month = oct,
  year = {2004},
  pages = {465--481},
  abstract = {This paper presents a platform-independent method for packaging learning objects and learning designs. The method, entitled a Smart Learning Design Framework, is based on the MPEG-21 standard, and uses IEEE Learning Object Metadata (LOM) to provide bibliographic, technical, and pedagogical descriptors for the retrieval and description of learning objects. This method represents a powerful platform that allows seamless searching, sharing, rights management, authoring, and adaptation of learning objects. In addition, the Smart Learning Design Framework encompasses the concept of generic learning designs, which provides the framework for including, sequencing, and aggregating learning objects. This paper describes the approach and places it within the context of the broader research agenda undertaken by the authors.},
  url = {http://go.editlib.org/p/6585},
  address = { Norfolk, VA },
  issn = { 1055-8896 },
  journal = {Journal of Educational Multimedia and Hypermedia},
  owner = {magsilva},
  publisher = { AACE }
}

@ARTICLE{Lum-Lau:2002,
  author = {W. Y. Lum and F. C. M. Lau},
  title = {A Context-Aware Decision Engine for Context Adaptation},
  volume = {1},
  number = {1},
  year = {2002},
  pages = {41-49},
  journal = {IEEE Pervasive Computing},
  timestamp = {2008.09.28}
}

@MISC{LundgrenCayrol-Leonard:2006,
  author = {Karin Lundgren-Cayrol and Michel Léonard},
  title = {{MOT+LD} Editor Modeling Technique: Steps, Hints and Graphical Examples},
  howpublished = {Guia},
  month = apr,
  year = {2006},
  url = {http://www1.licef.teluq.uqam.ca:90/cice/motplus/MOTPlus-logiciel/Guide_MotPlus.pdf}
}

@INPROCEEDINGS{luqi:2004,
  author = {Luqi and Lin Zhang and Valdis Berzins and Ying Qiao},
  title = {Documentation Driven Development for Complex Real-Time Systems},
  pages = {936-952},
  volume = {30},
  number = {12},
  booktitle = {IEEE Transactions on Software Engineering},
  owner = {Marco Aurélio Graciotto Silva},
  timestamp = {2008.07.30},
  year = {2004}
}

@INPROCEEDINGS{Lutteroth-etal:2007,
  author = {Lutteroth, Christof and Luxton-Reilly, Andrew and Dobbie, Gillian and Hamer, John},
  title = {A maturity model for computing education},
  pages = {107--114},
  abstract = {We propose a maturity model for computing education which is inspired by the Capability Maturity Model (CMM) used in software engineering. Similar to CMM, the Computing Education Maturity Model (CEMM) can be used to rate educational organisations according to their capability to deliver high-quality education on a five level scale. Furthermore, CEMM can be used in order to improve an institution's capability by implementing the best practises and organisational changes it describes.},
  keywords = {CMM, education, maturity, quality},
  volume = {66},
  address = {Darlinghurst, Australia, Australia},
  booktitle = {Australasian Conference on Computing education},
  isbn = {1-920-68246-5},
  location = {Ballarat, Victoria, Australia},
  publisher = {Australian Computer Society},
  url = {http://dl.acm.org/citation.cfm?id=1273672.1273685},
  year = {2007}
}

@INPROCEEDINGS{Luyi-etal:2010,
  author = {Li Luyi and Zheng Yanlin and Zheng Fanglin},
  title = {Design of a Computer-supported Ubiquitous Learning system},
  pages = {353 -356},
  doi = {10.1109/ICNDS.2010.5479203},
  abstract = {Computer-supported Ubiquitous Learning (CSUL) systems aim at providing ubiquitous learning resources and support for learners' ubiquitous learning needs, which makes it possible for learners to promote active learning anytime, anyplace, with any device and in any way that learners prefer to. This paper addresses the design framework of a CSUL system, and discusses interaction design, learning devices choice, context-awareness support, and learning service in CSUL.},
  keywords = {computer-supported ubiquitous learning system;context-awareness support;interaction design;learning devices choice;learning service;ubiquitous learning resources;computer aided instruction;ubiquitous computing;},
  volume = {1},
  booktitle = {Networking and Digital Society (ICNDS), 2010 2nd International Conference on},
  month = may,
  year = {2010}
}

@PHDTHESIS{luzzi:2007,
  author = {Daniel Angel Luzzi},
  title = {O papel da educação a distância na mudança de paradigma educativo: da visão dicotômica ao contiuum educativo},
  school = {Faculdade de Educação - Universidade de São Paulo},
  year = {2007},
  address = {São Paulo, SP},
  timestamp = {2008.09.15}
}

@INPROCEEDINGS{Chaim97FTES,
  author = {M. L. Chaim, J. C. Maldonado, M. Jino},
  title = {Ferramenta para o Teste Estrutural de Software Baseado em Análise de Fluxo de Dados: o Caso Poke-Tool},
  pages = {29--39},
  address = {\'Aguas de Lind\'oia -- SP},
  booktitle = {Workshop do Projeto de Valida\c c\~ao e Teste de Sistemas de Opera\c c\~ao},
  month = jan,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1997}
}

@MISC{M3C07,
  author = {M3C},
  title = {{Web Services Architecture Working Group}},
  year = {2007},
  note = {http://www.w3.org/2002/ws/arch/ [02/02/2008]},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@INPROCEEDINGS{ma-etal:2002,
  author = {Yu-Seung Ma and Yong-Rae Kwon and J. Offutt},
  title = {Inter-Class Mutation Operators for Java},
  pages = {352--363},
  doi = {10.1109/ISSRE.2002.1173287},
  address = {Annapolis, MD, } # USA,
  booktitle = {13th International Symposium on Software Reliability Engineering (ISSRE 2002)},
  month = nov,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {2002}
}

@BOOK{macaulay:1996,
  title = {Requirements Engineering},
  publisher = {Springer-Verlag},
  year = {1996},
  author = {Linda A. Macaulay},
  series = {Springer Series On Applied Computing},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@ARTICLE{macedo:1999,
  author = {A. A. Macedo and M. G. C. Pimentel and R. P. M. Fortes},
  title = {StudyConf: Infra-estrutura de suporte ao aprendizado cooperativo na WWW},
  volume = {1},
  number = {5},
  month = sep,
  year = {1999},
  pages = {77-102},
  journal = {Revista Brasileira de Informática na Educação},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@BOOK{Machado-Maia:2007,
  publisher = {LTC},
  year = {2007},
  author = {Francis Berenger Machado and Luiz Paulo Maia},
  isbn = {978-85-216-1548-4},
  pages = {308},
  address = {Rio de Janeiro, RJ, } # Brazil,
  edition = {4},
  booktitle = {Arquitetura de sistemas operacionais}
}

@INBOOK{machado-etal:2010,
  pages = {1-17},
  title = {Software Testing: An Overview},
  publisher = {Springer Berlin / Heidelberg},
  year = {2010},
  editor = {Borba, Paulo and Cavalcanti, Ana and Sampaio, Augusto and Woodcook, Jim},
  author = {Machado, Patrícia and Vincenzi, Auri and Maldonado, José},
  volume = {6153},
  series = {Lecture Notes in Computer Science},
  abstract = {The main goal of this chapter is to introduce common terminology and concepts on software testing that is assumed as background in this book. The chapter also presents the multidimensional nature of software testing, showing its different variants and levels of application. After a brief introduction, Section 2 presents a set of basic definitions used in the remaining of this book. Section 3 gives an overview of the essential activities and documents involved in most test processes. Section 4 discusses the kinds of properties we may want to test, including functional, non-functional, and structural properties. In Section 5, we discuss the various dimensions of software testing, covering unit, integration, system, and acceptance testing. Section 6 highlights that different domains have demanded effort from the research community to work on tailored strategies; we discuss object-oriented, component-based, product-line, and reactive-systems testing. Test selection is a main activity of a test process, and we discuss the main strategies in Section 7. We conclude this introduction in Section 8 with some final considerations.},
  affiliation = {Universidade Federal de Campina Grande Brazil},
  booktitle = {Testing Techniques in Software Engineering},
  doi = {10.1007/978-3-642-14335-9_1}
}

@MISC{software:flash,
  author = {{Macromedia}},
  title = {Flash},
  howpublished = {Programa de Computador},
  year = {2000},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://www.macromedia.com/platform/}
}

@BOOK{Madeyski:2010:book,
  title = {Test-Driven Development: An Empirical Evaluation of Agile Practice},
  publisher = {Springer},
  year = {2010},
  author = {Lech Madeyski},
  isbn = {978-3642042874},
  pages = {245},
  owner = {magsilva},
  timestamp = {2014.08.30}
}

@TECHREPORT{Mafra-Travassos:2006,
  author = {Sômulo Nogueira Mafra and Guilherme Horta Travassos},
  title = {Estudos Primários e Secundários Apoiando a busca por Evidências em Engenharia de Software},
  institution = {COPPE/UFRJ},
  month = mar,
  year = {2006},
  number = {RT-ES 687/06},
  address = {Rio de Janeiro, RJ, } # Brazil,
  url = {http://www.cos.ufrj.br/uploadfiles/1149103120.pdf},
  pages = {32}
}

@TECHREPORT{magalhes-etal:2001,
  author = {Léo Pini Magalhães and others},
  title = {Projeto {SAPIENS}},
  institution = {UNICAMP, USP},
  year = {2001},
  url = {http://www.dca.fee.unicamp.br/projects/sapiens/Reports/rf2000/rf2000.html},
  note = {Processo FAPESP 97/12807-1},
  owner = {magsilva},
  timestamp = {2009.04.08},
  type = {Relatório Final de Atividades}
}

@ARTICLE{Magdaleno-etal:2012,
  author = {Andréa Magalhães Magdaleno and Cláudia Maria Lima Werner and Renata Mendes de Araujo},
  title = {Reconciling software development models: A quasi-systematic review},
  volume = {85},
  number = {2},
  year = {2012},
  pages = {351 - 369},
  doi = {10.1016/j.jss.2011.08.028},
  abstract = {The purpose of this paper is to characterize reconciliation among the plan-driven, agile, and free/open source software models of software development. An automated quasi-systematic review identified 42 papers, which were then analyzed. The main findings are: there exist distinct organization, group and process levels of reconciliation; few studies deal with reconciliation among the three models of development; a significant amount of work addresses reconciliation between plan-driven and agile development; several large organizations (such as Microsoft, Motorola, and Philips) are interested in trying to combine these models; and reconciliation among software development models is still an open issue, since it is an emerging area and research on most proposals is at an early stage. Automated searches may not capture relevant papers in publications that are not indexed. Other data sources not amenable to execution of the protocol were not used. Data extraction was performed by only one researcher, which may increase the risk of threats to internal validity. This characterization is important for practitioners wanting to be current with the state of research. This review will also assist the scientific community working with software development processes to build a common understanding of the challenges that must be faced, and to identify areas where research is lacking. Finally, the results will be useful to software industry that is calling for solutions in this area. There is no other systematic review on this subject, and reconciliation among software development models is an emerging area. This study helps to identify and consolidate the work done so far and to guide future research. The conclusions are an important step towards expanding the body of knowledge in the field.},
  keywords = {Systematic review, Software process, Reconciliation among development models, Plan-driven, Agile, Free/open source software},
  issn = {0164-1212},
  journal = {Journal of Systems and Software}
}

@ARTICLE{Mahmoud:2005,
  author = {Mahmoud, Qusay H.},
  title = {Revitalizing Computing Science Education},
  volume = {38},
  month = {May},
  year = {2005},
  pages = {100--99},
  doi = {10.1109/MC.2005.170},
  abstract = {CS departments must fight shrinking enrollments by making their offerings more attractive.},
  keywords = {professional ethics, employment, the computing profession, computers and society, computer and information science education},
  acmid = {1069640},
  address = {Los Alamitos, CA, USA},
  issn = {0018-9162},
  issue = {5},
  journal = {Computer},
  numpages = {0},
  publisher = {IEEE Computer Society Press}
}

@ARTICLE{Mahmoud-etal:2004,
  author = {Mahmoud, Qusay H. and Dobosiewicz, Wlodek and Swayne, David},
  title = {Making Computer Programming Fun and Accessible},
  volume = {37},
  number = {2},
  month = {February},
  year = {2004},
  pages = {108--107},
  doi = {10.1109/MC.2004.1266305},
  abstract = {An introductory course's use of JavaScript provides an environment in which students can excel.},
  acmid = {1437309},
  address = {Los Alamitos, CA, USA},
  issn = {0018-9162},
  issue = {2},
  journal = {Computer},
  numpages = {0},
  publisher = {IEEE Computer Society Press}
}

@INPROCEEDINGS{Mahmoud-etal:2009,
  author = {Mahmoud, Qusay H. and Ngo, Thanh and Niazi, Razieh and Popowicz, Pawel and Sydoryshyn, Robert and Wilks, Matthew and Dietz, Dave},
  title = {An academic kit for integrating mobile devices into the CS curriculum},
  pages = {40--44},
  doi = {10.1145/1562877.1562896},
  abstract = {In this paper we present our freely available academic kit to help universities in integrating mobile devices into the Computer Science (CS) curriculum. The kit was designed and developed at the Centre for Mobile Education and Research at the University of Guelph, and includes instructors' resources for introducing and teaching mobile application development. The first release of the kit includes the teaching material for a full introductory course on mobile application development, and concrete teaching modules for integrating mobile devices into courses on software engineering, game design and development, web services, information security, and operating systems.},
  keywords = {blackberry, mobile application development, mobile devices, programming for fun, teaching computer programming, teaching tools},
  address = {New York, NY, USA},
  booktitle = {SIGCSE conference on Innovation and technology in computer science education},
  isbn = {978-1-60558-381-5},
  location = {Paris, France},
  publisher = {ACM},
  year = {2009}
}

@BOOK{Maia-Mattar:2008,
  title = {{ABC} da {EaD}: A educação a distância hoje},
  publisher = {Pearson Education},
  year = {2008},
  author = {Carmem Maia and João Mattar},
  editor = {Roger Trimer},
  isbn = {978-85-7605-157-2},
  pages = {138},
  address = {São Paulo, SP, } # Brazil,
  edition = {1},
  month = may,
  booktitle = {{ABC} da {EaD}: A educação a distância hoje}
}

@PHDTHESIS{Maidantchik:1999,
  author = {C. L. L. Maidantchik},
  title = {Gerência de Processos de Software para Equipes Geograficamente Dispersas},
  school = {COPPE/UFRJ},
  year = {1999},
  address = {Rio de Janeiro, RJ, Brasil},
  month = jun,
  owner = {magsilva},
  timestamp = {2008.01.21}
}

@INPROCEEDINGS{Maidantchik-Rocha:2002,
  author = {C. L. L. Maidantchik and A. R. Rocha},
  title = {Managing a worldwide software process},
  address = {Orlando, FL},
  booktitle = {Workshop on Global Software Development --- International Conference on Software Engineering (ICSE 2002)},
  month = may,
  owner = {magsilva},
  timestamp = {2008.01.21},
  year = {2002}
}

@ARTICLE{maiden:2005,
  author = {Maiden, N.},
  title = {What has requirements research ever done for us?},
  volume = {22},
  number = {4},
  month = jul,
  year = {2005},
  pages = {104- 105},
  journal = {IEEE Software},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@INPROCEEDINGS{Malaiya94RBTC,
  author = {Y. K. Malaiya and N. Li and J. Bieman and R. Karcick and B. Skibe},
  title = {The Relationship Between Test Coverage and Reliability},
  pages = {186--195},
  address = {Monterey, CA},
  booktitle = {International Symposium on Software Reliability Engineering},
  month = nov,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1994}
}

@INPROCEEDINGS{Maldonado00TSBF,
  author = {J. C. Maldonado},
  title = {Teste de Software Baseado em Fluxo de Dados e em Muta\c c\~ao: Uma Vis\~ao Geral},
  address = {São Carlos, SP},
  booktitle = {Concurso de Livre Docência -- ICMC-USP},
  month = feb,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {2000}
}

@MISC{Maldonado97CTSA,
  author = {J. C. Maldonado},
  title = {Critérios de Teste de Software: Aspectos Teóricos, Empíricos e de Automatização},
  howpublished = {Concurso de Livre Docência -- ICMC-USP},
  month = jan,
  year = {1997},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@PHDTHESIS{maldonado:1991,
  author = {J. C. Maldonado},
  title = {Critérios Potenciais Usos: Uma Contribuição ao Teste Estrutural de Software},
  school = {DCA/FEEC/UNICAMP},
  year = {1991},
  address = {Campinas, SP, Brazil},
  month = jul,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@MISC{maldonado-etal:2003,
  author = {J. C. Maldonado and E. F. Barbosa and A. M. R. Vincenzi and M. E. Delamaro and S. R. S. Souza and M. Jino},
  title = {Teste de Software: Teoria e Prática},
  howpublished = {Minicursos -- XVII Simpósio Brasileiro de Engenharia de Software (SBES 2003)},
  month = oct,
  year = {2003},
  address = {Manaus, AM},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{Maldonado89AFTA,
  author = {J. C. Maldonado and M. L. Chaim and M. Jino},
  title = {Arquitetura de uma Ferramenta de Teste de Apoio aos Critérios Potenciais Usos},
  address = {São Paulo, SP},
  booktitle = {XXII Congresso Nacional de Informática},
  month = sep,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1989}
}

@INPROCEEDINGS{Maldonado88SCTB,
  author = {J. C. Maldonado and M. L. Chaim and M. Jino},
  title = {Seleção de Casos de Testes Baseada na Análise de Fluxo de Dados através dos Critérios Potenciais Usos},
  pages = {24--35},
  address = {Canela, RS},
  booktitle = {II SBES -- Simpósio Brasileiro de Engenharia de Software (SBES 98)},
  month = oct,
  owner = {magsilva},
  timestamp = {2008.07.30},
  year = {1988}
}

@ARTICLE{Maldonado95VAMA,
  author = {J. C. Maldonado and M. E. Delamaro and M. L. Chaim and M Jino},
  title = {Uma Vis\~ao sobre a An\'alise de Mutantes e o Ambiente de Teste Proteum},
  volume = {3},
  number = {1},
  month = jan # {/} # jun,
  year = {1995},
  pages = {11--23},
  journal = {Revista do Instituto de Inform\'atica da PUCCAMP},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{Maldonado94AMTS,
  author = {J. C. Maldonado and S. C. P. F. Fabbri and M. E. Delamaro and P. C. Masiero},
  title = {An\'alise de Mutantes no Teste de Software e na Valida\c c\~ao de Sistemas Reativos},
  address = {IME-USP, S\~ao Paulo, SP},
  booktitle = {Jornada de Computa\c c\~ao -- Sess\~ao Regular da Academia Brasileira de Ci\^encias},
  month = apr,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1994}
}

@INPROCEEDINGS{maldonado-etal:1995,
  author = {J. C. Maldonado and S. R. S. Souza and M. E. Delamaro and P. C. Masiero},
  title = {Análise de Mutantes: Uma Avaliação Empírica da Propriedade de Antiextensionalidade},
  pages = {136--140},
  address = {Recife, PE},
  booktitle = {Workshop de Qualidade de Software},
  month = oct,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1995}
}

@INPROCEEDINGS{Maldonado92CPUA,
  author = {J. C. Maldonado and S. R. Vergílio and M. L. Chaim and M. Jino},
  title = {Critérios Potenciais Usos: Análise da Aplicação de um Benchmark},
  pages = {357--374},
  address = {Gramado, RS},
  booktitle = {VI SBES -- Simpósio Brasileiro de Engenharia de Software (SBES 92)},
  month = nov,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1992}
}

@TECHREPORT{Maldonado-etal:1998,
  author = {J. C. Maldonado and A. M. R. Vincenzi and E. F. Barbosa and S. R. S. Souza and M. E. Delamaro},
  title = {Aspectos Teóricos e Empíricos de Teste de Cobertura de Software},
  institution = {Instituto de Ciências Matemáticas e de Computação},
  month = jun,
  year = {1998},
  number = {31},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@MISC{mall:2009,
  author = {Rajib Mall},
  title = {Module 10 - Coding and Testing},
  howpublished = {Distance learning course on Software Engineering},
  year = {2009},
  note = {http://nptel.iitm.ac.in/courses/Webcourse-contents/IIT%20Kharagpur/Soft%20Engg/pdf/m10L25.pdf},
  owner = {magsilva},
  timestamp = {2009.12.09},
  url = {http://nptel.iitm.ac.in/courses/Webcourse-contents/IIT Kharagpur/Soft Engg/New_index1.html}
}

@BOOK{mall:2004,
  title = {Fundamentals of Software Engineering},
  publisher = {Prentice-Hall of India},
  year = {2004},
  author = {Rajib Mall},
  pages = {356},
  month = aug,
  owner = {magsilva},
  timestamp = {2009.11.30}
}

@INPROCEEDINGS{mancilha-musa:2006,
  author = {Diego Mancilha and D. L Musa},
  title = {Web Services para Auxílio na Integração de Bancos de Dados Heterogêneos},
  address = {Porto Alegre, RS, Brazil},
  booktitle = {Workshop de Software Livre},
  owner = {magsilva},
  review = {Eu achava que esse artigo ia tratar do problema que estou encontrando no NUMA, na integração de diferentes aplicações relacionadas a produção de software (vendas, prospecção, CRM, desenvolvimento de software). Ao menos era o que a figura que representava a arquitetura da ferramenta dava a impressão. Infelizmente, a solução deles é bem simples, baseada na integração diretamente no banco de dados, com uma camada de Web Services e de regras para transportar os dados. Não é o tipo de solução que eu procurava. No entanto, o artigo teve um aspecto positivo. Ele falou um pouco sobre o tamanho dos documentos XML trocados, citando a possibilidade de compactação. Certamente esse problema eu enfrentarei no NUMA. Pulei na Internet e encontrei um artigo na IBM sobre uso de compactação GZ. Eu já sabia que isso seria possível, o Apache possui o mod_deflate. No entanto, eu queria saber como fazê-lo sem depender do navegador. O artigo informa tudo isso: os cabeçalhos que precisam ser modificados, o código-fonte, etc: http://www-128.ibm.com/developerworks/webservices/library/ws-sqzsoap.html Para encerrar a discussão sobre o artigo, um ponto que vários trabalhos citam (inclusive alguns meus) e que hoje eu desacredito: a necessidade da existência de código documentado, documentação de usuário, tudo bem organizado, para que ele seja lançado publicamente. "Release early, release often", como diria Linus Torvalds. Não interessa se a documentação está ausente: o simples fato da aplicação funcionar, mesmo que precariamente, já é o suficiente epara várias pessoas. Eu pessoalmente gostaria de olhar o código, ver se eles fizeram alguma modificação no NuSOAP, como foi a implementação do mecanismo de regras de transformação (talvez de interesse para o MINT, após as várias e devidas adaptações).},
  timestamp = {2010.03.29},
  year = {2006}
}

@ARTICLE{mandrioli:onteaching1:1982,
  author = {Dino Mandrioli},
  title = {On teaching theoretical foundations of computer science},
  volume = {14},
  number = {3},
  year = {1982},
  pages = {36--53},
  doi = {10.1145/990511.990516},
  journal = {SIGACT News},
  owner = {magsilva},
  timestamp = {2008.01.20}
}

@ARTICLE{mandrioli:onteaching2:1982,
  author = {Dino Mandrioli},
  title = {On teaching theoretical foundations of Computer Science},
  volume = {14},
  number = {4},
  year = {1982},
  pages = {58--69},
  doi = {10.1145/1008902.1008904},
  journal = {SIGACT News},
  owner = {magsilva},
  timestamp = {2008.01.20}
}

@BOOK{manning-etal:2008,
  title = {Introduction to Information Retrieval},
  publisher = {Cambridge University},
  year = {2008},
  author = {Christopher D. Manning and Prabhakar Raghavan and Hinrich Schütze},
  pages = {482},
  address = {USA},
  edition = {1},
  url = {http://nlp.stanford.edu/IR-book/}
}

@MISC{software:mediawiki,
  author = {Magnus Manske},
  title = {MediaWiki},
  howpublished = {Programa de Computador},
  year = {2002},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://wikipedia.sourceforge.net/}
}

@BOOK{Manzano-Oliveira:2012,
  publisher = {Érica},
  year = {2012},
  author = {José Augusto N. G. Manzano and Jayr Figueiredo de Oliveira},
  isbn = {978-85-7194-413-8},
  pages = {238},
  series = {Estudo dirigido},
  address = {São Paulo, SP, } # Brazil,
  edition = {15},
  booktitle = {Estudo dirigido de algoritmos}
}

@BOOK{Manzano-Oliveira:2009,
  publisher = {Érica},
  year = {2009},
  author = {José Augusto N. G. Manzano and Oliveira, Jayr Figueiredo de},
  isbn = {978-85-365-0221-2},
  pages = {320},
  address = {São Paulo, SP, } # Brazil,
  edition = {22},
  booktitle = {Algoritmos: lógica para desenvolvimento de programação de computadores}
}

@INPROCEEDINGS{Marcelino-etal:2008,
  author = {Marcelino, Maria José and Redondo, Miguel Angel and Tinoco, Ana Isabel and Mendes, Antônio José},
  title = {SimulCol: A Collaborative Educational Modeling Simulation Tool},
  pages = {770--771},
  doi = {10.1109/ICALT.2008.201},
  abstract = {SimulCol is an asynchronous collaborative continuous modeling tool for generic systems allowing learners spread in anytime and anywhere to develop models in group. Model building can be abridged if done in group. However, many times, students are not physically together. Still they need to work collectively. That is what SimulCol provides, along with teacher tools to follow students' work.},
  keywords = {collaborative systems, modeling tools},
  acmid = {1381652},
  address = {Washington, DC, USA},
  booktitle = {Eighth IEEE International Conference on Advanced Learning Technologies},
  isbn = {978-0-7695-3167-0},
  numpages = {2},
  publisher = {IEEE Computer Society},
  url = {http://portal.acm.org/citation.cfm?id=1381300.1381652},
  year = {2008}
}

@MISC{software:gnupdf,
  author = {Jose E. Marchesi and Aleksander Morgado and Anish Patil and others},
  title = {GNU PDF},
  howpublished = {Programa de computador},
  year = {2008},
  owner = {magsilva},
  timestamp = {2010.04.06},
  url = {http://www.gnupdf.org/}
}

@INPROCEEDINGS{marcos-etal:2008,
  author = {Luis de Marcos and Jos\'{e}-Javier Mart\'{\i}nez and Jose-Antonio Gutierrez},
  title = {Swarm intelligence in e-learning: a learning object sequencing agent based on competencies},
  pages = {17--24},
  doi = {10.1145/1389095.1389099},
  address = {New York, NY, USA},
  booktitle = {GECCO '08: Proceedings of the 10th annual conference on Genetic and evolutionary computation},
  isbn = {978-1-60558-130-9},
  location = {Atlanta, GA, USA},
  publisher = {ACM},
  year = {2008}
}

@BOOK{Marcula-BeniniFilho:2010,
  publisher = {Érica},
  year = {2010},
  author = {Marcelo Marçula and Benini Filho, Pio Armando},
  isbn = {978-85-365-0053-9},
  pages = {406},
  address = {São Paulo, SP, } # Brazil,
  edition = {3},
  booktitle = {Informática: conceitos e aplicações}
}

@BOOK{Margolis-Fisher:2003,
  publisher = {MIT},
  year = {2003},
  author = {Jane Margolis and Allan Fisher},
  isbn = {9780262632690},
  pages = {182},
  address = {Cambridge, MA, } # USA,
  edition = {1},
  abstract = {The information technology revolution is transforming almost every aspect of society, but girls and women are largely out of the loop. Although women surf the Web in equal numbers to men and make a majority of online purchases, few are involved in the design and creation of new technology. It is mostly men whose perspectives and priorities inform the development of computing innovations and who reap the lion's share of the financial rewards. As only a small fraction of high school and college computer science students are female, the field is likely to remain a "male clubhouse," absent major changes. In Unlocking the Clubhouse, social scientist Jane Margolis and computer scientist and educator Allan Fisher examine the many influences contributing to the gender gap in computing. The book is based on interviews with more than 100 computer science students of both sexes from Carnegie Mellon University, a major center of computer science research, over a period of four years, as well as classroom observations and conversations with hundreds of college and high school faculty. The interviews capture the dynamic details of the female computing experience, from the family computer kept in a brother's bedroom to women's feelings of alienation in college computing classes. The authors investigate the familial, educational, and institutional origins of the computing gender gap. They also describe educational reforms that have made a dramatic difference at Carnegie Mellon --where the percentage of women entering the School of Computer Science rose from 7% in 1995 to 42% in 2000 -- and at high schools around the country.},
  booktitle = {Unlocking the Clubhouse: Women in Computing},
  timestamp = {2013-11-17}
}

@MISC{Markey:2009,
  author = {Nicolas Markey},
  title = {Tame the {BeaST} -- The {B} to {X} of {BibTeX}},
  month = oct,
  year = {2009},
  url = {http://www.ctan.org/tex-archive/info/bibtex/tamethebeast}
}

@INPROCEEDINGS{marrow-etal:2010,
  author = {Marrow, Paul and Meesters, Lydia and Obrist, Marianna},
  title = {Methods for user studies of interactive (TV) technologies},
  pages = {303--304},
  doi = {10.1145/1809777.1809838},
  abstract = {The purpose of this workshop is to share experience on how to prepare user studies around interactive TV technologies, including newly emerging services on mobile devices, in different contexts and for diverse target users. Finding and applying the right method for capturing users' experiences is challenging. We are all familiar with qualitative and quantitative methods, going out into the field and performing user studies in a laboratory setting. But how can we identify which method is the most appropriate one, and which should be combined to get the user feedback? These and other questions will be discussed within this workshop based on the organizers' expertise and the participants' own experience. Contributions from the audience will be combined with very interactive discussions based on practical examples, namely selected scenarios for user studies.},
  keywords = {interactive technologies, methods, user experience},
  address = {New York, NY, USA},
  booktitle = {Proceedings of the 8th international interactive conference on Interactive TV\&\#38;Video},
  isbn = {978-1-60558-831-5},
  location = {Tampere, Finland},
  publisher = {ACM},
  year = {2010}
}

@INPROCEEDINGS{marschall-schoenmakers:2003,
  author = {Frank Marschall and Maurice Schoenmakers},
  title = {Towards Model-Based Requirements Engineering for Web-Enabled B2B Applications},
  pages = {312-320},
  address = {Huntsville, AL, EUA},
  booktitle = {10th IEEE International Conference and Workshop on the Engineering of Computer-Based Systems (ECBS'03)},
  month = apr,
  owner = {magsilva},
  publisher = {IEEE Computer Society},
  timestamp = {2008.07.30},
  year = {2003}
}

@ARTICLE{marshall:1998,
  author = {Peter Marshall},
  title = {An Overview of the Development of Digital Terrestrial Television in the UK},
  year = {1998},
  pages = {1-5},
  journal = {IEE Afternoon Seminar on Digital Television Broadcasting},
  timestamp = {2008.09.01}
}

@INPROCEEDINGS{Marshall-Mitchell:2002,
  author = {S. Marshall and G. Mitchell},
  title = {An E-Learning Maturity Model?},
  address = {Auckland, Nova Zelândia},
  booktitle = {19th Annual Conference of the Australian Society for Computers in Learning in Tertiary Education},
  editor = {A. Williamson and K. Gunn and A. Young and T. Clear},
  location = {Auckland, New Zealand},
  publisher = {ASCILITE},
  timestamp = {2008.09.28},
  year = {2002}
}

@INPROCEEDINGS{Marshall-Mitchell:2004,
  author = {Stephen Marshall and Geoff Mitchell},
  title = {Applying {SPICE} to e-learning: an e-learning maturity model?},
  pages = {185--191},
  abstract = {The Capability Maturity Model and SPICE approach to software process improvement has resulted in a robust system for improving development process capability in the field of software engineering. We apply these same ideas in the area of e-learning in order to explore whether similar insights could be generated for institutions engaged in online delivery of teaching. In order to test this idea, a set of potential process areas are presented, based on a well known set of e-learning benchmarks and a trial analysis of a project is conducted. We suggest that this model offers a means for institutions to identify systemic weaknesses in their e-learning development, delivery and management that potentially can inform future resourcing and strategic priorities.},
  keywords = {e-learning, CMM, SPICE, process improvement},
  address = {Darlinghurst, Austrália},
  booktitle = {Australasian Computing Education},
  location = {Dunedin, New Zealand},
  publisher = {Australian Computer Society},
  year = {2004}
}

@INPROCEEDINGS{Marshall-Mitchell:2003,
  author = {S. Marshall and G. Mitchell},
  title = {Potential Indicators of e-Learning Process Capability},
  address = {Adelaide, Austrália},
  booktitle = {EDUCAUSE in Australasia},
  location = {Adelaide, Austrália},
  month = may,
  timestamp = {2008.09.28},
  year = {2003}
}

@INPROCEEDINGS{Martin:1997,
  author = {Martin, C. Dianne},
  title = {The case for integrating ethical and social impact into the computer science curriculum},
  pages = {114--120},
  doi = {10.1145/266057.266131},
  booktitle = {Conference on Integrating technology into Computer Science Education: Working Group Reports and Supplemental Proceedings},
  isbn = {1-58113-012-0},
  location = {Uppsala, #Sweden#},
  publisher = {ACM},
  year = {1997}
}

@INBOOK{Martinez:2000,
  title = {Designing Learning Objects to Personalize Learning},
  year = {2000},
  editor = {D. A. Wiley},
  author = {M. Martinez},
  booktitle = {The Instructional Use of Learning Objects},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@ARTICLE{MartinezOrtiz-etal:2009,
  author = {Martínez-Ortiz, Iván and Sierra, José-Luis and Fernández-Manjón, Baltasar},
  title = {Authoring and Reengineering of IMS Learning Design Units of Learning},
  volume = {2},
  number = {3},
  month = jul,
  year = {2009},
  pages = {189--202},
  doi = {10.1109/TLT.2009.14},
  abstract = {Educational Modeling Languages (EMLs) are notations that allow instructors to formally describe educational processes, including teaching and learning interactions and activities. The description of a specific teaching process using an EML is called a learning design. EMLs, where IMS Learning Design (IMS LD) is becoming a "de facto" standard, address aspects such as the interoperability and reusability of teaching practices across learning management systems. However, the actual application of EMLs is being hindered by different problems such as the technical skills required to use typical EMLs and the difficulty of understanding and maintaining preexisting learning designs. Thus, to promote the adoption of EMLs, it is necessary to provide more user-friendly tools and methodologies to facilitate their assimilation and reduce the workload required to use them. In this paper, we present the e-LD system, which provides a graphical notation to design or redesign learning designs, an import-modification-export process to reengineer IMS LD learning designs, and a tool to generate and analyze dependencies between different IMS LD elements.},
  acmid = {1638721},
  address = {Los Alamitos, CA, USA},
  issn = {1939-1382},
  issue = {3},
  journal = {Transactions on Learning Technologies},
  numpages = {14},
  owner = {magsilva},
  publisher = {IEEE}
}

@INPROCEEDINGS{Martins-Pimental:2011,
  author = {Martins, D.S. and da Graca Campos Pimentel, M.},
  title = {End-User Ubiquitous Multimedia Production: Process and Case Studies},
  pages = {197--202},
  doi = {10.1109/U-MEDIA.2011.18},
  abstract = {Traditional processes of multimedia production are generally regarded as professionally-oriented workflows, and they don't generally encompass the context of user-generated multimedia content. Taking into consideration production led by users, there is an urge for new frameworks that model end-users not only as consumers of multimedia content, but also as first-class elements in the whole multimedia production process. In this paper we advocate the need of an end-user production process that is oriented towards user-generated content, this process anticipates the participation of end-users in all phases of multimedia production and the assistance of user authoring tasks by means of metadata captured with low effort. We demonstrate the proposed process by means of results previously reported by several members of our research group.},
  keywords = {user-generated content; multimedia communication; ubiquitous computing; authoring systems},
  booktitle = {4th International Conference on Ubi-Media Computing (U-Media)},
  isbn = {978-1-4577-1174-9, 978-0-7695-4493-9},
  location = {São Paulo, SP, #Brazil#},
  month = jul,
  year = {2011}
}

@INPROCEEDINGS{Martins-etal:2009:SAC,
  author = {Martins, Diogo S. and Biajiz, Mauro and do Prado, Antonio F. and de Souza, Wanderley L.},
  title = {Implicit relevance feedback for context-aware information retrieval in UbiLearning environments},
  pages = {659--663},
  doi = {10.1145/1529282.1529418},
  abstract = {Ubiquitous Learning (UbiLearning) environments heavily employ mobile devices to empower users with mobility and tooling support to learn anytime, anywhere. Introducing mobile devices in educational settings imposes constraints on search behavior due to limited resources on these devices such as small screens and restricted input functionalities. Targeting this scenario, this paper proposes an architecture for implicit relevance feedback which considers users' work context to expand search queries in order to satisfy information needs with greater precision. Evaluation results conducted over a local test collection enriched with contextual features reveal improvements on average precision when compared to a pseudo relevance feedback baseline.},
  keywords = {context-awareness, information retrieval, query expansion, ubiquitous learning},
  series = {SAC '09},
  acmid = {1529418},
  address = {New York, NY, USA},
  booktitle = {Symposium on Applied Computing},
  isbn = {978-1-60558-166-8},
  location = {Honolulu, Hawaii, USA},
  numpages = {5},
  publisher = {ACM},
  year = {2009}
}

@INPROCEEDINGS{Martins99CCAU,
  author = {E. Martins and C. M. Toyota},
  title = {Construção de Classes Autotestáveis},
  pages = {196--209},
  address = {Campinas, SP},
  booktitle = {VIII SCTF -- Simp\'osio de Computa\c c\~ao Tolerante a Falhas},
  month = jul,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1999}
}

@ARTICLE{Martins-etal:2010:Scientometrics,
  author = {Martins, Waister and Gonçalves, Marcos and Laender, Alberto and Ziviani, Nivio},
  title = {Assessing the quality of scientific conferences based on bibliographic citations},
  volume = {83},
  year = {2010},
  pages = {133-155},
  doi = {10.1007/s11192-009-0078-y},
  abstract = {Assessing the quality of scientific conferences is an important and useful service that can be provided by digital libraries and similar systems. This is specially true for fields such as Computer Science and Electric Engineering, where conference publications are crucial. However, the majority of the existing quality metrics, particularly those relying on bibliographic citations, has been proposed for measuring the quality of journals. In this article we conduct a study about the relative performance of existing journal metrics in assessing the quality of scientific conferences. More importantly, departing from a deep analysis of the deficiencies of these metrics, we propose a new set of quality metrics especially designed to capture intrinsic and important aspects related to conferences, such as longevity, popularity, prestige, and periodicity. To demonstrate the effectiveness of the proposed metrics, we have conducted two sets of experiments that contrast their results against a gold standard produced by a large group of specialists. Our metrics obtained gains of more than 12% when compared to the most consistent journal quality metric and up to 58% when compared to standard metrics such as Thomson's Impact Factor.},
  affiliation = {Federal University of Minas Gerais Computer Science Department Belo Horizonte 31270-901 MG Brazil},
  issn = {0138-9130},
  issue = {1},
  journal = {Scientometrics},
  keyword = {Computer Science},
  note = {10.1007/s11192-009-0078-y},
  publisher = {Akadémiai Kiadó and Springer}
}

@INPROCEEDINGS{Martins-etal:2009:JCDL,
  author = {Martins, Waister Silva and Gonçalves, Marcos André and Laender, Alberto H. F. and Pappa, Gisele L.},
  title = {Learning to assess the quality of scientific conferences: a case study in computer science},
  pages = {193--202},
  doi = {10.1145/1555400.1555431},
  abstract = {Assessing the quality of scientific conferences is an important and useful service that can be provided by digital libraries and similar systems. This is specially true for fields such as Computer Science and Electric Engineering, where conference publications are crucial. However, the majority of the existing approaches for assessing the quality of publication venues has been proposed for journals. In this paper, we characterize a large number of features that can be used as criteria to assess the quality of scientific conferences and study how these several features can be automatically combined by means of machine learning techniques to effectively perform this task. Within the features studied are citations, submission and acceptance rates, tradition of the conference, and reputation of the program committee members. Among our several findings, we can cite that: (1) separating high quality conferences from medium and low quality ones can be performed quite effectively, but separating the last two types is a much harder task; and (2) citation features followed by those associated with the tradition of the conference are the most important ones for the task.},
  keywords = {classification, conference assessment, digital library, machine learning},
  series = {JCDL '09},
  acmid = {1555431},
  address = {New York, NY, USA},
  booktitle = {Joint Conference on Digital Libraries},
  isbn = {978-1-60558-322-8},
  location = {Austin, TX, USA},
  numpages = {10},
  publisher = {ACM/IEEE},
  year = {2009}
}

@INPROCEEDINGS{Marube-Tavares:2010,
  author = {Newton Nyamasege Marube and Daniel Campelo Tavares},
  title = {Ginga Edutainer: A Framework for the Development of T-Learning Applications on Ginga -- The Brazilian Digital Television},
  pages = {1--5},
  abstract = {The aim of this study is to propose a framework for developing educational applications for Digital Television, thus simplifying the process of developing applications by abstracting the execution platform. The arrival of digital TV in Brazil offers a range of possibilities in the field of education. The availability of television sets in 95.1% of households in Brazil indicates that studies on television as a form of teaching and learning can be adapted to this medium. The proposed tool incorporates entertainment and education and aims to make the task of producing educational software simpler, and consequently reducing the time needed to develop applications that can be used to educate and promote digital inclusion in the country. When implemented, the project will integrate interactivity in education, creating educational applications that can motivate the user in an environment of teaching and learning.},
  keywords = {T-learning, interactive digital tv, Ginga, Middleware, Frameworks},
  booktitle = {Workshop on Interactive Digital TV in Emergent Countries},
  location = {Tampere, Finland},
  month = jun,
  url = {http://www.ufam-automation.net/idtvec/acceptedpapers/W1_4_marube.pdf},
  year = {2010}
}

@BOOK{masetto:1998,
  title = {{Docência na Universidade}},
  publisher = {Papirus},
  year = {1998},
  author = {M. Masetto},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@ARTICLE{MAS91ES,
  author = {P. C. Masiero and R. P. M. Fortes and N. Batista},
  title = {Editing and simulating the behavioral aspects of real-time systems},
  year = {1991},
  pages = {45--61},
  journal = {Proceedings of the Twenty-Eighth Brazilian Integrated Seminar on Hardware and Software (SEMISH, Santos, Brazil, Aug. 5-9)},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@INPROCEEDINGS{massey:2002,
  author = {Bart Massey},
  title = {Where Do Open Source Requirements Come From (And What Should We Do About It)?},
  address = {Orlando, Flórida, EUA},
  booktitle = {ICSE Workshop on Open Source Software Engineering},
  owner = {Marco Aurélio Graciotto Silva},
  timestamp = {2008.07.30},
  year = {2002}
}

@BOOK{Mathur:2008,
  title = {Foundations of Software Testing},
  publisher = {Pearson Education},
  year = {2008},
  author = {Aditya P. Mathur},
  isbn = {978-8131716601},
  volume = {1},
  pages = {689},
  edition = {1},
  month = apr,
  abstract = {Foundations of Software Testing is the premiere example-based text and reference for establishing sound engineering practices in test generation, selection, minimization and enhancement, for software projects ranging from the most simple to the highly complex, to those used by government agencies such as the FAA. Foundations of Software Testing also covers data-flow based adequacy and mutation-based adequacy, which are the most powerful of the available test adequacy criteria. It distills knowledge developed by hundreds of testing researchers and practitioners from all over the world and brings it to readers in an easy to understand form. Test generation, selection, priortization and assessment lie at the foundation of all technical activities that arise in a test process. Appropriate deployment of the elements of this strong foundation enables the testing of different types of software applications, including Object Oriented systems, Web services, graphical user interfaces, embedded systems, as well as properties relating to security, performance, and reliability. With over 200 examples and exercises of mathematical, step-by-step approaches, Foundations describes a wide variety of testing techniqes, including finite state models, combinatorial designs, and minimization for regression testing},
  booktitle = {Foundations of Software Testing},
  owner = {magsilva},
  timestamp = {2009.08.18}
}

@ARTICLE{Mathur94MTES,
  author = {A. P. Mathur},
  title = {Mutation Testing},
  year = {1994},
  pages = {707--713},
  journal = {Encyclopedia of Software Engineering},
  owner = {magsilva},
  publisher = {John Wiley \& Sons},
  timestamp = {2008.07.31}
}

@MISC{Mathur92CSSE,
  author = {A. P. Mathur},
  title = {CS 406 Software Engineering},
  howpublished = {Course Handout, Purdue University},
  month = {Fall},
  year = {1992},
  owner = {magsilva},
  pages = {1--12},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{Mathur91EDFT,
  author = {A. P. Mathur},
  title = {On the Effectiveness of Data Flow Testing},
  pages = {1--14},
  address = {San Francisco, CA},
  booktitle = {Quality Week 1991},
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1991}
}

@INPROCEEDINGS{Mathur91PERI,
  author = {A. P. Mathur},
  title = {Performance, Effectiveness and Reliability Issues in Software Testing},
  pages = {604--605},
  address = {Tokio, Japan},
  booktitle = {15th Annual International Computer Software and Applications Conference},
  month = sep,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1991}
}

@INPROCEEDINGS{Mathur91RSDF,
  author = {A. P. Mathur},
  title = {On the Relative Strengths of Data Flow and Mutation Testing},
  pages = {165--181},
  address = {Portland, OR},
  booktitle = {Ninth Annual Pacific Northwest Software Quality Conference},
  month = oct,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1991}
}

@INPROCEEDINGS{mathur-krauser:1988,
  author = {A. P. Mathur and E. W. Krauser},
  title = {Modeling Mutation on Vector Processor},
  pages = {154--161},
  address = {Singapore},
  booktitle = {X International Conference on Software Engineering},
  month = apr,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1988}
}

@INPROCEEDINGS{Mathur94TCMD,
  author = {A. P. Mathur and W. E. Wong},
  title = {A Theoretical Comparison between Mutation and Data Flow Based Test Adequacy Criteria},
  pages = {38--45},
  address = {Phoenix, AZ},
  booktitle = {1994 ACM Computer Science Conference},
  month = mar,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1994}
}

@ARTICLE{mathur-wong:1994,
  author = {A. P. Mathur and W. E. Wong},
  title = {An Empirical Comparison of Data Flow and Mutation Based Test Adequacy Criteria},
  volume = {4},
  number = {1},
  month = mar,
  year = {1994},
  pages = {9--31},
  doi = {10.1002/stvr.4370040104},
  abstract = {Evaluation of the adequacy of a test set consisting of one or more test cases is a problem oftes encountered in software testing environments. Two test adequacy criiteria are considered, namely the data flow based all-uses criterion and a mutation based criterion. An empirical study was conducted to compare the difficulty of satisfying the two criteria and their costs. Similar studies conducted in the past are discussed in the light of this study. A discussion is also presented of how and why the results of this study, when viewed in conjunction with the results of earlier comparisons of testing methods, are useful to a software test team.},
  journal = {Software Testing, Verification and Reliability},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{Mathur93ECAM,
  author = {A. P. Mathur and W. E. Wong},
  title = {Evaluation of the Cost of Alternative Mutation Strategies},
  pages = {320--335},
  address = {Rio de Janeiro, RJ},
  booktitle = {VII Simpósio Brasileiro de Engenharia de Software (SBES 93)},
  month = oct,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1993}
}

@MISC{project:safe,
  author = {Renata Pontin de Mattos Fortes and Marcelo Augusto Santos Turine and Christian Robottom Reis},
  title = {Engenharia de Software Disponível a Todos - Software Engineering Available for Everyone (SAFE)},
  howpublished = {Proposta de Financiamento do Projeto},
  month = {oct},
  year = {2004},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@ARTICLE{Mayer-Moreno:2003,
  author = {Richard E. Mayer and Roxana Moreno},
  title = {Nine Ways to Reduce Cognitive Load in Multimedia Learning},
  volume = {38},
  number = {1},
  year = {2003},
  pages = {43-52},
  abstract = {First, we propose a theory of multimedia learning based on the assumptions that humans possess separate systems for processing pictorial and verbal material (dual-channel assumption), each channel is limited in the amount of material that can be processed at one time (limited-capacity assumption), and meaningful learning involves cognitive processing including building connections between pictorial and verbal representations (active-processing assumption). Second, based on the cognitive theory of multimedia learning, we examine the concept of cognitive overload in which the learner's intended cognitive processing exceeds the learner's available cognitive capacity. Third, we examine five overload scenarios. For each overload scenario, we offer one or two theory-based suggestions for reducing cognitive load, and we summarize our research results aimed at testing the effectiveness of each suggestion. Overall, our analysis shows that cognitive load is a central consideration in the design of multimedia instruction.},
  journal = {Educational Psychologist},
  publisher = {Lawrence Erlbaum}
}

@INPROCEEDINGS{mayorga-etal:1999,
  author = {José Ignacio Mayorga and Maria Felisa Verdejo and Miguel Rodríguez and M. Yolanda Calero},
  title = {Domain Modelling to Support Educational Web-Based Authoring},
  pages = {1-9},
  abstract = {This paper describes an approach to web-based authoring of educational material. We define a model for the class of subjects of our interest (those including both theoretical and practical issues). From this model, specific content outlines can be derived as subclasses and then instanced into actual domains. The last step consists in generating interactive documents, which use the instanced domain. Students can explore these documents through a web browser. Thus, an interactive learning scenario is created. This approach allows reusing and adapting the contents to a variety of situations, students and teaching purposes.},
  address = {Gjovik, Norway},
  booktitle = {Telecommunications for Education and Training (TET 99)},
  month = jun,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1999}
}

@MISC{software:advancecomp,
  author = {Andrea Mazzoleni},
  title = {AdvanceCOMP},
  howpublished = software,
  month = may,
  year = {2002},
  url = {http://advancemame.sourceforge.net/comp-readme.html}
}

@ARTICLE{mccabe:1976,
  author = {Thomas J. McCabe},
  title = {A Software Complexity Measure},
  volume = {2},
  number = {4},
  month = dec,
  year = {1976},
  pages = {308--320},
  journal = {IEEE Transactions of Software Engineering},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@MISC{xmlevents:2003,
  author = {Shane McCarron and Steven Pemberton and T. V. Raman},
  title = {XML Events},
  howpublished = {W3C Recommendation},
  month = oct,
  year = {2003},
  comment = {24/05/2005},
  file = {XML Events.pdf:XML Events.pdf:PDF},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://www.w3.org/TR/xml-events}
}

@MISC{javaserverfaces:2004,
  author = {Claig McClanahan and Ed Burns and Roger Kitain},
  title = {JavaServer Faces Specification 1.1},
  howpublished = {JCP Specification},
  month = feb,
  year = {2004},
  file = {JavaServer Faces Specification 1.1.pdf:JavaServer Faces Specification 1.1.pdf:PDF},
  owner = {Marco Aurélio Graciotto Silva},
  timestamp = {2008.07.30}
}

@ARTICLE{mcclure-etal:1999,
  author = {McClure, John R. and Sonak, Brian and Suen, Hoi K.},
  title = {Concept map assessment of classroom learning: Reliability, validity, and logistical practicality},
  volume = {36},
  number = {4},
  month = apr,
  year = {1999},
  pages = {475--492},
  abstract = {Abstract The psychometric characteristics and practicality of concept mapping as a technique for classroom assessment were evaluated. Subjects received 90 min of training in concept mapping techniques and were given a list of terms and asked to produce a concept map. The list of terms was from a course in which they were enrolled. The maps were scored by pairs of graduate students, each pair using one of six different scoring methods. The score reliability of the six scoring methods ranged from r = .23 to r = .76. The highest score reliability was found for the method based on the evaluation of separate propositions represented. Correlations of map scores with a measure of the concept maps' similarity to a master map provided evidence supporting the validity of five of the six scoring methods. The times required to provide training in concept mapping, produce concepts, and score concept maps were compatible with the adoption of concept mapping as classroom assessment technique.},
  issn = {1098-2736},
  journal = {Journal of Research in Science Teaching},
  publisher = {John Wiley \& Sons}
}

@ARTICLE{mccracken:1997,
  author = {W. M. McCracken},
  title = {{Software Engineering Education: What Academia Can Do}},
  volume = {14},
  number = {6},
  year = {1997},
  pages = {27-28},
  journal = {IEEE Software},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@TECHREPORT{Mcdaniel94TPIC,
  author = {R. McDaniel and J. D. McGregor},
  title = {Testing Polymorphic Interactions between Classes},
  institution = {Clemson University},
  month = mar,
  year = {1994},
  number = {TR-94-103},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{McGinley:2008:MTE:1453805.1453834,
  author = {McGinley, Maurice Joseph},
  title = {A map of the television experience},
  pages = {147--150},
  doi = {10.1145/1453805.1453834},
  abstract = {This paper presents an analysis of the experience of television based on a definition of experience as 'understanding situated in time'. Citing Heidegger's phenomenological investigations of everyday experiences, as well as tenets from Distributed Cognition, and Activity Theory, the experience of interaction with television is shown to be situated within personal and cultural contexts, which determine the meaning and therefore the quality of the experience. A diagram of television use cases representing television practices is presented, ordered according to proximity to cultural practice. The diagram and method are discussed. The method is recommended as a tool to direct user-interface design and requirements development priorities.},
  keywords = {activity theory, distributed cognition, hci theories, interactive television, phenomenology, television},
  address = {New York, NY, USA},
  booktitle = {1st international conference on Designing interactive user experiences for TV and video},
  isbn = {978-1-60558-100-2},
  location = {Silicon Valley, California, USA},
  publisher = {ACM},
  year = {2008}
}

@ARTICLE{McGreal-etal:2004,
  author = {Rory McGreal and Terry Anderson and Gilbert Babin and Stephen Downes and Norm Friesen and Kevin Harrigan and Marek Hatala and Doug MacLeod and Mike Mattson and Gilbert Paquette and Griff Richards and Toni Roberts and Steve Schafer},
  title = {EduSource: Canada's Learning Object Repository Network},
  month = mar,
  year = {2004},
  pages = {1--16},
  abstract = {Many years ago I attended a meeting at Stanford University where Steve Jobs did his first public demonstration of the NEXT computer. He amazed his audience by selecting a series of visual objects, each of which functioned like a part in a machine. By drawing lines between them on the screen, he made them function together as one machine where the functions integrated seamlessly. These were reusable objects designed to function in any context. The same principles are applied in Object Oriented (computer) Programming, which combines modules to create larger programs. Similar principles build custom learning experiences using Learning Objects. An alliance of Canadian Universities and government agencies pooled their resources to establish a network to share and combine Learning Objects from a variety of sources and further develop this technology. In the process, they resolved many learning, logistical, and legal problems and moved this technology forward by an order of magnitude. Principal goals include: nationwide interoperability, network of repositories, linked servers, repository software programs, national and international standards, digital rights management, business and management models, evaluation and feedback, dissemination of results, and bilingual access to all Canadians, particularly learners with disabilities. The defined tasks were sub-divided into nine work packages, each with a lead institution as package manager.},
  url = {http://www.itdl.org/Journal/Mar_04/article01.htm},
  issn = {1550-6908},
  journal = {International Journal of Instructional Technology and Distance Learning},
  timestamp = {2012.02.23}
}

@ARTICLE{mcgregor:2007,
  author = {J. D. McGregor},
  title = {Test early, test often},
  volume = {6},
  number = {4},
  month = may,
  year = {2007},
  pages = {7-14},
  url = {http://www.jot.fm/issues/issue_2007_05/column1},
  journal = {Journal of Object-Oriented Programming},
  owner = {magsilva},
  timestamp = {2009.04.22}
}

@ARTICLE{Mcgregor97CTES,
  author = {J. D. McGregor},
  title = {Component Testing},
  month = mar,
  year = {1997},
  url = {http://www.cs.clenson.edu/~johnmc/joop/},
  journal = joop,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@ARTICLE{Mcgregor97MCTM,
  author = {J. D. McGregor},
  title = {Making Component Testing More Effective},
  month = jun,
  year = {1997},
  url = {http://www.cs.clenson.edu/~johnmc/joop/},
  journal = joop,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{Mcgregor94FTCL,
  author = {J. D. McGregor},
  title = {Functional Testing of Classes},
  address = {San Francisco, CA},
  booktitle = {Proc. 7th International Quality Week},
  month = may,
  organization = {Software Research Institute},
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1994}
}

@ARTICLE{Mcgregor94IOOT,
  author = {J. D. McGregor and T. D. Korson},
  title = {Integrated Object-Oriented Testing and Development Process},
  volume = {37},
  number = {9},
  month = sep,
  year = {1994},
  pages = {59--77},
  journal = comacm,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@ARTICLE{mclaughlin:2004,
  author = {L. McLaughlin},
  title = {European union struggles with new rules for software patents},
  volume = {21},
  number = {5},
  month = {sep},
  year = {2004},
  pages = {101-104},
  journal = {IEEE Software},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@TECHREPORT{mcormond:2003,
  author = {Russell McOrmond},
  title = {A Review Of Software Patent Issues},
  year = {2003},
  url = {http://www.flora.ca/patent2003/software-patent2003.shtml},
  comment = {02/07/2005},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@RESEARCH-PROJECT{project:openED,
  title = {{openED} -- Designing for participatory learning in open educational environments},
  author = {Augusto Medina},
  institution = {Sociedade Portuguesa de Inovação (SPI)},
  number = {505667-LLP-1-2009-1-PT-KA3-KA3MP},
  month = nov,
  year = {2009},
  duration = {33},
  abstract = {The Web 2.0 in general and the Open Source world in particular demonstrates that volunteer collaboration can result in innovative products and provide learning opportunities. We aim to discover what happens when approaches from the volunteer community are used to break down barriers between teachers and learners in order to design and co-construct sites for participatory learning. Content creation, knowledge exchange, community dynamics, and the impact on the boundaries between formal and informal education are the key subjects of this project. The objective of the project is to evaluate the applicability of such approaches to supporting the provision of free/open learning within cross-cultural and multilingual settings. Particular attention will be paid to factors such as: the evolution of content and communities; the speed of innovation; the quality of learning provision and learning outcomes; and possible revenue models. We aim to apply principles from open source communities and to 'open-up' the OU's course 'Practice Based Research in Educational Technology' in order to create a free and open course in Technology Enhanced Learning. The openEd project will therefore: 1) Develop experimental approaches for participatory learning and teaching within open educational environments; 2) Implement and test these approaches through three consecutive pilots to promote continuity, community building and evolutionary growth; 3) Develop a sustainability framework and revenue models, to be implemented and tested alongside the pilots, to assure financial self-sustainability for such scenarios; 4) Analyze the results and benchmark them against initial assumptions; 5) Evaluate the project, disseminate outcomes and take the results to the wider community. The course will be open to: the project partners' student/trainee/employee population; educational providers outside the project partnership; partners from associated networks, and learners outside of formal education.}
}

@INPROCEEDINGS{Mehlenbacher:2012,
  author = {Mehlenbacher, Brad},
  title = {Massive open online courses ({MOOCs}): educational innovation or threat to higher education?},
  pages = {99--99},
  doi = {10.1145/2316936.2316953},
  abstract = {MOOCs are receiving the intense attention of the media and, in turn, of academic and industry researchers fascinated by their potential to revolutionize educational access and life-long learning. The presentation introduces MOOCs and traces their history and development both inside and outside the academy. This leads to an overview of documented strengths of MOOCs as elaborated upon by various educational technology futurists. These futurists and media accounts make it difficult to argue against taking up the charge and contributing to the next great educational wave. Still, as exciting as these promises and potentials are, I want also to describe the various challenges presented by MOOCs, challenges for learners, instructors and faculty, educational administrators and educational institutions in general. And the stakes for these developments can't be underestimated. Google, MIT, Georgia Tech, Stanford, and many others are investing millions of dollars in MOOC initiatives and start-ups. Investing in what has been called "the single biggest change in education since the printing press.".},
  keywords = {eLearning, education, open online courses},
  booktitle = {Workshop on Open Source and Design of Communication},
  isbn = {978-1-4503-1525-8},
  location = {Lisboa, #Portugal#},
  publisher = {ACM},
  year = {2012}
}

@BOOK{Meira-etal:2002,
  title = {Sistemas de comércio eletrônico: projeto e desenvolvimento},
  publisher = {Campus-Elsevier},
  year = {2002},
  author = {Meira Jr., Wagner and Cristina Duarte Murta and Sérgio Vale Aguiar Campos and Guedes Neto, Dorgival Olavo},
  isbn = {85-352-1012-1},
  pages = {371},
  series = {Campus -- SBC},
  address = {Rio de Janeiro, RJ, } # Brazil,
  edition = {1}
}

@TECHREPORT{Meiszner:2011,
  author = {Andreas Meiszner},
  title = {The Why and How of Open Education -- With lessons from the {openSE} and {openED} projects},
  institution = {United Nations University (UNU-MERIT)},
  month = oct,
  year = {2011},
  address = Netherlands,
  note = {Version 1.5},
  pages = {107}
}

@ARTICLE{Mellor-etal:2003,
  author = {Stephen J. Mellor and Anthony N. Clark and Takao Futagami},
  title = {Model-Driven Development},
  volume = {20},
  number = {5},
  month = sep # {-} # oct,
  year = {2003},
  pages = {14-18},
  doi = {10.1109/MS.2003.1231145},
  issn = {0740-7459},
  journal = {IEEE Software},
  publisher = {IEEE Computer Society}
}

@INPROCEEDINGS{melnik:2007,
  author = {Grigori Melnik},
  title = {Using Game Videos to Provoke Reflection on Testing Practice},
  address = {Melbourne, FL},
  booktitle = {6th Annual Workshop on Teaching Software Testing},
  timestamp = {2008.07.31},
  year = {2007}
}

@MISC{project:kerneljanitor,
  author = {Arnaldo Carvalho de Melo and Dave Jones and Jeff Garzik and Randy Dunlap and Maximilian Attems and Domen Puncer},
  title = {Kernel Janitor},
  howpublished = {Projeto},
  year = {2002},
  owner = {magsilva},
  timestamp = {2006.09.01},
  url = {http://janitor.kernelnewbies.org/}
}

@BOOK{melton:1995,
  title = {Software Measurement},
  publisher = {International Thomson Computer Press},
  year = {1995},
  author = {Austin Melton and others},
  editor = {Austin Melton},
  pages = {244},
  address = {UK},
  edition = {1},
  owner = {magsilva},
  timestamp = {2010.08.25}
}

@BOOK{Melton-Simon:2002,
  title = {{SQL:1999}: Understanding Relational Language Components},
  publisher = {Morgan Kaufmann},
  year = {2002},
  author = {Jim Melton and Alan R. Simon},
  isbn = {1-55860-456-1},
  pages = {895},
  series = {The Morgan Kaufmann Series in Data Management Systems},
  address = {San Francisco, CA, } # USA,
  edition = {1},
  booktitle = {{SQL:1999}: Understanding Relational Language Components}
}

@INPROCEEDINGS{menasce:1998,
  author = {D. A. Menascé},
  title = {Educational Challenges and Opportunities in the Web Era},
  pages = {433--444},
  address = {Belo Horizonte, MG},
  booktitle = {VI Workshop sobre Educação em Informática (WEI 1998)},
  month = aug,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1998}
}

@ARTICLE{mendes02asd,
  author = {A. Mendes},
  title = {Arquitetura de Software, Desenvolvimento orientado para arquitetura},
  year = {2002},
  journal = {Campus},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@ARTICLE{Mendes-etal:2007,
  author = {Luciano L. Mendes and José Marcos C. Brito and Fabbryccio A. Cardoso and Dayan A. Guimarães and Gustavo C. Lima and Geraldo G. R. Gomes and Dalton S. Arantes and Richard D. Souza},
  title = {{MI-SBTVD}: a proposal for the Brazilian digital television system SBTVD},
  volume = {12},
  number = {4},
  month = mar,
  year = {2007},
  doi = {10.1590/S0104-65002007000100007},
  abstract = {The objective of this paper is to present a general overview of the Innovative Modulation System Project -MI-SBTVD - developed for the Brazilian Digital TV System. The MI-SBTVD Project includes an LDPC high performance error correcting code, an advanced transmit spatial diversity and an efficient multi-carrier modulation scheme. The building blocks of the system, its characteristics and most relevant innovations are presented. The performance of the whole system under different channels is compared with the performance of the present-day Digital Television standards. The complete system was implemented in FPGA using VHDL language and rapid prototyping tools for DSP algorithms.},
  keywords = {Digital Television, LDPC Channel Coding, OFDM Modulation, Spatial Diversity, SBTVD},
  address = {Campinas, SP, Brazil},
  journal = {Journal of the Brazilian Computer Society},
  publisher = {SBC},
  timestamp = {2012.02.07}
}

@ARTICLE{Mendes-Abran:2004,
  author = {O. Mendes and A. Abran},
  title = {Software Engineering Ontology: A Development Methodology},
  volume = {9},
  year = {2004},
  pages = {68--76},
  journal = {Metrics News},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{Menezes-etal:2009,
  author = {Menezes, Guilherme Vale and Ziviani, Nivio and Laender, Alberto H. F. and Almeida, Virgílio},
  title = {A geographical analysis of knowledge production in computer science},
  pages = {1041--1050},
  doi = {10.1145/1526709.1526849},
  abstract = {We analyze knowledge production in Computer Science by means of coauthorship networks. For this, we consider 30 graduate programs of different regions of the world, being 8 programs in Brazil, 16 in North America (3 in Canada and 13 in the United States), and 6 in Europe (2 in France, 1 in Switzerland and 3 in the United Kingdom). We use a dataset that consists of 176,537 authors and 352,766 publication entries distributed among 2,176 publication venues. The results obtained for different metrics of collaboration social networks indicate the process of knowledge creation has changed differently for each region. Research is increasingly done in teams across different fields of Computer Science. The size of the giant component indicates the existence of isolated collaboration groups in the European network, contrasting to the degree of connectivity found in the Brazilian and North-American counterparts. We also analyzed the temporal evolution of the social networks representing the three regions. The number of authors per paper experienced an increase in a time span of 12 years. We observe that the number of collaborations between authors grows faster than the number of authors, benefiting from the existing network structure. The temporal evolution shows differences between well-established fields, such as Databases and Computer Architecture, and emerging fields, like Bioinformatics and Geoinformatics. The patterns of collaboration analyzed in this paper contribute to an overall understanding of Computer Science research in different geographical regions that could not be achieved without the use of complex networks and a large publication database.},
  keywords = {coauthorship networks, collaboration social networks, computer science},
  series = {WWW '09},
  acmid = {1526849},
  address = {New York, NY, USA},
  booktitle = {International Conference on World Wide Web},
  isbn = {978-1-60558-487-4},
  location = {Madrid, Spain},
  numpages = {10},
  publisher = {ACM},
  year = {2009}
}

@BOOK{Menezes,
  title = {Linguagens Formais e Autômatos},
  publisher = {Editora Sagra-Luzzatto},
  year = {1998},
  author = {Paulo Blauth Menezes},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@MASTERSTHESIS{magalhaes:1997,
  author = {Mônica Giacomassi de Menezes de Magalhães},
  title = {Estudo e avaliação de Educação à Distância utilizando a tecnologia WWW},
  school = {Instituto de Física de São Carlos - Universidade de São Paulo},
  year = {1997},
  address = {São Carlos, SP},
  note = {Orientada por Dietrich Schiel},
  timestamp = {2008.09.15}
}

@INPROCEEDINGS{Merialdo-etal:1999,
  author = {B. Merialdo and K. T. Lee and D. Luparello},
  title = {Automatic Construction of Personalized TV News Programs},
  pages = {323--331},
  booktitle = {ACM International Conference on Multimedia},
  location = {Orlando, FL, #USA#},
  publisher = {ACM},
  year = {1999}
}

@ARTICLE{Merrienboer-etal:2002,
  author = {Merriënboer, Jeroen van and Clark, Richard and Croock, Marcel de},
  title = {Blueprints for complex learning: The 4C/ID-model},
  volume = {50},
  number = {2},
  year = {2002},
  pages = {39--61},
  doi = {10.1007/BF02504993},
  abstract = {This article provides an overview description of the four-component instructional design system (4C/ID-model) developed originally by van Merriënboer and others in the early 1990s for the design of training programs for complex skills. It discusses the structure of training blueprints for complex learning and associated instructional methods. The basic claim is that four interrelated components are essential in blueprints for complex learning: (a) learning tasks, (b) supportive information, (c) just-in-time (JIT) information, and (d) part-task practice. Instructional methods for each component are coupled to the basic learning processes involved in complex learning and a fully worked-out example of a training blueprint for 'searching for literature' is provided. Readers who benefit from a structured advance organizer should consider reading the appendix at the end of this article before reading the entire article.},
  address = {Boston, } # USA,
  affiliation = {Educational Technology Expertise Center (OTEC), Open University of the Netherlands, P.O. Box 2960, NL-6401 DL Heerlen, The Netherlands},
  issn = {1042-1629},
  issue = {2},
  journal = {Educational Technology Research and Development},
  keyword = {Humanities, Social Sciences and Law},
  note = {10.1007/BF02504993},
  publisher = {Springer}
}

@INBOOK{Meszaros-Doble:1997,
  chapter = {A pattern language for pattern writing},
  pages = {529-574},
  title = {Pattern languages fof program design 3},
  publisher = {Addison-Wesley Longman Publishing},
  year = {1997},
  author = {Gerard Meszaros and Jim Doble},
  owner = {magsilva},
  timestamp = {2007.11.22}
}

@INPROCEEDINGS{Meyer-etal:1987,
  author = {Meyer, Bertrand and Nerson, Jean-Marc and Matsuo, Masanobu},
  title = {{EIFFEL}: Object-Oriented Design for Software Engineering},
  pages = {221--229},
  address = {London, UK, UK},
  booktitle = {1st European Software Engineering Conference},
  isbn = {3-540-18712-X},
  publisher = {Springer-Verlag},
  year = {1987}
}

@ARTICLE{Meyer-etal:2011,
  author = {Meyer, Marek and Rensing, Christoph and Steinmetz, Ralf},
  title = {Multigranularity reuse of learning resources},
  volume = {7},
  number = {1},
  month = jan,
  year = {2011},
  pages = {1--23},
  doi = {10.1145/1870121.1870122},
  abstract = {This article investigates a scenario of reuse in which existing learning resources serve as preliminary products for the creation of new learning resources. Authors should be able to reuse learning resources and also parts of them at different levels of granularity in a modular way. The requirements of multigranularity reuse are analyzed and compared to existing solutions. A concept for modular, multigranularity reuse is presented in this article. It is also shown how this kind of reuse can be achieved in practise.},
  keywords = {Reuse, e-learning, granularity, learning resources, reusability},
  acmid = {1870122},
  address = {New York, NY, EUA},
  articleno = {1},
  issn = {1551-6857},
  journal = {ACM Transactions on Multimedia Computing, Communications, and Applications (TOMCCAP)},
  lang = {en},
  numpages = {23},
  publisher = {ACM}
}

@BOOK{Meyers99ECCD,
  title = {Effective {C}++ {CD}: 85 Specific Ways to Improve Your Programs and Designs},
  publisher = {Addison-Wesley},
  year = {1999},
  author = {S. Meyers},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{Mian-etal:2005,
  author = {Paula Mian and Tayana Conte and Ana Natali and Jorge Biolchini and Guilherme Travassos},
  title = {A Systematic Review Process for Software Engineering},
  pages = {1-6},
  volume = {1},
  series = {Workshop Series on Empirical Software Engineering},
  address = {Kaiserslautern, Germany},
  booktitle = {Software Engineering Latin American Workshop (ESELAW)},
  note = {Workshop help in Brazil},
  owner = {magsilva},
  timestamp = {2007.11.12},
  year = {2005}
}

@INPROCEEDINGS{mian-falbo:2002,
  author = {P. G. Mian and R. A. Falbo},
  title = {Supporting Ontology Development with {ODEd}},
  pages = {1-11},
  address = {Salvador, BA},
  booktitle = {Ibero-American Symposium on Software Engineering and Knowledge Engineering},
  month = oct,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {2002}
}

@TECHREPORT{Michael97ODAS,
  author = {C. Michael and G. McGraw},
  title = {Opportunism and Diversity in Automated Software Test Data Generation},
  institution = {RST Corporation},
  month = dec,
  year = {1997},
  number = {RSTR-003-97-13},
  address = {Sterling, VA},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@ARTICLE{Michener:1978,
  author = {Edwina Rissland Michener},
  title = {Understanding Understanding Mathematics},
  volume = {2},
  number = {4},
  month = jan,
  year = {1978},
  pages = {361-383},
  doi = {10.1207/s15516709cog0204_3},
  abstract = {In this paper we look at some of the ingredients and processes involved in the understanding of mathematics. We analyze elements of mathematical knowledge, organize them in a coherent way and take note of certain classes of items that share noteworthy roles in understanding. We thus build a conceptual framework in which to talk about mathematical knowledge. We then use this representation to describe the acquisition of understanding. We also report on classroom experience with these ideas.},
  journal = {Cognitive Science},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@MISC{software:ie,
  author = {{Microsoft Corporation}},
  title = {Internet Explorer},
  howpublished = software,
  month = aug,
  year = {1995},
  url = {http://www.microsoft.com/windows/internet-explorer/}
}

@MISC{software:javaee,
  author = {Sun Microsystems},
  title = {Java 2 Plataform, Enterprise Edition 1.3 Specification},
  howpublished = {Especificação},
  month = sep,
  year = {2001},
  owner = {magsilva},
  timestamp = {2006.06.19}
}

@MISC{software:java,
  author = {Sun Microsystems},
  title = {Java},
  howpublished = {Programa de computador},
  month = may,
  year = {1995},
  owner = {magsilva},
  timestamp = {2006.06.18}
}

@MISC{software:javadoc,
  author = {Sun Microsystems},
  title = {Javadoc},
  howpublished = {Programa de computador},
  year = {1995},
  owner = {magsilva},
  timestamp = {2006.11.07},
  url = {http://java.sun.com/j2se/javadoc/}
}

@INCOLLECTION{Mikk:2002,
  author = {Jann Mikk},
  title = {Experimental Evaluation of Textbooks and Multimedia},
  booktitle = {New Educational Media and Textbooks: the 2nd IARTEM Volume},
  publisher = {Stockholm Institute of Education Press},
  year = {2002},
  editor = {Staffan Selander and Marita Tholey and Svein Lorentzen},
  volume = {9},
  pages = {121-140},
  abstract = {This paper begins by providing an overview of three types of textbook research methods: asking teachers, parents, or students about the different aspects of textbook quality; textbook analysis, i.e. counting some characteristics of a textbook using strictly fixed rules; and the experimental evaluation of textbooks, usually carried out in schools. Determining the appropriateness of a textbook for Estonian students is discussed, including three issues: which students should take part in the experiment; which tasks should be composed to the content of the textbook; and which level of correct answers is the optimal one. An experimental comparison of the quality of two Estonian textbooks (a textbook of physics for grade 7 and a textbook of anatomy for grade 8) is then presented, based on indices of the efficiency of the textbooks. The problem of equalizing the condition of using the two textbooks is discussed. Summary results present findings for four indicators of efficiency-comprehension, acquisition, information gain, and persistence of knowledge. Unexpected results of the experimental research are described, including the validity of some text characteristics in predicting reading outcomes.},
  timestamp = {2012.01.25},
  url = {http://www.eric.ed.gov/PDFS/ED472706.pdf}
}

@INPROCEEDINGS{millard:2000:1,
  author = {David Millard and Hugh Davis and Lue Morean},
  title = {Standardizing Hypertext: Where Next for {OHP}?},
  booktitle = {6th International Workshop on Open Hypermedia Systems},
  owner = {Marco Aurélio Graciotto Silva},
  timestamp = {2008.07.30},
  year = {2000}
}

@ARTICLE{millard:2000:2,
  author = {David Millard and Hugh Davis and Lue Morean},
  title = {Standardizing Hypertext: Where Next for {OHP}?},
  volume = {1903},
  month = may,
  year = {2000},
  pages = {3 - 12},
  booktitle = {6th International Workshop on Open Hypermedia Systems},
  journal = {Lecture Notes on Computer Science},
  owner = {Marco Aurélio Graciotto Silva},
  publisher = {Springer-Verlog},
  timestamp = {2008.07.30}
}

@ARTICLE{Miller:2000,
  author = {James Miller},
  title = {Applying meta-analytical procedures to software engineering experiments},
  volume = {54},
  number = {1},
  month = sep,
  year = {2000},
  pages = {29--39},
  doi = {10.1016/S0164-1212(00)00024-8},
  abstract = {Deriving reliable empirical results from a single experiment is an unlikely event. Hence to progress multiple experiments must be undertaken per hypothesis and the subsequent results effectively combined to produce a single reliable conclusion. Since results are quantitative in nature, a quantitative conclusion would be the optimal solution. Other disciplines use meta-analytic techniques to achieve this result. The treatise of this paper is: can meta-analysis be successfully applied to current software engineering experiments? The question is investigated by examining a series of experiments, which themselves to investigate - which defect-detection technique is best? Applying meta-analysis techniques to the software engineering data is relatively straightforward, but unfortunately the results are highly unstable, as the meta-analysis shows that the results are highly disparate and do not lead to a single reliable conclusion. The reason for this deficiency is the excessive variation within various components of the experiments. The paper outlines various ideas from other disciplines for controlling this variation and describes a number of recommendations for controlling and reporting empirical work to advance the discipline towards a position, where meta-analysis can be profitably employed.},
  acmid = {358525},
  address = {New York, NY, USA},
  issn = {0164-1212},
  issue = {1},
  journal = {Journal of Systems and Software},
  numpages = {11},
  publisher = {Elsevier Science Inc.}
}

@MISC{software:myst,
  author = {Robyn Miller and Rand Miller},
  title = {Myst},
  howpublished = {Programa de Computador},
  year = {1993},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://www.myst.com/myst_home.html}
}

@INPROCEEDINGS{minovic-etal:2009,
  author = {Minovic, Miroslav and Milovanovic, Milo\v{s} and Jovanovic, Mladjan and Star\v{c}evic, Du\v{s}an},
  title = {Model driven development of user interfaces for educational games},
  pages = {608--614},
  abstract = {The main topic of this paper is the problem of developing user interfaces for educational games. Focus of educational games is usually on the knowledge while it should be evenly distributed to the user interface as well. Our proposed solution is based on the model-driven approach, thus we created a framework that incorporates meta-models, models, transformations and software tools. We demonstrated practical application of the mentioned framework by developing user interface for educational adventure game.},
  keywords = {entertainment and gaming, humancentered design, learning and adaptive systems},
  series = {HSI'09},
  acmid = {1689464},
  address = {Piscataway, NJ, USA},
  booktitle = {Proceedings of the 2nd conference on Human System Interactions},
  isbn = {978-1-4244-3959-1},
  location = {Catania, Italy},
  numpages = {7},
  publisher = {IEEE Press},
  url = {http://portal.acm.org/citation.cfm?id=1689359.1689464},
  year = {2009}
}

@ARTICLE{minovic-etal:2010,
  author = {Minovic, Miroslav and Milovanovic, Milos and Starcevic, Dusan and Jovanovic, Mladan},
  title = {Learning objects in educational games},
  volume = {2},
  number = {4},
  month = oct,
  year = {2010},
  pages = {336--346},
  doi = {10.1504/IJTEL.2010.035736},
  abstract = {In this paper we will focus on the problem of using learning objects (LO) in educational games. The purpose of this paper is to propose a model that will attempt to establish the balance between knowledge integration into game on one side, and its reusability on the other. Our model driven approach is relying on use of LOs as constructing pieces of knowledge resources which are specialised for educational game design purpose. Presented models contribute to methodology of educational games development in a way that they embrace principles of learning and knowledge management early in design process. We demonstrated applicability of our models in design case study, where we developed an educational game editor where educators can easily define new educational game utilising existing knowledge, assessment and multimedia from repository.},
  keywords = {KM, MDA, assessments, educational games, educators, game design, game editors, knowledge integration, knowledge management, knowledge resources, learning objects, model\&\#45;driven architecture, multimedia, repositories, reusability, technology enhanced learning},
  address = {Inderscience Publishers, Geneva, SWITZERLAND},
  issn = {1753-5255},
  journal = {International Journal of Technology Enhanced Learning},
  publisher = {Inderscience Publishers}
}

@INPROCEEDINGS{Miotto:2001,
  author = {Aline Maria Malachini Miotto},
  title = {Um Modelo Formal para Aplicações em Sistemas Hipermídia Abertos: Características Específicas},
  pages = {104},
  address = {Mérida, Venezuela},
  annote = {CLEI'2001},
  booktitle = {XXVII Conferencia Latinoamericana de Informatica},
  editor = {Jonás Montilva C. and Isabel Besembel C.},
  month = sep,
  owner = {magsilva},
  timestamp = {2008.07.30},
  year = {2001}
}

@MASTERSTHESIS{Miotto:2001:MSC,
  author = {Aline Maria Malachini Miotto},
  title = {Especificação de um modelo formal para aplicações em sistemas hipermídias abertos},
  abstract = {Uma tendência no projeto de sistemas hipermídia é o desenvolvimento de sistemas que sejam abertos, extensíveis e distribuídos entre diferentes usuários. Na última década vários sistemas hipermídia abertos foram apresentados na literatura. Nesse contexto, técnicas formais consistem de ferramentas muito úteis para especificação de aplicações hipermídia (e por conseguinte, de aplicações em sistemas hipermídia abertos) por possibilitar que determinada solução especificada seja precisa, não ambígua, independente de sua implementação e reutilizável. Além disso, modelos formais adequados podem oferecer abordagens sistemáticas e confiáveis para a análise e verificação de propriedades estruturais dinâmicas dessas aplicações. Este projeto de mestrado tem como objetivo verificar a adequação do modelo formal XHMBS (eXtensible Hypertext Model Based on Statecharts) em relação à especificação de aplicações em sistemas hipermídia abertos e propor extensões a esse modelo para permitir a especificação de tais aplicações.},
  school = {Universidade de São Paulo},
  year = {2001},
  address = {São Carlos, SC, Brazil},
  month = oct,
  lang = {pt}
}

@INPROCEEDINGS{miotto:2001:2,
  author = {A. M. M. Miotto and R. P. M. Fortes},
  title = {Extending XHMBS for supporting Open Hyperdocuments},
  pages = {2-14},
  address = {Rio de Janeiro, RJ},
  booktitle = {IV Workshop de Métodos Formais},
  month = oct,
  note = {in conjunction with the XV Brazilian Symposium on Software Engineering (SBES'2001)},
  owner = {magsilva},
  timestamp = {2008.07.30},
  year = {2001}
}

@INPROCEEDINGS{Miranda-etal:2011,
  author = {Miranda, Leonardo and Hornung, Heiko and Baranauskas, M.},
  title = {Adjustable Interactive Rings for {iDTV}: First Results of an Experiment with End-Users},
  pages = {262--271},
  abstract = {Based on previous results of our research in the field of physical artifacts for interaction with Interactive Digital Television (iDTV) we developed a new digital device we named Adjustable Interactive Rings (AIRs). This work presents a quantitative analysis of an experiment conducted with twelve end-users in order to investigate the interaction of users with the hardware prototype of AIRs for iDTV. The experiment results presented in this paper indicate a positive acceptance of our solution and a good learning curve with respect to the interaction language of this physical artifact of interaction.},
  keywords = {interactive digital television; interaction design; user experiment; quantitative analysis; gesture-based interaction; human-computer interaction},
  volume = {6776},
  series = {Lecture Notes in Computer Science},
  booktitle = {2nd International Conference on Human Centered Design},
  editor = {Kurosu, Masaaki},
  isbn = {978-3-642-21752-4},
  keyword = {Computer Science},
  location = {Orlando, FL, #USA#},
  month = jul,
  publisher = {Springer},
  year = {2011}
}

@ARTICLE{Miranda-Morais:2008,
  author = {L. Miranda and C. Morais},
  title = {Estilos de aprendizagem: o questionário CHAEA adaptado para língua portuguesa},
  volume = {1},
  number = {1},
  month = abr,
  year = {2008},
  pages = {66--87},
  journal = {Revista de estilos de aprendizagem (Learning Style Review)}
}

@INPROCEEDINGS{Miranda-etal:2008,
  author = {Miranda, Leonardo Cunha de and Piccolo, Lara Schibelsky G. and Baranauskas, M. Cecília C.},
  title = {Artefatos f\ísicos de intera\ç\ão com a TVDI: desafios e diretrizes para o cen\ário brasileiro},
  pages = {60--69},
  abstract = {The existence of digital artifacts commonly used to interact with current television system does not guarantee that those devices are adequate to the developments with iDTV, where new types of applications should be offered. The coexistence of an increasing number of facilities that make use of the remote control could result in more complex interfaces limiting its popularization. This article presents the challenges arising from the design and insertion of new digital devices for interaction of users with iDTV in Brazil. In addition it presents guidelines that could conduct to the design of new digital device for use with the television in future works.},
  keywords = {TV digital interativa, análise semiótica, artefatos digitais, design da interação, interação humano-computador},
  address = {Porto Alegre, Brazil, Brazil},
  booktitle = {VIII Brazilian Symposium on Human Factors in Computing Systems},
  isbn = {978-85-7669-203-4},
  location = {Porto Alegre, RS, Brazil},
  publisher = {SBC},
  url = {http://dl.acm.org/citation.cfm?id=1497470.1497478},
  year = {2008}
}

@INPROCEEDINGS{mirlacher-etal:2010,
  author = {Mirlacher, Thomas and Pirker, Michael and Bernhaupt, Regina and Fischer, Thomas and Schwaiger, Daniel and Wilfinger, David and Tscheligi, Manfred},
  title = {Interactive simplicity for iTV: minimizing keys for navigating content},
  pages = {137--140},
  doi = {10.1145/1809777.1809806},
  abstract = {Based on extensive research on users' needs, three simplistic interaction concepts for interactive TV are proposed, developing physical and graphical interface together. This paper describes the development of a user interface by comparing three interface designs, which aim to simplify the interaction and minimize the number of keys on a remote control. With the goal to improve the usability of the interaction concept for various kinds of iTV services, the user interface design concept with a six key remote control has shown to be the best solution in terms of usability and ease of learning, compared to navigation systems using less keys. The concept also shows its advantage in allowing cross-media usage of the navigation concept even on PCs and mobile devices.},
  keywords = {iTV, interaction concept, living room, remote control},
  address = {New York, NY, USA},
  booktitle = {8th international interactive conference on Interactive TV\&\#38;Video},
  isbn = {978-1-60558-831-5},
  location = {Tampere, Finland},
  publisher = {ACM},
  year = {2010}
}

@MISC{project:OpenCourseWare:MIT,
  author = {{MIT} and Hewlett Foundation},
  title = {{OpenCourseWare}},
  howpublished = project,
  month = oct,
  year = {2002},
  url = {http://ocw.mit.edu/}
}

@BOOK{Mitchell97MLEA,
  title = {Machine Learning},
  publisher = {McGraw-Hill},
  year = {1997},
  author = {T. Mitchell},
  address = {New York, NY},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@MISC{soap-0:2003,
  author = {Nilo Mitra},
  title = {SOAP Version 1.2 Part 0: Primer},
  howpublished = {W3C Recommendation},
  month = jun,
  year = {2003},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://www.w3.org/TR/soap12-part0/}
}

@INPROCEEDINGS{Miyauchi-etal:2008,
  author = {Miyauchi, Koji and Sugahara, Taro and Oda, Hiromi},
  title = {Relax or Study?: A Qualitative User Study on the Usage of Mobile TV and Video},
  pages = {128-132},
  doi = {10.1007/978-3-540-69478-6_16},
  abstract = {The usage of mobile TV and video devices is now spreading in Japan as well as in other countries. We conducted a user study to know when, how and why people were using the devices through qualitative interviews. In this paper, we showed one of the findings from this user study, that is, different attitudes concerning the usage of live mobile TV compared with that of mobile video on commuter buses or trains.},
  volume = {5066},
  series = {Lecture Notes in Computer Science},
  address = {Salzburg, Áustria},
  affiliation = {Hewlett-Packard Japan, Ltd. Tokyo Japan},
  booktitle = {European Conference on Interactive Television},
  editor = {Tscheligi, Manfred and Obrist, Marianna and Lugmayr, Artur},
  isbn = {978-3-540-69477-9},
  keyword = {Computer Science},
  location = {Salzburg, Áustria},
  month = jul,
  publisher = {Springer Berlin / Heidelberg},
  year = {2008}
}

@INPROCEEDINGS{mohan-greer:2003,
  author = {Permanand Mohan and Jim Greer},
  title = {Reusable Learning Objects: Current Status and Future Directions},
  pages = { 257--264 },
  address = { Honolulu, Hawaii, USA },
  booktitle = {Proceedings of World Conference on Educational Multimedia, Hypermedia and Telecommunications 2003},
  editor = { David Lassner and Carmel McNaught },
  publisher = { AACE },
  url = { http://go.editlib.org/p/13757 },
  year = {2003}
}

@INPROCEEDINGS{Moissinac-Concolato:2010,
  author = {Moissinac, Jean-Claude and Concolato, Cyril},
  title = {A Model for the Delivery of Interactive Applications over Broadcast Channels},
  pages = {15--19},
  doi = {10.1145/1878022.1878026},
  abstract = {A good way to deliver video and multimedia services to mobile terminals is to broadcast them. But, methods to broadcast interactive applications are very crude. In current broadcasting systems, the available bandwidth for interactive applications is and will remain heavily constrained by the associated video and audio streams. To overcome these constraints, traditional techniques rely on carrousels to deliver the application in fragments, with some implied latency. The application starts when the base fragments have been received and the whole application is available when all the fragments have been delivered. It is crucial for broadcasters to control how an application is fragmented. Such fragmentation is in general made by hand, specifically for each application and differently for each broadcast technology. In this paper, we analyzed some typical interactive applications and derive a model, close to the application level, that can drive the broadcasting of the application independently from the type of application and from the broadcast technology. We also present a piece of software developed based on this model that validates the concepts on some applications.},
  keywords = {broadcast, carousel, interactive applications, interactive tv, multimedia systems},
  series = {MoViD},
  address = {New York, NY, USA},
  booktitle = {3rd Workshop on Mobile Video Delivery},
  isbn = {978-1-4503-0165-7},
  lang = {en},
  location = {Firenze, #Italy#},
  month = oct,
  publisher = {ACM},
  year = {2010}
}

@ARTICLE{Molich-etal:2010,
  author = {Molich, Rolf and Chattratichart, Jarinee and Hinkle, Veronica and Jensen, Janne Jul and Kirakowski, Jurek and Sauro, Jeff and Sharon, Tomer and Traynor, Brian},
  title = {Rent a Car in Just 0, 60, 240 or 1,217 Seconds? - Comparative Usability Measurement, CUE-8},
  volume = {6},
  number = {1},
  month = nov,
  year = {2010},
  pages = {8--24},
  abstract = {This paper reports on the approach and results of CUE-8, the eighth in a series of Comparative Usability Evaluation studies. Fifteen experienced professional usability teams simultaneously and independently measured a baseline for the usability of the car rental website Budget.com. The CUE-8 study documented a wide difference in measurement approaches. Teams that used similar approaches often reached similar results. This paper discusses a number of common pitfalls in usability measurements. This paper also points out a number of fundamental problems in unmoderated measurement studies, which were used by 6 of the 15 participating teams.},
  keywords = {SUS, comparative usability evaluation, time-on-task, unattended evaluations, unmoderated studies, usability measurement, user satisfaction},
  url = {http://dl.acm.org/citation.cfm?id=2016899.2016901},
  address = {Bloomingdale, IL, USA},
  issn = {1931-3357},
  journal = {Journal of Usability Studies},
  publisher = {Usability Professionals' Association}
}

@INPROCEEDINGS{Molina-etal:2008a,
  author = {Molina, Ana I. and Giraldo, William J. and Jurado, Francisco and Redondo, Miguel A. and Ortega, Manuel},
  title = {Model-Based Evolution of an E-Learning Environment Based on Desktop Computer to Mobile Computing},
  pages = {322--334},
  doi = {10.1007/978-3-540-69848-7_26},
  abstract = {In the last years a great amount of collaborative applications have been developed. Advances in wireless technology and its integration on mobile devices offer support to user-to-user interaction on the move, becoming any place a potential collaborative scenario. With the aim of obtaining an appropiate support for the development of multi-plataform groupware applications we propose use a model-based approach for the development of interactive groupware applications (CIAM). This approach can be used for supporting the evolution of existing systems based on desktop metaphor towards mobile support. In this paper we show the application of this method to a case study, the teaching of Domotics. We will take as a starting point a collaborative e-learning environment called "Domosim-TPC".},
  keywords = {Computer Supported Collaborative Learning, Graphical User Interfaces evolution process, Methodological framework, Mobile computing, Model-Based Design},
  series = {ICCSA '08},
  acmid = {1425377},
  address = {Berlin, Heidelberg},
  booktitle = {International Conference on Computational Science and Its Applications},
  isbn = {978-3-540-69840-1},
  location = {Perugia, Italy},
  numpages = {13},
  owner = {magsilva},
  publisher = {Springer-Verlag},
  year = {2008}
}

@INPROCEEDINGS{Molina-etal:2009,
  author = {Molina, Ana Isabel and Jurado, Francisco and Cruz, Ignacio de la and Redondo, Miguel Angel and Ortega, Manuel},
  title = {Tools to support the design, execution and visualization of instructional designs},
  pages = {232--235},
  doi = {10.1007/978-3-642-04265-2_33},
  abstract = {Describing CSCL scenarios can be performed in a standard way. To do so, Instructional Design or so called Learning Design (LD) can be used for describing CSCL scenarios by mean of a de facto specification known as IMS Learning Design (IMS-LD). A typical teaching/learning scenario based on this specification implies the use of several tools which must interact all together. This paper will show a set of tools that enriches the learning scenarios based on IMS-LD. The tools we are developing allow graphical editing of instructional design, a generic engine and a customizable player.},
  keywords = {collaboration design, computer supported collaborative learning, conceptual models, learning design},
  series = {CDVE'09},
  acmid = {1813016},
  address = {Berlin, Heidelberg},
  booktitle = {International Conference on Cooperative Design, Visualization, and Engineering},
  isbn = {978-3-642-04264-5},
  location = {Luxembourg, Luxembourg},
  numpages = {4},
  owner = {magsilva},
  publisher = {Springer-Verlag},
  year = {2009}
}

@INPROCEEDINGS{Molina-etal:2008b,
  author = {Molina, Ana I. and Jurado, Francisco and Giraldo, William J. and Redondo, Miguel A. and Ortega, Manuel},
  title = {Specifying Scripts and Collaborative Tasks in CSCL Environment Using IMS-LD and CIAN},
  pages = {775--777},
  doi = {10.1109/ICALT.2008.166},
  abstract = {The standardization of eLearning environments and the design of collaboration scripts are two research areas that are acquiring a greater attention within the Computer Supported Collaborative Learning (CSCL) community. We are interested in the suitability of the standard IMS-LD for modeling collaborative learning processes. We propose a reference model and the use of a graphical notation called CIAN as CSCL scripting language. Using these specifications of a high level of abstraction and mappable to a computer-interpretable notation such as IMS-LD, allows hiding the particularities of the standard to instructional designers.},
  keywords = {learning design, methodological approach, model-based design},
  acmid = {1381653},
  address = {Washington, DC, USA},
  booktitle = {International Conference on Advanced Learning Technologies},
  isbn = {978-0-7695-3167-0},
  numpages = {3},
  owner = {magsilva},
  publisher = {IEEE Computer Society},
  url = {http://portal.acm.org/citation.cfm?id=1381300.1381653},
  year = {2008}
}

@INPROCEEDINGS{molina-etal:2006,
  author = {Molina, Ana Isabel and Redondo, Miguel Angel and Ortega, Manuel},
  title = {Using Patterns in Reengineering Processes for Mobile Learning User Interfaces},
  pages = {1065--1069},
  abstract = {In the last years there has been a high production of groupware systems. However, most of these systems have been based on the desktop metaphor. We propose a translation process based on the use of the conceptual model (or, particularly, on the task model and the data model) of the original application. From this model and by means of a pattern-based reengineering process, we obtain mobile versions of the original systems. In this paper the user interface reengineering process is described and an example of the application of patterns for the evolution of a specific system, Domosim-TPC, is shown.},
  series = {ICALT '06},
  acmid = {1156392},
  address = {Washington, DC, USA},
  booktitle = {Proceedings of the Sixth IEEE International Conference on Advanced Learning Technologies},
  isbn = {0-7695-2632-2},
  numpages = {5},
  publisher = {IEEE Computer Society},
  url = {http://portal.acm.org/citation.cfm?id=1156068.1156392},
  year = {2006}
}

@BOOK{Montgomery:2000,
  title = {Design and Analysis of Experiments},
  publisher = {Wiley},
  year = {2000},
  author = {Douglas C. Montgomery},
  pages = {672},
  edition = {5}
}

@INCOLLECTION{Moon-Sproull:2002,
  author = {Jae Yun Moon and Lee Sproull},
  title = {Essence of Distributed Work: The Case of the {Linux Kernel}},
  booktitle = {Distributed Work},
  publisher = {MIT},
  year = {2002},
  chapter = {16},
  pages = {381--404},
  edition = {1},
  abstract = {This chapter provides a historical account from three different perspectives of how the Linux operating system kernel was developed. Each focuses on different critical factors in its success at the individual, group, and community levels. The technical and management decisions of Linus Torvalds were critical in laying the groundwork for a collaborative software development project that has lasted almost a decade. The contributions of volunteer programmers distributed worldwide enabled the development of an operating system on a par with proprietary operating systems. The Linux electronic community was the organizing structure that coordinated the efforts of the individual programmers. The chapter concludes by summarizing the factors important in the successful distributed development of the Linux kernel and the implications for organizationally managed distributed work arrangements.},
  isbn = {9780262256353}
}

@ARTICLE{Moore:1956,
  author = {Edward Forrest Moore},
  title = {Gedanken-experiments on sequential machines},
  volume = {34},
  year = {1956},
  pages = {129--152},
  journal = {Automata Studies, Annals of Mathematical Studies},
  publisher = {Princeton University Press}
}

@INPROCEEDINGS{moore:2001,
  author = {Ivan Moore},
  title = {Jester - a JUnit test tester},
  pages = {84--87},
  address = {Villasimius, Sardinia},
  booktitle = {XP2001},
  owner = {Marco Aurélio},
  timestamp = {2008.11.11},
  url = {http://www.agilealliance.org/show/881},
  year = {2001}
}

@ARTICLE{Moore:1990,
  author = {Michael G. Moore},
  title = {Recent contributions to the theory of distance education},
  volume = {5},
  number = {3},
  year = {1990},
  pages = {10-15},
  isbn = {978-0534506889},
  journal = {Open Learning},
  publisher = {Wadsworth}
}

@ARTICLE{Moore:1989,
  author = {Moore, Michael Graham},
  title = {Three Types of Interaction},
  volume = {3},
  number = {2},
  year = {1989},
  pages = {1--6},
  doi = {10.1080/08923648909526659},
  e-issn = {1538-9286},
  issn = {0892-3647},
  journal = {The American Journal of Distance Education},
  lang = {en},
  publisher = {Routledge}
}

@ARTICLE{Moral-Cernea:2005,
  author = {M. E. del Moral and D. A. Cernea},
  title = {Design and Evaluate Learning Objects in the New Framework of the Semantic Web},
  year = {2005},
  pages = {1-5},
  journal = {Recent Research Developments in Learning Technologies},
  owner = {magsilva},
  timestamp = {2008.09.26}
}

@MISC{moran:2002,
  author = {José Manuel Moran},
  title = {O que é educação a distância},
  howpublished = {Artigo},
  year = {2002},
  owner = {magsilva},
  timestamp = {2008.01.25},
  url = {http://www.eca.usp.br/prof/moran/dist.htm},
  urlaccessdate = {20 fev 2012}
}

@ARTICLE{Morell90TFBT,
  author = {L. J. Morell},
  title = {A Theory of Fault-Based Testing},
  volume = {16},
  number = {8},
  month = aug,
  year = {1990},
  pages = {844--857},
  journal = ieeese,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{moretto-etal:2006,
  author = {Emerson G. Moretto and Markus Reichel and Hemerson Pistori},
  title = {Rastreamento dinâmico de objetos: um experimento didático integrando conceitos de hardware e software},
  address = {Porto Alegre, RS, Brazil},
  booktitle = {Workshop de Software Livre},
  owner = {magsilva},
  review = {A primeira vista, pode parecer estranho um artigo sobre hardware e visão no meio de um monte de artigos sobre engenharia de sofware. E realmente é estranho! Este artigo foi selecionado apenas porque tem a ver com um projeto de longa duração meu, o TaSu. Trata-se de um programa e plataforma para rastreamento visual de objetos. E esse artigo veio bem a calhar! Por enquanto, eu o li apenas superficialmente, mas já anotei coisas importantes. Uma é o CI ULN2003, para enviar a energia dos motores de passo. Na graduação, eu utilizava um circuito não apenas complicado, mas também muito sensível a choques externos e trapalhadas. Substituir toda aquela parafernália por um único chip é perfeito. Outra coisa legal do artigo são as dicas para tratamento de imagens. Não é algo que pretendo mexer por enquanto, mas fica anotado para referência futura (principalmente por ser software livre): ImageJ (http://rsb.info.nih.gov/ij/).},
  timestamp = {2010.03.29},
  year = {2006}
}

@BOOK{Morrison-etal:2010,
  title = {Designing effective instruction},
  publisher = {John Wiley \& Sons},
  year = {2010},
  author = {Gary R. Morrison and Steven M. Ross and Jerrold E. Kemp and Howard Kalman},
  isbn = {0470522828, 978-0470522820},
  pages = {491},
  address = {Hoboken, NJ, EUA},
  edition = {6}
}

@INPROCEEDINGS{Motelet-Baloian:2006,
  author = {Motelet, Olivier and Baloian, Nelson},
  title = {Hybrid System for Generating Learning Object Metadata},
  pages = {563--567},
  abstract = {Generating LOM for learning material is a complex and tedious task to be completed "by hand". Therefore, the current trend is to automate this process. However, there are several important issues restricting this approach. In order to solve these issues, this article presents a hybrid system in which both human and computer collaborate for instantiating LOM attributes. This system is implemented in LessonMapper2, a graphical interface designed to generate LOM-based graphs of learning resources.},
  series = {ICALT '06},
  acmid = {1156362},
  address = {Washington, DC, USA},
  booktitle = {International Conference on Advanced Learning Technologies},
  isbn = {0-7695-2632-2},
  numpages = {5},
  owner = {magsilva},
  publisher = {IEEE Computer Society},
  url = {http://portal.acm.org/citation.cfm?id=1156068.1156362},
  year = {2006}
}

@INPROCEEDINGS{Motelet-Baloian:2004,
  author = {Motelet, Olivier and Baloian, Nelson},
  title = {Introducing Learning Management Systems Standards in Classroom},
  pages = {738--740},
  abstract = {Learning material reuse is a major topic in both distant learning and face-to-face teaching scenarios. This article investigates the portability in the classroom of two standards specifications (LOM and IMS LD) for interoperability of learning material between distant learning management systems. For concealing the divergence between face-to-face and distant learning contexts, we introduce LessonMapper, a teaching visual support enabling on-the-fly adaptation of digital learning material presentation and distribution. We present and discuss a three-layer structure consisting of learning objects, learning material graphs and learning design for LessonMapper to integrate IMS LD and LOM.},
  acmid = {1020102},
  address = {Washington, DC, USA},
  booktitle = {International Conference on Advanced Learning Technologies},
  isbn = {0-7695-2181-9},
  numpages = {3},
  owner = {magsilva},
  publisher = {IEEE Computer Society},
  url = {http://portal.acm.org/citation.cfm?id=1018423.1020102},
  year = {2004}
}

@ARTICLE{Motelet-etal:2009,
  author = {Motelet, Olivier and Baloian, Nelson and Pino, José A.},
  title = {Taking advantage of metadata semantics: the case of learning-object-based lesson graphs},
  volume = {20},
  month = aug,
  year = {2009},
  pages = {323--348},
  doi = {10.1007/s10115-008-0181-z},
  abstract = {Learning objects (LOs) are pieces of educational material characterized with a valuable amount of information about their content and usage. This additional information is defined as a set of metadata generally following the IEEE LOM specification. This specification also serves to characterize the relations existing between LOs. LOs whose relations are explicit are regarded as the nodes of a lesson graph. Link types and LO metadata constitute the lesson graph semantics. This article proposes to take advantage of lesson graph semantics using a context diffusion approach. It consists in diffusing the metadata-based processes along the edges of the lesson graph. This technique aims at coping with the metadata processing issues arising when some graph metadata are missing, incorrect, or incomplete. This article also presents a three-layer extensible framework for easing the use of context diffusion in a graph. As part of the framework, two original types of metadata processes are introduced. The first one takes advantage of the metadata attribute similarities between related LOs. The second one focuses on the lesson graph consistency. The framework and the application examples were implemented as an open-source Java library used in the lesson graph authoring tool LessonMapper2. During the lesson authoring process, we show that the framework can bring support not only for generating and validating metadata, but also for retrieving LOs.},
  keywords = {Learning object metadata, Learning object retrieval, Lesson authoring, Lesson graph, Metadata processing, Metadata propagation},
  acmid = {1611612},
  address = {New York, NY, USA},
  issn = {0219-1377},
  issue = {3},
  journal = {Knowledge and Information Systems},
  numpages = {26},
  owner = {magsilva},
  publisher = {Springer-Verlag}
}

@INPROCEEDINGS{Motelet-etal:2007,
  author = {Motelet, Olivier and Baloian, Nelson and Piwowarski, Benjamin and Pino, José A.},
  title = {Taking advantage of the Semantics of a Lesson Graph based on Learning Objects},
  pages = {459--466},
  abstract = {Lesson graphs are composed of Learning Objects (LOs) and include a valuable amount of information about the content and usage of the LOs, described by the LO metadata. Graphs also make explicit the links between the LOs (i.e. the graph semantics). This article proposes a conceptual model for taking advantage of this information. This model is based on an original diffusion process that copes with the problem of lesson graphs where some metadatas are missing. Two applications of the model are described and were implemented over a previously developed lesson authoring tool whose goal is to facilitate the lesson authoring process.},
  keywords = {Graph Semantics, Learning Object Metadata, Lesson Graph},
  acmid = {1563674},
  address = {Amsterdam, Netherlands},
  booktitle = {Conference on Artificial Intelligence in Education},
  isbn = {978-1-58603-764-2},
  numpages = {8},
  owner = {magsilva},
  publisher = {IOS Press},
  url = {http://portal.acm.org/citation.cfm?id=1563601.1563674},
  year = {2007}
}

@BOOK{mourani:2000,
  title = {Securing and Optimizing Linux: RedHat Edition - A Hands on Guide},
  publisher = {Open Network Architecture},
  year = {2000},
  author = {Gerhard Mourani and Madhu "Maddy"},
  owner = {magsilva},
  timestamp = {2006.07.06},
  url = {http://www.faqs.org/docs/securing/index.html}
}

@MISC{software:tinymce,
  author = {{Moxiecode Systems AB}},
  title = {TinyMCE},
  howpublished = {Programa de Computador},
  year = {2005},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://tinymce.moxiecode.com/}
}

@MISC{software:firefox,
  author = {{Mozilla Foundation}},
  title = {Firefox},
  howpublished = {Programa de computador},
  year = {2004},
  owner = {msilva},
  timestamp = {2006.02.24},
  url = {http://www.mozilla.com/firefox/}
}

@ARTICLE{Mresa99EMOS,
  author = {E.S. Mresa and L. Bottaci},
  title = {Efficiency of Mutation Operators and Selective Mutation Strategies: an Empirical Study},
  volume = {9},
  number = {4},
  month = dec,
  year = {1999},
  pages = {205--232},
  journal = {The Journal of Software Testing, Verification and Reliability},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{Mu:2003:ISE:827140.827190,
  author = {Mu, Xiangming and Marchionini, Gary and Pattee, Amy},
  title = {The interactive shared educational environment: user interface, system architecture and field study},
  pages = {291--300},
  abstract = {The user interface and system architecture of a novel Interactive Shared Educational Environment (ISEE) are presented. Based on a lightweight infrastructure, ISEE enables relatively low bandwidth network users to share videos as well as text messages. Smartlink is a new concept introduced in this paper. Individual information presentation components, like the video player and text chat room, are "smartly" linked together through video timestamps and hyperlinks. A field study related to children book selections using ISEE was conducted. The results indicated that the combination of three information presentation components, including video player with storyboard, shared browser, and text chat room, provided an effective and more comfortable collaboration and learning environment for the given tasks than text reviews or text chat alone or in combination. The video player was the most preferred information component. Text comments in the chat room that did not synchronize with the video content distracted some participants due to limited cognitive capacity. Using smartlink to synchronize various information components or "channels" is our attempt to reduce the user's working memory load in information enriched distance learning environments made possible by digital libraries.},
  series = {JCDL '03},
  acmid = {827190},
  address = {Washington, DC, USA},
  booktitle = {Proceedings of the 3rd ACM/IEEE-CS joint conference on Digital libraries},
  isbn = {0-7695-1939-3},
  location = {Houston, Texas},
  numpages = {10},
  publisher = {IEEE Computer Society},
  url = {http://portal.acm.org/citation.cfm?id=827140.827190},
  year = {2003}
}

@INPROCEEDINGS{MuchaluatSaade-etal:2002,
  author = {Muchaluat-Saade, Débora C. and Rodrigues, Rogério F. and Soares, Luiz Fernando G.},
  title = {XConnector: extending XLink to provide multimedia synchronization},
  pages = {49--56},
  doi = {10.1145/585058.585069},
  abstract = {This paper proposes XConnector, a language for the creation of complex hypermedia relations with causal or constraint semantics. XConnector allows the definition of relations independently of which resources are related. Another feature is the specification of relation libraries, providing reuse in relationship definition. The main goal is to improve linking languages or the linking modules of hypermedia authoring languages in order to provide multimedia synchronization capabilities using links. Following this direction, an extension to W3C XLink is proposed, incorporating XConnector facilities.},
  keywords = {XConnector, XLink, hypermedia connector, links, multimedia synchronization},
  series = {DocEng},
  booktitle = {2002 ACM Symposium on Document Engineering},
  location = {McLean, Virginia, #USA#},
  publisher = {ACM},
  year = {2002}
}

@MISC{software:orca,
  author = {Marc Mulcahy and Willie Walker and Mike Pedersen and Rich Burridge and Joanmarie Diggs},
  title = {Orca},
  howpublished = {Programa de computador},
  month = {jun},
  year = {2004},
  owner = {magsilva},
  timestamp = {2007.08.13},
  url = {http://live.gnome.org/Orca}
}

@INPROCEEDINGS{muller-etal:2010,
  author = {Müller, Jörg and Alt, Florian and Michelis, Daniel and Schmidt, Albrecht},
  title = {Requirements and design space for interactive public displays},
  pages = {1285--1294},
  doi = {10.1145/1873951.1874203},
  abstract = {Digital immersion is moving into public space. Interactive screens and public displays are deployed in urban environments, malls, and shop windows. Inner city areas, airports, train stations and stadiums are experiencing a transformation from traditional to digital displays enabling new forms of multimedia presentation and new user experiences. Imagine a walkway with digital displays that allows a user to immerse herself in her favorite content while moving through public space. In this paper we discuss the fundamentals for creating exciting public displays and multimedia experiences enabling new forms of engagement with digital content. Interaction in public space and with public displays can be categorized in phases, each having specific requirements. Attracting, engaging and motivating the user are central design issues that are addressed in this paper. We provide a comprehensive analysis of the design space explaining mental models and interaction modalities and we conclude a taxonomy for interactive public display from this analysis. Our analysis and the taxonomy are grounded in a large number of research projects, art installations and experience. With our contribution we aim at providing a comprehensive guide for designers and developers of interactive multimedia on public displays.},
  keywords = {design space, interaction, public displays, requirements},
  address = {New York, NY, USA},
  booktitle = {Proceedings of the international conference on Multimedia},
  isbn = {978-1-60558-933-6},
  location = {Firenze, Italy},
  publisher = {ACM},
  year = {2010}
}

@INPROCEEDINGS{Muller-etal:2004,
  author = {Muller, Orna and Haberman, Bruria and Averbuch, Haim},
  title = {(An almost) pedagogical pattern for pattern-based problem-solving instruction},
  pages = {102--106},
  doi = {10.1145/1007996.1008025},
  abstract = {Importing design patterns from software engineering to the computer science education (CSE) field was followed by defining patterns and pattern languages suitable for CS courses. The main goal of incorporating patterns in CSE was to enhance students' programming abilities, as well as their design and problem-solving skills. Accordingly, various instructional materials were suggested for using patterns in classroom learning activities, such as collections of patterns and related programming assignments. However, the existing pattern-based materials seem to be insufficient for implementation in the classroom, especially when teaching introductory courses that emphasize syntax and programming language features. Therefore, alternative methods using applicative models for pattern-based instruction, which emphasize problem solving and program design issues rather than specific language features and syntax, should be developed and assimilated within the CS teaching community. We believe that successful implementation of such models should be accompanied by appropriate teacher-training.In this paper we describe an initial effort to expose CS teachers to the notions of pedagogical patterns and pattern-based instruction, aimed at motivating them to meaningfully adopt and adapt patterns to their concrete pedagogical needs.},
  keywords = {computer science education, teacher training},
  series = {ITiCSE},
  address = {New York, NY, USA},
  booktitle = {9th SIGCSE Conference on Innovation and Technology in Computer Science Education},
  isbn = {1-58113-836-9},
  location = {Leeds, #UK#},
  month = jun,
  publisher = {ACM},
  year = {2004}
}

@BOOK{mulrow-cook:1998,
  title = {Systematic Reviews: Synthesis of Best Evidence for Health Care Decisions},
  publisher = {American College of Physicians},
  year = {1998},
  author = {C. Mulrow and D. Cook},
  url = {http://books.google.com/books?id=rYWIoJXyioIC&lpg=PA122&ots=anHG-1CqjG&dq=%22systematic%20reviews%3A%20synthesis%20of%20best%20evidence%20for%20health%20care%20decisions%22&pg=PA5#v=onepage&q&f=false}
}

@INPROCEEDINGS{munson:1999,
  author = {E. MUNSON},
  title = {The Software Concordance: Bringing Hypermedia to Software Development Environments},
  booktitle = {Anais do Simpósio Brasileiro de Sistemas Multimídia e Hipermídia},
  owner = {magsilva},
  page = {1-12},
  timestamp = {2008.07.30},
  year = {1999}
}

@ARTICLE{Munson:2010:PTN:1842468.1842479,
  author = {Munson, Ethan V. and Pimentel, Maria Da Gra\c{c}a},
  title = {Photos, time, navigation, visualization, recommendation and interactive TV: issues and contributions},
  volume = {50},
  month = {December},
  year = {2010},
  pages = {437--440},
  doi = {10.1007/s11042-010-0482-6},
  abstract = {In this editorial we first present the ACM Symposium on Applied Computing (SAC) and its Multimedia and Visualization (MMV) track. Next, we introduce the papers which were selected from the MMV track at the 2009 edition of SAC to present novel results in extended versions in this special issue.},
  keywords = {Guest editorial},
  acmid = {1842479},
  address = {Hingham, MA, USA},
  issn = {1380-7501},
  issue = {3},
  journal = {Multimedia Tools Appl.},
  numpages = {4},
  publisher = {Kluwer Academic Publishers}
}

@ARTICLE{Murata:1989,
  author = {T. Murata},
  title = {{P}etri Nets: Properties, Analysis and Applications},
  volume = {77},
  number = {4},
  month = apr,
  year = {1989},
  pages = {541--580},
  doi = {10.1109/5.24143},
  abstract = {This is an invited tutorial-review on Petri nets -- a graphical and mathematical modeling tool. Petri nets are a promising tool for describing and studying information processing systems that are characterized as being concurrent, asynchronous, distributed, parallel, nondeterministic, and/or stochastic. The paper starts with a brief review of the history and the application areas considered in the literature. The author then proceeds with introductory modeling examples, behavioral and structural properties, three methods of analysis, subclasses of Petri nets and their analysis. In particular, one section is devoted to marked graphs, the concurrent system model most amenable to analysis. Introductory discussions on stochastic nets with their application to performance modeling, and on high-level nets with their application to logic programming, are provided. Also included are recent results on reachability criteria. Suggestions are provided for further reading on many subject areas of Petri nets.},
  issn = {0018-9219},
  journal = {Proceedings of the IEEE},
  owner = {magsilva},
  publisher = {IEEE},
  timestamp = {2008.07.31}
}

@INBOOK{Murata84MACS,
  title = {Modeling and Analysis of Concurrent Systems},
  publisher = {Van Nostrand Reinhold Electrical},
  year = {1984},
  author = {T. Murata},
  address = {New York},
  booktitle = {Handbook of Software Engineering},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@ARTICLE{Murphy94ECCT,
  author = {G. C. Murphy and P. Townsend and P. S. Wong},
  title = {Experiences with Cluster and Class Testing},
  volume = {37},
  number = {9},
  month = sep,
  year = {1994},
  pages = {39--47},
  journal = comacm,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@ARTICLE{Mussoi-Taruoco:2011,
  author = {Eunice Maria Mussoi and Liane Margarida R. Taruoco},
  title = {Interatividade com Objetos de Aprendizagem},
  volume = {6},
  number = {1},
  year = {2011},
  pages = {297-300},
  abstract = {A interatividade é um importante pressuposto na elaboração de materiais educacionais digitais. O presente artigo é uma revisão bibliográfica e faz parte da construção de um projeto de tese. Assim, é parte integrante do seu referencial teórico. O objetivo do artigo é apresentar os resultados da pesquisa sobre a interatividade com objetos de aprendizagem em computador e na TV Digital Interativa (TVDI), apresentando a contribuição de importantes pesquisadores. Com este estudo, conclui-se também que ao se propor diferentes formas de interatividade com OAs deve-se considerar não apenas o público a que se destina o mesmo, pois as novas gerações de estudantes têm maior afinidade com diferentes níveis de interatividade em OAs, como, também, o meio pelo qual o usuário tem acesso ao OA.},
  keywords = {Interatividade, Objetos de Aprendizagem, Estratégias},
  url = {http://seer.ufrgs.br/cadernosdeinformatica/article/view/v6n1p297-300},
  journal = {Cadernos de Informática (UFRGS)},
  lang = {pt}
}

@ARTICLE{Muzio02EREO,
  author = {J. Muzio and T. Heins and R. Mundell},
  title = {Experiences with Reusable e-Learning Objects: From Theory to Practice},
  volume = {5},
  number = {1},
  month = jan,
  year = {2002},
  pages = {21--34},
  journal = {The Internet and Higher Education},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@BOOK{myers:2004,
  title = {The Art of Software Testing},
  publisher = {John Wiley \& Sons},
  year = {2004},
  author = {Glenford J. Myers},
  edition = {2},
  note = {Revised and updated by Tom Badgett and Todd M. Thomas, with Corey Sandler},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@BOOK{Myers:1979,
  title = {The Art of Software Testing},
  publisher = {John Wiley \& Sons},
  year = {1979},
  author = {Glenford. J. Myers},
  pages = {177},
  abstract = {Provides a practical rather than theoretical discussion of the purpose and nature of software testing. Emphasizes methodologies for the design of effective test cases. Comprehensively covers psychological and economic principles, managerial aspects of testing, test tools, high-order testing, code inspections, and debugging. Extensive bibliography. Programmers at all levels, and programming students, will find this reference work indispensible.},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@ARTICLE{mylopoulos:1999,
  author = {John Mylopoulos and Lawrence Chung and Eric Yu},
  title = {From object-oriented to goal oriented requirements analysis},
  volume = {42},
  number = {1},
  month = {jan},
  year = {1999},
  pages = {31 - 37},
  journal = {Communications of the ACM},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@INPROCEEDINGS{Na-Furuta:2001,
  author = {Na, Jin-Cheon and Furuta, Richard},
  title = {Dynamic documents: authoring, browsing, and analysis using a high-level petri net-based hypermedia system},
  pages = {38--47},
  doi = {10.1145/502187.502194},
  abstract = {caT (for Context-Aware Trellis) was initially developed to support context-aware documents by incorporating high-level Petri-net specification, context-awareness, user modeling, and fuzzy knowledge handling features into Trellis, a Petri-net-based hypermedia system. The browsing behavior of documents specified in the caT model can reflect the reader's contextual (such as location and time) and preference information. Recently, to provide a framework for the authoring, browsing, and analysis of reasonably complex, dynamic documents, we added (or extended) several features in the caT system, providing hierarchical Petri net support, a structured authoring tool, browsing tools for multiple presentations of a particular document's specification, and a Petri net analysis tool. In this paper, we present the extended features of caT and give examples of using caT to define and present various documents, such as formal specification of software requirements and customized Web documents. Since caT is based on a formal model, the behavioral characteristics of developed caT models can be analyzed. Current debugging and analysis tools, integrated into the authoring tool, are also introduced.},
  keywords = {caT, dynamic documents, petri-net-based hypertext, trellis},
  address = {New York, NY, USA},
  booktitle = {ACM Symposium on Document Engineering (DocEng 2001)},
  isbn = {1-58113-432-0},
  location = {Atlanta, Georgia, USA},
  publisher = {ACM},
  year = {2001}
}

@PHDTHESIS{nakagawa:2006,
  author = {Elisa Yumi Nakagawa},
  title = {Uma contribuição ao projeto arquitetural de ambienes de engenharia de software},
  school = {Universidade de São Paulo, Instituto de Ciências Matemáticas e de Computação},
  year = {2006},
  address = {São Carlos, SP},
  month = mar,
  owner = {magsilva},
  timestamp = {2006.11.13}
}

@PHDTHESIS{Nakagawa02SLPP,
  author = {E. Y. Nakagawa},
  title = {Software Livre: Processo e Produto Livres no Desenvolvimento de Aplicações Web},
  school = {ICMC-USP},
  year = {2002},
  address = {São Carlos, SP},
  month = nov,
  note = {(exame de qualificação)},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@MASTERSTHESIS{Nakagawa98SIDS,
  author = {E. Y. Nakagawa},
  title = {Um Sistema de Injeção de Defeitos de Software Baseado em Operadores de Mutação},
  school = {ICMC-USP},
  year = {1998},
  address = {S\~ao Carlos, SP},
  month = may,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{nakagawa-etal:2006,
  author = {Elisa Yumi Nakagawa and Norberto Fukuta Cruz and José Carlso Maldonado},
  title = {Relevância dos Requisitos no Desenvolvimento de Software Livre},
  pages = {171-176},
  address = {Porto Alegre, RS, Brazil},
  booktitle = {Workshop de Software Livre},
  owner = {magsilva},
  review = {O trabalho discute a importância de requisitos em software livres. Não se sabe muito sobre isso, eu mesmo, após pesquisar um bom tanto, ainda não estou convicto quanto à engenharia de requisitos nos projetos de software livre usuais. O que são as características essenciais do processo de engenharia de requisitos em SL? Desenvolvedor como cliente? Código-fonte (protótipo) como requisito? Bom, o trabalho de Nakagawa ataca um outro aspecto, um pouco estudado em software livre, que é o desenvolvimento de um produto original. Isso é estranho a primeira vista. Muitos SLs são ramificações de outros software livres, ou então a composição de diferentes projetos. A proposta de Nakagawa, além de tratar um software original, possui a característica adicional que os usuários do software não são os desenvolvedores. Nesse cenário, considera-se necessária a elicitação dos requisitos, com a utilização de ferramentas adequadas para a gerência. Existem poucas ferramentas livres para isso, nenhuma bem sucedida. Fico pensando, o que será necessária para uma ferramenta de engenharia de requisitos livre lograr sucesso? Não é tarefa fácil. Bom, retomando o trabalho de Nakagawa, a maior crítica é: será que o desenvolvimento de tal aplicação realmente deva seguir o processo de software livre. Digo porque, pelo descrito, não existem características do processo de software livre naquele utilizado por Nakagawa e sua equipe. Talvez, para um software original e que o cliente não seja desenvolvedor, o processo de software livre não seja o mais adequada. Ou talvez até seja tão adequado quanto os outros, mas o fato é que o presente trabalho não oferece condições para analisar a questão que o seu título propõe. Antes de querer falar em ER em SL, é necessário que seja SL. E isso não está evidente.},
  timestamp = {2010.03.29},
  year = {2006}
}

@INPROCEEDINGS{Nakagawa97APII,
  author = {E. Y. Nakagawa and {et al.}},
  title = {Aspectos de Projeto e Implementação de Interfaces Gráficas do Usuário para Ferramentas de Teste},
  pages = {57--67},
  address = {{\'A}guas de Lind{\'o}ia -- SP},
  booktitle = {Workshop do Projeto de Valida\c c\~ao e Teste de Sistemas de Opera\c c\~ao},
  month = jan,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1997}
}

@INPROCEEDINGS{Nakagawa98EIDB,
  author = {E. Y. Nakagawa and J. C. Maldonado},
  title = {Um Esquema de Injeção de Defeitos Baseado em Operadores de Mutação},
  pages = {31--36},
  address = {Porto Alegre, RS},
  booktitle = {I Workshop de Tolerância a Falhas},
  month = may,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1998}
}

@MASTERSTHESIS{Nakazato95MGST,
  author = {K. K. Nakazato},
  title = {M\'{o}dulo de Gera\c{c}\~{a}o de Seq\"{u}\^{e}ncias de Teste Baseada em M\'{a}quinas de Estado Finito},
  school = {ICMC-USP},
  year = {1995},
  address = {S\~ao Carlos, SP},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{napoles:2006,
  author = {Carmen L. Padrón Nápoles},
  title = {MD2 Method: The Didactic Materials Development from a Model Perspective},
  pages = {52-65},
  address = {Crete, Greece},
  month = oct,
  owner = {magsilva},
  timestamp = {2010.08.04},
  year = {2006}
}

@MISC{Nascimento-Morgado:2003,
  author = {A. Nascimento and E. Morgado},
  title = {Um projeto de colaboração internacional na América Latina},
  howpublished = {Projeto de pesquisa},
  year = {2003},
  abstract = {Este artigo descreve o desenvolvimento de módulos de aprendizagem mediados pela Web conduzido na América Latina num projeto de colaboração internacional. A Rede Internacional Virtual de Educacíon (RIVED) é uma iniciativa que utiliza a tecnologia do computador para melhorar o ensino / aprendizagem nas áreas de ciências e matemática do ensino médio. O módulo consiste numa seqüência de atividades pedagógicas em variados formatos, como diagramas, texto, animações, vídeo-clips, simulações, etc. O desenvolvimento dessas atividades baseia-se na abordagem de objetos de aprendizagem, a fim de assegurar flexibilidade, reutilização e escalabilidade. O processo de produção envolve uma série de passos os quais são desempenhados por uma equipe multidisciplinar em cada país participante do projeto. O artigo descreve cada um desses passos, assim como as mudanças e ajustes realizados desde os primeiros produtos.},
  timestamp = {2008.09.28},
  url = {http://www.rived.mec.gov.br/artigos/rived.pdf},
  urlaccessdate = {20 apr 2009}
}

@MONOGRAPH{Nascimento:2011,
  author = {Arthur Filipe Martins Nascimento},
  title = {Integração de dados e manutenção do {Projeto} {Urano}},
  month = jun,
  year = {2011},
  institution = {Universidade de São Paulo},
  address = {São Carlos -- SP},
  pages = {31},
  howpublished = monograph,
  keywords = {bases de dados, integração de dados}
}

@INPROCEEDINGS{Nathan-etal:2008,
  author = {Nathan, Mukesh and Harrison, Chris and Yarosh, Svetlana and Terveen, Loren and Stead, Larry and Amento, Brian},
  title = {{CollaboraTV}: making television viewing social again},
  pages = {85--94},
  doi = {10.1145/1453805.1453824},
  abstract = {With the advent of video-on-demand services and digital video recorders, the way in which we consume media is undergoing a fundamental change. People today are less likely to watch shows at the same time, let alone the same place. As a result, television viewing, which was once a social activity, has been reduced to a passive and isolated experience. To study this issue, we developed a system called CollaboraTV and demonstrated its ability to support the communal viewing experience through a month-long field study. Our study shows that users understand and appreciate the utility of asynchronous interaction, are enthusiastic about CollaboraTV's engaging social communication primitives and value implicit show recommendations from friends. Our results both provide a compelling demonstration of a social television system and raise new challenges for social television communication modalities.},
  keywords = {asynchronous communication, instant messaging, interactive television, social tagging, social television, video},
  series = {UXTV},
  address = {Silicon Valley, California, } # USA,
  booktitle = {1st International Conference on Designing Interactive User Experiences for TV and Video},
  isbn = {978-1-60558-100-2},
  location = {Silicon Valley, California, #USA#},
  publisher = {ACM},
  year = {2008}
}

@BOOK{book:how-people-learn,
  title = {How People Learn: Brain, Mind, Experience, and School},
  publisher = {National Academic Press},
  year = {2000},
  author = {{National Research Council}},
  isbn = {978-0-309-07036-2},
  pages = {384},
  abstract = {This popular trade book, originally released in hardcover in the Spring of 1999, has been newly expanded to show how the theories and insights from the original book can translate into actions and practice, now making a real connection between classroom activities and learning behavior. This paperback edition includes far-reaching suggestions for research that could increase the impact that classroom teaching has on actual learning. Like the original hardcover edition, this book offers exciting new research about the mind and the brain that provides answers to a number of compelling questions. When do infants begin to learn? How do experts learn and how is this different from non-experts? What can teachers and schools do-with curricula, classroom settings, and teaching methods--to help children learn most effectively? New evidence from many branches of science has significantly added to our understanding of what it means to know, from the neural processes that occur during learning to the influence of culture on what people see and absorb. How People Learn examines these findings and their implications for what we teach, how we teach it, and how we assess what our children learn. The book uses exemplary teaching to illustrate how approaches based on what we now know result in in-depth learning. This new knowledge calls into question concepts and practices firmly entrenched in our current education system. Topics include: How learning actually changes the physical structure of the brain; How existing knowledge affects what people notice and how they learn; What the thought processes of experts tell us about how to teach; The amazing learning potential of infants; The relationship of classroom learning and everyday settings of community and workplace; Learning needs and opportunities for teachers; A realistic look at the role of technology in education.},
  booktitle = {How People Learn: Brain, Mind, Experience, and School},
  url = {http://www.nap.edu/catalog.php?record_id=9853}
}

@TECHREPORT{Naur-Randel:1969,
  author = {Peter Naur and Brian Randell},
  title = {Software Engineering: A Report on a Conference Sponsored by the {NATO} Science Committee at Garmisch, Germany, 7th to 11th October 1968},
  institution = {NATO},
  month = jan,
  year = {1969},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@ARTICLE{navarro-hoek:2004,
  author = {Emily Oh Navarro and André van der Hoek},
  title = {Software Process Modeling for an Educational Software Engineering Simulation Game},
  volume = {10},
  number = {3},
  year = {2004},
  pages = {311-325},
  journal = {Software Process Improvement and Practice},
  owner = {magsilva},
  timestamp = {2008.07.24}
}

@CONFERENCE{negroponte:2005,
  author = {Nicholas Negroponte},
  title = {One Laptop Per Child},
  booktitle = {World Economic Forum},
  year = {2005},
  address = {Davos, Switzerland},
  month = jan,
  url = {http://laptop.org/en/vision/project/index.shtml}
}

@ARTICLE{nelson-etal:2011,
  author = {Nelson, Adam and Menzies, Tim and Gay, Gregory},
  title = {Sharing experiments using open-source software},
  volume = {41},
  number = {3},
  month = mar,
  year = {2011},
  pages = {283--305},
  doi = {10.1002/spe.1004},
  abstract = {When researchers want to repeat, improve or refute prior conclusions, it is useful to have a complete and operational description of prior experiments. If those descriptions are overly long or complex, then sharing their details may not be informative. OURMINE is a scripting environment for the development and deployment of data mining experiments. Using OURMINE, data mining novices can specify and execute intricate experiments, while researchers can publish their complete experimental rig alongside their conclusions. This is achievable because of OURMINE's succinctness. For example, this paper presents two experiments documented in the OURMINE syntax. Thus, the brevity and simplicity of OURMINE recommends it as a better tool for documenting, executing, and sharing data mining experiments.},
  keywords = {open source, data mining},
  issn = {1097-024X},
  journal = {Software: Practice and Experience},
  publisher = {John Wiley \& Sons, Ltd.}
}

@MISC{nelson:video,
  author = {Ted Nelson},
  title = {Ted Nelson on Hypertext from Hyperland},
  howpublished = {Vídeo},
  month = sep,
  year = {1990},
  note = {Entrevista extraída do documentário Hyperland, distribuído pela da BBC Television (canal BBC2) e produzido por Douglas Adams},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://xanadu.com.au/AV/hypertext.mpg}
}

@INPROCEEDINGS{nelson:1965,
  author = {Theodor H. Nelson},
  title = {A File Structure for The Complex, The Changing and the Indeterminate},
  pages = {84--100},
  booktitle = {ACM 20th national conference},
  owner = {magsilva},
  publisher = {ACM},
  timestamp = {2008.07.30},
  year = {1965}
}

@ARTICLE{NerySilva-etal:2007,
  author = {Nery e Silva, Lincoln David and Carlos Eduardo Coelho Freire Batista and Luiz Eduardo Cunha Leite and Souza Filho, Guido Lemos de},
  title = {Suporte para desenvolvimento de aplicações multiusuário e multidispositivo para {TV} digital com {Ginga}},
  volume = {5},
  number = {12},
  month = oct,
  year = {2007},
  pages = {75--83},
  url = {https://portal.fucapi.br/tec/index2.php?p=ver_artigo.php&sidrevista=13&sidartigo=129},
  address = {Manaus, Amazonas, } # Brazil,
  journal = {T\&C Amazônia},
  publisher = {FUCAPI}
}

@MISC{Nesbit-etal:XXXX,
  author = {John Nesbit and Karen Belfer and Tracey Leacock},
  title = {Learning Object Review Instrument ({LORI}) User Manual},
  howpublished = {Manual},
  year = {2003},
  abstract = {The Learning Object Review Instrument (LORI) is used to evaluate the quality of e-learning resources. LORI is an online form consisting of rubrics, rating scales and comment fields. The current version of LORI available from eLera is version 1.5.},
  lang = {en},
  timestamp = {2012.01.24},
  url = {http://www.elera.net/eLera/Home/Articles/LORI%201.5.pdf}
}

@ARTICLE{Nesbit-etal:2002,
  author = {John Nesbit and Karen Belfer and John Vargo},
  title = {A Convergent Participation Model for Evaluation of Learning Objects},
  volume = {28},
  number = {3},
  year = {2002},
  pages = {1-9},
  abstract = {The properties that distinguish learning objects from other forms of educational software - global accessibility, metadata standards, finer granularity and reusability - have implications for evaluation. This article proposes a convergent participation model for learning object evaluation in which representatives from stakeholder groups (e.g., students, instructors, subject matter experts, instructional designers, and media developers) converge toward more similar descriptions and ratings through a two-stage process supported by online collaboration tools. The article reviews evaluation models that have been applied to educational software and media, considers models for gathering and meta-evaluating individual user reviews that have recently emerged on the Web, and describes the peer review model adopted for the MERLOT repository. The convergent participation model is assessed in relation to other models and with respect to its support for eight goals of learning object evaluation: (1) aid for searching and selecting, (2) guidance for use, (3) formative evaluation, (4) influence on design practices, (5) professional development and student learning, (6) community building, (7) social recognition, and (8) economic exchange.},
  url = {http://www.cjlt.ca/content/vol28.3/nesbit_etal.html},
  address = {Ottawa, Ontario, Canadá},
  issn = {1499-6685},
  journal = {Canadian Journal of Learning and Technology},
  publisher = {Canadian Network for Innovation in Education (CNIE)},
  timestamp = {2008.09.28}
}

@INPROCEEDINGS{talarico-etal:2006,
  author = {Américo Talarico Neto and J. C. Anacleto and Vania Paula de Almeida Neris and M. de S. Godoi and A. F. P. de Carvalho},
  title = {Cognitor: um Framework baseado na Linguagem de Padrões Cog-Learn},
  pages = {529-538},
  address = {Brasília},
  booktitle = {XVII Simpósio Brasileiro de Informática na Educação (SBIE 2006)},
  timestamp = {2008.09.27},
  year = {2006}
}

@MASTERSTHESIS{bulcao:2001,
  author = {R. F. Bulcão Neto},
  title = {WLS: An XML-based Open Hypermedia Linking Service for the Web},
  school = {ICMC-USP},
  year = {2001},
  address = {São Paulo, Brasil},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@ARTICLE{bulcao:2002,
  author = {R. F. Bulcão Neto and C. A. Izeki and M. G. C. Pimentel and Renata P. M. Fortes},
  title = {An Open Linking Service Supporting the Authoring of Web Documents},
  month = nov,
  year = {2002},
  url = {http://www.sdml.cs.kent.edu/docent2002/},
  journal = {ACM DocEng'02 - Symposium on Document Engineering},
  note = {Aceito para publicação},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@BOOK{Neves:2006,
  publisher = {Brasport},
  year = {2006},
  author = {Julio Cezer Neves},
  isbn = {85-7452-264-3},
  pages = {422},
  address = {Rio de Janeiro, RJ, } # Brazil,
  edition = {6},
  booktitle = {Programação Shell Linux}
}

@INCOLLECTION{Newby-etal:1996,
  author = {T. J. Newby and D. A. Stepich and J. D. Lehman and J. D. Russell},
  title = {Instructional technology for teaching and earning-designing instruction, integrating computers},
  booktitle = {Using media theory into application},
  publisher = {Prentice-Hall},
  year = {1996},
  editor = {Debra A. Stollenwerk},
  pages = {24-43},
  address = {New Jersey, EUA}
}

@ARTICLE{newcomb:1991,
  author = {Steven R. Newcomb and Neill A. Kipp and Victoria T. Newcomb},
  title = {The ``HyTime'': hypermedia/time-based document structuring language},
  volume = {34},
  number = {11},
  month = nov,
  year = {1991},
  pages = {67 - 83},
  doi = {10.1145/125490.125495},
  journal = {Communications of the ACM},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@MISC{software:myspace,
  author = {{News Corporation}},
  title = {MySpace},
  howpublished = {Programa de Computador},
  month = aug,
  year = {2003},
  owner = {magsilva},
  timestamp = {2008.04.03},
  url = {http://www.myspace.com}
}

@INPROCEEDINGS{nguyen:2002,
  author = {Tien Nguyen and Satish Chandra Gupta and Ethan V. Munson},
  title = {Three Issues in the Use of Versioned Hypermedia for Software Development Systems},
  address = {Fortaleza, CE, Brazil},
  booktitle = {Proceedings of the 8th Brazilian Symposium on Multimedia and Hypermedia Systems},
  month = oct,
  owner = {magsilva},
  timestamp = {2008.07.30},
  year = {2002}
}

@ARTICLE{nie-leung:2011,
  author = {Nie, Changhai and Leung, Hareton},
  title = {A survey of combinatorial testing},
  volume = {43},
  month = {February},
  year = {2011},
  pages = {1-29},
  doi = {10.1145/1883612.1883618},
  abstract = {Combinatorial Testing (CT) can detect failures triggered by interactions of parameters in the Software Under Test (SUT) with a covering array test suite generated by some sampling mechanisms. It has been an active field of research in the last twenty years. This article aims to review previous work on CT, highlights the evolution of CT, and identifies important issues, methods, and applications of CT, with the goal of supporting and directing future practice and research in this area. First, we present the basic concepts and notations of CT. Second, we classify the research on CT into the following categories: modeling for CT, test suite generation, constraints, failure diagnosis, prioritization, metric, evaluation, testing procedure and the application of CT. For each of the categories, we survey the motivation, key issues, solutions, and the current state of research. Then, we review the contribution from different research groups, and present the growing trend of CT research. Finally, we recommend directions for future CT research, including: (1) modeling for CT, (2) improving the existing test suite generation algorithm, (3) improving analysis of testing result, (4) exploring the application of CT to different levels of testing and additional types of systems, (5) conducting more empirical studies to fully understand limitations and strengths of CT, and (6) combining CT with other testing techniques.},
  keywords = {Software testing, combinatorial testing (CT), covering array, test case generation},
  acmid = {1883618},
  address = {New York, NY, USA},
  articleno = {11},
  issn = {0360-0300},
  issue = {2},
  issue_date = {January 2011},
  journal = {ACM Computing Surveys},
  numpages = {29},
  publisher = {ACM}
}

@BOOK{nielsen:1995,
  title = {Multimedia and Hypertext: The Internet and Beyond},
  publisher = {Academic Press},
  year = {1995},
  author = {Jakob Nielsen},
  address = {Estados Unidos},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@BOOK{nielsen:1990,
  title = {Hypertext and hypermedia},
  publisher = {Academic Press},
  year = {1990},
  author = {Jakob Nielsen},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@BOOK{noblit-hare:1988,
  title = {Meta-ethnography: synthesizing qualitative studies},
  publisher = {Sage Publications},
  year = {1988},
  author = {George W. Noblit and R. Dwight Hare},
  pages = {99}
}

@ARTICLE{noguera-etal:2010,
  author = {Noguera, Manuel and Hurtado, María V. and Rodríguez, María Luisa and Chung, Lawrence and Garrido, José Luis},
  title = {Ontology-driven analysis of UML-based collaborative processes using OWL-DL and CPN},
  volume = {75},
  number = {8},
  month = aug,
  year = {2010},
  pages = {726--760},
  doi = {10.1016/j.scico.2009.05.002},
  abstract = {A key ingredient in system and organization modeling is modeling business processes that involve the collaborative participation of different teams within and outside the organization. Recently, the use of the Unified Modeling Language (UML) for collaborative business modeling has been increasing, thanks to its human-friendly visual representation of a rich set of structural and behavioral views, albeit its unclear semantics. In the meantime, the use of the Web Ontology Language (OWL) has also been emerging, thanks to its clearly-defined semantics, hence being amenable to automatic analysis and reasoning, although it is less human friendly than, and also perhaps not as rich as, the UML notation - especially concerning processes, or activities. In this paper, we view the UML and the OWL as being complementary to each other, and exploit their relative strengths. We provide a mapping between the two, through a set of mapping rules, which allow for the capture of UML activity diagrams in an OWL-ontology. This mapping, which results in a formalization of collaborative processes, also sets a basis for subsequent construction of executable models using the Colored Petri Nets (CPN) formalism. For this purpose, we also provide appropriate mappings from OWL-based ontological elements into CPN elements. A case study of a mortgage granting system is described, along with the potential benefits and limitations of our proposal.},
  keywords = {CPN, CSCW, Collaborative systems, OWL, Process analysis, Process modelling, Reasoning, Task modelling},
  acmid = {1808514},
  address = {Amsterdam, Netherlands},
  issn = {0167-6423},
  issue = {8},
  journal = {Science of Computer Programming},
  numpages = {35},
  publisher = {Elsevier}
}

@BOOK{Novak:1998,
  title = {Learning, Creating, and Using Knowledge: Concept Maps As Facilitative Tools in Schools and Corporations},
  publisher = {Lawrence Erlbaum Associates},
  year = {1998},
  author = {Joseph D. Novak},
  isbn = {978-0805826265},
  pages = {251},
  address = {EUA},
  booktitle = {Learning, Creating, and Using Knowledge: Concept Maps As Facilitative Tools in Schools and Corporations}
}

@ARTICLE{Novak:1990,
  author = {Joseph D. Novak},
  title = {Concept mapping: A useful tool for science education},
  volume = {27},
  number = {10},
  year = {1990},
  pages = {937--949},
  doi = {10.1002/tea.3660271003},
  abstract = {This article describes the genesis and development of concept mapping as a tool for science education. It also offers an overview of this special issue of the "Journal of Research in Science Teaching" and comments on the current state of knowledge representation. Suggestions for further research are made.},
  issn = {0022-4308},
  journal = {Journal of Research in Science Teaching},
  owner = {magsilva},
  timestamp = {2008.01.21}
}

@BOOK{Novak:1977,
  title = {A theory of education},
  publisher = {Cornell University Press},
  year = {1977},
  author = {Joseph Donald Novak},
  isbn = {9780801411045},
  pages = {295},
  address = {Ithaca, NY, EUA},
  month = apr,
  booktitle = {A theory of education},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@TECHREPORT{Novak-Canas:2006,
  author = {Joseph D. Novak and Alberto J. Canas},
  title = {The Theory Underlying Concept Maps and How to Construct and Use Them},
  institution = {Florida Institute for Human and Machine Cognition},
  month = jan,
  year = {2006},
  address = {Pensacola Fl},
  url = {http://cmap.ihmc.us/Publications/ResearchPapers/TheoryCmaps/TheoryUnderlyingConceptMaps.htm},
  timestamp = {2008.08.13}
}

@BOOK{Novak-Gowin:1984,
  title = {Learning How to Learn},
  publisher = {Cambridge University},
  year = {1984},
  author = {Joseph D. Novak and D. Bob Gowin},
  isbn = {978-0-521-26507-2, 978-0-521-31926-3},
  pages = {199},
  address = {New York, NY, EUA},
  booktitle = {Learning How to Learn},
  url = {http://www.cambridge.org/9780521265072}
}

@MISC{noy-mcguinness:2003,
  author = {N. F. Noy and D. L. McGuinness},
  title = {Ontology Development 101: A Guide to Creating Your First Ontology},
  month = may,
  year = {2003},
  address = {Stanford, CA},
  owner = {magsilva},
  publisher = {Stanford University},
  timestamp = {2008.07.31},
  url = {http://protege.stanford.edu/publications/ontology_development/ontology101.pdf}
}

@ARTICLE{Ntafos88CSST,
  author = {S. C. Ntafos},
  title = {A Comparison of Some Structural Testing Strategies},
  volume = {14},
  number = {6},
  month = jul,
  year = {1988},
  pages = {868--873},
  journal = ieeese,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@ARTICLE{Ntafos84RETE,
  author = {S. C. Ntafos},
  title = {On Required Element Testing},
  volume = {SE-10},
  month = nov,
  year = {1984},
  pages = {795--803},
  journal = ieeese,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{Nuseibeh-Easterbrook:2000,
  author = {Nuseibeh, Bashar and Easterbrook, Steve},
  title = {Requirements engineering: a roadmap},
  pages = {35--46},
  doi = {10.1145/336512.336523},
  abstract = {This paper presents an overview of the field of software systems requirements engineering (RE). It describes the main areas of RE practice, and highlights some key open research issues for the future.},
  series = {ICSE '00},
  acmid = {336523},
  address = {New York, NY, USA},
  booktitle = {Conference on The Future of Software Engineering},
  isbn = {1-58113-253-0},
  location = {Limerick, Ireland},
  numpages = {12},
  publisher = {ACM},
  year = {2000}
}

@ARTICLE{OReilly99LOSS,
  author = {T. O´Reilly},
  title = {Lessons from Open-Source Software Development},
  volume = {42},
  number = {4},
  year = {1999},
  journal = comacm,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@BOOK{OBrien-Marakas:2010,
  title = {Introduction to Information Systems},
  publisher = {McGraw-Hill/Irwin},
  year = {2012},
  author = {James A. O'Brien and George M. Marakas},
  isbn = {978-0-07-337677-6},
  pages = {592},
  address = {New York, NY, } # USA,
  edition = {15}
}

@ARTICLE{OGrady-etal:2005,
  author = {O'Grady, Winnie and Woodgate, Sheila and Gunn, Cathy},
  title = {Repurposing learning objects: a sustainable alternative?},
  volume = {13},
  number = {3},
  year = {2005},
  pages = {189-200},
  abstract = {Recent experience shows that reusable learning objects, like the computer assisted learning programmes of the early 1990s, have so far failed to achieve expected levels of integration into educational practice. This is despite technical interoperability, cataloguing systems, high quality standards, targeted dissemination and professional development initiatives. Analysis of this problem suggests that conceptualization of the problem may be limiting the scope of solutions. This paper proposes a sustainable and participative approach to reuse that involves repurposing learning objects for different discipline areas. For some time now there has been a growing awareness that even the most accessible resources have failed to be widely adopted by the educational community and as a result have also failed to fulfil their considerable educational potential.},
  url = {http://repository.alt.ac.uk/96/},
  issn = {0968-7769},
  journal = {Association for Learning Technology Journal},
  timestamp = {2012.01.25}
}

@INPROCEEDINGS{oleary-etal:2006,
  author = {O'Leary, C. and Lawless, D. and Gordon, D. and Carroll, D. and Mtenzi, F. and Collins, M.},
  title = {3D Alignment in the Adaptive Software Engineering Curriculum},
  pages = {1 -6},
  doi = {10.1109/FIE.2006.322345},
  abstract = {The Emersion education model was designed by embracing experience from industry and academia in Ireland, the UK and China. A significant part of the model is a curriculum for an honours degree programme in computer science to be delivered in the Harbin Institute of Technology, China. Elements of the curriculum are strongly aligned in three ways: constructively, horizontally and vertically. Constructive alignment is the well accepted approach to curriculum design which emphasizes that learning, teaching and assessment must be aligned with the learning outcomes of all components of the programme. Horizontal alignment of elements requires the student to transfer problem solving knowledge between domains at the same stage of the programme. Vertical alignment requires that elements are structured to build on foundational knowledge and provide a platform for future elements. When combined, the three dimensions of alignment guide the curriculum development process. Our 3D aligned curriculum demonstrates how components interlink at various layers in a hierarchy to support the development of both the technical and transferable skills required by the software industry in China and elsewhere},
  keywords = {Emersion education model;adaptive software engineering curriculum;computer science degree programme;constructive alignment;curriculum design;horizontal alignment;vertical alignment;computer science education;educational courses;software engineering;},
  booktitle = {Frontiers in Education Conference, 36th Annual},
  issn = {0190-5848},
  month = oct,
  year = {2006}
}

@ARTICLE{leary:1998,
  author = {Daniel E. O'Leary},
  title = {Using AI in Knowledge Managment: Knowldege Bases and Ontologies},
  volume = {13},
  number = {3},
  month = may,
  year = {1998},
  pages = {34-39},
  journal = {IEEE Intelligent Systems},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@MISC{standard:wsbpel,
  author = {{OASIS}},
  title = {Web Services Business Process Execution Language Version 2.0},
  howpublished = {Padrão},
  month = apr,
  year = {2007},
  timestamp = {2009.02.05},
  url = {http://docs.oasis-open.org/wsbpel/2.0/OS/wsbpel-v2.0-OS.html}
}

@MISC{UDDI,
  author = {OASIS},
  title = {{UDDI}},
  month = {January},
  year = {2007},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://uddi.xml.org/}
}

@MISC{xrds:2.0,
  author = {OASIS},
  title = {Extensible Resource Descriptor Sequence},
  howpublished = {Especificação},
  month = mar,
  year = {2006},
  owner = {msilva},
  timestamp = {2007.06.01},
  url = {http://www.oasis-open.org/committees/download.php/17293/xri-resolution-v2.0-wd-10.pdf}
}

@BOOK{Oates:2006,
  title = {Researching information systems and computing},
  publisher = {Sage Publications},
  year = {2006},
  author = {Oates, Briony J.},
  pages = {341},
  address = {London, UK}
}

@INPROCEEDINGS{Oates-Capper:2009,
  author = {Briony J Oates and Graham Capper},
  title = {Using systematic reviews and evidence-based software engineering with masters students},
  pages = {1-9},
  abstract = {Context: The problem of teaching research skills to masters students. In particular, improving their literature reviews, assessing them and providing good feedback. Objectives: To introduce systematic reviews and evidence-based software engineering (EBSE) guidance into our teaching, provide an experience report and empirical data, and investigate the results. Methods: A systematic review requirement was introduced into the students' assessed work. The format of the assessment brief (also provided in this paper) was influenced by previous research on EBSE work with students. Qualitative and quantitative data was generated, and statistical analysis investigated the students' performance across the different elements of the systematic review. Results: Most students could do a systematic review and more useful feedback could be given. The assessment brief deviated from the normal EBSE guidelines in order to address previous difficulties. This modification was successful. Differences were found in student marks for different elements of the systematic reviews, with a large effect size for differing scores between 'search' and 'criteria', and 'search' and 'evaluation'. Conclusions: Introducing systematic reviews and EBSE guidance can improve students' literature handing skills and support improved feedback. The EBSE guidance should be modified for students and novice researchers to incorporate the process of developing a well-defined research question. Further work should investigate the differing performance across different elements of the systematic review.},
  address = {Durham University, UK},
  booktitle = {International Conference on Evaluation and Assessment in Software Engineering (EASE)},
  month = apr,
  url = {http://www.bcs.org/content/conWebDoc/25028},
  year = {2009}
}

@ARTICLE{Oberweis-etal:2007,
  author = {Andreas Oberweis and Victor Pankratius and Wolffried Stucky},
  title = {Product lines for digital information products},
  volume = {32},
  number = {6},
  month = sep,
  year = {2007},
  pages = {909 - 939},
  doi = {10.1016/j.is.2006.09.003},
  abstract = {The growth of the Web has fueled the creation, storage, and exchange of digital information products (DIPs), whose main purpose is the delivery of information, entertainment, education, or training. Very often, after their initial creation, the growing amount of content also leads to a more complicated maintenance, since updates typically occur rather often and the potential variability of modifications is not limited in advance. Moreover, commonalities between different parts of similar information products are not exploited, which often leads to redundancy. At the moment, there is hardly any attempt to compose information products from different sources and to produce more complex information products in a coordinated way. To help remedy this situation, this paper introduces the Product Lines for digitAl iNformation producTs (PLANT) approach, which applies the concept of software product lines to DIPs. The PLANT approach explicitly manages the commonalities of similar DIPs by defining common requirements, limiting variability in advance, as well as planning and coordinating reuse. This article focuses on the modeling of such product lines. In particular, the developed general concepts will be exemplified throughout the paper in the area of e-learning, in which DIPs play an important role. The application of PLANT in other areas and an implemented tool that supports the creation of information products in a product line are outlined as well.},
  keywords = {Digital products, Digital information products, Software product lines, Feature models, Workflow management, e-learning},
  issn = {0306-4379},
  journal = {Information Systems},
  lang = {en},
  publisher = {Elsevier}
}

@MISC{standard:uml:infrastructure,
  author = {{Object Management Group}},
  title = {Unified Modeling Language -- Infrastructure},
  howpublished = {Specification},
  month = may,
  year = {2010},
  note = {Version 2.3},
  url = {http://www.omg.org/spec/UML/2.3/Infrastructure/PDF/}
}

@MISC{standard:uml:superstructure,
  author = {{Object Management Group}},
  title = {Unified Modeling Language -- Superstructure},
  howpublished = {Specification},
  month = may,
  year = {2010},
  note = {Version 2.3},
  url = {http://www.omg.org/spec/UML/2.3/Superstructure/PDF/}
}

@MISC{standard:xmi,
  author = {{Object Management Group}},
  title = {MOF 2.0/XMI Mapping},
  howpublished = {Specification},
  month = dec,
  year = {2007},
  note = {Version 2.1.1},
  url = {http://www.omg.org/spec/XMI/}
}

@MISC{software:fitnesse,
  author = {{Object Mentor, Inc}},
  title = {Fitnesse},
  howpublished = {Programa de Computador},
  month = mar,
  year = {2003},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://fitnesse.org/}
}

@ARTICLE{Obrenovic-Dusan:2004,
  author = {Obrenovic, Zeljko and Starcevic, Dusan},
  title = {Modeling Multimodal Human-Computer Interaction},
  volume = {37},
  number = {9},
  month = sep,
  year = {2004},
  pages = {65--72},
  doi = {10.1109/MC.2004.139},
  abstract = {To improve coverage, reliability, and usability, researchers are designing new multimodal interfaces that automatically learn and adapt to important user, task, and environmental parameters.The authors have designed a generic modeling framework for specifying multimodal HCI using the Unified Modeling Language. Because itýs a well-known and widely supported standard, UML makesit easier for software engineers unfamiliar with multimodal research to apply HCI knowledge, resulting in broader and more practical effects.},
  address = {Los Alamitos, CA, } # USA,
  issn = {0018-9162},
  journal = {Computer},
  publisher = {IEEE Computer Society}
}

@INPROCEEDINGS{Obrist-etal:2008,
  author = {Obrist, Marianna and Geerts, David and Brandtz\aeg, Petter Bae and Tscheligi, Manfred},
  title = {Design for creating, uploading and sharing user generated content},
  pages = {2391--2394},
  doi = {10.1145/1358628.1358692},
  abstract = {The power of users playing the roles of authors and editors is undeniable these days [1]. New media, not only the Internet, are enabling people to become active users related to content production and sharing, and in co-creation of User Generated Content (UGC). In particular younger users and heavy users of Internet use networked applications to create and share content [1]. There is a need for UGC applications targeting a broader market, including older users and average Internet users. Today, the knowledge in designing and building for co-creation in networked media is still rather weak. The lack of information about UGC characteristics makes it difficult to expect what kind and amount of content will be produced, and to understand and interpret the reasons why users and user communities arise or fail. A significant effort is currently made by the HCI community in order to support active user involvement into the design and evaluation of networked applications [6]. Non-professional users are encouraged to become active producers and designers themselves [1]. However, there is still the need to explore how to apply and further extend these approaches and methods to better understand, design for and evaluate UGC applications. This SIG will contribute to this discussion by actively involving the audience in UGC creation.},
  keywords = {co-creation, design and evaluation methods, end user involvement, media, non-professional users, user generated content},
  series = {CHI EA},
  address = {New York, NY, USA},
  booktitle = {26th International Conference on Human Factors in Computing Systems (Extended Abstracts)},
  isbn = {978-1-60558-012-8},
  location = {Florence, #Italy#},
  publisher = {ACM},
  year = {2008}
}

@INPROCEEDINGS{Obrist-etal:2009,
  author = {Obrist, Marianna and Roto, Virpi and Väänänen-Vainio-Mattila, Kaisa},
  title = {User experience evaluation: do you know which method to use?},
  pages = {2763--2766},
  doi = {10.1145/1520340.1520401},
  abstract = {High quality user experience (UX) has become a central competitive factor of product development in mature consumer markets. Although the term UX is widely used, the methods and tools for evaluating UX are still inadequate. This SIG session collects information and experiences about UX evaluation methods used in both academia and industry, discusses the pros and cons of each method, and ideates on how to improve the methods.},
  keywords = {evaluation methods, user experience},
  series = {CHI EA},
  address = {New York, NY, USA},
  booktitle = {29th International Conference on Human Factors in Computing Systems (Extended Abstracts)},
  isbn = {978-1-60558-247-4},
  location = {Boston, MA, USA},
  publisher = {ACM},
  year = {2009}
}

@INPROCEEDINGS{Obrist-etal:2010a,
  author = {Obrist, Marianna and Tscheligi, Manfred and de Ruyter, Boris and Schmidt, Albrecht},
  title = {Contextual user experience: how to reflect it in interaction designs?},
  pages = {3197--3200},
  doi = {10.1145/1753846.1753956},
  abstract = {User experience is highly influenced and even changed by the context in which it occurs. In this SIG session we want to discuss how specific contexts influence various aspects of user experience. So far, both concepts "user experience" and "context" have been discussed a lot to various extent and in different dimensions. With this SIG, we aim to bring both concepts together, highlighting the differences arising from the consideration of different specific contexts and their relevant user experience factors. Thus, we reach a more comprehensive understanding of "contextual user experience", which opens up different roads for research and challenges the HCI community in all design and development phases. We will discuss user experience as focal point of user interface and interaction design bound to specific situational cases.},
  keywords = {context, design, methods, user experience},
  series = {CHI EA},
  address = {New York, NY, USA},
  booktitle = {28th International Conference on Human Factors in Computing Systems (Extended Abstracts)},
  isbn = {978-1-60558-930-5},
  location = {Atlanta, Georgia, #USA#},
  publisher = {ACM},
  year = {2010}
}

@INPROCEEDINGS{Obrist-etal:2010b,
  author = {Obrist, Marianna and Wurhofer, Daniela and Beck, Elke and Karahasanovic, Amela and Tscheligi, Manfred},
  title = {User experience (UX) patterns for audio-visual networked applications: inspirations for design},
  pages = {343--352},
  doi = {10.1145/1868914.1868955},
  abstract = {This paper summarizes best practices for improving user experience (UX) of audio-visual networked applications such as YouTube, Flickr, or Facebook. Designing for a good UX is becoming increasingly important within the HCI community. However, there is still a lack of empirically based knowledge on how to design audio-visual networked applications for an optimal UX. Based on studies with more than 8000 users of ten different audio-visual networked applications, we have developed 30 user experience patterns (short UX patterns). Our UX patterns are build on the end users' experiences investigated in lab and field studies in three different European countries. Most other pattern collections are based on the experience of designers or developers. In this paper we will present how we have developed the UX patterns and will describe the major UX problem areas found in detail. Our pattern collection can be useful to the designers of audio-visual networked applications and for the researchers working in the area of UX by providing empirical evidence on identified UX problems and suggestions for solutions referring to one or more of our UX patterns.},
  keywords = {audio-visual applications, patterns, social media, social networked applications, user experience, user experience patterns},
  series = {NordiCHI},
  address = {New York, NY, USA},
  booktitle = {6th Nordic Conference on Human-Computer Interaction: Extending Boundaries},
  isbn = {978-1-60558-934-3},
  location = {Reykjavik, #Iceland#},
  publisher = {ACM},
  year = {2010}
}

@INPROCEEDINGS{Ochoa-etal:2002,
  author = {Ochoa, Sergio F. and Ormeño, Emilio G. and Pino, José A.},
  title = {Reusing courseware components},
  pages = {549--556},
  doi = {10.1145/568760.568857},
  abstract = {Traditional courseware tools produce courseware with property formats. Unfortunately, these formats are incompatible among them. Therefore, the reuse of courseware material is limited to those developed with the same courseware tool. The functionality of a courseware becomes limited to that provided by a specific courseware tool. To solve these problems this paper proposes a framework of software components. The software components are JavaBeans that provide an interchangeable format among courseware tools supporting this specification. It means the components of the framework make possible to reuse courseware contents and functionality among these tools. The reuse is a very desirable practice because it could reduce the courseware development time and cost. The obtained results using the proposed framework are encouraging.},
  keywords = {component-based development, courseware development, framework of software components},
  series = {SEKE},
  address = {New York, NY, USA},
  booktitle = {14th International Conference on Software Engineering and Knowledge Engineering},
  isbn = {1-58113-556-4},
  location = {Ischia, #Italy#},
  publisher = {ACM},
  year = {2002}
}

@INPROCEEDINGS{Ochoa-Duval:2006,
  author = {Xavier Ochoa and Erik Duval},
  title = {Quality Metrics for Learning Object Metadata},
  pages = {1004--1011},
  address = { Chesapeake, VA },
  booktitle = {World Conference on Educational Multimedia, Hypermedia and Telecommunications 2006},
  editor = {Elaine Pearson and Paul Bohman},
  month = jun,
  publisher = {AACE},
  url = {http://go.editlib.org/p/23127},
  year = {2006}
}

@MISC{projects:ocw,
  author = {{OCW Consortium}},
  title = {{OpenCourseWare}},
  howpublished = project,
  year = {2002},
  abstract = {An OpenCourseWare (OCW) is a free and open digital publication of high quality college and university-level educational materials. These materials are organized as courses, and often include course planning materials and evaluation tools as well as thematic content. OpenCourseWare are free and openly licensed, accessible to anyone, anytime via the internet.},
  lang = {en},
  url = {http://www.ocwconsortium.org/en/aboutus/whatisocw},
  urlaccessdate = {20 fev 2012}
}

@ARTICLE{Offutt92ISTC,
  author = {A. J. Offutt},
  title = {Investigations of The Software Testing Coupling Effect},
  volume = {1},
  number = {1},
  month = jan,
  year = {1992},
  pages = {3--18},
  journal = acmse,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{Offutt89CEFF,
  author = {A. J. Offutt},
  title = {Coupling Effect: Fact or Fiction},
  pages = {131--140},
  address = {Key West, FL},
  booktitle = {Third Symposium on Software Testing, Analysis, and Verification},
  month = dec,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1989}
}

@ARTICLE{Offutt94UCOT,
  author = {A. J. Offutt and W. M. Craft},
  title = {Using Compiler Optimization Techniques to Detect Equivalent Mutants},
  volume = {4},
  year = {1994},
  pages = {131--154},
  journal = stvr,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{Offutt96SMPF,
  author = {A. J. Offutt and J. H. Hayes},
  title = {A Semantic Model of Program Faults},
  pages = {195--199},
  address = {San Diego, CA},
  booktitle = {ISSTA 96},
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1996}
}

@INPROCEEDINGS{offutt-irvine:1995,
  author = {A. J. Offutt and A. Irvine},
  title = {Testing Object-Oriented Software Using the Category-Partition Method},
  pages = {293--304},
  address = {Santa Barbara, CA},
  booktitle = {International Conference on Technology of Object-Oriented Languages and Systems},
  month = aug,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1995}
}

@ARTICLE{Offutt99DDRA,
  author = {A. J. Offutt and Z. Jin and J. Pan},
  title = {The Dynamic Domain Reduction Approach to Test Data Generation},
  volume = {29},
  number = {2},
  month = jan,
  year = {1999},
  pages = {167--193},
  journal = spe,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{Offutt-King:1987,
  author = {A. J. Offutt and K. N. King},
  title = {A {Fortran} 77 Interpreter for Mutation Analysis},
  address = {St. Paul, Minnesota},
  booktitle = {SIGPLAN 87 Symposium on Interpreters and Interpretive Techniques},
  month = jul,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1987}
}

@ARTICLE{offutt-etal:1996,
  author = {A. Jefferson Offutt and Ammei Lee and Gregg Rothermel and Roland H. Untch and Christian Zapf},
  title = {An Experimental Determination of Sufficient Mutant Operators},
  volume = {5},
  number = {2},
  month = apr,
  year = {1996},
  pages = {99--118},
  doi = {10.1145/227607.227610},
  journal = {ACM Transactions on Software Engineering Methodology},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@ARTICLE{Offutt94EEWM,
  author = {A. J. Offutt and S. Lee},
  title = {An Empirical Evaluation of Weak Mutation},
  volume = {SE-20},
  number = {5},
  month = may,
  year = {1994},
  pages = {337--344},
  journal = ieeese,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@ARTICLE{Offutt97ADEM,
  author = {A. J. Offutt and J. Pan},
  title = {Automatically Detecting Equivalent Mutants and Infeasible Paths},
  volume = {7},
  number = {3},
  month = sep,
  year = {1997},
  pages = {165--192},
  journal = stvr,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{Offutt96DEMF,
  author = {A. J. Offutt and J. Pan},
  title = {Detecting Equivalent Mutants and the Feasible Path Problem},
  pages = {224--236},
  address = {Gaithersburg, MD},
  booktitle = {COMPASS'96´-- In Annual Conference on Computer Assurance},
  month = jun,
  owner = {magsilva},
  publisher = {IEEE Computer Society Press},
  timestamp = {2008.07.31},
  year = {1996}
}

@ARTICLE{Offutt96EEDF,
  author = {A. J. Offutt and J. Pan and K. Tewary and T. Zhang},
  title = {An Experimental Evaluation of Data Flow and Mutation Testing},
  volume = {26},
  number = {2},
  month = feb,
  year = {1996},
  pages = {165--176},
  journal = spe,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{Offutt93EESM,
  author = {A. J. Offutt and G. Rothermel and C. Zapf},
  title = {An Experimental Evaluation of Selective Mutation},
  pages = {100--107},
  address = {Baltimore, MD},
  booktitle = {15th International Conference on Software Engineering (ICSE 93)},
  month = may,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1993}
}

@MISC{oki:2008,
  author = {OKI},
  title = {{Open Knowledge Initiative -- Accelerated interoperability through simplified integration}},
  howpublished = {http://www.okiproject.org/ [20/02/08]},
  year = {2008},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@INPROCEEDINGS{Oksman-etal:2009,
  author = {Oksman, Virpi and Tammela, Antti and Mäkelä, Tiina},
  title = {{iTV} and changing social interactions},
  pages = {128--134},
  doi = {10.1145/1621841.1621866},
  abstract = {In this paper, we present findings from empirical studies on end users' attitudes towards peer-to-peer (P2P) networked television. This paper sheds light on the changing trends of consumers' media usage and television watching. We aim to understand the meanings people associate with TV in their everyday lives and to discuss further how interactive TV (iTV) might change the social situations in which TV is being viewed.},
  keywords = {interactive TV, peer-to-peer TV, social media, user experiences},
  address = {New York, NY, USA},
  booktitle = {13th International MindTrek Conference: Everyday Life in the Ubiquitous Era},
  isbn = {978-1-60558-633-5},
  location = {Tampere, Finland},
  publisher = {ACM},
  year = {2009}
}

@INPROCEEDINGS{Oliveira99UDKS,
  author = {K. M. Oliveira and A. R. C. Rocha and G. H. Travassos and C. S. Menezes},
  title = {Using Domain-Knowledge in Software Development Environments},
  address = {Kaiserlautern, Alemanha},
  booktitle = {Software Engineering and Knowledge Engineering},
  month = jun,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1999}
}

@ARTICLE{FerreiraOliveira-etal:2001,
  author = {Oliveira, Maria Cristina Ferreira de and Marcelo Augusto Santos Turine and Paulo Cesar Masiero},
  title = {A statechart-based model for hypermedia applications},
  volume = {19},
  number = {1},
  month = jan,
  year = {2001},
  pages = {28 - 52},
  doi = {10.1145/366836.366869},
  abstract = {This paper presents a formal definition for HMBS (Hypermedia Model Based on Statecharts). HMBS uses the structure and execution semantics of statecharts to specify both the structural organization and the browsing semantics of hypermedia applications. Statecharts are an extension of finite-state machines and the model is thus a generalization of hypergraph-based hypertext models. Some of the most important features of HMBS are its ability to model hierarchy and synchronization of information; provision of mechanisms for specifying access structures, navigational contexts, access control, multiple tailored versions,and hierarchical views. Analysis of the underlying statechart machine allows verification of page reachability, valid paths, and other properties, thus providing mechanisms to support authors in the development of structured applications.},
  address = {New York, NY, USA},
  issn = {1094-9224, 1557-7406},
  journal = {ACM Transactions on Information Systems (TOIS)},
  lang = {en},
  owner = {magsilva},
  publisher = {ACM},
  timestamp = {2008.07.30}
}

@MISC{standard:omg:spem,
  author = {{OMG}},
  title = {Software \& Systems Process Engineering Metamodel (SPEM)},
  howpublished = standard,
  month = apr,
  year = {2008},
  lang = {en},
  url = {http://www.omg.org/spec/SPEM/2.0}
}

@MISC{oagis9.0:2005,
  author = {{Open Applications Group}},
  title = {Open Applications Group Integration Specification},
  month = apr,
  year = {2005},
  owner = {magsilva},
  timestamp = {2007.11.08},
  url = {http://www.openapplications.org/downloads/oagis/loadfrmd.htm}
}

@MISC{software:adffaces,
  author = {Oracle},
  title = {Oracle ADF Faces Components},
  howpublished = {Programa de computador},
  owner = {magsilva},
  timestamp = {2007.10.07},
  url = {http://www.oracle.com/technology/products/adf/adffaces/index.html}
}

@MISC{software:virtualbox,
  author = {{Oracle Corporation}},
  title = {{VirtualBox}},
  howpublished = software,
  year = {2007},
  note = {Initially developed by Innotek, which was acquired by Sun Microsystem, which was acquired by Oracle Corporation.},
  abstract = {VirtualBox is a general-purpose full virtualizer for x86 hardware.},
  url = {http://www.virtualbox.org/}
}

@MISC{software:netbeans,
  author = {{Oracle Corporation}},
  title = {{NetBeans}},
  howpublished = {Software},
  year = {2000},
  url = {http://www.netbeans.org}
}

@INPROCEEDINGS{Ormeno-etal:2009,
  author = {Ormeño, Emilio and Ochoa, Sergio and Ibañez, Francisco and Lund, M. Inés and Ruíz, Susana and Aballay, Laura and Rosales, Víctor},
  title = {A {CMT}-based modeling language for courseware design},
  pages = {552--557},
  doi = {10.1109/CSCWD.2009.4968117},
  abstract = {This paper presents a language for courseware design that tries to overcome usability limitations shown by the Course Modeling Technique (CMT). The proposed language is able to deal with the key aspects of courseware design: objectives, contents, and instructional path. Given that its potential users are non-technical, the representation of the language is close to natural language. For its design, an emperical experimentation was made comparing its expressivity power regard to CMT. The results showed that the proposed language is more expressive and avoids some ambiguities that appears when CMT is used. Finally, the designers who participate in the tests, think that the new language is better than CMT in terms of effort required to use it.},
  acmid = {1579020},
  address = {Washington, DC, USA},
  booktitle = {International Conference on Computer Supported Cooperative Work in Design},
  isbn = {978-1-4244-3534-0},
  numpages = {6},
  owner = {magsilva},
  publisher = {IEEE Computer Society},
  url = {http://portal.acm.org/citation.cfm?id=1578024.1579020},
  year = {2009}
}

@BOOK{Orr:1986,
  title = {Structured Systems Development},
  publisher = {Prentice Hall},
  year = {1986},
  author = {Orr, Kenneth T.},
  isbn = {0138551499},
  address = {Upper Saddle River, NJ, } # USA,
  booktitle = {Structured Systems Development}
}

@INPROCEEDINGS{Osterweil:1987,
  author = {Osterweil, Leon},
  title = {Software processes are software too},
  pages = {2--13},
  series = {ICSE '87},
  acmid = {41766},
  address = {Los Alamitos, CA, USA},
  booktitle = {International Conference on Software Engineering},
  isbn = {0-89791-216-0},
  location = {Monterey, California, United States},
  numpages = {12},
  publisher = {IEEE Computer Society Press},
  url = {http://dl.acm.org/citation.cfm?id=41765.41766},
  year = {1987}
}

@INPROCEEDINGS{Osterweil:1997,
  author = {Osterweil, Leon J.},
  title = {Software processes are software too, revisited: an invited talk on the most influential paper of ICSE 9},
  pages = {540--548},
  doi = {10.1145/253228.253440},
  abstract = {The ICSE 9 paper, ``Software Processes are Software Too'' suggests that software processes are themselves a form of software and that there are considerable benefits that will derive from basing a discipline of software process development on the more traditional discipline of application software development. This paper attempts to clarify some misconceptions about this original ICSE 9 suggestion and summarizes some research carried out over the past ten years that seems to confirm the original suggestion. The paper then goes on to map out some future research directions that seem indicated. The paper closes with some ruminations about the significance of the controversy that has continued to surround this work.},
  series = {ICSE '97},
  acmid = {253440},
  address = {New York, NY, USA},
  booktitle = {International Conference on Software Engineering},
  isbn = {0-89791-914-9},
  location = {Boston, Massachusetts, United States},
  numpages = {9},
  publisher = {ACM},
  year = {1997}
}

@ARTICLE{Ostrand88CPMS,
  author = {T. J. Ostrand and M. J. Balcer},
  title = {The Category-Partition Method for Specifying and Generating Functional Tests},
  volume = {31},
  number = {6},
  month = jun,
  year = {1988},
  pages = {676--686},
  journal = comacm,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{Ostrand96DFBT,
  author = {T. J. Ostrand and E. J. Weyuker},
  title = {Data Flow Based Test Adequacy for Languages with Pointers},
  pages = {74--86},
  booktitle = {Symposium on Software Testing},
  month = oct,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1996}
}

@INPROCEEDINGS{Ostrand88UDFA,
  author = {T. J. Ostrand and E. J. Weyuker},
  title = {Using Data Flow Analysis for Regression Testing},
  address = {Portland, OR},
  booktitle = {Sixth Annual Pacific Northwest Software Quality Conference},
  month = sep,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1988}
}

@MISC{ScormInt,
  author = {Ostyn, C.},
  title = {SCORM Interactions},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@BOOK{ScormITE,
  title = {In the Eye of the SCORM: An introduction to SCORM 2004 for Content Developers},
  publisher = {http://www.ostyn.com/resources.htm [8/01/2008]},
  year = {2007},
  author = {Claude Ostyn},
  month = mar,
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@INBOOK{ott:1995,
  chapter = {Measurement Theory and Software Measurement},
  pages = {7-25},
  title = {Software Measurement},
  publisher = {International Thomson Computer Press},
  year = {1995},
  editor = {Austin Melton},
  author = {Linda M. Ott},
  address = {UK},
  owner = {magsilva},
  timestamp = {2010.08.25}
}

@ARTICLE{Leite:1989,
  author = {J. C. do P. Leite},
  title = {Viewpoint Analysis: A Case Study},
  volume = {14},
  number = {3},
  year = {1989},
  pages = {111--119},
  journal = {ACM J. Software Engineering Notes},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@INPROCEEDINGS{Pacheco99WCCF,
  author = {E. J. Pacheco and G. A. de Marco and H. F. Eberspächer},
  title = {{WCC -- Web Course Creator}: um Framework para a Criação de Ambientes de Aprendizado para a Web},
  address = {Assunción, Paraguay},
  booktitle = {XXV Latin-American Conference on Informatics (CLEI 99)},
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1999}
}

@INPROCEEDINGS{Pacheco99WCCS,
  author = {E. J. Pacheco and G. A. de Marco and H. F. Eberspächer},
  title = {{WCC -- Web Course Creator}: Um Sistema Tutor Inteligente para a Geração de Ambientes de Aprendizado},
  address = {Rio de Janeiro, RJ},
  booktitle = {V Workshop de Informática na Escola (WIE 99)},
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1999}
}

@INCOLLECTION{Padron-etal:2006,
  author = {Padrón, Carmen and Díaz, Paloma and Aedo, Ignacio},
  title = {MD2 Method: The Didactic Materials Creation from a Model Based Perspective},
  booktitle = {Innovative Approaches for Learning and Knowledge Sharing},
  publisher = {Springer},
  year = {2006},
  editor = {Nejdl, Wolfgang and Tochtermann, Klaus},
  volume = {4227},
  series = {Lecture Notes in Computer Science},
  pages = {366-382},
  note = {Proceedings of the First European Conference on Technology Enhanced Learning, EC-TEL 2006, Crete, Greece, October 1-4, 2006, 1st Doctoral Consortium in Technology Enhanced Learning.},
  abstract = {The creation of didactic materials is a complex task that needs an effective support for all practitioners involved in such process. This is the goal of the MD2 method presented in this paper. We propose the MD2 model to describe didactic materials requirements like its contents, pedagogical, technical and quality features. The rationale is to use some of those descriptors to provide mapping from high level technical descriptions of learning technology standards to simpler and closer descriptions to practitioners about material requirements. Those model mappings are used as foundation of MD2 creation method, and we show how they can guide the selection and composition phases of creation. By other side, another set of MD2 descriptors are used in the evaluation phase to control the usability and quality of the obtained material. A log of the whole process including the values of all model elements and the material's design rationales will be stored as extended semantic annotation. Thus, important properties of the created material like its interoperability, accessibility and reusability will be ensured.},
  affiliation = {DEI Laboratory Computer Science Department., Universidad Carlos III de Madrid, Avenida de la Universidad, 30, CP 28911 Leganés, Madrid, Spain},
  doi = {10.1007/11876663_29},
  isbn = {978-3-540-45777-0},
  owner = {magsilva}
}

@INPROCEEDINGS{Padron-etal:2008,
  author = {Padrón, C. L. and Zarraonandia, T. and Diaz, P. and Aedo, I.},
  title = {The Evaluation within the Development and Deployment of IMS LD-Based Didactic Materials: The MD2+ Runtime Adaptation Approach},
  pages = {1053-1054},
  doi = {10.1109/ICALT.2008.26},
  abstract = {Evaluation is one of the most important activities in the didactic materials creation since it allows developers to check if the features of created material satisfy all the requirements established at begin of its development and if that material can be an effective support to achieve the educational goals of a particular instructional situation. Its results provide relevant information for the material redesign in such cases when those requirements or educational goals are not satisfied. In this paper we describe an approach to evaluate IMS LD-based materials during their development and deployment in an educational process.},
  keywords = {didactic materials creation;educational goals;educational process;instructional situation;material redesign;runtime adaptation approach;distance learning;educational aids;multimedia systems;},
  address = {Santander, Cantabria},
  booktitle = {International Conference on Advanced Learning Technologies},
  month = jul,
  owner = {magsilva},
  publisher = {IEEE},
  year = {2008}
}

@MISC{software:google,
  author = {Larry Page and Sergey Brin},
  title = {Google Search},
  howpublished = {Programa de Computador},
  year = {1996},
  owner = {magsilva},
  timestamp = {2006.08.03}
}

@BOOK{PageJones:2000,
  publisher = {Addison-Wesley Professional},
  year = {2000},
  author = {Meilir Page-Jones},
  isbn = {978-0201699463},
  pages = {480},
  edition = {1},
  abstract = {Object technology is increasingly recognized as a valuable tool in application development, but what is not yet recognized is the importance of design in the construction of robust and adaptable object-oriented (OO) applications. With the recent introduction and widespread adoption of the Unified Modeling Language (UML), programmers are now equipped with a powerful tool for expressing software designs. Fundamentals of Object-Oriented Design in UML shows aspiring and experienced programmers alike how to apply design concepts, the UML, and the best practices in OO development to improve both their code and their success rates with object-based projects. In the first two chapters, best-selling author Meilir Page-Jones introduces novices to key concepts and terminology, demystifying the jargon, and providing a context in which to view object orientation. Part II is a practical and well-illustrated guide to UML notation and to building the most useful UML diagrams. Part III grapples with advanced topics in the testing and improvement of design quality, including connascence, level-2 encapsulation, and the use of state-space and behavior to assess class hierarchies. These design principles are explained and demonstrated without reference to any one design methodology so that they are easily accessible and applicable in a variety of contexts. Programmers and designers learn how to assess and enhance their work as the author walks them through the evaluation of designs taken from actual projects and the realistic example that ends the book. Readers will come away with a better understanding of object-oriented concepts and of how to design and develop the high-quality software their clients need.},
  booktitle = {Fundamentals of object-oriented design in {UML}}
}

@ARTICLE{pai-etal:2004,
  author = {Madhukar Pai and Michael McCulloch and Jennifer D. Gorman and Nitika Pai and Wayne Enanoria and Gail Kennedy and Prathap Tharyan and John M Colford, Jr},
  title = {Systematic reviews and meta-analyses: an illustrated, step-by-step guide},
  volume = {17},
  year = {2004},
  pages = {86-95},
  url = {http://www.ncbi.nlm.nih.gov/pubmed/15141602},
  journal = {The National Medical Journal of India}
}

@MISC{paille:2008,
  author = {Gerry Paille},
  title = {A Short Course on Structured Course Development, Learning Objects, and E-Learning Standards},
  howpublished = {Site},
  month = sep,
  year = {2008},
  timestamp = {2008.09.21},
  url = {http://careo.prn.bc.ca/losc/losccourse1.html}
}

@INPROCEEDINGS{paim:2002,
  author = {Fábio Rilston Silva Paim and Ana Elizabete Carvalho and Jaelson Brelaz de Castro},
  title = {Towards a Methodology for Requirements Analysis of Data Warehouse Systems},
  pages = {146-161},
  address = {Gramado, Rio Grando do Sul, Brasil},
  booktitle = {XVI Simpósio Brasileiro de Engenharia de Software},
  editor = {Leila Ribeiro},
  month = oct,
  owner = {magsilva},
  timestamp = {2008.07.30},
  year = {2002}
}

@MASTERSTHESIS{Paiva01PACR,
  author = {D. M. B. Paiva},
  title = {Proposta e Avaliação de um Conjunto de Requisitos para Sistemas de Autoria Hipermídia Educacional},
  school = {ICMC-USP},
  year = {2001},
  address = {São Carlos, SP},
  month = jan,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{paiva:2005,
  author = {Débora Maria Barroso Paiva and Fortes, Renata Pontin de Mattos},
  title = {Design Rationale in Software Engineering: A Case Study},
  pages = {14-16},
  address = {Taipei, China},
  booktitle = {Seventeenth International Conference on Software Engineering and Knowledge Engineering (SEKE 2005)},
  month = jul,
  owner = {magsilva},
  timestamp = {2008.07.30},
  year = {2005}
}

@INPROCEEDINGS{paiva:2005:1,
  author = {Débora M. B. Paiva and Alexandre M. Manduca and Marco Aurélio G. Silva and Leonardo J. Quemello and Rosana T. V. Braga and Renata P. de M. Fortes},
  title = {Reforçando a Comunicação com Uso de uma Ferramenta de Software Livre em Ensino de Engenharia de Software},
  address = {São Leopoldo, Brasil},
  booktitle = {XIII Workshop sobre Educação em Computação},
  month = {jul},
  note = {Aceito para publicação.},
  owner = {Marco Aurélio Graciotto Silva},
  timestamp = {2008.07.30},
  year = {2005}
}

@MASTERSTHESIS{Pan94UCDE,
  author = {J. Pan},
  title = {Using Constraints to Detect Equivalent Mutants},
  school = {George Mason University},
  year = {1994},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{Pankratius:2005,
  author = {Victor Pankratius},
  title = {Aspect-oriented learning objects},
  pages = {21-23},
  abstract = {Learning Objects (LOs) have evolved as a means to organize, encapsulate, and exchange reusable granules of learning material between different e-learning systems. A common problem encountered in practical situations is that conceptually coherent learning material may be distributed across several LOs, a problem which may originate in the way the material is decomposed into LOs. From a maintenance perspective, modifications and updates of such material are tedious and expensive, since modifications may have to be done in various locations in several LOs. This paper proposes to remedy this problem by using solutions already established in the area of Aspect-Oriented Programming (AOP). Furthermore, it is shown from a reengineering perspective how crosscutting concerns of LOs can be modularized as aspects and how aspects can be linked with LOs using XQUERY.},
  keywords = {learning objects, aspect-oriented programming},
  booktitle = {IASTED International Conference on Web-Based Education},
  location = {Grindelwald, Switzerland},
  month = feb,
  timestamp = {2008.09.26},
  year = {2005}
}

@ARTICLE{pankratius-stucky:2005,
  author = {Victor Pankratius and Wolffried Stucky},
  title = {Aspect-Oriented re-engineering of e-learning courseware},
  volume = {12},
  number = {5},
  year = {2005},
  pages = {457-470},
  journal = {The Learning Organization},
  timestamp = {2008.09.26}
}

@ARTICLE{Pankratius-etal:2005,
  author = {Victor Pankratius and Wolffried Stucky and Gottfried Vossen},
  title = {Aspect-oriented re-engineering of e-learning courseware},
  volume = {12},
  number = {5},
  year = {2005},
  pages = {457 -- 470},
  doi = {10.1108/09696470510611401},
  abstract = {This paper proposes solutions to problems related to the maintenance and update of already existing e-learning courseware. A structured approach in form of a reference model for the re-engineering of existing educational material is presented. In this context, concepts already established in the area of aspect-oriented programming are applied to deal with crosscutting concerns in e-learning material. Finally, a software product line approach is proposed for the creation of new courseware using re-engineered components. It turns out that some aspects of the methodology developed for aspect-oriented programming can also be used to restructure the existing e-learning material in such a way that maintenance is eased and redundancy is significantly reduced. In addition, software product lines for e-learning material provide a global framework for coordinating the re-engineering and reuse of components. The advantage of the proposed approach is that existing e-learning standards and systems do not have to be modified or adapted. Usually, courseware evolves during a longer period of time and its development does not start every time from zero. There is a high incentive for re-engineering of existing courseware, since it constitutes in many cases the competitive advantage of companies or universities. However, up to now, little attention is paid to the maintenance and the efficient update of e-learning material which is already there.},
  issn = {0969-6474},
  journal = {The Learning Organization},
  lang = {en},
  publisher = {Emerald},
  timestamp = {2012.01.26}
}

@TECHREPORT{Pansanato-Nunes:1999:ICMC,
  author = {Luciano Tadeu Esteves Pansanato and Maria das Graças Volpe Nunes},
  title = {{EHDM}: Método para Projeto de Hiperdocumentos para Ensino},
  institution = {Universidade de São Paulo - Instituto de Ciências Matemáticas e de Computação},
  month = mar,
  year = {1999},
  number = {43},
  address = {São Carlos, SP, Brazil},
  issn = {0103-2577},
  note = {42},
  timestamp = {2012.01.23},
  type = {Notas do ICMC - Série Computação}
}

@INPROCEEDINGS{Pansanato-Nunes:1999:SBMDIA,
  author = {Luciano Tadeu Esteves Pansanato and Maria das Graças Volpe Nunes},
  title = {{EHDM}: Método para projeto de Hiperdocumentos para Ensino},
  pages = {29-42},
  abstract = {Este artigo apresenta o Método para Projeto de Hiperdocumentos para Ensino, ou EHDM (Educational Hyperdocuments Design Method), uma abordagem sistemática para apoiar o projeto e o desenvolvimento de aplicações hipermídia para ensino. O método utiliza o modelo proposto por Michener e a técnica de mapeamento conceitual para modelar o domínio de conhecimento do hiperdocumento. As três fases que compõem o método - modelagem conceitual hierárquica, projeto navegacional de contextos e construção e teste - são apresentadas.},
  keywords = {Hipermídia na Educação, Engenharia de Hiperdocumentos, Ferramentas de Autoria Multimídia/Hipermídia},
  abstract-en = {This paper presents the Educational Hyperdocuments Design Method, or EHDM, a systematic approach to support the design and development of educational hypermedia applications. It uses Michener's model and the technique of concept mapping for modeling the knowledge domain. The three phases that comprise the method - hierarchical conceptual modeling, contextual navigational design and construction and test - are presented.},
  booktitle = {V Simpósio Brasileiro de Sistemas Multimídia e Hipermídia (SBMIDIA'99)},
  keywords-en = {Hypermedia in Education, Hyperdocuments Engineering, Multimedia/Hypermedia Authoring Tools},
  lang = {pt},
  location = {Goiânia, GO, Brazil},
  timestamp = {2012.01.23},
  year = {1999}
}

@ARTICLE{Pansanato-Nunes:1999:RBIE,
  author = {L. T. E. Pansanato and M. G. V. Nunes},
  title = {Autoria de Aplicações Hipermídia para Ensino},
  volume = {1},
  number = {5},
  month = sep,
  year = {1999},
  pages = {103-124},
  abstract = {Este artigo discute questões sobre a autoria de aplicações hipermídia para ensino, com o objetivo de identificar requisitos para um ambiente de desenvolvimento de aplicações hipermídia. A autoria de hiperdocumentos para ensino é uma tarefa complexa e sistemas de autoria hipermídia tradicionalmente utilizados, como HyperCard, ToolBook e mesmo a linguagem HTML, no caso de autoria para a WWW, são mais direcionados à criação de hiperdocumentos para apresentação e recuperação de informação. Este artigo apresenta algumas ferramentas para autoria de hiperdocumentos para ensino e argumenta pela necessidade de uma modelagem prévia do domínio de conhecimento. Um método para o projeto de aplicações hipermídia para o ensino, o EHDM, é proposto como base para o desenvolvimento de ferramentas de autoria que incorporam a modelagem do domínio do conhecimento como parte do seu processo de autoria. Uma ferramenta desenvolvida utilizando-se o EHDM como base metodológica é também apresentada como forma de validação do EHDM num contexto real.},
  keywords = {Hipermídia na Educação, Engenharia de Hiperdocumentos, Ferramentas de Autoria Hipermídia},
  abstract-en = {This paper discusses issues related to the authoring of educational hypermedia applications with the objective of identifying requirements for an environment of development of hypermedia applications. The authoring of educational hyperdocuments is a complex task and traditional hypermedia authoring systems, like HyperCard, ToolBook, and even the HTML language for the WWW, are more suitable for the tasks of information presentation and retrieval. This paper presents some tools for authoring of educational hyperdocuments and considers the need of a previous modeling of the knowledge domain. A method for the project of educational hyperdocuments applications, EHDM, is proposed as a basis for the development of authoring tools that incorporate the modeling of the knowledge domain as a part of their authoring process. A tool that was developed using the EHDM as its methodological basis is also presented as a way of validating the EHDM in a real context.},
  journal = {Revista Brasileira de Informática na Educação},
  lang = {pt},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@TECHREPORT{papaioannou:1998,
  author = {Vaious Papaioannou and Babis Theodoulidis},
  title = {HERE: A Web Based Environment for Requirements Engineering},
  institution = {UMIST},
  month = may,
  year = {1998},
  address = {UK},
  url = {http://www.crim.co.umist.ac.uk/projects/here},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@INPROCEEDINGS{papaioannou:1996,
  author = {Vaious Papaioannou and Babis Theodoulidis},
  title = {HERE: Hypermedia Environment for Requirements Engineering},
  pages = {20-21},
  address = {Heraklion, Crete},
  booktitle = {7ty Workshop on the Next Generation of CASE Tools (NGCT'96)},
  month = may,
  owner = {magsilva},
  timestamp = {2008.07.30},
  year = {1996}
}

@INPROCEEDINGS{papatheodorou-etal:1998,
  author = {T. S. Papatheodorou and G. D. Styliaras and S. P Christodoulou},
  title = {Evaluation of Hypermedia Application Development and Management Systems},
  pages = {1--10},
  address = {Pittsburgh},
  booktitle = {The Ninth ACM Conference on Hypertext and Hypermedia},
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1998}
}

@INPROCEEDINGS{papazoglou:2003,
  author = {Mike P. Papazoglou},
  title = {Service-Oriented Computing: Concepts, Characteristics and Directions},
  pages = {3--12},
  doi = {10.1109/WISE.2003.1254461},
  booktitle = {International Conference on Web Information Systems Engineering (WISE)},
  owner = {magsilva},
  timestamp = {2008.01.28},
  year = {2003}
}

@INPROCEEDINGS{papazoglou:2006,
  author = {Michael P. Papazoglou and Paolo Traverso and Schahram Dustdar and Frank Leymann and Bernd J. Krämer},
  title = {Service-Oriented Computing Research Roadmap},
  pages = {1--29},
  booktitle = {Dagstuhl Seminar Proceedings 05462},
  month = apr,
  owner = {magsilva},
  timestamp = {2008.01.28},
  year = {2006}
}

@ARTICLE{Papert:2004,
  author = {Seymour Papert},
  title = {Interviews with {Seymour Papert}},
  volume = {2},
  month = jan,
  year = {2004},
  pages = {9--9},
  doi = {10.1145/973801.973816},
  abstract = {The legendary Quincy Jones and Seymour Papert have graciously appeared on camera for interviews and joined the ACM Computers in Entertainment magazines editorial board. Quincy and Seymour are two of the nicest people to talk to and work with. Quincy talks about education as fun learning, the impact of music on children, how technology affects the way music is created and produced, and digital distribution of music over the Internet. Seymour speaks of learning-rich entertainment, Logo and computer programming for children, technology in schools and education, and the future of home schooling and learning environments. The video clips of the interviews are available at http://www.acm.org/pubs/cie/mar2004/index.html Quincy Jones, who composed more than 50 major motion picture and television scores, has earned international acclaim as producer of the best-selling single of all time and the best-selling album in the history of the recording industry. The all-time most nominated Grammy artist with a total of 76 nominations and 26 awards, Quincy has also received an Emmy Award, seven Oscar nominations, and the Academy of Motion Picture Arts and Sciences Jean Hersholt Humanitarian Award. More information can be found at http://www.quincyjonesmusic.com Seymour Papert, a mathematician and an early pioneer of Artificial Intelligence, is internationally recognized as the seminal thinker on how computers can change learning. He is a cofounder with Marvin Minsky of the AI Lab at MIT and a founding faculty member of the MIT Media Lab, where he continues to work. Seymour collaborated for many years with Jean Piaget at the University of Geneva in Switzerland. He wrote many books including Mindstorms: Children, Computers, and Powerful Ideas. More information can be found at http://www.papert.org/},
  address = {New York, NY, EUA},
  issn = {1544-3574},
  journal = {Computers in Entertainment},
  publisher = {ACM}
}

@INCOLLECTION{Paquette:2004,
  author = {Gilbert Paquette},
  title = {Educational modelling languages from an instructional engineering perspective},
  booktitle = {Online education using learning objects},
  publisher = {Routledge},
  year = {2004},
  editor = {Rory McGreal},
  chapter = {26},
  pages = {299-311},
  address = {EUA},
  edition = {1},
  month = sep,
  isbn = {0415335124, 978-0415335126}
}

@BOOK{Paquette:2003,
  title = {Instructional Engineering in Networked Environments},
  publisher = {Pfeiffer},
  year = {2003},
  author = {Gilbert Paquette},
  isbn = {0-7879-6466-2},
  pages = {266},
  address = {San Francisco, CA, EUA},
  edition = {1},
  booktitle = {Instructional Engineering in Networked Environments}
}

@ARTICLE{Paquette:2001,
  author = {Gilbert Paquette},
  title = {TeleLearning Systems Engineering -- Towards a new {ISD} model},
  number = {14},
  year = {2001},
  pages = {1-35},
  abstract = {The author has been deeply involved in technology-based learning and distance education since the seventies. The early projects were in the didactic of mathematics, on-line training of teachers in LOGO, authoring systems and AI-based learning environments. Since the creation of LICEF in 1992, the focus has shifted to knowledge-based instructional design, intelligent agents and virtual campus models and their implementations. This paper summarizes this more recent work and owes a debt to the many researchers and research professionals who have participated in the various projects at our research center on these questions. We will first examine the new challenges to Instructional Systems Design (ISD) entailed by the growth of web based learning and knowledge management, to justify the need for a new effort in the field. Then, we will give an account of the main actual approaches in network based education, present our own proposals, and underline the larger set of questions that addresses new challenges to the ISD field. Then, the stage will be set to present a method for Telearning Systems Engineering that we have developed in the last eight years, together with a set of performance support tools for designers. We will finally discuss the foundations of this method and present a set of eighteen principles that can be applied to plan meaningful interactions in distributed learning models and telelearning systems.},
  journal = {Journal of Structural Learning}
}

@INCOLLECTION{Paquette-etal:2011,
  author = {Gilbert Paquette and Michel Léonard and Karin Lundgren-Cayrol},
  title = {The {MOT+} Visual Language for Knowledge-Based Instructional Design},
  booktitle = {Instructional Design: Concepts, Methodologies, Tools and Applications},
  publisher = {{IGI} Global},
  year = {2011},
  chapter = {3.12},
  pages = {697--717},
  address = {Londres, Reino Unido},
  month = mar,
  abstract = {This chapter states and explains that a learning design is the result of a knowledge engineering process where knowledge and competencies, learning design, media and delivery models are constructed in an integrated framework. Consequently, we present our MOT+ general graphical language and editor that help construct structured interrelated visual models. The MOT+LD editor is the newly added specialization of this editor for learning designs, producing IMS-LD compliant Units of Learning. The MOT+OWL editor is another specialization of the general visual language for knowledge and competency models based on the OWL specification. We situate both models within our taxonomy of knowledge models respectively as a multi-actor collaborative process and a domain theory. The association between these "content" models and learning design components is seen as the essential task in an instructional design methodology, to guide the construction of high quality learning environments.},
  doi = {10.4018/978-1-60960-503-2.ch312},
  lang = {en}
}

@ARTICLE{Paquette-etal:2006,
  author = {Gilbert Paquette and Michel Léonard and Karin Lundgren-Cayrol and Stefan Mihaila and Denis Gareau},
  title = {Learning Design based on Graphical Knowledge-Modelling},
  volume = {9},
  number = {1},
  month = jan,
  year = {2006},
  pages = {97-112},
  abstract = {This chapter states and explains that a Learning Design is the result of a knowledge engineering process where knowledge and competencies, learning design and delivery models are constructed in an integrated framework. We present a general graphical language and a knowledge editor that has been adapted to support the construction of learning designs compliant with the IMS-LD specification. We situate LD within our taxonomy of knowledge models as a multi-actor collaborative system. We move up one step in the abstraction scale, showing that the process of constructing learning designs can itself be viewed as a unit-of-learning (or a unit-of-design): designers can be seen as learning by constructing learning designs, individually, in teams and with staff support. This viewpoint enables us to discuss and compare various 'design plays'. Further, the issue of representing knowledge, cognitive skills and competencies is addressed. The association between these 'content' models and learning design components can guide the construction of learning designs and help to classify them in repositories of LD templates.},
  keywords = {Learning design, Educational modelling, Knowledge-based systems, Graphic languages, Knowledge modelling, Competency-based learning design, IMS-LD, Learning design repositories},
  issn = {1436-522, 1176-3647},
  journal = {Educational Technology \& Society},
  lang = {en},
  publisher = {IFETS}
}

@ARTICLE{Paquette-etal:2005a,
  author = {Gilbert Paquette and Olga Marino and Ileana De la Teja and Karin Lundgren-Cayrol and Michel Lonard and Julien Contamines},
  title = {Implementation and Deployment of the {IMS} Learning Design Specification},
  volume = {31},
  number = {2},
  year = {2005},
  pages = {1-8},
  abstract = {Knowledge management in organizations, the learning objects paradigm, the advent of a new web generation, and the 'Semantic Web' are major actual trends that reveal a potential for a renewed distance learning pedagogy. First and foremost is the use of educational modelling languages and instructional engineering methods to help decide how to aggregate learning objects in learning and knowledge management environments. This article proposes a set of tools under implementation, such as a graphic Learning Design Editor and a delivery system, using learning object repositories to create IMS-LD online environments. We also propose a strategy for the deployment of learning design tools and methods in learning organizations.},
  url = {http://www.cjlt.ca/index.php/cjlt/article/view/144/137},
  issn = {1499-6685},
  journal = {Canadian Journal of Learning and Technology},
  owner = {magsilva},
  timestamp = {2009.02.20}
}

@MISC{Parasoft00CTES,
  author = {{PARASOFT Corporation}},
  title = {{C}++ {T}est},
  year = {2000},
  owner = {magsilva},
  timestamp = {2008.07.31},
  url = {ftp://ftp.parasoft.com/cpptest/C++Test-10.exe}
}

@MISC{Parasoft00INSU,
  author = {{PARASOFT Corporation}},
  title = {{I}nsure++},
  year = {2000},
  owner = {magsilva},
  timestamp = {2008.07.31},
  url = {ftp://ftp.parasoft.com/insure++/ins_win.exe}
}

@MISC{Parasoft99CWIZ,
  author = {{PARASOFT Corporation}},
  title = {{C}ode{W}izard},
  year = {1999},
  owner = {magsilva},
  timestamp = {2008.07.31},
  url = {ftp://ftp.parasoft.com/codewizard/c++/cw_win_jre.exe}
}

@MISC{Parasoft99JTES,
  author = {{PARASOFT Corporation}},
  title = {{J}test},
  year = {1999},
  owner = {magsilva},
  timestamp = {2008.07.31},
  url = {ftp://ftp.parasoft.com/jtest/jtest_win32.exe}
}

@INBOOK{pardillo:2010,
  pages = {407-422},
  title = {A Systematic Review on the Definition of UML Profiles},
  publisher = {Springer Berlin / Heidelberg},
  year = {2010},
  editor = {Petriu, Dorina and Rouquette, Nicolas and Haugen, Øystein},
  author = {Pardillo, Jesús},
  volume = {6394},
  series = {Lecture Notes in Computer Science},
  abstract = {This article reports a systematic review on the definition of UML profiles in the research literature. Several exploratory statistical analyses have been performed in order to characterise both the idiosyncrasy of UML profiles and how they are reported in the literature. This study uncovers the differences between presentation styles for behavioural and structural domains, and shows how UML profiles based on Class, Association, and Property structural metaclasses clearly outnumber any other kind. Also, this review reveals how half of the examined UML profiles merely extend the abstract syntax, without adding neither icons nor constraints. The main contribution of this study is therefore a clear picture of the state-of-the-art in UML profiling, together with a set of open questions regarding its future.},
  affiliation = {University of Alicante - DLSI/Lucentia, Spain},
  booktitle = {Model Driven Engineering Languages and Systems},
  doi = {10.1007/978-3-642-16145-2_28}
}

@ARTICLE{pardillo-cachero:2010,
  author = {Pardillo, Jesús and Cachero, Cristina},
  title = {Domain-specific language modelling with UML profiles by decoupling abstract and concrete syntaxes},
  volume = {83},
  month = {December},
  year = {2010},
  pages = {2591--2606},
  doi = {10.1016/j.jss.2010.08.019},
  abstract = {UML profiling presents some acknowledged deficiencies, among which the lack of expressiveness of the profiled notations, together with the high coupling between abstract and concrete syntaxes outstand. These deficiencies may cause distress among UML-profile modellers, who are often forced to extend from unsuitable metaclasses for mere notational reasons, or even to model domain-specific languages from scratch just to avoid the UML-profiling limitations. In order to palliate this situation, this article presents an extension of the UML profile metamodel to support arbitrarily-complex notational extensions by decoupling the UML abstract and concrete syntax. Instead of defining yet another metamodel for UML-notational profiling, notational extensions are modelled with DI, i.e., the UML notation metamodel for diagram interchange, keeping in this way the extension within the standard. Profiled UML notations are rendered with DI by defining the graphical properties involved, the domain-specific constraints applied to DI, and the rendering routines associated. Decoupling abstract and concrete syntax in UML profiles increases the notation expressiveness while decreasing the abstract-syntax complexity.},
  acmid = {1879301},
  address = {New York, NY, USA},
  issn = {0164-1212},
  issue = {12},
  journal = {Journal of Systems and Software},
  numpages = {16},
  publisher = {Elsevier Science}
}

@ARTICLE{Pargas99TDGU,
  author = {R. P. Pargas and M. J. Harrold and R. Peck},
  title = {Test-Data Generation Using Genetic Algorithms},
  volume = {9},
  number = {4},
  year = {1999},
  pages = {263--282},
  journal = stvr,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@ARTICLE{Parker:1999,
  author = {Angie Parker},
  title = {Interaction in Distance Education: The Critical Conversation},
  volume = {1},
  number = {12},
  year = {1999},
  pages = {13--17},
  abstract = {In 1897, with a series of shorthand lessons delivered by postal service, Anna Tickner changed the way instruction was presented forever. The early days of distance education witnessed the inclusion of the old passive/lecture paradigm, which was even more deadly from a distance than in person. Today's students who consistently iosurf the worldlt with the Internet will not tolerate this non-interactive style of instruction and will quickly search for a more Hollywood stylely course that provides active conversation with the instructors, experts, and other students. Interactivity has been defined in numerous ways ranging from irpressing the remoteli to activate the VCR to two-way conversationlv provided by satellite up links. Regardless of how interaction is defined, history has shown it to be an essential component in the learning process. Research has supported this inclusion but stops short of application due to the mediation between instructor and student provided by a wide range of technologies. Distance education is made up of a network of learners and teachers who travel electronic highways and meet in virtual classrooms. The new media for delivery brings with it a challenge and an opportunity. The challenge lies in the refocusing of the instruction to embody a component of lively interaction. The opportunity lies in the access to education for a worldwide coalition of students.},
  keywords = {Distance Education; Educational Technology; Inclusive Education; Interaction; Networking Technologies},
  url = {http://www.editlib.org/p/8117},
  address = {Charlottesville, VA},
  issn = {1065-6901},
  journal = {AACE Journal},
  publisher = {AACE}
}

@INPROCEEDINGS{Parnas:1972b,
  author = {Parnas, David L.},
  title = {Some conclusions from an experiment in software engineering techniques},
  pages = {325--329},
  doi = {10.1145/1479992.1480035},
  abstract = {In two earlier reports we have suggested some techniques to be used producing software with many programmers. The techniques were especially suitable for software which would exist in many versions due to modifications in methods or applications. These techniques have been taught in an undergraduate course and used in an experimental project in that course. The purpose of this report is to describe the results that have been obtained and to discuss some conclusions which we have reached. The experiment was completely uncontrolled, the programmers generally inexperienced and poor, and the programming system used was not designed for the task. The numerical data presented below have no real value. We include them primarily as an illustration of the type of result that can be obtained by use of the techniques described in the earlier reports. We consider these results a drastic improvement over the state of the art. Major changes in a system can be confined to well-defined, small, subsystems. No intellectual effort is required in the final assembly or "integration" phase.},
  volume = {1},
  booktitle = {Fall Joint Computer Conference},
  location = {Anaheim, California, #USA#},
  month = dec,
  publisher = {ACM},
  year = {1972}
}

@ARTICLE{Parrish:2004,
  author = {Patrick E. Parrish},
  title = {The Trouble with Learning Objects},
  volume = {52},
  number = {1},
  year = {2004},
  pages = {49--67},
  abstract = {Object-oriented instructional design (OOID) offers the promise of universal access to online instructional materials, increased productivity among trainers and educators, and solutions for individualizing learning. However, it is unclear whether it can fulfill these promises to the degree many envision. As with every new instructional technology, it is easy to become overoptimistic about learning objects, but problems of education are always more complex than technology alone can solve. In this article, I take a critical look at the proposed benefits of learning objects described in the published literature, particularly scalability and adaptability. I also look at both the difficulties in defining the term learning object and the limitations of metaphors used to describe the concept, and concludes with propositions for learning object usage.},
  issn = {1042-1629},
  journal = {Educational Technology, Research and Development}
}

@INPROCEEDINGS{PascualNieto-etal:2008,
  author = {Ismael Pascual-Nieto and Diana Rosario Pérez Marín and Pilar Rodríguez and Mick O'Donnell},
  title = {Using Automatically Generated Students' Clickable Conceptual Models for E-tutoring},
  pages = {1--8},
  abstract = {Computer methods for evaluating student's knowledge have traditionally been based on Multiple Choice Questions (MCQs) or fillin-the-blank exercises, which do not provide a reliable basis upon which to assess student's underlying misconceptions. Because of this lack, we have devised and implemented a procedure for automatically deriving clickable students' conceptual models from their free-text answers. A student's conceptual model can be defined as a network of interrelated concepts associated with a confidence value that indicates how well each student knows a concept. Several knowledge representation formats are used to show the generated conceptual model to the student. Furthermore, students can click on the concepts to get more information about them. 22 English Studies students are taking advantage of this new resource to review their Pragmatics course. Initial results show that they have found it very useful and claim that it is a good support for their review of the subject.},
  address = {Toulouse, França},
  bibsource = {DBLP, http://dblp.uni-trier.de},
  booktitle = {16th International Conference on Conceptual Structures -- Supllementary proceedings},
  editor = {Peter Eklund and Ollivier Haemmerté},
  ee = {http://ceur-ws.org/Vol-354/p10.pdf},
  location = {Toulouse, França},
  month = jul,
  publisher = {Springer Verlag},
  url = {http://sunsite.informatik.rwth-aachen.de/Publications/CEUR-WS/Vol-354/p10.pdf},
  year = {2008}
}

@INPROCEEDINGS{pashalidis:2003,
  author = {Andreas Pashalidis and Chris J. Mitchell},
  title = {A Taxonomy of Single Sign-On Systems},
  pages = {249-264},
  volume = {2727},
  address = {Berlim, Alemanha},
  booktitle = {Information Security and Privacy, 8th Australasian Conference (ACISP)},
  editor = {R. Safavi-Naini and J. Seberry},
  month = jul,
  note = {Lecture Notes in Computer Science},
  owner = {msilva},
  publisher = {Springer-Verlag},
  timestamp = {2007.06.04},
  year = {2003}
}

@UNPUBLISHED{Pasquini96SPRO,
  author = {A. Pasquini},
  title = {{SPACE} Program},
  note = {Personal correspondence},
  year = {1996},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@MISC{Patashnik:1988,
  author = {Oren Patashnik},
  title = {{BibTeXing}},
  month = feb,
  year = {1988},
  pages = {16},
  url = {http://mirrors.ctan.org/biblio/bibtex/base/btxdoc.pdf}
}

@MISC{Patashnik:1988:section5,
  author = {Oren Patashnik},
  title = {Designing BIBTEX Styles},
  month = feb,
  year = {1988},
  pages = {10},
  url = {http://mirrors.ctan.org/biblio/bibtex/base/btxhak.pdf}
}

@MISC{rdfsemantics:2004,
  author = {Patrick Hayes, Brian McBride},
  title = {RDF Semantics},
  howpublished = {W3C Recommendation},
  month = feb,
  year = {2004},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://www.w3.org/TR/rdf-mt/}
}

@MISC{smilanimation:2001,
  author = {Patrick Schmitz, Aaron Cohen},
  title = {{SMIL} Animation},
  howpublished = {W3C Recommendation},
  month = sep,
  year = {2001},
  comment = {24/05/2005},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://www.w3.org/TR/smil-animation}
}

@ARTICLE{Patterson:2004,
  author = {Patterson, David A.},
  title = {The health of research conferences and the dearth of big idea papers},
  volume = {47},
  number = {12},
  month = dec,
  year = {2004},
  pages = {23--24},
  doi = {10.1145/1035134.1035153},
  acmid = {1035153},
  address = {New York, NY, USA},
  issn = {0001-0782},
  issue = {12},
  issue_date = {December 2004},
  journal = {Communications of the ACM},
  numpages = {2},
  publisher = {ACM}
}

@TECHREPORT{standard:cmu:cmm:1.1,
  author = {Paulk, Mark and Curtis, William and Chrissis, Mary Beth and Weber, Charles},
  title = {Capability Maturity Model for Software -- Version 1.1},
  institution = {Software Engineering Institute -- Carnegie Mellon University},
  month = feb,
  year = {1993},
  number = {CMU/SEI-93-TR-24},
  address = USA,
  url = {http://www.sei.cmu.edu/library/abstracts/reports/93tr024.cfm},
  abstract = {In November 1986, the Software Engineering Institute (SEI) with assistance from the Mitre began developing a process maturity framework that would assist organizations in improving their software process. This effort was initiated in response to a request to provide the federal government with a method for assessing the capability of their software contractors. In September 1987, the SEI released a brief description of the process maturity framework and a maturity questionnaire (CMU/SEI-87-TR-023). The SEI intended the maturity questionnaire to provide a simple tool for identifying areas where an organization's software process needed improvement. Unfortunately, the questionnaire was too often regarded as "the model" rather than as a vehicle for exploring process maturity issues. After four years of experience with the software process maturity framework and the preliminary version of the maturity questionnaire, the SEI has evolved the software process maturity framework into a fully defined model. This model will be used in a systematic, principled way to derive a maturity questionnaire. By fully elaborating the maturity framework, a model has emerged that provides organizations with more effective guidance for establishing process improvement programs than was offered by the maturity questionnaire. Using knowledge acquired from software process assessments and extensive feedback from both industry and government, an improved version of the process maturity framework has been produced called the Capability Maturity Model for Software (CMM). This paper is an introduction to the revised model.}
}

@BOOK{Paulk-etal:1995,
  title = {The Capability Maturity Model: Guidelines for improving the software process},
  publisher = {Addison-Wesley},
  year = {1995},
  author = {M. C. Paulk and C. V. Weber and B. Curtis and M. B. Chrissis},
  isbn = {978-0201546644},
  pages = {456},
  series = {The SEI Series in Software Engineering},
  address = {Massachusetts, } # USA,
  booktitle = {The Capability Maturity Model: Guidelines for improving the software process}
}

@INPROCEEDINGS{Paulo-etal:1998,
  author = {Fabiano B. Paulo and Marcelo Augusto S. Turine and Maria Cristina F. de Oliveira and Paulo C. Masiero},
  title = {{XHMBS}: A Formal Model to Support Hypermedia Specification},
  pages = {161-170},
  doi = {10.1145/276627.276645},
  abstract = {This paper introduces XHMBS (the eXtended Hyperdocument Model Based on Statecharts) to support the formal specification of general hypermedia applications. XHMBS uses a novel formalism called hypercharts as its underlying model for specifying the navigational structure, browsing semantics and synchronization requirements of a hyperdocument. Hypercharts are statecharts extended with additional mechanisms for describing the time sequencing and information synchronization requirements typical of multimedia. The extensions incorporated into hypercharts are based on the major characteristics of some Petri net based multimedia models, and make it an alternative to such models for multimedia and hypermedia specification. XHMBS provides facilities for defining the structure of a hypermedia application in terms of nodes and links and also for describing the temporal behavior of dynamic data streams contained in nodes. The model incorporates presentation and communication channels for describing spatial coordination and distribution of information, and anchor objects for ensuring separation between information structure and content.},
  keywords = {Multimedia/Hypermedia Modeling, Statecharts, Hypercharts, HMBS, XHMBS, Temporal Synchronization, Formal Specification},
  address = {Pittsburgh},
  booktitle = {ACM Conference on Hypertext and Hypermedia (HYPERTEXT '98)},
  lang = {en},
  location = {Pittsburgh, PA, USA},
  month = jun,
  publisher = {ACM},
  timestamp = {2009.02.05},
  year = {1998}
}

@ARTICLE{travassos-medeiros:2010,
  author = {Guilherme Travassos e Paulo Sérgio Medeiros},
  title = {Praticando Ciência no Dia a Dia do Desenvolvimento de Sistemas},
  volume = {14},
  month = oct,
  year = {2010},
  pages = {22-23},
  journal = {Computação Brasil},
  publisher = {Sociedade Brasileira de Computação}
}

@ARTICLE{Paulovich-etal:2008,
  author = {F. V. Paulovich and L. G. Nonato and R. Minghim and H. Levkowitz},
  title = {{Least Square Projection}: a fast high precision multidimensional projection technique and its application to document mapping},
  volume = {14},
  number = {3},
  month = may # {-} # jun,
  year = {2008},
  pages = {564--575},
  doi = {10.1109/TVCG.2007.70443},
  abstract = {The problem of projecting multidimensional data into lower dimensions has been pursued by many researchers due to its potential application to data analyses of various kinds. This paper presents a novel multidimensional projection technique based on least square approximations. The approximations compute the coordinates of a set of projected points based on the coordinates of a reduced number of control points with defined geometry. We name the technique least square projections (LSP). From an initial projection of the control points, LSP defines the positioning of their neighboring points through a numerical solution that aims at preserving a similarity relationship between the points given by a metric in mD. In order to perform the projection, a small number of distance calculations are necessary, and no repositioning of the points is required to obtain a final solution with satisfactory precision. The results show the capability of the technique to form groups of points by degree of similarity in 2D. We illustrate that capability through its application to mapping collections of textual documents from varied sources, a strategic yet difficult application. LSP is faster and more accurate than other existing high-quality methods, particularly where it was mostly tested, that is, for mapping text sets.},
  issn = {1077-2626},
  journal = {IEEE Transactions on Visualization and Computer Graphics},
  publisher = {IEEE Computer Society Press}
}

@MISC{software:7zip,
  author = {Igor Pavlov},
  title = {7-Zip},
  howpublished = software,
  month = jul,
  year = {1999},
  url = {http://7-zip.org}
}

@ARTICLE{pawlowski-bick:2006,
  author = {Jan M. Pawlowski and Markus Bick},
  title = {Managing \& re-using didactival expertise: The Didactical Object Model},
  volume = {9},
  number = {1},
  year = {2006},
  pages = {84--96},
  journal = {Educational Technology \& Society},
  timestamp = {2008.09.26}
}

@ARTICLE{PazosArias-etal:2008,
  author = {Pazos-Arias, José J. and López-Nores, Martín and García-Duque, Jorge and Díaz-Redondo, Rebeca P. and Blanco-Fernández, Yolanda and Ramos-Cabrer, Manuel and Gil-Solla, Alberto and Fernández-Vilas, Ana},
  title = {Provision of distance learning services over Interactive Digital {TV} with {MHP}},
  volume = {50},
  number = {3},
  month = apr,
  year = {2008},
  pages = {927--949},
  doi = {10.1016/j.compedu.2006.09.008},
  abstract = {E-learning technologies have developed greatly in recent years, with considerable success. However, there is increasing evidence that web-based learning is not reaching the social sectors which are more reluctant to contact with the new technologies, thus leading to inequalities in the access to education and knowledge in the Information Society. By hiding the intricacies of computers behind the familiarity of household equipment, Interactive Digital TV (IDTV) is considered to play a key role in addressing this problem, and the term t-learning has been recently coined to mean TV-based interactive learning. Despite several approaches to t-learning have been proposed, works are missing that conceive it as a whole, delimit its scope in comparison with web-based learning and analyze the influence of the normalization of IDTV as a services platform. This paper addresses these issues, and introduces a framework for the development and deployment of t-learning services that promotes interoperability and reuse while taking into account the characteristic features of the IDTV medium.},
  keywords = {Architectures for educational technology system, Authoring tools and methods, Distance education and telelearning, Interactive learning environments, Multimedia/hypermedia systems},
  address = {Oxford, Reino Unido},
  issn = {0360-1315},
  journal = {Computers \& Education},
  publisher = {Elsevier}
}

@MISC{software:webdeveloper,
  author = {Chris Pederick},
  title = {Web Developer},
  howpublished = {Programa de computador},
  month = {jun},
  year = {2003},
  owner = {magsilva},
  timestamp = {2007.08.13},
  url = {http://chrispederick.com/work/web-developer/}
}

@INPROCEEDINGS{Pedrosa-etal:2011,
  author = {Pedrosa, Diogo and Martins, Jr., José Augusto C. and Melo, Erick L. and Teixeira, Cesar A. C.},
  title = {A multimodal interaction component for digital television},
  pages = {1253--1258},
  doi = {10.1145/1982185.1982459},
  abstract = {In most current digital TV applications the user interaction takes place by pressing keys on a remote control. For simple applications this type of interaction is sufficient --- however, as interactive applications become more popular new input devices are demanded. After discussing motivating scenarios, this paper presents an architecture that offers to applications running on a set-top-box the possibility of receiving multimodal data (audio, video, image, ink, accelerometer, text, voice and customized data) from multiple devices (such as mobile phones, PDAs, tablet PCs, notebooks or even desktops). We validated the architecture by implementing a corresponding multimodal interaction component which extends the Brazilian Digital TV middleware, and by building applications which use the component.},
  keywords = {digital TV, interactive TV, multimodal input},
  series = {SAC '11},
  acmid = {1982459},
  address = {New York, NY, EUA},
  booktitle = {ACM Symposium on Applied Computing},
  isbn = {978-1-4503-0113-8},
  location = {TaiChung, Taiwan},
  numpages = {6},
  publisher = {ACM},
  year = {2011}
}

@ARTICLE{peltz:2003,
  author = {Chris Peltz},
  title = {Web Services Orchestration and Choreography},
  volume = {36},
  number = {10},
  month = oct,
  year = {2003},
  pages = {46--52},
  doi = {10.1109/MC.2003.1236471},
  journal = {IEEE Computer},
  owner = {magsilva},
  timestamp = {2008.01.28}
}

@MISC{xhtml10:2002,
  author = {Steven Pemberton and Daniel Austin and Jonny Axelsson and Tantek Çelik and Doug Dominiak and Herman Elenbaas and Beth Epperson and Masayasu Ishikawa and Shin'ichi Matsui and Shane McCarron and Ann Navarro and Subramanian Peruvemba and Rob Relyea and Sebastian Schnitzenbaumer and Peter Stark},
  title = {XHTML 1.0 The Extensible HyperText Markup Language},
  howpublished = {W3C Recommendation},
  month = aug,
  year = {2002},
  comment = {24/05/2005},
  file = {XHTML 1.0 The Extensible HyperText Markup Language.pdf:XHTML 1.0 The Extensible HyperText Markup Language.pdf:PDF},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://www.w3.org/TR/xhtml1}
}

@ARTICLE{pequeno-etal:2010,
  author = {Pequeno, Henrique S. L. and Gomes, George A. M. and Andrade, Rossana M. C. and de Souza, José N. and de Castro, Miguel F.},
  title = {FrameIDTV: A framework for developing interactive applications on digital television environments},
  volume = {33},
  number = {4},
  month = jul,
  year = {2010},
  pages = {503--511},
  doi = {10.1016/j.jnca.2010.01.002},
  abstract = {Digital TV technologies are stretching out the horizons for interactive applications to end users. However, developing interactive applications for this new environment is not as straightforward as developing Internet applications. In order to make this development process easier in the context of interactive digital TV (iDTV), one of the solutions is the development of Frameworks. However, after investigating some of the existing iDTV framework solutions, we have found a limitation on the range of the interactive application domain to DTV available in these current frameworks, which mainly show solutions for local interactive (enhanced TV). Thus, in this paper, we propose an iDTV Framework (called FrameIDTV) that makes possible a broader solution in the DTV domain for the construction of interactive applications, both local and remote. The remote interactivity is possible using a generic and easy to customize communication protocol that is specified in the framework for the application layer. Furthermore, applications such as voting, home banking, and t-commerce, which are executed locally in the set-top box and are integrated to remote services using a return channel, can use the proposed framework. FrameIDTV also allows the establishment of secure communications and is developed following a specific framework methodology. This framework has primarily targeted the Brazilian Digital TV standard and its procedural middleware, called Ginga-J. Nevertheless, FrameIDTV can be broadly used worldwide, since it is compliant with the Globally Executable MHP (GEM) standard.},
  keywords = {Digital TV, Framework, Interactivity},
  address = {London, UK},
  issn = {1084-8045},
  journal = {Journal of Network and Computer Applications},
  publisher = {Academic Press}
}

@ARTICLE{pereira03oar,
  author = {L. A. M. Pereira and F. A. M. Porto and R. N. Melo},
  title = {{Objetos de Aprendizado Reutilizáveis (RLOs):} Conceitos, Padronização, Uso e Armazenamento},
  year = {2003},
  journal = {Monografias em Ciencia da Computação, PUC-RioInf. MCC10},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@INPROCEEDINGS{pereira-menezes:2005,
  author = {O. Pereira and C. Menezes},
  title = {O Uso de Ontologias como Instrumento de Avaliação de Ferramentas de Comunicação Mediada por Computador},
  pages = {136--146},
  address = {Juiz de Fora, MG},
  booktitle = {Simpósio Brasileiro de Informática na Educação (SBIE)},
  month = nov,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {2005}
}

@INPROCEEDINGS{PerezMarin-etal:2007,
  author = {Pérez-Marín, D. and Alfonseca, E. and Rodríguez, P. and Pascual-Nieto, I.},
  title = {Automatic Generation of Students' Conceptual Models from Answers in Plain Text},
  pages = {329--333},
  doi = {10.1007/978-3-540-73078-1_39},
  abstract = {Recently, we have introduced a new procedure to automatically generate students' conceptual models to assist teachers in finding out their students' main misconceptions and lack of concepts, from their interaction with an automatic and adaptive free-text scoring system. In this paper, we present an improvement of this procedure: the models can be built from the students' answers in plain text and they refer not only to one particular student but to the whole class. We also introduce a new tool called COMOV (COnceptual MOdels Viewer) to display the models as concept maps, tables, bar charts or text summaries. Finally, we provide an evaluation of this new approach.},
  volume = {4511},
  series = {Lecture Notes in Computer Science},
  address = {Corfu, Grécia},
  booktitle = {International Conference on User Modeling},
  editor = {Conati, Cristina and McCoy, Kathleen and Paliouras, Georgios},
  issn = {0302-9743},
  location = {Corfu, Greece},
  month = jul,
  publisher = {Springer},
  year = {2007}
}

@ARTICLE{PerezMarin-PascualNieto:2010,
  author = {Pérez-Marín, Diana and Pascual-Nieto, Ismael},
  title = {Showing Automatically Generated Students' Conceptual Models to Students and Teachers},
  volume = {20},
  number = {1},
  month = jan,
  year = {2010},
  pages = {47--72},
  doi = {10.3233/JAI-2010-0002},
  abstract = {A student conceptual model can be defined as a set of interconnected concepts associated with an estimation value that indicates how well these concepts are used by the students. It can model just one student or a group of students, and can be represented as a concept map, conceptual diagram or one of several other knowledge representation formats. Some e-assessment systems that automatically evaluate free-text students' answers have recently been extended to include the possibility of automatically generating students' conceptual models. The research reported in this paper focuses on studying the effects of showing these automatically generated models to students and teachers. The e-assessment system used was the Will Tools suite with a group of Engineering students during a semester at the Universidad Autónoma of Madrid.},
  keywords = {Open student models, e-assessment, e-learning, free-text scoring},
  url = {http://iaied.org/pub/1305/},
  address = {Amsterdam, Países Baixos},
  issn = {1560-4292},
  journal = {International Journal of Artificial Intelligence in Education},
  publisher = {IOS Press}
}

@BOOK{Perraton:2006,
  title = {Open and Distance Learning in the Developing World},
  publisher = {Routledge},
  year = {2006},
  author = {Hilary Perraton},
  isbn = {978-0-415-39398-0},
  e-isbn = {978-0-415-39397-3},
  pages = {256},
  address = USA,
  edition = {2},
  month = nov,
  abstract = {This revised and updated edition of Open and Distance Learning in the Developing World sets the expansion of distance education in the context of general educational change and explores its use for basic and non-formal education, schooling, teacher training and higher education. Engaging with a range of topics, this comprehensive overview includes new material on: non-formal education: mass-communication approaches to education about HIV/AIDS and recent literacy work in India, South Africa, and Zambia; schooling: new research projects in open schooling in Asia and subsaharan Africa, and interactive radio instruction in South Africa; the impact of new technology and globalisation: learning delivered through the internet and mobile learning the political economy: international agencies, the role of private sector, and funding. With its critical appraisal of the facts and examination of data about effectiveness, this book provides answers to problems and poses key questions for the consideration of policy makers, educational practitioners and all professionals involved in implementing and delivering sustainable open and distance learning.},
  booktitle = {Open and Distance Learning in the Developing World}
}

@ARTICLE{perrochon95ram,
  author = {L. Perrochon},
  title = {A reference architecture for multi-author World-Wide Web servers},
  year = {1995},
  pages = {197--205},
  journal = {Proceedings of conference on Organizational computing systems},
  owner = {magsilva},
  publisher = {ACM Press New York, NY, USA},
  timestamp = {2008.07.30}
}

@ARTICLE{perry-kaiser:1990,
  author = {D. E. Perry and G. E. Kaiser},
  title = {Adequate testing and object-oriented programming},
  volume = {2},
  number = {5},
  year = {1990},
  pages = {13-19},
  journal = {Journal on Object-Oriented Programming},
  owner = {magsilva},
  timestamp = {2009.11.10}
}

@BOOK{Peterson81PNTM,
  title = {{P}etri Net Theory and the Modeling of Systems},
  publisher = {Prentice-Hall, Englewood Cliffs},
  year = {1981},
  author = {J. L. Peterson},
  address = {New Jersey},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@ARTICLE{Peterson77PNET,
  author = {J. L. Peterson},
  title = {Petri Nets},
  volume = {9},
  number = {3},
  month = sep,
  year = {1977},
  pages = {223--252},
  journal = {{ACM} Computing Surveys},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@TECHREPORT{Petrenko96FCTF,
  author = {A. Petrenko and G. V. Bochmann},
  title = {On Fault Coverage of Tests for Finite State Specifications},
  institution = {D\'epartement d'Informatique et recherche op\'erationnelle -- Universit\'e de Montr\'eal},
  year = {1996},
  url = {http://www.iro.umontreal.ca/pub/teleinfo/TRs/Petr96b.ps.gz},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@TECHREPORT{Petri:1962,
  author = {Carl Adam Petri},
  title = {Kommunikation mit Automaten},
  institution = {Fachbereich Informatik},
  month = jun,
  year = {1962},
  address = {Alemanha},
  url = {http://epub.sub.uni-hamburg.de/informatik/volltexte/2011/160/},
  abstract-en = {The theory of automata is shown not capable of representing the actual physical flow of information in the solution of a recursive problem. The argument proceeds as follows: 1. We assume the following postulates: a) there exists an upper bound on the speed of signals; b) there exists an upper bound on the density with which information can be stored. 2. Automata of fixed, finite size can recognize, at best, only iteratively defined classes of input sequences. (See Kleene (11) and Copi, Elgot, and Wright (8).) 3. Recursively defined classes of input sequences that cannot be defined iteratively can be recognized only by automata of unbounded size. 4. In order for an automaton to solve a (soluble) recursive problem, the possibility must be granted that it can be extended unboundedly in whatever way might be required. 5. Automata (as actual hardware) formulated in accordance with automata theory will, after a finite number of extensions, conflict with at least one of the postulates named above. Suitable conceptual structures for an exact theory of communication are then discussed, and a theory of communication proposed. All of the really useful results of automata theory may be expressed by means of these new concepts. Moreover, the results retain their usefulness and the new nrocedure has definite advantages over the older ones. The proposed representation differs from each of the presently known theories concerning information on at least one of the following essential points: 1. The existence of a metric is assumed for either space nor time nor for other physical magnitudes. 2. Time is introduced as a strictly local relation between states. 3. The objects of the theory are discrete, and they are combined and produced only by means of strictly finite techniques. The following conclusions drawn from the results of this work may be cited as of some practical interest: 1. The tolerance requirements for the response characteristics of computer components can be substantially weakened if the computer is suitably structured. 2. It is possible to design computers structurally in such a way that they are asynchronous, all parts operating in parallel, and can be extended arbitrarily without interrupting their computation. 3. For complicated organizational processes of any given sort the theory yields a means of representation that with equal rigor and simplicity accomplishes more than the theory of synchronous automata.},
  lang = {de},
  note = {Orientador: A. Walther},
  timestamp = {2012.01.25}
}

@BOOK{Petticrew-Roberts:2006,
  title = {Systematic Reviews in the Social Sciences: A Practical Guide},
  publisher = {Blackwell},
  year = {2006},
  author = {Mark Petticrew and Helen Roberts},
  pages = {336}
}

@ARTICLE{pfaffenseller:2000,
  author = {Moisés Pfaffenseller and Matheus Pfaffenseller and Eduardo Kroth},
  title = {Uma ferramenta de apoio ao gerenciamento de componentes},
  month = jun,
  year = {2001 },
  journal = {Workshop de Desenvolvimento Baseado em Componentes},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@BOOK{pfleeger:2004,
  title = {Engenharia de Software: Teoria e Prática},
  publisher = {Prentice Hall},
  year = {2004},
  author = {Shari Lawrence Pfleeger},
  editor = {Roger Trimer},
  pages = {537},
  address = {São Paulo},
  edition = {2},
  note = {Tradução Dino Franklin; Revisão técnica Ana Regina Cavalcanti da Rocha},
  owner = {magsilva},
  timestamp = {2006.11.09}
}

@ARTICLE{phoha:1997,
  author = {V. Phoha},
  title = {A Standard for Software Documentation},
  volume = {30},
  number = {13},
  year = {1997},
  pages = {97-98},
  journal = {IEEE Computer},
  owner = {magsilva},
  timestamp = {2006.09.20}
}

@BOOK{Piaget:1950,
  title = {The Psychology of Intelligence},
  publisher = {Routledge and Kegan Paul},
  year = {1950},
  author = {Jean Piaget},
  isbn = {0-203-98152-9, 0415-21006-2},
  volume = {26},
  pages = {184},
  series = {Developmental psychology},
  booktitle = {The Psychology of Intelligence},
  notes = {Translated from the French by Malcolm Piercy and D. E. Berlyne}
}

@INPROCEEDINGS{Piccolo-Baranauskas:2006,
  author = {Piccolo, Lara Schibelsky Godoy and Baranauskas, Maria Cecília C.},
  title = {Desafios de design para a TV digital interativa},
  pages = {1--10},
  doi = {10.1145/1298023.1298025},
  abstract = {Taking in account the social relevance of the terrestrial TV in Brazil and the transition to the digital technology - meaning new opportunities for exploring interactivity on TV - this paper is a worldwide review of HCI studies applied to interactive TV. Organizational semiotics artifacts are used in order to identify the main questions related to the interactive TV in the Brazil scene. The main design challenges are also pointed out by this study.},
  keywords = {digital interactive tv, human computer interaction},
  booktitle = {VII Brazilian symposium on Human factors in computing systems},
  isbn = {1-59593-432-4},
  lang = {pt},
  location = {Natal, RN, Brazil},
  month = nov,
  publisher = {ACM},
  year = {2006}
}

@INPROCEEDINGS{Piccolo-etal:2007,
  author = {Lara Schibelsky G. Piccolo and Amanda Meincke Melo and Maria Cecília Calani Baranauskas},
  title = {Accessibility and interactive TV: design recommendations for the Brazilian scenario},
  pages = {361--374},
  doi = {10.1007/978-3-540-74796-3_34},
  abstract = {TV can be regarded as the most far-reaching media in Brazil. Its presence is noticed in 90% of Brazilian homes and it is the main source of information for a major part of the population. The moment of definition and consolidation of the digital TV technology provides us with a unique opportunity for analyzing and discussing this media accessibility. Making sure that TV contents and devices are flexible enough so that people are able to perceive, understand and interact with them is a main asset for its use and an essential requirement for the democratization of information via TV broadcasting. This paper analyzes interactive digital TV accessibility in informal, formal, and technical levels, considering the Brazilian context. In addition, it presents recommendations to design accessible interfaces by referring to the W3C guidelines 2.0 for Web accessibility and specific recommendations for iDTV.},
  keywords = {Accessibility; Interactive digital TV; User Interfaces for All},
  volume = {4662},
  series = {Lecture Notes in Computer Science},
  booktitle = {11th IFIP TC 13 International Conference on Human-Computer Interaction},
  editor = {Cécilia Baranauskas and Philippe Palanque and Julio Abascal and Simone Diniz Junqueira Barbosa},
  isbn = {978-3-540-74794-9},
  issn = {0302-9743},
  location = {Rio de Janeiro, RJ, Brazil},
  month = sep,
  publisher = {Springer},
  timestamp = {2012.02.09},
  year = {2007}
}

@INPROCEEDINGS{pimentel-etal:1997,
  author = {Pimentel, Maria da Graça C. and Baldochi Jr, Laércio and Teixeira, Cesar A. C. and Fagundes, Fabiano},
  title = {Temporal Relations in Multimedia Objects: WWW Presentation from HyTime Specification},
  pages = {84--91},
  doi = {10.1109/PRMNET.1997.638884},
  abstract = {The representation of temporal relations in multimedia objects is based on models of time that allow the identification and the specification of temporal relations among different media, particularly those relations relevant to the process of multimedia synchronization. Initially, this paper discusses the use of HyTime for the specification of binary temporal relations. Next, the paper discusses an approach to the automatic transformation of the HyTime synchronization specifications into elements to be presented in the context of the World Wide Web environment.},
  keywords = {HyTime, Media Scheduling and Synchronization, Synchronization Specification, WWW presentation},
  address = {Washington, DC, USA},
  booktitle = {Proceedings of the IEEE Conference on Protocols for Multimedia Systems - Multimedia Networking (PROMSMmNet'97)},
  isbn = {0-8186-7916-6},
  publisher = {IEEE Computer Society},
  year = {1997}
}

@ARTICLE{Pimentel-etal:2010,
  author = {Pimentel, Maria da Graca Campos and Cattelan, Renan G. and Melo, Erick Lazaro and Prado, Antonio Francisco and Teixeira, Cesar Augusto Camillo},
  title = {End-user live editing of {iTV} programmes},
  volume = {4},
  number = {1},
  month = dec,
  year = {2010},
  pages = {78--103},
  doi = {10.1504/IJAMC.2010.030007},
  abstract = {Watching TV is a practice many people enjoy and feel comfortable with. While watching a TV programme, users can be offered the opportunity to, while making annotations, create their own edited versions of the programme. In this scenario, it is a challenge to allow the user to add comments in a ubiquitous, transparent way. In this paper, we exploit the concept of end-user live editing of interactive video programmes by detailing an environment where users are able to live edit a video using the iTV remote control. We contextualise our approach in the context of the Brazilian Interactive Digital TV platform.},
  keywords = {Brazil, WaC, comment paradigm, interactive TV, interactive television, live video, multimedia document engineering, transparent interactive video, video editing},
  address = {Geneva, } # Switzerland,
  issn = {1462-4613},
  journal = {International Journal of Advanced Media and Communication},
  publisher = {Inderscience}
}

@INPROCEEDINGS{Pimentel:1998,
  author = {Mariano Gomes Pimentel},
  title = {Modelo Orientado a Conceitos {(MOC)}},
  pages = {1-10},
  abstract = {O Modelo Orientado a Conceitos (MOC) objetiva estruturar e sistematizar um conjunto de conceitos presente em um domínio de conhecimento. Este artigo apresenta as notações convencionadas, um exemplo completo de sua utilização, sugestões para a construção de um MOC, e comparações com "Mapas Conceituais" e "Modelo Orientada a Objetos" - modelos estes que serviram de base para a sua criação.},
  abstract-en = {The Concept-Oriented Model (COM) attempts to structure and systemize a set of concepts present in a knowledge domain. This article describes the conventional notations, gives a complete example of its use as well as suggestions on how to work with it. 'Conceptual Maps' and 'Object-Oriented Model' - which led to the creation of COM - are also compared with it.},
  address = {Fortaleza, CE},
  booktitle = {IX Simpósio Brasileiro de Informática na Educação},
  lang = {pt},
  location = {Fortaleza, CE, Brazil},
  month = nov,
  owner = {magsilva},
  timestamp = {2008.07.31},
  url = {http://www.inf.ufsc.br/infoedu/materiais/sbie98/anais/artigos/art23.html},
  year = {1998}
}

@ARTICLE{Pimentel01SLTE,
  author = {M. G. Pimentel and Y. Ishiguro and B. Kerimbaev and G. D. Abowd and M. Guzdial},
  title = {Supporting Long-Term Educational Activities through Dynamic Web Interfaces},
  volume = {13},
  number = {3},
  year = {2001},
  pages = {353--374},
  journal = {Journal Interacting with Computers},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@ARTICLE{pimentel:1998,
  author = {M. G. C. Pimentel and J. B. Santos Jr and R. P. M. Fortes},
  title = {Suporting structured multimedia documents in the World Wide Web},
  volume = {4},
  number = {11},
  year = {1998},
  pages = {825-838},
  journal = {JUCS - Journal of Universal Computer Science},
  owner = {magsilva},
  publisher = {Sprint-Verlag},
  timestamp = {2008.07.30}
}

@INPROCEEDINGS{pimentel-etal:1998,
  author = {M. G. C. Pimentel and J. B. Santos Jr. and R. P. M. Fortes},
  title = {Tools for Authoring and Presenting Structured Teaching Material in the WWW},
  address = {Orlando, FL},
  booktitle = {World Conference of the Web Society},
  month = nov,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1998}
}

@INPROCEEDINGS{Sousa-etal:2005,
  author = {Pimentel de Sousa, V. and Neto, M.M. and Obaid, A. and Agoulmine, N.},
  title = {An API for the discovery of educational content on the Brazilian digital TV},
  pages = {T4B-18 -- T4B-23},
  doi = {10.1109/ITHET.2005.1560260},
  abstract = {Considering the possibilities and strengths of the current telecommunication systems and the associate emergent technologies, it has become imperative to address concerns to open opportunities aiming at popularizing the access to education systems. This work proposes an API architecture to services for the discovery of educational contents using the transmission system to be adopted by the Brazilian standard for the Digital TV.},
  booktitle = {6th International Conference on Information Technology Based Higher Education and Training},
  isbn = {0-7803-9141-1},
  lang = {en},
  month = jul,
  year = {2005}
}

@RESEARCH-PROJECT{project:Pinheiro-Barbosa:2008,
  title = {Objetos de aprendizado como apoio ao ensino de teste de software},
  author = {Arineiza Cristina Pinheiro and Ellen Francine Barbosa},
  institution = {Institute of Mathematics Science and Computing -- University of São Paulo},
  number = {07/58282-0},
  funding = {FAPESP},
  month = jan,
  year = {2008}
}

@PHDTHESIS{pinheiro:2004,
  author = {Valdéres Fernandes Pinheiro},
  title = {Modelo organizacional de ensino a distância para Instituições Tecnológicas},
  school = {Instituto de Pesquisas Energéticas e Nucleares (IPEN)},
  year = {2004},
  month = sep,
  url = {http://www.teses.usp.br/teses/disponiveis/85/85131/tde-05102007-173822/},
  note = {Orientado por José Roberto Rogero, co-orientado por Eduardo Pinheiro Gondim de Vasconcellos},
  timestamp = {2008.09.15}
}

@INPROCEEDINGS{piwowarski-etal:1993,
  author = {Paul Piwowarski and Mitsuru Ohba and Joe Caruso},
  title = {Coverage measurement experience during function test},
  pages = {287--301},
  address = {Baltimore, Maryland, USA},
  booktitle = {International Conference on Software Engineering (ICSE)},
  isbn = {0-89791-588-7},
  location = {Baltimore, Maryland, United States},
  publisher = {IEEE Computer Society Press},
  year = {1993}
}

@MISC{dom2events:2000,
  author = {Tom Pixley},
  title = {Document Object Model (DOM) Level 2 Events Specification},
  howpublished = {W3C Recommendation},
  month = nov,
  year = {2000},
  comment = {24/05/2005},
  file = {Document Object Model (DOM) Level 2 Events Specification.pdf:Document Object Model (DOM) Level 2 Events Specification.pdf:PDF},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://www.w3.org/TR/DOM-Level-2-Events/}
}

@INPROCEEDINGS{Pleuss-Hussmann:2007,
  author = {Pleuss, Andreas and Hussmann, Heinrich},
  title = {Integrating Authoring Tools into Model-Driven Development of Interactive Multimedia Applications},
  pages = {1168-1177},
  doi = {10.1007/978-3-540-73105-4_127},
  abstract = {The Multimedia Modeling Language (MML) is a platform-independent modeling language for model-driven development of interactive multimedia applications. Using models provides several advantages like well-structured applications and better coordination of the different developer groups involved in the development process. However, the creative tasks -- like graphical design of the user interface and the design of media objects -- are better supported by traditional informal methods and tools. In particular multimedia authoring tools such as Adobe Flash are well established for multimedia application development. In this paper we show how MML and authoring tools can be integrated by the example of Flash. Therefore we transform the MML models into code skeletons which can be directly loaded into the Flash authoring tool to perform the creative design tasks and finalize the application. In that way, the strengths of models and authoring tools are combined. The paper shows the required level of abstraction for the models, introduces a metamodel and a suitable code structure for the Flash platform, and finally presents the transformation.},
  volume = {4550},
  series = {Lecture Notes in Computer Science},
  affiliation = {Department of Computer Science, University of Munich, Munich Germany},
  booktitle = {International Conference on Human-Computer Interaction},
  editor = {Jacko, Julie},
  isbn = {978-3-540-73104-7},
  keyword = {Computer Science},
  publisher = {Springer},
  year = {2007}
}

@BOOK{pohl-etal:2005,
  title = {Software Product Line Engineering: Foundations, Principles, and Techniques},
  publisher = {Springer},
  year = {2005},
  author = {Klaus Pohl and Günter Böckle and Frank van der Linden},
  number = {467},
  address = {Germany},
  owner = {magsilva},
  timestamp = {2010.07.09}
}

@TECHREPORT{PomeroyHuff-etal:2009,
  author = {Marsha Pomeroy-Huff and Robert Cannon and Timothy A. Chick and Julia L. Mullaney and William Nichols},
  title = {The {Personal Software Process} ({PSP}) Body of Knowledge, Version 2.0},
  institution = {Software Engineering Institute},
  month = aug,
  year = {2009},
  number = {CMU/SEI-2009-SR-018},
  address = {Pittsburgh, PA, } # USA,
  url = {http://resources.sei.cmu.edu/library/asset-view.cfm?assetID=8907},
  abstract = {As the profession of software engineering evolves and matures, it must achieve some of the critical elements needed for recognition as a bona fide discipline. Among these elements are the establishment of a recognized body of knowledge (BOK) and certification of professional practitioners. The body of knowledge contained in this report is designed to complement the IEEE Computer Society's Software Engineering Body of Knowledge (SWEBOK) by delineating the skills and concepts that compose the knowledge areas and competencies of a proven-effective process improvement method, the Personal Software Process (PSP). As adoption of the PSP methodology continues to grow, it becomes crucial to document the fundamental knowledge and skills that set PSP practitioners apart from other software professionals. The PSP BOK serves this purpose and more. It helps individual practitioners to assess and improve their own skills; provides employers with an objective baseline for assessing the personal process skills and capabilities of their product development team members; and guides academic institutions that want to incorporate PSP into their software and other engineering courses or curricula. The PSP BOK also facilitates the development of PSP certification programs that are based on a well-established, standard set of knowledge and skills.},
  owner = {magsilva},
  timestamp = {2014.09.29}
}

@TECHREPORT{PomeroyHuff-etal:2005,
  author = {Marsha Pomeroy-Huff and Julia L. Mullaney and Robert Cannon and Mark Sebern},
  title = {The {Personal Software Process} ({PSP}) Body of Knowledge, Version 2.0},
  institution = {Software Engineering Institute},
  month = aug,
  year = {2005},
  number = {CMU/SEI-2005-SR-003},
  address = {Pittsburgh, PA, } # USA,
  url = {http://resources.sei.cmu.edu/library/asset-view.cfm?assetID=8907},
  abstract = {As the profession of software engineering evolves and matures, it must achieve some of the critical elements needed for recognition as a bona fide discipline. Among these elements are the establishment of a recognized body of knowledge (BOK) and certification of professional practitioners. The body of knowledge contained in this report is designed to complement the IEEE Computer Society's Software Engineering Body of Knowledge (SWEBOK) by delineating the key skills and concepts that compose the knowledge areas and competencies of a proven-effective process improvement method, the Personal Software Process (PSP). As adoption of the PSP methodology continues to grow, it becomes crucial to document the fundamental knowledge and skills that set PSP practitioners apart from other software engineers. The PSP BOK serves this purpose and more. It helps individual practitioners to assess and improve their own skills; provides employers with an objective baseline for assessing the personal process skills and capabilities of their engineers and product development teams; and guides academic institutions that want to incorporate PSP into their software and other engineering courses or curricula. The PSP BOK also facilitates the development of PSP certification programs that are based on a well-established, standard set of knowledge and skills.},
  owner = {magsilva},
  timestamp = {2014.09.29}
}

@ARTICLE{porter-johnson:1997,
  author = {Porter, A.A. and Johnson, P.M.},
  title = {Assessing software review meetings: results of a comparative analysis of two experimental studies},
  volume = {23},
  number = {3},
  month = mar,
  year = {1997},
  pages = {129 -145},
  doi = {10.1109/32.585501},
  abstract = {Software review is a fundamental tool for software quality assurance. Nevertheless, there are significant controversies as to the most efficient and effective review method. One of the most important questions currently being debated is the utility of meetings. Although almost all industrial review methods are centered around the inspection meeting, recent findings call their value into question. In prior research the authors separately and independently conducted controlled experimental studies to explore this issue. The paper presents new research to understand the broader implications of these two studies. To do this, they designed and carried out a process of ldquo;reconciliation rdquo; in which they established a common framework for the comparison of the two experimental studies, reanalyzed the experimental data with respect to this common framework, and compared the results. Through this process they found many striking similarities between the results of the two studies, strengthening their individual conclusions. It also revealed interesting differences between the two experiments, suggesting important avenues for future research.},
  keywords = {inspection meeting;reconciliation;software quality assurance;software review meeting assessment;inspection;software development management;software quality;},
  issn = {0098-5589},
  journal = {IEEE Transactions on Software Engineering}
}

@ARTICLE{porto-berge:2008,
  author = {Stella C. S. Porto and Zane L. Berge},
  title = {Distance Education and Corporate Training in Brazil: Regulations and Interrelationships},
  volume = {9},
  number = {2},
  month = jun,
  year = {2008},
  url = {http://www.irrodl.org/index.php/irrodl/article/view/478/1033},
  journal = {The International Review of Research in Open and Distance Learning},
  owner = {magsilva},
  timestamp = {2009.02.20}
}

@ARTICLE{Poston94ATOM,
  author = {R. M. Poston},
  title = {Automated Testing from Object Models},
  volume = {37},
  number = {9},
  month = sep,
  year = {1994},
  pages = {48--58},
  journal = comacm,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{potdar:2004,
  author = {Vidyasagar Potdar and Elizabeth Chang},
  title = {Open Source vs Closed Source},
  pages = {14-17},
  address = {Porto, Portugal},
  booktitle = {International Conference on Enterprise Information Systems (ICEIS 2004)},
  owner = {Marco Aurélio Graciotto Silva},
  timestamp = {2008.07.30},
  year = {2004}
}

@INPROCEEDINGS{leite:2001,
  author = {Julio Cesar Sampaio do Prado Leite},
  title = {Extreme Requirements},
  address = {Sevilla},
  booktitle = {Jornadas de Ingeniería de Requisitos Aplicada},
  month = jun,
  owner = {magsilva},
  timestamp = {2008.07.30},
  year = {2001}
}

@MISC{leite:2001:1,
  author = {Julio Cesar Sampaio do Prado Leite},
  title = {Slides do Minicurso de Engenharia de Requisitos},
  howpublished = {V Semana da Computação - ICMC/USP},
  year = {2001},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@INPROCEEDINGS{leite-franco:1993,
  author = {Julio Cesar Sampaio do Prado Leite and Ana Paula M. Franco},
  title = {A strategy for conceptual model acquisition},
  pages = {243-246},
  booktitle = {IEEE International Symposium on Requirements Engineering},
  journal = {R},
  month = jan,
  owner = {magsilva},
  timestamp = {2008.07.30},
  year = {1993}
}

@ARTICLE{leite:1991,
  author = {Julio Cesar Sampaio do Prado Leite and Peter A. Freeman},
  title = {Requirements Validation Through Viewpoint Resolution},
  volume = {17},
  number = {12},
  month = dec,
  year = {1991},
  pages = {1253-1269},
  journal = {IEEE Transactions on Software Engineering},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@INPROCEEDINGS{leite:1997,
  author = {Julio Cesar Sampaio do Prado Leite and Gustavo Rossi and Federico Balaguer and Vanesa Maiorana and Gladys Kaplan and Graciela Hadad and Alejandro Oliveros},
  title = {Enhancing a Requirements Baseline with Scenarios},
  pages = {44},
  booktitle = {IEEE International Symposium on Requirements Engineering},
  journal = {Requirements Engineering Journal},
  owner = {magsilva},
  publisher = {IEEE Computer Society},
  timestamp = {2008.07.30},
  year = {1997}
}

@INPROCEEDINGS{prata-etal:2010a,
  author = {Prata, Alcina and Chambel, Teresa and Guimarães, Nuno},
  title = {Generation of crossmedia dynamic learning contexts from iTV},
  pages = {91--100},
  doi = {10.1145/1809777.1809798},
  abstract = {Tendencies in convergence, integration and co-existence of several media technologies are creating new opportunities for the globalization of learning practices. Simultaneously, the lifelong learning phenomena, which will take place in a wide variety of contexts and locations, call for flexible environments. iTV holds a great potential in this scenario, but there is still limited research in terms of cognitive and interaction aspects. This paper presents a new paradigm to generate crossmedia dynamic learning contexts from iTV with the aim to link the mentioned opportunities in flexible, adequate and effective learning contexts. In order to better illustrate this paradigm an iTV system, (e-iTV), was designed. The system generates, via iTV, Crossmedia Online Personalized Learning Environments, also designated as COPLE or web lessons, accessible from several types of devices. The system is prepared to respond to communication needs of the viewers since and allows them to share their web lesson. In practical terms, the e-iTV system uses the TV set, not as the final medium, but as a starting point to new crossmedia dynamic learning and communications contexts. The motivations and goals of this work are presented, followed by a review of related work and concepts and the presentation of the conceptual framework. A description of the analysis, planning, development and evaluation of the e-iTV system is presented based on a specific HCI based model. The paper concludes by opening perspectives for future research and developments.},
  keywords = {crossmedia, crossmedia learning environments, hci, itv, itv interaction, itv learning, itv service, personalized web lessons},
  address = {New York, NY, USA},
  booktitle = {8th international interactive conference on Interactive TV\&\#38;Video},
  isbn = {978-1-60558-831-5},
  location = {Tampere, Finland},
  numpages = {10},
  publisher = {ACM},
  year = {2010}
}

@INPROCEEDINGS{prata-etal:2010b,
  author = {Prata, Alcina and Guimarães, Nuno and Chambel, Teresa},
  title = {Crossmedia personalized learning contexts},
  pages = {305--306},
  doi = {10.1145/1810617.1810687},
  abstract = {The trends in convergence, integration and co-existence of various media technologies are creating new opportunities for the globalization of learning practices. The emerging era of lifelong learning is calling for flexible environments. Interactive television (iTV) holds a great potential in this scenario, but there is still limited research in terms of cognitive and interaction aspects. With the aim to link these opportunities, in flexible, adequate and effective learning contexts, a new paradigm to generate crossmedia personalized learning contexts from iTV, based on cognitive and affective aspects, is being studied. This paper presents the results obtained from the use of the e-iTV system, designed to illustrate and explore this paradigm.},
  keywords = {crossmedia learning environments, educational hypermedia, human-computer interaction, iTV, personalized web content},
  series = {HT '10},
  acmid = {1810687},
  address = {New York, NY, USA},
  booktitle = {Proceedings of the 21st ACM conference on Hypertext and hypermedia},
  isbn = {978-1-4503-0041-4},
  location = {Toronto, Ontario, Canada},
  numpages = {2},
  publisher = {ACM},
  year = {2010}
}

@INPROCEEDINGS{Prata-etal:2010c,
  author = {Prata, Alcina and Guimarães, Nuno and Chambel, Teresa},
  title = {Designing {iTV} based crossmedia personalized informal learning contexts},
  pages = {187--194},
  doi = {10.1145/1930488.1930528},
  abstract = {Crossmedia systems are becoming increasingly popular. The trends in convergence, integration and co-existence of various media technologies create new opportunities for the generalization of formal and informal learning practices, which are becoming more relevant considering the importance of lifelong learning. Video is a very rich medium to support learning, and TV is a privileged way to access it. By itself, broadcast TV provides limited support to learning processes. But, through structure and interaction, iTV can open the door to flexible environments that can access video and integrate it with different media, accessible from different devices, adequate to support different cognitive modes and learning processes in several learning contexts. In spite of the valuable potential of crossmedia systems to create rich and flexible environments, the design of these systems faces some challenges that may affect their effective use. This paper addresses the effective design of crossmedia personalized informal learning contexts from iTV, through the e-iTV system case study, designed to illustrate and explore this paradigm based on cognitive and affective aspects that influence user experience.},
  keywords = {HCI, crossmedia, design, iTV, interaction, learning, video},
  address = {New York, NY, USA},
  booktitle = {14th International Academic MindTrek Conference: Envisioning Future Media Environments},
  isbn = {978-1-4503-0011-7},
  location = {Tampere, Finland},
  publisher = {ACM},
  year = {2010}
}

@BOOK{Prata-Nascimento:2007,
  title = {Objetos de aprendizagem: uma proposta de recurso pedagógico},
  publisher = {Ministério da Educação},
  year = {2007},
  author = {C. L. Prata and A. C. A. A. Nascimento},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@ARTICLE{Prates:2009,
  author = {Raquel Prates},
  title = {Dedicação à Pequisa},
  number = {11},
  month = oct # {-} # dec,
  year = {2009},
  pages = {4-5},
  journal = {Computação Brasil},
  owner = {magsilva},
  timestamp = {2010.09.13}
}

@BOOK{Pressman:1997,
  title = {Software Engineering: A Practitioner's Approach},
  publisher = {McGraw-Hill},
  year = {1997},
  author = {Roger S. Pressman},
  editor = {Eric M. Munson},
  edition = {4},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@BOOK{Pressman:2005,
  title = {Software engineeering: a practioner's approach},
  publisher = {McGraw-Hill},
  year = {2005},
  author = {Pressman, Roger S.},
  pages = {880},
  address = {Boston, EUA},
  edition = {6},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@BOOK{Pressman:2002,
  title = {Engenharia de Software},
  publisher = {McGraw-Hill},
  year = {2002},
  author = {Roger S. Pressman},
  address = {Rio de Janeiro, RJ, Brazil},
  edition = {5},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@BOOK{Pressman:2000,
  title = {Software engineeering: a practioner's approach},
  publisher = {McGraw-Hill},
  year = {2000},
  author = {Pressman, Roger S.},
  address = {Boston, EUA},
  edition = {5},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@BOOK{Pressman:1995,
  title = {Engenharia de Software},
  publisher = {Makron Books do Brasil},
  year = {1995},
  author = {Roger S. Pressman},
  isbn = {85-346-0237-9},
  volume = {1},
  pages = {1056},
  address = {São Paulo, SP, } # Brazil,
  edition = {3},
  booktitle = {Engenharia de Software},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@BOOK{Pressman:1992,
  title = {Software Engineering -- A Practitioner's Approach},
  publisher = {McGraw-Hill},
  year = {1992},
  author = {R. S. Pressman},
  edition = {3},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{Price90VFCP,
  author = {A. M. Price and A. Zorzo},
  title = {Visualizando o Fluxo de Controle de Programas},
  address = {Águas de São Pedro, SP},
  booktitle = {IV Simpósio Brasileiro de Engenharia de Software (SBES 90)},
  month = oct,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1990}
}

@INPROCEEDINGS{probert-guo:1991,
  author = {R. L. Probert and F. Guo},
  title = {Mutation Testing of Protocols: Principles and Preliminary Experimental Results},
  pages = {57--76},
  booktitle = {Third International Workshop on Protocol Test Systems (IFIP TC6)},
  owner = {magsilva},
  publisher = {North-Holland},
  timestamp = {2008.07.31},
  year = {1991}
}

@TECHREPORT{projetoH264Setup:2010,
  author = {{Projeto H.264-SETUP}},
  title = {Linhas Mestras para Operação e Configuração de Sistemas Compressão de Vídeo para o SBTVD},
  institution = {IME, UERJ, UFRJ, UnB},
  month = nov,
  year = {2010},
  url = {http://www02.lps.ufrj.br/~tvdigital/h264setup/},
  lang = {pt},
  timestamp = {2012.02.04}
}

@MISC{project:tidia,
  author = {{Projeto TIDIA (FAPESP)}},
  title = {Programa de Tecnologia da Informação no Desenvolvimento da Internet Avançada},
  year = {2006},
  owner = {magsilva},
  timestamp = {2007.07.31},
  url = {http://www.tidia.fapesp.br/portal}
}

@MISC{project:tidia-ae,
  author = {{Projeto TIDIA-Ae}},
  title = {{TIDIA Ae: Aprendizado Eletrônico na Internet Avançada}},
  year = {2005},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@MISC{pucrs:estatuto,
  author = {{PUCRS}},
  title = {Estatuto da PUCRS},
  month = sep,
  year = {2006},
  owner = {magsilva},
  timestamp = {2010.06.21},
  url = {http://www3.pucrs.br/portal/page/portal/pucrs/Capa/AUniversidade/EstatutoRegimentoGeral/Estatuto}
}

@BOOK{pula:1968,
  title = {Application and operation of audiovisual equipment in education},
  publisher = {John Wiley \& Sons, Inc.},
  year = {1968},
  author = {Fred John Pula},
  owner = {magsilva},
  timestamp = {2008.01.24}
}

@INPROCEEDINGS{pullen:2006,
  author = {J. Mark Pullen},
  title = {Scaling Up a Distance Education Program in Computer Science},
  pages = {33-37},
  address = {Bologna, Italy},
  booktitle = {ITiCSE'06},
  owner = {magsilva},
  publisher = {ACM},
  timestamp = {2008.09.03},
  year = {2006}
}

@ARTICLE{punter:2004,
  author = {Teade Punter and Rob Kusters and Jos Trienekens and Theo Bemelmans and Aarnout Brombacher},
  title = {The W-Process for Software Product Evaluation: A Method for Goal-Oriented Implementation of the ISO 14598 Standard},
  volume = {12},
  number = {2},
  month = {aug},
  year = {2004},
  pages = {137-158},
  doi = {10.1023/B:SQJO.0000024060.32026.a2},
  journal = {Software Quality Control},
  owner = {magsilva},
  timestamp = {2006.08.22}
}

@MISC{puschitz:2006,
  author = {Werner Puschitz},
  title = {Securing and Hardening Linux Production Systems: A Practical Guide to Basic Linux Security in Production Enterprise Environments},
  howpublished = {Artigo},
  year = {2006},
  owner = {magsilva},
  timestamp = {2006.07.06}
}

@INPROCEEDINGS{qin-hernandez:2004,
  author = {Jian Qin and Naybell Hernández},
  title = {Ontological representation of learning objects: building interoperable vocabulary and structures},
  pages = {348--349},
  doi = {10.1145/1013367.1013469},
  address = {New York, NY, USA},
  booktitle = {WWW Alt. '04: Proceedings of the 13th international World Wide Web conference on Alternate track papers \& posters},
  isbn = {1-58113-912-8},
  location = {New York, NY, USA},
  publisher = {ACM},
  year = {2004}
}

@ARTICLE{osirix:2000,
  author = {Auguste Rabarijaona and Rose Dieng and Olivier Corby and Rajae Ouaddari},
  title = {Building and Searching an XML-Based Corporate Memory},
  month = may,
  year = {2000},
  pages = {56-63},
  journal = {IEEE Intelligent Systems},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@MISC{html4:1999,
  author = {Dave Raggett and Arnaud Le Hors and Ian Jacobs},
  title = {HTML 4.01 Specification},
  howpublished = {W3C Recommendation},
  month = dec,
  year = {1999},
  comment = {24/05/2005},
  file = {HTML 4.01 Specification.pdf:HTML 4.01 Specification.pdf:PDF},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://www.w3.org/TR/html4}
}

@ARTICLE{ramesh:2001,
  author = {Balasubramaniam Ramesh and Matthias Jarke},
  title = {Toward Reference Models for Requirements Traceability},
  volume = {27},
  number = {1},
  month = {jan},
  year = {2001},
  pages = {58-93},
  journal = {IEEE Transactions on Software Engineering},
  owner = {Marco Aurélio Graciotto Silva},
  timestamp = {2008.07.30}
}

@ARTICLE{rapps-weyuker:1985,
  author = {Sandra Rapps and Elaine J. Weyuker},
  title = {Selecting software test data using data flow information},
  volume = {11},
  number = {4},
  month = apr,
  year = {1985},
  pages = {367-375},
  doi = {10.1109/TSE.1985.232226},
  abstract = {This paper defines a family of program test data selection criteria derived from data flow analysis techniques similar to those used in compiler optimization. It is argued that currently used path selection criteria, which examine only the control flow of a program, are inadequate quate. Our procedure associates with each point in a program at which a variable is defined, those points at which the value is used. Several test data selection criteria, differing in the type and number of these associations, are defined and compared.},
  journal = {IEEE Transactions on Software Engineering},
  owner = {magsilva},
  timestamp = {2009.04.29}
}

@INPROCEEDINGS{rapps-weyuker:1982,
  author = {Sandra Rapps and Elaine J. Weyuker},
  title = {Data Flow Analysis Techniques for Program Test Data Selection},
  pages = {272--278},
  address = {Tokyo, Japan},
  booktitle = {6th International Conference on Software Engineering},
  month = sep,
  owner = {magsilva},
  publisher = {IEEE Computer Society Press},
  timestamp = {2008.07.31},
  year = {1982}
}

@MISC{rasch:2000,
  author = {Chris Rasch},
  title = {A Brief History of Free/Open Source Software Movement},
  howpublished = {Web site},
  month = dec,
  year = {2000},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://www.openknowledge.org/writing/open-source/scb/brief-open-source-history.html}
}

@MISC{Rational00RPCO,
  author = {{RATIONAL Software Corporation}},
  title = {{P}ure{C}overage},
  year = {2000},
  owner = {magsilva},
  timestamp = {2008.07.31},
  url = {ftp://ftp.rational.com/exchange/outgoing/devtools/nt/coverage65.exe}
}

@MISC{Rational00RPUR,
  author = {{RATIONAL Software Corporation}},
  title = {{P}urify},
  year = {2000},
  owner = {magsilva},
  timestamp = {2008.07.31},
  url = {ftp://ftp.rational.com/exchange/outgoing/devtools/nt/purify65.exe}
}

@INPROCEEDINGS{Rawlings-etal:2002,
  author = {Adrian Rawlings and Peter van Rosmalen and Rob Koper and Miguel Rodríguez-Artacho and Paul Lefrere},
  title = {Survey of Educational Modelling Languages ({EMLs})},
  abstract = {This survey and analysis of EMLs is a project of the CEN/ISSS Workshop on Learning Technologies (WS-LT). The purpose is to arrive at a CEN/ISSS Workshop Agreement (CWA) for EML that could eventually be passed on for consideration as part of the regular standardization work. The kick-off meeting took place in Torino in October 2001, at which there were 49 participants. A number of EMLs and other systems were presented, and a draft framework for the analysis was drawn up, and this was used as the basis for a questionnaire that was completed by participants at the meeting. Responses to this questionnaire were brought together in a draft report (version b), which was presented at a meeting in Berlin on 30th November 2001. The purpose of the meeting to get a consensus as to what should be considered for inclusion in the CWA. The findings from the questionnaire and this meeting were incorporated in version h of the report. An overview and the conclusion of version h was presented and discussed at a meeting in Brussels on 2nd July 2002. This version, the final one, incorporates the comments on this version and some minor editorial changes.},
  booktitle = {CEN/ISSS Workshop on Learning Technologies (WS/LT)},
  month = sep,
  owner = {magsilva},
  url = {http://www.cenorm.be/cenorm/businessdomains/businessdomains/isss/activity/emlsurveyv1.pdf},
  year = {2002}
}

@BOOK{raymond:1997,
  title = {The Cathedral and the Bazaar},
  year = {1997},
  author = {Eric Steven Raymond},
  edition = {1},
  month = feb,
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://www.catb.org/~esr/writings/cathedral-bazaar/}
}

@INPROCEEDINGS{recchioni-etal:2007,
  author = {Recchioni, Marco and Casalino, Nunzio and Castello, Valentina and Roscani, Maurizio},
  title = {An innovative training system by digital terrestrial television: TSC-learning},
  pages = {537--542},
  abstract = {The term digital video broadcasting (DVB) is today used as a synonym for digital television in many countries. Digital Terrestrial Television (DTT) is an implementation of digital technology to provide a greater number of channels, a better quality of picture and sound through a conventional antenna instead of a satellite dish or cable connection. Digital television isn't just an innovative signal representation; it represents a new multiple-channel data broadcasting that affect not only the technology side but also the content itself. Within this framework, the T-Learning (Television-Learning) has reached a considerable importance in the last years and is emerging as a potentially important media to create opportunities for learning at home. The main aim of the paper is to describe a system to provide the use of a Learning Management System (LMS) on digital-terrestrial platform, respecting the reference standards (SCORM, IMS, AICC, LOM, etc.). This innovative system allows users to get learning services at home, using a LMS that has to meet a number of requirements, including the integration of a multiplicity of contents.},
  keywords = {DVB-T, IDTV, T-learning, digital divide, learning management system (LMS), two ways digital terrestrial television (DTT)},
  acmid = {1323254},
  address = {Anaheim, CA, USA},
  booktitle = {Proceedings of the sixth conference on IASTED International Conference Web-Based Education - Volume 2},
  location = {Chamonix, France},
  numpages = {6},
  publisher = {ACTA Press},
  url = {http://portal.acm.org/citation.cfm?id=1323159.1323254},
  year = {2007}
}

@INPROCEEDINGS{Redeker:2003,
  author = {Giselher H. J. Redeker},
  title = {An educational taxonomy for learning objects},
  pages = {250 - 251},
  doi = {10.1109/ICALT.2003.1215068},
  abstract = {Current discussions within the standardization process of learning technology are mainly focused on economical opportunities and technical aspects of so called learning objects. Surprisingly little discussion is about instructional or didactical issues. The main purpose is to conceptualize a didactical taxonomy of learning objects and a didactical metadata approach for the facilitation of reusable instructional navigation patterns.},
  keywords = {didactical metadata approach; educational taxonomy; learning technology; reusable instructional navigation pattern; Internet; distance learning; educational technology; meta data},
  address = {Athens, } # Greece,
  booktitle = {International Conference on Advanced Learning Technologies},
  isbn = {0-7695-1967-9},
  month = jul,
  publisher = {IEEE},
  year = {2003}
}

@ARTICLE{regli:2000,
  author = {William C. Regli and Xiaochun Hu and Michael Atwood and Wei Sun},
  title = {A Survey of Design Rationale Systems: Approaches, Representation, Capture and Retrieval},
  volume = {16},
  month = jan,
  year = {2000},
  pages = {209-235},
  journal = {Engineering with Computers: An Int'l Journal for Simulation-Based Engineering},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@ARTICLE{reifer:2000,
  author = {Donald J. Reifer},
  title = {Requirements Management: The Search for Nirvana},
  volume = {17},
  number = {3},
  month = {may},
  year = {2000},
  pages = {45-47},
  journal = {IEEE Software},
  owner = {Marco Aurélio Graciotto Silva},
  timestamp = {2008.07.30}
}

@MASTERSTHESIS{reis:2003,
  author = {Christian Robottom Reis},
  title = {Caracterização de um Modelo de Processo para Projetos de Software Livre},
  school = {Universidade de São Paulo},
  year = {2003},
  address = {São Carlos, São Paulo},
  month = feb,
  howpublished = {Monografia de Qualificação de Mestrado},
  note = {Orientadora: Renata Pontin de Mattos Fortes},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@MISC{reis:2001,
  author = {Christian Robottom Reis},
  title = {Caracterização de um Processo de Software para Projetos de Software Livre},
  howpublished = {Monografia de Qualificação de Mestrado},
  month = jun,
  year = {2001},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@INPROCEEDINGS{Reis-Fortes:2002,
  author = {Christian Robottom Reis and Renata Pontin Mattos Fortes},
  title = {An Overview of the Software Engineering Process and Tools in the Mozilla Project},
  pages = {155--175},
  abstract = {The Mozilla Project is an Open Source Software project which is dedicated to development of the Mozilla Web browser and application framework. Possessing one of the largest and most complex communities of developers among Open Source projects, it presents interesting requirements for a software process and the tools to support it. Over the past four years, process and tools have been refined to a point where they are both stable and effective in serving the project's needs. This paper describes the software engineering aspect of a large Open Source project. It also covers the software engineering tools used in the Mozilla Project, since the Mozilla process and tools are intimately related. These tools include Bugzilla, a Web application designed for bug tracking, bug triage, code review and correction; Tinderbox, an automated build and regression testing system; Bonsai, a tool which performs queries to the CVS code repository; and LXR, a hypertext-based source code browser.},
  keywords = {open source software, free software, software engineering, software process, software engineering tools, bug tracking, nightly builds, code versioning},
  address = {Newcastle, UK},
  booktitle = {Workshop on Open Source Software Development},
  month = feb,
  year = {2002}
}

@INPROCEEDINGS{reis:2002:1,
  author = {Tiago P. C. Reis and Jaelson F. B. Castro e Luis A. Olsina},
  title = {Medição de Qualidade de Aplicações Web na Fase de Requisitos},
  pages = {162-174},
  address = {Gramado, Rio Grande do Sul, Brasil},
  booktitle = {XVI Simpósio Brasileiro de Engenharia de Software},
  editor = {Leila Ribeiro},
  month = oct,
  organization = {PUCRS, UCS, UFGRS, ULBRA, UNISC, UNISINOS},
  owner = {magsilva},
  timestamp = {2008.07.30},
  year = {2002}
}

@ARTICLE{reiss:2007,
  author = {David Reiss},
  title = {Video-based multimedia designs: A research study testing learning effectiveness},
  volume = {33},
  number = {3},
  year = {2007},
  url = {http://www.cjlt.ca/index.php/cjlt/article/view/164/154},
  journal = {Canadian Journal of Learning and Technology},
  owner = {magsilva},
  timestamp = {2009.02.20}
}

@INPROCEEDINGS{Reitz-Hoffmann:2010,
  author = {Reitz, Florian and Hoffmann, Oliver},
  title = {An analysis of the evolving coverage of computer science sub-fields in the DBLP digital library},
  pages = {216--227},
  doi = {10.1007/978-3-642-15464-5_23},
  abstract = {Many scientists and research groups make use of the DBLP bibliographic project collection in various ways. Most of them are unaware of its internal structure, although it can have significant influence on their results. Prior work has shown that the collection does not cover all sub-fields of computer science in the same quality but has not provided an explanation for these differences. We introduce an extension of the DBLP data set which gives us a detailed picture on how DBLP has evolved since 1995. We show that the project started with a narrow focus on two sub-fields and discuss how additional themes have been added in recent years.We analyze the relations between sub-fields at different times and provide a model which explains the differences in coverage.},
  volume = {6273/2010},
  series = {Lecture Notes in Computer Science},
  acmid = {1887791},
  address = {Berlin, Heidelberg},
  booktitle = {European Conference on Research and Advanced Technology for Digital Libraries},
  isbn = {3-642-15463-8, 978-3-642-15463-8},
  location = {Glasgow, UK},
  numpages = {12},
  publisher = {Springer-Verlag},
  year = {2010}
}

@INPROCEEDINGS{Retzinger:2009,
  author = {Retzinger, Katie},
  title = {Confounding definitions: using a continuum to understand interactivity},
  pages = {245--250},
  doi = {10.1145/1621995.1622044},
  abstract = {The term interactivity is used in many disciplines, including communication, professional/technical writing, new media, computer science, and marketing to describe a specific feature of different types of texts. However, little consensus has been achieved as to what interactivity actually is or can be. Using and categorizing definitions of interactivity from the fields of new media, computer science, communication, and advertising in order to begin to conceptualize interactivity, this paper will argue that rather than coming up with a single definition of interactivity that can be used in multiple disciplines, interactivity should be conceptualized along a continuum. By conceptualizing the term interactivity along a continuum, practitioners and instructors can be better able to use the term interactivity more productively, which can help practitioners and instructors who create or who teach others how to create interactive documents have a more generally agreed upon meaning that will further the ability to produce texts appropriate for an audience, purpose, and context.},
  keywords = {active, continuum, control, interaction, interactivity, passive, time, user-to-documents, user-to-system, user-to-user},
  series = {SIGDOC '09},
  acmid = {1622044},
  address = {New York, NY, USA},
  booktitle = {Proceedings of the 27th ACM international conference on Design of communication},
  isbn = {978-1-60558-559-8},
  lang = {en},
  location = {Bloomington, Indiana, USA},
  numpages = {6},
  publisher = {ACM},
  year = {2009}
}

@ARTICLE{Reylopez-etal:2007,
  author = {Rey-Lopez, Marta and Diaz-Redondo, Rebeca P. and Fernandez-Vilas, Ana and Pazos-Arias, Jose J.},
  title = {Entercation: engaging viewers in education through {TV}},
  volume = {5},
  number = {2},
  month = apr,
  year = {2007},
  pages = {7},
  doi = {10.1145/1279540.1279547},
  abstract = {IDTV (interactive digital TV) opens new learning opportunities where new forms of education are needed. In order to gain the participation of viewers, and overcome their typical passivity, it is essential to combine education and entertainment. In this article we present a new concept in t-learning, called entercation experiences, where we use TV programs as a hook to engage users in education. The key element in this approach is an ontology for learning content based on the ADL SCORM (Sharable Content Object Reference Model) standard. We have developed this ontology so that we can choose the appropriate elements to construct entercation experiences, and thus provide learning personalization.},
  keywords = {ADL SCORM, intelligent tutoring systems, t-learning},
  acmid = {1279547},
  address = {New York, NY, EUA},
  articleno = {7},
  issn = {1544-3574},
  issue = {2},
  journal = {Computers in Entertainment},
  publisher = {ACM}
}

@ARTICLE{ReyLopez-etal:2008,
  author = {Rey-López, Marta and Díaz-Redondo, Rebeca P. and Fernández-Vilas, Ana and Pazos-Arias, José J. and López-Nores, Martín and García-Duque, Jorge and Gil-Solla, Alberto and Ramos-Cabrer, Manuel},
  title = {T-MAESTRO and its authoring tool: using adaptation to integrate entertainment into personalized t-learning},
  volume = {40},
  number = {3},
  month = dec,
  year = {2008},
  pages = {409--451},
  doi = {10.1007/s11042-008-0213-4},
  abstract = {Interactive Digital TV opens new learning possibilities where new forms of education are needed. On the one hand, the combination of education and entertainment is essential to boost the participation of viewers in TV learning (t-learning), overcoming their typical passiveness. On the other hand, researchers broadly agree that in order to prevent the learner from abandoning the learning experience, it is necessary to take into account his/her particular needs and preferences by means of a personalized experience. Bearing this in mind, this paper introduces a new approach to the conception of personalized t-learning: edutainment and entercation experiences. These experiences combine TV programs and learning contents in a personalized way, with the aim of using the playful nature of TV to make learning more attractive and to engage TV viewers in learning. This paper brings together our work in constructing edutainment/entercation experiences by relating TV and learning contents. Taking personalization one step further, we propose the adaptation of learning contents by defining A-SCORM (Adaptive-SCORM), an extension of the ADL SCORM standard. Over and above the adaptive add-ons, this paper focuses on two fundamental entities for the proposal: (1) an Intelligent Tutoring System, called T-MAESTRO, which constructs the t-learning experiences by applying semantic knowledge about the t-learners; and (2) the authoring tool which allow teachers to create adaptive courses with a minimal technical background.},
  keywords = {Adaptation, Edutainment, Personalization, SCORM, T-learning},
  address = {Hingham, MA, USA},
  issn = {1380-7501},
  journal = {Multimedia Tools and Applications},
  publisher = {Kluwer Academic}
}

@BOOK{rezende2005sif,
  title = {Sistemas inteligentes: fundamentos e aplicações},
  publisher = {Manole},
  year = {2005},
  author = {S. O. Rezende and others},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@INPROCEEDINGS{riaz-etal:2010,
  author = {Mehwish Riaz and Muhammad Sulayman and Norsaremah Salleh and Emilia Mendes},
  title = {Experiences Conducting Systematic Reviews from Novices' Perspective},
  abstract = {A systematic review (SR) is a sound methodology for collecting evidence on a research topic of interest and establishing the context of future research. Unlike ordinary or even expert literature reviews, SRs are systematic thus increasing the confidence in the findings from the previous published literature. SRs can be carried out by both experienced and novice researchers; however, while expert researchers' experiences with conducting SRs are important for improving the SR body of knowledge, we believe that novice researchers' experiences are equally important to establish what distinct problems they face while carrying out SRs. With a prior knowledge of these issues, novice researchers can better plan their SRs and seek guidance from expert researchers. Aim: The aim of this paper is therefore to report on experiences conducting SRs from the perspective of novice researchers. The paper reports first hand experiences of novices conducting SRs and compares them with the experiences of an expert as well as with the experiences reported in the previous literature. Method: An instrument was created and used to gather the experiences conducting SRs from three PhD students and their supervisor. The instrument covered all the SR steps; it was individually filled out by each of the participating subjects and its data was later on aggregated. Results: The results show that the problems faced by novices in terms of time taken to conduct the review; defining the research questions, inclusion/exclusion criteria, data extraction and data synthesis forms are not faced by expert researchers. Moreover, problems faced by novices related to defining quality criteria are different in nature than those faced by expert researchers. Conclusions: It has been observed that while numerous problems are faced by both novices and experts, many others are specific to novices, where several of these can be solved with the help of domain and SR experts.},
  address = {Keele University, UK},
  booktitle = {International Conference on Evaluation and Assessment in Software Engineering (EASE)},
  url = {http://www.bcs.org/content/conWebDoc/34784},
  year = {2010}
}

@ARTICLE{richardson:2007,
  author = {Ita Richardson and Christiane Gresse von Wangenheim},
  title = {Why Are Small Software Organizations Different?},
  volume = {24},
  number = {1},
  month = jan,
  year = {2007},
  pages = {18-22},
  doi = {10.1109/MS.2007.12},
  journal = {IEEE Software},
  owner = {magsilva},
  timestamp = {2007.04.27}
}

@ARTICLE{richer-etal:2006,
  author = {Mark S. Richer and Glenn Reitmeier and Tom Gurley and Graham A. Jones and Jerry Whitaker and Robert Rast},
  title = {The {ATSC} Digital Television System},
  volume = {94},
  number = {1},
  month = jan,
  year = {2006},
  pages = {37-43},
  journal = {Proceedings of the {IEEE}},
  timestamp = {2008.10.07}
}

@INPROCEEDINGS{ridao:2000,
  author = {Marcela Ridao and Jorge Doorn and Julio César Sampaio do Prado Leite},
  title = {Uso de Patrones en la Construcción de Escenarios},
  pages = {140-157},
  booktitle = {WER 2000},
  owner = {magsilva},
  publisher = {WER},
  timestamp = {2008.07.30},
  year = {2000}
}

@MISC{Riekstin:2007,
  author = {Ana Cláudia Riekstin},
  title = {Aspectos de Desenvolvimento, Evolução e Validação do Ambiente {PROGTEST}},
  howpublished = {Projeto de Iniciação Científica},
  year = {2007},
  note = {Orientadora: Ellen Francine Barbosa.},
  owner = {magsilva},
  timestamp = {2007.10.10}
}

@MISC{riel:2006,
  author = {Rik van Riel},
  title = {UpstreamMerge},
  howpublished = {Artigo disponível na Web},
  month = {aug},
  year = {2006},
  owner = {magsilva},
  timestamp = {2006.09.01},
  url = {http://kernelnewbies.org/UpstreamMerge}
}

@ARTICLE{Rising00SSDP,
  author = {L. Rising and N. S. Janoff},
  title = {The {SCRUM} Software Development Process for Small Teams},
  volume = {17},
  number = {4},
  year = {2000},
  pages = {26--32},
  journal = ieees,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@PHDTHESIS{Robbins:1999,
  author = {Jason Elliot Robbins},
  title = {Cognitive Support Features for Software Development Tools},
  school = {University of California, Irvine},
  year = {1999},
  address = {EUA},
  isbn = {0-599-44359-6},
  note = Advisor # {: David F. Redmiles}
}

@BOOK{roberts:1979,
  title = {Measurement Theory with Applications to Decision Making, Utility, and the Social Sciences},
  publisher = {Addison-Wesley},
  year = {1979},
  author = {Fred S. Roberts},
  address = {Reading, MA, USA},
  owner = {magsilva},
  timestamp = {2010.08.25}
}

@ARTICLE{robertson:2005,
  author = {Robertson, S.},
  title = {Learning from other disciplines},
  volume = {22},
  number = {3},
  month = {may},
  year = {2005},
  pages = {54- 56},
  doi = {10.1109/MS.2005.68},
  journal = {IEEE Software},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@INPROCEEDINGS{Robles:2010,
  author = {Gregorio Robles},
  title = {Replicating {MSR}: A study of the potential replicability of papers published in the Mining Software Repositories proceedings},
  pages = {171--180},
  doi = {10.1109/MSR.2010.5463348},
  abstract = {This paper is the result of reviewing all papers published in the proceedings of the former International Workshop on Mining Software Repositories (MSR) (2004-2006) and now Working Conference on MSR (2007-2009). We have analyzed the papers that contained any experimental analysis of software projects for their potentiality of being replicated. In this regard, three main issues have been addressed: i) the public availability of the data used as case study, ii) the public availability of the processed dataset used by researchers and iii) the public availability of the tools and scripts. A total number of 171 papers have been analyzed from the six workshops/working conferences up to date. Results show that MSR authors use in general publicly available data sources, mainly from free software repositories, but that the amount of publicly available processed datasets is very low. Regarding tools and scripts, for a majority of papers we have not been able to find any tool, even for papers where the authors explicitly state that they have built one. Lessons learned from the experience of reviewing the whole MSR literature and some potential solutions to lower the barriers of replicability are finally presented and discussed.},
  keywords = {replication, tools, public datasets, mining software repositories}
}

@BOOK{Rocha-etal:2001,
  title = {Qualidade de Software: teoria e prática},
  publisher = {Prentice-Hall},
  year = {2001},
  author = {Ana Regina Cavalcanti da Rocha and José Carlos Maldonado and Kival Chaves Weber},
  editor = {Roger Trimer},
  isbn = {8587918540},
  pages = {303},
  address = {São Paulo, SP, } # Brazil,
  edition = {1}
}

@PHDTHESIS{rocha:1983,
  author = {A. R. C. D. Rocha},
  title = {Um modelo para avaliação da qualidade de especificações},
  school = {PUC-RJ},
  year = {1983},
  address = {Riode Janeiro, RJ},
  owner = {magsilva},
  timestamp = {2006.09.12}
}

@MISC{rocha:2003,
  author = {H. V. Rocha},
  title = {Guia do Ambiente Virtual {TelEduc}},
  howpublished = {Rio de Janeiro: Núcleo de Pesquisa e Projetos de Educação a Distância},
  year = {2003},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@MISC{project:teleduc,
  author = {Heloisa Vieira da Rocha},
  title = {Projeto {TelEduc}},
  howpublished = project,
  year = {1997}
}

@INBOOK{simone-etal:2007,
  chapter = {10},
  pages = {251-268},
  title = {Estudos Teóricos e Experimentais},
  publisher = {Campus},
  year = {2007},
  editor = {Márcio Eduardo Delamaro},
  author = {Simone do Rocio Senger de Souza and Sandra C. Pinto Ferraz Fabri and Ellen Francine Barbosa and Marcos Lordello Chaim and Auri Marcelo Rizzo Vincenzi and Márcio Eduardo Delamaro and Mario Jino and José Carlos Maldonado}
}

@INPROCEEDINGS{RodriguezArtacho-Verdejo:2001,
  author = {Rodriguez-Artacho, M. and Verdejo, M. F.},
  title = {Creating constructivist learning scenarios using an educative modeling language},
  pages = {11-12},
  doi = {10.1109/FIE.2001.963752},
  abstract = {This paper illustrates the use of PALO, a general-purpose educative modeling language (EML), to embed constructivist features in distance learning scenarios. Educative modeling languages allow describing learning content using an XML-based representation independent from the final delivery format, thus providing a higher level of abstraction in the authoring process. We have defined a subset of elements and attributes of PALO language to describe constructivist properties, in order to improve knowledge construction process in distance learning educational environments.},
  volume = {2},
  acmid = {1254594},
  address = {Washington, DC, USA},
  booktitle = {Frontiers in Education Conference},
  isbn = {0-7803-6669-7},
  owner = {magsilva},
  publisher = {IEEE Computer Society},
  year = {2001}
}

@INPROCEEDINGS{RodriguezArtacho-etal:1999,
  author = {M. Rodríguez-Artacho and M. F. Verdejo and J. I. Mayorga and M. Y. Calero},
  title = {Using a High-Level Language to Describe and Create Web-Based Learning Scenarios},
  pages = {1-6},
  doi = {10.1109/FIE.1999.841711},
  abstract = {An approach to Web-based educational authoring, separating content from structure is presented. The paper focuses on PALO, a SGML derived language, to define instructional templates. On the one hand, these templates are a way to organize learning material with a particular purpose, on the other they provide high-level specifications related to structural, navigational and interaction properties for the final product. The system supplies a compiler to parse PALO instructional templates, automatically generating a Web environment.},
  number = {13A},
  booktitle = {Frontiers in Education Conference},
  isbn = {0-7803-5643-8},
  location = {San Juan , Puerto Rico},
  month = nov,
  owner = {magsilva},
  publisher = {IEEE},
  timestamp = {2008.07.31},
  year = {1999}
}

@INPROCEEDINGS{Paula-etal:2001,
  author = {Rogerio dePaula, Gerhard Fischer, and Jonathan Ostwald},
  title = {Courses as Seeds: Expectations and Realities},
  pages = {1--8},
  abstract = {In our long-term efforts to support collaborative learning, we are exploring how to supplement community-based learning theories with innovative collaborative technologies. Inspired by a process model that underlies the evolutionary and decentralized development of open systems, we reconceptualize courses as seeds rather than as finished products. This paper outlines the conceptual framework underlying the courses-as-seeds model and contrasts it with traditional educational models in which courses are seen as finished products. Characteristics of course information environments (CIEs) as supporting technology are then presented, along with a set of initial expectations that provide criteria for assessing applications of the model. Next, an application of the courses-as-seeds model in a university course is reported and analyzed with respect to the expectations. We found that the primary challenges of applying the courses-as-seeds model were cultural in nature and more difficult than we anticipated. The paper presents these findings in more detail, and closes with suggestions for future refinement of the approach.},
  keywords = {Courses as seeds, seeding, evolutionary growth, reseeding model (SER), course information environments (CIE), DynaSites, educational models, cultural change, collaborative knowledge construction},
  booktitle = {European Conference on Computer-Supported Collaborative Learning (Euro-CCSL)},
  location = {Maastricht, #Netherlands#},
  month = mar,
  year = {2001}
}

@INPROCEEDINGS{Roibas-etal:2006:chi2,
  author = {Roibás, Anxo Cereijo and Geerts, David and Calvi, Licia and Anttila, Akseli and Daly-Jones, Owen},
  title = {Mobile {iTV}: new challenges for the design of pervasive multimedia systems},
  pages = {407--410},
  doi = {10.1145/1125451.1125539},
  abstract = {This SIG will stimulate informal debate around the futures of interfaces for pervasive multimedia systems such as mobile and ubiquitous iTV with special attention to the new contextual usage of this media in entertainment, work and government contexts.It aims to create a provocative framework to uncover future usage scenarios and generate debate about novel processes for creation, sharing, and consumption of digital content that match the nomadic lifestyles of mobile users and about related new applications and original interaction models that support social use. Likewise it intends to discuss possible controversial evolutions and trends of this prospected scenario such as 'an utterly controlled society' (as in Aldous Huxley's book 'Brave New World'), applications in nano and biotechnology, etc.},
  keywords = {context awareness, controversial trends, design of the innovation, future user experience, new sociability, novel cross-media smart content, novel interactive patterns, pervasive iTV, prospected scenarios},
  address = {New York, NY, USA},
  booktitle = {CHI '06 extended abstracts on Human factors in computing systems},
  isbn = {1-59593-298-4},
  location = {Montreal, Quebec, Canada},
  publisher = {ACM},
  year = {2006}
}

@INPROCEEDINGS{Roibas-etal:2006:chi1,
  author = {Roibás, Anxo Cereijo and Geerts, David and Furtado, Elizabeth and Calvi, Licia},
  title = {Investigating new user experience challenges in iTV: mobility \& sociability},
  pages = {1659--1662},
  doi = {10.1145/1125451.1125756},
  abstract = {This workshop is a discussion platform to unfold the design of future interactive television (iTV) scenarios characterized by pervasive communications in contexts of entertainment, work and government, with special attention to the social character of the usage of these media and the implications for interface design. In particular, it will focus on the use of handhelds and other advanced interfaces (e.g. Interactive Public Displays, spectacles) to extend the iTV social experience outside the home boundaries and to enhance users' communication in diverse contexts. The workshop will look at how innovative ethno-methodologies, collaborative design approaches and advanced evaluation techniques can lead to the creation and representation of feasible and relevant future communications scenarios that are characterized by a strong collaboration and interaction between users such as mobile iTV. Workshop organizers will also open up a debate around how to identify suitable applications for the above scenarios as well as related new forms of content and novel interaction models that support social use.},
  keywords = {novel interactive systems, pervasive communication scenarios, pervasive iTV, sociability, user experience},
  address = {New York, NY, USA},
  booktitle = {CHI '06 extended abstracts on Human factors in computing systems},
  isbn = {1-59593-298-4},
  location = {Montreal, Quebec, Canada},
  publisher = {ACM},
  year = {2006}
}

@INPROCEEDINGS{Roibas-Sala:2007,
  author = {Roibás, Anxo Cereijo and Sala, Riccardo},
  title = {Beyond mobile {TV}: understanding how mobile interactive systems enable users to become digital producers},
  pages = {801--810},
  abstract = {This paper aims to explore the quality of the user experience with mobile and pervasive interactive multimedia systems that enable the creation and sharing of digital content through mobile phones. It also looks at discussing the use and validity of different experimental in-situ and other data gathering and evaluation techniques for the assessment of how the physical and social contexts might influence the use of these systems. This scenario represents an important shift away from professionally produced digital content for the mass-market. It addresses methodologies and techniques that are suitable to design co-creative applications for non-professional users in different contexts of use at home or in public spaces. Special focus is be given to understand how user participation and motivation in small themed communities can be encouraged, and how social interaction can be enabled through mobile interfaces. An enhancement of users creativity, self-authored content sharing, sociability and co-experience can be evidence for how creative people can benefit from Information and Communication Technologies.},
  keywords = {mobileTV, pervasive multimedia, users' generated content},
  series = {HCI'07},
  acmid = {1769681},
  address = {Berlin, Heidelberg},
  booktitle = {Proceedings of the 12th international conference on Human-computer interaction: intelligent multimodal interaction environments},
  isbn = {978-3-540-73108-5},
  location = {Beijing, China},
  numpages = {10},
  publisher = {Springer-Verlag},
  url = {http://portal.acm.org/citation.cfm?id=1769590.1769681},
  year = {2007}
}

@BOOK{Romiszowski-Romiszowski:1998,
  title = {Dicionário de Terminologia de Educação a Distância},
  publisher = {Fundação Roberto Marinho},
  year = {1998},
  author = {Alexander J. Romiszowski and Hermelina P. Romiszowski},
  address = {Rio de Janeiro, RJ, Brasil},
  timestamp = {2008.09.19}
}

@BOOK{roper:1994,
  title = {Software Testing},
  publisher = {McGraw-Hill},
  year = {1994},
  author = {Marc Roper},
  pages = {149},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@BOOK{rosen:2009,
  title = {E-learning 2.0: proven practices and emerging technologies to achieve results},
  publisher = {American Management Association (AMACON)},
  year = {2009},
  author = {Anita Rosen},
  pages = {236},
  address = {United States},
  edition = {1},
  quality = {0},
  review = {The book is geared toward companies that are rushing to implement training initiatives. As such, it provides an overview regarding computer technologies that can be used for e-Learning. Unfortunately, the topics discussed in the book are too shallow. For instance, the very beginning of the book establishes that goals must be set and they must be set properly: measurable, actionable, and realistics. However, such goals are not defined anywhere else (e.g., I was expecting they could be defined for some case studies). The only mechanisms that are provided for guidance are hints and checklists. Even those checklists seem grounded only by the author's knowledge, as can be verified by the absence of bibliography or references in the book. That is odd, as there is plenty of literature on the subject, that could (and should) be cited. Finally, the '2.0' is just about technological features. Pedagogically, it is more to '0.5'. It suggests courses organized in chapters, pages, subpages, almost as a book. Most companies are not looking anymore for such structure. Project and problem-based courses, with highly interactive content (like simulations and games, and not as simple tests) are desirable, but the book does not provide any help regarding that. So, if you are looking for a solid book to implement an e-learning, be aware there are other options more suitable. However, if you need an overview of the technologies and you need to bootstrap a simple e-learning initiative, the contents, specially the checklists, can be useful.}
}

@TECHREPORT{Rosenblum97ATCB,
  author = {D. S. Rosenblum},
  title = {Adequate Testing of Component-Based Software},
  institution = {University of California},
  month = aug,
  year = {1997},
  number = {UCI-ICS-97-34},
  address = {Irvine, CA},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@ARTICLE{vanrosmalen-etal:2006,
  author = {P. Van Rosmalen and H. Vogten and R. Van Es and H. Passier and P. Poelmans and R. Koper},
  title = {Authoring a full life cycle model in standards-based, adaptive e-learning},
  volume = {9},
  year = {2006},
  pages = {1},
  journal = {Educational Technology \& Society},
  timestamp = {2008.09.26}
}

@PHDTHESIS{rossi1996,
  author = {G. Rossi},
  title = {Um método orientado a objetos para o projeto de aplicação hipermídia},
  school = {PUC-RJ},
  year = {1996},
  address = {Rio de Janeiro, RJ},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@INPROCEEDINGS{rossling-etal:2004,
  author = {Rössling, Guido and Trompler, Christoph and Mühlhäuser, Max and Köbler, Susanne and Wolf, Susanne},
  title = {Enhancing classroom lectures with digital sliding blackboards},
  pages = {218--222},
  doi = {10.1145/1007996.1008054},
  abstract = {Traditional blackboard-based lectures provide context on the sliding blackboards. Modern lectures incorporating video projectors typically do not provide this context. We describe a project that combines both approaches to provide context for modern lectures. We also discuss the benefits for educators and students. The software is sufficiently versatile to incorporate practically any software for content display.},
  keywords = {VMB, digital lecture hall, digital sliding blackboards},
  series = {ITiCSE '04},
  acmid = {1008054},
  address = {New York, NY, USA},
  booktitle = {Proceedings of the 9th annual SIGCSE conference on Innovation and technology in computer science education},
  isbn = {1-58113-836-9},
  location = {Leeds, United Kingdom},
  numpages = {5},
  publisher = {ACM},
  year = {2004}
}

@MISC{jsp:2003,
  author = {Mark Roth and Eduardo Pelegrí-Llopart},
  title = {JavaServer Pages Specification 2.0},
  howpublished = {JCP Specification},
  month = {nov},
  year = {2003},
  file = {JavaServer Pages Specification 2.0.pdf:JavaServer Pages Specification 2.0.pdf:PDF},
  owner = {Marco Aurélio Graciotto Silva},
  timestamp = {2008.07.30}
}

@ARTICLE{roth:1994,
  author = {Tina Roth and Peter Aiken and Scarlette Hobbs},
  title = {Hypermedia Support for Software Development: A Retrospective Assessment},
  volume = {6},
  number = {3},
  year = {1994},
  pages = {149-173},
  journal = {HYPERMEDIA},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@BOOK{Rowntree:1992,
  title = {Exploring Open and Distance Learning},
  publisher = {Routledge},
  year = {1992},
  author = {Derek Rowntree},
  isbn = {978-0749408138},
  pages = {299},
  address = {Padstow, Reino Unido},
  month = sep,
  booktitle = {Exploring Open and Distance Learning},
  lang = {en},
  timestamp = {2008.09.19}
}

@MISC{project:ideaisCNPq,
  author = {Henrique Rozenfeld},
  title = {Ferramentas para melhoria do processo de gestão do desenvolvimento e comercialização colaborativos de Software},
  howpublished = {Plano},
  month = sep,
  year = {2004},
  note = {Processo 507212/2004-5},
  owner = {magsilva},
  timestamp = {2006.05.30}
}

@MISC{project:ideais,
  author = {Henrique Rozenfeld and others},
  title = {{IDEAIS: Integração de Empresas na Aplicação e Implementação de Sistemas}},
  howpublished = {Projeto},
  year = {2004},
  owner = {magsilva},
  timestamp = {2006.08.31}
}

@MISC{standard:dod178b,
  author = {{RTCA}},
  title = {{DO-178B}: Software Considerations in Airborne Systems and Equipment Certification},
  year = {1982},
  organization = {Radio Technical Commission for Aeronautics (RTCA)},
  owner = {magsilva},
  timestamp = {2009.04.30}
}

@TECHREPORT{RTRGmbH:2006,
  author = {RTR-GmbH},
  title = {Mobile TV in Österreich},
  institution = {Rundfunk \& Telekom Regulierungs-GmbH},
  month = feb,
  year = {2006},
  address = {Viena, Áustria},
  url = {http://www.rtr.at/de/komp/SchriftenreiheNr22006},
  lang = {de}
}

@ARTICLE{ruiz-etal:2004,
  author = {F. Ruiz and A. Vizcaíno and M. Piattini and F. García},
  title = {An Ontology for the Management of Software Maintenance Projects},
  volume = {14},
  number = {3},
  year = {2004},
  pages = {323--349},
  journal = {International Journal of Software Engineering and Knowledge Engineering},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@ARTICLE{ruizprimo-etal:1996,
  author = {Ruiz-Primo, Maria Araceli and Shavelson, Richard J.},
  title = {Problems and issues in the use of concept maps in science assessment},
  volume = {33},
  number = {6},
  month = aug,
  year = {1996},
  pages = {569--600},
  abstract = {The search for new, authentic science assessments of what students know and can do is well under way. This has unearthed measures of students' hands-on performance in carrying out science investigations, and has been expanded to discover more or less direct measures of students' knowledge structures. One potential finding is concept mapping, the focus of this review. A concept map is a graph consisting of nodes representing concepts and labeled lines denoting the relation between a pair of nodes. A student's concept map is interpreted as representing important aspects of the organization of concepts in his or her memory (cognitive structure). In this article we characterize a concept map used as an assessment tool as: (a) a task that elicits evidence bearing on a student's knowledge structure in a domain, (b) a format for the student's response, and (c) a scoring system by which the student's concept map can be evaluated accurately and consistently. Based on this definition, multiple concept-mapping techniques were found from the myriad of task, response format, and scoring system variations identified in the literature. Moreover, little attention has been paid to the reliability and validity of these variations. The review led us to arrive at the following conclusions: (a) an integrative working cognitive theory is needed to begin to limit this variation in concept-mapping techniques for assessment purposes; (b) before concept maps are used for assessment and before map scores are reported to teachers, students, the public, and policy makers, research needs to provide reliability and validity information on the effect of different mapping techniques; and (c) research on students' facility in using concept maps, on training techniques, and on the effect on teaching is needed if concept map assessments are to be used in classrooms and in large-scale accountability systems.},
  issn = {1098-2736},
  journal = {Journal of Research in Science Teaching},
  publisher = {Wiley}
}

@BOOK{Rumbaugh91OOMD,
  title = {Object-Oriented Modeling and Design},
  publisher = {Prentice Hall International},
  year = {1991},
  author = {J. Rumbaugh and M. Blaha and W. Premerlani and F. Eddy and W. Lorensen},
  address = {Englewood Cliffs, New Jersey, USA},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@MISC{Rumjanek:2011,
  author = {Vivian Rumjanek},
  title = {A ciência vista pelo surdo},
  howpublished = talk,
  month = ago,
  year = {2011},
  note = {IFSP-USP},
  abstract = {A comunidade surda é linguística e socialmente marginalizada quanto à educação, principalmente na área científica. Isso decorre de várias barreiras. A maioria dos surdos não é oralizada, isto é, não faz leitura labial nem fale, e apresenta grande dificuldade com relação à língua Portuguesa escrita. Dessa forma, além de não escutarem e encontrarem dificuldades no aprendizado formal nas escolas, não absorvem conhecimento informal através da mídia. Apesar da língua natural de comunicação entre os surdos ser a língua brasileira de sinais (LIBRAS), cerca de 90% de nossos surdos são filhos de pais ouvintes (que não conhecem LIBRAS) e muitas crianças surdas chegam aos 6, 7 anos sem nenhuma língua e sem organizar seu pensamento. Com relação à área científica e tecnológica, a exclusão é ainda mais evidente, pois além de envolver muitos conceitos abstratos, a LIBRAS é muito pobre em sinais científicos. O que iremos discutir é uma abordagem bem sucedida que visa circundar algumas dessas dificuldades. O mundo dos surdos passa a ser visto e não ouvindo.},
  address = {São Carlos, SP, } # Brazil
}

@INPROCEEDINGS{Rummel:2006:LCC:1150034.1150126,
  author = {Rummel, Nikol and Spada, Hans and Hauser, Sabine},
  title = {Learning to collaborate in a computer-mediated setting: observing a model beats learning from being scripted},
  pages = {634--640},
  abstract = {In an earlier study we had tested if observing a model collaboration or following a collaboration script could improve students' subsequent collaboration in a computer-mediated setting and promote their knowledge of what makes good collaboration. Both model and script showed positive effects. The current study was designed to further probe the effects of model and script by comparing them to conditions (model-plus, script-plus) in which the learning was further supported by providing elaboration support (instructional prompts and guided self-explanation). 40 dyads were tested, 8 in each of the following conditions: model plus elaboration, model, script plus elaboration, script, control. Observing a model collaboration with elaboration support yielded the best results over all other conditions on several measures of the quality of collaborative process and on outcome variables. Model without elaboration was second best. The results for the script conditions were mixed; on some variables even below those of the control condition.},
  series = {ICLS '06},
  acmid = {1150126},
  booktitle = {Proceedings of the 7th international conference on Learning sciences},
  isbn = {0-8058-6174-2},
  location = {Bloomington, Indiana},
  numpages = {7},
  publisher = {International Society of the Learning Sciences},
  url = {http://portal.acm.org/citation.cfm?id=1150034.1150126},
  year = {2006}
}

@ARTICLE{russell2004ia,
  author = {S. Russell and P. Norvig},
  title = {{Inteligência Artificial}},
  year = {2004},
  journal = {Editora Campus},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@BOOK{Russell95AIMA,
  title = {Artificial Intelligence: A Modern Approach},
  publisher = {Prentice-Hall},
  year = {1995},
  author = {S. J. Russell and P. norving},
  address = {Upper Saddle River, New Jersey},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@ARTICLE{Ryan:1991,
  author = {Bob Ryan},
  title = {Dynabook revisited with {Alan Kay}},
  volume = {16},
  number = {2},
  month = feb,
  year = {1991},
  pages = {203--208},
  address = {Hightstown, NJ, } # USA,
  issn = {0360-5280},
  journal = {BYTE},
  publisher = {McGraw-Hill}
}

@ARTICLE{Sabnani88PTGP,
  author = {K. K. Sabnani and A. Dahbura},
  title = {Protocol Test Generation Procedure},
  volume = {15},
  number = {4},
  month = apr,
  year = {1988},
  pages = {285--297},
  journal = {Computer Networks and ISDN Systems},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{sacool-etal:2009,
  author = {Saccol, A.Z. and Kich, M. and Schlemmer, E. and Reinhard, N. and Barbosa, J.L.V. and Hahn, R.},
  title = {A Framework for the Design of Ubiquitous Learning Applications},
  pages = {1 -10},
  doi = {10.1109/HICSS.2009.13},
  abstract = {The article presents a framework for the design of ubiquitous learning applications that considers four main elements: the knowledge about learner's profile and needs; the context (physical, temporal and social) that surrounds mobile learners; the educational paradigm or model considered and the possibilities and limitations of mobile and wireless technologies. The proposed framework is applied in the analysis of a case of development of a virtual learning environment designed to support the competence development of mobile workers. The design experience is detailed, showing lessons learned and indications for future research.},
  keywords = {competence development;educational paradigm;mobile worker;ubiquitous learning application;virtual learning environment;wireless technology;computer aided instruction;mobile computing;},
  booktitle = {Hawaii International Conference on System Sciences (HICSS)},
  issn = {1530-1605},
  month = jan,
  year = {2009}
}

@BOOK{Sackett-etal:2000,
  title = {Evidence-Based Medicine: How to Practice nad Teach EBM},
  publisher = {Churchill Livingstone},
  year = {2000},
  author = {D. L. Sackett and S. E. Straus and W. S. Richardson},
  edition = {2},
  owner = {magsilva},
  timestamp = {2007.11.12}
}

@ARTICLE{Sacks-etal:1987,
  author = {Henry S. Sacks and Jayne Berrier and Dinah Reitman and Ancona-Berk and Thomas C. Chalmers},
  title = {Meta-Analyses of Randomized Controlled Trials},
  volume = {316},
  month = feb,
  year = {1987},
  pages = {450-455},
  abstract = {A new type of research, termed meta-analysis, attempts to analyze and combine the results of previous reports. We found 86 meta-analyses of reports of randomized controlled trials in the English-language literature. We evaluated the quality of these meta-analyses, using a scoring method that considered 23 items in six major areas - study design, combinability, control of bias, statistical analysis, sensitivity analysis, and application of results. Only 24 meta-analyses (28 percent) addressed all six areas, 31 (36 percent) addressed five, 25 (29 percent) addressed four, 5 (6 percent) addressed three, and 1 (1 percent) addressed two. Of the 23 individual items, between 1 and 14 were addressed satisfactorily (mean +/-SD, 7.7+/-2.7). We conclude that an urgent need exists for improved methods in literature searching, quality evaluation of trials, and synthesizing of the results.},
  journal = {The New England Journal of Medicine}
}

@MISC{Sadker-Sadker:1978,
  author = {Sadker, Myra and Sadker, David},
  title = {The Teacher Educator's Role},
  howpublished = {Guia do Professor},
  year = {1978},
  abstract = {This 2-day workshop package was developed to address the needs of teacher educators with regard to Title IX and sex equity. The role of teacher educators in reinforcing sex fairness and in eliminating sex bias in teacher education curricula and in the classroom is the focus of the workshop. The workshop begins with a consideration of the need and rationale for Title IX. Title IX regulations and grievance procedures are reviewd, followed by an examination of the application of the Title IX regulations and sex equity principles to the job functions of various groups of education personnel. Also presented is an overview of the change process and an opportunity for participant action planning related to Title IX compliance and the achievement of sex equity. Specifications of the population, objectives, and instructional materials are outlined for each of the workshop's two sessions. The first session addresses the subject of preparing teachers to analyze and alleviate sex bias in instructional materials. The session includes discussions on assessing elementary, secondary, and teacher education textbooks for biased wording and attitudes and provides guidelines for forming a curricular response to sex-biased materials. The second session covers the topic of forms of sex bias in instructional procedures and in teacher education classrooms. Affirmative teaching strategies to eliminate bias are presented. Ways of alleviating sexism through institution building and scholarship are discussed. Sample worksheets and activity forms are included in the workbook.},
  timestamp = {2012.01.25},
  url = {http://www.eric.ed.gov/ERICWebPortal/detail?accno=ED222466}
}

@ARTICLE{sadoski1997tts,
  author = {D. Sadoski and S. Comella-Dorda},
  title = {Three Tier Software Architectures},
  year = {1997},
  journal = {Software Technology Review. Software Engineering Institute, Carnegie Mellon University},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@ARTICLE{safayeni-etal:2005,
  author = {Safayeni, F. and Derbentseva, N. and Cañnas, A. J.},
  title = {A theoretical note on concepts and the need for Cyclic Concept Maps},
  volume = {42},
  number = {7},
  month = sep,
  year = {2005},
  pages = {741-766},
  doi = {10.1002/tea.20074},
  abstract = {This article examines concepts and propositions from a theoretical perspective, and establishes the need for and develops an extension to Concept Maps (CMaps), called Cyclic Concept Maps (Cyclic CMaps). Cyclic CMaps are considered to be an appropriate tool for representing knowledge of functional or dynamical relationships between concepts. CMaps, on the other hand, are viewed as an appropriate tool for representing hierarchic or static knowledge. The two maps complement each other and collectively capture a larger domain of knowledge, thus forming a more effective knowledge representation tool.},
  keywords = {Hierarchical systems; Knowledge acquisition; Maps, Concept maps (CMaps); Cyclic concept maps; Static knowledge, Teaching},
  issn = {00224308},
  journal = {Journal of Research in Science Teaching},
  language = {English},
  source = {Scopus}
}

@MISC{software:sakai,
  author = {{Sakai Project}},
  title = {Sakai},
  howpublished = {Programa de computador},
  month = mar,
  year = {2005},
  timestamp = {2008.08.05}
}

@INPROCEEDINGS{Saleemi-etal:2008b,
  author = {Saleemi, M. Mohsin and Björkqvist, Jerker and Lilius, Johan},
  title = {System architecture and interactivity model for mobile TV applications},
  pages = {407--414},
  doi = {10.1145/1413634.1413706},
  abstract = {Interactive services and applications for Mobile TV are considered to be one of the promising concepts that offer new opportunities for mass media, mobile and broadcast industry. This article explores the concepts of interactivity, interactive applications and system architecture aspects in interactive mobile TV. It investigates demands and constraints for the software platform of mobile TV, suggests possible solutions for them and proposes prototype software architecture for mobile TV based on this investigation and proposed solutions. Interactivity model for the interactive mobile TV applications is proposed that facilitate the evaluation of these applications to prospect the terminal and server side's requirements. This model has significance because it specifies the overall image of mobile interactive system that will be helpful for defining common application framework based on the user's perception.},
  keywords = {design requirements, interactive applications, interactivity model, mobile TV, system architecture},
  address = {New York, NY, USA},
  booktitle = {Proceedings of the 3rd international conference on Digital Interactive Media in Entertainment and Arts},
  isbn = {978-1-60558-248-1},
  location = {Athens, Greece},
  publisher = {ACM},
  year = {2008}
}

@INPROCEEDINGS{Saleemi-etal:2008a,
  author = {Saleemi, M. Mohsin and Nybom, Kristian and Lilius, Johan and Björkqvist, Jerker},
  title = {Content scheduling in multimedia interactive mobile games},
  pages = {152--159},
  doi = {10.1145/1496984.1497010},
  abstract = {In this paper, we study how to implement interactive multimedia services using a DVB-H broadcast channel combined with a point-to-point channel, such as 3G or GPRS. We study the problem in the context of a location-based interactive mobile game. The technical challenge is to schedule the sending of data over the broadcast channel while maintaining Quality-of-Service, that is, sending the right data to the right user at the right time to provide a seamless interactive experience. We explore design issues and problems related to the scheduling of content in the game, present a usecase study to describe scheduling problems and propose a content scheduling algorithm to solve these problems. Moreover, we provide a simulation of the system and the experimental results to show how different game parameters influence the in-time delivery of the multimedia content to the players. We conclude that most of the problems involved with our approach can be expressed as the problem of defining delivery deadlines for a scheduling algorithm.},
  keywords = {algorithm, content scheduling, interactive applications, location-based game, multimedia},
  series = {Future Play '08},
  acmid = {1497010},
  address = {New York, NY, USA},
  booktitle = {Proceedings of the 2008 Conference on Future Play: Research, Play, Share},
  isbn = {978-1-60558-218-4},
  location = {Toronto, Ontario, Canada},
  numpages = {8},
  publisher = {ACM},
  year = {2008}
}

@ARTICLE{samuelson:2004,
  author = {Pamela Samuelson},
  title = {Why reform the U.S. patent system?},
  volume = {47},
  number = {6},
  month = {jun},
  year = {2004},
  pages = {19-23},
  journal = {Communications of the ACM},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@ARTICLE{samuelson:2001,
  author = {Pamela Samuelson},
  title = {Intellectual property for an information age: introduction},
  volume = {44},
  number = {2},
  month = {feb},
  year = {2001},
  pages = {66 - 68},
  journal = {Communications of the ACM},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@ARTICLE{samuelson:1988,
  author = {P. Samuelson},
  title = {Is copyright law steering the right course?},
  volume = {5},
  number = {5},
  month = {sep},
  year = {1988},
  pages = {78-86},
  journal = {IEEE Software},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@ARTICLE{Sanger-Greenbowe:1999,
  author = {Sanger, Michael J. and Greenbowe, Thomas J.},
  title = {An Analysis of College Chemistry Textbooks As Sources of Misconceptions and Errors in Electrochemistry},
  volume = {76},
  number = {6},
  month = jun,
  year = {1999},
  pages = {853-860},
  doi = {10.1021/ed076p853},
  abstract = {The oxidation-reduction and electrochemistry chapters of 10 introductory college chemistry textbooks were reviewed for misleading or erroneous statements, using a list of student misconceptions. These misconceptions include the notions that the identity of the anode and cathode depends on the physical placement of the half-cell; half-cell potentials are independent of each other, meaningful, and measurable; electrons can flow through electrolyte solutions and the salt bridge; cation movement does not constitute an electrical current; electrodes have large net positive or negative charges that can be used to explain ion and electron flow; and electrolysis products cannot be predicted using standard reduction potentials. As a result of this analysis, we provide suggestions for chemistry instructors and textbook authors: simplifications such as always drawing the anode as the left-hand half-cell or only describing the flow of anions in electrolyte solutions and the salt bridge should be avoided; vague or misleading statements should be avoided; cell potentials should be calculated using the difference method instead of the additive method; simple electrostatic arguments should not be used to predict ion and electron flow in electrochemical cells; and all possible oxidation and reduction half-reactions should be considered when predicting the products of electrolysis.},
  eprint = {http://pubs.acs.org/doi/pdf/10.1021/ed076p853},
  issn = {0021-9584, 1938-1328},
  journal = {Journal of Chemical Education},
  publisher = {ACS}
}

@INPROCEEDINGS{SanPedro:2008,
  author = {San Pedro, Jose},
  title = {Fobs: an open source object-oriented library for accessing multimedia content},
  pages = {1097--1100},
  doi = {10.1145/1459359.1459580},
  abstract = {The exceptionally large nature of multimedia content has motivated the creation of many different compression algorithms and encapsulation formats to make its transportation and storage feasible. Developers of multimedia applications have to deal repeatedly with the massive number of forms in which content is present, turning the single task of media access into an unnecessary challenge. The open source project FOBS provides a way to abstract developers from these difficulties, by offering an intuitive and powerful object oriented multimedia access API. FOBS has been conceived to be inherently platform independent and to be easily adaptable to multiple programming languages, making the addition of multimedia support possible in almost any application.},
  keywords = {api, codec, fobs, format, multimedia access, object oriented},
  series = {MM},
  booktitle = {16th ACM international conference on Multimedia},
  isbn = {978-1-60558-303-7},
  location = {Vancouver, BC, Canada},
  publisher = {ACM},
  year = {2008}
}

@MASTERSTHESIS{santos:2007,
  author = {Davi Trindade dos Santos},
  title = {Estudo de Aplicativos de {TVDi} para Educação a Distância},
  school = {UNICAMP},
  year = {2007},
  address = {Campinas, SP, Brasil},
  month = jun,
  timestamp = {2008.10.03},
  type = {Mestrado}
}

@INPROCEEDINGS{Santos-etal:2006,
  author = {Santos, Davi Trindade dos and Vale, Douglas Terêncio do and Meloni, Luís Geraldo Pedroso},
  title = {Digital {TV} and Distance Learning: Potentials and Limitations},
  pages = {1 -6},
  doi = {10.1109/FIE.2006.322670},
  abstract = {One of the goals of the Brazilian Digital TV (DTV) system is to offer high-quality distance learning programs through DTV (t-learning). There are several differences between t-learning and e-learning that makes prohibitive just translate e-learning software's to DTV. This paper presents the potentials that t-learning programs can achieve on countries with high digital divide, and also the limitations of t-learning environment. Different scenarios of DTV resource availability are also presented and its influence on t-learning potentials. With these scenarios we present some t-learning applications that were developed, among with an authoring tool for these applications. These studies are being conducted considering the previous experiences on Web-based learning programs},
  keywords = {Interactive Digital TV, T-Learning, E-Learning convergence, iTV Potential},
  address = {San Diego, CA, EUA},
  booktitle = {Frontiers in Education Conference},
  issn = {0190-5848},
  location = {San Diego, CA, EUA},
  month = oct,
  publisher = {IEEE},
  year = {2006}
}

@INPROCEEDINGS{Santos97SAAH,
  author = {G. H. R. Santos and F. M. Vieira and R. Hasegawa and M. G. V. Nunes},
  title = {{SASHE}: Autoria de Aplicações Hipermídia para o Ensino},
  pages = {425--440},
  address = {São José dos Campos},
  booktitle = {VIII Simpósio Brasileiro de Informática na Educação},
  month = nov,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1997}
}

@INPROCEEDINGS{santos-etal:2005,
  author = {N. Santos and F. Campos and R. Braga and A. Oliveira and E. Cirilo and T. Senador},
  title = {An Ontology-Based Digital Library on the e-Learning Domain},
  pages = {580--590},
  address = {Juiz de Fora, MG},
  booktitle = {Simpósio Brasileiro de Informática na Educação (SBIE)},
  month = nov,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {2005}
}

@ARTICLE{SantosJunior-etal:2001,
  author = {Santos Junior, João Benedito and Goularte, Rudinei and dos Santos Moreira, Edson and Faria, Gustavo Blengini},
  title = {The Modeling Of Structured Context-Aware Interactive Environments},
  volume = {5},
  number = {4},
  month = dec,
  year = {2001},
  pages = {77--93},
  abstract = {Using multimedia video objects in building rich, interactive and distributed environments is complex. We want to provide ways in which the user can interact freely with those objects. As a result, the quality of the applications is not only ruled by the presentation machine and its neighborhood but by the traffic conditions and the status of the server as well. As a good practice of design, modeling is essential, as well as the observation of standards. This paper presents a proposal for modeling Structured Context-Aware Interactive Environments, as an approach for covering the user-network-application interactions that occur in an interactive environment. In this scenario, the work discusses mainly which type of contextual information (both at the terminal and the network) could be used in an interactive environment and how it should be manipulated. The concept of program profile is also presented and methods for using profiles in interactive video are discussed. Interactive Television (ITV) programs are presented as an example of application that can use our modeling.},
  acmid = {1241745},
  address = {Amsterdam, } # Netherlands,
  issn = {1092-0617},
  issue_date = {December 2001},
  journal = {Journal of Integrated Design \& Process Science},
  numpages = {17},
  publisher = {IOS Press}
}

@ARTICLE{sanzrodrigues-etal:2011,
  author = {Sanz-Rodriguez, Javier and Dodero, Juan and Sanchez-Alonso, Salvador},
  title = {Metrics-based evaluation of learning object reusability},
  volume = {19},
  year = {2011},
  pages = {121-140},
  doi = {10.1007/s11219-010-9108-5},
  abstract = {This paper aims to help in the selection of reusable educational materials from repositories on the web, developing an indicator of the reusability of learning objects. For this purpose, our research will be carried out in three stages. The first, based on previous studies in this area, will determine those aspects that influence reusability. The second will define a set of metrics that measure those aspects using metadata. The third will propose different methods of aggregation in order to obtain a single resulting value and evaluate the efficiency of the model by analyzing a significant set of learning objects obtained from the eLera and Merlot repositories. The results obtained suggest that the proposed indicator could provide useful information when searching for learning objects in repositories. This reusability measurement could constitute an indicator of quality, which would allow search results to be ordered, with those with the greatest possibility of being reused taking priority. Furthermore, the proposed reusability indicator could be calculated automatically or in an assisted way if metadata elements satisfy the minimum quality requisites identified.},
  affiliation = {University Carlos III of Madrid, Av. Universidad 30, 28911 Leganes, Madrid, Spain},
  issn = {0963-9314},
  issue = {1},
  journal = {Software Quality Journal},
  keyword = {Computer Science},
  publisher = {Springer Netherlands}
}

@INPROCEEDINGS{Saraiva:2010:AMA:1887899.1887915,
  author = {Saraiva, Diego and Pereira, Lucas and Batista, Thais and Delicato, Flávia C. and Pires, Paulo F.},
  title = {Architecting a model-driven aspect-oriented product line for a digital TV middleware: a refactoring experience},
  pages = {166--181},
  abstract = {In this paper, we present the experience of refactoring the architecture of Ginga, the Brazilian Terrestrial Digital TV System (SBTVD) middleware. The main goal of the Ginga refactoring was to increase its configurability, through the automatic management of its variabilities. The resultant middleware, named GingaForAll, is based on a software product line (SPL) architecture, which encompasses both the middleware commonalities and its specific functionalities. Aspect-oriented techniques were used to improve the modularization of crosscutting mandatory and variable features from the Ginga SPL architecture. A model-driven based process was developed to allow the automatic management of the common and variable features in a high abstraction level that supports the management of code assets in terms of configurable models. The integration of such software engineering techniques have contributed to provide a flexible and configurable Ginga architecture, which allows the automatic generation of middleware customizations driven by the devices constraints and applications needs.},
  keywords = {architecture refactoring, aspect-oriented development, configurable middleware, model-driven development, software product lines},
  series = {ECSA'10},
  acmid = {1887915},
  address = {Berlin, Heidelberg},
  booktitle = {Proceedings of the 4th European conference on Software architecture},
  isbn = {978-3-642-15113-2},
  location = {Copenhagen, Denmark},
  numpages = {16},
  publisher = {Springer-Verlag},
  url = {http://portal.acm.org/citation.cfm?id=1887899.1887915},
  year = {2010}
}

@INPROCEEDINGS{sato:1994,
  author = {Livia Matsumoto Sato and Elisa Hatsue Moriya Huzita and L. N. Salvador and T. H. Hsueh},
  title = {ONIX: An Environment for the Development of Parallel Object Oriented Software},
  pages = {167-183},
  address = {São Paulo},
  booktitle = {Internacional Workshop on High Performance Computing},
  owner = {magsilva},
  timestamp = {2008.07.30},
  year = {1994}
}

@INPROCEEDINGS{Sauro-Lewis:2011,
  author = {Sauro, Jeff and Lewis, James R.},
  title = {When designing usability questionnaires, does it hurt to be positive?},
  pages = {2215--2224},
  doi = {10.1145/1978942.1979266},
  abstract = {When designing questionnaires there is a tradition of including items with both positive and negative wording to minimize acquiescence and extreme response biases. Two disadvantages of this approach are respondents accidentally agreeing with negative items (mistakes) and researchers forgetting to reverse the scales (miscoding). The original System Usability Scale (SUS) and an all positively worded version were administered in two experiments (n=161 and n=213) across eleven websites. There was no evidence for differences in the response biases between the different versions. A review of 27 SUS datasets found 3 (11%) were miscoded by researchers and 21 out of 158 questionnaires (13%) contained mistakes from users. We found no evidence that the purported advantages of including negative and positive items in usability questionnaires outweigh the disadvantages of mistakes and miscoding. It is recommended that researchers using the standard SUS verify the proper coding of scores and include procedural steps to ensure error-free completion of the SUS by users. Researchers can use the all positive version with confidence because respondents are less likely to make mistakes when responding, researchers are less likely to make errors in coding, and the scores will be similar to the standard SUS.},
  keywords = {acquiescent bias, satisfaction measures, standardized questionnaires, system usability scale (sus), usability evaluation},
  address = {New York, NY, USA},
  booktitle = {Annual Conference on Human Factors in Computing Systems},
  isbn = {978-1-4503-0228-9},
  location = {Vancouver, BC, Canada},
  publisher = {ACM},
  year = {2011}
}

@BOOK{Savage,
  title = {Models of computation : exploring the power of computing},
  publisher = {Addison Wesley},
  year = {1998},
  author = {John E. Savage},
  isbn = {0201895390},
  pages = {672},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@ARTICLE{scacchi:2004,
  author = {W. Scacchi},
  title = {Free and open source development practices in the game community},
  volume = {21},
  number = {1},
  month = jan,
  year = {2004},
  pages = {59 - 66},
  journal = {IEEE Software},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@INPROCEEDINGS{scacchi:2002,
  author = {Walt Scacchi},
  title = {Understanding the requirements for developing open source software systems},
  pages = {24-39},
  volume = {149},
  number = {1},
  booktitle = {IEE Proceedings - Software},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://mit.edu/papers/Scacchi.pdf},
  year = {2002}
}

@BOOK{Schach:2008,
  title = {Engenharia de Software: Os Paradigmas Clássico e Orientado a Objetos},
  publisher = {McGraw-Hill},
  year = {2008},
  author = {Stephen R. Schach},
  isbn = {978-85-7726-045-4},
  translator = {Ariovaldo Griesi},
  translation-of = {Scach:2007},
  pages = {618},
  address = {São Paulo, SP, } # Brazil,
  edition = {7},
  owner = {magsilva},
  timestamp = {2014.08.26}
}

@BOOK{Scach:2007,
  title = {Object-Oriented and Classical Software Engineering},
  publisher = {McGraw-Hill},
  year = {2007},
  author = {Stephen R. Schach},
  isbn = {978-0-07-319126-3},
  edition = {7},
  owner = {magsilva},
  timestamp = {2014.08.26}
}

@ARTICLE{Schaefer:2011,
  author = {Schaefer, Robert},
  title = {On the limits of visual programming languages},
  volume = {36},
  month = mar,
  year = {2011},
  pages = {7--8},
  doi = {10.1145/1943371.1943373},
  acmid = {1943373},
  address = {New York, NY, USA},
  issn = {0163-5948},
  issue = {2},
  issue_date = {March 2011},
  journal = {SIGSOFT Software Engieerng Notes},
  numpages = {2},
  publisher = {ACM}
}

@PHDTHESIS{Schafer:2001,
  author = {John Benjamin Schafer},
  title = {{MetaLens}: a framework for multi-source recommendations},
  school = {University of Minnesota},
  year = {2001},
  advisor = {Joseph A. Konstan},
  address = USA,
  month = jul,
  url = {http://www.cs.uni.edu/~schafer/publications/schafer_thesis.pdf},
  timestamp = {2013-09-26}
}

@TECHREPORT{schelebbe:1995,
  author = {H. Schelebbe},
  title = {Distributed PROSOFT},
  institution = {University of Stuttgart},
  year = {1995},
  address = {Germany},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@BOOK{Schildt:2008,
  publisher = {Pearson},
  year = {2008},
  author = {Herbert Schildt},
  isbn = {978-85-346-0595-3},
  pages = {827},
  address = {São Paulo, SP, } # Brazil,
  edition = {3},
  month = mar,
  booktitle = {C Completo e Total}
}

@MISC{software:codecover,
  author = {Rainer Schmidberger and others},
  title = {{CodeCover}},
  howpublished = software,
  year = {2007},
  license = {EPL},
  owner = {magsilva},
  timestamp = {2014.07.21},
  url = {http://codecover.org}
}

@ARTICLE{Schmidt:2006,
  author = {Douglas C. Schmidt},
  title = {Model-Driven Engineering},
  volume = {39},
  number = {2},
  month = feb,
  year = {2006},
  pages = {25-31},
  doi = {10.1109/MC.2006.58},
  abstract = {Model-driven engineering technologies offer a promising approach to address the inability of third-generation languages to alleviate the complexity of platforms and express domain concepts effectively.},
  issn = {0018-9162},
  journal = {IEEE Software},
  lang = {en},
  owner = {magsilva},
  publisher = {IEEE},
  timestamp = {2009.01.29}
}

@INPROCEEDINGS{schmidt:1997,
  author = {K. Schmidt},
  title = {Of Maps and Scripts --- Status of Informal Constructs in Cooperative Work},
  pages = {138-147},
  booktitle = {ACM Conference on Supporting Group Work},
  owner = {magsilva},
  timestamp = {2008.07.30},
  year = {1997}
}

@INPROCEEDINGS{Schmieder-Wierzbicki:2009,
  author = {Schmieder, Thomas and Wierzbicki, Robert J.},
  title = {Competitive acting: issues on action, interaction and acting in converged media},
  pages = {6--10},
  doi = {10.1145/1621841.1621844},
  abstract = {One of the challenging problems of tomorrow's iTV is how to generate a digital drama that looks like a real movie but which emerges out of the interaction of many (thousands) users. The problem of actors' credibility has been widely discussed in the relevant literature, however only in the context of the traditional theatre play. This article describes some basic aspects of future acting in digital environments. It also introduces the concept of "competitive acting", a new paradigm for digital stage plays of the future combining drama with interaction-driven dialogue and action elements in converged media.},
  keywords = {GAMECAST, competitive acting, converged media, digital drama, digital stage play, future drama, iTV, participation-of-many, series type, television},
  address = {Tampere, Finlândia},
  booktitle = {13th International MindTrek Conference: Everyday Life in the Ubiquitous Era},
  isbn = {978-1-60558-633-5},
  location = {Tampere, Finlândia},
  publisher = {ACM},
  year = {2009}
}

@ARTICLE{Hans,
  author = {Hans J. Schneider},
  title = {Computability in an Introductory Course on Programming},
  volume = {73},
  year = {2001},
  pages = {153-164},
  url = {\url{http://www2.informatik.uni-erlangen.de/~schneide/publications/comput.pdf} (19/09/2002)},
  journal = {Bulletin of the European Association for Theoretical Computer Science (EATCS)},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@MISC{software:pear-soap,
  author = {Jan Schneider and Chuck Hagenbuch and Shane Caraveo and Al Baker and Arnaud Limbourg},
  title = {PEAR::Package::SOAP},
  howpublished = {Programa de Computador},
  month = jul,
  year = {2002},
  owner = {magsilva},
  timestamp = {2006.08.01},
  url = {http://pear.php.net/package/SOAP}
}

@ARTICLE{schneidewind:2002,
  author = {Norman F. Schneidewind},
  title = {Body of Knowledge for Software Quality Measurement},
  month = feb,
  year = {2002},
  pages = {77-83},
  journal = {IEEE Computer},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@MISC{software:amule,
  author = {Angel Vidal Veiga \and K. B. \and Mikkel Schubert and others},
  title = {aMule},
  howpublished = {Programa de computador},
  month = sep,
  year = {2003},
  owner = {msilva},
  timestamp = {2006.02.24},
  url = {http://www.amule.org}
}

@BOOK{schumacher:2003,
  title = {Security Engineering with Patterns},
  publisher = {Springer},
  year = {2003},
  author = {Markus Schumacher},
  editor = {G. Goos and J. Hartmanis and J. van Leeuwen},
  volume = {2754},
  series = {Lecture Notes in Computer Science},
  owner = {magsilva},
  timestamp = {2006.07.10}
}

@INBOOK{schumacher:2003:1,
  chapter = {Ontology Development},
  pages = {179-184},
  title = {Ontology development},
  publisher = {Springer},
  year = {2003},
  author = {Markus Schumacher},
  owner = {magsilva},
  timestamp = {2006.07.10}
}

@INBOOK{schumacher:2003:2,
  chapter = {Toward a Security Core Ontology},
  pages = {87-96},
  title = {Toward a Securit Core Ontology},
  publisher = {Springer},
  year = {2003},
  author = {Markus Schumacher},
  owner = {magsilva},
  timestamp = {2006.07.10}
}

@INPROCEEDINGS{Schwabe-Rossi:1995,
  author = {Daniel Schwabe and Gustavo Rossi},
  title = {Building Hypermedia Applications as Navigational Views of information Models},
  pages = {231-240},
  doi = {10.1109/HICSS.1995.375557},
  abstract = {Presents a novel approach for defining hypermedia applications as navigational views of an object-oriented hypermedia schema. We briefly describe an object-oriented hypermedia design model (OOHDM) using an academic information system as a concrete example to illustrate each modeling construct. We further analyze the whole process of hypermedia applications building, focusing mainly on navigational design. The approach we propose allows clean separation of the content design, navigational design and abstract interface design. Such separation of concerns allows seamless evolution from abstract domain models to concrete implementation of hypermedia applications, especially those in which there is a wide range of information to be handled.},
  volume = {3},
  address = {Maui, Havaí},
  booktitle = {28th Hawaii International Conference on Information Systems},
  citeseerurl = {citeseer.ist.psu.edu/schwabe95building.html},
  isbn = {0-8186-6940-3},
  location = {Wailea, HI , #USA#},
  month = jan,
  owner = {magsilva},
  publisher = {IEEE},
  timestamp = {2008.07.30},
  year = {1995}
}

@INPROCEEDINGS{Schwabe-etal:1996,
  author = {Daniel Schwabe and Gustavo Rossi and Simone D. J. Barbosa},
  title = {Systematic Hypermedia Application Design with {OOHDM}},
  pages = {116-128},
  booktitle = {{UK} Conference on Hypertext},
  citeseerurl = {citeseer.ist.psu.edu/schwabe96systematic.html},
  owner = {magsilva},
  timestamp = {2008.07.30},
  year = {1996}
}

@ARTICLE{kmail:2000,
  author = {David G. Schwartz and Dov Te'eni},
  title = {Tying Knowledge to Action with kMail},
  month = may,
  year = {2000},
  pages = {33-39},
  journal = {IEEE Intelligent Systems},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@MISC{software:sci2,
  author = {{Sci2 Team}},
  title = {Science of Science (Sci2) Tool},
  howpublished = {Programa de Computador},
  year = {2009},
  note = {Indiana University and SciTech Strategies},
  url = {http://sci2.cns.iu.edu}
}

@BOOK{seels-glasgow:1998,
  title = {Making Instructional Design Decisions},
  publisher = {Columbus: Prentice-Hall, Inc.},
  year = {1998},
  author = {B. Seels and Z. Glasgow},
  edition = {2},
  owner = {magsilva},
  timestamp = {2008.01.21}
}

@INPROCEEDINGS{steffah:2002,
  author = {Seffah, A. and Grogono, P.},
  title = {Learner-centered software engineering education: from resources to skills and pedagogical patterns},
  booktitle = {15th Conference on Software Engineering Education and Training (CSEE\&T 2002)},
  owner = {magsilva},
  timestamp = {2007.10.10},
  year = {2002}
}

@PHDTHESIS{SantaremSegundo:2010,
  author = {José Eduardo Santarem Segundo},
  title = {Representação iterativa: um modelo para repositórios digitais},
  abstract = {A recuperação da informação tem sido muito discutida e abordada dentro da Ciência da Informação nos últimos anos, principalmente depois da explosão informacional gerada pela Internet. A busca por informação de qualidade e compatível com a necessidade do usuário tem sido tratada como obsessão, atualmente. A utilização da Internet indicou novos modelos de armazenamento de informações, como os repositórios digitais, que têm sido utilizados em ambientes acadêmicos e de pesquisa como principal forma de autoarquivar e, principalmente, de disseminar informação, porém com uma estrutura de informação que sugere melhor descrição dos recursos do que a própria Web e indica uma melhor recuperação da informação nestes ambientes. Os repositórios ainda não estão aptos a recuperar informação de forma semântica e contextualizada. Os novos paradigmas de Internet sugerem utilização dos recursos de Web 2.0 e também de Web 3.0, permitindo, respectivamente, interatividade e também estrutura de informação semântica. Desta forma o objetivo desta pesquisa é melhorar o processo de recuperação da informação, apresentando uma proposta de modelo estrutural no contexto da Web Semântica, abordando o uso de recursos da Web 2.0 e Web 3.0 em repositórios digitais, que permita recuperação semântica da informação, através da construção de uma camada de informação chamada Representação Iterativa. Através do modelo sugerido e proposto -- Representação Iterativa -- será possível adequar os repositórios digitais para que utilizem Folksonomia e também vocabulário controlado de domínio, de forma a gerar uma camada de informação iterativa, que possibilite retroalimentação da informação, além de recuperação semântica da informação, através do modelo estrutural desenhado para repositórios. O modelo sugerido resultou na efetivação da tese de que através da Representação Iterativa é possível estabelecer um processo de recuperação semântica da informação em repositórios digitais.},
  school = {UNESP},
  year = {2010},
  address = {Marília, SP, } # Brazil
}

@INPROCEEDINGS{senas-moroni:1997,
  author = {P. Senãs and N. Moroni},
  title = {Un Ambiente Computacional para el Aprendizaje Significativo: Mapas Conceptuales Hipermediales},
  pages = {469--483},
  address = {São José dos Campos},
  booktitle = {Simpósio Brasileiro de Informática na Educação},
  month = nov,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1997}
}

@PHDTHESIS{seno:2007,
  author = {Wesley Peron Seno},
  title = {Capacitação docente para a educação a distância sob a óptica de competências: um modelo de referência},
  school = {Escola de Engenharia de São Carlos - Universidade de São Paulo},
  year = {2007},
  address = {São Carlos, SP},
  note = {Orientado por Renato Vairo Belhot},
  timestamp = {2008.09.15}
}

@ARTICLE{serrano-camposcapelastegui:2011,
  author = {Serrano, Nicolas and Campos-Capelastegui, Joseba},
  title = {Don't Read Books},
  volume = {28},
  number = {2},
  month = mar # {-} # apr,
  year = {2011},
  pages = {92 -94},
  doi = {10.1109/MS.2011.30},
  abstract = {Reading is a critical habit to learn and keeping current. But books aren't the only thing available to read. The articles discuss pros and cons of articles related to books and how to organize and choose your readings. Reading articles is a good source of knowledge and will help you to read better, read better books, and even read more books.},
  issn = {0740-7459},
  journal = {IEEE Software},
  publisher = {IEEE}
}

@MISC{software:bzip2,
  author = {Julian Seward},
  title = {bzip2},
  howpublished = {Programa de computador},
  year = {1996},
  owner = {msilva},
  timestamp = {2006.02.23},
  url = {http://www.bzip.org/}
}

@INPROCEEDINGS{Sgrignoli:2007,
  author = {Gary Sgrignoli},
  title = {History of {ATSC} Digital Television Transmission System},
  pages = {1-2},
  doi = {10.1109/ICCE.2007.341420},
  abstract = {The ATSC 8-VSB DTV transmission system has been the U.S. standard since December 1996. Its path to becoming a standard included the work of many people and organizations, among them the Grand Alliance (GA), the Federal Communications Commission (FCC), and the Advanced Television Systems Committee (ATSC). A brief history of the ATSC transmission system is described.},
  address = {Las Vegas, NV, EUA},
  booktitle = {International Conference on Consumer Electronics (ICCE)},
  isbn = {1-4244-0763-X, 1-4244-0763-X},
  location = {Las Vegas, NV, #USA#},
  month = jan,
  publisher = {IEEE},
  review = {en},
  timestamp = {2008.09.01},
  year = {2007}
}

@ARTICLE{Shaer-Hornecker:2010,
  author = {Shaer, Orit and Hornecker, Eva},
  title = {Tangible User Interfaces: Past, Present, and Future Directions},
  volume = {3},
  number = {1-2},
  month = jan,
  year = {2010},
  pages = {1--137},
  doi = {10.1561/1100000026},
  abstract = {In the last two decades, Tangible User Interfaces (TUIs) have emerged as a new interface type that interlinks the digital and physical worlds. Drawing upon users' knowledge and skills of interaction with the real non-digital world, TUIs show a potential to enhance the way in which people interact with and leverage digital information. However, TUI research is still in its infancy and extensive research is required in order to fully understand the implications of tangible user interfaces, to develop technologies that further bridge the digital and the physical, and to guide TUI design with empirical knowledge. This monograph examines the existing body of work on Tangible User Interfaces. We start by sketching the history of tangible user interfaces, examining the intellectual origins of this field. We then present TUIs in a broader context, survey application domains, and review frameworks and taxonomies. We also discuss conceptual foundations of TUIs including perspectives from cognitive sciences, psychology, and philosophy. Methods and technologies for designing, building, and evaluating TUIs are also addressed. Finally, we discuss the strengths and limitations of TUIs and chart directions for future research.},
  acmid = {1755234},
  address = {Hanover, MA, USA},
  issn = {1551-3955},
  issue = {1\&\#8211;2},
  journal = {Foundations and Trends in Human-Computer Interaction},
  numpages = {137},
  publisher = {Now Publishers Inc.}
}

@ARTICLE{Shaer-Jacob:2009,
  author = {Shaer, Orit and Jacob, Robert J.K.},
  title = {A specification paradigm for the design and implementation of tangible user interfaces},
  volume = {16},
  number = {4},
  month = nov,
  year = {2009},
  pages = {1--39},
  doi = {10.1145/1614390.1614395},
  abstract = {Tangible interaction shows promise to significantly enhance computer-mediated support for activities such as learning, problem solving, and design. However, tangible user interfaces are currently considered challenging to design and build. Designers and developers of these interfaces encounter several conceptual, methodological, and technical difficulties. Among others, these challenges include: the lack of appropriate interaction abstractions, the shortcomings of current user interface software tools to address continuous and parallel interactions, as well as the excessive effort required to integrate novel input and output technologies. To address these challenges, we propose a specification paradigm for designing and implementing Tangible User Interfaces (TUIs), that enables TUI developers to specify the structure and behavior of a tangible user interface using high-level constructs which abstract away implementation details. An important benefit of this approach, which is based on User Interface Description Language (UIDL) research, is that these specifications could be automatically or semi-automatically converted into concrete TUI implementations. In addition, such specifications could serve as a common ground for investigating both design and implementation concerns by TUI developers from different disciplines. Thus, the primary contribution of this article is a high-level UIDL that provides developers from different disciplines means for effectively specifying, discussing, and programming a broad range of tangible user interfaces. There are three distinct elements to this contribution: a visual specification technique that is based on Statecharts and Petri nets, an XML-compliant language that extends this visual specification technique, as well as a proof-of-concept prototype of a Tangible User Interface Management System (TUIMS) that semi-automatically translates high-level specifications into a program controlling specific target technologies.},
  keywords = {Tangible interaction, tangible user interfaces, user interface description language, user interface management system},
  acmid = {1614395},
  address = {New York, NY, USA},
  articleno = {20},
  issn = {1073-0516},
  issue = {4},
  issue_date = {November 2009},
  journal = {ACM Transactions on Computer-Human Interaction (TOCHI)},
  lang = {en},
  numpages = {39},
  publisher = {ACM}
}

@MISC{j2ee:2003,
  author = {Bill Shannon},
  title = {Java 2 Plataform Enterprise Edition Specification v1.4},
  howpublished = {JCP Specification},
  month = {nov},
  year = {2003},
  file = {Java 2 Plataform Enterprise Edition Specification v1.4.pdf:Java 2 Plataform Enterprise Edition Specification v1.4.pdf:PDF},
  owner = {Marco Aurélio Graciotto Silva},
  timestamp = {2008.07.30}
}

@ARTICLE{Sharples:2000,
  author = {Mike Sharples},
  title = {The Design of Personal Mobile Technologies for Lifelong Learning},
  volume = {34},
  number = {3-4},
  year = {2000},
  pages = {177-193},
  doi = {10.1016/S0360-1315(99)00044-5},
  abstract = {This paper sets out a framework for the design of a new genre of educational technology -- personal (handheld or wearable) computer systems that support learning from any location throughout a lifetime. We set out a theory of lifelong learning mediated by technology and indicate how it can provide requirements for the software, hardware, communications and interface design of a handheld learning resource, or HandLeR. The paper concludes with a description and formative evaluation of a demonstrator system for children aged 7-11.},
  keywords = {Architectures for educational technology systems; Human-computer interaction; Interactive learning environments; Lifelong learning},
  issn = {0360-1315},
  journal = {Computers and Education},
  timestamp = {2008.10.01}
}

@ARTICLE{sharples-etal:2002,
  author = {Mike Sharples and Dan Corlett and Oliver Westmancott},
  title = {The Design and Implementation of a Mobile Learning Resource},
  volume = {6},
  year = {2002},
  pages = {220-234},
  journal = {Personal and Ubiquitous Computing},
  timestamp = {2008.10.01}
}

@BOOK{Shaw-Garlan:1996,
  title = {Software architecture: perspectives on an emerging discipline},
  publisher = {Prentice-Hall},
  year = {1996},
  author = {Mary Shaw and David Garlan},
  isbn = {978-0131829572},
  pages = {242},
  address = {Upper Saddle River, NJ, } # USA,
  edition = {1},
  month = apr,
  booktitle = {Software architecture: perspectives on an emerging discipline},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@PHDTHESIS{sherba:2005,
  author = {Susanne A. Sherba},
  title = {Towards Automating Traceability: An Incremental and Scalable Approach},
  abstract = {Software engineers face significant challenges when creating and maintaining traceability information. Many software tools lack the ability to automatically create semantic relationships between a software project's heterogeneous artifacts. Thus, traceability typically involves laborious, manual procedures and, as such, these important techniques face serious adoption hurdles by developers. In this work, we describe a new approach to traceability that automates the creation and maintenance of traceability information among heterogeneous software artifacts. Furthermore, our approach allows these relationships to be viewed in the tool that originally created the artifact rather than forcing the user to switch to a separate tool to view these relationships. Our conceptual framework, TraceM, incorporates techniques from open hypermedia and information integration to provide scheduling, query, relationship mapping, evolution, and export services. We have developed a prototype implementation of TraceM to evaluate our approach. Our evaluation includes a small study of its usability and utility as well as a separate scalability test using artifacts obtained from industry.},
  school = {University of Colorado in Boulder},
  year = {2005},
  month = {aug},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@BOOK{shneiderman:1989,
  title = {Hypertext Hands-On! An introduction to a New Way of Organizing and Accessing Information},
  publisher = {Addison-Wesley},
  year = {1989},
  author = {B. Shneiderman and G. Kearsley},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@INPROCEEDINGS{Shull-etal:2001,
  author = {F. Shull and J. Carver and G. H. Travassos},
  title = {An Empirical Methodology for Introducing Software Processes},
  pages = {288--296},
  doi = {10.1145/503209.503248},
  abstract = {There is a growing interest in empirical study in software engineering, both for validating mature technologies and for guiding improvements of less-mature technologies. This paper introduces an empirical methodology, based on experiences garnered over more than two decades of work by the Empirical Software Engineering Group at the University of Maryland and related organizations, for taking a newly proposed improvement to development processes from the conceptual phase through transfer to industry. The methodology presents a series of questions that should be addressed, as well as the types of studies that best address those questions. The methodology is illustrated by a specific research program on inspection processes for Object-Oriented designs. Specific examples of the studies that were performed and how the methodology impacted the development of the inspection process are also described.},
  keywords = {Empirical studies, OO design inspections, software process, experimental process, software quality},
  booktitle = {Joint 8th European Software Engineering Conference (ESEC) and 9th ACM SIGSOFT Symposium on the Foundations of Software Engineering (FSE-9)},
  isbn = {1-58113-390-1},
  lang = {en},
  location = {Vienna, #Austria#},
  month = sep,
  publisher = {ACM},
  year = {2001}
}

@INBOOK{Shull-Feldmann:2008,
  chapter = {Building Theories from Multiple Evidence Sources},
  pages = {337-364},
  title = {Guide to Advanced Empirical Software Engineering},
  publisher = {Springer},
  year = {2008},
  editor = {F. Shull and others},
  author = {Forrest Shull and Raimund L. Feldmann},
  owner = {magsilva},
  timestamp = {2010.08.10}
}

@ARTICLE{Shull:2000,
  author = {Forrest Shull and Ioana Rus and Victor Basili},
  title = {How Perspective-Based Reading Can Improve Requirements Inspections},
  volume = {33},
  number = {7},
  month = {jul},
  year = {2000},
  pages = {73-79},
  journal = {IEEE Software},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@ARTICLE{Shull-etal:2006,
  author = {Forrest Shull and Carolyn Seaman and Marvin Zelkowitz},
  title = {{Victor R. Basili's} contributions to software quality},
  volume = {23},
  number = {1},
  month = jan,
  year = {2006},
  pages = {16-18},
  doi = {10.1109/MS.2006.33},
  abstract = {This article deals with Victor R. Basili's contributions to software quality. Basili's contributions cover three broad areas: research in the 1970s and early 1980s on software measurement and the Goal Question Metric (GQM) model, research in the 1980s and 1990s on these measurement ideas' maturation into a software engineering model of empirical studies, including the development of the Quality Improvement Paradigm (QIP) and the influence of the NASA Goddard Space Flight Center Software Engineering Laboratory, and research since 1990 in the Experience Factory as a model for creating learning organizations for continuous software process improvement. Some of Basili's most important contributions are in measuring software development processes and products and gifted the community with an invaluable tool: the GQM approach. The GQM approach is based on the assumption that for an organization to measure its products and processes usefully, it must first specify goals for itself and its projects},
  journal = {IEEE Software},
  owner = {magsilva},
  timestamp = {2010.08.09}
}

@BOOK{Siegel96CFPR,
  title = {{CORBA} Fundamentals and Programming},
  publisher = {Wiley},
  year = {1996},
  author = {J. Siegel},
  address = {New York, NY},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@BOOK{Silberschatz-etal:,
  title = {Sistema de Banco de Dados},
  publisher = {Elsevier},
  year = {2006},
  author = {Abraham Silberschatz and Henry F. Korth and S. Sudarshan},
  isbn = {978-85-352-1107-8},
  pages = {781},
  address = {Rio de Janeiro, RJ, } # Brazil,
  edition = {5},
  note = {Traduzido por Daniel Vieira},
  booktitle = {Sistema de Banco de Dados}
}

@INPROCEEDINGS{Siller-Woods:2003,
  author = {Siller, M. and Woods, J.C.},
  title = {QoS arbitration for improving the QoE in multimedia transmission},
  pages = {238 - 241},
  doi = {10.1049/cp:20030531},
  abstract = {This contribution presents a Quality of Experience (QoE) framework. It evaluates QoE using QoS metrics, network feedback, and dynamic user requirements. and proposes a definition for QoE. A model for experimenting within the QoE framework is presented. It is believed that a better QoE can be achieved when the QoS and its interaction with the network and application layer, is considered as a whole rather than a single entity.},
  keywords = {Quality of Experience; Quality of Service; arbitration; differential services; layered coding; multimedia; user requirements; multimedia communication; quality of service;},
  booktitle = {International Conference on Visual Information Engineering},
  isbn = {0-85296-757-8},
  issn = {0537-9989},
  month = jul,
  year = {2003}
}

@MISC{silva04dsb,
  author = {G. Silva and P. Pereira and G. Magalhães},
  title = {Disponibilização de Serviços Baseados em Localização via Web Services},
  year = {2004},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@MISC{decreto5296,
  author = {Luiz Inácio Lula da Silva},
  title = {Decreto Nº 5.296 de 2 de Dezembro de 2004},
  howpublished = {Decreto},
  month = dec,
  year = {2004},
  owner = {magsilva},
  timestamp = {2007.08.11},
  url = {https://www.planalto.gov.br/ccivil_03/_Ato2004-2006/2004/Decreto/D5296.htm}
}

@MISC{decree:brazil:5820,
  author = {Luiz Inácio Lula da Silva and Helio Costa},
  title = {Decreto nº 5.820},
  howpublished = {Decree},
  month = jun,
  year = {2006},
  note = {Published at 30/06/2006.},
  owner = {magsilva},
  timestamp = {2009.08.19},
  url = {http://www.planalto.gov.br/ccivil_03/_Ato2004-2006/2006/Decreto/D5820.htm}
}

@MISC{decree:brazil:4901,
  author = {Luiz Inácio Lula da Silva and Miro Teixeira and José Dirceu de Oliveira e Silva},
  title = {Decreto nº 4.901},
  howpublished = {Decree},
  month = nov,
  year = {2003},
  note = {Published at 27/11/2003.},
  owner = {magsilva},
  timestamp = {2009.08.19},
  url = {http://www.planalto.gov.br/ccivil_03/decreto/2003/D4901.htm}
}

@MISC{software:semaps,
  author = {Marco Aurélio Graciotto Silva},
  title = {Mapas da Engenharia de Software no Brasil},
  howpublished = {Programa de Computador},
  timestamp = {2008.09.01},
  url = {http://www.labes.icmc.usp.br/~magsilva/SELabMaps}
}

@MISC{GraciottoSilva:2013:ComputingContestProject,
  author = {Marco Aurélio Graciotto Silva},
  title = {Competições de programação como instrumento para formação e aperfeiçoamento em {Informática}},
  howpublished = {Projeto de extensão},
  month = jun,
  year = {2013},
  note = {Projeto homologado pelo Edital PROREC 02/2013-UTFPR\_Extensão},
  timestamp = {2013-11-17}
}

@TECHREPORT{silva:2011:sysrev,
  author = {Marco Aurélio Graciotto Silva},
  title = {Processo de revisão sistemática},
  institution = {Instituto de Ciências Matemáticas e de Computação},
  year = {2011},
  owner = {magsilva},
  timestamp = {2010.09.13}
}

@MISC{silva:2008:projetodoutorado,
  author = {Marco Aurélio Graciotto Silva},
  title = {Uma contribuição ao processo de desenvolvimento de módulos educacionais abertos para televisão digital},
  howpublished = {Projeto de Doutorado},
  month = jan,
  year = {2008},
  note = {Orientador: José Carlos Maldonado},
  timestamp = {2008.08.06}
}

@MISC{silva:2007,
  author = {Marco Aurélio Graciotto Silva},
  title = {Processo de Revisão Sistemática},
  month = nov,
  year = {2007},
  owner = {magsilva},
  timestamp = {2007.11.16}
}

@MISC{silva:2007:revsys,
  author = {Marco Aurélio Graciotto Silva},
  title = {Revisão sistemática sobre padrões pedagógicos},
  howpublished = {Artigo para disciplina},
  month = nov,
  year = {2007},
  timestamp = {2008.10.07},
  url = {http://www.labes.icmc.usp.br/~magsilva/Projects/RevSys/PedagogicalPatterns.pdf}
}

@MISC{silva:ideais:plano:2006,
  author = {Marco Aurélio Graciotto Silva},
  title = {Integração de ferramentas utilizadas em empresas de desenvolvimento de software},
  howpublished = {Bolsa de Fomento Tecnológico DTI/CNPq (Processo 551994/2005)},
  month = apr,
  year = {2006},
  owner = {magsilva},
  timestamp = {2007.01.18}
}

@MISC{silva:ideais:relatorio:2006,
  author = {Marco Aurélio Graciotto Silva},
  title = {Avaliação de Ferramentas Livres de Apoio às Atividades de Desenvolvimento de Software},
  howpublished = {Relatório Final (DTI)},
  month = jul,
  year = {2006},
  owner = {magsilva},
  timestamp = {2007.02.27}
}

@MASTERSTHESIS{silva:2005,
  author = {Marco Aurélio Graciotto Silva},
  title = {Uma ferramenta Web colaborativa para apoiar a engenharia de requisitos em software livre},
  school = {Universidade de São Paulo},
  year = {2005},
  address = {São Carlos, Brasil},
  month = {nov},
  owner = {magsilva},
  timestamp = {2006.09.28}
}

@MISC{silva:ideais:plano:2005,
  author = {Marco Aurélio Graciotto Silva},
  title = {Avaliação de Ferramentas Livres de Apoio às Atividades de Desenvolvimento de Software},
  howpublished = {Plano de Trabalho},
  month = nov,
  year = {2005},
  owner = {magsilva},
  timestamp = {2006.09.12}
}

@MISC{software:coteia,
  author = {Marco Aurélio Graciotto Silva},
  title = {CoTeia},
  howpublished = {Programa de Computador},
  month = feb,
  year = {2004},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://incubadora.fapesp.br/projects/coteia}
}

@MISC{silva:2002:1,
  author = {Marco Aurélio Graciotto Silva},
  title = {Uma Ferramenta para Apoiar a Definição de Requisitos no Desenvolvimento de Software Distribuído},
  howpublished = {Relatório de Iniciação Científica},
  month = mar,
  year = {2002},
  institution = {UEM},
  owner = {magsilva},
  school = {UEM},
  timestamp = {2008.07.30}
}

@MISC{silva:2002:2,
  author = {Marco Aurélio Graciotto Silva},
  title = {Uma Ferramenta para Apoiar a Definição de Requisitos no Desenvolvimento de Software Distribuído},
  howpublished = {Monografia de Trabalho de Graduação},
  month = jun,
  year = {2002},
  owner = {magsilva},
  school = {UEM},
  timestamp = {2008.07.30}
}

@MASTERSTHESIS{silva:2005:masterthesis,
  author = {SILVA, S.R.Q.M},
  title = {Controle de versões - um apoio à edição colaborativa na Web},
  school = {Instituto de Ciências Matemáticas e de Computação de São Carlos, Universidade de São Paulo},
  year = {2005},
  month = jul,
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@INPROCEEDINGS{Solino-Vergilio:2009,
  author = {Silva Solino, André Luiz da and Vergilio, Silvia Regina},
  title = {Mutation based testing of Web Services},
  pages = {1--6},
  doi = {10.1109/LATW.2009.4813786},
  abstract = {Web services (WS) have been largely used in the development of Web applications. Because of this and due to their importance and inherent characteristics, there is a crescent demand for WS testing techniques and tools. Different testing approaches have been proposed, however most of them do not offer a criterion to be used to evaluate the generated test data. To allow this, the present work explores mutation operators, specific for WSDL documents. The idea is to consider semantic aspects of those documents and to reveal different kind of faults. A supporting tool is also described and evaluation results of a study case are discussed, which allow comparison with other approaches.},
  booktitle = {10th Latin American Test Workshop (LATW '09)},
  location = {Búzios, RJ, #Brazil#},
  month = mar,
  year = {2009}
}

@MASTERSTHESIS{simao:2000:dissertation,
  author = {Adenilso S. Simão},
  title = {{Proteum-RS/PN}: Uma Ferramenta para a Validação de Redes de Petri Baseada na Análise de Mutantes},
  abstract = {Sistemas Reativos caracterizam-se por reagir continuamente a estímulos externos e internos e controlar atividades humanas. A ocorrência de falhas nesses sistemas pode resultar em grandes prejuízos. Dessa forma, o uso de métodos e técnicas rigorosas para a especificação do comportamento desse tipo de sistema é essencial, buscando-se evitar inconsistências e ambigüidades no modelo. Redes de Petri é uma das técnicas que têm sido usadas para a especificação de sistemas reativos. Teste e validação são atividades essenciais na produção dessa classe de sistemas. Por isso, o critério Análise de Mutantes, um critério de teste baseado em erros normalmente aplicado ao teste de programas, tem sido explorado no contexto de teste de especificações de sistemas reativos. É necessário o desenvolvimento de ferramentas que apóiem sua utilização, visto que a aplicação manual do critério é impraticável. O objetivo deste trabalho é a implementação da ferramenta Proteum-RS/PN, que apóia a aplicação do critério Análise de Mutantes para validar especificações baseadas em Redes de Petri.},
  school = {ICMC-USP},
  year = {2000},
  address = {São Carlos, SP},
  month = feb,
  note = Advisor # {: José Carlos Maldonado},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{simao-maldonado:2001:sbes,
  author = {A. S. Simão and J. C. Maldonado},
  title = {{MuDeL}: A Language and a System for Describing and Generating Mutants},
  address = {Rio de Janeiro, RJ, Brasil},
  booktitle = {XV Simpósio Brasileiro de Engenharia de Software (SBES 2001)},
  month = oct,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {2001}
}

@INPROCEEDINGS{simao-maldonado:2000:wmf,
  author = {A. S. Simão and J. C. Maldonado},
  title = {Geração de Seqüências para Redes de Petri Baseadas em Mutação},
  address = {João Pessoa, PB, Brasil},
  booktitle = {III Workshop de Métodos Formais},
  month = oct,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {2000}
}

@INPROCEEDINGS{simao-etal:2006:wei,
  author = {Adenilso S. Simão and Elaine P. M. de Sousa and Francisco J. Monaco and Luciana A. F. Martimiano},
  title = {Multidisciplinaridade com o uso de Jogos Eletrônicos},
  pages = {196-205},
  address = {Campo Grande, MS},
  booktitle = {XXVI Congresso da SBC, XIV Workshop sobre Educação em Computação},
  month = jul,
  timestamp = {2008.07.31},
  year = {2006}
}

@INPROCEEDINGS{simao-etal:2002:icse,
  author = {A. S. Simão and A. M. R. Vincenzi and J. C. Maldonado and A. C. L. Santana},
  title = {{ID}e{L}: An Abstract Language for Instrumenting Code},
  address = {Buenos Aires, Argentina},
  booktitle = {24th International Conference on Software Engineering -- ICSE'2002},
  month = may,
  note = {(artigo submetido)},
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {2002}
}

@TECHREPORT{Simpson:1966,
  author = {Elizabeth Jane Simpson},
  title = {The Classification of Educational Objectives, Psychomotor Domain},
  institution = {University of Illinois},
  year = {1966},
  number = {BR-5-0090, ERO-251-65},
  address = {Urbana, Illinois, EUA},
  abstract = {A schema for classifying educational objectives in the psychomotor domain was developed. The general procedures included (1) a comprehensive review of related literature, (2) the collection and analysis of behavioral objectives of the domain, (3) laboratory analysis of certain tasks to discover by observation and instrospection the nature of the psychomotor activity involved, and (4) conferences with scholars who has specialized knowledge of the domain. The tentative classification system was presented in taxonomic form in the conclusion of the report.},
  keywords = {psychomotor skills, educational objectives, taxonomy, data analysis, indexes (locators)},
  lang = {en},
  pages = {35}
}

@ARTICLE{Sims-Jones:2003,
  author = {Roderick C. Sims and D. Jones},
  title = {Where practice informs theory: Reshaping instructional design for academic communities of practice in online teaching and learning},
  volume = {4},
  number = {1},
  year = {2003},
  pages = {3-20},
  issn = {1037-616X},
  journal = {Information Technology, Education and Society},
  publisher = {James Nicholas}
}

@MISC{Alistair,
  author = {Alistair Sinclair},
  title = {Note on Random Access Machines},
  year = {2002},
  organization = {University of California, Berkeley},
  owner = {magsilva},
  timestamp = {2002.09.19},
  url = {http://www.cs.berkeley.edu/~sinclair/cs172/ram.ps}
}

@MASTERSTHESIS{Singh:2012,
  author = {Inderjeet Singh},
  title = {A Mapping Study of Automation Support Tools for Unit Testing},
  abstract = {Unit testing is defined as a test activity usually performed by a developer for the purpose of demonstrating program functionality and meeting the requirements specification of module. Nowadays, unit testing is considered as an integral part in the software development cycle. However, performing unit testing by developers is still considered as a major concern because of the time and cost involved in it. Automation support for unit testing, in the form of various automation tools, could significantly lower the cost of performing unit testing phase as well as decrease the time developer involved in the actual testing. The problem is how to choose the most appropriate tool that will suit developer requirements consisting of cost involved, effort needed, level of automation provided, language support, etc. This research work presents results from a systematic literature review with the aim of finding all unit testing tools with an automation support. In the systematic literature review, we initially identified 1957 studies. After performing several removal stages, 112 primary studies were listed and 24 tools identified in total. Along with the list of tools, we also provide the categorization of all the tools found based on the programming language support, availability (License, Open source, Free), testing technique, level of effort required by developer to use tool, target domain, that we consider as good properties for a developer to make a decision on which tool to use. Additionally, we categorized type of error(s) found by some tools, which could be beneficial for a developer when looking at the tool's effectiveness. The main intent of this report is to aid developers in the process of choosing an appropriate unit testing tool from categorization table of available tools with automation unit testing support that ease this process significantly. This work could be beneficial for researchers considering to evaluate efficiency and effectiveness of each tool and use this information to eventually build a new tool with the same properties as several others.},
  keywords = {Testing, Unit testing, Test date generation, systematic literature review, automatic unit testing},
  school = {Mälardalen University -- School of Innovation, Design and Engineering},
  year = {2012},
  advisor = {Adnan Causevic},
  address = {Västerás, } # Sweden,
  month = jun,
  url = {http://www.idt.mdh.se/utbildning/exjobb/files/TR1334.pdf},
  owner = {magsilva},
  timestamp = {2014.09.12}
}

@INPROCEEDINGS{Singh-etal:2004,
  author = {Rajendra G. Singh and Margaret Bernard and Ross Gardler},
  title = {Creating sharable learning objects from existing digital course content},
  pages = {6},
  doi = {10.1145/1275571.1275582},
  abstract = {Our research is targeting Instructors that have course material as a collection of various digital documents (raw content) and whose objective is to re-structure this raw content into a standards-based format in order to support a higher degree of content reuse, sharing and easier maintenance. In previous work, we differentiated a Reusable Learning Object (RLO) from a Sharable Learning Object (SLO) and developed a model which can be applied to convert RLOs into SLOs. In this paper, we present an iterative five-step method to re-structure selected raw content into RLOs. The model from the previous work is then applied to convert the RLOs into SLOs. Thus far, we have used raw content from one Instructor's Computer Architecture course and found that conversion of the raw content can successfully result in a subset of the raw content residing in SLOs, a form which is more conducive to reuse, sharing and content maintenance. In ongoing work, we are applying the methodology to additional raw content from several other Instructors (Computer Science courses) with a view to refining and automating the process where possible.},
  address = {New York, NY, USA},
  booktitle = {Workshop on Computer Architecture Education},
  location = {Munich, Germany},
  owner = {magsilva},
  publisher = {ACM},
  year = {2004}
}

@INPROCEEDINGS{sinha-harrold:1999,
  author = {Sinha, S. and Harrold, M.J.},
  title = {Criteria for testing exception-handling constructs in Java programs},
  pages = {265-274},
  doi = {10.1109/ICSM.1999.792624},
  abstract = {Exception-handling constructs provide a mechanism for mixing exceptions and a facility for designating protected code by attaching exception handlers to blocks of code. Despite the frequency of their occurrences, the behavior of exception-handling constructs is often the least understood and poorly tested part of a program. The presence of such constructs introduces new structural elements, such as control-flow paths, in a program. To adequately test such programs, these new structural elements must be considered for coverage during structural testing. In this paper, we describe a class of adequacy criteria that can be used to test the behavior of exception-handling constructs. We present a subsumption hierarchy of the criteria, and illustrate the relationship of the criteria to those found in traditional subsumption hierarchies. We describe techniques for generating the testing requirements for the criteria using our control-flow representations. We also describe a methodology for applying the criteria to unit and integration testing of programs that contain exception-handling constructs},
  keywords = {Java programs;control-flow paths;exception-handling constructs;structural elements;structural testing;subsumption hierarchy;Java;exception handling;program testing;},
  address = {Oxford, UK},
  booktitle = {International Conference on Software Maintenance},
  month = aug,
  year = {1999}
}

@INPROCEEDINGS{sinha-harrold:1998,
  author = {Saurabh Sinha and Mary Jean Harrold},
  title = {Analysis of Programs with Exception-Handling Constructs},
  pages = {348--357},
  doi = {10.1109/ICSM.1998.738526},
  address = {Bethesda, MD, USA},
  booktitle = {International Conference on Software Maintenance (ICSM)},
  month = nov,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1998}
}

@ARTICLE{Sizo-etal:2010,
  author = {Sizo, Amanda Monteiro and Lino, Adriano Del Pino e Favero, Eloi Luiz},
  title = {Uma proposta de Arquitetura de Software para Construção e Integração de Ambientes Virtuais de Aprendizagem},
  number = {6},
  month = dez,
  year = {2010},
  pages = {17--30},
  abstract = {Este artigo propõe uma arquitetura de software fundamentada no padrão arquitetural em camadas e demonstra sua aplicabilidade na construção e integração de ambientes virtuais de aprendizagem. Com o surgimento de ambientes cada vez mais modernos, sistemas legados são descontinuados pela dificuldade em mantê-los. A arquitetura proposta facilita a integração de novos módulos a estes sistemas de forma distribuída visando mantê-los competitivos. Esta proposta é implementada a partir da construção de um módulo avaliador e gerador de mapas conceituais que se integra via web service ao ambiente LabSQL. Ao fim são apresentados resultados obtidos com utilização da arquitetura e do módulo de serviço construído.},
  keywords = {arquitetura de software; ambientes virtuais de aprendizagem; MVC; web service},
  abstract-en = {This paper proposes a software architecture based on standard architectural and demonstrates its applicability in the construction and integration of virtual learning environments. With the emergence of more modern environnments, legacy systems are discontinued by the diffiiculty in maintaining them. The proposed architecture facilitates the integration of new modules for these systems in a distributed way in order to keep the competitiv. This proposal is implemented through the construction of a module generator and evaluation of concept maps that integrates environmental LabSQL via web service.},
  address = {Rio Tinto, } # Portugal,
  issn = {1646-9895},
  journal = {Revista Ibérica de Sistemas e Tecnologias de Informação},
  keywords-en = {softwar architecture; virtual learning environments; MVC; web service}
}

@BOOK{Skienna-Revilla:2003,
  publisher = {Springer},
  year = {2003},
  author = {Steven S. Skiena and Miguel A. Revilla},
  editor = {David Gries and Fred B. Schneider},
  isbn = {0-387-00163-8},
  pages = {359},
  series = {Texts in Computer Science},
  address = {New York, NY, } # USA,
  edition = {1},
  booktitle = {Programming Challenges: The Programming Contest Training Manual},
  timestamp = {2013-12-11}
}

@ARTICLE{Skinner:1960,
  author = {B. F. Skinner},
  title = {Pigeons in a pelican},
  volume = {15},
  year = {1960},
  pages = {28-37},
  journal = {American Psychologist}
}

@ARTICLE{Skinner:1954,
  author = {Skinner, B. F.},
  title = {The Science of Learning and the Art of Teaching},
  volume = {24},
  year = {1954},
  pages = {86-97},
  abstract = {Recent advances in the systematic analysis of learning are exemplified in the development of improved laboratory techniques for controlling the contingencies of reinforcement to shape behavior at will and to maintain its strength over long periods of time. In contrast, classroom teaching techniques are characterized by aversive control of behavior, the contingencies of reinforcement are not optimally arranged, there is no provision for progressive approximation to the final behavior desired, and reinforcement is too infrequent. Changes in the practical situation are indicated, principally in the direction of providing mechanical devices for controlling the contingencies of reinforcement.},
  issn = {1943-5045, 0017-8055},
  journal = {Harvard Educational Review},
  publisher = {Harvard Education}
}

@ARTICLE{Skinner:1931,
  author = {Burrhus Frederic Skinner},
  title = {The concept of the reflex in the description of behavior},
  volume = {5},
  year = {1931},
  pages = {427-458},
  journal = {Journal of General Psychology}
}

@INPROCEEDINGS{skolglund-runeson:2009,
  author = {Mats Skoglund and Per Runeson},
  title = {Reference-based search strategies in systematic review},
  abstract = {In systematic reviews, the number of articles found by search strings tend to be very large. In order to limit the number of articles to handle manually, we investigate a search strategy based on references between papers. We first identify a "take-off paper" which is the starting point for the search and then we follow the references from that paper. We also investigate "cardinal papers", i.e. papers that are referenced by many authors, and let the references to those papers guide the selection in the systematic review. We evaluate the search strategies on three published systematic reviews. The results vary greatly between the three studied systematic reviews, from 88% reduction to 92% extension of the original paper set.},
  address = {Durham University, UK},
  booktitle = {International Conference on Evaluation and Assessment in Software Engineering (EASE)},
  month = apr,
  url = {http://www.bcs.org/content/conWebDoc/25022},
  year = {2009}
}

@TECHREPORT{Sleeman:1984,
  author = {D. Sleeman},
  title = {Pascal and High-School Students: A Study of Misconceptions},
  institution = {School of Education -- Stanford University},
  year = {1984},
  number = {009},
  abstract = {In an attempt to initiate a new approach to the teaching of Pascal, a study was conducted to ascertain the difficulties students encountered when they attempt to learn this computer language. Screening tests were given to 68 students in grades 11 and 12 who had just completed a semester course in Pascal. The purpose of the test was to detect possible difficulties in basic constructs such as reading and printing data, assignments, and the several control structures provided by Pascal. This test that showed over 50% of students had major difficulties with Pascal, and those problems are described, with notations as to whether the errors were frequent, or fairly frequent, or occasional. A group of 35 students were given a detailed clinical interview which is also described, and their explanations of why errors occurred are given as well. A discussion of the data includes a summary of the investigators' assessment of the students interviewed and profiles of typical students. Finally, a comparison is drawn between this and similar studies, and the report concludes with a plan for future investigations which will include: (1) a look at the difficulties high school students have with advanced concepts of Pascal and also with Logo; (2) an attempt to determine whether the errors noted in this study can be remediated; and (3) experimentation with different teaching/presentation strategies.},
  pages = {34},
  type = {Occasional Report}
}

@MISC{software:htmlib,
  author = {Sergey Smirnov},
  title = {HTML Layout Tag Library},
  howpublished = {Programa de computador},
  year = {2004},
  owner = {magsilva},
  timestamp = {2007.10.07},
  url = {http://www.jsftutorials.net/htmLib/}
}

@INPROCEEDINGS{Smith:2008,
  author = {Smith, Glenn and Fidge, Colin},
  title = {On the efficacy of prerecorded lectures for teaching introductory programming},
  pages = {129--136},
  abstract = {Teaching introductory programming is a notoriously challenging problem in any information technology or computer science course. Failure and dropout rates are usually high, and many students seem unable to grasp the notion of solving problems algorithmically. Given contemporary students' fondness for multimedia styles of presentation, we conducted an experiment on the effectiveness of providing prerecorded mini-lectures in a first-year programming subject. Although we found only a weak quantitative correlation between students' use of the prerecorded material and their final grades, anecdotal feedback on the experiment was overwhelmingly positive, suggesting that students' perceptions of the subject were improved.},
  keywords = {first-year programming, multimedia lectures, on-line teaching materials},
  volume = {78},
  booktitle = {10th Conference on Australasian Computing Education},
  isbn = {978-1-920682-59-0},
  issn = {1445-1336},
  location = {Wollongong, #Australia#},
  publisher = {Australian Computer Society},
  year = {2008}
}

@ARTICLE{Smith92FTOO,
  author = {M. D. Smith and D. J. Robson},
  title = {A Framework for Testing Object-Oriented Programs},
  volume = {5},
  number = {3},
  month = jun,
  year = {1992},
  pages = {45--53},
  journal = joop,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@MISC{Smith:2011,
  author = {Mark K. Smith},
  title = {Introducing informal education},
  howpublished = {Encyclopaedia of informal education},
  year = {2011},
  lang = {en},
  url = {http://www.infed.org/i-intro.htm},
  urlaccessdate = {20 fev 2012}
}

@MISC{software:camstudio,
  author = {Nick Smith and Paul McQuade and others},
  title = {CamStudio},
  howpublished = software,
  year = {2005},
  url = {http://camstudio.org/, http://sourceforge.net/projects/camstudio/}
}

@MISC{software:phpsysinfo,
  author = {Uriah Welcome \and Matthew Snelham},
  title = {phpSysInfo},
  howpublished = {Programa de computador},
  year = {1999},
  owner = {msilva},
  timestamp = {2006.02.24},
  url = {http://phpsysinfo.sourceforge.net/}
}

@ARTICLE{soare96computability,
  author = {Robert I. Soare},
  title = {Computability and Recursion},
  volume = {2},
  number = {3},
  year = {1996},
  pages = {284--321},
  url = {http://citeseer.nj.nec.com/soare96computability.html},
  journal = {The Bulletin of Symbolic Logic},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@ARTICLE{Soares-etal:2010a,
  author = {Soares, Luiz and Rodrigues, Rogério and Cerqueira, Renato and Barbosa, Simone},
  title = {Variable and state handling in {NCL}},
  volume = {50},
  year = {2010},
  pages = {465-489},
  doi = {10.1007/s11042-010-0478-2},
  abstract = {Most time-based declarative languages have limited support for variable definition and manipulation, which causes developers to resort to imperative languages. However, a declarative language should provide a variable handling model sufficiently rich to describe a wide range of interactive applications, avoiding, as much as possible, the help of an imperative scripting language. On the other hand, the declarative simplicity should not be lost, leaving for the imperative objects more complex manipulations, with the necessary care to avoid any impact in the application's temporal graph. Based on this principle, variables and the presentation state are handled by NCL and Ginga-NCL, as discussed in this paper. NCL is the declarative language of the Brazilian Terrestrial Digital TV System (SBTVD) supported by its middleware called Ginga. NCL and Ginga-NCL are part of ISDB standards and also of ITU-T Recommendations for IPTV services.},
  address = {Netherlands},
  issn = {1380-7501},
  issue = {3},
  journal = {Multimedia Tools and Applications},
  keyword = {Computer Science},
  publisher = {Springer}
}

@BOOK{Soares-Barbosa:2009,
  title = {Programando em {NCL} 3.0},
  publisher = {Elsevier},
  year = {2009},
  author = {Luiz Fernando Gomes Soares and Simone Diniz Junqueira Barbosa},
  isbn = {978-85-352-3457-2},
  pages = {341},
  address = {Rio de Janeiro, RJ, Brasil},
  edition = {1},
  booktitle = {Programando em {NCL} 3.0}
}

@INPROCEEDINGS{Soares-Fortes:2001,
  author = {M. D. Soares and R. P. M. Fortes},
  title = {{Um Suporte ao Controle de Versões na Web}},
  address = {Rio de Janeiro},
  booktitle = {Anais do Caderno de Ferramentas do Simpósio Brasileiro de Engenharia de Software (SBES'2001)},
  owner = {magsilva},
  timestamp = {2008.07.30},
  year = {2001}
}

@ARTICLE{Soares-etal:2002,
  author = {M. D. Soares and R. P. M. Fortes and D. A. Moreira},
  title = {VersionWeb: a tool for helping Web pages version control},
  month = oct,
  year = {2002},
  pages = {1-3},
  url = {http://www.linuxjournal.com/article/6330},
  journal = {Linux Journal},
  owner = {magsilva},
  publisher = {Belltown Media},
  timestamp = {2008.07.30}
}

@INPROCEEDINGS{Soares-etal:2000,
  author = {Marinalva Dias Soares and Renata Pontin de Mattos Fortes and D. A. Moreira},
  title = {{VersionWeb: a Tool for Helping Web Pages Version Control}},
  pages = {275-280},
  address = {Las Vegas, USA},
  booktitle = {International Conference on Internet Multimedia Systems and Applications},
  month = nov,
  owner = {magsilva},
  timestamp = {2008.07.30},
  year = {2000}
}

@MISC{standard:smpte343m,
  author = {{Society of Motion Picture and Television Engineers (SMPTE)}},
  title = {Declarative Data Essence (343M)},
  howpublished = {Padrão},
  year = {2002},
  timestamp = {2008.09.30}
}

@MISC{standard:smpte357m,
  author = {{Society of Motion Picture and Television Engineers (SMPTE)}},
  title = {Declarative Data Essence, IP Multicast Encapsulation (357M)},
  howpublished = {Padrão},
  year = {2002},
  timestamp = {2008.09.30}
}

@MISC{standard:smpte361m,
  author = {{Society of Motion Picture and Television Engineers (SMPTE)}},
  title = {NTSC IP and Trigger Binding to VBI (361M)},
  howpublished = {Padrão},
  year = {2002},
  timestamp = {2008.09.30}
}

@MISC{standard:smpte364m,
  author = {{Society of Motion Picture and Television Engineers (SMPTE)}},
  title = {Declarative Data Essence - Unidirectional Transport Protocol (364M)},
  howpublished = {Padrão},
  year = {2001},
  timestamp = {2008.09.30}
}

@MISC{Softech00CBDE,
  author = {Princeton Softech},
  title = {Component Based Development: A Roadmap to e{B}usiness Success},
  howpublished = {White Paper},
  month = jan,
  year = {2000},
  owner = {magsilva},
  timestamp = {2008.07.31},
  url = {http://princetonsoftech.com/}
}

@ARTICLE{Solheim93ESTI,
  author = {F. Solheim and J. H. Rowland},
  title = {An Empirical Study of Testing and Integration Strategies Using Artificial Software Systems},
  volume = {19},
  number = {10},
  month = oct,
  year = {1993},
  pages = {941--949},
  journal = ieeese,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{soller:2001,
  author = {Amy Soller},
  title = {Supporting Social Interaction in an Intelligent Collaborative Learning System},
  booktitle = {Artificial Intelligence in Education},
  owner = {magsilva},
  timestamp = {2010.09.14},
  year = {2001}
}

@BOOK{Soloway-etal:1988,
  title = {Studying the Novice Programmer},
  publisher = {L. Erlbaum Associates},
  year = {1988},
  author = {Soloway, E. and Spohrer, James C.},
  isbn = {0805800026},
  pages = {504},
  series = {Interacting with Computers Series},
  address = {Hillsdale, NJ, } # USA,
  abstract = {Parallel to the growth of computer usage in society is the growth of programming instruction in schools. This informative volume unites a wide range of perspectives on the study of novice programmers that will not only inform readers of empirical findings, but will also provide insights into how novices reason and solve problems within complex domains. The large variety of methodologies found in these studies helps to improve programming instruction and makes this an invaluable reference for researchers planning studies of their own. Topics discussed include historical perspectives, transfer, learning, bugs, and programming environments.},
  booktitle = {Studying the Novice Programmer}
}

@BOOK{sommerville:2003,
  title = {Engenharia de Software},
  publisher = {Addison Wesley},
  year = {2003},
  author = {Ian Sommerville},
  editor = {Roger Trimer},
  pages = {592},
  address = {São Paulo, SP},
  edition = {6},
  note = {Tradução André Maurício de Andrade Ribeiro; Revisão técnica Kechi Hirama},
  owner = {magsilva},
  timestamp = {2006.11.09}
}

@ARTICLE{sommerville:2005:1,
  author = {Ian Sommerville},
  title = {Integrated Requirements Engineering},
  volume = {22},
  number = {1},
  month = jan,
  year = {2005},
  pages = {16-23},
  journal = {IEEE Software},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@BOOK{sommerville:2001,
  title = {Software Engineering},
  publisher = {Addison-Wesley},
  year = {2001},
  author = {Ian Sommerville},
  series = {International computer science series},
  address = {New York, USA},
  edition = {6},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@BOOK{sommerville:1996,
  title = {Software Engineering},
  publisher = {Addison Wesley},
  year = {1996},
  author = {Ian Sommerville},
  address = {Massachussets},
  edition = {5},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@ARTICLE{sommerville:2005:2,
  author = {Sommerville, I. and Ransom, J. B},
  title = {An Industrial Experiment in Requirements Engineering Process Assessment and Improvement},
  volume = {14},
  number = {1},
  month = {jan},
  year = {2005},
  pages = {1-33},
  journal = {ACM Transactions on Software Engineering and Methodology (TOSEM)},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@ARTICLE{sommerville:1997,
  author = {Ian Sommerville and Pete Sawyer},
  title = {Viewpoints: principles, problems and a pratical approach to requirements engineering},
  volume = {3},
  year = {1997},
  pages = {101-130},
  journal = {Annals of Software Engineering},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@INPROCEEDINGS{Song-Tjondronegoro:2010,
  author = {Song, Wei and Tjondronegoro, Dian},
  title = {A survey on usage of mobile video in {Australia}},
  pages = {5--8},
  doi = {10.1145/1952222.1952225},
  abstract = {The growth of powerful entertainment functions of mobile devices, in particular mobile video, has recently attracted much attention. Studies on mobile TV, one form of mobile video, have been conducted in many countries. However, little research focuses on the holistic usage of mobile video. To understand the features of such usage, we conducted an online survey in Brisbane, Australia, during the first half of 2010. Our findings reveal similarities and diversities between usage of mobile TV in particular and mobile video on the whole.. The results could aid in improving the design of future studies, with a view to ultimately increase user satisfaction.},
  keywords = {Australia, mobile TV, mobile video, survey, usage},
  series = {OZCHI '10},
  acmid = {1952225},
  address = {New York, NY, EUA},
  booktitle = {Conference of the Computer-Human Interaction Special Interest Group of Australia on Computer-Human Interaction},
  isbn = {978-1-4503-0502-0},
  location = {Brisbane, Australia},
  numpages = {4},
  publisher = {ACM},
  year = {2010}
}

@ARTICLE{Sosteric02WLOO,
  author = {M. Sosteric and Susan Hesemeier},
  title = {When is a Learning Object not an Object: A first step towards a theory of learning objects},
  month = oct,
  year = {2002},
  url = {http://www.irrodl.org},
  journal = {International Review of Research in Open and Distance Learning},
  owner = {magsilva},
  timestamp = {2006.04.01}
}

@INPROCEEDINGS{Sousa:2006:AMA:1298023.1298037,
  author = {Sousa, Kenia and Mendon\c{c}a, Hildeberto and Furtado, Elizabeth},
  title = {Applying a multi-criteria approach for the selection of usability patterns in the development of DTV applications},
  pages = {91--100},
  doi = {10.1145/1298023.1298037},
  abstract = {In this paper we describe a multi-criteria approach in which the execution of its steps integrated to a Software Development Process (SDP) allow the generation of the User Interface (UI) Definition Plan, which is an artifact used for UI design of software. This approach applies techniques from Operational Research (OR), and from Human-Computer Interaction (HCI), considering diverse criteria (functional and non functional requirements) that have an impact on the interaction design and using usability patterns, respectively. In this text, its main goal was to identify the order of attractiveness of a list of usability patterns for a certain interactive task of Digital TV (DTV) applications, thus allowing the selection of the most appropriate pattern in this new communication resource.},
  keywords = {multi-criteria decision-analysis, usability, usability patterns},
  address = {New York, NY, USA},
  booktitle = {Proceedings of VII Brazilian symposium on Human factors in computing systems},
  isbn = {1-59593-432-4},
  location = {Natal, RN, Brazil},
  publisher = {ACM},
  year = {2006}
}

@INPROCEEDINGS{Souto-etal:2007,
  author = {Souto, Maria and Warpechowski, Mariusa and de Oliveira, José},
  title = {An Ontological Approach for the Quality Assessment of Computer Science Conferences},
  pages = {202-212},
  doi = {10.1007/978-3-540-76292-8_24},
  abstract = {Today the proliferation of the availability of the information of scientific events on the Web has created the necessity to offer a quickly access to up-to-date information about the quality of these events. This requirement demands for (semi) automatic tools to speedily provide this information. The human-performed activity of the information quality evaluation is extremely time consuming and easily leads to failures. The application OntoQualis here described was motivated to support the quality evaluation of Scientific Conferences, in the Computer Science area, based on the graduated programs evaluation protocol of the Brazilian agency CAPES. The evaluation mechanism is specified in the QUALIS document specifically designed to assess journals and conferences ranking. This paper presents a brief vision of the ongoing process of domain analysis and ontology prototyping aiming to classify Scientific Conferences: the OntoQualis project. Some results of OntoQualis preliminary evaluation have shown a satisfactory classification level in comparison with CAPES-QUALIS ranking.},
  volume = {4802},
  series = {Lecture Notes in Computer Science},
  booktitle = {Conference on Advances in Conceptual Modeling -- Foundations and Applications},
  editor = {Hainaut, Jean-Luc and Rundensteiner, Elke and Kirchberg, Markus and Bertolotto, Michela and Brochhausen, Mathias and Chen, Yi-Ping and Cherfi, Samira and Doerr, Martin and Han, Hyoil and Hartmann, Sven and Parsons, Jeffrey and Poels, Geert and Rolland, Colette and Trujillo, Juan and Yu, Eric and Zimányie, Esteban},
  isbn = {978-3-540-76291-1},
  keyword = {Computer Science},
  note = {10.1007/978-3-540-76292-8_24},
  publisher = {Springer},
  year = {2007}
}

@INPROCEEDINGS{souza-oliveira:1998,
  author = {C. T. Souza and M. Ábaco Oliveira},
  title = {Um Ambiente de Desenvolvimento Baseado em Objetos Distribuídos Configuráveis},
  pages = {205-220},
  address = {Maringá-PR},
  booktitle = {Simpósio Brasileira de Engenharia de Software},
  month = oct,
  owner = {magsilva},
  timestamp = {2008.07.30},
  year = {1998}
}

@ARTICLE{LacerdaSouza-etal:2011,
  author = {Daniel Faustino Lacerda de Souza and Liliane S. Machado and Tatiana A. Tavares},
  title = {3D Technologies to Extend Brazilian DTV Middleware},
  volume = {2},
  number = {1},
  year = {2011},
  pages = {23-32},
  abstract = {Entertainment and interactivity possibilities in Digital Television (DTV) can be extended to support 3D technologies. In this paper is described an architecture based on a middleware for DTV that incorporates 3D technologies on the Brazilian standard. The integration strategies will be presented and compared with other studies in the literature. As case study, it will be presented a virtual environment to analyze the advantages and disadvantages of this integration.},
  url = {http://seer.ufrgs.br/jis/article/view/20118},
  issn = {2236-3297},
  journal = {Journal on 3D Interactive Systems},
  publisher = {SBC}
}

@RESEARCH-PROJECT{project:Souza-Barbosa:2012,
  title = {Subsídios à integração de ferramentas de avaliação automática e sistemas de gerenciamento de aprendizagem},
  author = {Draylson Micael de Souza and Ellen Francine Barbosa},
  institution = {Institute of Mathematics Science and Computing -- University of São Paulo},
  number = {12/04352-6},
  funding = {FAPESP},
  month = may,
  year = {2012},
  abstract = {Experiências relacionadas ao uso de ferramentas de avaliação automática de trabalhos práticos de programação têm sido bastantes positivas, com benefícios tanto para os alunos como para os professores. No entanto, essas ferramentas dificilmente são utilizadas além das instituições em que foram criadas. A principal razão para isso está relacionada a questões de adaptação e rastreabilidade. Geralmente, é difícil para os professores identificar tais ferramentas e adapta-las às notações e metodologias que ele utiliza. Por outro lado, professores e intituições de ensino têm caminhado em direção ao uso de sistemas de gerenciamento de aprendizagem (LMS). Nesse contexto, disciplinas de computação constituem um cenário interessante e produtivo para explorar a adoção, o uso, a experimentação e o aperfeiçoamento dos LMS's. No entanto, a maioria desses sistemas não são, por padrão, preparados de maneira adequada para atender às demandas de tais disciplinas. Neste sentido, pesquisas vêm sendo desenvolvidas a fim de explorar o aperfeiçoamento de LMS's especificamente para o ensino de conceitos de programação. Dentre as questões investigadas, destaque especial tem sido dado às ferramentas de avaliação automática de trabalhos de programação. O presente projeto tem como objetivo investigar e explorar a integração de ferramentas para avaliação automática de trabalhos de programação em LMS's. Desse modo, através de um LMS, o professor pode facilmente identificar e utilizar as ferramentas que melhor se adequem às notações e metodologias de sua disciplina ou que melhor forneçam as funcionalidades que deseja, sem a necessidade de uma prévia instalação e configuração. A ideia é estabelecer mecanismos capazes de minimizar os problemas associados ao acesso e utilização de tais ferramentas, incentivando e facilitando sua adoção por parte dos professores. Estudos de caso envolvendo cenários reais de ensino também deverão ser realizados a fim de validar os mecanismos estabelecidos.}
}

@RESEARCH-PROJECT{project:Souza-Barbosa:2010,
  title = {Ensino e aprendizado de fundamentos de programação: uma abordagem baseada em teste de software},
  author = {Draylson Micael de Souza and Ellen Francine Barbosa},
  institution = {Institute of Mathematics Science and Computing -- University of São Paulo},
  number = {09/12956-6},
  funding = {FAPESP},
  month = mar,
  year = {2010},
  abstract = {Tanto programação como teste de software não são disciplinas triviais de serem ensinadas. Entre asvárias iniciativas investigadas a fim de amenizar os problemas associados destaca-se o ensino conjunto de conceitos básicos de programação e de teste de software em disciplinas introdutórias dos cursos de computação. Do ponto de vista da programação, testes podem contribuir para melhorar acapacidade global de compreensão e análise dos alunos. Do ponto de vista da atividade de teste, se a mesma for ensinada juntamente com fundamentos de programação, pode-se criar uma "cultura de teste" nos alunos, tornando-a uma prática comum entre os desenvolvedores, incentivando-os a aplicar testes desde o início do processo desenvolvimento de software.Motivados por este cenário, em trabalhos anteriores foi proposto e desenvolvido um ambiente de apoio à submissão e avaliação automática de trabalhos práticos dos alunos, baseado em atividades de teste de software - PROGTEST. Em sua versão atual, a PROGTEST encontra-se integrada a uma ferramenta que apóia o teste estrutural de programas escritos em Java.O presente trabalho de mestrado insere-se nessa perspectiva, tendo como principal objetivoidentificar e integrar diferentes ferramentas de teste ao ambiente PROGTEST, propiciandoa utilização, por parte dos alunos, de técnicas e critérios distintos na condução de seus testes. Aspectos de aplicação e validação do ambiente em disciplinas introdutórias de programação também deverão ser explorados. A idéia é que o ambiente PROGTEST possa ser utilizado como mecanismo de apoio ao processo de ensino e aprendizado, tanto de conceitos de programação como de teste de software.}
}

@RESEARCH-PROJECT{project:Souza-Barbosa:2009,
  title = {{ProgTest}: um ambiente para submissão e avaliação automática de trabalhos de programação baseado em atividades de teste},
  author = {Draylson Micael de Souza and Ellen Francine Barbosa},
  institution = {Institute of Mathematics Science and Computing -- University of São Paulo},
  number = {09/00006-3},
  funding = {FAPESP},
  month = mar,
  year = {2009},
  abstract = {Tanto programação como teste de software não são disciplinas triviais de serem ensinadas. Entre asvárias iniciativas investigadas a fim de amenizar os problemas associados destaca-se o ensino conjunto de conceitos básicos de programação e de teste de software em disciplinas introdutórias doscursos de computação. Do ponto de vista da programação, testes podem contribuir para melhorar a capacidade global de compreensão e análise dos alunos. Do ponto de vista da atividade de teste, se a mesma for ensinada juntamente com fundamentos de programação, pode-se criar uma "cultura de teste" nos alunos, tornando-a uma prática comum entre os desenvolvedores, motivando-os a aplicar testes desde o início do processo desenvolvimento de software.O presente trabalho de iniciação científica insere-se nessa perspectiva, tendo como principalobjetivo o desenvolvimento e a evolução do ambiente ProgTest - um ambiente para submissão eavaliação automática de trabalhos práticos baseado em atividades de teste. Aspectos de aplicação e validação do ambiente no contexto de disciplinas introdutórias de programação também deverão ser explorados. A idéia é que, em curto prazo, o ambiente ProgTest possa ser utilizado como mecanismo de apoio ao processo de ensino e aprendizado, tanto de conceitos de programaçãocomo de teste de software.}
}

@INPROCEEDINGS{Souza-etal:2010,
  author = {Souza, Maria de Fátima C. de and Castro-Filho, José A. and Andrade, Rossana M. C.},
  title = {Model-Driven Development in the Production of Customizable Learning Objects},
  pages = {701 -702},
  doi = {10.1109/ICALT.2010.198},
  abstract = {Learning Objects (LO) are digital resources developed to help teachers present the pedagogical concepts to students. However, the way these resources are produced does not allow teachers to adapt them to the reality of their students. Thus, this paper proposes a development process of customizable learning objects using a strategy based on models. Based on this approach, teachers will make adjustments to the LO and thus achieve more autonomy in the use of these resources.},
  keywords = {customizable learning objects;development process;digital resources;model-driven development;computer aided instruction;},
  address = {Washington, DC, EUA},
  booktitle = {International Conference on Advanced Learning Technologies},
  lang = {en},
  location = {Sousse, Tunísia},
  month = jul,
  organization = {IEEE Computer Society},
  owner = {magsilva},
  year = {2010}
}

@INPROCEEDINGS{Souza-etal:2008:SBIE,
  author = {Maria Fátima C. de Souza and J. Aires de Castro Filho and Rossana M. C. Andrade},
  title = {ExpertDSL: um perfil UML para o suporte à definição de escopo pedagógico em um processo de desenvolvimento de objetos de aprendizagem orientados a modelo},
  pages = {1-4},
  abstract = {A produção de objetos de aprendizagem (OA) exige um nível de complexidade que só é possível ser atingido devido ao suporte de uma equipe multidisciplinar. No entanto, essa multidisciplinaridade resulta em uma série de problemas relacionados à integração das atividades de comunicação entre os profissionais. Nesse trabalho é apresentada uma linguagem de domínio específico (DSL), a ser utilizada, pela equipe multidisciplinar, no processo de desenvolvimento de OA. Essa DSL faz parte da estratégia orientada a modelos empregada na fase inicial da produção desse software e tem por objetivo facilitar a comunicação efetiva entre os profissionais envolvidos no processo.},
  abstract-en = {The development of learning objects (LO) demands a level of complexity only possible with the support of a multidisciplinary team which results in a series of problems related to integrate the communication among the professionals. The present work presents a domain specific language (DSL) to be used by multidisciplinary teams in the process of developing LO. This DSL is part of model oriented strategy used in the initial phase of software production and aims facilitate the effective communication between members involved in this process.},
  address = {Fortaleza, CE, } # Brazil,
  booktitle = {Simpósio Brasileiro de Informática na Educação},
  location = {Fortaleza, CE, #Brazil#},
  note = {Poster},
  owner = {magsilva},
  publisher = {SBC},
  year = {2008}
}

@INPROCEEDINGS{Souza-etal:2008:PVMGroup,
  author = {Souza, Paulo Lopes and Sawabe, Eduardo T. and Silva Simão, Adenilso and Vergilio, Silvia R. and Rocio Senger De Souza, Simone},
  title = {{ValiPVM} -- A Graphical Tool for Structural Testing of {PVM} Programs},
  pages = {257--264},
  doi = {10.1007/978-3-540-87475-1_35},
  abstract = {This work presents ValiPVM, a testing tool for C/PVM parallel programs. This tool implements structural coverage criteria, using an architecture already employed for MPI programs. It supports generation and evaluation of test sets and considers the control, data and communication flows of PVM programs. ValiPVM has a graphical user interface, designed to facilitate the test execution, analysis of results and to guide the user during the execution of the testing activity.},
  keywords = {PVM, coverage testing, testing tool},
  address = {Berlin, Heidelberg},
  booktitle = {15th European PVM/MPI Users' Group Meeting on Recent Advances in Parallel Virtual Machine and Message Passing Interface},
  isbn = {978-3-540-87474-4},
  location = {Dublin, #Ireland#},
  publisher = {Springer},
  year = {2008}
}

@MASTERSTHESIS{souza:1996,
  author = {S. R. S. Souza},
  title = {Avaliação do Custo e Eficácia do Critério Análise de Mutantes na Atividade de Teste de Programas},
  school = {ICMC-USP},
  year = {1996},
  address = {S\~ao Carlos, SP},
  month = jun,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{souza-maldonado:1998,
  author = {S. R. S. Souza and J. C. Maldonado},
  title = {Applying Test Set Minimization to Mutation-based Test Criteria},
  pages = {275--281},
  address = {Seattle, USA},
  booktitle = {International Conference on Reliability and Quality in Design},
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1998}
}

@INPROCEEDINGS{Souza-etal:2000:clei,
  author = {S. R. S. Souza and J. C. Maldonado and S. C. P. Fabbri and P. C. Masiero},
  title = {Statecharts Specifications: A Family of Coverage Testing Criteria},
  pages = {1--12},
  abstract = {This paper proposes a family of coverage testing criteria for specifications based on Statecharts. Statecharts are an extension of finite state machines with the capability of expressing parallelism and hierarchy. They have been used to specify the behavior of Reactive Systems. Recently, they have also been used in the context of object oriented software development. The two main approaches used for testing and validation of statecharts specifications are simulation and analysis of properties. However, these approaches do not essentially provide a mechanism for quantifying the specification testing activity and this compromises the testing quality assessment. The coverage criteria family proposed in this paper aims at complementing these approaches providing mechanisms either to evaluate the adequacy of test sequences generated by simulation, for example, or to guide the generation of adequate test sequences with respect to a given criterion. The underlying model to derive the requirements of the testing criteria is the statecharts reachability tree. The concepts and criteria are illustrated using an environment for editing and simulating statecharts called StatSim.},
  keywords = {software engineering},
  address = {Monterrey, México},
  booktitle = {Conferência Latinoamericana de Informática},
  location = {Monterrey, #Mexico#},
  month = sep,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {2000}
}

@RESEARCH-PROJECT{project:Barbeiro-Barbosa:2008,
  title = {Subsídios ao desenvolvimento e disponibilização de módulos educacionais para ensino a distância},
  author = {Rodolfo de Souza Barbeiro and Ellen Francine Barbosa},
  institution = {Institute of Mathematics Science and Computing -- University of São Paulo},
  number = {08/02338-0},
  funding = {FAPESP},
  month = sep,
  year = {2010},
  abstract = {Entre as linhas que têm sido objeto de pesquisa no contexto de Ensino e Aprendizado destaca-se o desenvolvimento de módulos educacionais - unidades concisas de estudo, compostas por conteúdos teóricos integrados a atividades práticas e avaliações, cuja disponibilização aos aprendizes é apoiada por recursos tecnológicos e computacionais. No decorrer das atividades associadas ao trabalho de doutorado de Barbosa(Processo FAPESP 98/16490-5) foram investigados e definidos mecanismos de apoio ao processo de desenvolvimento e modelagem de módulos educacionais. Os mecanismos estabelecidos propiciaram a reestruturação de materiais didáticos na área de Engenharia de Software, mais especificamente dentro da temática de Teste de Software.Em continuidade a esse trabalho, encontra-se em execução o projeto "Estudo, Definição e Estabelecimento de Mecanismos de Apoio ao Desenvolvimento Aberto, Cooperativo e Distribuído de Módulos Educacionais" (Processo FAPESP 07/52629-9), tendo como objetivo investigar e definir mecanismos de apoio ao processo de desenvolvimento aberto, cooperativo e distribuído de módulos educacionais. A idéia é que os conteúdos construídos sejam flexíveis, customizáveis e reutilizáveis, intermultidisciplinares e, até certo ponto, "globalizados", como forma deestabelecer mecanismos apropriados para contribuir na melhoria do processo de ensino e aprendizado, tornando-o compatível com as novas demandas impostas pelas transformações educacionais em curso. Ainda, a longo prazo, pretende-se estabelecer um cenário para o desenvolvimento de módulos educacionais livres (open learning materials).Nessa perspectiva, no presente trabalho de mestrado pretende-se explorar aspectos referentes à investigação, definição/adaptação e aplicação dos mecanismos já identificados para o ensino presencial, contemplando agora aspectos relevantes no escopo de ensino a distância. Visando à validação dos mecanismos explorados, estes devem ser aplicados no desenvolvimento aberto, cooperativo e distribuído de módulos educacionais no domínio de Engenharia de Software, incorporando características específicas para sua disponibilização em cursos a distância oferecidos pelo ICMC/USP. Além disso, os módulos educacionais presenciais já desenvolvidos no contexto de Teste de Software também devem ser considerados, sendo evoluídos em função das novas características e requisitos identificados.}
}

@ARTICLE{SouzaFilho-etal:2007,
  author = {Guido Lemos de Souza Filho and Luiz Eduardo Cunha Leite and Carlos Eduardo Coelho Freire Batista},
  title = {{Ginga-J}: the procedural middleware for the {B}razilian digital {TV} system},
  volume = {12},
  number = {4},
  month = mar,
  year = {2007},
  pages = {47-56},
  doi = {10.1590/S0104-65002007000100006},
  abstract = {The recent development of the research on digital terrestrial television in Brazil has led the country's government to state a series of premises in which the government shows to care not only for technology improvement, but also to use this development as a tool for ameliorating the Brazilian social context, in what concerns digital inclusion. These premises and necessities have generated some peculiarities in the development process, which directly influenced in the functionalities granted by the Brazilian's middleware choice. This paper, thus, seeks to explain all the architecture of the Java part - called Ginga-J - of the Ginga middleware, highlighting the new features, especially when confronting the Brazilian middleware with the other middlewares worldwide defined.},
  keywords = {Digital TV, middleware},
  issn = {0104-6500},
  journal = {Journal of the Brazilian Computer Society},
  lang = {en}
}

@ARTICLE{Spada:2010,
  author = {Spada, Hans},
  title = {Of scripts, roles, positions, and models},
  volume = {26},
  month = {July},
  year = {2010},
  pages = {547--550},
  doi = {10.1016/j.chb.2009.08.011},
  abstract = {The analysis of emerging roles in computer-supported collaborative learning (CSCL) is of high relevance for a better understanding of the effects of learning in groups and is important for adapting the scripting of roles to the already existing role pattern(s). This commentary first reviews the individual contributions to this special issue and subsequently addresses three additional perspectives: (a) what are the characteristics of good collaboration in problem-solving and learning, and which roles, or patterns of roles, might have favourable effects in this regard? (b) besides scripting roles learners can be instructed to collaborate by providing them with a model of an exemplary collaboration. Are the effects comparable? (c) ultimately we want learners to use roles in a strategic way, and in concluding the commentary outlines how this aim is in line with the overarching goal of promoting the concept of human agency in learning.},
  keywords = {CSCL, Learning from models, Positions, Roles, Scripts},
  address = {Amsterdam, The Netherlands, The Netherlands},
  issn = {0747-5632},
  issue = {4},
  journal = {Comput. Hum. Behav.},
  numpages = {4},
  publisher = {Elsevier Science Publishers B. V.}
}

@INPROCEEDINGS{Spada-etal:2005,
  author = {Spada, Hans and Meier, Anne and Rummel, Nikol and Hauser, Sabine},
  title = {A new method to assess the quality of collaborative process in CSCL},
  pages = {622--631},
  abstract = {In CSCL research, the collaborative process - the way people collaborate while working on tasks and learning -- is of central importance. Instructional measures are being developed to improve the quality of the collaboration which itself determines to a great extent the results of working and learning in groups. However, assessing collaborative process is not easy. We have developed a new assessment method by quantitatively rating nine qualitatively defined characteristic dimensions of collaboration. In this paper, we first describe how these dimensions were extracted from video-recordings of dyads collaborating to solve interdisciplinary tasks. Then we explain how the resulting rating system was applied to and tested on another sample. Based on positive findings from this application, we argue that the new method can be recommended for different areas of CSCL research.},
  keywords = {affective dimensions, assessment method, cognitive dimensions, collaborative process, rating system, videoconferencing},
  series = {CSCL '05},
  acmid = {1149375},
  booktitle = {Proceedings of th 2005 conference on Computer support for collaborative learning: learning 2005: the next 10 years!},
  isbn = {0-8058-5782-6},
  location = {Taipei, Taiwan},
  numpages = {10},
  publisher = {International Society of the Learning Sciences},
  url = {http://portal.acm.org/citation.cfm?id=1149293.1149375},
  year = {2005}
}

@ARTICLE{Spafford90EMTF,
  author = {E. H. Spafford},
  title = {Extending Mutation Testing to Find Environmental Bugs},
  volume = {20},
  number = {2},
  month = feb,
  year = {1990},
  pages = {181--189},
  journal = spe,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@ARTICLE{specht-kravcik:2006,
  author = {Marcus Specht and Milos Kravcik},
  title = {Authoring of Learning Objects in Context},
  volume = {5},
  number = { 1 },
  year = {2006},
  pages = {25--33},
  abstract = { Learning objects and content interchange standards provide new possibilities for e-learning... },
  url = { http://go.editlib.org/p/21735 },
  address = { Chesapeake, VA },
  issn = { 1537-2456 },
  journal = {International Journal on E-Learning},
  publisher = { AACE }
}

@MISC{software:phpcoverage,
  author = {{SpikeSource, Inc}},
  title = {PHPCoverage},
  howpublished = {Programa de computador},
  month = apr,
  year = {2005},
  owner = {magsilva},
  timestamp = {2010.05.14},
  url = {http://developer.spikesource.com/wiki/index.php/Projects:phpcoverage}
}

@INPROCEEDINGS{Springett:2008,
  author = {Springett, Mark V. and Griffiths, Richard N.},
  title = {Innovation for inclusive design: an approach to exploring the {iDTV} design space},
  pages = {49--58},
  doi = {10.1145/1453805.1453817},
  keywords = {creativity, design-space, evaluation, prototypes, task models},
  series = {UXTV '08},
  acmid = {1453817},
  address = {New York, NY, USA},
  booktitle = {1st international conference on Designing interactive user experiences for TV and video},
  isbn = {978-1-60558-100-2},
  location = {Silicon Valley, California, USA},
  publisher = {ACM},
  year = {2008}
}

@INPROCEEDINGS{Sridharan00NITM,
  author = {B. Sridhanan and S. Mundkur and A. P. Mathur},
  title = {Non-Intrusive Testing, Monitoring and Control of Distributed {CORBA} Objects},
  pages = {195--206},
  address = {Mont-saint-Michel, France},
  booktitle = {33rd International Conference on Technology of Object-Oriented Languages (TOOLS 33)},
  month = jun,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {2000}
}

@ARTICLE{Srinivas94GASU,
  author = {M. Srinivas and L. M. Patnaik},
  title = {Genetic Algorithms: A Survey},
  volume = {27},
  number = {6},
  month = jul,
  year = {1994},
  pages = {17--26},
  journal = ieeec,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@BOOK{Srivastava:2002,
  title = {Interactive TV Technology and Markets},
  publisher = {Artech House},
  year = {2002},
  author = {H. O. Srivastava},
  address = {Norwood},
  timestamp = {2008.09.28}
}

@BOOK{Stahl:2010,
  title = {Global Introduction to CSCL},
  year = {2010},
  author = {Gerry Stahl},
  isbn = {978-0-557-69556-0, 978-1-4581-4779-0},
  volume = {8},
  pages = {196},
  series = {Collected Writings of Gerry Stahl},
  booktitle = {Global Introduction to CSCL},
  lang = {en},
  url = {http://gerrystahl.net/elibrary/global/}
}

@INPROCEEDINGS{Stahl:2009,
  author = {Stahl, Gerry},
  title = {For a science of group interaction},
  pages = {129--138},
  doi = {10.1145/1531674.1531694},
  abstract = {As a foundation for the design of groupware, we need a new science of group interaction, a systematic description of the processes at the group level of description that may contribute to problem solving, knowledge building and other cognitive tasks undertaken by small groups collaborating synchronously over networked computers. A scientific investigation of the knowledge-building interactions of online teams involves explorations along multiple dimensions: (a) designing a testbed to support interaction within teams, (b) analyzing how interaction takes place within this setting and (c) describing how the teams achieve their tasks. This paper discusses how a current CSCL project designed a groupware environment in which this could take place and be studied; it reviews how the project approached the rigorous study of what took place there; and it reflects on the nature of group interaction as an object for a new science.},
  keywords = {CSCL, CSCW, group cognition, group interaction},
  series = {GROUP '09},
  acmid = {1531694},
  address = {New York, NY, USA},
  booktitle = {Proceedings of the ACM 2009 international conference on Supporting group work},
  isbn = {978-1-60558-500-0},
  lang = {en},
  location = {Sanibel Island, Florida, #USA#},
  numpages = {10},
  publisher = {ACM},
  year = {2009}
}

@INPROCEEDINGS{Stahl:2007,
  author = {Stahl, Gerry},
  title = {Meaning making in CSCL: conditions and preconditions for cognitive processes by groups},
  pages = {652--661},
  abstract = {Meaning making is central to the interactions that take place in CSCL settings. The collaborative construction of shared meaning is a complex process that has not previously been analyzed in detail despite the fact that it is often acknowledged as being the distinguishing element in CSCL. Here, a three-minute excerpt from a discussion among three students is considered in some detail. The students are reflecting on their analysis of mathematical patterns in a synchronous online environment with text chat and a shared whiteboard. Several interaction methods and group cognitive processes are identified. The analysis suggests a number of conditions and preconditions of such interaction. These are necessary for achieving the potential of CSCL as the accomplishment of high-order cognitive tasks by small groups of learners. An understanding of the conditions and preconditions of the small-group meaning-making process may aid in the design and analysis of CSCL activities, as well as in the development of a theory of group cognition.},
  series = {CSCL'07},
  acmid = {1599723},
  booktitle = {Proceedings of the 8th iternational conference on Computer supported collaborative learning},
  isbn = {978-0-6151-5436-7},
  location = {New Brunswick, New Jersey, USA},
  numpages = {10},
  publisher = {International Society of the Learning Sciences},
  url = {http://portal.acm.org/citation.cfm?id=1599600.1599723},
  year = {2007}
}

@BOOK{Stahl-Volter:2006,
  title = {Model-Driven Software Development},
  publisher = {Wiley},
  year = {2006},
  author = {Thomas Stahl and Markus Völter},
  isbn = {978-0-470-02570-3},
  pages = {428},
  address = {Great Britain},
  edition = {1},
  note = {Título original: Modellgetriebene Softwareentwicklung. Traduzido por Bettina von Stockfleth.}
}

@BOOK{stair:1998,
  title = {Princípios de Sistemas de Informação: Uma Abordagem Gerencial},
  publisher = {LTC},
  year = {1998},
  author = {R. Stair},
  owner = {magsilva},
  timestamp = {2006.09.20}
}

@BOOK{Stake:1995,
  title = {The Art of Case Study Research},
  publisher = {Sage Publications},
  year = {1995},
  author = {Robert E. Stake},
  pages = {192},
  edition = {1}
}

@MISC{software:gcc,
  author = {Richard M. Stallman and others},
  title = {GNU Compiler Collection},
  howpublished = {Programa de Computador},
  month = nov,
  year = {1987},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://gcc.gnu.org}
}

@ARTICLE{staples-niazi:2007,
  author = {Mark Staples and Mahmood Niazi},
  title = {Experiences using systematic review guidelines},
  volume = {80},
  month = nov,
  year = {2007},
  pages = {1425-1437},
  abstract = {Systematic review is a method to identify, assess and analyse published primary studies to investigate research questions. We critique recently published guidelines for performing systematic reviews on software engineering, and comment on systematic review generally with respect to our experience conducting one. Overall we recommend the guidelines. We recommend researchers clearly and narrowly define research questions to reduce overall effort, and to improve selection and data extraction. We suggest that complementary research questions can help clarify the main questions and define selection criteria. We show our project timeline, and discuss possibilities for automating and increasing the acceptance of systematic review.},
  journal = {The Journal of Systems and Software},
  owner = {magsilva},
  timestamp = {2007.11.12}
}

@INPROCEEDINGS{staples-niazi:2006,
  author = {Mark Staples and Mahmood Niazi},
  title = {Experiences Using Systematic Review Guidelines},
  abstract = {A systematic review is a defined and methodical way to identify, assess and analyse published primary studies in order to investigate a specific research question. Kitchenham has recently published guidelines for software engineering researchers performing systematic reviews. The objective of our paper is to critique Kitchenham's guidelines and to comment on systematic review generally with respect to our experiences conducting our first systematic review. Our perspective as neophytes may be particularly illuminating for other software engineering researchers who are also considering conducting their first systematic review. Overall we can recommend Kitchenham's guidelines to other researchers considering systematic reviews. We caution researchers to clearly and narrowly define the research questions they will investigate by systematic review, to reduce the overall effort and to improve the quality of the selection of papers and extraction of data. In particular we recommend defining complementary research questions that are not within the scope of the systematic review in order to clarify the boundaries of the specific research question of interest. An instance of this recommendation is that researchers should clearly define the unit of study for the systematic review.},
  address = {Keele University, UK},
  booktitle = {International Conference on Evaluation and Assessment in Software Engineering (EASE)},
  month = apr,
  url = {http://www.bcs.org/content/conWebDoc/3724},
  year = {2006}
}

@BOOK{stapleton:1997,
  title = {Dynamic Systems Development Method},
  publisher = {Addison Wesley},
  year = {1997},
  author = {J. Stapleton},
  timestamp = {2008.09.26}
}

@BOOK{Steinbert-etal:2009,
  title = {{EMF}: Eclipse Modeling Framework},
  publisher = {Addison-Wesley},
  year = {2009},
  author = {Dave Steinberg and Frank Budinsky and Marcelo Paternostro and Ed Merks},
  editor = {Erich Gamma and Lee Nackman and John Wiegand},
  isbn = {9780321331885},
  pages = {673},
  series = {The Eclipse Series},
  address = {Ann Arbor, MI, USA},
  edition = {2},
  booktitle = {{EMF} Eclipse Modeling Framework}
}

@MISC{dom2html:2003,
  author = {Johnny Stenback and Philippe Le Hégaret and Arnaud Le Hors},
  title = {Document Object Model (DOM) Level 2 HTML Specification},
  howpublished = {W3C Recommendation},
  month = jan,
  year = {2003},
  file = {Document Object Model (DOM) Level 2 HTML Specification.pdf:Document Object Model (DOM) Level 2 HTML Specification.pdf:PDF},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://www.w3.org/TR/DOM-Level-2-HTML}
}

@MISC{dom3loadsave:2004,
  author = {Johnny Stenback and Andy Heninger},
  title = {Document Object Model (DOM) Level 3 Load and Save Specification},
  howpublished = {W3C Recommendation},
  month = apr,
  year = {2004},
  comment = {24/05/2005},
  file = {Document Object Model (DOM) Level 3 Load and Save Specification.pdf:Document Object Model (DOM) Level 3 Load and Save Specification.pdf:PDF},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://www.w3.org/TR/DOM-Level-3-LS/}
}

@MISC{software:pdftk,
  author = {Sid Steward},
  title = {PDF Toolkit (pdftk)},
  howpublished = {Programa de computador},
  year = {2004},
  owner = {magsilva},
  timestamp = {2010.04.06},
  url = {http://www.accesspdf.com/pdftk/}
}

@ARTICLE{strauss:1996,
  author = {K. F. Strauss and G. J. Stockton},
  title = {Cassini Solid State Recorder: A High Capacity, Radiation Tolerant High-Performance Unit},
  month = aug,
  year = {1996},
  abstract = {Onboard the Cassini spacecraft, and the subject of this paper, are two Solid State Recorders designed and built by TRW, Inc., of Redondo Beach, California, for NASA's Jet Propulsion Laboratory. These recorders, which were the first ones designed and selected by NASA for a space program, represent the new frontier and a new beginning for spaceborne data storage.},
  url = {http://hdl.handle.net/2014/26062},
  comment = {Denver, Colorado, USA},
  journal = {JPL Technical Report},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@ARTICLE{Stroustrup00WC++M,
  author = {B. Stroustrup},
  title = {Wrapping {C++} Member Function Calls},
  volume = {12},
  number = {6},
  month = jun,
  year = {2000},
  url = {http://www.research.att.com/~bs/papers.html},
  journal = {The {C++} Report},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@ARTICLE{Stuikys-Damasevicius:2007,
  author = {Vytautas Stuikys and Robertas Damasevicius},
  title = {Towards knowledge-based generative learning objects},
  volume = {36},
  number = {2},
  year = {2007},
  pages = {202-212},
  abstract = {Today there are many efforts to shift the reuse dimension from component-based to generative reuse in the learning object (LO) domain. This requires more precise LO models and commonality-variability analysis. We propose a new knowledge-based model for representing LO instances. The model is based on factoring and aggregating knowledge units within a LO and is presented as a structure of interface and functionality. Interface serves for explicit describing knowledge communication to and from the LO. Functionality describes knowledge representation and managing. The model contributes to better compositionality, reusability and can be further generalized easily to support the personalized content delivery and automatic generation. Using the introduced model as a basis for generalization, we extended the known concept of generative LOs by linking domain commonality-variability analysis with meta-programming techniques for generating LO instances on demand from the generic LO specification.},
  keywords = {learning object model, generative learning object, commonality-variability analysis},
  url = {http://itc.ktu.lt/itc362/Damasev362.pdf},
  address = {Kaunas, Lithuania},
  issn = {1392-124X},
  journal = {Information Technology and Control},
  timestamp = {2008.09.26}
}

@INPROCEEDINGS{Stuikys-etal:2008,
  author = {Vytautas Stuikys and Robertas Damasevicius and Ilona Brauklyte and Virginija Limanauskiene},
  title = {Exploration of Learning Object Ontologies Using Feature Diagrams},
  pages = {2144-2154},
  address = {Vienna, Austria},
  booktitle = {World Conference on Educational Multimedia, Hypermedia and Telecommunications},
  month = jun,
  publisher = {AACE},
  url = {http://go.editlib.org/p/28667},
  year = {2008}
}

@MISC{software:wmctrl,
  author = {Tomas Styblo},
  title = {wmctrl},
  howpublished = software,
  month = sep,
  year = {2003},
  owner = {magsilva},
  timestamp = {2010.08.26},
  url = {http://tomas.styblo.name/wmctrl/}
}

@ARTICLE{Su-etal:2006,
  author = {Su, Jun-Ming and Tseng, Shian-Shyong and Chen, Chia-Yu and Weng, Jui-Feng and Tsai, Wen-Nung},
  title = {Constructing {SCORM} compliant course based on High-Level {Petri} Nets},
  volume = {28},
  number = {3},
  month = jan,
  year = {2006},
  pages = {336--355},
  doi = {10.1016/j.csi.2005.04.001},
  abstract = {With rapid development of the Internet, e-learning system has become more and more popular. Currently, to solve the issue of sharing and reusing of teaching materials in different e-learning system, Sharable Content Object Reference Model (SCORM) is the most popular standard among existing international standards. In SCORM standard, the Sequencing and Navigation (SN) defines the course sequencing behavior, which controls the sequencing, selecting and delivering of a course, and organizes the content into a hierarchical structure, namely Activity Tree (AT). However, the structures with complicated sequencing rules of Activity Tree (AT) in SCORM make the design and creation of course sequences hard. Therefore, how to provide a user-friendly authoring tool to efficiently construct SCORM compliant course becomes an important issue. However, before developing the authoring tool, how to provide a systematic approach to analyze the sequencing rules and to transform the created course into SCORM compliant are our concerns. Therefore, in this paper, based upon the concept of Object Oriented Methodology (OOM), we propose a systematic approach, called Object Oriented Course Modeling (OOCM), to construct the SCORM compliant course. High-Level Petri Nets (HLPN), which is a powerful language for system modeling and validation, are applied to model the basic sequencing components, called Object-Oriented Activity Tree (OOAT), for constructing the SCORM course with complex sequencing behaviors. Every OOAT as a middleware represents a specific sequencing behavior in learning activity and corresponding structure with associated sequencing rules of AT in SCORM. Thus, these OOATs can be efficiently used to model and construct the course with complex sequencing behaviors for different learning guidance. Moreover, two algorithms, called PN2AT and AT2CP, are also proposed to transform HLPN modeled by OOATs into a tree-like structure with related sequencing rules in Activity Tree (AT) and package the AT and related physical learning resources into a SCORM compliant course file described by XML language, respectively. Finally, based upon the OOCM scheme, a prototypical authoring tool with graphical user interface (GUI) is developed. For evaluating the efficiency of the OOCM approach compared with existing authoring tools, an experiment has been done. The experimental results show that the OOCM approach is workable and beneficial for teachers/instructional designers.},
  keywords = {Adaptive learning environment, Course sequencing, High-Level Petri Nets (HLPN), Learning activity, SCORM},
  address = {Amsterdam, } # Netherlands,
  issn = {0920-5489},
  journal = {Computer Standards \& Interfaces},
  publisher = {Elsevier}
}

@ARTICLE{su-etal:2007,
  author = {Su, Moon Ting and Wong, Chee Shyang and Soo, Chuak Fen and Ooi, Choon Tsun and Sow, Shun Ling},
  title = {Service-Oriented E-Learning System},
  year = {2007},
  pages = {6-11},
  doi = {10.1109/ISITAE.2007.4409227},
  abstract = {Instead of building an e-Learning system from scratch, it can be assembled by choosing the required functionalities from a set of web services related to e-Learning. Web services eliminate many interoperability issues between components written and running on different hardware and software platforms. This study aims to construct a set of e-Learning web services. With these web services, new e-Learning system(s) can be constructed by choosing the services which are required. The developed web services include Assessment, Course Management, Grading, Marking, Metadata, Registration and Reporting web services. These web services are highly in demand as the functionalities for each of the web services are very useful and important in e-Learning systems. In Marking web service, rubrics can be defined to assist in assessment evaluation. In Metadata web service, Learning Object Metadata (LOM) is applied to capture the description of the learning objects.},
  journal = {IEEE International Symposium on Information Technologies and Applications in Education (ISITAE)},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@BOOK{Sudkamp,
  title = {Languages and machines :an introduction to the theory of computer science},
  publisher = {Addison Wesley},
  year = {1998},
  author = {Thomas A. Sudkamp},
  isbn = {0201821362},
  pages = {569},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@MASTERSTHESIS{Sugeta:1999,
  author = {Tatiana Sugeta},
  title = {{Proteum-RS/ST} : Uma Ferramenta para Apoiar a Validação de Especificações Statecharts Baseada na Análise de Mutantes},
  school = {ICMC-USP},
  year = {1999},
  address = {São Carlos, SP, } # Brazil,
  month = nov,
  note = Advisor # {: José Carlos Maldonado},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{Sugeta-etal:2001,
  author = {Tatiane Sugeta and José Carlos Maldonado and Sandra C. P. F. Fabbri},
  title = {{Proteum/ST}: a tool to support statecharts validation based on mutation testing},
  pages = {370--384},
  booktitle = {Ideas 2001 -- Jornadas Iberoamericanas de Ingeniería de Requisitos y Ambientes de Software},
  location = {Santo Domingo, #Costa Rica#},
  month = apr,
  year = {2001}
}

@INPROCEEDINGS{Sugeta-etal:2004,
  author = {T. Sugeta and J. C. Maldonado and W. E. Wong},
  title = {Mutation Testing Applied to Validate {SDL} Specifications},
  pages = {193--208},
  doi = {10.1007/b95741},
  abstract = {Mutation Testing is an error-based criterion that provides mechanisms to evaluate the quality of a test set and/or to generate test sets. This criterion, originally proposed to program testing, has also been applied to specification testing. In this paper, we propose the application of Mutation Testing for testing SDL specifications. We define a mutant operator set for SDL that intends to model errors related to the behavioral aspect of the processes, the communication among processes, the structure of the specification and some intrinsic characteristics of SDL. A testing strategy to apply the mutant operators to test SDL specifications is proposed. We illustrate our approach using the Alternating-Bit protocol},
  volume = {2978},
  series = {Lecture Notes in Computer Science},
  address = {Oxford, United Kingdom},
  booktitle = {16th IFIP International Conference on Testing of Communicating Systems (TestCom 2004)},
  editor = {R. Groz and R. M. Hierons},
  month = feb,
  organization = {IFIP},
  owner = {magsilva},
  publisher = {Springer},
  timestamp = {2008.07.31},
  year = {2004}
}

@INPROCEEDINGS{Suleman:2008,
  author = {Suleman, Hussein},
  title = {Automatic marking with {Sakai}},
  pages = {229--236},
  doi = {10.1145/1456659.1456686},
  abstract = {Large student numbers often drive teaching staff to consider greater degrees of automation of assessment activities. In introductory Computer Science classes - where submitted programs need to repeatedly be compiled, executed and tested -automation is an obvious route to investigate. This paper reports on an experimental automation system for assessing programming assignments, and its integration with the open source Sakai learning management system. While the system has been an administrative success, feedback from students has identified numerous areas for improvement at the interface of the student and the automatic marker. Furthermore, the use of automation has highlighted the need for teaching software development methodology from an early stage.},
  keywords = {Sakai, assessment, automation, interoperability},
  booktitle = {Annual Research Conference of the South African Institute of Computer Scientists and Information Technologists on IT research in developing countries: riding the wave of technology},
  isbn = {978-1-60558-286-3},
  location = {Wilderness, South Africa},
  publisher = {ACM},
  timestamp = {2013-08-23},
  year = {2008}
}

@MISC{software:pngrewrite,
  author = {Jason Summers},
  title = {Pngrewrite},
  howpublished = software,
  month = feb,
  year = {2003},
  url = {http://www.pobox.com/~jason1/pngrewrite/}
}

@MISC{software:jwsdp,
  author = {{SUN Microsystems}},
  title = {Java Web Services Developer Pack},
  howpublished = {Programa de Computador},
  year = {2004},
  comment = {22/06/2005},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://java.sun.com/webservices/jwsdp/index.jsp}
}

@MISC{jaas:2003,
  author = {{Sun Microsystems}},
  title = {Java Authentication and Authorization Service (JAAS)},
  year = {2003},
  owner = {magsilva},
  timestamp = {2007.12.11}
}

@MISC{jndi:1999,
  author = {{Sun Microsystems}},
  title = {Java Naming and Directory Interface (JNDI)},
  month = dec,
  year = {1999},
  owner = {magsilva},
  timestamp = {2007.12.11},
  url = {http://java.sun.com/products/jndi/}
}

@MISC{software:jsfsunri,
  author = {Sun Microsystems, Inc},
  title = {JavaServer Faces RI},
  howpublished = {Programa de computador},
  owner = {magsilva},
  timestamp = {2007.10.07},
  url = {https://javaserverfaces.dev.java.net/}
}

@MISC{software:jms,
  author = {Sun microsystems, Inc},
  title = {Java Message Server (JMS) Specification},
  howpublished = {Especificação},
  month = apr,
  year = {2002},
  owner = {magsilva},
  timestamp = {2006.08.30},
  url = {http://java.sun.com/products/jms/}
}

@PHDTHESIS{Sutherland:1963,
  author = {Ivan Edward Sutherland},
  title = {Sketchpad: A man-machine graphical communication system},
  abstract = {The Sketchpad system uses drawing as a novel communication medium for a computer. The system contains input, output, and computation programs which enable it to interpret information drawn directly on a computer display. It has been used to draw electrical, mechanical, scientific, mathematical, and animated drawings; it is a general purpose system. Sketchpad has shown the most usefulness as an aid to the understanding of processes, such as the notion of linkages, which can be described with pictures. Sketchpad also makes it easy to draw highly repetitive or highly accurate drawings and to change drawings previously drawn with it. The many drawings in this thesis were all made with Sketchpad. A Sketchpad user sketches directly on a computer display with a light pen. The light pen is used both to position parts of the drawing on the display and to point to them to change them. A set of push buttons controls the changes to be made such as erase, or move. Except for legends, no written language is used. Information sketched can include straight line segments and circle arcs. Arbitrary symbols may be defined from any collection of line segments, circle arcs, and previously defined symbols. A user may define and use as many symbols as he wishes. Any change in the definition of a symbol is at once seen wherever that symbol appears. Sketchpad stores explicit information about the topology of a drawing. If the user moves one vertex of a polygon, both adjacent sides will be moved. If the user moves a symbol, all lines attached to that symbol will automatically move to stay attached to it. The topological connections of the drawing are automatically indicated by the user as he sketches. Since Sketchpad is able to accept topological information from a human being in a picture language perfectly natural to the human, it can be used as an input program for computation programs which require topological data, e.g., circuit simulators. Sketchpad itself is able to move parts of the drawing around to meet new conditions which the user may apply to them. The user indicates conditions with the light pen and push buttons. For example, to make two lines parallel, he successively points to the lines withthe light pen and presses a button. The conditions themselves are displayed on the drawing so that they may be erased or changed with the light pen language. Any combination of conditions can be defined as a composite condition and applied in one step. It is easy to add entirely new types of conditions to Sketchpad's vocabulary. Since the conditions can involve anything computable, Sketchpad can be used for a very wide range of problems. For example, Sketchpad has been used to find the distribution of forces in the members of truss bridges drawn with it. Sketchpad drawings are stored in the computer in a specially designed ring structure. The ring structure features rapid processing of topological information with no searching at all. The basic operations used in Sketchpad for manipulating the ring structure are described.},
  school = {Massachusetts Institute of Technology},
  year = {1963},
  month = jan,
  url = {http://www.cl.cam.ac.uk/techreports/UCAM-CL-TR-574.pdf},
  note = {Advisor: Claude E. Shannon},
  owner = {magsilva},
  timestamp = {2011.01.14}
}

@INPROCEEDINGS{Svensson:2005:DWL:1365618.1365626,
  author = {Svensson, Lars and \"{O}stlund, Christian},
  title = {Designing web lectures: bridging design theory and educational practice through an inductive approach},
  pages = {44--52},
  abstract = {This paper explores the potential of an inductive approach to bridging IS design theory and the educational context where the design is to be implemented. The findings indicate three major advantages of deriving an emergent design concept that is rooted in actual design practice. Firstly, this approach generates design concepts that are likely to be situated in existing technological infrastructure Secondly, it introduces a bottom up focus on multimedia prodution issues, where lean production is put at the centre. Thirdly, and finally, a natural consequence of an inductive approach is that system design practice becomes evolutionary rather than revolutionary.},
  keywords = {design concept, distance learning, learning management systems, streaming video, web lectures},
  acmid = {1365626},
  address = {Stevens Point, Wisconsin, USA},
  booktitle = {Proceedings of the 5th WSEAS International Conference on Distance Learning and Web Engineering},
  isbn = {960-8457-34-3},
  location = {Corfu Island, Greece},
  numpages = {9},
  publisher = {World Scientific and Engineering Academy and Society (WSEAS)},
  url = {http://portal.acm.org/citation.cfm?id=1365618.1365626},
  year = {2005}
}

@INPROCEEDINGS{Sze00ACTC,
  author = {Lyu Sze},
  title = {{ATACOBOL}: A COBOL Test Coverage Analysis Tool and its Applications},
  address = {San Jose, CA},
  booktitle = {ISSRE'2000 -- International Symposium on Software Reliability Engineering},
  month = oct,
  note = {(Aceito para publicação)},
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {2000}
}

@ARTICLE{nist:2000,
  author = {Simon Szykman and Ram D. Sriram and Christophe Bochenek and Janusz W. Racz and Jocelyn Senfaute},
  title = {Design Repositories: Engineering Design's New Knowledge Base},
  month = may,
  year = {2000},
  pages = {48-55},
  journal = {IEEE Intelligent Systems},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@MISC{software:okular,
  author = {Piotr Szymanski and Albert Astals Cid and others},
  title = {Okular},
  howpublished = software,
  year = {2005},
  url = {http://okular.kde.org/}
}

@INPROCEEDINGS{takahashi:1996,
  author = {Kenji Takahashi and Colin Potts and Vinay Kumar and Kenji Ota and Jeffrey D. Smith},
  title = {Hypermedia Support for Collaboration in Requirements Analysis},
  pages = {31-40},
  address = {Washington, EUA},
  booktitle = {2nd International Conference on Requirements Engineering (ICRE '96)},
  owner = {magsilva},
  publisher = {IEEE Computer Society},
  timestamp = {2008.07.30},
  year = {1996}
}

@INPROCEEDINGS{Tan-etal:2010,
  author = {Tan, Xiaohong and Ullrich, Carsten and Wang, Yan and Shen, Ruimin},
  title = {The Design and Application of an Automatic Course Generation System for Large-Scale Education},
  pages = {607--609},
  doi = {10.1109/ICALT.2010.172},
  abstract = {In China, the number of online learners who attend formal education has quadrupled in the last 5 years to 8.2 millions until the end of 2008. How can online teachers build and update web-courses for such a large numbers of online students -- courses that ideally respect the different requirements of the students? In this paper we describe an automatic course generation System (ACGS) developed at the Shanghai Jiao Tong University (SJTU). In this ACGS, teachers can build web-based courses according to their own instructional plan and publish the web-based courses without requiring technological support. Teachers can also update the web-courses whenever the instructional objective changes. The web-course learning environment generated from this system takes into account pedagogical scenarios. The ease of use of our system is illustrated by its quickly increasing number of users. About 50 teachers in the SJTU School of Continuing Education (SOCE-SJTU) have developed 45 web-courses in only two months. These 45 web-courses have been provided to about 5800 online learners in the last 2009 autumn semester alone.},
  keywords = {Course generation, large scale education, pedagogical scenario},
  series = {ICALT},
  booktitle = {10th IEEE International Conference on Advanced Learning Technologies},
  isbn = {978-0-7695-4055-9},
  publisher = {IEEE Computer Society},
  year = {2010}
}

@BOOK{Tanenbaum:2010,
  publisher = {Pearson},
  year = {2010},
  author = {Andrew S. Tanenbaum},
  isbn = {978-85-7605-237-1},
  pages = {653},
  address = {São Paulo, SP, } # Brazil,
  edition = {3},
  booktitle = {Sistemas operacionais modernos}
}

@MISC{software:pgf-tikz,
  author = {Till Tantau and Christian Feuersaenger and others},
  title = {PGF and TikZ},
  howpublished = software,
  month = aug,
  year = {2003},
  abstract = {PGF is a TeX macro package for generating graphics. It is platform- and format-independent and works together with the most important TeX backend drivers, including pdftex and dvips. It comes with a user-friedly syntax layer called TikZ.},
  url = {http://sourceforge.net/projects/pgf/},
  urlaccessdate = {20 fev 2012}
}

@MISC{software:latex-beamer,
  author = {Till Tantau and Joseph Wright and Vedran Miletiç and others},
  title = {LaTeX Beamer},
  howpublished = software,
  year = {2003},
  url = {http://bitbucket.org/rivanvx/beamer/wiki/Home},
  urlaccessdate = {20 fev 2012}
}

@INPROCEEDINGS{Tarr-etal:1999,
  author = {Tarr, Peri and Ossher, Harold and Harrison, William and Sutton,Jr., Stanley M.},
  title = {N degrees of separation: multi-dimensional separation of concerns},
  pages = {107--119},
  doi = {10.1145/302405.302457},
  abstract = {Done well, separation of concerns can provide many software engineering benefits, including reduced complexity, improved reusability, and simpler evolution. The choice of boundaries for separate concerns depends on both requirements on the system and on the kind(s) of decomposition and composition a given formalism supports. The predominant methodologies and formalisms available, however, support only orthogonal separation of concerns, along single dimensions fo composition and decomposition. These characteristics lead to a number of well-known and difficult problems. This paper describes a new paradigm for modeling and implementing software artifacts, one that permits separation of overlapping concerns along multiple dimensions of composition and decomposition. This approach addresses numerous problem throughout the software lifecycle in achieving well-engineered, evolvable, flexible software artifacts and traceability across artifacts.},
  keywords = {hypermodules, hyperslices, multi-dimensional separation of concerns, software decomposition and composition},
  series = {ICSE '99},
  acmid = {302457},
  address = {New York, NY, USA},
  booktitle = {International Conference on Software Engineering},
  isbn = {1-58113-074-0},
  location = {Los Angeles, California, United States},
  numpages = {13},
  publisher = {ACM},
  year = {1999}
}

@INPROCEEDINGS{Tate-Dalton:2003,
  author = {Tate, A. and Dalton, J.},
  title = {{O-Plan}: a {Common Lisp} Planning Web Service},
  booktitle = {International Lisp Conference 2003},
  days = {12--15},
  location = {New York, NY, #USA#},
  month = oct,
  owner = {magsilva},
  timestamp = {2014.01.16},
  year = {2003}
}

@INPROCEEDINGS{Taylor-etal:2008,
  author = {Carol A. Taylor and Kejun Xu and Ona Anicello and Scott Somohano and Judith Ramey},
  title = {Skimming the Surface: Understanding Real World Mobile Internet Use},
  pages = {1-4},
  abstract = {In this position paper we discuss the findings so far from an ongoing diary study examining current mobile Internet usage in the United States. Our study addresses these two questions for U.S. mobile phone users: 1) What motivations lead people to access the Internet on their mobile phones?; 2) What do they do?; and 3) Where do they do it? In the first part of the ongoing study, we examined a group of active US mobile Internet users via questionnaires, semi-structured interviews, and a voicemail recording system through which participants recorded each instance of mobile Internet use. Based on the qualitative data analysis, we constructed a framework for understanding mobile Internet motivations and behaviors. By the time of the workshop we will also be able to discuss the validation study now under way. Based on our preliminary findings, however, mobile internet usage by this audience is seamless and superficial: users constantly skim along the surface of Internet information, monitoring and sampling information opportunistically to meet unfolding needs and impulses. Information needs of any depth or complexity, on the other hand, drive these users to the stationary Internet.},
  keywords = {Mobile Internet, mobile Web, mobile usage, user behavior, user motivation, field studies, semi structured interviews},
  address = {Amsterdam, } # Netherlands,
  booktitle = {International Workshop on Mobile Internet User Experience},
  location = {Amsterdam, #Netherlands#},
  month = sep,
  publisher = {ACM},
  timestamp = {2008.09.30},
  year = {2008}
}

@ARTICLE{Taylor-etal:1983,
  author = {Taylor, T. and VanDyk, G. and Funk, L. W. and Hutcheon, R. M. and Schriber, S. O.},
  title = {Therac 25: A New Medical Accelerator Concept},
  volume = {30},
  number = {2},
  month = apr,
  year = {1983},
  pages = {1768--1771},
  doi = {10.1109/TNS.1983.4332638},
  abstract = {An electron linear accelerator system with several novel features has been developed for radiation therapy. The beam from a 25 cell S-band standing wave structure, operated in the Â¿/2 mode with on-axis couplers, is reflected in an achromatic isochronous magnet and reinjected into the accelerator. The second pass doubles the energy while conserving rf power and minimizing the overall length of the unit. The beam is then transported through an annular electron gun and bent into the collimator by an innovative two-element doubly achromatic doubly focusing 270Â° magnet which allows a significant reduction in unit height. The energy is reduced by adjusting the position of the reflecting magnet with respect to the accelerator. The system generates 5 Gy m2min-1 beams of 25 MV photons and 5 to 25 MeV electrons. Extensive use of tungsten shielding minimizes neutron leakage. The photon mode surface dose is reduced by a carefully optimized electron filter. An improved scanning system gives exceptionally low electron -mode photon contamination.},
  issn = {0018-9499},
  journal = {Nuclear Science, IEEE Transactions on}
}

@MISC{software:swf2avi,
  author = {swf2avi Team},
  title = {swf2avi},
  howpublished = software,
  year = {2004},
  url = {http://www.avi-swf-convert.com}
}

@MISC{software:camtasia,
  author = {{TechSmith}},
  title = {Camtasia},
  howpublished = software,
  year = {2011},
  url = {http://www.techsmith.com/camtasia.html}
}

@MISC{software:jing,
  author = {{TechSmith}},
  title = {Jing},
  howpublished = software,
  year = {2011},
  url = {http://www.techsmith.com/jing.html}
}

@INPROCEEDINGS{Teixeira-etal:2009,
  author = {Teixeira, Cesar A. C. and Melo, Erick L. and Cattelan, Renan G. and Pimentel, Maria da Graça C.},
  title = {User-media interaction with interactive TV},
  pages = {1829--1833},
  doi = {10.1145/1529282.1529690},
  abstract = {Watching TV is a practice many people enjoy and feel comfortable with. We propose the capture of the user interaction while interacting with a remote control to watch TV: such detailed information is most valuable to many applications and services. We discuss our proposed approach in the context of the Brazilian Interactive Digital TV platform.},
  keywords = {Ginga-NCL, annotation, interactive digital video},
  series = {SAC},
  address = {New York, NY, USA},
  booktitle = {ACM symposium on Applied Computing},
  isbn = {978-1-60558-166-8},
  location = {Honolulu, Hawaii, #USA#},
  publisher = {ACM},
  year = {2009}
}

@INPROCEEDINGS{Teixeira-etal:1997,
  author = {Teixeira, C. and Abrao, I. and Barrere, E. and Graca Pimentel, M. and Buford, J.},
  title = {A {DAVIC}-based architecture for hypermedia applications over the Internet},
  pages = {4--10},
  doi = {10.1109/PRMNET.1997.638874},
  abstract = {This paper presents an architecture aimed at supporting distributed hypermedia applications focusing on the exchange of multimedia objects over the Internet, their processing and presentation. The model is based on the Digital Audio-Visual Council (DAVIC) proposals for interactive TV, which means that the Multimedia and Hypermedia information coding Expert Group (MHEG-5) is adopted as the representation standard for multimedia objects and the Digital Storage Media Command and Control (DSM-CC) as the real time protocol for data delivery},
  keywords = {DA VIC (Digital Audio- Visual Council); MHEG-5 (Multimedia and Hypermedia information coding Expert Group); DSM-CC (Digital Storage Media Command and Control); Multimedia Objects; Real Time Delivery},
  booktitle = {IEEE Conference on Protocols for Multimedia Systems - Multimedia Networking},
  isbn = {0-8186-7916-6},
  location = {Santiago, #Chile#},
  month = nov,
  year = {1997}
}

@BOOK{Teixeira:2009,
  title = {Televisão Digital: Interação e Usabilidade},
  publisher = {Universidade Católica de Goiás},
  year = {2009},
  author = {Lauro Teixeira},
  isbn = {978-85-7103-590-4},
  pages = {152},
  address = {Goiânia, GO, } # Brazil,
  booktitle = {Televisão Digital: Interação e Usabilidade},
  lang = {pt}
}

@MISC{Telcordia98XTOO,
  author = {{Telcordia Technologies -- USA}},
  title = {x{S}uds {T}oolsuite},
  year = {1998},
  owner = {magsilva},
  timestamp = {2008.07.31},
  url = {http://xsuds.argreenhouse.com/xsuds-demo-intel.exe}
}

@MISC{software:doors,
  author = {{Telelogic}},
  title = {{DOORS}},
  howpublished = {Programa de Computador},
  year = {2005},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://www.telelogic.com/products/doorsers/doors/index.cfm}
}

@MISC{TemplemoreFinlayson:2000,
  author = {Justin George Templemore-Finlayson},
  title = {{JESTELLE}: a super Java-Estelle idea},
  howpublished = {Draft paper},
  month = feb,
  year = {2000},
  url = {http://www-lor.int-evry.fr/~templemo/Academic/Jestelle/jestelle.ps.gz}
}

@MASTERSTHESIS{TemplemoreFinlayson:1998:thesis,
  author = {Justin George Templemore-Finlayson},
  title = {A Graphical Representation for the Formal Description Technique {Estelle}},
  school = {Department of Computer Science, Faculty of Science, University of Cape Town},
  year = {1998},
  address = {Cape Town},
  month = oct,
  url = {http://www-lor.int-evry.fr/~templemo/Academic/GE/jtf-msc-thesis.ps.gz},
  note = {Advisor: P. S. Kritzinger}
}

@MISC{TemplemoreFinlayson:1998:whitepaper,
  author = {Justin George Templemore-Finlayson},
  title = {Estelle Graphical Representation},
  howpublished = {White paper},
  month = dec,
  year = {1998},
  url = {http://www-lor.int-evry.fr/~templemo/GE/estelleGR.ps.gz}
}

@INPROCEEDINGS{tenenberg:2007,
  author = {Josh Tenenberg and Sally Fincher},
  title = {Opening the Door of the Computer Science Classroom: The Disciplinary Commons},
  booktitle = {SIGCSE Symposium},
  owner = {magsilva},
  timestamp = {2007.10.10},
  year = {2007}
}

@INPROCEEDINGS{Tentori-Hayes:2010,
  author = {Tentori, Monica and Hayes, Gillian R.},
  title = {Designing for interaction immediacy to enhance social skills of children with autism},
  pages = {51--60},
  doi = {10.1145/1864349.1864359},
  abstract = {Children with Autism Spectrum Disorder often require therapeutic interventions to support engagement in effective social interactions. In this paper, we present the results of a study conducted in three public schools that use an educational and behavioral intervention for the instruction of social skills in changing situational contexts. The results of this study led to the concept of interaction immediacy to help children maintain appropriate spatial boundaries, reply to conversation initiators, disengage appropriately at the end of an interaction, and identify potential communication partners. We describe design principles for Ubicomp technologies to support interaction immediacy and present an example design. The contribution of this work is twofold. First, we present an understanding of social skills in mobile and dynamic contexts. Second, we introduce the concept of interaction immediacy and show its effectiveness as a guiding principle for the design of Ubicomp applications.},
  keywords = {autism, interaction immediacy, social compass, social skills},
  booktitle = {12th ACM International Conference on Ubiquitous Computing},
  isbn = {978-1-60558-843-8},
  lang = {en},
  location = {Copenhagen, Denmark},
  month = sep,
  publisher = {ACM},
  year = {2010}
}

@INPROCEEDINGS{Teo:2012:CMG:2208276.2208414,
  author = {Teo, Leong-Hwee and John, Bonnie and Blackmon, Marilyn},
  title = {{CogTool-Explorer}: a model of goal-directed user exploration that considers information layout},
  pages = {2479--2488},
  doi = {10.1145/2208276.2208414},
  abstract = {CogTool-Explorer 1.2 (CTE1.2) predicts novice exploration behavior and how it varies with different user-interface (UI) layouts. CTE1.2 improves upon previous models of information foraging by adding a model of hierarchical visual search to guide foraging behavior. Built within CogTool so it is easy to represent UI layouts, run the model, and present results, CTE1.2's vision is to assess many design ideas at the storyboard stage before implementation and without the cost of running human participants. This paper evaluates CTE1.2 predictions against observed human behavior on 108 tasks (36 tasks on 3 distinct website layouts). CTE1.2's predictions accounted for 63-82% of the variance in the percentage of participants succeeding on each task, the number of clicks to success, and the percentage of participants succeeding without error. We demonstrate how these predictions can be used to identify areas of the UI in need of redesign.},
  keywords = {ACT-R, CogTool, human performance modeling, information foraging},
  address = {New York, NY, USA},
  booktitle = {Proceedings of the 2012 ACM annual conference on Human Factors in Computing Systems},
  isbn = {978-1-4503-1015-4},
  location = {Austin, Texas, USA},
  publisher = {ACM},
  year = {2012}
}

@INPROCEEDINGS{Ternier-etal:2006,
  author = {Stefaan Ternier and Ben Bosman and Erik Duval and Lorin Metzger and Mike Halm and Scott Thorne and Jeffrey Kahn},
  title = {Connecting OKI And SQI: One Small Piece Of Code, A Giant Leap For Reusing Learning Objects},
  pages = {825--831},
  abstract = {Learning object repositories are infrastructures for storing learning resources. If they offer a critical mass of materials, they have the potential to facilitate teaching and learning by offering means to reuse and integrate existing materials. This paper discusses search interoperability efforts. By bridging the OKI Open Service Interface Definition (OSIDs) for repositories and Simple Query Interface (SQI), a CEN/ISSS standard for interconnecting search engines, two worlds of repositories are consolidated. The results of this work have already been implemented in two systems: ARIADNE and the LionShare Peer-to-Peer (P2P) environment},
  keywords = {learning objects},
  booktitle = {World Conference on Educational Multimedia, Hypermedia and Telecommunications},
  editor = {Elaine Pearson and Paul Bohman},
  isbn = {1-880094-60-6},
  location = {Chesapeake, VA, USA},
  month = jun,
  publisher = {AACE},
  url = {http://www.editlib.org/p/23102},
  year = {2006}
}

@MISC{software:pdftex,
  author = {Hàn Thé Thành and others},
  title = {pdfTeX},
  howpublished = software,
  year = {1998},
  url = {http://tug.org/applications/pdftex/}
}

@MISC{software:lucene,
  author = {{The Apache Foundation}},
  title = {Lucene},
  howpublished = {Programa de Computador},
  month = mar,
  year = {2000},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://lucene.apache.org/}
}

@MISC{software:struts,
  author = {{The Apache Software Foundation}},
  title = {Struts},
  howpublished = {Programa de Computador},
  month = jun,
  year = {2001},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://struts.apache.org/}
}

@INPROCEEDINGS{Thees1998,
  author = {J. Thees and R. Gotzhein},
  title = {{Open Estelle} -- An {FDT} for Open Distributed Systems},
  pages = {19--36},
  abstract = {An Estelle specification describes a system of communicating components (module instances). The specified system is closed, i.e. it has no ability to interact with some environment. Because of this restriction, open systems can only be specified together with and incorporated into an (Estelle) environment. To overcome this restriction, we introduce a compatible extension of Estelle, called `Open Estelle'. It allows one to specify open systems (i.e. systems that have the ability to communicate with any environment through a well-defined external interface), as well as their formal incorporation into different environments. We define a formal syntax and a formal semantics for Open Estelle, both based on and extending the syntax and semantics of Estelle. Furthermore, we present a set of tools, including a compiler for the automatic generation of implementations directly from Open Estelle specifications.},
  volume = {135},
  series = {IFIP Conference Proceedings},
  booktitle = {Joint International Conference on Formal Description Techniques for Distributed Systems and Communication Protocols (FORTE XI) and Protocol Specification, Testing and Verification (PSTV XVIII)},
  editor = {S. Budkowski and A. Cavalli and E. Najm},
  isbn = {0-412-84760-4},
  location = {Paris, #France#},
  month = nov,
  publisher = {Kluwer},
  year = {1998}
}

@INPROCEEDINGS{Thees-Gotzhein:1998,
  author = {Thees, Joachim and Gotzhein, Reinhard},
  title = {The experimental Estelle Compiler: automatic generation of implementations from formal specifications},
  pages = {54--61},
  doi = {10.1145/298595.298858},
  abstract = {An important aspect of the application of formal methods in software practice is the automatic creation of efficient implementations directly from formal specifications. This often allows to save(or at least to simplify) the costly and error prone step of manual coding. In this paper, we introduce the eXperimental Estde Compder (XEC), a new implementation generator for the specification language Estelle. This tool is experimental in the sense that it has been developed as a platform for the performance-evaluation, optimization, and testing of implementation methods. The special structure of generated implementations allows a very flexible execution model, supporting extensive static and dynamic optimizations. Finally, we report on a casestudy with the Xpress Transport Protocol (XTP), including quantitative performance data of different implementation methods in comparison to other Estelle code generators.},
  keywords = {specification Languages, Estelle, Protocol Implementation, Automatic Code Generation, Tool Support, Performance Optimization, PerformanceMonitoring, XTP},
  booktitle = {2nd Workshop on Formal Methods in Software Practice (FMSP)},
  isbn = {0-89791-954-8},
  location = {Clearwater Beach, Florida, #USA#},
  month = mar,
  publisher = {ACM},
  year = {1998}
}

@TECHREPORT{Thees-Gotzhein:1997,
  author = {J. Thees and R. Gotzhein},
  title = {A Formal Syntax and a Formal Semantics for {Open Estelle}},
  institution = {Department of Computer Sciences, University of Kaiserslautern},
  year = {1997},
  number = {292/97},
  address = {Kaiserslautern, } # Germany,
  abstract = {Estelle is an internationally standardized formal description technique (FDT) designed for the specification of distributed systems, in particular communication protocols. An Estelle specification describes a system of communicating components (module instances). The specified system is closed in a topological sense, i.e. it has no ability to interact with some environment. Because of this restriction, open systems can only be specified together with and incorporated with an environment. To overcome this restriction, we introduce a compatible extension of Estelle, called 'Open Estelle'. It allows the specification of (topologically) open systems, i.e. systems that have the ability to communicate with any environment through a well-defined external interface. We define a formal syntax and a formal semantics for Open Estelle, both based on and extending the syntax and semantics of Estelle. The extension is compatible syntactically and semantically, i.e. Estelle is a subset of Open Estelle. In particular, the formal semantics of Open Estelle reduces to the Estelle semantics in the special case of a closed system. Furthermore, we present a tool for the textual integration of open systems into environments specified in Open Estelle, and a compiler for the automatic generation of implementations directly from Open Estelle specifications.},
  pages = {20}
}

@MISC{software:evince,
  author = {{The Evince Team}},
  title = {Evince},
  howpublished = software,
  month = dec,
  year = {2004},
  url = {http://projects.gnome.org/evince/}
}

@MISC{rfc4510,
  author = {{The Internet Society}},
  title = {Lightweight Directory Access Protocol (LDAP): Technical Specification Road Map},
  howpublished = {RFC 4510},
  year = {2006},
  owner = {magsilva},
  timestamp = {2008.01.28}
}

@MISC{software:openssl,
  author = {{The OpenSSL Project}},
  title = {{OpenSSL}},
  howpublished = {Programa de computador},
  month = dec,
  year = {1998},
  owner = {magsilva},
  timestamp = {2007.12.11},
  url = {http://www.openssl.org/}
}

@MISC{software:twiki,
  author = {Peter Thoeny},
  title = {TWiki},
  howpublished = {Programa de Computador},
  month = jul,
  year = {1998},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://twiki.org}
}

@MISC{xmlschema-1:2004,
  author = {Henry S. Thompson and David Beech and Murray Maloney and Noah Mendelsohn},
  title = {XML Schema Part 1: Structures},
  howpublished = {W3C Recommendation},
  month = oct,
  year = {2004},
  comment = {24/05/2005},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://www.w3.org/TR/xmlschema-1/}
}

@ARTICLE{Thuring95HCDC,
  author = {M. Thüring and J. Hannemann and J. M. Haake},
  title = {Hypermedia and Cognition: Designing for Comprehension},
  volume = {38},
  number = {8},
  month = aug,
  year = {1995},
  pages = {57--66},
  journal = cacm,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@MISC{rcs:1982,
  author = {Walter Tichy},
  title = {Revision Control System (RCS)},
  howpublished = {Software},
  year = {1982},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://www.cs.purdue.edu/homes/trinkle/RCS/}
}

@PHDTHESIS{Tiellet:2010,
  author = {Claudio Afonso Baron Tiellet},
  title = {Construção e avaliação do hipervídeo como ferramenta auxiliar para aprendizagem de cirurgia},
  abstract = {Na busca de formas alternativas com vistas à aprendizagem de cirurgia veterinária, em substituição ao uso de animais vivos não humanos, e hoje proibidos por lei, o Hipervídeo é considerado um promissor candidato como uma ferramenta de auxilio ao aprendizado. O vídeo como meio de comunicação visual, dinâmico e combinado com áudio, se constitui num poderoso meio de comunicação. Aumenta o realismo e a autenticidade em ambientes de aprendizagem computadorizados. Através de recursos interativos adicionados nos vídeos, são exploradas outras mídias relacionadas aos conteúdos apresentados, aumentando a retenção mnemônica. Alinha-se, portanto, às teorias pedagógicas que defendem a importância da autonomia do sujeito nos processos de aprendizagem. O Hipervídeo pode, então, apoiar a criação de um ambiente rico e realista para aprendizagem, através do acesso interativo, construção e comunicação do conhecimento em cirurgia veterinária. Esta tese trata da avaliação de um ambiente Hipervídeo desenvolvido para apoiar a aprendizagem de cirurgia veterinária. O projeto foi desenvolvido com base em teorias cognitivas e meios de comunicação. A avaliação foi baseada na utilização do Hipervídeo por estudantes de medicina veterinária para aprenderem a realizar cirurgias, a fim de testar a sua eficácia na substituição de aprendizagem e formação, com animais vivos. Os resultados confirmam a hipótese, mostrando o potencial do Hipervídeo como uma ferramenta valiosa e eficaz para apoiar a aprendizagem da técnica cirúrgica.},
  school = {Universidade Federal do Rio Grande do Sul (UFRGS) -- Centro de Estudos Interdisciplinares em Novas Tecnologias da Educação},
  year = {2010},
  advisor = {José Valdeni de Lima and Eliseo Berni Reategui},
  address = {Porto Alegre, RS, } # Brazil,
  month = nov,
  url = {http://hdl.handle.net/10183/27967},
  abstract-en = {Searching for alternative methods of learning in the veterinary surgery arena, in which the use of live animals is strictly regulated, the hypervideo is now considered a promising candidate as an instrument to facilitate the learning process. The dynamics of the video as a means of visual communication, combined with audio, constitutes in a powerful communication tool because it enhances the realism and authenticity in computer-based learning environments. Through interactive features added to the videos, other forms of media related to content submitted are explored, enhancing the mnemonic absorption. It corroborates teaching theories that advocate the importance of subject autonomy in the learning process. The hypervideo can then support the creation of a rich and realistic learning environment through interactive access, construction and communication of the knowledge in veterinary surgery. This research aims to evaluate the environment of hypervideo developed to help and facilitate the learning of veterinary surgery. The project was developed based on cognitive theories and the computer? media. The evaluation was based on the use of hypervideo for veterinary medicine undergraduate students to learn to perform surgery in order to test its effectiveness in replacing the learning and training experience with live animals. The results confirmed the hypothesis, showing the potential of hypervideo as a valuable and effective support method for learning the surgery techniques.},
  lang = {pt}
}

@MISC{uri:2005,
  author = {Timothy J. Berners-Lee, R. Fielding, L. Masinter},
  title = {Uniform Resource Identifier (URI): Generic Syntax},
  howpublished = {Request for Comments},
  month = jan,
  year = {2005},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://www.gbiv.com/protocols/uri/rfc/rfc3986.html}
}

@ARTICLE{tip:1995,
  author = {Frank Tip},
  title = {A Survey of Program Slicing Techniques},
  volume = {3},
  number = {3},
  year = {1995},
  pages = {121-189},
  address = {Amsterdam, Netherlands},
  institution = {Centre for Mathematics and Computer Science (CWI)},
  journal = {Journal of Programming Languages},
  owner = {magsilva},
  timestamp = {2010.07.12}
}

@ARTICLE{Tomayko:1998,
  author = {Tomayko, James E.},
  title = {Forging a discipline: An outline history of software engineering education},
  volume = {6},
  number = {1--4},
  month = mar,
  year = {1998},
  pages = {3--18},
  doi = {10.1023/A:1018953214201},
  abstract = {Software engineering education has a 30-year history. It is a story of academics struggling to fulfill industry needs with almost no support from computer science curriculum designers. It is a story of industry finally winning over some of academia to teach software engineering rather than vanilla computer science. It is a story of a discipline still incomplete, but having made great strides in the last decade. This paper discusses the succeeding eras of software engineering education, from lone teachers to master's curricula to undergraduate degree programs. Even though the maturity of the discipline is as yet unattained, it will achieve adult status through practice, not by waiting for academia to glacially catch up.},
  address = Netherlands,
  issn = {1022-7091},
  issue = {1},
  journal = {Annals of Software Engineering},
  keyword = {Computer Science},
  publisher = {Springer}
}

@ARTICLE{Tompsett:2005,
  author = {Tompsett, C.},
  title = {Reconfigurability: creating new courses from existing learning objects will always be difficult!},
  volume = {21},
  number = {6},
  month = dec,
  year = {2005},
  pages = {440--448},
  doi = {10.1111/j.1365-2729.2005.00154.x},
  abstract = {The suggestion that new courses can be constructed from existing learning objects appears technically self-evident but remains unproven. Despite increasing evidence that learning objects can provide a suitable structure for constructing courses most evidence is based on creating learning objects, either through restructuring existing materials or as a set of newly created learning objects. There is little evidence for building a new course from existing learning objects where any significant number of these have been developed for a different course elsewhere. Authors who adopt a constructivist model of knowledge might view this lack of evidence as confirmation of the inherent difficulty of integrating resources created within different communities. Those following a scientific model of knowledge would view this as a temporary problem that will be resolved when a sufficient volume of materials exists in repositories. This paper argues that reconfiguration of learning objects to create new courses is significantly more complex than is currently recognized, even within a scientific framework of knowledge. By implication, far more research is needed to understand reconfiguration and re-integration than initial creation.},
  keywords = {cliques, complexity, course construction, Hamiltonian paths, learning objects, mathematical, metadata, NP-complete, reconfigurability, reusable, semantic Web},
  issn = {1365-2729},
  journal = {Journal of Computer Assisted Learning},
  lang = {en},
  publisher = {Blackwell Science}
}

@MISC{software:rem,
  author = {Amador Durán Toro},
  title = {REM (REquisite Management)},
  howpublished = {Programa de Computador},
  year = {2004},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://www.lsi.us.es/descargas/descarga_programas.php?id=3}
}

@PHDTHESIS{duran:2000:2,
  author = {Amador Dur\'an Toro},
  title = {Un Entorno Metodológico de Ingeniería de Requisitos para Sistemas de Información},
  school = {Universidad de Sevilla},
  year = {2000},
  month = sep,
  url = {http://www.lsi.us.es/~amador/publicaciones/tesis.pdf.zip},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@INPROCEEDINGS{Toro-etal:2000,
  author = {A. Durán Toro and A. Ruiz Cortés and R. Corchuelo Gil and M. Toro Bonilla},
  title = {Identificación de Patrones de Reutilización de Requisitos de Sistemas de Información},
  booktitle = {WER2000},
  owner = {magsilva},
  timestamp = {2008.07.30},
  year = {2000 }
}

@INPROCEEDINGS{toro:1999,
  author = {A. Durán Toro and B. Bernárdez Jiménez and Antonio Ruiz Cortés and M. Toro Bonilla},
  title = {A Requirements Elicitation Approach Based in Templates and Patterns},
  pages = {17-29},
  address = {Buenos Aires, Argentina},
  booktitle = {Workshop em Engenharia de Requisitos},
  owner = {magsilva},
  timestamp = {2008.07.30},
  year = {1999}
}

@MISC{software:git,
  author = {Linus Torvalds and Junio C. Hamano},
  title = {GIT},
  howpublished = software,
  month = apr,
  year = {2005},
  owner = {magsilva},
  timestamp = {2006.07.17},
  url = {http://git.or.cz/}
}

@MISC{software:linux,
  author = {Linus Torvalds and others},
  title = {Linux},
  howpublished = {Programa de Computador},
  month = aug,
  year = {1991},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://www.kernel.org}
}

@ARTICLE{toth:2007,
  author = {Kal Toth},
  title = {Experiences with Open Source Software Engineering Tools},
  volume = {23},
  number = {6},
  month = nov,
  year = {2007},
  pages = {44-52},
  journal = {IEEE Software},
  owner = {magsilva},
  timestamp = {2007.04.27}
}

@ARTICLE{Tracey00ATDG,
  author = {N. Tracey and J. Clark and K. Mander and J. McDermid},
  title = {Automated Test-Data Generation for Exception Conditions},
  volume = {30},
  year = {2000},
  pages = {61--79},
  journal = spe,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@TECHREPORT{Travassos-etal:2002,
  author = {Guilherme Horta Travassos and Dmytro Gurov and Edgar Augusto Gurgel do Amaral},
  title = {Introdução à Engenharia de Software Experimental},
  institution = {COPPE/UFJR},
  year = {2002},
  number = {RT-ES-590/02},
  address = {Rio de Janeiro, RJ, Brazil},
  url = {http://www.ufpa.br/cdesouza/teaching/topes/4-ES-Experimental.pdf},
  type = {Technical Report}
}

@INPROCEEDINGS{Triacca-etal:2004,
  author = {Triacca, Luca and Bolchini, Davide and Botturi, Luca and Inversini, Alessandro},
  title = {MiLE: Systematic Usability Evaluation for E-Learning Web Applications},
  pages = {4398-4405},
  abstract = {This paper presents a proven and reusable methodology (MiLE) for performing a cost-effective usability evaluation of an e-learning web application. MiLE is a scenario-driven inspection technique which is based on the concepts of user profile, user goal, scenario, and usability attribute. Mitigating the drawbacks and merging the respective benefits of state-of-the-art methods for usability evaluation, MiLE is intended to be a helpful tool for project managers, instructional designers, and evaluators to carry out a learner-centered validation which can anticipate and analytically justify the usability breakdowns, thus providing organized indications for a focused redesign. Examples of the results that can be obtained using MiLE are showed through a real case study evaluation of a large e-learning corporate platform.},
  booktitle = {World Conference on Educational Multimedia, Hypermedia and Telecommunications 2004},
  location = {Chesapeake, VA, USA},
  publisher = {AACE},
  timestamp = {2012.01.24},
  url = {http://editlib.org/p/11709},
  year = {2004}
}

@MISC{software:samba,
  author = {Andrew Tridgell and others},
  title = {Samba},
  howpublished = {Programa de computador},
  year = {1992},
  owner = {magsilva},
  timestamp = {2007.12.11},
  url = {http://www.samba.org}
}

@MASTERSTHESIS{Trindade:2009,
  author = {Trindade, Cleyton Carvalho da},
  title = {{Presley}: uma ferramenta de recomendação de especialistas para apoio à colaboração em desenvolvimento distribuído de software},
  abstract = {Nowadays, it is common to find software companies with distributed development teams in different locations; in many cases, this division occurs in a global extent. The increase of this new mode of organization and arrangement of teams is connected to the companies' interest in getting the most capable professionals, reducing the cost of developing, having a globalized presence and reaching a larger proximity with its clients. However, the Distributed Software Development has created several challenges in the communication among its collaborators. Amongst the aspects that were most damaged by deficient communication, there is the identification of experts in the project. Because of this, the beginning of the process of communication becomes slow, affecting the performance of the activities in the project and creating delays in the project's accomplishment. As the teams may have a very short overlap of working hours, the identification of the most probable person to answer doubt messages seems tom be a great opportunity to reduce the delays created in the communication, mainly asynchronous, among distributed teams. The present work proposes the tool Presley to identify and recommend the experts existing in a project to those people who search for help during the encoding activity, reducing the waiting time and avoiding waste of effort in the localization of the expert. This is carried out through the analysis of the information enclosed in the records of communication of the developers and in the historical of alterations of the source codes. The experiment carried out demonstrated that the tool can be helpful in the collaboration between distributed teams and that the communication recorded can provide valuable information in the identification of the specialists.},
  keywords = {Distributed Software Development, Expert Recommendation Systems},
  school = {UFPE},
  year = {2009},
  advisor = {Silvio Romero de Lemos Meira},
  address = {Recife, PE, } # Brazil,
  month = aug,
  url = {http://www.bdtd.ufpe.br/bdtd/tedeSimplificado/tde_busca/processaPesquisa.php?listaDetalhes[]=3181},
  abstract-original = {Atualmente é comum encontrar empresas de software com equipes de desenvolvimento distribuídas em diferentes localizações; em vários casos esta divisão ocorre em escala global. O crescimento desta nova modalidade de organização e disposição dos times está ligado aos interesses das empresas em conseguir os profissionais mais capacitados, reduzir o custo de desenvolvimento, ter presença globalizada e alcançar maior proximidade com os seus clientes. Contudo, o Desenvolvimento Distribuído de Software (DDS) tem criado diversos desafios na comunicação entre seus colaboradores. Entre os aspectos mais prejudicados pela comunicação deficiente está a identificação dos especialistas no projeto. Por conta disso, o inicio do processo de comunicação torna-se lento, afetando o desempenho das atividades no projeto e gerando atrasos na execução do projeto. Como as equipes podem ter um tempo de sobreposição de horário de trabalho muito curto, a identificação da pessoa mais provável a responder mensagens de dúvidas aponta ser uma grande oportunidade para reduzir os atrasos gerados na comunicação, principalmente assíncrona, entre equipes distribuídas. O presente trabalho propõe a ferramenta Presley para identificar e recomendar os especialistas existentes em um projeto àquelas pessoas que buscam por ajuda durante a atividade de codificação, reduzindo o tempo de espera e evitando desperdício de esforço na localização dos especialistas. Isto é realizado através da análise das informações contidas nos registros de comunicação dos desenvolvedores e no histórico de alterações dos códigosfonte. O experimento realizado demonstrou que a ferramenta pode ajudar na colaboração entre equipes distribuídas e que a comunicação registrada pode fornecer informações valiosas na identificação dos especialistas},
  keywords-original = {Desenvolvimento Distribuído de Software, Sistemas de Recomendação de Especialistas},
  lang = {pt},
  title-original = {{Presley}: uma ferramenta de recomendação de especialistas para apoio à colaboração em desenvolvimento distribuído de software}
}

@ARTICLE{trojahn-etal:2011,
  author = {Trojahn, Tiago and Gonçalves, Juliano and Mattos, Júlio and Agostini, Luciano and Da Rosa, Leomar},
  title = {Evaluating two implementations of the component responsible for decoding video and audio in the Brazilian digital TV middleware},
  year = {2011},
  pages = {1-20},
  doi = {10.1007/s11042-011-0753-x},
  abstract = {The project Ginga Code Development Network (GingaCDN) was created to implement a reference version of Ginga, the Brazilian Digital Television System (SBTVD) middleware, supporting the declarative GingaNCL and the procedural GingaJ environments in the same middleware. To reach that, a common core is being implemented, named Ginga Common Core (GingaCC). One of the main components of the GingaCC is the one responsible to decode audio and video streams, called Media Processing. In this work, two Media Processing implementations using libVLC and Xine graphical libraries are investigated. Performance tests and results of both Media Processing implementations running in two different desktop architectures are discussed.},
  affiliation = {Technological Development Center, Federal University of Pelotas, Pelotas, Brazil},
  issn = {1380-7501},
  journal = {Multimedia Tools and Applications},
  keyword = {Computer Science},
  publisher = {Springer Netherlands}
}

@INPROCEEDINGS{detroyer:1998,
  author = {O. M. F. De Troyer and C. J. Leune},
  title = {{WSDM}: a user centered design method for {Web} sites},
  pages = {85-94},
  volume = {30},
  booktitle = {Computer Networks and ISDN Systems},
  citeseerurl = {citeseer.ist.psu.edu/detroyer98wsdm.html},
  file = {WSDM\: A User Centered Design Method for Web Sites.pdf:home/magsilva/toCD/Artigos/WSDM\: A User Centered Design Method for Web Sites.pdf:PDF},
  owner = {magsilva},
  timestamp = {2008.07.30},
  year = {1998}
}

@MISC{truta:2008,
  author = {Cosmin Truta},
  title = {A guide to PNG optimization},
  howpublished = {White paper},
  month = may,
  year = {2008},
  url = {http://optipng.sourceforge.net/pngtech/optipng.html}
}

@ARTICLE{Tse-etal:2004,
  author = {T. H. Tse and T. Y. Chen and Robert L. Glass},
  title = {An assessment of systems and software engineering scholars and institutions (2000-2004)},
  volume = {79},
  year = {2004},
  pages = {816-819},
  journal = {The Journal of System and Software},
  owner = {magsilva},
  timestamp = {2006.11.10}
}

@ARTICLE{Tsekleves-etal:2011,
  author = {Emmanuel Tsekleves and Roger Whitham and Koko Kondo and Annette Hill},
  title = {Investigating media use and the television user experience in the home},
  volume = {2},
  number = {3},
  year = {2011},
  pages = {151 - 161},
  doi = {10.1016/j.entcom.2011.02.002},
  abstract = {In this paper we report on a study conducted in 2007 and 2008 looking at the media use habits of 27 families in the Greater London area. The project builds on previous work studying media use within a similar group in 2006. The study investigated attitudes towards different types of media and the role television (TV) currently plays and could play within the home environment. To facilitate the study we rapidly prototyped an experimental home media device and asked participants to use and respond to it. We explored issues of interactional simplicity and sharing media using a TV and employed the experimental device as a focal point for discussion and the generation of new ideas. Our key findings indicate a strong desire for services which support media presentation and consumption through the TV (combined with a suitable control device) and cater for social interaction within the home such as sharing photos and videos with other household members. In addition we found a strong user preference for services that offer fast and immediate access to specialised online activities, such as quick checks of e-mail accounts and social networking services.},
  keywords = {Interactive television, User studies, Media use in the home, Sharing media, Experimental device, User experience},
  issn = {1875-9521},
  journal = {Entertainment Computing}
}

@INPROCEEDINGS{tuckeretal:2003,
  author = {Allen Tucker and Fadi Deek and Jill Jones and Dennis McCowan and Chris Stephenson and Anita Verno},
  title = {Toward a {K-12} computer science curriculum},
  pages = {305--306},
  doi = {10.1145/611892.611912},
  address = {New York, NY, USA},
  booktitle = {SIGCSE '03: Proceedings of the 34th SIGCSE technical symposium on Computer science education},
  isbn = {1-58113-648-X},
  location = {Reno, Navada, USA},
  owner = {magsilva},
  publisher = {ACM},
  timestamp = {2008.07.30},
  year = {2003}
}

@ARTICLE{Tucker95AVCP,
  author = {R. W. Tucker},
  title = {Assessing the Virtual Classrooms: a Progress Report},
  volume = {5},
  number = {2},
  year = {1995},
  journal = {Assessment and Accountability Forum},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@PHDTHESIS{Turine:1998,
  author = {M. A. S. Turine},
  title = {{HMBS}: Um Modelo Baseado em Statecharts para a Especificação Formal de Hiperdocumentos},
  abstract = {Um novo modelo para a especificação de hiperdocumentos denominado HMBS - Hyperdocument Model Based on Statecharts - é proposto. O HMBS adota como modelo formal subjacente a técnica Statecharts, cuja estrutura e semântica operacional são utilizadas para especificar a estrutura organizacional e a semântica de navegação de hiperdocumentos grandes e complexos. A definição do HMBS, bem como a semântica de navegação adotada, são apresentadas. Na definição apresenta-se como o modelo permite separar as informações referentes à estrutura organizacional e navegacional das representações físicas do hiperdocumento. Também são discutidas características do modelo que possibilitam ao autor analisar a estrutura do hiperdocumento, encorajando a especificação de hiperdocumentos estruturados. Para provar e validar a viabilidade prática do uso do HMBS num contexto real foi desenvolvido um ambiente de autoria e navegação de hiperdocumentos denominado HySCharts - Hyperdocument System based on StateCharts. Esse ambiente fornece facilidades de prototipação rápida e simulação interativa de hiperdocumentos. Para ilustrar como o modelo HMBS e o HySCharts podem ser utilizados no contexto de uma abordagem de projeto sistemática é utilizada como estudo de caso a especificação de um hiperdocumento que apresenta o Parque Ecológico de São Carlos.},
  school = {Universidade de São Paulo (USP) -- Instituto de Física de São Carlos (IFSP)},
  year = {1998},
  address = {São Carlos, SP, Brazil},
  url = {http://www.dct.ufms.br/~turine/tese/tese.htm},
  abstract-en = {A new model for hyperdocument specification called HMBS - Hyperdocument Model Based on Statecharts - is proposed. HMBS uses the Statechart formalism as its underlying model. Statecharts structure and operational semantics are used to specify the organizational structure and the browsing semantics of large and complex hyperdocuments. The definition of HMBS is presented and its browsing semantics is described. It is shown how the model allows the separation of information related to the organizational and navigational structure from the hyperdocument's physical representation. Model features that allow authors to analyse the hyperdocument structure, encouraging the specification of structured hyperdocuments are also discussed. As a proof of concept and also to evaluate the feasibility of using HMBS in real-life applications a system called HySCharts - Hyperdocument System based on StateCharts - was developed. HySCharts is composed by an authoring and a browsing environments, supporting rapid prototyping and interactive simulation of hyperdocuments. A case study is presented that uses the specification of a hyperdocument introducing the Ecological Park of São Carlos to illustrate the use of HMBS and of the HySCharts environment integrated into a systematic design approach.},
  note = {Advisor: Paulo César Masiero. Co-advisor: Maria Cristina F. de Oliveira},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@ARTICLE{Turine-etal:1999:MTA,
  author = {M. A. S. Turine and M. C. F. Oliveira and P. C. Masiero},
  title = {{HySCharts}: A Statechart-Based Environment for Hyperdocument Authoring and Browsing},
  volume = {8},
  number = {3},
  month = may,
  year = {1999},
  pages = {309--324},
  doi = {10.1023/A:1009618225419},
  abstract = {The HySCharts environment (Hyperdocument System Based on StateCharts) supports the formal specification of hyperdocuments using a novel formalism called HMBS (Hyperdocument Model Based on Statecharts). This paper presents the HySCharts system architecture, with emphasis on its underlying model and on the functionality of its authoring and browsing modules. HMBS is a statechart-based, navigation-oriented model for hyperdocument specification that uses the structure and execution semantics of statecharts to specify both the structural organization and the browsing semantics of a hyperdocument. The formal definition of HMBS and its associated browsing semantics are introduced. A discussion of the system and its capabilities, as supported by the model, is also provided.},
  keywords = {hypermedia system, hypermedia model, statecharts, HMBS, hierarchical views, HySCharts},
  issn = {1380-7501, 1573-7721},
  journal = {Multimedia Tools and Applications},
  lang = {en},
  owner = {magsilva},
  publisher = {Springer},
  timestamp = {2008.07.30}
}

@INPROCEEDINGS{Turine-etal:1999:SBES,
  author = {M. A. S. Turine and M. C. F. Oliveira and P. C. Masiero},
  title = {{HySCharts}: um ambiente de autoria e navegação para a especificação formal de aplicações hipermídia},
  pages = {1-4},
  abstract = {O ambiente HySCharts (Hyperdocument System based on StateCharts) permite especificar formalmente aplicações hipermídia segundo o modelo HMBS (Hyperdocument Model Based on Statecharts). O HMBS adota a técnica Statecharts como modelo formal subjacente. Para provar e validar a viabilidade prática do uso do HMBS num contexto real, desenvolveu-se um ambiente de autoria e navegação denominado HySCharts, que permite criar, interpretar e executar especificações formais de aplicações hipermídia segundo o modelo HMBS, além de oferecer facilidades para prototipação rápida e simulação interativa.},
  booktitle = {Simpósio Brasileiro de Engenharia de Software (SBES 99)},
  owner = {magsilva},
  timestamp = {2008.07.30},
  year = {1999}
}

@INPROCEEDINGS{Turine-etal:1998,
  author = {Marcelo Augusto Santos Turine and Maria Cristina Ferreira de Oliveira and Paulo Cesar Masiero},
  title = {{HySCharts}: Um Ambiente de Autoria e Navegação Baseado no Modelo {HMBS}},
  pages = {27-38},
  abstract = {O ambiente HySCharts (Hyperdocument System based on StateCharts) permite criar, interpretar e executar especificações formais de aplicações hipermídia segundo o modelo HMBS (Hyperdocument Model Based on Statecharts). A arquitetura do HySCharts, enfatizando as funcionalidades dos seus módulos de autoria e de navegação, é apresentada. O modelo HMBS utiliza a estrutura e a semântica operacional de Statecharts para especificar a estrutura e a semântica de navegação de hiperdocumentos grandes e complexos. A definição formal do HMBS, bem como a semântica de navegação adotada são introduzidas. Uma breve discussão das características do ambiente HySCharts e do modelo também é apresentada.},
  keywords = {Sistemas Hiperdocumento, Modelos para Especificação de Hiperdocumentos, Ferramentas para Sistemas Hiperdocumento, Statecharts, HMBS, HySCharts},
  abstract-en = {The HySCharts environment (Hyperdocument System based on StateCharts) supports the formal specification of hyperdocuments using a novel formalism called HMBS (Hyperdocument Model Based on Statecharts). This paper presents the HySCharts system architecture, stressing the functionalities of its authoring and browsing modules, as well as its underlying model. HMBS is a statechart-based, navigation-oriented model for hyperdocument specification that uses the structure and execution semantics of statecharts to specify both the structural organization and the browsing semantics of a hyperdocument. The formal definition of the model and its associated browsing semantics are introduced. A short discussion on the system and model capabilities is also provided.},
  address = {Rio de Janeiro, RJ},
  booktitle = {IV Simpósio Brasileiro de Multimídia e Sistemas Hipermídia (SBMIDIA 98)},
  location = {Rio de Janeiro, RJ, Brrazil},
  month = may,
  owner = {magsilva},
  timestamp = {2008.07.30},
  year = {1998}
}

@INPROCEEDINGS{Turine-etal:1997,
  author = {Marcelo Augusto Santos Turine and Maria Cristina Ferreira de Oliveira and Paulo Cesar Masiero},
  title = {A navigation-oriented hypertext model based on statecharts},
  pages = {241--256},
  doi = {10.1145/267437.267449},
  abstract = {In this paper we present a navigation-oriented model for hyperdocument specification based on statecharts. The HMBS (Hypertext Model Based on Statecharts) model uses the structure and execution semantics of statecharts to specify both the structural organization and the browsing semantics of a hyperdocument. The formal definition of the model is presented, as well as its associated browsing semantics. A short discussion on the model's capabilities is also provided. A prototype hypertext system which implements HMBS as its underlying model for hyperdocument authoring and browsing is introduced, and some examples are presented that illustrate the application of the model.},
  address = {New York, NY, EUA},
  booktitle = {ACM Conference on Hypertext},
  isbn = {0-89791-866-5},
  location = {Southampton, UK},
  month = apr,
  owner = {magsilva},
  publisher = {ACM},
  timestamp = {2008.07.30},
  year = {1997}
}

@INPROCEEDINGS{Turner93SBTO,
  author = {C. D. Turner and D. J. Robson},
  title = {The State-Based Testing of Object-Oriented Programs},
  pages = {302--310},
  booktitle = {IEEE Conference on Software Maintenance},
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1993}
}

@BOOK{Turner:1993,
  title = {Using Formal Description Techniques -- An Introduction to {E}stelle, {L}otos and {SDL}},
  publisher = {John Wiley \& Sons},
  year = {1993},
  author = {K. J. Turner},
  isbn = {0471934550},
  address = {New York, NY, USA},
  month = oct,
  booktitle = {Using Formal Description Techniques -- An Introduction to {E}stelle, {L}otos and {SDL}},
  url = {http://www.cs.stir.ac.uk/~kjt/using-fdts/}
}

@INPROCEEDINGS{turner-etal:2008,
  author = {Mark Turner and Barbara Kitchenham and David Budgen and Pearl Brereton},
  title = {Lessons learnt Undertaking a Large-scale Systematic Literature Review},
  abstract = {We have recently undertaken a large-scale Systematic Literature Review (SLR) of a research question concerning the Technology Acceptance Model (TAM). At the end of the study, we observed some anomalies during the analysis of the extracted data. In our attempts to identify the cause of the anomalies, we found a number of mistakes that had been made during the data extraction process. We discuss each of the mistakes in terms of why they occurred and how they might have been avoided. We suggest a number of ways in which the available guidelines for conducting SLRs should be amended to help avoid such problems occurring in future reviews.},
  address = {University of Bari, Italy},
  booktitle = {International Conference on Evaluation and Assessment in Software Engineering (EASE)},
  month = jun,
  url = {http://www.bcs.org/content/conWebDoc/19549},
  year = {2008}
}

@INPROCEEDINGS{Twidale-Nichols:2005,
  author = {Twidale, Michael B. and Nichols, David M.},
  title = {Exploring Usability Discussions in Open Source Development},
  doi = {10.1109/HICSS.2005.266},
  volume = {7},
  series = {HICSS},
  acmid = {1043103},
  address = {Washington, DC, USA},
  booktitle = {38th Annual Hawaii International Conference on System Sciences},
  isbn = {0-7695-2268-8-7},
  publisher = {IEEE Computer Society},
  year = {2005}
}

@ARTICLE{undercoffer-etal:2003,
  author = {Jeffrey Undercoffer and Anupam Joshi and John Pinkston},
  title = {Modeling Computer Attacks: An Ontology for Intrusion Detection},
  volume = {2820},
  year = {2003},
  pages = {113-135},
  journal = {Lectures Notes On Computer Science},
  owner = {magsilva},
  timestamp = {2006.07.10}
}

@PROCEEDINGS{unesco:2002,
  title = {Final report of the Forum on the Impact of Open Courseware for Higher Education in Developing Countries},
  year = {2002},
  month = jul,
  days = {1--3},
  location = {Paris, #France#},
  author = {{UNESCO}},
  institution = {UNESCO},
  pages = {28}
}

@MISC{unesco:2001,
  author = {{United Nations Educational, Scientific and Cultural Organization}},
  title = {Free Software History},
  howpublished = {Web site},
  year = {2001},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://www.unesco.org/webworld/portal_freesoft/open_history.shtml}
}

@MISC{software:weka,
  author = {{University of Waikato}},
  title = {Weka},
  howpublished = {Software},
  year = {1997},
  url = {http://www.cs.waikato.ac.nz/ml/weka/}
}

@INPROCEEDINGS{Untch93MSCH,
  author = {R. Untch and M. J. Harrold and J. Offutt},
  title = {Mutation Analysis Using Mutant Schemata},
  pages = {139--148},
  address = {Cambridge, Massachusetts},
  booktitle = {International Symposium on Software Testing and Analysis},
  month = jun,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1993}
}

@ARTICLE{ural-yang:1988,
  author = {Hasan Ural and Bo Yang},
  title = {A Structural Test Selection Criterion},
  volume = {28},
  number = {3},
  month = jul,
  year = {1988},
  pages = {157--163},
  doi = {10.1016/0020-0190(88)90162-7},
  journal = {Information Processing Letters},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{Urbanek:2003,
  author = {Simon Urbanek},
  title = {{RServe}: A Fast Way to Provide R Functionality to Applications},
  pages = {1-11},
  abstract = {Rserve is a TCP/IP server which allows other programs to use facilities of R from various languages without the need to initialize R or link to the R library. Every connection has a separate workspace and working directory. Client-side implementations are available for popular languages such as C/C++ and Java. Rserve supports remote connection, authentication and file transfer. This paper describes the Rserve concept, compares it with other techniques and illustrates its use on several practical examples.},
  booktitle = {3rd International Workshop on Distributed Statistical Computing},
  editor = {Kurt Hornik and Friedrich Leisch and Achim Zeileis},
  issn = {1609-395X},
  location = {Vienna, Austria},
  month = mar,
  url = {http://www.ci.tuwien.ac.at/Conferences/DSC-2003/},
  year = {2003}
}

@INPROCEEDINGS{Ursu:2007:CST:1763017.1763031,
  author = {Ursu, Marian F. and Cook, Jonathan J. and Zsombori, Vilmos and Zimmer, Robert and Kegel, Ian and Williams, Doug and Thomas, Maureen and Wyver, John and Mayer, Harald},
  title = {Conceiving ShapeShifting TV: a computational language for truly-interactive TV},
  pages = {96--106},
  abstract = {iTV does not yet have truly interactive programmes, that is programmes whose content adapts to the preferences of their viewers. In commercially deployed iTV productions, the programmes themselves are essentially linear and therefore non-interactive. In the research arena, the main bulk of work in computational support for interactive narratives focuses on wrapping interactions up in meaningful and interesting narratives, rather than on expanding traditional linear narratives with interactivity. This paper presents a validated approach to the development of truly interactive programmes called ShapeShifting TV. In focus is a representation language for narrative structures.},
  keywords = {authoring, automatic, editing, intelligence, interactive, itv, narrative, programme, reasoning, representation, space, storytelling, structure, testing},
  series = {EuroITV'07},
  acmid = {1763031},
  address = {Berlin, Heidelberg},
  booktitle = {Proceedings of the 5th European conference on Interactive TV: a shared experience},
  isbn = {978-3-540-72558-9},
  location = {Amsterdam, The Netherlands},
  numpages = {11},
  publisher = {Springer-Verlag},
  url = {http://portal.acm.org/citation.cfm?id=1763017.1763031},
  year = {2007}
}

@ARTICLE{Ursu:2008:ITN:1412196.1412198,
  author = {Ursu, Marian F. and Thomas, Maureen and Kegel, Ian and Williams, Doug and Tuomola, Mika and Lindstedt, Inger and Wright, Terence and Leurdijk, Andra and Zsombori, Vilmos and Sussner, Julia and Myrestam, Ulf and Hall, Nina},
  title = {Interactive {TV} narratives: Opportunities, progress, and challenges},
  volume = {4},
  month = nov,
  year = {2008},
  pages = {25:1--25:39},
  doi = {10.1145/1412196.1412198},
  abstract = {This article is motivated by the question whether television should do more than simply offer interactive services alongside (and separately from) traditional linear programs, in the context of its dominance being seriously challenged and threatened by interactive forms of screen media entertainment. It suggests: yes. Interactive narrativity, that is, the ability to interact with (and influence) stories whilst they are being told, represents one clear development path for interactive television. The capabilities of computing technology are ripe for exploring this new form of storytelling, from creation to commercial distribution. The article starts by looking at the relationship between narrativity and interactivity in the current context of screen media, and identifies clear signs of interest from certain European public broadcasters in interactive TV narratives. It then presents in detail four recent experimental interactive TV productions in the genres of drama, news, and documentary, developed in collaboration with public broadcasters, which illustrate the potential and richness of this new form of storytelling, but also highlight new technological capabilities necessary for such productions. A number of essential technological requirements are then discussed in more detail in the final part. The article suggests that the ShapeShifting Media Technology, employed in the implementation of the four productions, has made significant advances both at the technological and the creative ends in supporting the development of interactive TV narrativity, but, however, that further developments are required before being able to answer questions such as 'Would end users want such a form of screen media entertainment?' and 'Would it be effective for both end users and producers?'},
  keywords = {Interactive, computational narrativity, digital storytelling, entertainment, media, narrativity, nonlinear, screen media, shapeshifting, television},
  address = {New York, NY, USA},
  issn = {1551-6857},
  journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
  publisher = {ACM}
}

@MISC{usa:2003,
  author = {USA},
  title = {The 21st Century Strategic Plan - Revised},
  howpublished = {Government},
  month = {feb},
  year = {2003},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://www.uspto.gov/web/offices/com/strat21/}
}

@INPROCEEDINGS{uschold:1996,
  author = {M. Uschold},
  title = {Building Ontologies: Towards a Unified Methodology},
  booktitle = {Annual Conference of the British Computer Society Specialist Group in Expert System},
  month = dec,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1996}
}

@ARTICLE{uschold-gruninger:1995,
  author = {M. Uschold and M. Grüninger},
  title = {Ontologies: Principles, Methods and Applications},
  volume = {11},
  number = {2},
  month = jun,
  year = {1996},
  journal = {Knowledge Engineering Review},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{uschold-king:1995,
  author = {M. Uschold and M. King},
  title = {Towards a Methodology for Building Ontologies},
  booktitle = {Workshop on Basic Ontological Issues in Knowledge Sharing (IJCAI)},
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1995}
}

@MASTERSTHESIS{utsunomiya:2003,
  author = {Carla Tiaki Utsunomiya},
  title = {Métricas OO Aplicadas a Código Objeto Jav},
  school = {Universidade Federal do Paraná},
  year = {2003},
  address = {Curitiba, PR},
  owner = {magsilva},
  timestamp = {2010.07.16},
  type = {Dissertation}
}

@INPROCEEDINGS{utsunomiya-etal:2003,
  author = {Carla Tiaki Utsunomiya and Márcio Delamaro and Edmundo Sérgio Spoto},
  title = {Métricas OO Aplicadas a Código Objeto Java},
  booktitle = {Simpósio Brasileiro de Qualidade de Software (SBQS)},
  owner = {magsilva},
  timestamp = {2010.07.16},
  year = {2003}
}

@ARTICLE{valiente:2010,
  author = {Valiente, Maria-Cruz},
  title = {A systematic review of research on integration of ontologies with the model-driven approach},
  volume = {5},
  number = {2},
  month = may,
  year = {2010},
  pages = {134--150},
  doi = {10.1504/IJMSO.2010.033283},
  abstract = {Despite years of research, dealing with software complexity is still considered to be a challenging problem in Software Engineering. Software development is a complex process which requires the creation and management of a great deal of artefacts. In this vein, Model-Driven Engineering (MDE) has become a reference approach in software development. This paper presents a systematic review of the literature related to the integration of ontologies into the MDE approach. The objective of this paper is to provide an unbiased and up-to-date framework that helps software engineering researchers to identify new research activities and take advantage of this integration.},
  keywords = {MDA, MDE, model-driven architecture, model-driven engineering, model-driven software development, ontologies, software complexity, software engineering},
  acmid = {1805328},
  address = {Geneva, Switzerland},
  issn = {1744-2621},
  issue = {2},
  journal = {International Journal of Metadata, Semantics and Ontologies},
  numpages = {17},
  publisher = {Inderscience}
}

@ARTICLE{bergh-etal:2008,
  author = {Van den Bergh, Jan and Bruynooghe, Bert and Moons, Jan and Huypens, Steven and Hemmeryckx-Deleersnijder, Bart and Coninx, Karin},
  title = {Using high-level models for the creation of staged participatory multimedia events on {TV}},
  volume = {14},
  year = {2008},
  pages = {89-103},
  doi = {10.1007/s00530-008-0116-2},
  abstract = {Broadcasted television shows are becoming more interactive. Some broadcast TV shows allow even home viewers without professional equipment to be part of them. In this paper we present an approach that takes this concept even further. In the proposed kind of participation television viewers will not only participate in the show through interaction or video streams, but also be able to create and host their own show. The core of the presented approach consists of the use of high-level models to describe the different aspects of the television show, and a generic runtime environment. This paper discusses this type of participation television, Staged Participatory Multimedia Events, and the supporting runtime environment in more detail. It also introduces the tool and the models that are used to support graphical creation of the structure and appearance of Staged Participatory Multimedia Events.},
  affiliation = {Hasselt University, Transnationale Universiteit Limburg Expertise Centre for Digital Media, Institute for BroadBand Technology Wetenschapspark 2 3590 Diepenbeek Belgium},
  issn = {0942-4962},
  issue = {2},
  journal = {Multimedia Systems},
  keyword = {Computer Science},
  publisher = {Springer Berlin / Heidelberg}
}

@INPROCEEDINGS{bergh-etal:2006,
  author = {Van Den Bergh, Jan and Huypens, Steven and Coninx, Karin},
  title = {Towards model-driven development of staged participatory multimedia events},
  pages = {81--94},
  doi = {10.1007/978-3-540-69554-7_7},
  abstract = {The industry nowadays is showing an increasing interest towards an extended interactive television experience, called participation television. This increasing interactivity brings the creation of such television events closer to the creation of regular software as we know it for personal computers and mobile devices. In this paper we report on our work in model-driven development of one kind of such interactive television shows, staged participatory multimedia events. More specifically, this work reports on the domain-specific language we created to model these events and the generation of abstract prototypes. These interactive prototypes are built using web-languages and can be used to perform early evaluation.},
  series = {DSVIS'06},
  acmid = {1756439},
  address = {Berlin, Heidelberg},
  booktitle = {Proceedings of the 13th international conference on Interactive systems: Design, specification, and verification},
  isbn = {978-3-540-69553-0},
  location = {Dublin, Ireland},
  numpages = {14},
  publisher = {Springer-Verlag},
  year = {2007}
}

@INPROCEEDINGS{VandenEnde:2007:ICQ:1531407.1531494,
  author = {Van den Ende, Nele and Hoonhout, Jettie and Meesters, Lydia},
  title = {Issues with the construct of quality},
  pages = {261--262},
  abstract = {This paper proposes an outline for a framework that aims to give a comprehensive view of perceived video quality, including physical characteristics, perceptual attributes and cognitive factors.},
  keywords = {perceived video quality, quality research, theoretical framework},
  address = {Swinton, UK, UK},
  booktitle = {21st British HCI Group Annual Conference on People and Computers: HCI\ldots{}but not as we know it - Volume 2},
  isbn = {978-1-902505-95-4},
  location = {University of Lancaster, United Kingdom},
  publisher = {British Computer Society},
  year = {2007}
}

@MISC{VanEs:2004,
  author = {Van Es, René},
  title = {Overview of online databases with lesson plans and other learning design methods},
  month = jan,
  year = {2004},
  url = {http://hdl.handle.net/1820/102}
}

@INPROCEEDINGS{Vangenck-etal:2008,
  author = {Vangenck, Marinka and Jacobs, An and Lievens, Bram and Vanhengel, Eva and Pierson, Jo},
  title = {Does Mobile Television Challenge the Dimension of Viewing Television? An Explorative Research on Ti Place and Social Context of the Use of Mobile Television Content},
  pages = {122--127},
  doi = {10.1007/978-3-540-69478-6_15},
  abstract = {Television is one of the last media technologies to become disconnected from a fixed place like home. Media like newspaper, radio, audio recordings and computing have already been introduced in a mobile setting since some time. However with the wide spread and strong domestication of mobile devices, and the dominant character of television in households, it seems that the transition to mobile television is inevitable. Viewing patterns and behavior are strongly determined by dimensions of time, place and social context and it is exactly on those dimensions that the mobility aspect has a great impact. The question we therefore address in this paper is to what extent that relationship between mobility and these dimensions will influence the uptake and usage of mobile television.},
  keywords = {DVB-H, Maduf, Mobile television, living lab, proxy technology assessment, television experience, user practices},
  volume = {5066},
  series = {Lecture Notes on Computer Science},
  address = {Berlin, Heidelberg},
  booktitle = {European Conference on Interactive TV},
  isbn = {978-3-540-69477-9},
  location = {Salzburg, Austria},
  month = jul,
  numpages = {6},
  publisher = {Springer-Verlag},
  year = {2008}
}

@ARTICLE{Varadan95TRTS,
  author = {G. S. Varadan},
  title = {Trends in Reliability and Test Strategies},
  month = may,
  year = {1995},
  journal = ieees,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@ARTICLE{Vargo-etal:2003,
  author = {J. Vargo and J. C. Nesbit and K. Belfer and A. Archambault},
  title = {Learning object evaluation: computer-mediated collaboration and inter-reater reliability},
  volume = {25},
  number = {3},
  year = {2003},
  pages = {1-8},
  abstract = {Learning objects offer increased ability to share learning resources so that system-wide production costs can be reduced. But how can users select from a set of similar learning objects in a repository and be assured of quality? This article reviews recent developments in the establishment of learning object repositories and metadata standards, and presents a formative reliability analysis of an online, collaborative method for evaluating quality of learning objects. The method uses a 10-item Learning Object Review Instrument (LORI) within a Convergent Participation evaluation model that brings together instructional designers, media developers, and instructors. The inter-rater reliability analysis of 12 raters evaluating eight learning objects identified specific items in LORI that require further development. Overall, the collaborative process substantially increased the reliability and validity of aggregate learning object ratings. The study concludes with specific recommendations including changes to LORI items, a rater training process, and requirements for selecting an evaluation team.},
  keywords = {Learning objects, eLearning, collaborative, design, reliability, evaluation, Web-based education},
  issn = {1925-7074, 1206-212X},
  journal = {International Journal of Computers and Applications},
  lang = {en},
  publisher = {ACTA Press},
  timestamp = {2012.01.24}
}

@MASTERSTHESIS{varoto02vas,
  author = {Ane Cristina Varoto},
  title = {Visões em arquitetura de software},
  school = {IME-USP, São Paulo, SP},
  year = {2002},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@INPROCEEDINGS{Vasconcelos-etal:2008,
  author = {Francisco Herbert Lima Vasconcelos and Lucas Lopes do Amaral and Maria de Fátima Costa de Souza and José Aires de Castro Filho and Mauro Cavalcante Pequeno and Giovanni Cordeiro Barroso},
  title = {Redes de Petri Colorida no Desenvolvimento de Objetos de Aprendizagem: Uma Análise das Propriedades Comportamentais do Modelo LOCPN},
  abstract = {Este trabalho tem como principal objetivo à análise das propriedades comportamentais das Redes de Petri (RdP) com foco em sua semântica para o desenvolvimento de Objetos de Aprendizagem. Neste artigo realizou-se um experimento de validação com o modelo LOCPN, uma extensão das já tradicionais Redes de Petri Coloridas (RdPC), utilizadas para construir e observar estas propriedades e avaliar se vão ao encontro das definições iniciais. Os resultados alcançados demonstram a viabilidade do uso das propriedades comportamentais das RdPC no desenvolvimento de OA.},
  abstract-en = {This paper aims to make an analysis on the Petri Nets (RdP) behavioral properties focusing at its semantics on Learning Objects development. We use the Learning Object Colored Petri Nets, also known as LOCPN, an extension of the traditional Colored Petri Nets (RdPC), to observe those properties and see if it go towards the initial proposal. The reached results demonstrate the viability of the use of the properties behavior of RdPC in the development of OA.},
  booktitle = {Simpósio Brasileiro de Informática na Educação},
  lang = {pt},
  timestamp = {2012.01.25},
  year = {2008}
}

@BOOK{Vasconcelos:2007,
  publisher = {Laércio Vasconcelos Computação},
  year = {2007},
  author = {Laércio Vasconcelos},
  isbn = {978-85-86770-07-4},
  pages = {748},
  address = {Rio de Janeiro, RJ, } # Brazil,
  edition = {2},
  booktitle = {Hardware na prática}
}

@INPROCEEDINGS{Vazques-Ostrovskaya:2006,
  author = {Arturo Rodríguez Vázquez and Yulia A. Ostróvskaya},
  title = {Analysis of Open Technological Standards for Learning Objects},
  pages = {105-108},
  doi = {10.1109/LA-WEB.2006.5},
  abstract = {There are many technological standards related with learning objects: some are general purpose and others are specialized in e-learning. This paper presents an analysis of four open standards commonly related to learning objects: Dublin Core, ADL SCORM, IEEE LOM and IMS. The result of this comparison represented important decision making information in the context of the Voice Enhanced Learning Object Authoring Tool (VELOAT) software development project.},
  booktitle = {4th Latin America Web Congress (LA-WEB'06)},
  isbn = {0-7695-2693-4},
  location = {Cholula, Puebla, Mexico},
  month = oct,
  publisher = {IEEE},
  timestamp = {2012.01.24},
  year = {2006}
}

@ARTICLE{Veevers94RBSC,
  author = {A. Veevers and A. Marshall},
  title = {A Relationship Between Software Coverage Metrics and Reliability},
  volume = {4},
  year = {1994},
  pages = {3--8},
  journal = {Software Testing, Verification and Reliability},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{VegaOliveros-etal:2011:SAC,
  author = {Vega-Oliveros, Didier A. and Martins, Diogo S. and Pimentel, Maria da Graça C.},
  title = {Media-oriented operators for authoring interactive multimedia documents generated from capture sessions},
  pages = {1267--1272},
  doi = {10.1145/1982185.1982461},
  abstract = {Synchronous communication tools allow remote users to collaborate by exchanging text, audio, images or video messages in synchronous sessions. When generating records from captured meetings, the alternative usually adopted is to generate a linear video with the contents of the exchanged media. Such approach limits the review of the meeting for watching a video using the traditional timeline-based video controls. In scenarios in which automated tools generate interactive multimedia documents as a result of capturing a meeting, the literature reports the use of ink-based and audio-based operators that allow the identification of points of interaction in the resulting document. In this paper we extend that set of media-based operators in order to take into account user interactions with boards and videos, and to extend the audio and ink-based operators with action-based alternatives.},
  keywords = {authoring, document engineering, interactive video},
  series = {SAC},
  address = {New York, NY, USA},
  booktitle = {2011 ACM Symposium on Applied Computing},
  isbn = {978-1-4503-0113-8},
  location = {TaiChung, #Taiwan#},
  publisher = {ACM},
  year = {2011}
}

@INPROCEEDINGS{VegaOliveros-etal:2011:EuroITV,
  author = {Vega-Oliveros, Didier Augusto and Oliveira, Lílian Simão and Martins, Diogo Santana and Pimentel, Maria da Graça Campos},
  title = {Viewing by interactions: media-oriented operators for reviewing recorded sessions on tv},
  pages = {213--222},
  doi = {10.1145/2000119.2000163},
  abstract = {When generating records from captured meetings, such as video lectures or distance education activities supported by synchronous communication tools, the alternative usually adopted is to generate a linear video with the contents of the exchanged media. Such approach limits the review of the meeting, reducing it to watching a video using the traditional time-based video controls. In other scenarios, the literature reports the use of media-based operators, like ink-based and audio-based operators, that allow the indexing of points of interaction in the resulting document. In this paper we tackle the issue of automatically generating document-based browsers by means of several types of indexes captured during recording and post-production phases of the multimedia production process. These indexes are used to provide an interface focused on menu navigation to create compositions of logical operators in order to improve the access to points of interest by generating interactive timelines. Our document-centric approach tackles challenges for meeting browsers: in particular, the approach enables the efficient review of meeting recordings via a constrained device such as a TV set-top box and a remote control. In terms of evaluation, we conducted two user studies in order to verify our model. Overall, the evaluation results suggested that the approach provided a satisfactory level of usability and that users understood the proposed menu navigation approach to review the recorded sessions.},
  keywords = {authoring, document engineering, interactive video},
  series = {EuroITV},
  address = {New York, NY, USA},
  booktitle = {9th International Interactive Conference on Interactive Television},
  isbn = {978-1-4503-0602-7},
  lang = {en},
  location = {Lisbon, #Portugal#},
  publisher = {ACM},
  year = {2011}
}

@INPROCEEDINGS{Veiga-Tavares:2007,
  author = {Elba Guimarães Veiga and Tatiana Aires Tavares},
  title = {Um Modelo de Processo para o Desenvolvimento de Programas para TV Digital e Interativa baseado em Metodologias Ágeis},
  pages = {1--8},
  abstract = {Os impactos da TV Digital e Interativa (TVDI) devem alterar o modo com o qual assistimos TV e, especialmente, o modo com qual fazemos TV. Fazer TV envolverá integrar soluções de software ao programa televisivo. O presente trabalho introduz um modelo de processo para o desenvolvimento de programas de TVDI que integra atividades inerentes ao processo de produção de TV e atividades do desenvolvimento de software. Para tanto, adotamos uma estratégia baseada em metodologias ágeis, onde são identificadas práticas essenciais, etapas, stakeholders, suas responsabilidades e artefatos. Por fim, são discutidos os resultados obtidos através de um estudo de caso do modelo de processo ora proposto.},
  abstract-en = {The impacts of the Digital TV must modify the way with which we attend TV and, especially, the way we make TV. TV programs will involve software solutions integrated with televising program. The present work introduces a process model for Digital TV programs development that integrates inherent TV production activities to software development cycle. We adopt a strategy based on agile methodologies, which includes principals, phases, stakeholders, its responsibilities and artifacts. Finally, we present a study case and the obtained results.},
  booktitle = {Workshop de Desenvolvimento Rápido de Aplicações},
  location = {Porto de Galinhas, PE, #Brazil#},
  month = jun,
  year = {2007}
}

@BOOK{Veiga:2008,
  title = {Aula: gênese, dimensões, princípios e práticas},
  publisher = {Papirus},
  year = {2008},
  author = {Ilma Passos Alencastro Veiga},
  editor = {Ilma Passos Alencastro Veiga},
  isbn = {978-85-308-0859-4},
  pages = {298},
  series = {Coleção Magistério: Formação e Trabalho Pedagógico},
  address = {Campinas, SP, } # Brazil,
  edition = {1},
  booktitle = {Aula: gênese, dimensões, princípios e práticas},
  lang = {pt}
}

@BOOK{Veiga-Castanho:2000,
  title = {Pedagogia universitária: a aula em foco},
  publisher = {Papirus},
  year = {2000},
  author = {Ilma Passos Alencastro Veiga and Maria Eugênia L. M. Castanho},
  editor = {Ilma Passos Alencastro Veiga and Maria Eugênia L. M. Castanho},
  isbn = {85-308-0582-8},
  pages = {248},
  series = {Coleção Magistério: Formação e Trabalho Pedagógico},
  address = {Campinas, SP, Brazil},
  edition = {5},
  booktitle = {Pedagogia universitária: a aula em foco},
  lang = {pt}
}

@INPROCEEDINGS{Verbert-Duval:2004,
  author = {Katrien Verbert and Erik Duval},
  title = {Towards a Global Architecture for Learning Objects: A Comparative Analysis of Learning Object Content Models},
  pages = {202--208},
  abstract = {This paper investigates basic research issues that need to be addressed in order to reuse learning objects in a flexible way. We review a number of learning object content models that define learning objects and their components in a more or less precise way. A comparative analysis is made of these models in order to address questions about repurposing learning objects in a different context. The content models are mapped on our general model for learning objects to facilitate the comparison.},
  keywords = {learning objects},
  address = {Lugano, Switzerland},
  booktitle = {World Conference on Educational Multimedia, Hypermedia and Telecommunications},
  editor = {Lorenzo Cantoni and Catherine McLoughlin},
  isbn = {1-880094-53-3},
  publisher = {AACE},
  url = {http://www.editlib.org/p/12933},
  year = {2004}
}

@INPROCEEDINGS{Verdejo-etal:2006,
  author = {Verdejo, Maria Felisa and Celorrio, Carlos and Lorenzo, Emilio Julio},
  title = {Improving Learning Object Description Mechanisms to Support an Integrated Framework for Ubiquitous Learning Scenarios},
  pages = {93--97},
  doi = {10.1109/WMTE.2006.24},
  abstract = {This paper describes an approach to provide an integrated support for learners across a variety of ubiquitous learning activities, including mobile scenarios. Artefacts generated by students using tools in different devices and localizations are stored in a Learning Object Repository (LOR), enabling search, distribution and reuse of the students' results and products in other tools. As metadata is a key factor for the retrieval task, a framework adaptable to a diversity of tools and capable of auto-metadocumenting the objects in terms of the tools and LOR's context is discussed, as well as wrapping methods for automatically reify data into objects, for those tools with limited or null interoperability with the LOR.},
  series = {WMTE '06},
  address = {Washington, DC, USA},
  booktitle = {Proceedings of the Fourth IEEE International Workshop on Wireless, Mobile and Ubiquitous Technology in Education},
  isbn = {0-7695-2723-X},
  publisher = {IEEE Computer Society},
  year = {2006}
}

@INPROCEEDINGS{Vergilio93EGDT,
  author = {S. R. Verg\'{\i}lio and J. C. Maldonado and M. Jino},
  title = {Uma Estratégia para a Geração de Dados de Teste},
  pages = {307--319},
  address = {Rio de Janeiro, RJ},
  booktitle = {VII Simp\'osio Brasileiro de Engenharia de Software (SBES 93)},
  month = oct,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1993}
}

@INPROCEEDINGS{Vergilio92CNEA,
  author = {S. R. Verg\'{\i}lio and J. C. Maldonado and M. Jino},
  title = {Caminhos N\~ao-Execut\'aveis na Automa\c c\~ao das Atividades de Teste},
  pages = {343--356},
  address = {Gramado, RS},
  booktitle = {VI Simp\'osio Brasileiro de Engenharia de Software (SBES 92)},
  month = nov,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1992}
}

@PHDTHESIS{Vergilio97CRCA,
  author = {S. R. Vergilio},
  title = {Critérios Restritos: Uma Contribuição para Aprimorar a Eficácia da Atividade de Teste de Software},
  school = {DCA/FEEC/UNICAMP},
  year = {1997},
  address = {Campinas, SP},
  month = jul,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{Vermeeren:2010:UEE:1868914.1868973,
  author = {Vermeeren, Arnold P. O. S. and Law, Effie Lai-Chong and Roto, Virpi and Obrist, Marianna and Hoonhout, Jettie and Väänänen-Vainio-Mattila, Kaisa},
  title = {User experience evaluation methods: current state and development needs},
  pages = {521--530},
  doi = {10.1145/1868914.1868973},
  abstract = {The recent shift of emphasis to user experience (UX) has rendered it a central focus of product design and evaluation. A multitude of methods for UX design and evaluation exist, but a clear overview of the current state of the available UX evaluation methods is missing. This is partly due to a lack of agreement on the essential characteristics of UX. In this paper, we present the results of our multi-year effort of collecting UX evaluation methods from academia and industry with different approaches such as literature review, workshops, Special Interest Groups sessions and an online survey. We have collected 96 methods and analyzed them, among other criteria, based on the product development phase and the studied period of experience. Our analysis reveals development needs for UX evaluation methods, such as early-stage methods, methods for social and collaborative UX evaluation, establishing practicability and scientific quality, and a deeper understanding of UX.},
  keywords = {evaluation method, methodological development needs, user experience},
  address = {New York, NY, USA},
  booktitle = {Proceedings of the 6th Nordic Conference on Human-Computer Interaction: Extending Boundaries},
  isbn = {978-1-60558-934-3},
  location = {Reykjavik, Iceland},
  publisher = {ACM},
  year = {2010}
}

@INPROCEEDINGS{vernoetal:2007,
  author = {Anita Verno and Steve Cooper and Thomas J. Cortina and Barb Ericson and Bill Madden},
  title = {Developing resources to support a national computer science curriculum for K-12},
  pages = {377--378},
  doi = {10.1145/1227310.1227442},
  address = {New York, NY, USA},
  booktitle = {SIGCSE '07: Proceedings of the 38th SIGCSE technical symposium on Computer science education},
  isbn = {1-59593-361-1},
  location = {Covington, Kentucky, USA},
  owner = {magsilva},
  publisher = {ACM},
  timestamp = {2008.07.30},
  year = {2007}
}

@ARTICLE{verstegen-etal:2008,
  author = {Daniëlle Verstegen and Yvonne Barnard and Albert Pilot},
  title = {Instructional Design by Novice Designers: Two Empirical Studies},
  volume = {19},
  number = {2},
  year = {2008},
  pages = {351-383},
  abstract = {In many cases advanced instructional products, such as computer-based training, e-learning programs, simulations, and simulators are not designed by experienced instructional designers, but by novices: subject matter experts, teachers, instructors, or inexperienced designers. The literature indicates that these novices do not always have the necessary expertise about instructional design and advanced instructional products. One solution would be to insist that the design task is handed over to experienced instructional designers. Another solution is to try to support novice designers in a better way. That is the approach taken in this article. In two studies novice designers worked on a realistic, complex design problem with different kinds of support including a structured design method with guidelines, an accompanying software tool, contact with domain experts and peers (other novice designers), a division of work over time and various ways to stimulate iteration. The results of the two studies show that novice designers can indeed solve realistic complex design problems when they spend enough time on the task and are given adequate support. A framework for further discussing and researching different kinds of support for the instructional design task is proposed.},
  url = {http://editlib.org/p/22961},
  issn = {1093-023X},
  journal = {Journal of Interactive Learning Research},
  timestamp = {2008.10.02}
}

@MISC{Veryard99CBDE,
  author = {Richard Veryard},
  title = {Component-Based Development},
  howpublished = {P\'agina Web},
  month = oct,
  year = {1999},
  owner = {magsilva},
  timestamp = {2008.07.31},
  url = {http://www.users.globalnet.co.uk/~rxv/CBDmain/cbdnotions.htm}
}

@INPROCEEDINGS{Vest:2010,
  author = {Charles Marstiller Vest},
  title = {Open Education for an Open World},
  booktitle = {5th Conference of Learning International Networks Consortium (LINC 2010 Conference)},
  location = {Cambridge, MA, #USA#},
  month = may,
  note = {Keynote speech.},
  year = {2010}
}

@MISC{Vincenzi-etal:2007,
  author = {Auri Marcelo Rizzo Vicenzi and Márcio Eduardo Delamaro and Erika Nina Höhn and José Carlos Maldonado},
  title = {Functional, Control and Data Flow, and Mutation Testing: Theory and Practice},
  howpublished = {Summer course on testing},
  year = {2007},
  owner = {magsilva},
  timestamp = {2009.04.22}
}

@ARTICLE{vieira2006doa,
  author = {C. E. M. Vieira and E. R. Nicoleit},
  title = {Desenvolvimento de Objetos de Aprendizagem baseado em especificações de Normatização SCORM para o caso de suporte à aprendizagem de funções},
  year = {2006},
  journal = {UNESC. Criciúma},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@INPROCEEDINGS{Vieira98AATB,
  author = {M. E. R. Vieira and G. H. Travassos},
  title = {Apoio Automatizado ao Teste Baseado no Comportamento de Sistemas Orientados a Objetos},
  pages = {255--267},
  address = {Curitiba, PR},
  booktitle = {IX CITS -- Conferência Internacional de Tecnologia de Software: Qualidade de Software},
  month = jun,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1998}
}

@INPROCEEDINGS{vieira-etal:2005,
  author = {V. Vieira and P. Tedesco and A. C. Salgado},
  title = {Representação de Contextos em Ambientes Colaborativos Usando Ontologias},
  pages = {721--730},
  address = {Juiz de Fora, MG},
  booktitle = {Workshop Brasileiro de Tecnologias para Colaboração (WCSCW)},
  month = nov,
  note = {Joint event of Simpósio Brasileiro de Informática na Educação (SBIE)},
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {2005}
}

@TECHREPORT{Vigder96CSIS,
  author = {M. R. Vigder and W. M. Gentleman and J. Dean},
  title = {{COTS} Software Integration: State of the Art},
  institution = {National Research Council -- Software Engineering Group},
  month = jan,
  year = {1996},
  address = {Canadá},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@ARTICLE{vilas-etal:2010,
  author = {Vilas, Ana Fernández and Díaz Redondo, Rebeca P. and Pazos Arias, José J. and Cabrer, Manuel Ramos and Gil Solla, Alberto and Duque, Jorge Garcia},
  title = {Context-aware personalization services for a residential gateway based on the OSGi platform},
  volume = {37},
  month = sep,
  year = {2010},
  pages = {6538--6546},
  doi = {10.1016/j.eswa.2010.02.132},
  abstract = {Ideally, smart homes should make its inhabitants' lives more comfortable by anticipating their needs and satisfying their preferences. With this aim, we introduce an approach for context-aware personalized smart homes based on two main pillars: the Open Service Gateway Initiative (OSGi) platform and the Semantic Web philosophy. By combining both fields, we enrich the OSGi service-oriented architecture by providing a semantical conceptualization of (i) services at home, (ii) contextual information and (iii) inhabitants' preferences. This ontological structure supports reasoning about the captured behavior and inferring new knowledge.},
  keywords = {OSGi, Pervasive computing, Residential gateways, Semantic services},
  address = {Tarrytown, NY, USA},
  issn = {0957-4174},
  journal = {Expert Systems with Applications: An International Journal},
  publisher = {Pergamon}
}

@PHDTHESIS{Vilela98CPUI,
  author = {P. R. S. Vilela},
  title = {Critérios Potenciais Usos de Integração: Definição e Análise},
  school = {DCA/FEEC/UNICAMP},
  year = {1998},
  address = {Campinas, SP},
  month = apr,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@MASTERSTHESIS{Vilela94FAVT,
  author = {P. R. S. Vilela},
  title = {Uma Ferramenta para Aux\'ilio Visual ao Teste e Depura\c c\~ao de Programas},
  school = {DCA/FEE/UNICAMP},
  year = {1994},
  address = {Campinas, SP},
  month = mar,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@ARTICLE{Vilela97PGVI,
  author = {P. R. S. Vilela and J. C. Maldonado and M. Jino},
  title = {Program Graph Visualization},
  volume = {27},
  number = {11},
  month = nov,
  year = {1997},
  pages = {1245--1262},
  journal = spe,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@BOOK{villardi-oliveira:2005,
  title = {Tecnologia na educação},
  publisher = {Qualitymark},
  year = {2005},
  author = {R. Villardi and E. G. de Oliveira},
  address = {Rio de Janeiro},
  timestamp = {2008.09.15}
}

@ARTICLE{villela-etal:2005,
  author = {K. Villela and G. Santos and L. Schnaider and A. R. Rocha and G. H. Travassos},
  title = {The Use of an Enterprise Ontology to Support Knowledge Management in Software Development Environments},
  volume = {11},
  number = {2},
  month = nov,
  year = {2005},
  pages = {45--59},
  journal = {Journal of Brazilian Computer Society},
  note = {Special Issue on Ontologies Issues and Applications},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INCOLLECTION{Vincenzi-etal:2010,
  author = {Vincenzi, Auri and Delamaro, Márcio and Höhn, Erika and Maldonado, José Carlos},
  title = {Functional, Control and Data Flow, and Mutation Testing: Theory and Practice},
  booktitle = {Testing Techniques in Software Engineering},
  publisher = {Springer},
  year = {2010},
  editor = {Borba, Paulo and Cavalcanti, Ana and Sampaio, Augusto and Woodcook,Jim},
  volume = {6153},
  series = {Lecture Notes in Computer Science},
  chapter = {2},
  pages = {18--58},
  address = {Berlin, } # Germany,
  month = dec,
  abstract = {The growth of user request for higher software quality has motivated the definition of methods and techniques in order to improve the way software is developed. Several works have investigated a variety of testing criteria in an attempt to obtain a testing strategy with lower application costs and higher efficacy in detecting faults. The aim of this chapter is to present the theoretical and practical aspects related to the software testing activity. A synthesis of functional, structural, and fault-based testing techniques is presented. A comparison of the testing criteria (cost, efficacy, and strength) is also considered from the theoretical and experimental points of view.},
  doi = {10.1007/978-3-642-14335-9_2},
  isbn = {978-3-642-14334-2},
  journal = {Testing Techniques in Software Engineering}
}

@TECHREPORT{Vincenzi01UMDJ,
  author = {A. M. Vincenzi and A. S. Sim{\~a}o and J. C. Maldonado},
  title = {Using {MuDeL} to Describe {C++} and {Java} Mutant Operators},
  institution = {ICMC-USP},
  year = {2001},
  note = {(em preparação)},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@PHDTHESIS{Vincenzi00OODA,
  author = {A. M. R. Vincenzi},
  title = {Orientação a Objetos: Definição e Análise de Recursos de Teste e Validação},
  school = {ICMC-USP},
  year = {2000},
  address = {S\~ao Carlos, SP},
  month = oct,
  note = {(exame de qualificação)},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@MASTERSTHESIS{Vincenzi98SEET,
  author = {A. M. R. Vincenzi},
  title = {Subs\'idios para o Estabelecimento de Estrat\'egias de Teste Baseadas na T\'ecnica de Muta\c c\~ao},
  school = {ICMC-USP},
  year = {1998},
  address = {S\~ao Carlos, SP},
  month = nov,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{vincenzi-etal:1997,
  author = {A. M. R. Vincenzi and E. F. Barbosa and Vincenzi S. R. S. Souza and M. E. Delamaro and J. C. Maldonado},
  title = {Critério Análise de Mutantes: Estado Atual e Perspectivas},
  pages = {15--26},
  address = {Águas de Lindóia, SP},
  booktitle = {Workshop do Projeto de Validação e Teste de Sistemas de Operação},
  month = jan,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1997}
}

@TECHREPORT{GraciottoSilva-etal:2010:JaBUTi,
  author = {Auri Marcelo Rizzo Vincenzi and Márcio Eduardo Delamaro and Graciotto Silva, Marco Aurélio and José Carlos Maldonado},
  title = {{JaBUTi} -- Java Bytecode Understanding and Testing -- User's manual},
  institution = {Laboratório de Engenharia de Software -- Instituto de Ciências Matemáticas e de Computação -- Universidade de São Paulo},
  month = sep,
  year = {2010},
  address = {São Carlos, SP, } # Brazil,
  url = {http://www.labes.icmc.usp.br/~magsilva/publications/GraciottoSilva-JaBUTi.pdf},
  pages = {107}
}

@INPROCEEDINGS{Vincenzi-etal:2002,
  author = {A. M. R. Vincenzi and M. E. Delamaro and A. S. Simão and W. E. Wong and J. C. Maldonado},
  title = {{JaBÁ}: A {Java} Bytecode Analyzer},
  pages = {414--419},
  address = {Gramado, RS, } # Brazil,
  booktitle = {XVI Simpósio Brasileiro de Engenharia de Software},
  owner = {magsilva},
  timestamp = {2010.08.22},
  year = {2002}
}

@INPROCEEDINGS{vincenzi-etal:1999,
  author = {A. M. R. Vincenzi and J. C. Maldonado and E. F. Barbosa and M. E. Delamaro},
  title = {Operadores Essenciais de Interface: Um Estudo de Caso},
  pages = {373--391},
  address = {Florianópolis, SC, Brasil},
  booktitle = {Simpósio Brasileiro de Engenharia de Software},
  month = oct,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1999}
}

@INBOOK{Vincenzi05SBCR,
  chapter = {Software Baseado em Componentes: Uma Revisão sobre Teste},
  title = {Desenvolvimento Baseado em Componentes: Conceitos e Técnicas},
  publisher = {Editora Ciência Moderna Ltda.},
  year = {2005},
  author = {A. M. R. Vincenzi and J. C. Maldonado and M. E. Delamaro and E. S. Spoto and E. Wong},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INCOLLECTION{Vincenzi-etal:2003:LNCS,
  author = {A. M. R. Vincenzi and J. C. Maldonado and M. E. Delamaro and E. S. Spoto and W. E. Wong},
  title = {Component-Based Software: An Overview of Testing},
  booktitle = {Component-Based Software Quality: Methods and Techniques},
  publisher = {Springer},
  year = {2003},
  editor = {Alejandra Cechich, Mario Piattini and Antonio Vallecillo},
  volume = {2693},
  series = {Lecture Notes in Computer Science},
  chapter = {6},
  pages = {99--127},
  address = {Berlin, } # Germany,
  month = jun,
  abstract = {Component-based development makes heavy use of Object Oriented features which have motivated a major re-evaluation of software testing strategies. This chapter introduces the basic concepts of software testing focusing on the state-of-the-art and on the state-of-the-practice of this relevant area in the context of component-based software development.},
  doi = {10.1007/978-3-540-45064-1_6},
  issn = {0302-9743, 1611-3349}
}

@INPROCEEDINGS{Vincenzi01BLBG,
  author = {A. M. R. Vincenzi and E. Y. Nakagawa and J. C. Maldonado and M. E. Delamaro and R. A. F. Romero},
  title = {Bayesian-Learning Based Guidelines to Determine Equivalente Mutants},
  pages = {180--187},
  address = {Buenos Aires, Argentina},
  booktitle = {13th International Conference on Software Engineering \& Knowledge Engineering -- SEKE'2001},
  month = jun,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {2001}
}

@INPROCEEDINGS{Vincenzi-etal:2003:SBES,
  author = {A. M. R. Vincenzi and W. E. Wong and M. E. Delamaro and J. C. Maldonado},
  title = {{JaBUTi}: A Coverage Analysis Tool for Java Programs},
  pages = {79-84},
  abstract = {This paper describes a coverage testing tool, named JaBUTi, designed to test Java programs and Java-based components. From the Java bytecode, the tool extracts intra-method control-flow and data-flow testing requirements that can be used to generate or to assess the quality of a given test set. Many existing control-flow and data-flow testing tools require the source code to perform their activities. However, this approach may not be feasible in some situations, e.g., for component-based software development as some of the components can be commercial off-the-shelf products or developed by a third party, and therefore the corresponding source code is not always available. For programs written in Java, using the object code (bytecode) one can overcome this cronstraint.},
  address = {Manaus, AM, Brasil},
  booktitle = {Sessão de Ferramentas do Simpósio Brasileiro de Engenharia de Software (SBES)},
  month = oct,
  owner = {magsilva},
  publisher = {SBC},
  timestamp = {2008.07.30},
  url = {http://ccsl.icmc.usp.br/projects/jabuti-0},
  year = {2003}
}

@BOOK{Vita:1964,
  title = {Introdução à filosofia},
  publisher = {Herder},
  year = {1964},
  author = {Luís Washington Vita},
  pages = {264},
  address = {São Paulo, SP, Brazil},
  edition = {2}
}

@MISC{software:hammurapi,
  author = {Pavel Vlasov and others},
  title = {Hammurapi},
  howpublished = {Programa de Computador},
  month = jul,
  year = {2004},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://www.hammurapi.org, http://sourceforge.net/projects/hammurapi/}
}

@ARTICLE{Voas91PWFC,
  author = {J. Voas and L. Morell and K. Miller},
  title = {Predicting Where Faults Can Hide from Testing},
  volume = {8},
  number = {2},
  month = mar,
  year = {1991},
  pages = {41--48},
  journal = ieees,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@ARTICLE{vossen-westerkamp:2003,
  author = {Vossen, G. and Westerkamp, P.},
  title = {E-learning as a Web service},
  year = {2003},
  pages = {242-249},
  abstract = { E-learning has been a topic of increasing interest in recent years. It is often perceived as a group effort, where content authors, instructional designers, multimedia technicians, teachers, trainers, database administrators, and people from various other areas of expertise come together in order to serve a community of learners. In a typical e-learning scenario, many of the activities can be perceived and modeled as processes and consequently be executed as workflows; there are even prototypical system developments that are experimenting with this approach. On the other hand, there are increasingly many activities, which aim at providing services of any kind on the Web; these can occur as business-to-business or as business-to-consumer services and are generally subsumed under the term Web services. In this paper we suggest to combine the areas of e-learning and Web services, by providing electronic learning offerings as (individual or collections of) Web services as well. We elaborate on this by showing how content providers and content consumers (i.e., learners) can communicate appropriately through a Web service platform with its common description, publication, and retrieval functionalities. Finally, we indicate how a corresponding system can be realized.},
  issn = {1098-8068},
  journal = {International Database Engineering and Applications Symposium},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@INPROCEEDINGS{Vrba-etal:2006,
  author = {Vrba, Vit and Cvrk, Lubomir and Sykora, Martin},
  title = {Framework for digital TV applications},
  pages = {184--184},
  doi = {10.1109/ICNICONSMCL.2006.102},
  abstract = {A crucial problem of recent applications requiring a DTV-based solution is that they are designed to solve one specific problem. The aim of this paper is to propose a universal framework for DTV applications that will use sophisticated methods of object sharing, data abstraction and template exploitation. This framework should realize all repeating programmer operations automatically - e.g. template based output, data transfer and validation, multilanguage support, security, authorization, etc. The system should realize maximum tasks (generating output) automatically without additional programming by content developer.},
  booktitle = {International Conference on Mobile Communications and Learning Technologies},
  isbn = {0-7695-2552-0},
  lang = {en},
  publisher = {IEEE},
  year = {2006}
}

@BOOK{Vygotsky:1978,
  title = {Mind in Society: The Development of Higher Psychological Processes},
  publisher = {Harvard University Press},
  year = {1978},
  author = {Lev S. Vygotsky},
  editor = {Michael Cole and Vera John-Steiner and Sylvia Scribner and Ellen Souberman},
  isbn = {978-0674576292},
  pages = {159},
  address = {Cambridge, MA, } # USA,
  edition = {14},
  booktitle = {Mind in Society: The Development of Higher Psychological Processes}
}

@MISC{XML,
  author = {W3C},
  title = {{Extensible Markup Language (XML)}},
  month = {January},
  year = {2008},
  owner = {magsilva},
  timestamp = {2008.02.25},
  url = {http://www.w3.org/XML}
}

@MISC{standard:ws-cdl,
  author = {{W3C}},
  title = {Web Services Choreography Description Language Version 1.0},
  howpublished = {Padrão},
  month = nov,
  year = {2005},
  timestamp = {2009.02.05},
  url = {http://www.w3.org/TR/ws-cdl-10/}
}

@MISC{SOAP,
  author = {W3C},
  title = {{SOAP Version 1.2 Part 1: Messaging Framework (Second Edition)}},
  year = {2004},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://www.w3.org/TR/soap12-part1/}
}

@MISC{standard:owl-s,
  author = {{W3C}},
  title = {OWL-S: Semantic Markup for Web Services},
  howpublished = {Padrão},
  month = nov,
  year = {2004},
  timestamp = {2009.02.05},
  url = {http://www.ai.sri.com/daml/services/owl-s/1.2/}
}

@MISC{standard:wsci,
  author = {{W3C}},
  title = {Web Service Choreography Interface (WSCI) 1.0},
  howpublished = {Padrão},
  month = aug,
  year = {2002},
  timestamp = {2009.02.05},
  url = {http://www.w3.org/TR/wsci/}
}

@MISC{webservices,
  author = {W3C},
  title = {Web Services},
  month = jan,
  year = {2002},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://www.w3.org/2002/ws/}
}

@MISC{w3c:1994,
  author = {W3C},
  title = {World Wide Web Consortium},
  year = {1994},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://www.w3c.org}
}

@ARTICLE{Wagner:2002,
  author = {Ellen D. Wagner},
  title = {Steps to Creating a Content Strategy for your Organization},
  month = oct,
  year = {2002},
  pages = {1-9},
  journal = {Learning Solutions e-Magazine},
  publisher = {eLearning Guild},
  timestamp = {2012.01.20}
}

@MISC{Wagner-Braga:2001,
  author = {Helcio Wagner and Vladimir Braga},
  title = {Introdução à Estelle},
  howpublished = {Tutorial},
  month = may,
  year = {2001},
  lang = {pt},
  url = {http://www.ic.unicamp.br/~eliane/Cursos/MO409/artigos2001/artigoestelle.ps}
}

@INPROCEEDINGS{Wah00TICE,
  author = {K. S. How Tai Wah},
  title = {Theoretical Insights into the Coupling Effect},
  pages = {84--92},
  address = {San Jose, CA},
  booktitle = {Mutation 2000 Symposium},
  month = oct,
  owner = {magsilva},
  publisher = {Kluwer Academic Publishers},
  timestamp = {2008.07.31},
  year = {2000}
}

@INPROCEEDINGS{waldo-etal:1997,
  author = {Waldo, Jim and Wyant, Geoff and Wollrath, Ann and Kendall, Samuel C.},
  title = {A Note on Distributed Computing},
  pages = {49--64},
  doi = {10.1007/3-540-62852-5_6},
  volume = {1222},
  series = {Lecture Notes on Computer Science},
  acmid = {747342},
  address = {London, UK},
  booktitle = {International Workshop on Mobile Object Systems},
  editor = {Jan Vitek and Christian Tschudin},
  isbn = {3-540-62852-5},
  issn = {0302-9743},
  location = {Linz, Austria},
  month = jul,
  numpages = {16},
  publisher = {Springer},
  year = {1996}
}

@MISC{software:freetts,
  author = {Willie Walker and Paul Lamere and Philip Kwok},
  title = {FreeTTS},
  howpublished = {Programa de computador},
  month = {nov},
  year = {2001},
  owner = {magsilva},
  timestamp = {2007.08.13},
  url = {http://freetts.sourceforge.net/}
}

@MISC{wallingford:1998,
  author = {Eugene Wallingford},
  title = {Elementary Patterns and their Role in Instruction: A Report on the ChiliPLoP'98 Hot Topic Workshop},
  howpublished = {OOPSLA'98 Educators Symposium Notes},
  month = jul,
  year = {1998},
  owner = {magsilva},
  timestamp = {2007.09.12},
  url = {http://cns2.uni.edu/~wallingf/patterns/elementary/chiliplop98/summary.html}
}

@MISC{software:xstream,
  author = {Joe Walnes and Mauro Talevi and Jason van Zyl and Nat Pryce and Dan North},
  title = {XStream},
  howpublished = {Programa de Computador},
  month = apr,
  year = {2005},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://xstream.codehaus.org/}
}

@ARTICLE{walrad:2002,
  author = {Chuck Walrad and Darrel Strom},
  title = {The Importance of Branching Models in SCM},
  month = nov,
  year = {2002},
  pages = {31-38},
  journal = {IEEE Computer},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@INBOOK{wang-etal:2006,
  pages = {633-641},
  title = {Automatic Keyphrases Extraction from Document Using Neural Network},
  publisher = {Springer},
  year = {2006},
  editor = {Yeung, Daniel and Liu, Zhi-Qiang and Wang, Xi-Zhao and Yan, Hong},
  author = {Wang, Jiabing and Peng, Hong and Hu, Jing-song},
  volume = {3930},
  series = {Lecture Notes in Computer Science},
  note = {4th International Conference on Advances in Machine Learning and Cybernetics (ICMLC 2005), Guangzhou, China, August, 2005.},
  abstract = {Keyphrase extraction is a task with many applications in information retrieval, text mining, and natural language processing. In this paper, a keyphrase extraction approach based on neural network is proposed. To determine whether a phrase is a keyphrase, the following features of a phrase in a given document are adopted: its term frequency and inverted document frequency, whether to appear in the title or headings (subheadings) of the given document, and its frequency appearing in the paragraphs of the given document. The algorithm is evaluated by the standard information retrieval metrics of precision and recall, and human assessment.},
  affiliation = {School of Computer Science and Engineering, South China University of Technology, Guangzhou, 510641 China},
  booktitle = {Advances in Machine Learning and Cybernetics},
  doi = {10.1007/11739685_66}
}

@INPROCEEDINGS{wang:2001,
  author = {Qing Wang and Xufang Lai},
  title = {Requirements Management for the Incremental Development Model},
  pages = {295-301},
  doi = {10.1109/APAQS.2001.990034},
  booktitle = {Asia-Pacific Conference on Quality Software},
  month = {dec},
  owner = {Marco Aurélio Graciotto Silva},
  publisher = {IEEE},
  timestamp = {2008.07.30},
  year = {2001}
}

@INPROCEEDINGS{Warren-Mosteller:1993,
  author = {K. S. Warren and F. Mosteller},
  title = {Doing More Good Than Harm -- The Evaluation of Health Care Interventions},
  booktitle = {New York Academy of Sciences},
  year = {1993}
}

@ARTICLE{wasserman:1996,
  author = {Anthony I. Wasserman},
  title = {Toward a Discipline of Software Engineering},
  month = nov,
  year = {1996},
  pages = {23-31},
  journal = {IEEE Software},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@ARTICLE{webber2002tlm,
  author = {Webber, C. and Pesty, S.},
  title = {{A two-level multi-agent architecture for a distance learning environment}},
  year = {2002},
  pages = {26--38},
  journal = {ITS},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@BOOK{weber:1999,
  title = {Qualidade e produtividade de software},
  publisher = {Makron Books},
  year = {1999},
  author = {K. C. Weber and A. R. C. Rocha},
  note = {Programa Brasileiro da Qualidade e Produtividade},
  owner = {magsilva},
  timestamp = {2006.08.22}
}

@ARTICLE{webster:1988,
  author = {Webster, D.E.},
  title = {Mapping the design information representation terrain},
  volume = {21},
  number = {12},
  month = dec,
  year = {1988},
  pages = {8-23},
  journal = {IEEE Computer},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@ARTICLE{weiser:1982,
  author = {Mark Weiser},
  title = {Programmers use slices when debugging},
  volume = {25},
  number = {7},
  year = {1982},
  pages = {446--452},
  doi = {10.1145/358557.358577},
  address = {New York, NY, USA},
  eid = jul,
  issn = {0001-0782},
  journal = {Communications of the ACM},
  publisher = {ACM}
}

@INPROCEEDINGS{weiser:1981,
  author = {Mark Weiser},
  title = {Program slicing},
  pages = {439--449},
  address = {San Diego, California, United States},
  booktitle = {International Conference on Software Engineering (ICSE)},
  isbn = {0-89791-146-6},
  location = {San Diego, California, United States},
  publisher = {IEEE Press},
  year = {1981}
}

@PHDTHESIS{weiser:1979,
  author = {Mark David Weiser},
  title = {Program slices: formal, psychological, and practical investigations of an automatic program abstraction method},
  school = {University of Michigan},
  year = {1979},
  address = {Ann Arbor, MI, USA},
  month = apr,
  url = {http://proquest.umi.com/pqdlink?did=751590211&Fmt=7&clientId=61611&RQT=309&VName=PQD},
  order_no = {AAI8007856},
  publisher = {University of Michigan},
  type = {Dissertation}
}

@BOOK{weiss-lai:1999,
  title = {Software product-line engineering: a family-based software development process},
  publisher = {Addison-Wesley Longman},
  year = {1999},
  author = {David M. Weiss and Chi Tau Robert Lai},
  pages = {426},
  owner = {magsilva},
  timestamp = {2010.07.12}
}

@BOOK{weiss:1999,
  title = {Multiagent Systems: A Modern Approach to Distributed Artificial Intelligence},
  publisher = {MIT Press},
  year = {1999},
  author = {Weiss, G.},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@BOOK{weiss:1999:cpp,
  title = {Data Structures and Algorithm Analysis in {C}++},
  publisher = {Addison-Wesley},
  year = {1999},
  author = {M. A. Weiss},
  edition = {Segunda Edi\c c\~ao},
  owner = {magsilva},
  timestamp = {2008.07.31},
  url = {http://www.cs.fiu.edu/~weiss/}
}

@BOOK{weiss:1999:java,
  title = {Data Structures and Algorithm Analysis in {J}ava},
  publisher = {Addison-Wesley},
  year = {1999},
  author = {M. A. Weiss},
  owner = {magsilva},
  timestamp = {2008.07.31},
  url = {http://www.cs.fiu.edu/~weiss/}
}

@BOOK{weiss:1997:c,
  title = {Data Structures and Algorithm Analysis in {C}},
  publisher = {Addison-Wesley},
  year = {1997},
  author = {M. A. Weiss},
  edition = {2},
  note = {http://www.cs.fiu.edu/~weiss/},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@MISC{software:bugzilla,
  author = {Terry Weissman and others},
  title = {Bugzilla},
  howpublished = {Programa de Computador},
  year = {1998},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://www.bugzilla.org}
}

@RESEARCH-PROJECT{project:ouldi,
  title = {Open University Learning Design Initiative},
  author = {Martin Weller and Simon Cross and Grainne Conole and others},
  institution = {Open University},
  funding = {{JISC} e-Learning programme},
  month = mar,
  year = {2008},
  duration = {26},
  url = {http://www.open.ac.uk/blogs/OULDI/}
}

@MISC{werner-braga:2000,
  author = {C. M.L. Werner and R. M.M. Braga},
  title = {Desenvolvimento Baseado em Componentes},
  howpublished = {Minicurso apresentado no SBES 2000 -- Simpósio Brasileiro de Engenharia de Software},
  month = oct,
  year = {2000},
  address = {João Pessoa, PB},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@ARTICLE{weyers-etal:2011,
  author = {Weyers, Benjamin and Luther, Wolfram and Baloian, Nelson},
  title = {Interface creation and redesign techniques in collaborative learning scenarios},
  volume = {27},
  month = jan,
  year = {2011},
  pages = {127--138},
  doi = {10.1016/j.future.2010.05.001},
  abstract = {User interfaces are redesigned for various purposes, like adapting interfaces or meeting new requirements during software creation processes. In the context of learning systems, the aim of interface redesign is to let the student creates his or her own interface corresponding to the abstract concept to be learned, which is reflected in the interface designed. In this article we present an approach to interface redesign in a cooperative learning scenario for cryptographic protocols. We describe an iterative workflow using two different pieces of software for the creation and redesign of interfaces and distributed simulation and evaluate this approach.},
  keywords = {Concept keyboard, Cooperative learning, Distributed learning, Interface redesign, Iterative interface creation},
  acmid = {1857386},
  address = {Amsterdam, Netherlands},
  issn = {0167-739X},
  issue = {1},
  journal = {Future Generation Computer Systems},
  numpages = {12},
  publisher = {Elsevier Science}
}

@ARTICLE{weyuker:1998,
  author = {E. J. Weyuker},
  title = {Testing Component-Based Software: A Cautionary Tale},
  volume = {15},
  number = {5},
  month = sep # {/} # oct,
  year = {1998},
  pages = {54--59},
  journal = ieees,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@ARTICLE{weyuker:1990,
  author = {E. J. Weyuker},
  title = {The Cost of Data Flow Testing: an Empirical Study},
  volume = {16},
  number = {2},
  month = feb,
  year = {1990},
  pages = {121--128},
  doi = {10.1109/32.44376},
  abstract = {A family of test data adequacy criteria employing data-flow information was previously proposed, and a theoretical complexity analysis was performed. The author describes an empirical study to determine the actual cost of using these criteria. The aim is to establish the practical usefulness of these criteria in testing software and provide a basis for predicting the amount of testing needed for a given program. The first goal of the study is to confirm the belief that the family of software testing criteria considered is practical to use. An attempt is made to show that even as the program size increases, the amount of testing, expressed in terms of the number of test cases sufficient to satisfy a given criterion, remains modest. Several ways of evaluating this hypothesis are explored. The second goal is to provide the prospective user of these criteria with a way of predicting the number of test cases that will be needed to satisfy a given criterion for a given program. This provides testers with a basis for selecting the most comprehensive criterion that they can expect to satisfy. Several plausible bases for such a prediction are considered.},
  journal = {IEEE Transactions on Software Engineering},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@ARTICLE{weyuker:1988,
  author = {E. J. Weyuker},
  title = {The Evaluation of Program-Based Software Teste Data Adequacy Criteria},
  volume = {31},
  number = {6},
  month = jun,
  year = {1988},
  pages = {668--675},
  journal = comacm,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@ARTICLE{weyuker:1986,
  author = {E. J. Weyuker},
  title = {Axiomatizing Software Testing Data Adequacy},
  volume = {12},
  number = {12},
  month = dec,
  year = {1986},
  pages = {1128--1138},
  journal = ieeese,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@ARTICLE{weyuker:1984,
  author = {E. J. Weyuker},
  title = {The Complexity of Data Flow for Test Data Selection},
  volume = {19},
  number = {2},
  month = aug,
  year = {1984},
  pages = {103--109},
  journal = {Information Processing Letters},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@ARTICLE{weyuker-etal:1994,
  author = {E. J. Weyuker and T. Goradia and A. Singh },
  title = {Automatically Generating Test Data from a Boolean Specification},
  volume = {20},
  number = {5},
  month = may,
  year = {1994},
  pages = {353--363},
  journal = ieeese,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@ARTICLE{weyuker-jeng:1991,
  author = {E. J. Weyuker and B. Jeng},
  title = {Analyzing Partition Testing Strategies},
  volume = {17},
  number = {7},
  month = jul,
  year = {1991},
  pages = {703--711},
  journal = ieeese,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@ARTICLE{weyuker-ostrand:1980,
  author = {E. J. Weyuker and T. Ostrand},
  title = {Theory of Program Testing and the Application of Revealing Subdomains},
  volume = {6},
  month = jun,
  year = {1980},
  journal = ieeese,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{weyuker-etal:1991,
  author = {E. J. Weyuker and S. N. Weiss and R. G. Hamlet},
  title = {Comparison of Program Testing Strategies},
  pages = {154--164},
  address = {Victoria, British Columbia, Canada},
  booktitle = {4th Symposium on Software Testing, Analysis and Verification},
  owner = {magsilva},
  publisher = {ACM Press},
  timestamp = {2008.07.31},
  year = {1991}
}

@ARTICLE{Wheatley-Basapur:2011,
  author = {D.J. Wheatley and S. Basapur},
  title = {Concept evaluation and usability testing of a TV based video communications system},
  volume = {2},
  number = {3},
  year = {2011},
  pages = {163 - 173},
  doi = {10.1016/j.entcom.2011.03.003},
  abstract = {Attempts to successfully commercialize video telephony have thus far failed, however technical developments in broadband networks, video encoding, imaging and processing are now making TV based video telephony both technically and commercially viable. This paper describes two empirical studies carried out to evaluate such a concept. A first study assessed the user value of TV based video telephony by means of a comparative evaluation against a PC/webcam solution and face to face communication using subject dyads and structured audio/visual tasks. Significant differences were found between all three conditions; while pre- and post-test Likert scales indicated that ratings for the TV condition increased post-experience and were not significantly different from the face to face condition ratings. Two prototype systems were then developed which enabled TV to TV video telephony calls and a second study was carried out to evaluate in greater depth, the usability and acceptability of the feature sets and their respective ease of access. The studies indicated that TV-based video communications does have intrinsic user value and also has the potential to approach the richness of face to face communications, but that certain control and privacy functions need to be implemented in the UI before this can be fully realized. Such functions included; control over the callers with whom video would be used, control over who could access the videotelephony system, control over the recording of calls, the ability to turn off the self-view and, for total privacy, physical occlusion of the camera when not in use.},
  keywords = {Interactive TV, User evaluation, Usability testing, NextGen TV},
  issn = {1875-9521},
  journal = {Entertainment Computing}
}

@MISC{software:sloccount,
  author = {David A. Wheeler},
  title = {SLOCCount},
  howpublished = {Programa de Computador},
  month = jan,
  year = {2001},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://www.dwheeler.com/sloccount/}
}

@ARTICLE{white-leung:1994,
  author = {L. J. White and H. K. N. Leung},
  title = {Integration Testing},
  year = {1994},
  pages = {573--577},
  journal = {Encyclopedia of Software Engineering},
  owner = {magsilva},
  publisher = {John Wiley \& Sons},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{white-sahay:1985,
  author = {L. J. White and P. N. Sahay},
  title = {A Computer System for Generating Test Data Using the Domain Strategy},
  pages = {38-45},
  address = {San Francisco, CA},
  booktitle = {Softfair II},
  month = dec,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1985}
}

@ARTICLE{whitehead:1998,
  author = {E. J. Whitehead and M. Wiggins},
  title = {WebDAV: IETF Standard for Collaborative Authoring on the Web},
  year = {1998},
  pages = {34-40},
  journal = {IEEE Internet Computing},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@MISC{whitehead:2001:2,
  author = {Jim Whitehead},
  title = {DeltaV: Adding Versioning to the Web},
  howpublished = {Tutorial},
  month = may,
  year = {2000},
  address = {Hong Kong},
  booktitle = {Tenth International World Wide Web Conference},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://www.webdav.org/deltav/WWW10/deltav-intro.htm}
}

@BOOK{whitehead:2002,
  title = {Component-Based Development: Principles and Planning for Business Systems},
  publisher = {Addison-Wesley Professional},
  year = {2002},
  author = {Katharine Whitehead},
  edition = {1},
  month = jun,
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@BOOK{wieringa:1995,
  title = {Requirements Engineering: Framework for understanding},
  publisher = {Wiley},
  year = {1995},
  author = {R. J. Wieringa},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@MISC{software:wikipedia,
  author = {{Wikimedia Foundation}},
  title = {Wikipedia},
  howpublished = {Programa de computador},
  month = jan,
  year = {2001},
  owner = {magsilva},
  timestamp = {2008.04.03},
  url = {http://www.wikipedia.org}
}

@MISC{wikipedia:firstwebsearchsite,
  author = {Wikipedia},
  title = {Search engine},
  howpublished = {Artigo em enciclopédia},
  month = {jul},
  year = {2006},
  owner = {magsilva},
  timestamp = {2006.07.26}
}

@TECHREPORT{Wiley:2007,
  author = {David Wiley},
  title = {On the sustainability of open educational resource initiatives in higher education},
  institution = {OECD's Centre for Educational Research and Innovation (CERI)},
  year = {2007},
  address = {Paris, } # France,
  url = {http://www.oecd.org/dataoecd/33/9/38645447.pdf},
  pages = {21}
}

@PHDTHESIS{Wiley:2000,
  author = {David A. Wiley},
  title = {Learning Object Design and Sequencing Theory},
  school = {Brigham Young University},
  year = {2000},
  address = {Provo, Utah, } # USA,
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@ARTICLE{Wiley-etal:2004,
  author = {David Wiley and Sandie Waters and Deonne Dawson and Brent Lambert and Matthew Barclay and David Wade and Laurie Nelson},
  title = {Overcoming the Limitations of Learning Objects},
  volume = {13},
  number = {4},
  month = oct,
  year = {2004},
  pages = {507-521},
  abstract = { There are a number of issues that face individuals who would use learning objects for instructional purposes. These issues include problems with decontextualization... },
  url = { http://go.editlib.org/p/6586 },
  address = {Norfolk, VA, USA},
  issn = {1055-8896},
  journal = {Journal of Educational Multimedia and Hypermedia},
  publisher = {AACE}
}

@INPROCEEDINGS{wilfinger-etal:2009,
  author = {Wilfinger, David and Pirker, Michael and Bernhaupt, Regina and Tscheligi, Manfred},
  title = {Evaluating and investigating an iTV interaction concept in the field},
  pages = {175--178},
  doi = {10.1145/1542084.1542119},
  abstract = {This work presents results from an evaluation in the field using a prototype iTV system. Besides standard iTV services (e.g. EPG), this iTV system offers a number of privacy and personalization functions combined with a fingerprint reader in the remote control. The goal was to research how the iTV system would perform in terms of user experience and usability in the field and how users perceive security and personalization functions in the original context of use. Main findings the study showed unexpected perceptions concerning privacy and security issues by users in the field and confirmed good results on usability and user experience gained in prior laboratory studies.},
  keywords = {context home, field study, interactivetv, prototype},
  series = {EuroITV '09},
  acmid = {1542119},
  address = {New York, NY, USA},
  booktitle = {Proceedings of the seventh european conference on European interactive television conference},
  isbn = {978-1-60558-340-2},
  location = {Leuven, Belgium},
  numpages = {4},
  publisher = {ACM},
  year = {2009}
}

@BOOK{wilkesetal:1951,
  title = {The Preparation of Programs for an Electronic Digital Computer, with Special Reference to the EDSAC and the Use of a Library of Subroutines},
  publisher = {Addison-Wesley},
  year = {1951},
  author = {Maurice V. Wilkes and David J. Wheeler and Stanley Gill},
  isbn = {0262231182},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@INPROCEEDINGS{wille-etal:2004,
  author = {C. Wille and R. R. Dumke and A. Abran and J. M. Desharnais},
  title = {E-Learning Infrastructure for Software Engineering Education: Steps in Ontology Modeling for SWEBOK},
  address = {Innsbruck, Austria},
  booktitle = {IASTED International Conference - Software Engineering},
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {2004}
}

@MISC{dom2style:2000,
  author = {Chris Wilson and Philippe Le Hégaret and Vidur Apparao},
  title = {Document Object Model (DOM) Level 2 Style Specification},
  howpublished = {W3C Recommendation},
  month = nov,
  year = {2000},
  comment = {24/05/2005},
  file = {Document Object Model (DOM) Level 2 Style Specification.pdf:Document Object Model (DOM) Level 2 Style Specification.pdf:PDF},
  owner = {magsilva},
  timestamp = {2008.07.30},
  url = {http://www.w3.org/TR/DOM-Level-2-Style/}
}

@INPROCEEDINGS{Wilson-etal:2011,
  author = {Tina Wilson and Patrick McAndrew and Andreas Meiszner},
  title = {Sharing software engineering resources and open source software across entities},
  pages = {1--5},
  abstract = {In the last 10 years Open Educational Resources (OER) have become established to provide free access to content. The Open Source movement has a well developed approach to software construction that has produced many successes. As open learning develops it is important to explore how OER and Open Source can work together, and learn from each other. In the OpenSE project an international consortium developed a learning framework to offer open courses based on OER that link learners with internship opportunities within open source projects, therefore allowing for authentic and deeper learning and connecting the motivation for learning with the enthusiasm for open software. This paper reviews the approach as a next stage in OER to offer both free and paid for learning opportunities. The OpenSE courses operate across formal and informal boundaries and provide an exemplar for a new approach to teaching particularly suited to information and computer science.},
  keywords = {Open Education Resources, OER, Open Source, Software Engineering, Formal and Informal learning},
  booktitle = {12th Annual Conference of Higher Education Academy Subject Centre for Information and Computer Science},
  location = {Belfast, #UK#},
  month = aug,
  publisher = {Higher Education Academy},
  year = {2011}
}

@ARTICLE{Winckler:2009,
  author = {Marco Winckler},
  title = {Opiniões - {Brasil} afora},
  number = {11},
  month = oct # {-} # dec,
  year = {2009},
  pages = {17},
  journal = {Computação Brasil},
  owner = {magsilva},
  timestamp = {2010.09.13}
}

@BOOK{WirfsBrock-etal:1990,
  publisher = {Prentice Hall},
  year = {1990},
  author = {Rebecca Wirfs-Brock and Brian Wilkerson and Lauren Wiener},
  isbn = {978-0136298250},
  pages = {341},
  address = USA,
  edition = {1},
  booktitle = {Designing Object-Oriented Software},
  timestamp = {2013-11-12}
}

@BOOK{Wirth:2004,
  title = {Algorithms and Data Structures},
  year = {2004},
  author = {Niklaus Wirth},
  edition = {Oberon edition},
  month = aug,
  url = {http://www.inf.ethz.ch/personal/wirth/books/AD.pdf}
}

@BOOK{Wirth:1978,
  title = {Algorithms + Data Structures = Programs},
  publisher = {Prentice Hall},
  year = {1975},
  author = {Wirth, Niklaus},
  isbn = {0-13-022418-9},
  pages = {366},
  address = {Upper Saddle River, NJ, USA},
  abstract = {Algorithms + Data Structures = Programs presents a very systematic and scientific approach to the fundamental techniques associated with data composition and program development. The basic principles covered here are applicable to many scientific and engineering endeavors. Contents include chapters devoted to fundamental data structures, internal and external sorting, recursive algorithms, dynamic data structures (recursive data types, pointers, list structures, tree structures, optimal search trees, multiway trees, and key transformations), and language structures and compiling (language definition and analysis, syntax graphs, parser and translator/construction). Among the features: covers important basic techniques of program and data structuring and demonstrates their suitability to a wide variety of practical applications; develops programs in step-wise fashion, and expresses them in a well-structured, detailed, and unambiguous presentation; stresses the importance of performance analysis and demonstrates how algorithm selection and refinement are used most effectively in program design; presents illustrative programs that were run and thoroughly tested before their inclusion here; practically oriented, employs the minimum required mathematical formalism.},
  booktitle = {Algorithms + Data Structures = Programs}
}

@BOOK{witten-etal:1999,
  title = {Managing Gigabytes: Compressing and Indexing Documents and Images},
  publisher = {Morgan Kaufmann},
  year = {1999},
  author = {Ian H. Witten and Alistair Moffat and Timothy C. Bell},
  pages = {550},
  series = {The Morgan Kaufmann Series in Multimedia Information and Systems},
  edition = {2},
  month = may
}

@INBOOK{Wohlin-etal:2003,
  chapter = {Empirical Research Methods in Software Engineering},
  pages = {7-23},
  title = {Empirical Methods and Studies in Software Engineering -- Experiences from ESERNET},
  publisher = {Springer-Verlag Berlin Heidelbert},
  year = {2003},
  editor = {Reider Conradi and Alf Inge Wang},
  author = {Claes Wohlin and Martin Höst and Kennet Henningsson},
  volume = {2765},
  series = {Lecture Notes in Computer Science},
  address = {Germany},
  owner = {magsilva},
  timestamp = {2010.08.09}
}

@BOOK{Wohlin-etal:2000,
  title = {Experimentation in Software Engineering: An Introduction},
  publisher = {Kluwer Academic Publishers},
  year = {2000},
  author = {Claes Wohlin and Per Runeson and Martin Höst and Magnus C. Ohlsson and Björn Regnell and Anders Wesslén},
  pages = {204},
  series = {The Kluwer International Series in Software Engineering},
  address = {Sweden},
  edition = {1},
  owner = {magsilva},
  timestamp = {2010.08.10}
}

@ARTICLE{wolff:1994,
  author = {Karl Erich Wolff},
  title = {A frist course in Formal Concept Analysis},
  volume = {4},
  year = {1994},
  pages = {429-438},
  url = {http://www.fbmn.fh-darmstadt.de/home/wolff/Publikationen/A_First_Course_in_Formal_Concept_Analysis.pdf},
  booktitle = {StatSoft'93},
  editor = {Gustav Fischer Verlag},
  journal = {Advances in Statistical Software}
}

@INPROCEEDINGS{Wong97RCRT,
  author = {W.E. Wong and J.C. Maldonado and M.E. Delamaro},
  title = {Reducing the Cost of Regression Test by Using Selective Mutation},
  pages = {11--13},
  address = {Curitiba, PR},
  booktitle = {8th CITS -- International Conference on Software Technology},
  month = jun,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1997}
}

@INPROCEEDINGS{wong-etal:1997,
  author = {W.E. Wong and J.C. Maldonado and M.E. Delamaro and S.R.S. Souza},
  title = {A Comparison of Selective Mutation in {C} and FORTRAN},
  pages = {71--80},
  address = {Águas de Lindóia, SP},
  booktitle = {Workshop do Projeto Validação e Teste de Sistemas de Operação},
  month = jan,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1997}
}

@ARTICLE{Wong-et,
  author = {W.E. Wong and T. Sugeta and J. J. Li and J. C. Maldonado},
  title = {Coverage Testing Software Architectural Design in {SDL}},
  volume = {42},
  number = {3},
  month = jun,
  year = {2003},
  pages = {359-374},
  journal = {Journal of Computer Networks},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@PHDTHESIS{Wong93MDFL,
  author = {W. E. Wong},
  title = {On Mutation and Data Flow},
  school = {Department of Computer Science, Purdue University},
  year = {1993},
  address = {W. Lafayette, IN},
  month = dec,
  number = {SERC-TR-149-P},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{wong-etal:1995,
  author = {W. E. Wong and J. R. Horgan and S. London and A. P. Mathur},
  title = {Effect of Test Set Minimization on Fault Detection Effectiveness},
  pages = {41--50},
  address = {Seattle, WA},
  booktitle = {International Conference on Software Engineering (ICSE)},
  month = apr,
  owner = {magsilva},
  publisher = {ACM},
  timestamp = {2008.07.31},
  year = {1995}
}

@INPROCEEDINGS{wong-etal:1994,
  author = {W. E. Wong and J. R. Horgan and S. London and A. P. Mathur},
  title = {Effect of Test Set Size and Block Coverage on Fault Detection Effectiveness},
  pages = {230--238},
  address = {Monterey, CA},
  booktitle = {International Symposium on Software Reliability Engineering},
  month = nov,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1994}
}

@INPROCEEDINGS{Wong-etal:1997,
  author = {W. Eric Wong and José Carlos Maldonado and Márcio Eduardo Delamaro and Simone do Rocio Senger Souza},
  title = {Use of Proteum to Accelerate Mutation Testing in C Programs},
  pages = {254--258},
  abstract = {Although Mutation testing has been found to be powerfully effective for detecting faults, the large number of mutants generated and the corresponding cost to execute them make it difficult to apply in industry. Several ways have been proposed and investigated to reduce the number of mutants to consider while testing a program, most of them using Mothra in Fortran programs. In this paper we compare fault detection capability of selective mutation in the context of C and Fortran languages, using Proteum and Mothra, respectively. Proteum is a tool that supports mutation testing for C programs. The results obtained agree with previous results concerning selective mutation. In addition, a subset of six operators, out of the 71 C operators available in Proteum, has been characterized as a good basis for determining a C sufficient mutant operator set. This provides an important important aspect from the point of view of industrial application.},
  booktitle = {3rd International Conference on Reliability and Quality in Design},
  editor = {Hoang Pham},
  isbn = {0-9639998-2-6},
  location = {Anaheim, CA, #USA#},
  month = mar,
  publisher = {ISSAT},
  year = {1997}
}

@ARTICLE{Wong95FDEM,
  author = {W. E. Wong and A. P. Mathur},
  title = {Fault Detection Effectiveness of Mutation and Data Flow Testing},
  volume = {4},
  number = {1},
  month = mar,
  year = {1995},
  pages = {69--83},
  journal = sqj,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@ARTICLE{Wong95RCMT,
  author = {W. E. Wong and A. P. Mathur},
  title = {Reducing the Cost of Mutation Testing: An Empirical Study},
  volume = {31},
  number = {3},
  month = dec,
  year = {1995},
  pages = {185--196},
  journal = jss,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{Wong94HSCM,
  author = {W. E. Wong and A. P. Mathur},
  title = {How Strong is Constrained Mutation in Fault Detection\,?},
  pages = {515--520},
  address = {Taiwan},
  booktitle = {International Computer Symposium},
  month = dec,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1994}
}

@INPROCEEDINGS{Wong94MVAU,
  author = {W. E. Wong and A. P. Mathur and J. C. Maldonado},
  title = {Mutation Versus All-Uses: An Empirical Evaluation of Cost, Strength, and Effectiveness},
  pages = {258--265},
  address = {Hong Kong},
  booktitle = {International Conference on Software Quality and Productivity},
  month = dec,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1994}
}

@ARTICLE{Wong-etal:2011,
  author = {W. Eric Wong and T.H. Tse and Robert L. Glass and Victor R. Basili and T.Y. Chen},
  title = {An assessment of systems and software engineering scholars and institutions (2003-2007 and 2004-2008)},
  volume = {84},
  number = {1},
  year = {2011},
  pages = {162 - 168},
  doi = {10.1016/j.jss.2010.09.036},
  abstract = {An ongoing, annual survey of publications in systems and software engineering identifies the top 15 scholars and institutions in the field over a 5-year period. Each ranking is based on the weighted scores of the number of papers published in TSE, TOSEM, JSS, SPE, EMSE, IST, and Software of the corresponding period. This report summarizes the results for 2003-2007 and 2004-2008. The top-ranked institution is Korea Advanced Institute of Science and Technology, Korea for 2003-2007, and Simula Research Laboratory, Norway for 2004-2008, while Magne Jørgensen is the top-ranked scholar for both periods.},
  keywords = {Top scholars, Top institutions, Systems and software engineering, Research publications},
  issn = {0164-1212},
  journal = {Journal of Systems and Software},
  note = {Information Networking and Software Services}
}

@ARTICLE{Wong-etal:2009,
  author = {W. Eric Wong and T.H. Tse and Robert L. Glass and Victor R. Basili and T.Y. Chen},
  title = {An assessment of systems and software engineering scholars and institutions (2002-2006)},
  volume = {82},
  number = {8},
  year = {2009},
  pages = {1370 - 1373},
  doi = {10.1016/j.jss.2009.06.018},
  abstract = {This paper summarizes a survey of publications in the field of systems and software engineering from 2002 to 2006. The survey is an ongoing, annual event that identifies the top 15 scholars and institutions over a 5-year period. The rankings are calculated based on the number of papers published in TSE, TOSEM, JSS, SPE, EMSE, IST, and Software. The top-ranked institution is Korea Advanced Institute of Science and Technology, Korea, and the top-ranked scholar is Magne Jørgensen of Simula Research Laboratory, Norway.},
  keywords = {Top scholars},
  url = {http://www.sciencedirect.com/science/article/B6V0N-4WJBBPB-1/2/d366961873cef17aca306dd20bbbabb2},
  issn = {0164-1212},
  journal = {Journal of Systems and Software},
  note = {SI: Architectural Decisions and Rationale}
}

@ARTICLE{Wong-etal:2008,
  author = {W. Eric Wong and T.H. Tse and Robert L. Glass and Victor R. Basili and T.Y. Chen},
  title = {An assessment of systems and software engineering scholars and institutions (2001-2005)},
  volume = {81},
  number = {6},
  year = {2008},
  pages = {1059 - 1062},
  doi = {10.1016/j.jss.2007.09.018},
  abstract = {This paper presents the findings of a five-year study of the top scholars and institutions in the systems and software engineering field, as measured by the quantity of papers published in the journals of the field in 2001-2005. The top scholar is Magne Jørgensen of Simula Research Laboratory, Norway, and the top institution is Korea Advanced Institute of Science and Technology, Korea. This paper is part of an ongoing study, conducted annually, that identifies the top 15 scholars and institutions in the most recent five-year period.},
  url = {http://www.sciencedirect.com/science/article/B6V0N-4PRRBG9-1/2/568653a276de312b23ab5f1de33cac9a},
  issn = {0164-1212},
  journal = {Journal of Systems and Software}
}

@INPROCEEDINGS{Wood97CCSD,
  author = {M. Wood and M. Roper and A. Brooks and J. Miller},
  title = {Comparing and Combining Software Defect Detection Techniques: A Replicated Empirical Study},
  pages = {262--277},
  booktitle = {5th {ACM SIGSOFT} -- Symposium on the Foundations of Software Engineering},
  month = sep,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1997}
}

@BOOK{wood:1984,
  title = {Introdução à segurança do computador},
  publisher = {Editora Campus},
  year = {1984},
  author = {Michael B. Wood},
  note = {Traduzido por: Eduardo Schoueri},
  owner = {magsilva},
  timestamp = {2006.07.06}
}

@INPROCEEDINGS{woodall-brereton:2006,
  author = {Phillip Woodall and Pearl Brereton},
  title = {Conducting a Systematic Literature Review from the Perspective of a Ph.D. Student},
  booktitle = {International Conference on Evaluation and Assessment in Software Engineering (EASE)},
  owner = {magsilva},
  timestamp = {2007.11.15},
  year = {2006}
}

@INPROCEEDINGS{Woodward88FWSD,
  author = {M. R. Woodward and K. Halewood},
  title = {From Weak to Strong, Dead or Alive? An Analysis of Some Mutation Testing Issues},
  address = {Banff, Canada},
  booktitle = {Second Workshop on Software Testing, Verification and Analysis},
  month = may,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1988}
}

@ARTICLE{woodward-etal:1980,
  author = {M. R. Woodward and D. Heddley and M. A. Hennel},
  title = {Experience with Path Analysis and Testing of Programs},
  volume = {6},
  number = {3},
  month = may,
  year = {1980},
  pages = {278--286},
  abstract = {There are a number of practical difficulties in performing a path testing strategy for computer programs. One problem is in deciding which paths, out of a possible infinity, to use as test cases. A hierarchy of structural test metrics is suggested to direct the choide and to monitor the coverge of test paths. Another problem is that many of the chosen paths may be infeasible in the sense that no test data can ever execute them. Experience with the use of "allegations" to circumvent this problem and prevent the static generation of many infeasible paths is reported.},
  journal = ieeese,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@ARTICLE{wooldridge:1999,
  author = {M. J. Wooldridge and N. R. Jennings},
  title = {Software Engineering with Agents: Pitfalls and Pratifalls},
  volume = {3},
  number = {3},
  month = may,
  year = {1999 },
  pages = {20-27},
  journal = {IEEE Internet Computing},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@MISC{xml:2006,
  author = {{World Wide Web Consortium}},
  title = {Extensible Markup Language (XML) 1.0},
  howpublished = {Recomendation},
  month = sep,
  year = {2006},
  owner = {magsilva},
  timestamp = {2007.11.07},
  url = {http://www.w3.org/TR/2006/REC-xml-20060816}
}

@MISC{xml1.1:2006,
  author = {{World Wide Web Consortium}},
  title = {Extensible Markup Language (XML) 1.1},
  howpublished = {Recomendation},
  month = sep,
  year = {2006},
  owner = {magsilva},
  timestamp = {2007.11.07},
  url = {http://www.w3.org/TR/2006/REC-xml11-20060816}
}

@MISC{w3c-accessibility-preliminaryreview:2005,
  author = {{World Wide Web Consortium}},
  title = {Preliminary Review of Web Sites for Accessibility},
  howpublished = {Artigo na Internet},
  month = {apr},
  year = {2005},
  owner = {magsilva},
  timestamp = {2007.08.13},
  url = {http://www.w3.org/WAI/eval/preliminary.html}
}

@MISC{RDF03RDFS,
  author = {{World Wide Web Consortium (W3C)}},
  title = {{RDF Suite}},
  year = {2003},
  owner = {magsilva},
  timestamp = {2003.07.31},
  url = {http://139.91.183.30:9090/RDF/publications/index.html}
}

@INPROCEEDINGS{wu:2005,
  author = {Chen Wu and Elizabeth Chang},
  title = {Comparison of Web Service Architectures Based on Architecture Quality Properties},
  pages = {746-755},
  booktitle = {IEEE International Conference on Industrial Informatics (INDIN)},
  owner = {magsilva},
  timestamp = {2006.12.11},
  year = {2005}
}

@INPROCEEDINGS{wurhofer-etal:2009,
  author = {Wurhofer, Daniela and Obrist, Marianna and Beck, Elke and Tscheligi, Manfred},
  title = {Introducing a Comprehensive Quality Criteria Framework for Validating Patterns},
  pages = {242--247},
  doi = {10.1109/ComputationWorld.2009.86},
  abstract = {Patterns represent an important tool for communicating, documenting and looking up best practices for both novice and expert system developers and designers. Although there are a number of different patterns and pattern languages available, it is still unclear how to validate patterns in a structured way. Within this paper, we aim to fill this gap by introducing a Quality Criteria Framework developed on the basis of existing pattern research and applied within iterative evaluation sessions for improving our developed User Experience (UX) Patterns. In particular, five main quality criteria for patterns will be presented and discussed in detail.},
  keywords = {patterns, validation, quality framework, validation methods},
  address = {Washington, DC, USA},
  booktitle = {Proceedings of the 2009 Computation World: Future Computing, Service Computation, Cognitive, Adaptive, Content, Patterns},
  isbn = {978-0-7695-3862-4},
  publisher = {IEEE Computer Society},
  year = {2009}
}

@INPROCEEDINGS{Xiao-etal:2008,
  author = {Xiao, Kun and Chen, Shihong and Chen, Xi},
  title = {Course Material Research Based on Petri Net},
  pages = {79--86},
  doi = {10.1007/978-3-540-85033-5_9},
  abstract = {Many designers pay much more attention to establish an e-learning system but ignore to judge what material is proper for courseware merger. This paper tries to realize it via the Petri net. The relationship between material and knowledge point (KP) is closely. So, in order to use the Petri net, it presents the relationships among KP as the net firstly. Based on the relationships among KP, It analyzes the relationships among material in detail and brings forth the material sets (MS) net. And then, it gives the formalization description of the material Petri net (MPN) based on the Petri net (PN) and provides the method of the transformation from the MS net graph to MPN. When material is merged into the courseware, some speciality of material can be checked by the MPN. The experiments shows that the MPN can validate the reasonableness of the material merger effectively.},
  keywords = {Petri net, courseware, material},
  series = {ICWL '08},
  acmid = {1428654},
  address = {Berlin, Heidelberg},
  booktitle = {International Conference on Advances in Web Based Learning},
  isbn = {978-3-540-85032-8},
  location = {Jinhua, China},
  numpages = {8},
  publisher = {Springer-Verlag},
  year = {2008}
}

@ARTICLE{baowen-etal:2005,
  author = {Xu, Baowen and Qian, Ju and Zhang, Xiaofang and Wu, Zhongqiang and Chen, Lin},
  title = {A Brief Survey Of Program Slicing},
  volume = {30},
  number = {2},
  month = mar,
  year = {2005},
  pages = {1--36},
  doi = {10.1145/1050849.1050865},
  address = {New York, NY, USA},
  issn = {0163-5948},
  journal = {ACM SIGSOFT Software Engineering Notes},
  publisher = {ACM}
}

@ARTICLE{yaghmaie-bahreininejad:2011,
  author = {Yaghmaie, Mahkameh and Bahreininejad, Ardeshir},
  title = {A context-aware adaptive learning system using agents},
  volume = {38},
  number = {4},
  month = apr,
  year = {2011},
  pages = {3280--3286},
  doi = {10.1016/j.eswa.2010.08.113},
  abstract = {Evolution of Web technologies has made e-learning a popular common way of education and training. As an outcome, learning content adaptation has been the subject of many research projects lately. This paper suggests a framework for building an adaptive Learning Management System (LMS). The proposed architecture is based upon multi-agent systems and uses both Sharable Content Object Reference Model (SCORM) 2004 and semantic Web ontology for learning content storage, sequencing and adaptation. This system has been implemented upon a well known open-source LMS and its functionalities are demonstrated through the simulation of a scenario mimicing the real life conditions. The result reveals the system effectiveness for which it appears that the proposed approach may be very promising.},
  keywords = {Adaptive learning, Agent, Intelligent tutoring systems, Ontology, SCORM},
  acmid = {1922970},
  address = {Tarrytown, NY, USA},
  issn = {0957-4174},
  issue = {4},
  issue_date = {April, 2011},
  journal = {Expert Systems with Applications: An International Journal},
  numpages = {7},
  publisher = {Pergamon Press, Inc.}
}

@INPROCEEDINGS{yahya-etal:2002,
  author = {Yazrina Yahya and John Jenkins and Mohammed Yusoff},
  title = {The Development of The Learning Object Standard Using A Pedagogic Approach: A Comparative Study},
  pages = { 2091--2096 },
  address = { Denver, Colorado, USA },
  booktitle = {Proceedings of World Conference on Educational Multimedia, Hypermedia and Telecommunications 2002},
  editor = { Philip Barker and Samuel Rebelsky },
  publisher = { AACE },
  url = { http://go.editlib.org/p/9242 },
  year = {2002}
}

@INPROCEEDINGS{yamakami-etal:2009,
  author = {Yamakami, Toshihiko},
  title = {An interactivity model of mobile interactive {TV}: a oneseg case for mobile glue},
  pages = {212--217},
  doi = {10.1145/1655925.1655963},
  abstract = {One-seg is a new mobile use context combining user experience for mobile and broadcast. This new technology enables to combine real-time broadcast contexts and personal mobile interactive contexts. The author coins an interactivity model for service development of one-seg applications on a mobile handset. The author discusses work-flow based service scenarios for four interactivity aspects of the one-seg applications based on the proposed model. The author presents a mobile glue model to enable a service composition platform perspective for flexible service composition for mobile communication/broadcast converged services.},
  keywords = {interactivity model, one-seg, work-flow analysis},
  address = {New York, NY, USA},
  booktitle = {Proceedings of the 2nd International Conference on Interaction Sciences: Information Technology, Culture and Human},
  isbn = {978-1-60558-710-3},
  location = {Seoul, Korea},
  publisher = {ACM},
  year = {2009}
}

@INPROCEEDINGS{Yanagawa-Martins:2000,
  author = {R. L. Yanagawa and E. Martins},
  title = {Avaliação Empírica da Eficácia dos Testes Baseados no Modelo de Fluxo de Transação em Sistemas Orientados a Objetos},
  pages = {18--30},
  address = {Curitiba, PR},
  booktitle = {XI Conferência Internacional de Tecnologia de Software: Qualidade de Software},
  month = jun,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {2000}
}

@MISC{Yano01EACT,
  author = {T. Yano},
  title = {Estudo dos Aspectos Complementares do Teste de Muta\c c\~ao em N\'ivel de Especifica\c c\~oes e de Programas},
  howpublished = {Exame Geral de Qualificação -- Instituto de Ci\^encias Matem\'aticas e de Computa\c c\~ao -- ICMC-USP},
  year = {2001},
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@ARTICLE{svetlana-guzdial:2008,
  author = {Svetlana Yarosh and Mark Guzdial},
  title = {Narrating data structures: The role of context in CS2},
  volume = {7},
  number = {4},
  month = jan,
  year = {2008},
  journal = {Journal on Educational Resources in Computing (JERIC)},
  owner = {magsilva},
  timestamp = {2008.07.24}
}

@ARTICLE{yen-etal:2010,
  author = {Yen, Neil Y. and Shih, Timothy K. and Chao, Louis R. and Jin, Qun},
  title = {Ranking Metrics and Search Guidance for Learning Object Repository},
  volume = {3},
  number = {3},
  month = jul,
  year = {2010},
  pages = {250--264},
  doi = {10.1109/TLT.2010.15},
  abstract = {In line with the popularity of the Internet and the development of search engine, users request information through web-based services. Although general-purpose searching such as one provided by Google is powerful, searching mechanism for specific purposes could rely on metadata. In distance learning (or e-learning), SCORM provides an efficient metadata definition for learning objects to be searched and shared. To facilitate searching in a federated repository, CORDRA provides a common architecture for discovering and sharing Learning Objects. We followed SCORM and CORDRA specifications to develop a registry system, called the MINE Registry, for storing and sharing 20,738 Learning Objects created in the past five years. As a contribution, we propose the concept of 'Reusability Tree' to represent the relationships among relevant Learning Objects and enhance CORDRA. We further collect relevant information, while users are utilizing Learning Objects, such as citations and time period persisted. The feedbacks from the user community are also considered as critical elements for evaluating significance degree of Learning Objects. Through theses factors, we propose a mechanism to weight and rank Learning Objects in the MINE Registry, in addition to other external learning objects repositories. As a practical contribution, we provide a tool called 'Search Guider' to assist users in finding relevant information in Learning Objects based on individual requirements.},
  keywords = {CORDRA, LOM, learning object repository, ranking metrics, search guidance, reusability tree, social feedback, information retrieval, distance learning.},
  acmid = {1907824},
  address = {Los Alamitos, CA, USA},
  issn = {1939-1382},
  issue = {3},
  issue_date = {July 2010},
  journal = {IEEE Transactions on Learning Technologies},
  numpages = {15},
  publisher = {IEEE Computer Society}
}

@INPROCEEDINGS{yeun:2007,
  author = {Chan Yeob Yeun},
  title = {Mobile TV Technologies},
  pages = {2-9},
  doi = {10.1109/ITICT.2007.4475607},
  booktitle = {International Conference on Information and Communications Technology (ICICT)},
  journal = {International Conference on Information and Communications Technology (ICICT)},
  month = dec,
  timestamp = {2008.09.01},
  year = {2007}
}

@INPROCEEDINGS{Yim-etal:2009,
  author = {Yim, Hyun-Jeong and Choy, Yoon-Chul and Lim, Soon-Bum},
  title = {A content-based synchronization approach for timing description in EnhancedTV},
  pages = {1-1},
  doi = {10.1145/1666778.1666786},
  series = {SIGGRAPH ASIA '09},
  acmid = {1666786},
  address = {New York, NY, USA},
  articleno = {8},
  booktitle = {ACM SIGGRAPH ASIA 2009 Posters},
  location = {Yokohama, Japan},
  numpages = {1},
  publisher = {ACM},
  year = {2009}
}

@INPROCEEDINGS{yim-etal:2009,
  author = {Yim, Hyun-Jeong and Choy, Yoon-Chul and Lim, Soon-Bum},
  title = {A study of GUI representation based on BIFs for enhanced mobile TV},
  pages = {297--302},
  doi = {10.1145/1570433.1570488},
  abstract = {Content based interaction is a key factor when creating communications between viewers and content within enhanced mobile TV. However, it is not easy to implement enhanced content, including Graphical User Interfaces (GUIs), in mobile broadcasting environments that are based on Binary Format for Scene (BIFS). Therefore, we designed and implemented a GUI nodes library that can be used for content development and show its prototyped contents, with suggested nodes, on Digital Multimedia Broadcasting (DMB). The results of this study make it easier to present a GUI in data content and enhance the efficiency of content development.},
  keywords = {dmb, enhanced data contents, gui, mobile tv, mpeg-4 bifs, node library},
  series = {EICS '09},
  acmid = {1570488},
  address = {New York, NY, USA},
  booktitle = {Proceedings of the 1st ACM SIGCHI symposium on Engineering interactive computing systems},
  isbn = {978-1-60558-600-7},
  location = {Pittsburgh, PA, USA},
  numpages = {6},
  publisher = {ACM},
  year = {2009}
}

@BOOK{Yin:2002,
  title = {Case Study Research: Design and Methods},
  publisher = {Sage Publications},
  year = {2002},
  author = {Robert K. Yin},
  pages = {200},
  edition = {3}
}

@INPROCEEDINGS{yu:1997,
  author = {Eric S. K. Yu},
  title = {Why Agent-Oriented Requirements Engineering},
  address = {Barcelona, Espanha},
  booktitle = {REFSQ'97 - Requirements Engineering: Foundation of Software Quality},
  owner = {magsilva},
  publisher = {Presses Universitaires de Namur},
  timestamp = {2008.07.30},
  year = {1997}
}

@ARTICLE{Yu-etal:2009,
  author = {Yu, Lu and Chen, Sijia and Wang, Jianpeng},
  title = {Overview of {AVS}-video coding standards},
  volume = {24},
  number = {4},
  month = apr,
  year = {2009},
  pages = {247--262},
  doi = {10.1016/j.image.2009.02.003},
  abstract = {Audio-video coding standard (AVS) is a working group of audio and video coding standard in China, which established in 2002. AVS-video coding standards are important parts of productions of AVS working group. Considering the different requirements of various video applications, AVS-video coding standards define different profiles, combining advanced video coding tools with trade-off between coding efficiency and encoder/decoder implementation complexity as well as functional properties. This paper provides an overview of major AVS-video coding tools and their combinations as profiles.},
  keywords = {AVS, Standard, Video coding},
  acmid = {1539104},
  address = {New York, NY, EUA},
  issn = {0923-5965},
  issue = {4},
  journal = {Image Communication},
  numpages = {16},
  publisher = {Elsevier}
}

@ARTICLE{ma-etal:2005,
  author = {Yu-Seung Ma, Jeff Offutt and Yong Rae Kwon},
  title = {MuJava: An Automated Class Mutation System},
  volume = {15},
  number = {2},
  month = jun,
  year = {2005},
  pages = {97-133},
  abstract = {Several module and class testing techniques have been applied to object-oriented programs, but researchers have only recently begun developing test criteria that evaluate the use of key OO features such as inheritance, polymorphism, and encapsulation. Mutation testing is a powerful testing technique for generating software tests and evaluating the quality of software. However, the cost of mutation testing has traditionally been so high it cannot be applied without full automated tool support. This paper presents a method to reduce the execution cost of mutation testing for OO programs by using two key technologies, Mutant Schemata Generation (MSG) and reflection. This method adapts the existing MSG method for mutants that change the program behavior and uses load-time structural reflection for mutants that change the program structure. A key advantage is in performance: only two compilations are required and both the compilation and execution time for each is greatly reduced. A mutation tool based on the MSG/reflection method has been built and used to measure the speedup over the separate compilation approach. Experimental results show that the MSG/reflection method is about five times faster than separate compilation.},
  journal = {Software Testing, Verification and Reliability},
  publisher = {John Wiley \& Sons}
}

@INPROCEEDINGS{zanlorenci:2000,
  author = {Edna Pacheco Zanlorenci and Robert Carlisle Burnett},
  title = {{REQAV}: Modelo para Descrição, Qualificação, Análise e Validação de Requisitos},
  pages = {61-72},
  booktitle = {IDEAS2000: Jornada Ibero Americana de Ingeneria de Requisitos Y Ambientes de Software},
  owner = {magsilva},
  timestamp = {2008.07.30},
  year = {2000}
}

@ARTICLE{Zanting-etal:2003,
  author = {Anneke Zanting and Nico Verloop and Jan D. Vermunt},
  title = {Using interviews and concept maps to access mentor teachers' practical knowledge},
  volume = {46},
  number = {2},
  year = {2003},
  pages = {195-214},
  doi = {10.1023/A:1024719816657},
  abstract = {Mentor teachers' practical knowledge often remains implicit for the student teachers they supervise. Practical knowledge consists of various cognitions that clarify mentors' own lessons and the feedback given to student teachers. The aim of the present study was to evaluate two instruments, the interview and concept map, for accessing practical knowledge in the context of teacher education. Seventy student teachers participating in a postgraduate teacher education programme in the Netherlands interviewed their mentors and discussed a concept map made by these mentors. They summarised their mentors' explicated practical knowledge about 'teaching' and 'order', wrote down their learning experiences, and evaluated both instruments. Several categories of learning experiences and evaluations were derived from the reports that were analysed qualitatively and quantitatively. The summaries of practical knowledge were analysed using two distinctions: (1) 'absolute' versus 'situational' and (2) 'descriptive' versus 'analytical' statements. At least half of the student teachers evaluated interviewing and concept mapping positively for accessing practical knowledge. The analysis showed that concept mapping had elicited more reasons underlying teaching than interviewing. It was concluded that both instruments can help student teachers to access practical knowledge, each revealing qualitatively different information: interviewing yielded more concrete, practical information while that produced by concept mapping was more abstract.},
  journal = {Higher education},
  publisher = {Kluwer Academic}
}

@MISC{software:openldap,
  author = {Kurt Zeilenga and Howard Chu and Pierangelo Masarati and others},
  title = {{OpenLDAP}},
  howpublished = {Programa de computador},
  month = ago,
  year = {1998},
  owner = {magsilva},
  timestamp = {2007.12.11},
  url = {http://www.openldap.org/}
}

@INPROCEEDINGS{Zelkowitz97EVSE,
  author = {M. Zelkowitz and D. Wallace},
  title = {Experimental Validation in {S}oftware {E}ngineering},
  address = {Keele University, UK},
  booktitle = {International Conference on Empirical Assessment and Evaluation in SE},
  month = mar,
  owner = {magsilva},
  timestamp = {2008.07.31},
  year = {1997}
}

@ARTICLE{Zelkowitz:2008,
  author = {Marvin V. Zelkowitz},
  title = {An update to experimental models for validating computer technology},
  volume = {82},
  year = {2008},
  pages = {373-376},
  journal = {The Journal of Systems and Software},
  owner = {magsilva},
  timestamp = {2010.08.09}
}

@ARTICLE{Zelkowitz-Wallace:1998,
  author = {Marvin V. Zelkowitz and Dolores R. Wallace},
  title = {Experimental models for validating computer technology},
  volume = {31},
  number = {5},
  month = may,
  year = {1998},
  pages = {23-31},
  abstract = {Experimentation helps determine the effectiveness of proposed theories and methods. However, computer science has not developed a concise taxonomy of methods for demonstrating the validity of new techniques. Experimentation is a crucial part of attribute evaluation and can help determine whether methods used in accordance with some theory during product development will result in software being as effective as necessary. By looking at multiple examples of technology validation, the authors develop a taxonomy for software engineering experimentation that describes twelve different experimental approaches.},
  journal = {IEEE Computer},
  owner = {magsilva},
  timestamp = {2010.08.09}
}

@ARTICLE{zeller:2001,
  author = {Andreas Zeller},
  title = {Automated Debugging: Are We Close?},
  month = nov,
  year = {2001},
  pages = {26-31},
  journal = {IEEE Computer},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@INPROCEEDINGS{zemel-etal:2009,
  author = {Zemel, Alan and Cakir, Murat Perit and Zhou, Nan and Stahl, Gerry},
  title = {Learning as a practical achievement: an interactional perspective},
  pages = {118--122},
  abstract = {Despite the definitional difficulties associated with learning and instruction, they evidently occur as social realities for those involved in the practical, day-to-day work of learning and instructing. In this paper we offer an interactional perspective of learning and instruction by relying on the commonsense recognizability of learning to investigate what participants themselves do to achieve and recognize learning's work.},
  volume = {1},
  series = {CSCL'09},
  acmid = {1600071},
  booktitle = {Proceedings of the 9th international conference on Computer supported collaborative learning},
  isbn = {978-1-4092-8598-4},
  location = {Rhodes, Greece},
  numpages = {5},
  publisher = {International Society of the Learning Sciences},
  url = {http://portal.acm.org/citation.cfm?id=1600053.1600071},
  year = {2009}
}

@INPROCEEDINGS{Zeng-etal:2009,
  author = {Fanping Zeng and Liangliang Mao and Zhide Chen and Qing Cao},
  title = {Mutation-Based Testing of Integer Overflow Vulnerabilities},
  pages = {1--4},
  doi = {10.1109/WICOM.2009.5302048},
  abstract = {Integer overflow vulnerability is a kind of common software vulnerabilities, there has been no effective way to detect integer overflow vulnerabilities. Because of the lack of dynamic execution, static analysis can not determinethe run-time distribution of memory, and may miss the detection of possible security issues; source code auditing is an expensive and time consuming process. Although there has been applying mutation analysis for testing ANSI C programs, and lots of mutation operators have been designed with respect to specific questions, there are not any of operators specifically designed for integer overflow. In this paper, we propose some new mutation operators to force the generation of adequate test data set for integer overflow vulnerabilities. The results indicate that the proposed operators are effective for detecting integer overflow vulnerabilities.},
  keywords = {integer overflow; ANSI C; mutation testing; mutation operators},
  address = {Beijing, China},
  booktitle = {5th International Conference on Wireless Communications, Networking and Mobile Computing},
  month = sep,
  publisher = {IEEE Communications Society},
  year = {2009}
}

@ARTICLE{Zhang-etal:2006,
  author = {Zhang, Dongsong and Zhou, Lina and Briggs, Robert O. and Nunamaker,Jr., Jay F.},
  title = {Instructional video in e-learning: Assessing the impact of interactive video on learning effectiveness},
  volume = {43},
  month = {January},
  year = {2006},
  pages = {15--27},
  doi = {10.1016/j.im.2005.01.004},
  abstract = {Interactive video in an e-learning system allows proactive and random access to video content. Our empirical study examined the influence of interactive video on learning outcome and learner satisfaction in e-learning environments. Four different settings were studied: three were e-learning environments-with interactive video, with non-interactive video, and without video. The fourth was the traditional classroom environment. Results of the experiment showed that the value of video for learning effectiveness was contingent upon the provision of interactivity. Students in the e-learning environment that provided interactive video achieved significantly better learning performance and a higher level of learner satisfaction than those in other settings. However, students who used the e-learning environment that provided non-interactive video did not improve either. The findings suggest that it may be important to integrate interactive instructional video into e-learning systems.},
  keywords = {E-learning, Interactive video, Learning effectiveness},
  acmid = {1709370},
  address = {Amsterdam, } # Netherlands,
  issn = {0378-7206},
  journal = {Inf. Manage.},
  publisher = {Elsevier Science}
}

@ARTICLE{zhang-etal:2002,
  author = {Shidong Zhang and Qingzhong Li and Yongqing Zheng and Haiyang Wang},
  title = {The multi-tier architecture based on offline component agent},
  year = {2002},
  pages = {241-244},
  doi = {10.1109/CSCWD.2002.1047690},
  abstract = { In order to implement the complex business process involved in multi-computer applications, it is necessary for correlative computer applications to cooperate with each other and connect to each other. Under the traditional client/server architecture, there are many difficulties in implementing connections to each application. It can offer a better foundation of architecture that constructs an application server and forms the multi-tier architecture of the client/application server/database server using a component based software technique. However, this architecture needs the correlative applications to connect to each other continuously. Apparently, it is confined under the environment of noncontinuous connection. In this paper we propose the concept of offline component agent and the multi-tiered architecture based on an offline component agent, which can effectually implement interconnection of multi-applications under the environment of non-continuous connection. Offline component agents provided by the server application and configured at the client application process business logic and data logic in correlative server applications. The client application and offline component agent maintain continuous connection, but the offline component agent and server application may not maintain continuous connection, these two parts cooperating with each other according to special arithmetic. The merit of the architecture of software multi-tier components includes clarity of the interface between different applications, consistency between software structure and problem structure, better encapsulation of software logic, and the advantages of safe management and simplicity of maintenance and version management. We explicate the architecture based on the offline component agent.},
  keywords = { business data processing, client-server systems, configuration management, groupware, software agents, software architecture, software maintenance business logic, business process, client/application server/database server architecture, component based software, correlative server application, data logic, interface, maintenance, multi-computer application, multi-tier architecture, offline component agent, software logic encapsulation, version management},
  issn = { },
  journal = {International Conference on Computer Supported Cooperative Work in Design},
  owner = {magsilva},
  timestamp = {2008.07.30}
}

@INPROCEEDINGS{zhao:2000,
  author = {Jianjun Zhao},
  title = {Dependence analysis of Java bytecode},
  pages = {486-491},
  doi = {10.1109/CMPSAC.2000.884771},
  abstract = {Understanding program dependencies in a computer program is essential for many software engineering tasks such as program understanding, testing, debugging, reverse engineering, and maintenance. The article presents an approach to dependence analysis of Java bytecode, and discusses some applications of the technique, which include Java bytecode slicing, understanding, and testing},
  keywords = {Java bytecode analysis;Java bytecode slicing;computer program;dependence analysis;maintenance;program dependencies;program testing;program understanding;reverse engineering;software engineering task;Java;program slicing;program testing;reverse engineering;},
  address = {Taipei, Twain},
  booktitle = {Computer Software and Applications Conference (COMPSAC)},
  month = oct,
  year = {2000}
}

@INPROCEEDINGS{zhao:1999,
  author = {Jianjun Zhao},
  title = {Analyzing Control Flow in Java Bytecode},
  pages = {313--316},
  booktitle = {Conference of Japan Society for Software Science and Technology},
  year = {1999}
}

@ARTICLE{Zhu96FASR,
  author = {H. Zhu},
  title = {A Formal Analysis of the Subsume Relation Between Software Test Adequacy Criteria},
  volume = {SE-22},
  number = {4},
  month = apr,
  year = {1996},
  pages = {248--255},
  journal = ieeese,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@ARTICLE{Zhu93TDAM,
  author = {H. Zhu and P. Hall},
  title = {Test Data Adequacy Measurements},
  volume = {8},
  number = {1},
  month = jan,
  year = {1993},
  pages = {211--224},
  journal = sej,
  owner = {magsilva},
  timestamp = {2008.07.31}
}

@INPROCEEDINGS{zhu-huo:2004,
  author = {H. Zhu and Q. Huo},
  title = {Developing A Software Testing Ontology in {UML} for A Software Growth Environment of Web-Based Applications},
  booktitle = {Software Evolution with UML and XML},
  editor = {Hongji Yang},
  owner = {magsilva},
  publisher = {Idea Group},
  timestamp = {2008.07.31},
  year = {2004}
}

@MISC{Zweben:2012,
  author = {Stuart Zweben},
  title = {Computing Degree and Enrollment Trends: From the the 2010-2011 {CRA} {Taulbee} Survey},
  howpublished = Report # { } # from # { Computer Research Association},
  year = {2012},
  address = {Washington, DC, } # USA,
  pages = {17},
  timestamp = {2013-11-10},
  url = {http://www.cra.org/uploads/documents/resources/taulbee/CS_Degree_and_Enrollment_Trends_2010-11.pdf}
}

@INPROCEEDINGS{zylbermann:2003,
  author = {Debi Zylbermann and Yigal Cohen and Leah Goldin},
  title = {The Road to Requirements Maturity},
  pages = {71-78},
  booktitle = {IEEE Internacional Conference on Software - Science, Technology \& Engineering (SwSTE´03)},
  owner = {Marco Aurélio Graciotto Silva},
  publisher = {IEEE Computer Society},
  timestamp = {2008.07.30},
  year = {2003}
}

@PROCEEDINGS{proceedings:isda:2009,
  booktitle = {9th International Conference on Intelligent Systems Design and Applications},
  title = {International Conference on Intelligent Systems Design and Applications},
  year = {2009},
  month = nov # {-} # dec,
  days = {30-2},
  location = {Pisa, Italy},
  editor = {Ajith Abraham and José Manuel Benitez Sánchez and Francisco Herrera and Vincenzo Loia and Francesco Marcelloni and Sabrina Senatore},
  series = {International Conference on Intelligent Systems Design and Applications},
  address = {Los Alamitos, California, USA},
  publisher = {IEEE Computer Society},
  papers-accepted = {249},
  papers-submitted = {413}
}

@PROCEEDINGS{proceedings:xp:2009,
  booktitle = {10th International Conference on Agile Software Development},
  title = {10th International Conference on Agile Software Development},
  year = {2009},
  month = may,
  days = {25--29},
  location = {Sardinia, #Italy#},
  isbn = {978-3-642-01852-7},
  editor = {Abrahamsson, Pekka and Marchesi, Michele and Maurer, Frank},
  volume = {31},
  series = {Lecture Notes in Business Information Processing},
  publisher = {Springer Berlin Heidelberg},
  owner = {magsilva},
  timestamp = {2014.10.20}
}

@PROCEEDINGS{proceedings:xp:2006,
  booktitle = {7th International Conference on Extreme Programming and Agile Processes in Software Engineering},
  title = {7th International Conference on Extreme Programming and Agile Processes in Software Engineering},
  year = {2006},
  month = jun,
  days = {17--22},
  location = {Oulu, #Finland#},
  isbn = {978-3-540-35094-1},
  editor = {Abrahamsson, Pekka and Marchesi, Michele and Succi, Giancarlo},
  volume = {4044},
  series = {Lecture Notes in Computer Science},
  publisher = {Springer Berlin Heidelberg},
  owner = {magsilva},
  timestamp = {2014.10.20}
}

@PROCEEDINGS{proceedings:sbes:1988,
  booktitle = {2nd Brazilian Symposium on Software Engineering},
  title = {2nd Brazilian Symposium on Software Engineering},
  year = {1988},
  month = oct,
  location = {Canela, RS, Brazil},
  editor = {Ana Maria de Alencar Price and Daltro José Nunes and Loreta Scheuer de Oliveira Ramos},
  series = {Brazilian Symposium on Software Engineering},
  organization = {UFRGS},
  owner = {magsilva},
  papers-accepted = {26},
  papers-submitted = {63},
  promoter = {SBC, UFRGS},
  title-en = {2nd Brazilian Symposium on Software Engineering},
  title-pt = {III Simpósio Brasileiro de Engenharia de Software}
}

@PROCEEDINGS{proceedings:oer:2011,
  booktitle = {1st International Symposium on Open Educational Resources: Issues for Globalization and Localization},
  title = {1st International Symposium on Open Educational Resources: Issues for Globalization and Localization},
  year = {2011},
  month = apr,
  days = {11 -- 13},
  location = {Logan, Utah, #USA#},
  editor = {Tel Amiel and Richard West},
  e-issn = {2163-3398},
  issn = {2163-3401}
}

@PROCEEDINGS{proceedings:sigdoc:2010,
  booktitle = {28th International Conference on Design of Communication},
  title = {28th International Conference on Design of Communication},
  year = {2010},
  month = sep,
  days = {27-29},
  location = {São Carlos, SP, #Brazil#},
  isbn = {978-1-4503-0403-0},
  editor = {Junia C. Anacleto and Renata Pontin de M. Fortes and Carlos J. Costa},
  series = {International Conference on Design of Communication},
  address = {São Carlos, SP, } # Brazil,
  publisher = {ACM},
  organization = {UFSCar, USP},
  pages = {302},
  papers-accepted = {28},
  papers-submitted = {88},
  promoter = {ACM SIGDOC, SBC}
}

@BOOK{Anderson-Krathwohl:2000,
  title = {A Taxonomy for Learning, Teaching, and Assessing: A Revision of Bloom's Taxonomy of Educational Objectives},
  publisher = {Longman},
  year = {2001},
  editor = {Lorin W. Anderson and David R. Krathwohl},
  pages = {352},
  address = {New York, NY, } # USA,
  abstract = {This revision of Bloom's taxonomy is designed to help teachers understand and implement standards-based curriculums. Cognitive psychologists, curriculum specialists, teacher educators, and researchers have developed a two-dimensional framework, focusing on knowledge and cognitive processes. In combination, these two define what students are expected tolearn in school. Like no other text, it explores curriculums from three unique perspectives-cognitive psychologists (learning emphasis), curriculum specialists and teacher educators (C&I emphasis), and measurement and assessment experts (assessment emphasis). This "revisited" framework allows you to connect learning in all areas of curriculum. Educators, or others interested in Educational Psychology or Educational Methods for grades K-12.},
  booktitle = {A Taxonomy for Learning, Teaching, and Assessing: A Revision of Bloom's Taxonomy of Educational Objectives}
}

@BOOK{Armstrong-etal:1968,
  title = {Developing and Writing Behavioral Objectives},
  publisher = {Educational Innovators},
  year = {1968},
  editor = {Robert. J. Armstrong and others},
  address = {Tucson, Arizona, USA},
  note = {Também conhecido como ``A Systematic approach to developing and writing behavioral objectives: a handbook designed to increase the communication of laymen and educators''},
  abstract = {An organizational structure which permits the identification of the variables affecting an educational program is presented. It is designed to solve the problem of clearly and systematically developing and writing behavioral objectives which can be evaluated with validity and reliability. Three types of variables--behavioral, instructional, and institutional--are isolated. Sixteen terms are used to describe cognitive, affective, and psychomotor levels of behavior. These terms are used to write up behavioral objectives which can be measured by various techniques. These behavioral objectives must be critiqued and stated clearly. Two added elements--time and proficiency level--may then be considered. The level of specificity desired and type of performance objective complete the list of necessary elements of a behavioral objective.}
}

@PROCEEDINGS{proceedings:sw-el:2005,
  booktitle = {International Workshop on Applications of Semantic Web Technologies for E-Learning (SW-EL)},
  title = {International Workshop on Applications of Semantic Web Technologies for E-Learning (SW-EL)},
  year = {2005},
  month = jul,
  days = {18},
  location = {Amsterdan, #Netherlands#},
  editor = {Lora Aroyo and Darina Dicheva},
  series = {SW-EL},
  url = {http://www.win.tue.nl/SW-EL/2005/swel05-aied05/swel05-aied05.html}
}

@PROCEEDINGS{proceedings:iv:2006,
  booktitle = {10th International Conference on Information Visualization},
  title = {10th International Conference on Information Visualization},
  year = {2006},
  month = jul,
  days = {5--7},
  location = {London, #UK#},
  editor = {Ebad Banissi and Remo Aslak Burkhard and Anna Ursyn and Jian J Zhang and Mark Bannatyne and Carsten Maple and Andrew J. Cowell and Gui Yun Tian and and Ming Hou},
  address = {Los Alamitos, CA, EUA},
  publisher = {IEEE Computer Society},
  issn = {1550-6037}
}

@PROCEEDINGS{proceedings:interact:2007,
  booktitle = {11th IFIP TC 13 International Conference ({INTERACT})},
  year = {2007},
  month = sep,
  days = {10--14},
  location = {Rio de Janeiro, RJ, #Brazil#},
  isbn = {978-3-540-74799-4},
  editor = {Maria Cecília Calani Baranauskas and Philippe A. Palanque and Julio Abascal and Simone Diniz Junqueira Barbosa},
  volume = {4663},
  series = {Lecture Notes in Computer Science}
}

@PROCEEDINGS{proceedings:iwdc:2006,
  booktitle = {Empirical Software Engineering Issues: Critical Assessment and Future Directions},
  year = {2006},
  month = jun,
  location = {Dagstuhl Castle, #Germany#},
  isbn = {978-3-540-71300-5},
  e-isbn = {978-3-540-71301-2},
  editor = {Victor R. Basili and Dieter Rombach and Kurt Schneider and Barbara Kitchenham and Dietmar Pfahl and Richard Wl. Selby},
  volume = {4336},
  series = {Lecture Notes on Computer Science},
  address = {Dagstuhl Castle, } # Germany,
  publisher = {Springer},
  day = {26--30},
  issn = {302-9743}
}

@PROCEEDINGS{proceedings:dagstuhl:2006,
  booktitle = {International Workshop on Empirical Software Engineering Issues},
  title = {International Workshop on Empirical Software Engineering Issues},
  year = {2006},
  month = jun,
  days = {26--30},
  location = {Dagstuhl Castle, #Germany#},
  isbn = {978-3-540-71300-5},
  editor = {Victor R. Basili and H. Dieter Rombach and Kurt Schneider and Barbara A. Kitchenham and Dietmar Pfahl and Richard W. Selby},
  volume = {4336},
  series = {Lecture Notes in Computer Science},
  publisher = {Springer}
}

@PROCEEDINGS{proceedings:sbes:2010,
  booktitle = {24th Brazilian Symposium on Software Engineering},
  title = {24th Brazilian Symposium on Software Engineering},
  year = {2010},
  month = sep,
  days = {27-1},
  location = {Salvador, BA, Brazil},
  editor = {Thais Batista},
  volume = {1},
  series = {Brazilian Symposium on Software Engineering},
  organization = {DCC-UFBA},
  issn = {2178-6097},
  papers-accepted = {19},
  papers-submitted = {88},
  promoter = {Sociedade Brasileira de Computação},
  title-en = {24th Brazilian Symposium on Software Engineering},
  title-pt = {XXIV Simpósio Brasileiro de Engenharia de Software}
}

@PROCEEDINGS{proceedings:xp:2013,
  booktitle = {14th International Conference on Agile Software Development},
  title = {14th International Conference on Agile Software Development},
  year = {2013},
  month = jun,
  days = {3--7},
  location = {Vienna, #Austria#},
  isbn = {978-3-642-38313-7},
  editor = {Baumeister, Hubert and Weber, Barbara},
  volume = {149},
  series = {Lecture Notes in Business Information Processing},
  publisher = {Springer Berlin Heidelberg},
  owner = {magsilva},
  timestamp = {2014.10.20}
}

@PROCEEDINGS{proceedings:sigcse:1994,
  booktitle = {25th SIGCSE Symposium on Computer Science Education},
  year = {1994},
  location = {Phoenix, Arizona, #USA#},
  isbn = {0-89791-646-8},
  editor = {Robert Beck and Don Goelman},
  address = {New York, NY, } # USA,
  publisher = {ACM}
}

@PROCEEDINGS{proceedings:icannga:2007,
  booktitle = {International Conference on Adaptive and Natural Computing Algorithms},
  title = {International Conference on Adaptive and Natural Computing Algorithms},
  year = {2007},
  month = apr,
  days = {11-14},
  location = {Warsaw, Poland},
  isbn = {978-3-540-71589-4},
  editor = {Beliczynski, B. and Dzielinski, A. and Iwanowski, M. and Ribeiro, B.},
  series = {International Conference on Adaptive and Natural Computing Algorithmss},
  address = {Berlin, Heidelberg},
  publisher = {Springer-Verlag}
}

@PROCEEDINGS{Berque-etal:2006,
  booktitle = {Workshop on the Impact of Tablet PCs and Pen-based Technology on Education},
  title = {Workshop on the Impact of Tablet PCs and Pen-based Technology on Education},
  year = {2006},
  month = apr,
  isbn = {978-1-55753-531-3},
  editor = {Dave A. Berque and Jane C. Prey and Robert H. Reed},
  address = {Indiana, EUA},
  publisher = {Purdue University Press},
  timestamp = {2008.10.05}
}

@PROCEEDINGS{proceedings:forte:1995,
  booktitle = {8th International Conference on Formal Description Techniques for Distributed Systems and Communications Protocols (FORTE)},
  title = {8th International Conference on Formal Description Techniques for Distributed Systems and Communications Protocols (FORTE)},
  year = {1995},
  month = oct,
  days = {17--20},
  location = {Montreal, Québec, #Canada#},
  isbn = {0-412-73270-X},
  editor = {Gregor von Bochmann and Rachida Dssouli and Omar Rafiq},
  volume = {43},
  series = {IFIP Conference Proceedings},
  publisher = {Chapman \& Hall},
  papers-accepted = {26},
  papers-submitted = {74},
  promoter = {IFIP}
}

@BOOK{Boehm-etal:2005,
  title = {Foundations of Empirical Software Engineering: The Legacy of Victor R. Basili},
  publisher = {Springer-Verlag},
  year = {2005},
  editor = {Barry Boehm and Hans Dieter Rombach and Marvin V. Zelkowitz},
  pages = {431},
  address = {Germany},
  month = jan,
  owner = {magsilva},
  timestamp = {2010.08.09}
}

@PROCEEDINGS{procedings:oss:2009,
  booktitle = {5th IFIP WG 2.13 International Conference on Open Source Systems},
  title = {5th IFIP WG 2.13 International Conference on Open Source Systems},
  year = {2009},
  month = jun,
  days = {3--6},
  location = {Skövde, #Sweden#},
  isbn = {978-3-642-02031-5},
  editor = {Boldyreff, Cornelia and Crowston, Kevin and Lundell, Björn and Wasserman, AnthonyI.},
  volume = {299},
  series = {IFIP Advances in Information and Communication Technology},
  publisher = {Springer Berlin Heidelberg},
  owner = {magsilva},
  timestamp = {2014.05.29}
}

@PROCEEDINGS{proceedings:sbes:2009,
  booktitle = {23rd Brazilian Symposium on Software Engineering},
  title = {23rd Brazilian Symposium on Software Engineering},
  year = {2009},
  month = oct,
  days = {5-9},
  location = {Fortaleza, CE, Brazil},
  isbn = {978-0-7695-3844-0},
  editor = {Paulo Borba},
  series = {Brazilian Symposium on Software Engineering},
  address = {Los Alamitos, California, USA},
  publisher = {IEEE Computer Society},
  papers-accepted = {24},
  papers-submitted = {122},
  promoter = {SBC, ACM-SIGSOFT},
  title-en = {23rd Brazilian Symposium on Software Engineering},
  title-pt = {XXIII Simpósio Brasileiro de Engenharia de Software}
}

@PROCEEDINGS{proceedings:sbes:1997,
  booktitle = {9th Brazilian Symposium on Software Engineering},
  title = {9th Brazilian Symposium on Software Engineering},
  year = {1997},
  month = oct,
  days = {15-17},
  location = {Fortaleza, CE, Brazil},
  editor = {Marcos Borges},
  series = {Brazilian Symposium on Software Engineering},
  organization = {UFC, UECE, CEFET-CE},
  owner = {Marco Aurélio},
  papers-accepted = {28},
  papers-submitted = {104},
  promoter = {SBC},
  timestamp = {2011.05.09},
  title-en = {9th Brazilian Symposium on Software Engineering},
  title-pt = {XI Simpósio Brasileiro de Engenharia de Software}
}

@PROCEEDINGS{proceedings:sbes-tools:1997,
  booktitle = {9th Brazilian Symposium on Software Engineering -- 4th Tools Session},
  title = {9th Brazilian Symposium on Software Engineering -- 4th Tools Session},
  year = {1997},
  month = oct,
  days = {15-17},
  location = {Fortaleza, CE, Brazil},
  editor = {Marcos Borges},
  series = {Brazilian Symposium on Software Engineering -- Tools Session},
  organization = {UFC, UECE, CEFET-CE},
  owner = {Marco Aurélio},
  papers-accepted = {10},
  promoter = {SBC},
  timestamp = {2011.05.09},
  title-en = {9th Brazilian Symposium on Software Engineering -- 4th Tools Session},
  title-pt = {XI Simpósio Brasileiro de Engenharia de Software -- IV Sessão de Ferramentas}
}

@BOOK{Botturi-Stubbs:2008,
  title = {Handbook of Visual Languages for Instructional Design: Theories and Practices},
  publisher = {Information Science Reference},
  year = {2008},
  editor = {Luca Botturi and Todd Stubbs},
  isbn = {9781599047317},
  pages = {405},
  address = {EUA},
  month = jan,
  abstract = {The more complex instructional design (ID) projects grow, the more a design language can support the success of the projects, and the continuing process of integration of technologies in education makes this issue even more relevant. The Handbook of Visual Languages for Instructional Design: Theories & Practices serves as a practical guide for the integration of ID languages and notation systems into the practice of ID by presenting recent languages and notation systems for ID; exploring the connection between the use of ID languages and the integration of technologies in education, and assessing the benefits and drawbacks of the use of ID languages in specific project settings.},
  booktitle = {Handbook of Visual Languages for Instructional Design: Theories and Practices},
  lang = {en}
}

@BOOK{Broy-Denert:2002,
  title = {Software Pioneers: Contributions to Software Engineering},
  publisher = {Springer},
  year = {2002},
  editor = {Manfrey Broy and Ernst Denert},
  isbn = {3540430814},
  pages = {728},
  address = Germany,
  edition = {1},
  abstract = {This book, including four DVDs, presents epochal works of 16 of the most influential software pioneers. Seminal historical papers, going bak as far as the 1950s, are complemented by new essays specifically written by the software pioneers today in retrospective to their ground breaking work for inclusion in this book. The volume is based on a conference organized by sd&m in Bonn, Germany, June 2001, where the pioneers met and presented their assessment of the past, new ideas, and visions for the future. The volume editors coherently integrated the historical contributions with current aspects and future perspectives. The four DVDs included are an important supplement to the book providing more than 12 hours of video documentation of the pioneers' lectures. Besides a representative overview drawing together the highlights of the presentations, a video recording of each pioneer's talk together with the transparencies used is contained. Together, the book and the four DVDs constitute a unique and major contribution to the history of software engineering.},
  booktitle = {Software Pioneers: Contributions to Software Engineering}
}

@PROCEEDINGS{proceedings:doceng:2008,
  booktitle = {8th Symposium on Document Engineering},
  year = {2008},
  month = sep,
  days = {16--19},
  location = {São Paulo, SP, Brazil},
  isbn = {978-1-60558-081-4},
  editor = {Dick C. A. Bulterman and Luiz Fernando G. Soares and Maria da Graça Campos Pimentel},
  series = {DocEng},
  publisher = {ACM},
  organization = {USP, PUC-Rio, CWI},
  pages = {302},
  papers-accepted = {21},
  papers-submitted = {62},
  promoter = {ACM SIGWEB, ACM SIGDOC}
}

@PROCEEDINGS{proceedings:sbes:2004,
  booktitle = {18th Brazilian Symposium on Software Engineering},
  title = {18th Brazilian Symposium on Software Engineering},
  year = {2004},
  month = oct,
  days = {18-22},
  location = {Brasília, DF, Brazil},
  isbn = {85-7669-002-0},
  editor = {Jaelson Freire Brelaz de Castro},
  series = {Brazilian Symposium on Software Engineering},
  organization = {UFPE, UnB},
  papers-accepted = {18},
  papers-submitted = {133},
  promoter = {SBC, ACM SIGSOFT},
  title-en = {18th Brazilian Symposium on Software Engineering},
  title-pt = {XVIII Simpósio Brasileiro de Engenharia de Software}
}

@PROCEEDINGS{proceedings:sbes:1995,
  booktitle = {9th Brazilian Symposium on Software Engineering},
  title = {9th Brazilian Symposium on Software Engineering},
  year = {1995},
  month = oct,
  days = {3-6},
  location = {Recife, PE, Brazil},
  editor = {Jaelson Freire Brelaz de Castro},
  number = {9},
  series = {Brazilian Symposium on Software Engineering},
  address = {Recife, PE, Brazil},
  publisher = {DI-UFPE},
  organization = {DI-UFPE},
  papers-accepted = {23},
  papers-submitted = {76},
  promoter = {DI-UFPE, SBC},
  title-en = {9th Brazilian Symposium on Software Engineering},
  title-pt = {IX Simpósio Brasileiro de Engenharia de Software}
}

@PROCEEDINGS{proceedings:sbes-tools:1995,
  booktitle = {9th Brazilian Symposium on Software Engineering -- 2nd Tools Session},
  title = {9th Brazilian Symposium on Software Engineering -- 2nd Tools Session},
  year = {1995},
  month = oct,
  days = {3-6},
  location = {Recife, PE, Brazil},
  editor = {Jaelson Freire Brelaz de Castro},
  number = {9},
  series = {Brazilian Symposium on Software Engineering -- Tools Session},
  address = {Recife, PE, Brazil},
  publisher = {DI-UFPE},
  organization = {DI-UFPE},
  papers-accepted = {13},
  promoter = {DI-UFPE, SBC},
  title-en = {9th Brazilian Symposium on Software Engineering -- 2nd Tools Session},
  title-pt = {IX Simpósio Brasileiro de Engenharia de Software -- II Sessão de Ferramentas}
}

@PROCEEDINGS{proceedings:euroitv:2007,
  booktitle = {EuroITV -- Interactive TV: a Shared Experience},
  year = {2007},
  month = may,
  days = {24--25},
  location = {Amsterdam, #Netherlands#},
  isbn = {978-3-540-72558-9},
  editor = {Cesar, Pablo and Chorianopoulos, Konstantinos and Jensen, Jens},
  volume = {4471},
  series = {Lecture Notes in Computer Science},
  publisher = {Springer},
  issn = {1456-2774}
}

@PROCEEDINGS{proceedings:sbes-tools:2003,
  booktitle = {17th Brazilian Symposium on Software Engineering -- 10th Tools Session},
  title = {17th Brazilian Symposium on Software Engineering -- 10th Tools Session},
  year = {2003},
  month = oct,
  days = {8-9},
  location = {Manaus, AM, Brazil},
  isbn = {85-7401-122-3},
  editor = {Nabor das Chagas Mendonça},
  series = {Brazilian Symposium on Software Engineering -- Tools Session},
  organization = {UFAM},
  papers-accepted = {16},
  papers-submitted = {54},
  promoter = {SBC, ACM SIGSOFT},
  title-en = {17th Brazilian Symposium on Software Engineering -- 10th Tools Session},
  title-pt = {XVII Simpósio Brasileiro de Engenharia de Software -- X Sessão de Ferramentas}
}

@PROCEEDINGS{proceedings:sbes-tools:2002,
  booktitle = {16th Brazilian Symposium on Software Engineering -- 9th Tools Session},
  title = {16th Brazilian Symposium on Software Engineering -- 9th Tools Session},
  year = {2002},
  month = oct,
  days = {16-18},
  location = {Gramado, RS, Brazil},
  editor = {Nabor das Chagas Mendonça},
  series = {Brazilian Symposium on Software Engineering -- Tools Session},
  organization = {UFAM},
  papers-accepted = {16},
  papers-submitted = {54},
  promoter = {SBC, ACM SIGSOFT},
  title-en = {16th Brazilian Symposium on Software Engineering -- 9th Tools Session},
  title-pt = {XVI Simpósio Brasileiro de Engenharia de Software -- IX Sessão de Ferramentas}
}

@PROCEEDINGS{proceedings:sbes-tools:2008,
  booktitle = {22nd Brazilian Symposium on Software Engineering -- 15th Tools Session},
  title = {22nd Brazilian Symposium on Software Engineering -- 15th Tools Session},
  year = {2008},
  month = oct,
  days = {13-17},
  location = {Campinas, SP, Brazil},
  isbn = {978-85-7669-201-0},
  editor = {Marcos Lordello Chaim},
  series = {Brazilian Symposium on Software Engineering -- Tools Session},
  organization = {Unicamp},
  promoter = {SBC, ACM-SIGSOFT},
  title-en = {22nd Brazilian Symposium on Software Engineering -- 15th Tools Session},
  title-pt = {XXII Simpósio Brasileiro de Engenharia de Software}
}

@PROCEEDINGS{proceedings:cascon:2008,
  booktitle = {2008 Conference of the Center for Advanced Studies on Collaborative Research: Meeting of Minds},
  title = {2008 Conference of the Center for Advanced Studies on Collaborative Research: Meeting of Minds},
  year = {2008},
  month = oct,
  location = {Richmond Hill, Ontario, #Canada#},
  editor = {Marsha Chechik and Mark R. Vigder and Darlene A. Stewart},
  address = {New York, NY, } # USA,
  publisher = {ACM},
  accepted-papers = {23},
  day = {27--30},
  submitted-papers = {73}
}

@PROCEEDINGS{proceedings:www:2003,
  booktitle = {Twelfth International World Wide Web Conference},
  title = {International World Wide Web Conference},
  year = {2003},
  month = may,
  days = {20-24},
  location = {Budapest, Hungary},
  editor = {Yih-Farn Robin Chen and László Kovács and Steve Lawrence},
  series = {International World Wide Web Conference},
  organization = {International World Wide Web Conference Committee (IW3C2) and Computer and Automation Research Institute of the Hungarian Academy of Sciences (MTA SZTAKI)},
  papers-accepted = {77},
  papers-submitted = {602}
}

@PROCEEDINGS{proceedings:xp:2007,
  booktitle = {8th International Conference on Agile Software Development},
  title = {8th International Conference on Agile Software Development},
  year = {2007},
  month = jun,
  days = {18--22},
  location = {Como, #Italy#},
  isbn = {978-3-540-73100-9},
  editor = {Concas, Giulio and Damiani, Ernesto and Scotto, Marco and Succi, Giancarlo},
  volume = {4536},
  series = {Lecture Notes in Computer Science},
  publisher = {Springer Berlin Heidelberg},
  owner = {magsilva},
  timestamp = {2014.10.20}
}

@BOOK{Dhal-etal:1972,
  publisher = {Academic Press},
  year = {1972},
  editor = {Dahl, O. J. and Dijkstra, E. W. and Hoare, C. A. R.},
  isbn = {0-12-200550-3},
  address = {London, UK, UK},
  booktitle = {Structured Programming}
}

@PROCEEDINGS{proceedings:sbes-tools:2006,
  booktitle = {20th Brazilian Symposium on Software Engineering -- 13th Tools Session},
  title = {20th Brazilian Symposium on Software Engineering -- 13th Tools Session},
  year = {2006},
  month = oct,
  days = {18--20},
  location = {Florianópolis, SC, Brazil},
  isbn = {85-7669-079-9, 85-7669-081-0},
  editor = {Márcio Eduardo Delamaro},
  series = {Brazilian Symposium on Software Engineering -- Tools Session},
  organization = {UFSC, IDESTI},
  papers-accepted = {25},
  papers-submitted = {60},
  promoter = {SBC, ACM SIGSOFT},
  title-en = {20th Brazilian Symposium on Software Engineering -- 13th Tools Session},
  title-pt = {XX Simpósio Brasileiro de Engenharia de Software -- XXIII Sessão de Ferramentas}
}

@PROCEEDINGS{proceedings:sbes-tools:1999,
  booktitle = {13th Brazilian Symposium on Software Engineering -- 6th Tools Session},
  title = {13th Brazilian Symposium on Software Engineering -- 6th Tools Session},
  year = {1999},
  month = oct,
  days = {13-15},
  location = {Florianópolis, SC, Brazil},
  editor = {Márcio Eduardo Delamaro and Murilo Silva de Camargo},
  series = {Brazilian Symposium on Software Engineering -- Tools Session},
  organization = {UEM, UFSC},
  abstract = {Primeiramente, gostaríamos, em nome de toda a Comissão Organizadora, de saudar os participantes do XIII Simpósio Brasileiro de Engenharia de Software (SBES'99). O SBES é um evento promovido anualmente pela SBC - Sociedade Brasileira de Computação através da Comissão Especial de Engenharia de Software e organizado por uma Universidade. O SBES tem como objetivo a criação de um fórum para a discussão de temas de pesquisa, desenvolvimento e serviços na área de Engenharia de Software, congregando pesquisadores brasileiros e estrangeiros, como também profissionais com interesse no assunto. Este ano o SBES está sendo realizado em Florianópolis, Santa Catarina e co-organizado pelo Departamento de Informática e de Estatística da Universidade Federal de Santa Catarina e pelo Instituto de Informática da Universidade Federal do Rio Grande do Sul. Para o SBES'99 foram submetidos 100 artigos do Brasil e do exterior. Os artigos foram avaliados pelo Comitê de Programa do SBES o qual se constituiu de 30 pesquisadores dos principais centros de pesquisa em Engenharia de Software do Brasil e de 11 pesquisadores de centros de grande prestígio do exterior. Dos artigos submetidos, 94 foram originados do Brasil dos seguintes estados: Pernambuco (6), Pará (2), Rio Grande do Sul (18), São Paulo (28), Rio de Janeiro (18), Santa Catarina (8), Paraná (4), Minas Gerais (2), Paraíba (2), Ceará (1), Maranhão (3) e Espírito Santo (2). Do total, 6 artigos foram provenientes do exterior: Inglaterra (1), EUA (1), Tunisia (1), Canadá (1), Singapura (1) e México (1). Dos 100 artigos submetidos, 26 foram selecionados para apresentação e encontram-se publicados nestes anais, em ordem de apresentação. Além destes, há também duas palestras convidadas internacionais. Cada artigo foi submetido a três avaliadores. Após análise pelo Steering Committee, alguns artigos, em que a precisão/profundidade da avaliação poderia comprometer o resultado, foram avaliados por um quarto avaliador. Aqueles artigos onde se percebeu falta de harnonia nos conceitos atribuídos foram devolvidos aos avaliadores para, em conjunto, encontrar consenso. Tornadas as avaliações homogêneas, e após um processo interativo, o Steering Committee aprovou proposta da Coordenação, selecionando os 26 melhores artigos. A realização deste evento contou com o apoio financeiro do CNPq, CAPES e da Sterling Software. Os apoios dados pela direção do Centro Tecnológico da Universidade Federal de Santa Catarina, bem como pela administração da UFSC foram fundamentais para a viabilização do SBES'99. Agradecemos aos membros do Comitê de Programa cuja qualidade do trabalho reflete-se no conteúdo destes anais. Todo nosso reconhecimento aos mebros do Comitê de Organização, aos alunos do PET/CCO/UFSC e do curso de Bacharelado em Ciência da Computação da UFSC cujos esforços e trabalho tornaram possível a realização deste Simpósio. Finalmente, agradecemos a cada um dos participantes, que com sua presença contribuiu para o sucesso do SBES'99.},
  articles-accepted = {26},
  articles-submitted = {100},
  papers-accepted = {16},
  papers-submitted = {22},
  promoter = {SBC},
  title-en = {13th Brazilian Symposium on Software Engineering -- 6th Tools Session},
  title-pt = {XIII Simpósio Brasileiro de Engenharia de Software -- VI Sessão de Ferramentas}
}

@BOOK{DiBona-Ockman:1999,
  title = {Open Sources: Voices from the Open Source Revolution},
  publisher = {O'Reilly Media},
  year = {1999},
  editor = {Chris DiBona and Sam Ockman},
  isbn = {978-1-56592-582-3},
  e-isbn = {978-0-596-15301-4},
  pages = {288},
  series = {Open Source Software Development},
  month = jan,
  booktitle = {Open Sources: Voices from the Open Source Revolution},
  timestamp = {2012.01.23}
}

@PROCEEDINGS{conference:iccs:2008,
  booktitle = {ICCS Supplement},
  title = {Supplementary Proceedings of the 16th International Conference on Conceptual Structures (ICCS 2008)},
  year = {2008},
  month = jul,
  editor = {Peter W. Eklund and Ollivier Haemmerlé},
  volume = {354},
  series = {CEUR Workshop Proceedings},
  address = {Toulouse, France},
  publisher = {CEUR-WS.org},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}

@PROCEEDINGS{proceedings:sbes-tools:2009,
  booktitle = {23rd Brazilian Symposium on Software Engineering -- 16th Tools Session},
  title = {23rd Brazilian Symposium on Software Engineering -- 16th Tools Session},
  year = {2009},
  month = oct,
  days = {5-9},
  location = {Fortaleza, CE, Brazil},
  isbn = {978-0-7695-3844-0},
  editor = {Glêdson Elias},
  series = {Brazilian Symposium on Software Engineering -- Tools Session},
  address = {Los Alamitos, California, USA},
  publisher = {IEEE Computer Society},
  organization = {UFPB},
  papers-accepted = {12},
  papers-submitted = {32},
  promoter = {SBC, ACM-SIGSOFT},
  title-en = {23rd Brazilian Symposium on Software Engineering -- 16th Tools Session},
  title-pt = {XXIII Simpósio Brasileiro de Engenharia de Software -- XVI Sessão de Ferramentas}
}

@PROCEEDINGS{proceedings:sofsem:2013,
  booktitle = {39th Internacional Conference on Current Trends in Theory and Practice of Computer Science},
  year = {2013},
  month = jan,
  location = {#Cezch#},
  isbn = {978-3-642-35842-5},
  editor = {Emde Boas, Peter and Groen, FransC.A. and Italiano, GiuseppeF. and Nawrocki, Jerzy and Sack, Harald},
  volume = {7741},
  series = {Lecture Notes in Computer Science},
  publisher = {Springer Berlin Heidelberg},
  day = {26--31},
  timestamp = {2013-08-08}
}

@PROCEEDINGS{proceedings:fie:1998,
  booktitle = {28th Annual Frontiers in Education},
  title = {Frontiers in Education},
  year = {1998},
  month = nov,
  days = {4-7},
  location = {Tempe, AZ, USA},
  isbn = {0-7803-4762-5},
  editor = {Don Evans},
  series = {Frontiers in Education},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  organization = {Center for Innovation in Engineering Education (Arizona State University)}
}

@PROCEEDINGS{proceedings:sibgrapi:2007,
  booktitle = {XX Brazilian Symposium on Computer Graphics and Image Processing},
  title = {Brazilian Symposium on Computer Graphics and Image Processing},
  year = {2007},
  month = oct,
  days = {7-10},
  location = {Belo Horizonte, MG, Brazil},
  isbn = {978-0-7695-2996-8},
  e-isbn = {978-0-7695-2996-7},
  editor = {Alexandre Falcão and Hélio Lopes},
  address = {Los Alamitos, CA, EUA},
  publisher = {IEEE Computer Society},
  issn = {1530-1834},
  papers-accepted = {40},
  papers-submitted = {120},
  promoter = {SBC and {PUC Minas}},
  url = {http://www.inf.pucminas.br/sibgrapi2007/}
}

@PROCEEDINGS{proceedings:webmedia:2008,
  booktitle = {14th Brazilian Symposium on Multimedia and the Web},
  year = {2008},
  month = oct,
  days = {26--29},
  location = {Vila Velha, ES, #Brazil#},
  isbn = {978-85-7669-199-0},
  editor = {José Gonçalves Pereira Filho and Roberta Lima Gomes and Marco Aurélio Gerosa and Renata Silva Souza Guizzardi},
  series = {WebMedia},
  publisher = {ACM},
  papers-accepted = {32},
  papers-submitted = {120}
}

@PROCEEDINGS{proceedings:sose:2011,
  booktitle = {6th International Symposium on Service Oriented System Engineering},
  title = {6th International Symposium on Service Oriented System Engineering},
  year = {2011},
  month = dec,
  days = {11--14},
  location = {Irvine, CA, #USA#},
  isbn = {978-1-4673-0411-5, 978-1-4673-0410-8},
  editor = {Jerry Gao and Xiaodong Lu and Muhammad Younas and Hong Zhu},
  publisher = {IEEE Computer Society},
  papers-accepted = {19},
  papers-submitted = {57}
}

@PROCEEDINGS{proceedings:sbes:2011,
  booktitle = {25th Brazilian Symposium on Software Engineering},
  title = {25th Brazilian Symposium on Software Engineering},
  year = {2011},
  month = sep,
  days = {28-30},
  location = {São Paulo, SP, #Brazil#},
  isbn = {978-1-4577-2187-8},
  editor = {Alessandro Garcia},
  volume = {1},
  series = {Brazilian Symposium on Software Engineering},
  organization = {USP, Mackenzie},
  issn = {2175-9677},
  papers-accepted = {34},
  papers-submitted = {111},
  promoter = {SBC, ACM},
  title-en = {25th Brazilian Symposium on Software Engineering},
  title-pt = {XXV Simpósio Brasileiro de Engenharia de Software}
}

@BOOK{genero-etal:2005,
  title = {Metrics for Software Conceptual Models},
  publisher = {Imperial College Press},
  year = {2005},
  editor = {Marcela Genero and Mario Piattini and Coral Calero},
  isbn = {1-86094-497-3},
  address = {London, UK},
  edition = {1}
}

@BOOK{Glass:2006:book,
  title = {Software Creativity 2.0},
  publisher = {developer.*},
  year = {2006},
  editor = {Robert L. Glass},
  isbn = {978-0977213313},
  pages = {484},
  address = USA,
  edition = {2},
  month = dec,
  booktitle = {Software Creativity 2.0}
}

@PROCEEDINGS{proceedings:icse:2012,
  booktitle = {34th International Conference on Software Engineering},
  title = {34th International Conference on Software Engineering},
  year = {2012},
  month = jun,
  days = {2--9},
  location = {Zurich, #Switzerland#},
  isbn = {978-1-4673-1067-3},
  e-isbn = {978-1-4673-1065-9},
  editor = {Martin Glinz and Gail Murphy and Mauro Pezzè},
  address = {Piscataway, NJ, } # USA,
  publisher = {IEEE/ACM},
  acmid = {2337253},
  issn = {0270-5257},
  papers-accepted = {87},
  papers-submitted = {408}
}

@PROCEEDINGS{proceedings:sbmidia:2002,
  booktitle = {Brazilian Symposium on Multimedia and Hypermedia Systems},
  title = {Brazilian Symposium on Multimedia and Hypermedia Systems},
  year = {2002},
  month = oct,
  days = {7-10},
  location = {Fortaleza, Ceará, Brazil},
  isbn = {858844238-8},
  editor = {Maria da Graça Campos Pimentel and Riverson Rios},
  volume = {1},
  publisher = {BNB},
  organization = {Fundação Edson Queiros (UFC)},
  pages = {416},
  papers-accepted = {23},
  papers-submitted = {41},
  promoter = {SBC},
  timestamp = {2012.01.27}
}

@PROCEEDINGS{proceedings:ace:2003,
  booktitle = {5th Australasian Conference on Computing Education},
  title = {5th Australasian Conference on Computing Education},
  year = {2003},
  month = feb,
  days = {4--7},
  location = {Adelaide, #Australia#},
  isbn = {0-909925-98-4},
  editor = {Tony Greening and Raymond Lister},
  address = {Darlinghurst, } # Australia,
  publisher = {Australian Computer Society}
}

@PROCEEDINGS{proceedings:icg:2007,
  booktitle = {CRIWG'07: Proceedings of the 13th international conference on Groupware: design implementation, and use},
  title = {CRIWG'07: Proceedings of the 13th international conference on Groupware: design implementation, and use},
  year = {2007},
  month = sep,
  location = {Bariloche, Argentina},
  isbn = {978-3-540-74811-3},
  editor = {Haake, Jörg M. and Ochoa, Sergio F. and Cechich, Alejandra},
  series = {International Conference on Groupware},
  address = {Berlin, Heidelberg},
  publisher = {Springer-Verlag},
  issn = {0302-9743},
  papers-accepted = {17},
  papers-submitted = {49}
}

@PROCEEDINGS{proceedings:ed-media:2010,
  booktitle = {{ED-MEDIA} 2010 -- World Conference on Educational Multimedia, Hypermedia and Telecommunications},
  title = {{ED-MEDIA} 2010 -- World Conference on Educational Multimedia, Hypermedia and Telecommunications},
  year = {2010},
  month = jun # {-} # jul,
  days = {29 -- 2},
  isbn = {1-880094-81-9},
  editor = {Jan Herrington and Bill Hunter},
  address = {Toronto, } # Canada,
  publisher = {AACE},
  papers-accepted = {247},
  papers-submitted = {381}
}

@PROCEEDINGS{proceedings:criwg:2012,
  booktitle = {Collaboration and Technology},
  title = {18th CRIWG International Conference on Collaboration and Technology},
  year = {2012},
  month = sep,
  location = {Duisburg, #Germany#},
  isbn = {978-3-642-33283-8},
  e-isbn = {978-3-642-33284-5},
  editor = {Herskovic, Valeria and Hoppe, H. Ulrich and Jansen, Marc and Ziegler, Jürgen},
  volume = {7493},
  series = {Lecture Notes in Computer Science},
  publisher = {Springer},
  day = {16--19}
}

@PROCEEDINGS{proceedings:issep:2010,
  booktitle = {4th International Conference on Informatics in Secondary Schools - Evolution and Perspectives},
  title = {4th International Conference on Informatics in Secondary Schools - Evolution and Perspectives},
  year = {2010},
  month = jan,
  days = {13--15},
  location = {Zurich, #Switzerland#},
  isbn = {978-3-642-11375-8},
  editor = {Hromkovic, Juraj and Královic, Richard and Vahrenhold, Jan},
  volume = {5941},
  series = {Lecture Notes in Computer Science},
  publisher = {Springer},
  owner = {magsilva},
  timestamp = {2014.07.17}
}

@PROCEEDINGS{proceedings:hicss:2000,
  booktitle = {33rd Annual Hawaii International Conference on System Sciences},
  year = {2000},
  month = jan,
  location = {Hawaii, #USA#},
  isbn = {0-7695-0493-0},
  editor = {IEEE},
  organization = {Hawai'i International Conference On System Sciences},
  day = {4--7}
}

@PROCEEDINGS{proceedings:am:1961,
  booktitle = {Symposia in Applied Mathematics},
  title = {Symposia in Applied Mathematics},
  year = {1961},
  location = {Providence, RI, #USA#},
  isbn = {978-0-8218-1312-6},
  editor = {R. Jakobson},
  volume = {12},
  publisher = {American Mathematical Society},
  owner = {magsilva},
  timestamp = {2014.07.15}
}

@BOOK{Keegan:1993,
  publisher = {Routledge},
  year = {1993},
  editor = {Desmond Keegan},
  isbn = {978-0415089425},
  pages = {288},
  edition = {1},
  month = nov,
  abstract = {According to UNESCO statistics, 10 million of the world's 600 million students study at a distance. Theoretical Principles of Distance Education seeks to lay solid foundations for the education of these students and for the structures within which they study. As a more industrialised form of education provision, distance education is well adapted to the use of new communication technologies, and brings to education many of the strengths and dangers of post-industrialism. The central focus of the study of distance education is the placing of the student at home or at work and the justification of the abandonment in this form of education of interpersonal, face-to-face communication, previously considered to be a cultural imperative for education in both east and west. This book explores the problems that distance education poses to the theorist, bringing together an international team of distance educators to address these issues for the first time in a systematic way. The team comprises theoreticians, administrators, experts in educational technology and adult education, experts in learning from video machines, from computers and other forms of technology. Contributions from Italy, and Scandinavia contrast with viewpoints provided by scholars from the US, Canada, Australia, and the UK.},
  booktitle = {Theoretical Principles of Distance Education}
}

@BOOK{Koper-Tattersall:2005,
  title = {Learning Design: A Handbook on Modelling and Delivering Networked Education and Training},
  publisher = {Springer},
  year = {2005},
  editor = {Rob Koper and Colin Tattersall},
  isbn = {3-540-22814-4},
  pages = {412},
  address = {Países Baixos},
  edition = {1},
  booktitle = {Learning Design},
  owner = {magsilva}
}

@PROCEEDINGS{proceedings:sbes-tools:2010,
  booktitle = {24th Brazilian Symposium on Software Engineering -- 17th Tools Session},
  title = {24th Brazilian Symposium on Software Engineering -- 17th Tools Session},
  year = {2010},
  month = sep,
  days = {27-1},
  location = {Salvador, BA, Brazil},
  editor = {Uirá Kulesza},
  volume = {4},
  series = {Brazilian Symposium on Software Engineering -- Tools Session},
  organization = {DCC-UFBA},
  issn = {2178-6097},
  papers-accepted = {16},
  papers-submitted = {39},
  promoter = {SBC},
  title-en = {24th Brazilian Symposium on Software Engineering -- 17th Tools Session},
  title-pt = {XXIV Simpósio Brasileiro de Engenharia de Software -- XVII Sessão de Ferramentas}
}

@PROCEEDINGS{proceedings:sbes-tools:1994,
  booktitle = {8th Brazilian Symposium on Software Engineering -- 1st Tools Session},
  title = {8th Brazilian Symposium on Software Engineering -- 1st Tools Session},
  year = {1994},
  month = oct,
  days = {25-28},
  location = {Curitiba, PR, Brazil},
  editor = {José Carlos Maldonado},
  series = {Brazilian Symposium on Software Engineering},
  organization = {CITS, PUC-PR, UFRGS},
  owner = {Marco Aurélio},
  papers-accepted = {9},
  promoter = {SBC},
  timestamp = {2011.05.17},
  title-en = {8th Brazilian Symposium on Software Engineering -- Tools Session},
  title-pt = {VIII Simpósio Brasileiro de Engenharia de Software -- Sessão de Ferramentas}
}

@PROCEEDINGS{proceedings:sbes-tools:1993,
  booktitle = {7th Brazilian Symposium on Software Engineering -- Tools Session},
  title = {7th Brazilian Symposium on Software Engineering -- Tools Session},
  year = {1993},
  month = oct,
  days = {27-29},
  location = {Rio de Janeiro, RJ, Brazil},
  editor = {José Carlos Maldonado},
  series = {Brazilian Symposium on Software Engineering -- Tools Session},
  organization = {DI/PUC-Rio},
  papers-accepted = {20},
  promoter = {SBC},
  title-en = {7th Brazilian Symposium on Software Engineering -- Tools Session},
  title-pt = {VII Simpósio Brasileiro de Engenharia de Software -- Caderno de Ferramentas}
}

@PROCEEDINGS{proceedings:sbes:1996,
  booktitle = {10th Brazilian Symposium on Software Engineering},
  title = {10th Brazilian Symposium on Software Engineering},
  year = {1996},
  month = oct,
  days = {14-18},
  location = {São Carlos, SP, Brazil},
  editor = {José Carlos Maldonado and Paulo Cesar Masiero},
  series = {Brazilian Symposium on Software Engineering},
  organization = {ICMC/USP, UFScar},
  owner = {Marco Aurélio},
  papers-accepted = {21},
  papers-submitted = {66},
  promoter = {SBC},
  timestamp = {2011.05.17},
  title-en = {10th Brazilian Symposium on Software Engineering},
  title-pt = {X Simpósio Brasileiro de Engenharia de Software}
}

@PROCEEDINGS{proceedings:xp:2003,
  booktitle = {3rd XP and 2nd Agile Universe Conference},
  title = {3rd XP and 2nd Agile Universe Conference},
  year = {2003},
  month = aug,
  days = {10--13},
  location = {New Orleans, LA, #USA#},
  isbn = {978-3-540-40215-2},
  editor = {Marchesi, Michele and Succi, Giancarlo},
  volume = {2675},
  series = {Lecture Notes in Computer Science},
  publisher = {Springer Berlin Heidelberg},
  owner = {magsilva},
  timestamp = {2014.10.21}
}

@PROCEEDINGS{proceedings:isola:2010,
  booktitle = {4th International Symposium on Leveraging Applications},
  title = {4th International Symposium on Leveraging Applications,},
  year = {2010},
  month = oct,
  location = {Heraklion, #Greece#},
  isbn = {978-3-642-16557-3},
  e-isbn = {978-3-642-16558-0},
  editor = {Margaria, Tiziana and Steffen, Bernhard},
  volume = {6415},
  series = {Lecture Notes in Computer Science},
  publisher = {Springer},
  day = {18--21}
}

@PROCEEDINGS{proceedings:wer:2003,
  booktitle = {6th International Workshop on Requirements Engineering},
  title = {6th International Workshop on Requirements Engineering},
  year = {2003},
  month = nov,
  days = {27-28},
  location = {Piracicaba, SP, Brazil},
  isbn = {85-87926-07-1},
  editor = {Luiz Eduardo Galvão Martins and Xavier Franch},
  series = {International Workshop on Requirements Engineering},
  organization = {PUC-Rio, UNIMEP, UPC, PUCRS},
  papers-accepted = {22},
  papers-submitted = {35}
}

@PROCEEDINGS{proceedings:sbes:2006,
  booktitle = {20th Brazilian Symposium on Software Engineering},
  title = {20th Brazilian Symposium on Software Engineering},
  year = {2006},
  month = oct,
  days = {16--20},
  location = {Florianópolis, SC, #Brazil#},
  isbn = {85-7669-079-9},
  editor = {Paulo Cesar Masiero},
  series = {Brazilian Symposium on Software Engineering},
  organization = {UFSC, IDESTI},
  papers-accepted = {20},
  papers-submitted = {134},
  promoter = {SBC, ACM SIGSOFT},
  title-en = {20th Brazilian Symposium on Software Engineering},
  title-pt = {XX Simpósio Brasileiro de Engenharia de Software}
}

@PROCEEDINGS{proceedings:sbes:1990,
  booktitle = {4th Brazilian Symposium on Software Engineering},
  title = {4th Brazilian Symposium on Software Engineering},
  year = {1990},
  month = oct,
  days = {24--26},
  location = {Águas de São Pedro, SP, Brazil},
  editor = {Paulo Cesar Masiero},
  series = {Brazilian Symposium on Software Engineering},
  papers-accepted = {18},
  papers-submitted = {70},
  promoter = {SBC, ICMC-USP},
  title-en = {4th Brazilian Symposium on Software Engineering},
  title-pt = {IV Simpósio Brasileiro de Engenharia de Software}
}

@BOOK{Massarani-etal:2002,
  title = {Ciência e público: caminhos da divulgação científica no Brasil},
  publisher = {Casa da Ciência -- Centro Cultural de Ciência e Tecnologia da Universidade Federal do Rio de Janeiro},
  year = {2002},
  editor = {Luisa Massarani and Lideu de Castro Moreira and Fatima Brito},
  isbn = {85-89229-01-7},
  volume = {1},
  pages = {232},
  series = {Série Terra Incógnita},
  address = {Rio de Janeiro, RJ, Brazil},
  edition = {1},
  chapter = {A educação formal e a educação informal em ciências},
  journal = {Terra Incógnita -- Ciência e Público},
  timestamp = {2008.10.10}
}

@PROCEEDINGS{proceedings:webmedia:2005,
  booktitle = {11th Brazilian Symposium on Multimedia and the Web},
  year = {2005},
  month = dec,
  days = {5--7},
  location = {Poços de Caldas, MG, #Brazil#},
  editor = {Renata Pontin de Mattos Fortes},
  series = {WebMedia},
  publisher = {ACM},
  papers-accepted = {31},
  papers-submitted = {100}
}

@PROCEEDINGS{proceedings:seek:2004,
  booktitle = {6th International Conference on Software Engineering \& Knowledge Engineering (SEEK)},
  title = {6th International Conference on Software Engineering \& Knowledge Engineering (SEEK)},
  year = {2004},
  month = jun,
  days = {20--24},
  location = {Banff, Alberta, #Canada#},
  isbn = {1-891706-14-4},
  editor = {Frank Maurer and Günther Ruhe}
}

@PROCEEDINGS{proceedings:sbes:1989,
  booktitle = {3rd Brazilian Symposium on Software Engineering},
  title = {3rd Brazilian Symposium on Software Engineering},
  year = {1989},
  month = oct,
  location = {Recife, PE, Brazil},
  editor = {Silvio R. L. Meira},
  series = {Brazilian Symposium on Software Engineering},
  owner = {magsilva},
  papers-accepted = {23},
  papers-submitted = {64},
  title-en = {3rd Brazilian Symposium on Software Engineering},
  title-pt = {III Simpósio Brasileiro de Engenharia de Software}
}

@PROCEEDINGS{proceedings:sbes:2008,
  booktitle = {22nd Brazilian Symposium on Software Engineering},
  title = {22nd Brazilian Symposium on Software Engineering},
  year = {2008},
  month = oct,
  days = {13--17},
  location = {Campinas, SP, Brazil},
  isbn = {978-85-7669-201-0},
  editor = {Manoel Gomes de Mendonça Neto},
  series = {Brazilian Symposium on Software Engineering},
  publisher = {SBC},
  organization = {UNICAMP},
  pages = {374},
  papers-accepted = {22},
  papers-submitted = {113},
  promoter = {SBC, ACM-SIGSOFT},
  title-en = {22nd Brazilian Symposium on Software Engineering},
  title-pt = {XXII Simpósio Brasileiro de Engenharia de Software}
}

@PROCEEDINGS{proceedings:ecoop:2011,
  booktitle = {25th European conference on Object-oriented programming},
  year = {2011},
  location = {Lancaster, #UK#},
  isbn = {978-3-642-22654-0},
  editor = {Mezini, Mira},
  volume = {6813},
  series = {Lecture Notes in Computer Science},
  address = {Berlin,} # Germany,
  publisher = {Springer-Verlag},
  timestamp = {2013-08-04}
}

@BOOK{Moore-Anderson:2003,
  publisher = {Lawrence Erlbaum},
  year = {2003},
  editor = {Michael Grahame Moore and William G. Anderson},
  isbn = {0-8058-3924-0},
  pages = {817},
  address = {Mahwah, NJ, EUA},
  edition = {1},
  booktitle = {Handbook of distance education}
}

@PROCEEDINGS{proceedings:sbes-tools:2005,
  booktitle = {19th Brazilian Symposium on Software Engineering -- 12th Tools session},
  title = {19th Brazilian Symposium on Software Engineering -- 12th Tools session},
  year = {2005},
  month = oct,
  days = {3-7},
  location = {Uberlândia, MG, Brazil},
  isbn = {85-7669-030-6},
  editor = {Hermano Perrelli de Moura},
  series = {Brazilian Symposium on Software Engineering -- Tools Session},
  address = {Uberlândia, MG, Brasil},
  organization = {UFU},
  owner = {olivrap},
  papers-accepted = {12},
  papers-submitted = {35},
  promoter = {SBC, ACM SIGSOFT},
  timestamp = {2011.05.25},
  title-en = {19th Brazilian Symposium on Software Engineering -- 12th Tools session},
  title-pt = {19° Simpósio Brasileiro de Engenharia de Software -- 12ª Sessão de Ferramentas}
}

@PROCEEDINGS{proceedings:ec-tel:2006,
  booktitle = {First European Conference on Technology Enhanced Learning (EC-TEL): Innovative Approaches for Learning and Knowledge Sharing},
  year = {2006},
  month = oct,
  days = {1 -- 4},
  location = {Crete, #Greece#},
  isbn = {978-3-540-45777-0},
  editor = {Nejdl, Wolfgang and Tochtermann, Klaus},
  volume = {4227},
  series = {Lecture Notes in Computer Science},
  publisher = {Springer}
}

@PROCEEDINGS{proceedings:JCDL:2011,
  booktitle = {International Joint Conference on Digital Libraries},
  title = {International Joint Conference on Digital Libraries},
  year = {2011},
  month = jun,
  days = {13-17},
  location = {Ottawa, ON, Canadá},
  isbn = {978-1-4503-0744-4},
  editor = {Glen Newton and Michael Wright and Lillian N. Cassel},
  address = {Ottawa, ON, Canadá},
  publisher = {ACM, IEEE}
}

@BOOK{Nielsen-Mack:1994,
  title = {Usability Inspection Methods},
  publisher = {John Wiley \& Sons},
  year = {1994},
  editor = {Jakob Nielsen and Robert L. Mack},
  isbn = {978-0471018773},
  pages = {448},
  address = {New York, NY, EUA},
  edition = {1},
  booktitle = {Usability Inspection Methods}
}

@PROCEEDINGS{proceedings:sbes:1999,
  booktitle = {13th Brazilian Symposium on Software Engineering},
  title = {13th Brazilian Symposium on Software Engineering},
  year = {1999},
  month = oct,
  days = {13-15},
  location = {Florianópolis, SC, Brazil},
  editor = {Daltro José Nunes and Murilo Silva de Camargo},
  volume = {1},
  series = {Brazilian Symposium on Software Engineering},
  organization = {Departamento de Informática e de Estatística - Universidade Federal de Santa Catarina e Instituto de Informática - Universidade Federal do Rio Grande do Sul.},
  abstract = {Primeiramente, gostaríamos, em nome de toda a Comissão Organizadora, de saudar os participantes do XIII Simpósio Brasileiro de Engenharia de Software (SBES'99). O SBES é um evento promovido anualmente pela SBC - Sociedade Brasileira de Computação através da Comissão Especial de Engenharia de Software e organizado por uma Universidade. O SBES tem como objetivo a criação de um fórum para a discussão de temas de pesquisa, desenvolvimento e serviços na área de Engenharia de Software, congregando pesquisadores brasileiros e estrangeiros, como também profissionais com interesse no assunto. Este ano o SBES está sendo realizado em Florianópolis, Santa Catarina e co-organizado pelo Departamento de Informática e de Estatística da Universidade Federal de Santa Catarina e pelo Instituto de Informática da Universidade Federal do Rio Grande do Sul. Para o SBES'99 foram submetidos 100 artigos do Brasil e do exterior. Os artigos foram avaliados pelo Comitê de Programa do SBES o qual se constituiu de 30 pesquisadores dos principais centros de pesquisa em Engenharia de Software do Brasil e de 11 pesquisadores de centros de grande prestígio do exterior. Dos artigos submetidos, 94 foram originados do Brasil dos seguintes estados: Pernambuco (6), Pará (2), Rio Grande do Sul (18), São Paulo (28), Rio de Janeiro (18), Santa Catarina (8), Paraná (4), Minas Gerais (2), Paraíba (2), Ceará (1), Maranhão (3) e Espírito Santo (2). Do total, 6 artigos foram provenientes do exterior: Inglaterra (1), EUA (1), Tunisia (1), Canadá (1), Singapura (1) e México (1). Dos 100 artigos submetidos, 26 foram selecionados para apresentação e encontram-se publicados nestes anais, em ordem de apresentação. Além destes, há também duas palestras convidadas internacionais. Cada artigo foi submetido a três avaliadores. Após análise pelo Steering Committee, alguns artigos, em que a precisão/profundidade da avaliação poderia comprometer o resultado, foram avaliados por um quarto avaliador. Aqueles artigos onde se percebeu falta de harnonia nos conceitos atribuídos foram devolvidos aos avaliadores para, em conjunto, encontrar consenso. Tornadas as avaliações homogêneas, e após um processo interativo, o Steering Committee aprovou proposta da Coordenação, selecionando os 26 melhores artigos. A realização deste evento contou com o apoio financeiro do CNPq, CAPES e da Sterling Software. Os apoios dados pela direção do Centro Tecnológico da Universidade Federal de Santa Catarina, bem como pela administração da UFSC foram fundamentais para a viabilização do SBES'99. Agradecemos aos membros do Comitê de Programa cuja qualidade do trabalho reflete-se no conteúdo destes anais. Todo nosso reconhecimento aos mebros do Comitê de Organização, aos alunos do PET/CCO/UFSC e do curso de Bacharelado em Ciência da Computação da UFSC cujos esforços e trabalho tornaram possível a realização deste Simpósio. Finalmente, agradecemos a cada um dos participantes, que com sua presença contribuiu para o sucesso do SBES'99.},
  articles-accepted = {26},
  articles-submitted = {100},
  papers-accepted = {26},
  papers-submitted = {100},
  promoter = {Specialist Committee on Software Engineering/SBC - Brazilian Computing Society.},
  title-en = {13th Brazilian Symposium on Software Engineering},
  title-pt = {XIII Simpósio Brasileiro de Engenharia de Software}
}

@PROCEEDINGS{proceedings:iadis-is:2011,
  booktitle = {International Conference Information Systems 2011},
  year = {2011},
  month = mar,
  days = {11--13},
  location = {Avila, #Spain#},
  isbn = {978-972-8939-47-2},
  editor = {Miguel Baptista Nunes and Pedro Isaías and Philip Powell},
  publisher = {IADIS},
  papers-accepted = {24},
  papers-submitted = {140}
}

@BOOK{Okada-etal:2008,
  title = {Knowledge Cartography: Software Tools and Mapping Techniques},
  publisher = {Springer},
  year = {2008},
  editor = {Alexandra Okada and Simon Buckingham Shum and Tony Sherbone},
  isbn = {978-1-84800-148-0},
  pages = {400},
  series = {Advanced Information and Knowledge Processing},
  address = {London, Reino Unido},
  edition = {1},
  booktitle = {Knowledge Cartography: Software Tools and Mapping Techniques},
  doi = {10.1007/978-1-84800-149-7}
}

@PROCEEDINGS{proceedings:sbes-wtes:2003,
  booktitle = {8th Workshop of Dissertations on Software Engineering},
  title = {8th Workshop of Dissertations on Software Engineering},
  year = {2003},
  month = oct,
  days = {7-9},
  location = {Manaus, Amazonas, Brazil},
  isbn = {85-7401-125-8},
  editor = {Rosângela Dellosso Penteado},
  series = {Workshop of Dissertations on Software Engineering},
  publisher = {EDUA},
  organization = {UFAM},
  papers-accepted = {13},
  promoter = {SBC, ACM-SIGSOFT},
  title-en = {8th Workshop of Dissertations on Software Engineering},
  title-pt = {VIII Workshop de Teses em Engenharia de Software}
}

@PROCEEDINGS{proceedings:pcs:1996,
  booktitle = {Conference on Performability in Computing Systems},
  title = {Conference on Performability in Computing Systems},
  year = {1996},
  month = jul,
  days = {25--26},
  location = {East Brunswick, NJ, #USA#},
  editor = {H. Pham and E. A. Elsayed},
  organization = {Rutgers University},
  papers-accepted = {14}
}

@PROCEEDINGS{proceedings:icrqd:1998,
  booktitle = {4th International Conference on Reliability and Quality in Design},
  title = {4th International Conference on Reliability and Quality in Design},
  year = {1998},
  month = aug,
  isbn = {0-9639998-3-4},
  editor = {Hoang Pham and Ming-Wei Lu}
}

@BOOK{Pimentel-Fuks:2011,
  publisher = {Elsevier},
  year = {2011},
  editor = {Mariano Pimentel and Hugo Fuks},
  isbn = {978-85-352-4669-8},
  pages = {375},
  series = {Sociedade Brasileira de Computação},
  address = {Rio de Janeiro, RJ, } # Brazil,
  edition = {1},
  booktitle = {Sistemas colaborativos},
  timestamp = {2013-09-26}
}

@PROCEEDINGS{proceedings:sbes:1993,
  booktitle = {7th Brazilian Symposium on Software Engineering},
  title = {7th Brazilian Symposium on Software Engineering},
  year = {1993},
  month = oct,
  days = {26-29},
  location = {Rio de Janeiro, RJ, Brazil},
  editor = {Julio Cesar Sampaio do Prado Leite},
  series = {Brazilian Symposium on Software Engineering},
  organization = {DI/PUC-Rio},
  papers-accepted = {26},
  papers-submitted = {72},
  promoter = {SBC},
  title-en = {7th Brazilian Symposium on Software Engineering},
  title-pt = {VII Simpósio Brasileiro de Engenharia de Software}
}

@PROCEEDINGS{proceedings:fees:2008,
  booktitle = {Fórum de Educação em Engenharia de Software},
  title = {Fórum de Educação em Engenharia de Software},
  year = {2008},
  month = oct,
  location = {Campinas, SP, Brazil},
  editor = {Julio Cesar Sampaio do Prado Leite and Cláudia Maria Lima Werner},
  number = {43/08},
  series = {FEES},
  address = {Rio de Janeiro, RS, Brazil},
  publisher = {PUC-Rio},
  issn = {0103-9741},
  papers-accepted = {14},
  papers-submitted = {22}
}

@PROCEEDINGS{Prey-etal:2007,
  booktitle = {Workshop on the Impact of Tablet PCs and Pen-based Technology on Education},
  title = {Workshop on the Impact of Tablet PCs and Pen-based Technology on Education},
  year = {2007},
  month = jun,
  location = {West Lafayette, IN, EUA},
  isbn = {1-55753-461-6},
  editor = {Jane C. Prey and Rober H. Reed and Dave A. Berque},
  address = {West Lafayette, IN, EUA},
  publisher = {Purdue University Press},
  timestamp = {2008.10.05}
}

@PROCEEDINGS{proceedings:sbes:1994,
  booktitle = {8th Brazilian Symposium on Software Engineering},
  title = {8th Brazilian Symposium on Software Engineering},
  year = {1994},
  month = oct,
  days = {25-28},
  location = {Curitiba, PR, Brazil},
  editor = {Roberto Tom Price},
  series = {Brazilian Symposium on Software Engineering},
  organization = {CITS, PUC-PR, UFRGS},
  owner = {Marco Aurélio},
  papers-accepted = {30},
  papers-submitted = {91},
  promoter = {SBC},
  timestamp = {2011.05.17},
  title-en = {8th Brazilian Symposium on Software Engineering},
  title-pt = {VIII Simpósio Brasileiro de Engenharia de Software}
}

@BOOK{Reigeluth:1999,
  title = {Instructional Design Theories and Models: A New Paradigm of Instructional Theory},
  publisher = {Erlbaum},
  year = {1999},
  editor = {Charles M. Reigeluth},
  isbn = {9780805828597},
  volume = {2},
  pages = {730},
  address = {Mahwah, NJ, USA},
  month = apr,
  note = {Also known as the 'Green Book II'.},
  abstract = {This volume provides a concise summary of a broad sampling of new methods of instruction currently under development, helps show the interrelationships among these diverse theories, and highlights current issues and trends in instructional design. It is a sequel to Volume I of Instructional-Design Theories and Models, which provided a "snapshot in time" of the status of instructional theory in the early 1980s. Dramatic changes in the nature of instructional theory have occurred since then, partly in response to advances in knowledge about the human brain and learning theory, partly due to shifts in educational philosophies and beliefs, and partly in response to advances in information technologies. These changes have made new methods of instruction not only possible, but also necessary in order to take advantage of new instructional capabilities offered by the new technologies. These changes are so dramatic that many argue they constitute a new paradigm of instruction, which requires a new paradigm of instructional theory.},
  booktitle = {Instructional Design Theories and Models: A New Paradigm of Instructional Theory}
}

@BOOK{Reigeluth:1983,
  title = {Instructional Design Theories and Models: An Overview of their Current Status},
  publisher = {Erlbaum},
  year = {1983},
  editor = {Charles M. Reigeluth},
  isbn = {0898592755},
  volume = {1},
  pages = {487},
  address = {Hillsdale, NJ, EUA},
  month = nov,
  note = {Também conhecido como `Green Book'.},
  abstract = {This book is dedicated to increasing our knowledge about how to improve instruction. It is founded on the premise that the process of learning can be made easier and more enjoyable. During the previous twenty-five years (1957-1982), a young discipline has developed to so improve instruction. This discipline about Instruction has produced a growing knowledge base about methods of instruction and their effects for different kinds of goals, content, and learners. Because it is a very new discipline, the knowledge that has been generated so far has tended to be piecemeal, and instructional researchers have tended to develop independent "knowledge bases." Moreover, different researchers often use different terms to refer to the same phenomenon, and they often use the same term to refer to different phenomena. The result has been somewhat chaotic. The major purpose of this book is to encourage the building of a common knowledge base that integrates the independent and piecemeal "knowledge bases" that presently characterize the discipline. Unit I discusses the nature of the discipline, especially the nature of the knowledge it generates. Unit II summarizes some of the most comprehensive "knowledge bases" that presently characterize the discipline. It shows that, rather than conflicting and competing with each other, these "knowledge bases"-theories and models-tend to either duplicate or complement each other. Several of these theories represent efforts to integrate independent and piecemeal "knowledge bases" into a common knowledge base, mainly in the form of optimal models of instruction which are prescribed on the basis of kind of goals, content, and/or learners. It should be noted that this unit summarizes but a sampling of instructional design theories and models-it is by no means a complete representation of work that has been done. Finally, Unit III presents a discussion about the preceding chapters. At the time that this book was going to press, a companion volume is nearing completion. It is also edited by myself, and is entitled Instructional Theories in Action: Lessons Illustrating Selected Theories and Models. In that book, each of the theories in this book is illustrated in a Lesson, and all lessons teach the same objectives in order to facilitate comparison of the theories and models. Each lesson is followed by commentary that relates specific aspects of the lesson design to specific prescriptions in the theory or model. With only one exception (the Gagne-Briggs theory), the lesson and commentary are authored by the original theorist. The six objectives that comprise each lesson represent a variety of intellectual skills and verbal information. That book complements this one nicely by (1) facilitating the understanding of each theory or model through a concrete representation of it and (2) facilitating the comparison and integration of the theories and models through a clear indication of what unique and valuable contributions each makes to the design of a variety of objectives. One can envision a time when there will be a variety of different models of instruction, each prescribing the best available methods for achieving a different kind of learning goal under different kinds of conditions. One can also envision researchers all over the world building upon this common knowledge base, continually improving and refining those models. It is my hope that this book will contribute in some small way to forming that common knowledge base.},
  booktitle = {Instructional Design Theories and Models: An Overview of their Current Status}
}

@BOOK{Reigeluth-CarrChellman:2009,
  title = {Instructional Design Theories and Models: Building a Common Knowledge Base},
  publisher = {Routledge},
  year = {2009},
  editor = {Charles M. Reigeluth and Alison A. Carr-Chellman},
  isbn = {978-0-8058-6456-4},
  volume = {3},
  pages = {416},
  address = {New York, NY, EUA},
  note = {Também conhecido como `Green Book III'},
  abstract = {This volume provides a concise summary of a broad sampling of new methods of instruction currently under development, helps show the interrelationships among these diverse theories, and highlights current issues and trends in instructional design. It is a sequel to Volume I of Instructional-Design Theories and Models, which provided a "snapshot in time" of the status of instructional theory in the early 1980s. Dramatic changes in the nature of instructional theory have occurred since then, partly in response to advances in knowledge about the human brain and learning theory, partly due to shifts in educational philosophies and beliefs, and partly in response to advances in information technologies. These changes have made new methods of instruction not only possible, but also necessary in order to take advantage of new instructional capabilities offered by the new technologies. These changes are so dramatic that many argue they constitute a new paradigm of instruction, which requires a new paradigm of instructional theory.},
  booktitle = {Instructional Design Theories and Models: Building a Common Knowledge Base}
}

@PROCEEDINGS{proceedings:sbes-tools:2004,
  booktitle = {18th Brazilian Symposium on Software Engineering -- 11th Tools Session},
  title = {18th Brazilian Symposium on Software Engineering -- 11th Tools Session},
  year = {2004},
  month = oct,
  days = {21-22},
  location = {Brasília, DF, Brazil},
  isbn = {85-7669-004-7},
  editor = {Rodrigo Quites Reis},
  series = {Brazilian Symposium on Software Engineering -- Tools Session},
  organization = {UnB},
  papers-accepted = {15},
  papers-submitted = {35},
  promoter = {UnB, UFPA},
  title-en = {18th Brazilian Symposium on Software Engineering -- 11th Tools Session},
  title-pt = {XVIII Simpósio Brasileiro de Engenharia de Software -- XI Sessão de Ferramentas}
}

@PROCEEDINGS{proceedings:sbes-tools:1998,
  booktitle = {12th Brazilian Symposium on Software Engineering -- 5th Tools Session},
  title = {12th Brazilian Symposium on Software Engineering -- 5th Tools Session},
  year = {1998},
  month = oct,
  days = {13-16},
  location = {Maringá, PR, Brazil},
  editor = {Douglas Renaux and Carlos Benedito Sica de Toledo},
  series = {Brazilian Symposium on Software Engineering -- Tools Session},
  address = {Maringá, PR, Brasil},
  organization = {DIN-UEM, CITS, IC-UNICAMP},
  owner = {olivrap},
  papers-accepted = {13},
  promoter = {SBC},
  timestamp = {2011.05.25},
  title-en = {12th Brazilian Symposium on Software Engineering -- Tools Session},
  title-pt = {XII Simpósio Brasileiro de Engenharia de Software -- V Sessão de Ferramentas}
}

@PROCEEDINGS{proceedings:wsl:2004,
  booktitle = {5th Workshop on Open Source Software},
  title = {5th Workshop on Open Source Software},
  year = {2004},
  month = jun,
  days = {2-5},
  location = {Porto Alegre, RS, Brazil},
  editor = {Alexandre Moretto Ribeiro and Celso Maciel da Costa and Edgar Meneguetti and Lisandro Zambenedetti Granville},
  series = {Workshop on Open Source Software},
  publisher = {Evergraf},
  organization = {ASL-PSL/RS, PUCRS, UCS, UFRGS, UNISINOS},
  note = {In conjunction with 5th International Forum of Free Software (FISL)},
  papers-accepted = {43},
  papers-submitted = {93},
  promoter = {SBC},
  title-en = {5th Workshop on Open Source Software},
  title-pt = {5° Workshop sobre Software Livre}
}

@PROCEEDINGS{proceedings:sbes:2002,
  booktitle = {16th Brazilian Symposium on Software Engineering},
  title = {16th Brazilian Symposium on Software Engineering},
  year = {2002},
  month = oct,
  days = {16-18},
  location = {Gramado, RS, Brazil},
  isbn = {85-88442-31-0},
  editor = {Leila Ribeiro},
  series = {Brazilian Symposium on Software Engineering},
  organization = {PUCRS, UCS, UFRGRS, ULBRA, UNISC, UNISINOS},
  papers-accepted = {20},
  papers-submitted = {104},
  promoter = {SBC, ACM SIGSOFT},
  title-en = {16th Brazilian Symposium on Software Engineering},
  title-pt = {XVI Simpósio Brasileiro de Engenharia de Software}
}

@PROCEEDINGS{proceedings:sbes:1987,
  booktitle = {1st Brazilian Symposium on Software Engineering},
  title = {1st Brazilian Symposium on Software Engineering},
  year = {1987},
  month = oct,
  days = {22-23},
  location = {Petrópolis/Itaipava, RJ, Brazil},
  editor = {Ana Regina C. da Rocha},
  series = {Brazilian Symposium on Software Engineering},
  papers-accepted = {25},
  papers-submitted = {40},
  promoter = {SBC, COPPE/UFRJ},
  title-en = {1st Brazilian Symposium on Software Engineering},
  title-pt = {I Simpósio Brasileiro de Engenharia de Software}
}

@PROCEEDINGS{proceedings:wqs:1994,
  booktitle = {Workshop de qualidade de software},
  title = {Workshop de qulidade de software},
  year = {1994},
  month = oct,
  days = {26--27},
  location = {Curitiba, PR, #Brazil#},
  editor = {Ana Regina C. da Rocha and Kival Chaves Weber},
  organization = {CITS, PUCPR, UFRGS},
  pages = {534},
  promoter = {SBC}
}

@PROCEEDINGS{proceedings:webmedia:2006,
  booktitle = {12th Brazilian Symposium on Multimedia and the Web},
  year = {2006},
  month = nov,
  days = {19--22},
  location = {Natal, RN, #Brazil#},
  isbn = {85-7669-100-0},
  editor = {Rogerio Ferreira Rodrigues and Jair C. Leite},
  series = {WebMedia},
  publisher = {ACM},
  papers-accepted = {33},
  papers-submitted = {120}
}

@PROCEEDINGS{proceedings:sbes:2000,
  booktitle = {14th Brazilian Symposium on Software Engineering},
  title = {14th Brazilian Symposium on Software Engineering},
  year = {2000},
  month = oct,
  days = {4-6},
  location = {João Pessoa, PB, Brazil},
  editor = {Augusto Sampaio and Adriano Augusto de Souza and Damires Yluska de Souza Fernandes and Daniela Coelho Freire Batista},
  series = {Brazilian Symposium on Software Engineering},
  organization = {UFPB, UFPE},
  papers-accepted = {20},
  papers-submitted = {76},
  promoter = {SBC},
  title-en = {14th Brazilian Symposium on Software Engineering},
  title-pt = {XIV Simpósio Brasileiro de Engenharia de Software}
}

@PROCEEDINGS{proceedings:sbes-tools:2000,
  booktitle = {14th Brazilian Symposium on Software Engineering -- 7th Tools Session},
  title = {14th Brazilian Symposium on Software Engineering -- 7th Tools Session},
  year = {2000},
  month = oct,
  days = {4-6},
  location = {João Pessoa, PB, Brazil},
  editor = {Augusto Sampaio and Adriano Augusto de Souza and Damires Yluska de Souza Fernandes and Daniela Coelho Freire Batista},
  series = {Brazilian Symposium on Software Engineering -- Tools Session},
  organization = {UFPB, UFPE},
  papers-accepted = {13},
  promoter = {SBC},
  title-en = {14th Brazilian Symposium on Software Engineering -- 7th Tools Session},
  title-pt = {XIV Simpósio Brasileiro de Engenharia de Software -- VII Sessão de Ferramentas}
}

@PROCEEDINGS{proceedings:sbes-tools:1996,
  booktitle = {10th Brazilian Symposium on Software Engineering -- 3rd Tools Session},
  title = {10th Brazilian Symposium on Software Engineering -- 3rd Tools Session},
  year = {1996},
  month = oct,
  days = {15-18},
  location = {São Carlos, SP, Brazil},
  editor = {Rosely Sanches and Antonio Francisco do Prado},
  series = {Simpósio Brasileiro de Engenharia de Software -- Tools Session},
  organization = {ICMC/USP, UFScar},
  owner = {Marco Aurélio},
  papers-accepted = {8},
  promoter = {SBC},
  timestamp = {2011.05.17},
  title-en = {10th Brazilian Symposium on Software Engineering -- 3rd Tools Session},
  title-pt = {X Simpósio Brasileiro de Engenharia de Software -- III Caderno de Ferramentas}
}

@PROCEEDINGS{proceedings:oss:2005,
  booktitle = {1st International Conference on Open Source Systems},
  title = {1st International Conference on Open Source Systems},
  year = {2005},
  month = jul,
  location = {Genova, #Italy#},
  editor = {Marco Scotto and Giancarlo Succi},
  address = {Genova, Italy},
  accepted-papers = {53},
  day = {11--15},
  owner = {magsilva},
  timestamp = {2013-10-11}
}

@PROCEEDINGS{proceedings:xp:2010,
  booktitle = {11th International Conference on Agile Software Development},
  title = {11th International Conference on Agile Software Development},
  year = {2010},
  month = jun,
  days = {1--4},
  location = {Trondheim, #Norway#},
  isbn = {978-3-642-13053-3},
  editor = {Sillitti, Alberto and Martin, Angela and Wang, Xiaofeng and Whitworth, Elizabeth},
  volume = {48},
  series = {Lecture Notes in Business Information Processing},
  publisher = {Springer Berlin Heidelberg},
  owner = {magsilva},
  timestamp = {2014.10.20}
}

@PROCEEDINGS{proceedings:sbes:1991,
  booktitle = {5th Brazilian Symposium on Software Engineering},
  title = {5th Brazilian Symposium on Software Engineering},
  year = {1991},
  month = oct,
  days = {23-25},
  location = {Ouro Preto, MG, Brazil},
  editor = {Roberto da Silva Bigonha},
  series = {Brazilian Symposium on Software Engineering},
  papers-accepted = {16},
  papers-submitted = {62},
  promoter = {SBC, UFMG, UFOP},
  title-en = {5th Brazilian Symposium on Software Engineering},
  title-pt = {V Simpósio Brasileiro de Engenharia de Software}
}

@PROCEEDINGS{proceedings:acm-se:2012,
  booktitle = {50th ACM Annual Southeast Regional Conference},
  title = {50th ACM Annual Southeast Regional Conference},
  year = {2012},
  month = mar,
  days = {29--31},
  location = {Tuscaloosa, Alabama, #USA#},
  isbn = {978-1-4503-1203-5},
  editor = {Randy K. Smith and Susan V. Vrbsky},
  address = {New York, NY, } # USA,
  publisher = {ACM},
  owner = {magsilva},
  timestamp = {2014.08.19}
}

@PROCEEDINGS{proceedings:sbes-tools:2011,
  booktitle = {25th Brazilian Symposium on Software Engineering - 18th Tools Session},
  title = {25th Brazilian Symposium on Software Engineering - 18th Tools Session},
  year = {2011},
  month = sep,
  days = {29-30},
  location = {São Paulo, SP, Brazil},
  editor = {Sérgio Soares},
  volume = {4},
  series = {Brazilian Symposium on Software Engineering},
  organization = {USP, Mackenzie},
  issn = {2178-6097},
  papers-accepted = {15},
  papers-submitted = {27},
  promoter = {SBC},
  title-en = {25th Brazilian Symposium on Software Engineering},
  title-pt = {XXV Simpósio Brasileiro de Engenharia de Software}
}

@PROCEEDINGS{proceedings:sbes:2007,
  booktitle = {21st Brazilian Symposium on Software Engineering},
  title = {21st Brazilian Symposium on Software Engineering},
  year = {2007},
  month = oct,
  days = {15-19},
  location = {João Pessoa, PB, Brazil},
  isbn = {978-85-7669-143-3},
  editor = {Itana Maria de Souza Gimenes},
  series = {Brazilian Symposium on Software Engineering},
  organization = {DI-UFPB},
  papers-accepted = {24},
  papers-submitted = {105},
  promoter = {SBC, ACM SIGSOFT},
  title-en = {21st Brazilian Symposium on Software Engineering},
  title-pt = {XXI Simpósio Brasileiro de Engenharia de Software}
}

@PROCEEDINGS{proceedings:sbes:1998,
  booktitle = {12th Brazilian Symposium on Software Engineering},
  title = {12th Brazilian Symposium on Software Engineering},
  year = {1998},
  month = oct,
  days = {13-16},
  location = {Maringá, PR, Brazil},
  editor = {Itana Maria de Souza Gimenes},
  series = {Brazilian Symposium on Software Engineering},
  address = {Maringá, PR, Brasil},
  organization = {DIN-UEM, CITS},
  owner = {olivrap},
  papers-accepted = {21},
  papers-submitted = {71},
  promoter = {SBC},
  timestamp = {2011.05.25},
  title-en = {12th Brazilian Symposium on Software Engineering},
  title-pt = {XII Simpósio Brasileiro de Engenharia de Software}
}

@PROCEEDINGS{proceedings:sbes:2005,
  booktitle = {19th Brazilian Symposium on Software Engineering},
  title = {19th Brazilian Symposium on Software Engineering},
  year = {2005},
  month = oct,
  days = {3-7},
  location = {Uberlândia, MG, Brazil},
  isbn = {85-7669-030-6},
  editor = {Arndt von Staa},
  series = {Brazilian Symposium on Software Engineering},
  address = {Uberlândia, MG, Brasil},
  organization = {UFU},
  owner = {olivrap},
  papers-accepted = {21},
  papers-submitted = {115},
  promoter = {SBC, ACM SIGSOFT},
  timestamp = {2011.05.25},
  title-en = {19th Brazilian Symposium on Software Engineering},
  title-pt = {19° Simpósio Brasileiro de Engenharia de Software}
}

@PROCEEDINGS{proceedings:wcce:2009,
  booktitle = {9th IFIP TC3 World Conferece on Computers in Education},
  year = {2009},
  month = jul,
  days = {27--31},
  location = {Bento Gonçalvez, RS, #Brazil#},
  isbn = {978-3-642-03114-4},
  editor = {Arthur Tatnall and Anthony Jones},
  publisher = {Springer},
  accepted-papers = {146},
  day = {27--31},
  issn = {1868-4238},
  submitted-papers = {289}
}

@PROCEEDINGS{proceedings:std:icmc:2006,
  booktitle = {X Simpósio de Teses e Dissertações},
  title = {X Simpósio de Teses e Dissertações},
  year = {2006},
  month = mar,
  days = {23-24},
  location = {São Carlos, SP, Brazil},
  isbn = {85-87837-10-9},
  editor = {Franklina Maria Bragion de Toledo and Leandro Franco de Souza and Maria Cristina Ferreira de Oliveira and Rodrigo Fernandes de Mello and Rudinei Goularte},
  series = {Simpósio de Teses e Dissertações},
  organization = {ICMC-USP}
}

@PROCEEDINGS{proceedings:icse:2002,
  booktitle = {24th International Conference on Software Engineering},
  title = {24th International Conference on Software Engineering},
  year = {2002},
  month = may,
  days = {19--25},
  location = {Orlando, Florida, #USA#},
  isbn = {1-58113-472-X},
  editor = {Will Tracz and Michal Young and Jeff Magee},
  address = {New York, NY, } # USA,
  publisher = {ACM},
  owner = {magsilva},
  timestamp = {2014.09.11}
}

@PROCEEDINGS{proceedings:sbes:2003,
  booktitle = {17th Brazilian Symposium on Software Engineering},
  title = {17th Brazilian Symposium on Software Engineering},
  year = {2003},
  month = oct,
  days = {8-10},
  location = {Manaus, AM, Brazil},
  isbn = {85-7401-126-6},
  editor = {Guilherme Horta Travassos},
  series = {Brazilian Symposium on Software Engineering},
  organization = {UFAM},
  papers-accepted = {20},
  papers-submitted = {129},
  promoter = {SBC, ACM SIGSOFT},
  title-en = {17th Brazilian Symposium on Software Engineering},
  title-pt = {XVII Simpósio Brasileiro de Engenharia de Software}
}

@PROCEEDINGS{proceedings:webmedia:2009,
  booktitle = {15th Brazilian Symposium on Multimedia and the Web},
  year = {2009},
  month = oct,
  days = {5--7},
  location = {Fortaleza, Ceará, #Brazil#},
  isbn = {978-1-60558-880-3},
  editor = {Fernando Antonio Mota Trinta and Pedro Porfírio},
  series = {WebMedia},
  publisher = {ACM},
  papers-accepted = {32},
  papers-submitted = {107}
}

@PROCEEDINGS{proceedings:euroitv:2008,
  booktitle = {European Interactive {TV} Conference},
  title = {European Interactive {TV} Conference},
  year = {2008},
  month = jul,
  days = {3-4},
  location = {Salzburg, Austria},
  isbn = {978-3-540-69477-9},
  editor = {M. Tscheligi and M. Obrist and A. Lugmayr},
  volume = {5066},
  series = {Lecture Notes in Computer Science},
  publisher = {Springer}
}

@PROCEEDINGS{proceedings:sbes-tools:2007,
  booktitle = {21st Brazilian Symposium on Software Engineering -- 14th Tools Session},
  title = {21st Brazilian Symposium on Software Engineering -- 14th Tools Session},
  year = {2007},
  month = oct,
  days = {17-18},
  location = {João Pessoa, PB, Brazil},
  isbn = {978-85-7669-144-0},
  editor = {Auri Marcelo Rizzo Vincenzi},
  series = {Brazilian Symposium on Software Engineering -- Tools Session},
  organization = {DI-UFPB},
  papers-accepted = {14},
  papers-submitted = {52},
  promoter = {SBC, ACM SIGSOFT},
  title-en = {21st Brazilian Symposium on Software Engineering -- 14th Tools Session},
  title-pt = {XXI Simpósio Brasileiro de Engenharia de Software - XIV Sessão de Ferramentas}
}

@PROCEEDINGS{proceedings:xp:2002,
  booktitle = {2nd XP Universe and 1st Agile Universe Conference},
  title = {2nd XP Universe and 1st Agile Universe Conference},
  year = {2002},
  month = aug,
  days = {4--7},
  location = {Chicago, IL, #USA#},
  isbn = {978-3-540-44024-6},
  editor = {Wells, Don and Williams, Laurie},
  volume = {2418},
  series = {Lecture Notes in Computer Science},
  publisher = {Springer Berlin Heidelberg},
  owner = {magsilva},
  timestamp = {2014.10.21}
}

@PROCEEDINGS{proceedings:sbes:2001,
  booktitle = {15th Brazilian Symposium on Software Engineering},
  title = {15th Brazilian Symposium on Software Engineering},
  year = {2001},
  month = oct,
  days = {3-5},
  location = {Rio de Janeiro, RJ, Brazil},
  editor = {Cláudia Werner and Vera Werneck},
  series = {Brazilian Symposium on Software Engineering},
  organization = {EMBRAPA, IME-RJ, LNCC, PUC-Rio, UERJ, UFRJ},
  owner = {olivrap},
  papers-accepted = {21},
  papers-submitted = {83},
  promoter = {SBC, ACM SIGSOFT},
  title-en = {15th Brazilian Symposium on Software Engineering},
  title-pt = {XV Simpósio Brasileiro de Engenharia de Software}
}

@PROCEEDINGS{proceedings:sbes-tools:2001,
  booktitle = {15th Brazilian Symposium on Software Engineering -- 8th Tools Session},
  title = {15th Brazilian Symposium on Software Engineering -- 8th Tools Session},
  year = {2001},
  month = oct,
  days = {3-5},
  location = {Rio de Janeiro, RJ, Brazil},
  editor = {Cláudia Werner and Vera Werneck},
  series = {Brazilian Symposium on Software Engineering -- Tools Session},
  organization = {EMBRAPA, IME-RJ, LNCC, PUC-Rio, UERJ, UFRJ},
  owner = {olivrap},
  papers-accepted = {18},
  promoter = {SBC, ACM SIGSOFT},
  title-en = {15th Brazilian Symposium on Software Engineering -- 8th Tools Session},
  title-pt = {XV Simpósio Brasileiro de Engenharia de Software -- VIII Sessão de Ferramentas}
}

@BOOK{Wiley:2001,
  title = {The Instructional Use of Learning Objects},
  publisher = {AIT/AECT},
  year = {2000},
  editor = {David A. Wiley},
  isbn = {978-0784208922},
  pages = {298},
  address = USA,
  edition = {1},
  booktitle = {The Instructional Use of Learning Objects},
  chapter = {Connecting learning objects to instructional design theory: A definition, a metaphor, and a taxonomy},
  owner = {magsilva},
  timestamp = {2008.09.27},
  url = {http://reusability.org/read/}
}

@PROCEEDINGS{proceedings:icse:1978,
  booktitle = {3rd International Conference on Software Engineering},
  title = {3rd International Conference on Software Engineering},
  year = {1978},
  month = may,
  days = {10--12},
  location = {Atlanta, Georgia, #USA#},
  editor = {Maurice V. Wilkes and Laszlo A. Belady and Y. H. Su and Harry Hayman and Enslow Jr, Philip H.},
  address = {Piscataway, NJ, } # USA,
  publisher = {IEEE},
  owner = {magsilva},
  timestamp = {2014.09.11}
}

@PROCEEDINGS{proceedings:mutation:2000,
  booktitle = {{MUTATION 2000}: A Symposium on Mutation Testing for the new Century},
  title = {{MUTATION 2000}: A Symposium on Mutation Testing for the new Century},
  year = {2000},
  month = oct,
  days = {6--7},
  location = {San Jose, California, #USA#},
  isbn = {0-7923-7323-5},
  editor = {W. Eric Wong},
  series = {Advances in Database Systems},
  publisher = {Kluwer Academic Publishers},
  papers-accepted = {8}
}

@PROCEEDINGS{proceedings:xp:2004,
  booktitle = {4th International Conference on Extreme Programming and Agile Methods},
  title = {4th International Conference on Extreme Programming and Agile Methods},
  year = {2004},
  month = aug,
  days = {15--18},
  location = {Calgary, #Canada#},
  isbn = {978-3-540-22839-4},
  editor = {Zannier, Carmen and Erdogmus, Hakan and Lindstrom, Lowell},
  volume = {3134},
  series = {Lecture Notes in Computer Science},
  publisher = {Springer Berlin Heidelberg},
  owner = {magsilva},
  timestamp = {2014.10.21}
}

@MISC{Brazil:2011,
  title = {Estratégia Nacional de Ciência, Tecnologia e Inovação}
}

@MISC{isoiec23360:,
  title = {LSB Core 3.1},
  owner = {msilva},
  timestamp = {2007.07.23}
}

@JOURNAL{jounal:ieee:proceedings,
  journal = {Proceedings of the {IEEE}},
  publisher = {IEEE},
  address = USA,
  issn = {0018-9219}
}

@JOURNAL{journal:aaai:ai,
  journal = {{AI} Magazine},
  publisher = {Association for the Advancement of Artificial Intelligence},
  address = {Palo Alto, CA, } # USA,
  issn = {0738-4602},
  timestamp = {2013-10-07}
}

@JOURNAL{journal:aace:ijel,
  journal = {International Journal on E-Learning},
  publisher = {{AACE}},
  address = {Chesapeake, VA, } # USA,
  issn = {1537-2456},
  url = {http://www.editlib.org/j/IJEL}
}

@JOURNAL{journal:academy:js,
  journal = {Journal of Software},
  publisher = {Academy Publisher},
  address = {Road Town, British Virgin Islands, } # UK,
  issn = {1796-217X},
  timestamp = {2013-10-15}
}

@JOURNAL{journal:acm:acr,
  journal = {SIGAPP Applied Computing Review},
  publisher = {ACM},
  address = {New York, NY, USA},
  issn = {1559-6915}
}

@JOURNAL{journal:acm:cacm,
  journal = {Communications of the {ACM}},
  publisher = {ACM},
  address = {New York, NY, } # USA,
  issn = {0001-0782},
  title = {Communications of the {ACM}}
}

@JOURNAL{journal:acm:cie,
  journal = {Computers in Entertainment},
  publisher = {ACM},
  address = {New York, NY, } # USA,
  issn = {1544-3574}
}

@JOURNAL{journal:acm:csur,
  journal = {ACM Computing Surveys},
  publisher = {ACM},
  address = {New York, NY, } # USA,
  issn = {0360-0300}
}

@MISC{journal:acm:inroads,
  title = {Inroads},
  address = {New York, NY, USA},
  issn = {2153-2184, 2153-2192},
  journal = {Inroads},
  publisher = {ACM}
}

@JOURNAL{journal:acm:interactions,
  journal = {Interactions},
  publisher = {ACM},
  address = {New York, NY, } # USA,
  issn = {1072-5520}
}

@JOURNAL{journal:acm:jacm,
  journal = {Journal of the ACM},
  publisher = {ACM},
  address = {New York, NY, } # USA,
  issn = {0004-5411}
}

@JOURNAL{journal:acm:jeric,
  journal = {Journal on Educational Resources in Computing},
  publisher = {ACM},
  address = {New York, NY, } # USA,
  issn = {1531-4278}
}

@JOURNAL{journal:acm:sen,
  journal = {SIGSOFT Software Engineering Notes},
  publisher = {ACM},
  address = {New York, NY, } # USA,
  issn = {0163-5948}
}

@JOURNAL{journal:acm:sigcse-bulletin,
  journal = {SIGCSE Bulletin},
  publisher = {ACM},
  address = {New York, NY, } # USA,
  issn = {0097-8418}
}

@JOURNAL{journal:acm:sigkdd,
  journal = {{SIGKDD} Explorations Newsletter},
  publisher = {ACM},
  address = {New York, NY, } # USA,
  issn = {1931-0145}
}

@JOURNAL{journal:acm:sigplan,
  journal = {SIGPLAN Notices},
  publisher = {ACM},
  address = {New York, NY, } # USA,
  issn = {0362-1340}
}

@JOURNAL{journal:acm:tce,
  journal = {Transactions on Computer Education},
  publisher = {ACM},
  address = {New York, NY, } # USA,
  issn = {1946-6226}
}

@JOURNAL{journal:acm:toce,
  journal = {Transactions on Computing Education},
  publisher = {ACM},
  address = {New York, NY, } # USA,
  issn = {1946-6226}
}

@JOURNAL{journal:acm:tochi,
  journal = {Transactions on Computer-Human Interaction},
  publisher = {ACM},
  address = {New York, NY, } # USA,
  issn = {1073-0516},
  acronym = {TOCHI}
}

@MISC{journal:acm:tois,
  title = {Transactions on Information Systems},
  address = {New York, NY, EUA},
  issn = {1046-8188},
  journal = {Transactions on Information Systems},
  publisher = {ACM},
  timestamp = {2012.01.24}
}

@JOURNAL{journal:acm:tosem,
  journal = {Transactions on Software Engineering and Methodology},
  publisher = {{ACM}},
  address = {New York, NY, USA},
  issn = {1049-331X}
}

@JOURNAL{journal:acm:xrds,
  journal = {{XRDS}},
  publisher = {ACM},
  address = {New York, NY, USA},
  issn = {1528-4972}
}

@JOURNAL{journal:baywood:jecr,
  journal = {Journal of Education Computing Research},
  publisher = {Baywood},
  address = {Amityville, NY, } # USA,
  issn = {0735-6331},
  e-issn = {1541-4140}
}

@JOURNAL{journal:cambridge:nle,
  journal = {Natural Language Engineering},
  publisher = {Cambridge University},
  address = {New York, NY, } # USA,
  issn = {1351-3249}
}

@JOURNAL{journal:ccsc:jcsc,
  journal = {Journal of Computing Sciences in Colleges},
  publisher = {Consortium for Computing Sciences in Colleges},
  address = USA,
  issn = {1937-4771},
  e-issn = {1937-4763}
}

@JOURNAL{journal:chm:algol-bulletin,
  journal = {ALGOL Bulletin},
  publisher = {Computer History Museum},
  address = {Mountain View, CA, } # USA,
  issn = {0084-6198}
}

@JOURNAL{journal:educa:etd,
  journal = {ETD -- Educação Temática Digital},
  publisher = {Educ@},
  address = {Campinas, SP, } # Brazil,
  issn = {1676-2592}
}

@JOURNAL{journal:educause:educause-review,
  journal = {{EDUCAUSE} Review},
  publisher = {EDUCAUSE},
  address = USA,
  issn = {1945-709X, 1527-6619}
}

@JOURNAL{journal:elsevier:aei,
  journal = {Advanced Engineering Informatics},
  publisher = {Elsevier Science},
  address = {Amsterdam, } # Netherlands,
  issn = {1474-0346}
}

@JOURNAL{journal:elsevier:ce,
  journal = {Computers \& Education},
  publisher = {Elsevier},
  address = Netherlands,
  issn = {0360-1315}
}

@JOURNAL{journal:elsevier:chb,
  journal = {Computers in Human Behavior},
  publisher = {Elsevier},
  address = {Amsterdam, } # Netherlands,
  issn = {0747-5632}
}

@JOURNAL{journal:elsevier:clss,
  journal = {Computer Languages, Systems \& Structures},
  publisher = {Elsevier},
  address = Netherlands,
  issn = {1477-8424}
}

@JOURNAL{journal:elsevier:csi,
  journal = {Computer Standards \& Interfaces},
  publisher = {Elsevier Science},
  address = {Amsterdam, } # Netherlands,
  issn = {0920-5489},
  owner = {magsilva},
  timestamp = {2014.08.31}
}

@JOURNAL{journal:elsevier:fgcs,
  journal = {Future Generation Computer Systems},
  publisher = {Elsevier},
  address = {Amsterdam, } # Netherlands,
  issn = {0167-739X},
  owner = {magsilva},
  timestamp = {2014.09.04}
}

@JOURNAL{journal:elsevier:ic,
  journal = {Information and Control},
  publisher = {Elsevier},
  issn = {0019-9958},
  timestamp = {2013-12-10}
}

@JOURNAL{journal:elsevier:ihe,
  journal = {The Internet and Higher Education},
  publisher = {Elsevier},
  address = Netherlands,
  issn = {1096-7516}
}

@JOURNAL{journal:elsevier:is,
  journal = {Information Sciences},
  publisher = {Elsevier},
  address = Netherlands,
  issn = {0020-0255}
}

@JOURNAL{journal:elsevier:ist,
  journal = {Information and Software Technology},
  publisher = {Elsevier},
  issn = {0950-5849}
}

@JOURNAL{journal:elsevier:jsis,
  journal = {The Journal of Strategic Information Systems},
  publisher = {Elsevier},
  address = Netherlands,
  issn = {0963-8687}
}

@JOURNAL{journal:elsevier:jss,
  journal = {Journal of Systems and Software},
  publisher = {Elsevier},
  address = Netherlands,
  issn = {0164-1212}
}

@JOURNAL{journal:elsevier:research-policy,
  journal = {Research Policy},
  publisher = {Elsevier},
  address = Germany,
  issn = {0048-7333},
  owner = {magsilva},
  timestamp = {2014.05.29}
}

@JOURNAL{journal:elsevier:scp,
  journal = {Science of Computer Programming},
  publisher = {Elsevier},
  address = {Amsterdam, } # Netherlands,
  issn = {0167-6423}
}

@JOURNAL{journal:elsevier:sn,
  journal = {Social Networks },
  publisher = {Elsevier},
  issn = {0378-8733}
}

@JOURNAL{journal:elsevier:ti,
  journal = {Telematics and Informatics},
  publisher = {Elsevier},
  address = Netherlands,
  issn = {0736-5853}
}

@JOURNAL{journal:erlbaum:hci,
  journal = {Human-Computer Interaction},
  publisher = {L. Erlbaum Associates},
  address = {Hillsdale, NJ, } # USA,
  issn = {0737-0024}
}

@JOURNAL{journal:hea-ics;italics,
  journal = {{ITALICS}},
  publisher = {HEA-ICS},
  address = {Southampton, } # UK,
  issn = {1473-7507}
}

@JOURNAL{journal:iee:sej,
  journal = {Software Engineering Journal},
  publisher = {IEE},
  address = USA,
  issn = {0268-6961}
}

@JOURNAL{journal:ieee:communications,
  journal = {IEEE Communications Magazine},
  publisher = {IEEE Communications Society},
  address = USA,
  issn = {0163-6804}
}

@JOURNAL{journal:ieee:computer,
  journal = {Computer},
  publisher = {IEEE Computer Society},
  address = USA,
  issn = {0018-9162}
}

@JOURNAL{journal:ieee:education,
  journal = {IEEE Transactions on Education},
  publisher = {IEEE},
  address = USA,
  issn = {0018-9359},
  owner = {magsilva},
  timestamp = {2014.08.29}
}

@JOURNAL{journal:ieee:history-computing,
  journal = {Annals of the History of Computing},
  publisher = {IEEE},
  issn = {0164-1239}
}

@JOURNAL{journal:ieee:internet-computing,
  journal = {IEEE Internet Computing},
  publisher = {IEEE Computer Society},
  address = {Los Alamitos, CA, } # USA,
  issn = {1089-7801}
}

@JOURNAL{journal:ieee:itee,
  journal = {Technology and Engineering Education},
  publisher = {IEEE Education Society Students Activities Committee (EdSocSAC)},
  address = USA,
  issn = {1558-7908}
}

@JOURNAL{journal:ieee:meem,
  journal = {Multidisciplinary Engineering Education Magazine},
  publisher = {IEEE Education Society Students Activities Committee (EdSocSAC)},
  address = USA,
  issn = {1558-7908},
  note = {This journal has been renamed to `Technology and Engineering Education'.}
}

@JOURNAL{journal:ieee:multimedia,
  journal = {IEEE MultiMedia},
  publisher = {IEEE Computer Society},
  address = USA,
  issn = {1070-986X}
}

@JOURNAL{journal:ieee:software,
  journal = {IEEE Software},
  publisher = {IEEE Computer Society},
  address = {Los Alamitos, CA, USA},
  issn = {0740-7459}
}

@JOURNAL{journal:ieee:tc,
  journal = {IEEE Transactions on Computers},
  publisher = {IEEE},
  issn = {0018-9340},
  owner = {magsilva},
  timestamp = {2014.10.23}
}

@JOURNAL{journal:ieee:te,
  journal = {Transactions on Education},
  publisher = {IEEE Education Society},
  address = {Los Alamitos, CA, } # USA,
  issn = {0018-9359}
}

@JOURNAL{journal:ieee:tlt,
  journal = {Transactions on Learning Technology},
  publisher = {IEEE Computer Society and IEEE Education Society},
  address = {Los Alamitos, CA, } # USA,
  issn = {1939-1382}
}

@JOURNAL{journal:ieee:tse,
  journal = {Transactions on Software Engineering},
  publisher = {IEEE Computer Society},
  address = USA,
  issn = {0098-5589}
}

@JOURNAL{journal:ieee:tsmc,
  journal = {IEEE Transactions on Systems, Man and Cybernetics},
  publisher = {IEEE},
  address = USA,
  issn = {0018-9472}
}

@JOURNAL{journal:iet:software,
  journal = {IET Software},
  publisher = {IET},
  address = England,
  issn = {1751-8806}
}

@JOURNAL{journal:ifets:ets,
  journal = {Journal of Educational Technology \& Society},
  publisher = {International Forum of Educational Technology \& Society},
  address = USA,
  issn = {1436-4522, 1176-3647}
}

@MISC{journal:ijel,
  title = {International Journal on E-Learning},
  address = {Chesapeake, VA, USA},
  issn = {1537-2456},
  journal = {International Journal on E-Learning},
  publisher = {AACE}
}

@JOURNAL{journal:imi:ie,
  journal = {Informatics in education},
  publisher = {Institute of Mathematics and Informatics},
  address = {Vilnius, } # Lithuania,
  issn = {1648-5831}
}

@JOURNAL{journal:informs:ms,
  journal = {Management Science},
  publisher = {Informs},
  address = {Catonsville, MD, } # USA,
  issn = {0025-1909},
  e-issn = {1526-5501},
  owner = {magsilva},
  timestamp = {2014.05.29}
}

@JOURNAL{journal:ios:ijaie,
  journal = {International Journal of Artificial Intelligence in Education},
  publisher = {IOS Press},
  address = {Amsterdam, } # Netherlands,
  issn = {1560-4292}
}

@JOURNAL{journal:jot,
  journal = {Journal of Object Technology},
  publisher = {Association Internationale pour les Technologies Objets (AITO)},
  address = {Kaiserslautern, } # Germany,
  issn = {1660-1769},
  timestamp = {2013-11-13}
}

@JOURNAL{journal:kluwer:umuai,
  journal = {User Modeling and User-Adapted Interaction},
  publisher = {Kluwer Academic Publishers},
  address = {Hingham, MA, } # USA,
  issn = {0924-1868},
  timestamp = {2013-09-24}
}

@JOURNAL{journal:misrc:misq,
  journal = {MIS Quarterly},
  publisher = {Society for Information Management and The Management Information Systems Research Center},
  address = {Minneapolis, MN, } # USA,
  issn = {0276-7783}
}

@JOURNAL{journal:nas:pnas,
  journal = {Proceedings of the National Academy of Sciences of the United States of America},
  publisher = {National Academy of Sciences},
  address = {Washington, DC, } # USA,
  e-issn = {1091-6490}
}

@JOURNAL{journal:puc-sp:rct,
  journal = {Revista de Computação e Tecnologia},
  publisher = {PUC-SP},
  address = {São Paulo, SP, } # Brazil,
  issn = {2176-7998},
  owner = {magsilva},
  timestamp = {2014.04.07}
}

@MISC{journal:rbie,
  title = {Revista Brasileira de Informática na Educação (RBIE)},
  address = {Porto Alegre, RS, Brazil},
  issn = {1414-5685},
  journal = {Revista Brasileira de Informática na Educação (RBIE)},
  publisher = {Comissão Especial de Informática na Educação (CEIE) -- Sociedade Brasileira de Computação (SBC)},
  url = {http://www.br-ie.org/pub/index.php/rbie/}
}

@JOURNAL{journal:routledge:cse,
  journal = {Computer Science Education},
  publisher = {Routledge},
  issn = {0899-3408},
  e-issn = {1744-5175}
}

@JOURNAL{journal:routledge:tip,
  journal = {Theory into Practice},
  publisher = {Routledge},
  address = {Philadelphia, PA, } # USA,
  issn = {0040-5841},
  e-issn = {1543-0421}
}

@JOURNAL{journal:sage:sscr,
  journal = {Social Science Computer Review},
  publisher = {Sage},
  address = {Thousand Oaks, CA, } # USA,
  issn = {0894-4393}
}

@JOURNAL{journal:sbc:jbcs,
  journal = {Journal of the Brazilian Computer Society},
  publisher = {SBC},
  address = {Porto Alegre, RS, } # Brazil,
  issn = {0104-6500},
  title = {Journal of the Brazilian Computer Society}
}

@JOURNAL{journal:sepc:ijics,
  journal = {International Journal of Information and Computer Science},
  publisher = {Science and Engineering Publishing Company},
  issn = {2161-6450},
  e-issn = {2161-5381}
}

@JOURNAL{journal:springer:acta-informatica,
  journal = {Acta Informatica},
  publisher = {Springer},
  address = {Berlin, } # Germany,
  issn = {0001-5903, 1432-0525}
}

@JOURNAL{journal:springer:cscw,
  journal = {Computer Supported Cooperative Work (CSCW)},
  publisher = {Springer},
  address = {Netherlands},
  issn = {0925-9724}
}

@JOURNAL{journal:springer:ese,
  journal = {Empirical Software Engineering},
  publisher = {Springer},
  address = USA,
  issn = {1382-3256},
  e-issn = {1573-7616}
}

@JOURNAL{journal:springer:heuristics,
  journal = {Journal of Heuristics},
  publisher = {Springer},
  address = USA,
  issn = {1381-1231}
}

@JOURNAL{journal:springer:hu,
  journal = {Journal of Heuristics},
  publisher = {Kluwer Academic Publishers},
  address = {Hingham, MA, } # USA,
  issn = {1381-1231}
}

@JOURNAL{journal:springer:is,
  journal = {Instructional Science},
  publisher = {Springer},
  address = Netherlands,
  issn = {0020-4277},
  owner = {magsilva},
  timestamp = {2014.08.13}
}

@JOURNAL{journal:springer:jbcs,
  journal = {Journal of the Brazilian Computer Society},
  publisher = {Springer},
  address = {Heidelberg, } # Germany,
  issn = {0104-6500, 1678-4804},
  title = {Journal of the Brazilian Computer Society}
}

@JOURNAL{journal:springer:jet,
  journal = {Journal of Electronic Testing},
  publisher = {Springer},
  address = Netherlands,
  issn = {0923-8174}
}

@JOURNAL{journal:springer:jisa,
  journal = {Journal of Internet Service and Applications},
  publisher = {Springer},
  address = {London, } # UK,
  issn = {1867-4828, 1869-0238}
}

@JOURNAL{journal:springer:jserd,
  journal = {Journal of Software Engineering Research and Development},
  publisher = {Springer},
  address = Germany,
  issn = {2195-1721}
}

@JOURNAL{journal:springer:mta,
  journal = {Multimedia Tools and Applications},
  publisher = {Springer},
  address = Netherlands,
  issn = {1380-7501}
}

@ARTICLE{journal:springer:multimedia-systems,
  address = {Berlin, } # Germany,
  issn = {0942-4962},
  journal = {Multimedia Systems},
  publisher = {Springer}
}

@JOURNAL{journal:springer:qip,
  journal = {Quantum Information Processing},
  publisher = {Springer},
  address = USA,
  issn = {1570-0755}
}

@JOURNAL{journal:springer:re,
  journal = {Requirements Engineering},
  publisher = {Springer},
  address = {Secaucus, NJ, } # USA,
  issn = {0947-3602}
}

@JOURNAL{journal:springer:scientometrics,
  journal = {Scientometrics},
  publisher = {Springer},
  address = {Netherlands},
  issn = {0138-9130}
}

@JOURNAL{journal:springer:scis,
  journal = {Science China Information Sciences},
  publisher = {Springer-Verlag and Science China},
  address = China,
  issn = {1674-733X},
  e-issn = {1869-1919},
  timestamp = {2013-08-09}
}

@JOURNAL{journal:springer:sosym,
  journal = {Software and Systems Modeling},
  publisher = {Springer-Verlag},
  address = {Secaucus, NJ, } # USA,
  issn = {1619-1366}
}

@JOURNAL{journal:springer:sqj,
  journal = {Software Quality Journal},
  publisher = {Springer},
  address = USA,
  issn = {0963-9314},
  e-issn = {1573-1367}
}

@JOURNAL{journal:unicep:multiciencia,
  journal = {Multiciência},
  publisher = {UNICEP},
  address = {São Carlos, SP, } # Brazil,
  issn = {1413-8972}
}

@JOURNAL{journal:wiley:bell,
  journal = {Bell Systems Technical Journal},
  publisher = {Blackwell Publishing},
  address = USA,
  issn = {1538-7305},
  pages = {1045-1079}
}

@JOURNAL{journal:wiley:ccpe,
  journal = {Concurrency and Computation: Practice and Experience},
  publisher = {John Wiley \& Sons},
  address = USA,
  issn = {1532-0634},
  doi = {10.1002/cpe.1297}
}

@JOURNAL{journal:wiley:jsep,
  journal = {Journal of Software Maintenance and Evolution: Research and Practice},
  publisher = {John Wiley \& Sons},
  address = USA,
  issn = {1532-0618}
}

@JOURNAL{journal:wiley:spe,
  journal = {Software: Practice and Experience},
  publisher = {John Wiley \& Sons},
  address = {New York, NY, } # USA,
  issn = {0038-0644}
}

@JOURNAL{journal:wiley:stvr,
  journal = {Software Testing, Verification and Reliability},
  publisher = {Wiley},
  address = USA,
  issn = {1099-1689}
}

@JOURNAL{journal:wiley:sys,
  journal = {Systems Engineering},
  publisher = {John Wiley and Sons},
  address = {Chichester, } # UK,
  issn = {1098-1241},
  owner = {magsilva},
  timestamp = {2014.09.25}
}

@MISC{LearningSpace02,
  title = {{Learning Space}},
  howpublished = {Project Page},
  owner = {magsilva},
  timestamp = {2008.07.31},
  url = {http://www.lotus.com/home.nsf/welcome/learnspace}
}

@MISC{PGL02-EN,
  title = {{Partnership in Global Learning}},
  howpublished = {Project Page},
  owner = {magsilva},
  timestamp = {2008.07.31},
  url = {http://www.pgl.ufl.edu}
}

@MISC{proc:2006,
  title = {The /proc filesystem documentation},
  owner = {magsilva},
  timestamp = {2006.07.06},
  url = {http://linux.inet.hr/proc_sys_net_ipv4.html}
}

@PROCEEDINGS{proceedings:cbie:2012,
  owner = {magsilva},
  timestamp = {2014.08.01}
}

@PROCEEDINGS{proceedings:euroitv:2005,
  booktitle = {EuroITV 2005},
  title = {EuroITV 2005},
  month = mar # {--} # apr,
  days = {30-1},
  location = {Aalborg, Denmark},
  series = {EuroITV}
}

@MISC{software:adldap,
  title = {adLDAP},
  howpublished = {Programa de Computador},
  owner = {msilva},
  timestamp = {2007.07.23},
  url = {http://adldap.sourceforge.net/}
}

@MISC{software:appalachian,
  title = {Appalachian},
  owner = {msilva},
  timestamp = {2007.07.23},
  url = {http://simile.mit.edu/wiki/Appalachian}
}

@MISC{software:CruiseControl,
  title = {CruiseControl},
  owner = {magsilva},
  timestamp = {2010.05.14},
  url = {http://cruisecontrol.sourceforge.net/}
}

@MISC{software:phpUnderControl,
  title = {phpUnderControl},
  owner = {magsilva},
  timestamp = {2010.05.14},
  url = {http://www.phpundercontrol.org}
}

@MISC{software:snaptest,
  title = {SnapTest},
  howpublished = {Programa de computador},
  owner = {magsilva},
  timestamp = {2010.05.14},
  url = {http://github.com/Jakobo/snaptest}
}

@MISC{standard:java:javadtv,
  title = {Java {DTV}},
  organization = {{Fórum Brasileiro de TV Digital} and {Sun Microsystems}},
  url = {http://www.forumsbtvd.org.br/materias.asp?id=200}
}

@MISC{TopClass02,
  title = {{TopClass}},
  howpublished = {Project Page},
  owner = {magsilva},
  timestamp = {2008.07.31},
  url = {http://www.wbtsystems.com/index.html}
}

@PROCEEDINGS{proceedings:ease:2014,
  booktitle = {18th International Conference on Evaluation and Assessment in Software Engineering},
  title = {18th International Conference on Evaluation and Assessment in Software Engineering},
  year = {2014},
  month = may,
  days = {13--14},
  location = {London, #UK#},
  isbn = {9781450324762},
  publisher = {ACM},
  owner = {magsilva},
  timestamp = {2014.08.19}
}

@PROCEEDINGS{proceedings:hicss:2014,
  booktitle = {47th Hawaii International Conference on System Science},
  year = {2014},
  location = {Hawaii, #USA#},
  publisher = {IEEE Computer Society}
}

@PROCEEDINGS{proceedings:icer:2014,
  booktitle = {10th Annual Conference on International Computing Education Research},
  title = {10th Annual Conference on International Computing Education Research},
  year = {2014},
  month = aug,
  days = {11--13},
  location = {Glasgow, Scotland, #UK#},
  isbn = {978-1-4503-2755-8},
  address = {New York, NY, } # USA,
  publisher = {ACM},
  owner = {magsilva},
  timestamp = {2014.09.13}
}

@PROCEEDINGS{proceedings:icse:2014,
  booktitle = {36th International Conference on Software Engineering},
  title = {36th International Conference on Software Engineering},
  year = {2014},
  month = may # {--} # jun,
  days = {31--7},
  location = {Hyderabad, #India#},
  isbn = {978-1-4503-2756-5},
  address = {New York, NY, } # USA,
  publisher = {ACM},
  owner = {magsilva},
  timestamp = {2014.05.22}
}

@PROCEEDINGS{proceedings:icse:seet:2014,
  booktitle = {36th International Conference on Software Engineering -- Software Engineering Education and Training (SEET) Track},
  title = {36th International Conference on Software Engineering -- Software Engineering Education and Training (SEET) Track},
  year = {2014},
  month = jun,
  location = {Hyderabad, #India#},
  address = {New York, NY, } # USA,
  publisher = {ACM}
}

@PROCEEDINGS{proceedings:icse-doctoral:2014,
  booktitle = {Companion Proceedings of the 36th International Conference on Software Engineering -- Doctoral Symposium},
  title = {Companion Proceedings of the 36th International Conference on Software Engineering -- Doctoral Symposium},
  year = {2014},
  month = jun,
  days = {4},
  location = {Hyderabad, #India#},
  isbn = {978-1-4503-2768-8},
  address = {New York, NY, } # USA,
  publisher = {ACM},
  owner = {magsilva}
}

@PROCEEDINGS{proceedings:issta:2014,
  booktitle = {2014 International Symposium on Software Testing and Analysis},
  title = {2014 International Symposium on Software Testing and Analysis},
  year = {2014},
  month = jul,
  days = {21--26},
  location = {San Jose, CA, #USA#},
  isbn = {978-1-4503-2645-2},
  address = {New York, NY, USA},
  publisher = {ACM},
  owner = {magsilva},
  timestamp = {2014.07.21}
}

@PROCEEDINGS{proceedings:itcse:2014,
  booktitle = {19th Annual Conference on Innovation and Technology in Computer Science Education},
  title = {19th Annual Conference on Innovation and Technology in Computer Science Education},
  year = {2014},
  month = jun,
  days = {23--25},
  location = {Uppsala, #Sweden#},
  isbn = {978-1-4503-2833-3},
  address = {New York, NY, } # USA,
  publisher = {ACM},
  owner = {magsilva},
  timestamp = {2014.08.30}
}

@PROCEEDINGS{proceedings:las:2014,
  booktitle = {1st ACM Conference on Learning @ Scale Conference},
  year = {2014},
  location = {Atlanta, Georgia, USA},
  isbn = {978-1-4503-2669-8},
  address = {New York, NY, USA},
  publisher = {ACM},
  owner = {magsilva},
  timestamp = {2014.05.18}
}

@PROCEEDINGS{proceedings:libreoffice:2014,
  booktitle = {LibreOffice Conference 2014},
  title = {LibreOffice Conference 2014},
  year = {2014},
  month = sep,
  days = {2--5},
  location = {Bern, #Switzerland#},
  owner = {magsilva},
  timestamp = {2014.09.12}
}

@PROCEEDINGS{proceedings:msr:2014,
  booktitle = {11th Working Conference on Mining Software Repositories},
  title = {11th Working Conference on Mining Software Repositories},
  year = {2014},
  month = may # {--} # jun,
  days = {30--1},
  location = {Hyderabad, #India#},
  isbn = {978-1-4503-2863-0},
  address = {New York, NY, USA},
  publisher = {ACM},
  owner = {magsilva},
  timestamp = {2014.05.21}
}

@PROCEEDINGS{proceedings:sac:2014,
  booktitle = {29th Annual ACM Symposium on Applied Computing},
  title = {29th Annual ACM Symposium on Applied Computing},
  year = {2014},
  month = mar,
  days = {24--28},
  location = {Gyeongju, #South Korea#},
  isbn = {978-1-4503-2469-4},
  address = {New York, NY, } # USA,
  publisher = {ACM},
  owner = {magsilva},
  timestamp = {2014.08.29}
}

@PROCEEDINGS{proceedings:sigcse:2014,
  booktitle = {45th ACM technical symposium on Computer science education},
  title = {45th ACM technical symposium on Computer science education},
  year = {2014},
  month = mar,
  days = {5--8},
  location = {Atlanta, GA, #USA#},
  isbn = {978-1-4503-2605-6},
  address = {New York, NY, } # USA,
  publisher = {ACM},
  owner = {magsilva},
  timestamp = {2014.03.04}
}

@PROCEEDINGS{proceedings:swqd:2014,
  booktitle = {6th International Conference on Software Quality Days},
  title = {6th International Conference on Software Quality Days},
  year = {2014},
  month = jan,
  days = {14--16},
  location = {Vienna, #Austria#},
  isbn = {9783319036014},
  volume = {166},
  series = {Lecture Notes in Business Information Processing},
  publisher = {Springer Verlag},
  issn = {18651348},
  owner = {magsilva},
  timestamp = {2014.08.19}
}

@PROCEEDINGS{proceedings:alice:2013,
  booktitle = {3rd Alice Symposium on Alice Symposium},
  title = {3rd Alice Symposium on Alice Symposium},
  year = {2013},
  month = jun,
  days = {17--21},
  location = {Durham, NC, #USA#},
  isbn = {978-1-4503-2250-8},
  address = {New York, NY, } # USA,
  publisher = {ACM},
  owner = {magsilva},
  timestamp = {2014.03.03}
}

@PROCEEDINGS{proceedings:chase:2013,
  booktitle = {6th International Workshop on Cooperative and Human Aspects of Software Engineering},
  title = {6th International Workshop on Cooperative and Human Aspects of Software Engineering},
  year = {2013},
  month = may,
  location = {San Francisco, CA, #USA#},
  isbn = {978-1-4673-6290-0},
  accepted-papers = {9},
  day = {25--25},
  submitted-papers = {51},
  timestamp = {2013-12-18}
}

@PROCEEDINGS{proceedings:cise:2013,
  booktitle = {1st International Workshop on Conducting Empirical Studies in Industry},
  title = {1st International Workshop on Conducting Empirical Studies in Industry},
  year = {2013},
  month = may,
  days = {20},
  location = {San Francisco, CA, #USA#},
  address = {San Francisco, CA},
  publisher = {IEEE Computer Society},
  owner = {magsilva},
  timestamp = {2014.08.19}
}

@PROCEEDINGS{proceedings:cisti:2013,
  booktitle = {8th Iberian Conference on Information Systems and Technologies},
  title = {8th Iberian Conference on Information Systems and Technologies},
  year = {2013},
  month = jun,
  days = {19--22},
  location = {Lisboa, #Portugal#}
}

@PROCEEDINGS{proceedings:clei:2013,
  booktitle = {XXXIX Latin American Computing Conference},
  title = {XXXIX Latin American Computing Conference},
  year = {2013},
  month = oct,
  days = {7--11},
  location = {Naiguatá, Vargas, #Venezuela#},
  isbn = {978-1-4799-2957-3},
  owner = {magsilva},
  timestamp = {2014.03.03}
}

@PROCEEDINGS{proceedings:cseet:2013,
  booktitle = {26th Conference on Software Engineering Education and Training},
  title = {26th Conference on Software Engineering Education and Training},
  year = {2013},
  month = may,
  days = {19--21},
  location = {San Francisco, CA, #USA#},
  issn = {1093-0175},
  owner = {magsilva},
  timestamp = {2014.09.12}
}

@PROCEEDINGS{proceedings:ercica:2013,
  booktitle = {1st International Conference on Emerging Research in Computing, Information, Communication and Applications},
  title = {1st International Conference on Emerging Research in Computing, Information, Communication and Applications},
  year = {2013},
  month = aug,
  days = {2--3},
  location = {Yelahanka, Bangalore, #India#},
  isbn = {9789351071020},
  publisher = {Elsevier},
  owner = {magsilva},
  timestamp = {2014.07.21}
}

@PROCEEDINGS{proceedings:esem:2013,
  booktitle = {7th International Symposium on Empirical Software Engineering and Measurement},
  title = {7th International Symposium on Empirical Software Engineering and Measurement},
  year = {2013},
  month = oct,
  days = {10--11},
  location = {Baltimore, MD, #USA#},
  isbn = {978-0-7695-5056-5},
  issn = {1938-6451},
  keywords = {software engineering;SE domain;SLR process;automated search strategy;mapping study;software engineering;support systematic literature reviews;visualisation techniques;Software;Software engineering;Software measurement;Systematics;Text mining;Visualization;automated tool;systematic literature review}
}

@PROCEEDINGS{proceedings:esud:2013,
  booktitle = {X Congresso Brasileiro de Ensino Superior a Distância},
  title = {X Congresso Brasileiro de Ensino Superior a Distância},
  year = {2013},
  month = jun,
  location = {Belém, PA, #Brazil#},
  publisher = {UNIREDE},
  day = {11--13},
  timestamp = {2013-09-22}
}

@PROCEEDINGS{proceedings:euromicro-seaa:2013,
  booktitle = {39th Euromicro Conference Series on Software Engineering and Advanced Applications},
  title = {39th Euromicro Conference Series on Software Engineering and Advanced Applications},
  year = {2013},
  month = sep,
  days = {4--6},
  location = {Santander, #Spain#},
  isbn = {9780769550916},
  owner = {magsilva},
  timestamp = {2014.08.19}
}

@PROCEEDINGS{proceedings:fie:2013,
  booktitle = {43rd Annual Frontiers in Education Conference},
  title = {43rd Annual Frontiers in Education Conference},
  year = {2013},
  month = oct,
  days = {23--26},
  location = {Oklahome City, Oklahoma, #USA#},
  isbn = {978-1-4673-5261-1},
  publisher = {IEEE},
  issn = {0190-5848},
  owner = {magsilva},
  timestamp = {2014.07.21}
}

@PROCEEDINGS{proceedings:hicss:2013,
  booktitle = {46th Hawaii International Conference on System Sciences},
  title = {46th Hawaii International Conference on System Sciences},
  year = {2013},
  month = jan,
  days = {7--10},
  location = {Wailea, HI, #USA#},
  isbn = {978-1-4673-5933-7},
  e-isbn = {978-0-7695-4892-0},
  issn = {1530-1605}
}

@PROCEEDINGS{proceedings:icer:2013,
  booktitle = {9th Annual International ACM Conference on International Computing Education Research},
  title = {9th Annual International ACM Conference on International Computing Education Research},
  year = {2013},
  month = aug,
  location = {San Diego, San California, USA},
  isbn = {978-1-4503-2243-0},
  series = {ICER '13},
  address = {New York, NY, USA},
  publisher = {ACM},
  day = {12--14}
}

@PROCEEDINGS{proceedings:icse:2013,
  booktitle = {35th International Conference on Software Engineering},
  year = {2013},
  month = may,
  location = {San Francisco, CA, #USA#},
  isbn = {978-1-4673-3076-3},
  address = {Piscataway, NJ, } # USA,
  publisher = {IEEE},
  day = {18--26}
}

@PROCEEDINGS{proceedings:isec:2013,
  booktitle = {6th India Software Engineering Conference},
  title = {6th India Software Engineering Conference},
  year = {2013},
  month = feb,
  location = {New Delhi, #India#},
  isbn = {978-1-4503-1987-4},
  publisher = {ACM},
  day = {21--23}
}

@PROCEEDINGS{proceedings:msr:2013,
  booktitle = {10th Working Conference on Mining Software Repositories},
  title = {10th Working Conference on Mining Software Repositories},
  year = {2013},
  month = may,
  location = {San Francisco, CA, #USA#},
  isbn = {978-1-4673-2936-1},
  address = {Piscataway, NJ, } # USA,
  publisher = {IEEE and ACM},
  colocated-with = {proceedings:icse:2013},
  day = {18--19},
  issn = {2160-1852}
}

@PROCEEDINGS{proceedings:osdoc:2013,
  booktitle = {Workshop on Open Source and Design of Communication},
  title = {Workshop on Open Source and Design of Communication},
  year = {2013},
  location = {Lisbon, #Portugal#},
  isbn = {978-1-4503-2255-3},
  address = {New York, NY, } # USA,
  publisher = {ACM},
  owner = {magsilva},
  timestamp = {2014.05.22}
}

@PROCEEDINGS{proceedings:pmde:2013,
  booktitle = {3rd Workshop on Process-Based Approaches for Model-Driven Engineering},
  title = {3rd Workshop on Process-Based Approaches for Model-Driven Engineering},
  year = {2013},
  month = jul,
  days = {2},
  location = {Montpellier, #France#},
  isbn = {978-1-4503-2047-4},
  address = {New York, NY, } # USA,
  publisher = {ACM},
  colocated-with = {proceedings:ecoop:2013},
  owner = {magsilva},
  timestamp = {2014.02.23}
}

@PROCEEDINGS{proceedings:reser:2013,
  booktitle = {3rd International Workshop on Replication in Empirical Software Engineering Research},
  title = {3rd International Workshop on Replication in Empirical Software Engineering Research},
  year = {2013},
  month = oct,
  days = {9},
  location = {Baltimore, MD, #USA#}
}

@PROCEEDINGS{proceedings:sac:2013,
  booktitle = {28th Annual ACM Symposium on Applied Computing},
  year = {2013},
  month = mar,
  location = {Coimbra, #Portugal#},
  isbn = {978-1-4503-1656-9},
  publisher = {ACM},
  day = {18--22}
}

@PROCEEDINGS{proceedings:sigcse:2013,
  booktitle = {44th ACM Technical Symposium on Computer Science Education},
  year = {2013},
  month = mar,
  location = {Denver, Colorado, #USA#},
  isbn = {978-1-4503-1868-6},
  address = {New York, NY, } # USA,
  publisher = {ACM},
  day = {6--9}
}

@PROCEEDINGS{proceedings:sigite:2013,
  booktitle = {14th Annual ACM SIGITE Conference on Information Technology Education},
  title = {14th Annual ACM SIGITE Conference on Information Technology Education},
  year = {2013},
  month = oct,
  location = {Orlando, Florida, USA},
  isbn = {978-1-4503-2239-3},
  publisher = {ACM},
  day = {10--12}
}

@PROCEEDINGS{proceedings:splash:docsym:2013,
  booktitle = {2013 Conference on Systems, Programming, \& Applications: Software for Humanity -- Doctoral Symposium},
  year = {2013},
  location = {Indianapolis, Indiana, #USA#},
  isbn = {978-1-4503-1995-9},
  address = {New York, NY, } # USA,
  publisher = {ACM},
  owner = {magsilva},
  timestamp = {2014.08.31}
}

@PROCEEDINGS{proceedings:wikisym-opensym:2013,
  booktitle = {Joint International Symposium on Open Collaboration: OpenSym + WikiSym},
  year = {2013},
  month = aug,
  location = {Hong Kong, #China#},
  publisher = {ACM},
  day = {5--7},
  timestamp = {2013-08-07}
}

@PROCEEDINGS{proceedings:www:2013,
  booktitle = {22nd International Conference on World Wide Web},
  title = {22nd International Conference on World Wide Web},
  year = {2013},
  month = may,
  days = {13--17},
  location = {Rio de Janeiro, RJ, #Brazil#},
  isbn = {978-1-4503-2035-1},
  publisher = {International World Wide Web Conferences Steering Committee},
  owner = {magsilva},
  timestamp = {2014.05.21}
}

@PROCEEDINGS{proceedings:ase:2012,
  booktitle = {27th International Conference on Automated Software Engineering},
  title = {27th International Conference on Automated Software Engineering},
  year = {2012},
  month = sep,
  days = {3--7},
  location = {Essen, #Germany#},
  isbn = {978-1-4503-1204-2},
  address = {New York, NY, } # USA,
  publisher = {IEEE/ACM}
}

@PROCEEDINGS{proceedings:cbie:wrea:2012,
  booktitle = {Congresso Brasileiro de Informática na Educação 2012 -- Workshop Recursos Educacionais},
  title = {Congresso Brasileiro de Informática na Educação 2012 -- Workshop Recursos Educacionais},
  year = {2012},
  month = nov,
  days = {28--29},
  issn = {2316-8889},
  owner = {magsilva},
  timestamp = {2014.08.01}
}

@PROCEEDINGS{proceedings:cgc:2012,
  booktitle = {2nd International Conference on Cloud and Green Computing},
  title = {2nd International Conference on Cloud and Green Computing},
  year = {2012},
  month = nov,
  location = {Xiangtan, Hunan, #China#},
  day = {1--3}
}

@PROCEEDINGS{proceedings:cisis:2012,
  booktitle = {6th International Conference on Complex, Intelligent and Software Intensive Systems},
  title = {6th International Conference on Complex, Intelligent and Software Intensive Systems},
  year = {2012},
  month = jul,
  location = {Palermo, #Italy#},
  isbn = {978-1-4673-1233-2},
  day = {4--6},
  timestamp = {2013-12-20}
}

@PROCEEDINGS{proceedings:compsac:2012,
  booktitle = {IEEE 36th Annual Computer Software and Applications Conference},
  year = {2012},
  month = jul,
  location = {Izmir, #Turkey#},
  isbn = {978-1-4673-1990-4},
  e-isbn = {978-0-7695-4736-7},
  volume = {1},
  publisher = {IEEE Computer Society},
  accepted-papers = {41},
  day = {16--20},
  issn = {0730-3157},
  submitted-papers = {237}
}

@PROCEEDINGS{proceedings:coneco:2012,
  booktitle = {5º Congresso de Estudantes de Pós-graduação em Comunicação},
  title = {5º Congresso de Estudantes de Pós-graduação em Comunicação},
  year = {2012},
  month = oct,
  days = {24--26},
  location = {Niterói, RJ, #Brazil#},
  owner = {magsilva},
  timestamp = {2014.04.01}
}

@PROCEEDINGS{proceedings:csbc:2012,
  booktitle = {Congresso da Sociedade Brasileira da Computação (CSBC) -- XXXI Jornadas de Atualização em Informática (JAI)},
  year = {2012},
  month = jul,
  days = {16--19},
  location = {Curitiba, PR, #Brazil#}
}

@PROCEEDINGS{proceedings:ease:2012,
  booktitle = {16th International Conference on Evaluation and Assessment in Software Engineering},
  title = {16th International Conference on Evaluation and Assessment in Software Engineering},
  year = {2012},
  month = may,
  days = {14--15},
  location = {Ciudad Real, #Spain#},
  isbn = {9781849195416},
  owner = {magsilva},
  timestamp = {2014.08.19}
}

@PROCEEDINGS{proceedings:escience:2012,
  booktitle = {IEEE 8th International Conference on E-Science},
  title = {IEEE 8th International Conference on E-Science},
  year = {2012},
  month = oct,
  days = {8--12},
  location = {Chicago, IL, #USA#},
  isbn = {978-1-4673-4467-8},
  owner = {magsilva},
  timestamp = {2014.04.08}
}

@PROCEEDINGS{proceedings:esem:2012,
  booktitle = {6th International Symposium on Empirical Software Engineering and Measurement},
  title = {6th International Symposium on Empirical Software Engineering and Measurement},
  year = {2012},
  month = sep,
  location = {Lund, #Sweden#},
  isbn = {978-1-4503-1056-7},
  address = {New York, NY, } # USA,
  publisher = {ACM},
  day = {19--20}
}

@PROCEEDINGS{proceedings:fse:2012,
  booktitle = {ACM SIGSOFT 20th International Symposium on the Foundations of Software Engineering},
  year = {2012},
  month = nov,
  location = {Cary, North Carolina, #USA#},
  isbn = {978-1-4503-1614-9},
  publisher = {ACM},
  day = {11--16}
}

@PROCEEDINGS{proceedings:icce:2012,
  booktitle = {20th International Conference on Computers in Education},
  year = {2012},
  month = nov,
  days = {26--30},
  location = {#Singapore#}
}

@PROCEEDINGS{proceedings:icer:2012,
  booktitle = {9th Annual International Conference on International Computing Education Research},
  title = {9th Annual International Conference on International Computing Education Research},
  year = {2012},
  location = {Auckland, #New Zealand#},
  isbn = {978-1-4503-1604-0},
  address = {New York, NY, } # USA,
  publisher = {ACM}
}

@PROCEEDINGS{proceedings:icgse:2012,
  booktitle = {7th International Conference on Global Software Engineering},
  title = {7th International Conference on Global Software Engineering},
  year = {2012},
  month = aug,
  days = {27--30},
  location = {Porto Alegre, RS, #Brazil#},
  isbn = {978-1-4673-2357-4},
  e-isbn = {978-0-7695-4787-9},
  owner = {magsilva},
  timestamp = {2014.03.03}
}

@PROCEEDINGS{proceedings:icsm:2012,
  booktitle = {28th IEEE International Conference on Software Maintenance},
  year = {2012},
  month = sep,
  location = {Trento, #Italy#},
  isbn = {978-1-4673-2313-0},
  day = {23--28},
  issn = {1063-6773}
}

@PROCEEDINGS{proceedings:icst:2012,
  booktitle = {IEEE 5h International Conference on Software Testing, Verification and Validation},
  title = {IEEE 5h International Conference on Software Testing, Verification and Validation},
  year = {2012},
  month = apr,
  location = {Montreal, QC, #Canada#},
  isbn = {978-1-4577-1906-6},
  day = {17--21},
  timestamp = {2013-12-09}
}

@PROCEEDINGS{proceedings:iri:2012,
  booktitle = {13th International Conference on Information Reuse and Integration (IRI)},
  year = {2012},
  month = aug,
  location = {Las Vegas, Nevada, #USA#},
  isbn = {978-1-4673-2284-3},
  publisher = {IEEE Systems, Man, and Cybernetics Society (SMC)},
  day = {8--10}
}

@PROCEEDINGS{proceedings:itcse:2012,
  booktitle = {17th Annual Joint Conference on Innovation and Technology in Computer Science Education},
  title = {17th Annual Joint Conference on Innovation and Technology in Computer Science Education},
  year = {2012},
  month = jul,
  days = {3--5},
  location = {Haifa, #Israel#},
  isbn = {978-1-4503-1246-2},
  publisher = {ACM}
}

@PROCEEDINGS{proceedings:kdd:2012,
  booktitle = {18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  year = {2012},
  month = agu,
  location = {Beijing, #China#},
  isbn = {978-1-4503-1462-6},
  address = {New York, NY, } # USA,
  publisher = {ACM},
  day = {12--16}
}

@PROCEEDINGS{proceedings:koli-calling:2012,
  booktitle = {12th Koli Calling International Conference on Computing Education Research},
  title = {12th Koli Calling International Conference on Computing Education Research},
  year = {2012},
  month = nov,
  location = {Koli, #Finland#},
  isbn = {978-1-4503-1795-5},
  address = {New York, NY, } # USA,
  publisher = {ACM},
  day = {15--18}
}

@PROCEEDINGS{proceedings:lak:2012,
  booktitle = {2nd International Conference on Learning Analytics and Knowledge},
  title = {2nd International Conference on Learning Analytics and Knowledge},
  year = {2012},
  month = apr # {--} # may,
  location = {Vancouver, BC, #Canada#},
  isbn = {978-1-4503-1111-3},
  day = {29--2}
}

@PROCEEDINGS{proceedings:quatic:2012,
  booktitle = {8th International Conference on the Quality of Information and Communications Technology},
  title = {8th International Conference on the Quality of Information and Communications Technology},
  year = {2012},
  month = sep,
  days = {2--6},
  location = {Lisbon, #Portugal#},
  isbn = {9780769547770},
  owner = {magsilva},
  timestamp = {2014.08.19}
}

@PROCEEDINGS{proceedings:rsse:2012,
  booktitle = {3rd International Workshop on Recommendation Systems for Software Engineering},
  title = {3rd International Workshop on Recommendation Systems for Software Engineering},
  year = {2012},
  month = jun,
  location = {Zurich},
  isbn = {978-1-4673-1758-0},
  day = {4}
}

@PROCEEDINGS{proceedings:sac:2012,
  booktitle = {27th Annual ACM Symposium on Applied Computing},
  title = {27th Annual ACM Symposium on Applied Computing},
  year = {2012},
  month = mar,
  days = {26--30},
  location = {Riva del Garda, Trento, #Italy#},
  isbn = {978-1-4503-0857-1},
  address = {New York, NY, } # USA,
  publisher = {ACM},
  owner = {magsilva},
  timestamp = {2014.06.04}
}

@PROCEEDINGS{proceedings:sbes:2012,
  booktitle = {26th Brazilian Symposium on Software Engineering},
  title = {26th Brazilian Symposium on Software Engineering},
  year = {2012},
  month = sep,
  days = {23--28},
  location = {Natal, RN, #Brazil#},
  isbn = {978-0-7695-4868-5},
  publisher = {IEEE Computer Society},
  papers-accepted = {18},
  papers-submitted = {93}
}

@PROCEEDINGS{proceedings:sbie:2012,
  booktitle = {23º Simpósio Brasileiro de Informática na Educação},
  title = {23º Simpósio Brasileiro de Informática na Educação},
  year = {2012},
  month = nov,
  location = {Rio de Janeiro, RJ, #Brazil#},
  day = {26--30},
  issn = {2316-6533},
  timestamp = {2013-09-22}
}

@PROCEEDINGS{proceedings:sbsc:2012,
  booktitle = {Brazilian Symposium on Collaborative Systems},
  title = {Brazilian Symposium on Collaborative Systems},
  year = {2012},
  month = oct,
  location = {São Paulo, SP, #Brazil#},
  isbn = {978-1-4673-4696-2},
  day = {15--18}
}

@PROCEEDINGS{proceedings:scam:2012,
  booktitle = {12th International Working Conference on Source Code Analysis and Manipulation},
  title = {12th International Working Conference on Source Code Analysis and Manipulation},
  year = {2012},
  month = sep,
  days = {23--24},
  location = {Trento, #Italy#},
  isbn = {978-1-4673-2398-7},
  publisher = {IEEE Computer Society},
  owner = {magsilva},
  timestamp = {2014.01.27}
}

@PROCEEDINGS{proceedings:seke:2012,
  booktitle = {24th International Conference on Software Engineering \& Knowledge Engineering},
  year = {2012},
  month = jul,
  location = {Redwood City, San Francisco Bay, #USA#},
  isbn = {1-891706-31-4},
  day = {1--3}
}

@PROCEEDINGS{proceedings:sigcse:2012,
  booktitle = {43rd ACM Technical Symposium on Computer Science Education},
  title = {43rd ACM Technical Symposium on Computer Science Education},
  year = {2012},
  month = feb # {--} # mar,
  days = {29--3},
  location = {Raleigh, North Carolina, #USA#},
  isbn = {978-1-4503-1098-7},
  publisher = {ACM}
}

@PROCEEDINGS{proceedings:sigite:2012,
  booktitle = {13th Annual Conference on Information Technology Education},
  year = {2012},
  location = {Calgary, Alberta, #Canada#},
  isbn = {978-1-4503-1464-0},
  publisher = {ACM}
}

@PROCEEDINGS{proceedings:sigmis-cpr:2012,
  booktitle = {50th Annual Conference on Computers and People Research},
  title = {50th Annual Conference on Computers and People Research},
  year = {2012},
  location = {Milwaukee, Wisconsin, #USA#},
  isbn = {978-1-4503-1110-6},
  address = {New York, NY, } # USA,
  publisher = {ACM}
}

@PROCEEDINGS{proceedings:wccce:2012,
  booktitle = {17th Western Canadian Conference on Computing Education},
  title = {17th Western Canadian Conference on Computing Education},
  year = {2012},
  month = may,
  location = {Vancouver, BC, #Canada#},
  isbn = {978-1-4503-1407-7},
  address = {New York, NY, USA},
  publisher = {ACM},
  day = {4--5}
}

@PROCEEDINGS{proceedings:webmedia:2012,
  booktitle = {18th Brazilian symposium on Multimedia and the Web},
  title = {18th Brazilian symposium on Multimedia and the Web},
  year = {2012},
  month = oct,
  days = {15--18},
  location = {São Paulo, SP, #Brazil#},
  isbn = {978-1-4503-1706-1},
  address = {New York, NY, } # USA,
  publisher = {ACM},
  papers-accepted = {33},
  papers-submitted = {108},
  promoter = {Brazilian Computer Society}
}

@PROCEEDINGS{proceedings:xp:2012,
  booktitle = {13th International Conference on Agile Software Development},
  title = {13th International Conference on Agile Software Development},
  year = {2012},
  month = may,
  days = {21--25},
  location = {Malmo, #Sweden#},
  isbn = {9783642303494},
  volume = {111},
  series = {Lecture Notes in Business Information Processing},
  issn = {18651348},
  owner = {magsilva},
  timestamp = {2014.08.19}
}

@PROCEEDINGS{proceedings:ace:2011,
  booktitle = {13nd Australasian Computing Education Conference},
  title = {13nd Australasian Computing Education Conference},
  year = {2011},
  location = {Perth, #Australia#},
  isbn = {978-1-920682-94-1},
  volume = {114},
  address = {Darlinghurst, } # Australia,
  publisher = {Australian Computer Society},
  owner = {magsilva},
  timestamp = {2014.08.31}
}

@PROCEEDINGS{proceedings:aosd:2011,
  booktitle = {10th International Conference on Aspect-Oriented Software Development},
  title = {10th International Conference on Aspect-Oriented Software Development},
  year = {2011},
  month = mar,
  days = {21--25},
  location = {Porto de Galinhas, #Brazil#},
  isbn = {978-1-4503-0606-5},
  publisher = {ACM}
}

@PROCEEDINGS{proceedings:applets:2011,
  booktitle = {1st Workshop on Applications to Provide Learning and Teaching Support (APPLETS)},
  title = {1st Workshop on Applications to Provide Learning and Teaching Support (APPLETS)},
  year = {2011},
  month = oct,
  location = {Aracaju, SE, #Brazil#},
  colocated-with = {proceedings:sbie:2011},
  day = {21},
  issn = {2176-4301},
  timestamp = {2013-09-23}
}

@PROCEEDINGS{proceedings:ase:2011,
  booktitle = {26th IEEE/ACM International Conference on Automated Software Engineering},
  title = {26th IEEE/ACM International Conference on Automated Software Engineering},
  year = {2011},
  month = nov,
  days = {6--12},
  location = {Lawrence, Kansas, #USA#},
  isbn = {978-1-4577-1638-6},
  address = {Washington, DC, } # USA,
  publisher = {IEEE Computer Society},
  owner = {magsilva},
  timestamp = {2014.02.22}
}

@PROCEEDINGS{proceedings:cseet:2011,
  booktitle = {24th Conference on Software Engineering Education and Training},
  title = {24th Conference on Software Engineering Education and Training},
  year = {2011},
  month = may,
  days = {22--24},
  location = {Waikiki, Hawaii, #USA#},
  isbn = {978-1-4577-0349-2},
  publisher = {IEEE Computer Society},
  issn = {1093-0175}
}

@PROCEEDINGS{proceedings:csmr:2011,
  booktitle = {15th European Conference on Software Maintenance and Reengineering},
  year = {2011},
  month = mar,
  location = {Oldenburg, #Netherlands#},
  isbn = {978-1-61284-259-2},
  day = {1--4},
  issn = {1534-5351}
}

@PROCEEDINGS{proceedings:ease:2011,
  booktitle = {15th Annual Conference on Evaluation Assessment in Software Engineering},
  title = {15th Annual Conference on Evaluation Assessment in Software Engineering},
  year = {2011},
  month = apr,
  location = {Durham University, #UK#},
  e-isbn = {978-1-84919-509-6},
  day = {11--12},
  timestamp = {2013-11-20}
}

@PROCEEDINGS{proceedings:esem:2011,
  booktitle = {5th International Symposium on Empirical Software Engineering and Measurement},
  title = {5th International Symposium on Empirical Software Engineering and Measurement},
  year = {2011},
  month = sep,
  location = {Banff, #Canada#},
  isbn = {978-0-7695-4604-9},
  publisher = {IEEE Computer Society},
  day = {22--23},
  timestamp = {2013-10-15}
}

@PROCEEDINGS{proceedings:euroitv:2011,
  booktitle = {9th International Interactive Conference on Interactive Television},
  year = {2011},
  month = jun # {--} # jul,
  days = {29--1},
  location = {Lisbon, #Portugal#},
  isbn = {978-1-4503-0602-7},
  series = {EuroITV},
  publisher = {ACM}
}

@PROCEEDINGS{proceedings:eurovis:2011,
  booktitle = {Eurographics / IEEE Symposium on Visualization},
  title = {Computer Graphics Forum (EuroVis'11)},
  year = {2011},
  month = may # {-} # jun,
  days = {31-3},
  location = {Bergen, Norway},
  volume = {30},
  number = {3},
  address = {Bergen, Noruega},
  publisher = {Blackwell Publishing Ltd}
}

@PROCEEDINGS{proceedings:fie:2011,
  booktitle = {41st ASEE/IEEE Frontiers in Education Conference},
  title = {41st ASEE/IEEE Frontiers in Education Conference},
  year = {2011},
  month = oct,
  days = {12-15},
  location = {Rapid City, South Dakota, USA},
  isbn = {978-1-61284-467-1},
  series = {FIE},
  publisher = {IEEE},
  issn = {0190-5848},
  papers-accepted = {242},
  promoter = {IEEE, ASEE}
}

@PROCEEDINGS{proceedings:fisl:2010,
  booktitle = {XI Fórum Internacional de Software Livre (FISL 11)},
  year = {2011},
  month = jul,
  location = {Porto Alegre, RS, Brazil},
  series = {Fórum Internacional de Software Livre}
}

@PROCEEDINGS{proceedings:fse:2011,
  booktitle = {19th ACM SIGSOFT Symposium on the Foundations of Software Engineeringand the 13th European Conference on Foundations of Software Engineering},
  title = {19th ACM SIGSOFT Symposium on the Foundations of Software Engineering and the 13th European Conference on Foundations of Software Engineering},
  year = {2011},
  month = sep,
  location = {Szeged, #Hungary#},
  isbn = {978-1-4503-0443-6},
  series = {ESEC/FSE '11},
  publisher = {ACM},
  day = {5--9}
}

@PROCEEDINGS{proceedings:ghtc:2011,
  booktitle = {2011 IEEE Global Humanitarian Technology Conference},
  title = {2011 IEEE Global Humanitarian Technology Conference},
  year = {2011},
  month = oct # {--} # nov,
  days = {30--1},
  location = {Seattle, WA, #USA#},
  isbn = {978-1-61284-634-7},
  e-isbn = {978-0-7695-4595-0}
}

@PROCEEDINGS{proceedings:ht:2011,
  booktitle = {22nd Conference on Hypertext and Hypermedia},
  title = {22nd Conference on Hypertext and Hypermedia},
  year = {2011},
  month = jun,
  days = {6--9},
  location = {Eindhoven, #Netherlands#},
  isbn = {978-1-4503-0256-2},
  address = {New York, NY, } # USA,
  publisher = {ACM}
}

@PROCEEDINGS{proceedings:icer:2011,
  booktitle = {7th International Workshop on Computing Education Research},
  title = {7th International Workshop on Computing Education Research},
  year = {2011},
  month = aug,
  days = {8--9},
  location = {Providence, RI, #USA#},
  isbn = {978-1-4503-0829-8},
  publisher = {ACM}
}

@PROCEEDINGS{proceedings:icse:2011,
  booktitle = {33rd International Conference on Software Engineering},
  title = {33rd International Conference on Software Engineering},
  year = {2011},
  month = may,
  days = {21--28},
  location = {Waikiki, HI, #USA#},
  isbn = {978-1-4503-0445-0},
  address = {New York, NY, } # USA,
  publisher = {ACM}
}

@PROCEEDINGS{proceedings:icsea:2011,
  booktitle = {Sixth International Conference on Software Engineering Advances},
  title = {Sixth International Conference on Software Engineering Advances},
  year = {2011},
  month = oct,
  days = {23--29},
  location = {Barcelona, #Spain#},
  isbn = {978-1-61208-165-6}
}

@PROCEEDINGS{proceedings:icsm:2011,
  booktitle = {27th International Conference on Software Maintenance},
  title = {27th International Conference on Software Maintenance},
  year = {2011},
  month = sep,
  location = {Williamsburg, VA, #USA#},
  isbn = {978-1-4577-0663-9},
  publisher = {IEEE Computer Society},
  day = {25--30},
  issn = {1063-6773}
}

@PROCEEDINGS{proceedings:itcse:2011,
  booktitle = {16th Annual Joint Conference on Innovation and Technology in Computer Science Education},
  title = {16th Annual Joint Conference on Innovation and Technology in Computer Science Education},
  year = {2011},
  month = jun,
  days = {27--29},
  location = {Darmstadt, #Germany#},
  isbn = {978-1-4503-0697-3},
  address = {New York, NY, } # USA,
  publisher = {ACM}
}

@PROCEEDINGS{proceedings:itcse-wgr:2011,
  booktitle = {16th Annual Conference Reports on Innovation and Technology in Computer Science Education -- Working Group Reports},
  year = {2011},
  month = jun,
  location = {Darmstadt, #Germany#},
  isbn = {978-1-4503-1122-9},
  address = {New York, NY, USA},
  publisher = {ACM},
  day = {27--29}
}

@PROCEEDINGS{proceedings:koli-calling:2011,
  booktitle = {11th Koli Calling International Conference on Computing Education Research},
  year = {2011},
  location = {Koli, #Finland#},
  isbn = {978-1-4503-1052-9},
  publisher = {ACM}
}

@PROCEEDINGS{proceedings:msr:2011,
  booktitle = {8th Working Conference on Mining Software Repositories},
  title = {8th Working Conference on Mining Software Repositories},
  year = {2011},
  month = may,
  location = {Honolulu, HI, #USA#},
  isbn = {978-1-4503-0574-7},
  series = {MSR '11},
  address = {New York, NY, USA},
  publisher = {ACM},
  day = {21--22}
}

@PROCEEDINGS{proceedings:plateau:2011,
  booktitle = {3rd ACM SIGPLAN Workshop on Evaluation and Usability of Programming Languages and Tools},
  title = {3rd ACM SIGPLAN Workshop on Evaluation and Usability of Programming Languages and Tools},
  year = {2011},
  month = oct,
  days = {24},
  location = {Portland, Oregon, #USA#},
  isbn = {978-1-4503-1024-6},
  address = {New York, NY, } # USA,
  publisher = {ACM}
}

@PROCEEDINGS{proceedings:profes:2011,
  booktitle = {12th International Conference on Product-Focused Software Process Improvement},
  title = {12th International Conference on Product-Focused Software Process Improvement},
  year = {2011},
  month = jun,
  days = {20--22},
  location = {Torre Canne, #Italy#},
  isbn = {9783642218422},
  volume = {6759},
  series = {Lecture Notes in Computer Science},
  issn = {03029743},
  owner = {magsilva},
  timestamp = {2014.08.19}
}

@PROCEEDINGS{proceedings:sbie:2011,
  booktitle = {XXII Simpósio Brasileiro de Informática na Educação},
  title = {XXII Simpósio Brasileiro de Informática na Educação},
  year = {2011},
  month = nov,
  days = {21-25},
  location = {Aracaju, SE, #Brazil#},
  series = {SBIE},
  address = {Aracaju, SE, } # Brazil,
  publisher = {SBC},
  issn = {2176-4301},
  papers-submitted = {376}
}

@PROCEEDINGS{proceedings:sigcse:2011,
  booktitle = {42nd ACM Technical Symposium on Computer Science Education},
  title = {42nd ACM Technical Symposium on Computer Science Education},
  year = {2011},
  month = mar,
  days = {9--12},
  location = {Dallas, TX, #USA#},
  isbn = {978-1-4503-0500-6},
  publisher = {ACM}
}

@PROCEEDINGS{proceedings:siicusp:2011,
  booktitle = {19º Simpósio Internacional de Iniciação Científica},
  year = {2011},
  month = nov,
  days = {21--25},
  location = {São Carlos, SP, #Brazil#}
}

@PROCEEDINGS{proceedings:t4e:2011,
  booktitle = {IEEE International Conference on Technology for Education},
  year = {2011},
  month = jul,
  days = {14--16},
  location = {Tamil Nadu, #India#},
  isbn = {978-0-7695-4534-9},
  publisher = {IEEE Computer Society}
}

@PROCEEDINGS{proceedings:wbma:2011,
  booktitle = {Workshop Brasileiro de Métodos Ágeis 2011},
  title = {Workshop Brasileiro de Métodos Ágeis 2011},
  year = {2011},
  month = jun,
  days = {29},
  location = {Fortaleza, CE, #Brazil#},
  owner = {magsilva},
  timestamp = {2014.10.14}
}

@PROCEEDINGS{proceedings:webmedia:2011,
  booktitle = {XVII Simpósio Brasileiro de Sistemas Multimídias e Web},
  year = {2011},
  month = oct,
  days = {3--6},
  location = {Florianópolis, SC, #Brazil#},
  isbn = {9782175-964005},
  publisher = {SBC},
  issn = {2175-9642}
}

@PROCEEDINGS{proceedings:wosq:2011,
  booktitle = {8th International Workshop on Software Quality},
  title = {8th International Workshop on Software Quality},
  year = {2011},
  month = sep,
  location = {Szeged, #Hungary#},
  isbn = {978-1-4503-0851-9},
  series = {WoSQ},
  address = {New York, NY, USA},
  publisher = {ACM},
  day = {4}
}

@PROCEEDINGS{proeedings:sbes:2011,
  booktitle = {25th Brazilian Symposium on Software Engineering},
  title = {25th Brazilian Symposium on Software Engineering},
  year = {2011},
  month = {Sept}
}

@PROCEEDINGS{proceedings:ase:2010,
  booktitle = {IEEE/ACM international conference on Automated Software Engineering},
  year = {2010},
  location = {Antwerp, #Belgium#},
  isbn = {978-1-4503-0116-9},
  address = {New York, NY, } # USA,
  publisher = {ACM},
  timestamp = {2013-08-01}
}

@PROCEEDINGS{proceedings:chi:2010,
  booktitle = {28th International Conference on Human Factors in Computing Systems},
  title = {28th International Conference on Human Factors in Computing Systems},
  year = {2010},
  month = apr,
  days = {10--15},
  location = {Atlanta, GA, #USA#},
  isbn = {978-1-60558-929-9},
  series = {CHI},
  publisher = {ACM}
}

@PROCEEDINGS{proceedings:collaboratecom:2010,
  booktitle = {6th International Conference on Collaborative Computing: Networking, Applications and Worksharing},
  title = {6th International Conference on Collaborative Computing: Networking, Applications and Worksharing},
  year = {2010},
  month = oct,
  location = {Chicago, IL, #USA#},
  isbn = {978-963-9995-24-6},
  day = {9--12}
}

@PROCEEDINGS{proceedings:dis:2010,
  booktitle = {8th ACM Conference on Designing Interactive Systems},
  title = {8th ACM Conference on Designing Interactive Systems},
  year = {2010},
  month = aug,
  location = {Aarhus, #Denmark#},
  isbn = {978-1-4503-0103-9},
  address = {New York, NY, USA},
  publisher = {ACM},
  day = {16--20}
}

@PROCEEDINGS{proceedings:ease:2010,
  booktitle = {14th International Conference on Evaluation and Assessment in Software Engineering (EASE)},
  title = {14th International Conference on Evaluation and Assessment in Software Engineering (EASE)},
  year = {2010},
  month = apr,
  location = {Keele University, #UK#},
  address = {Swinton, UK},
  publisher = {British Computer Society},
  accepted-papers = {12},
  day = {12--13},
  timestamp = {2013-10-15}
}

@PROCEEDINGS{proceedings:esem:2010,
  booktitle = {2010 ACM-IEEE International Symposium on Empirical Software Engineering and Measurement},
  title = {2010 ACM-IEEE International Symposium on Empirical Software Engineering and Measurement},
  year = {2010},
  month = sep,
  location = {Bolzano-Bozen, #Italy#},
  isbn = {978-1-4503-0039-1},
  address = {New York, NY, } # USA,
  publisher = {ACM},
  day = {16--17}
}

@PROCEEDINGS{proceedings:euroitv:2010,
  booktitle = {European Conference on Interactive TV},
  year = {2010},
  location = {Tampere, #Finland#},
  isbn = {978-1-60558-831-5},
  series = {EuroITV},
  publisher = {ACM}
}

@PROCEEDINGS{proceedings:fie:2010,
  booktitle = {40th Frontiers in Education Conference},
  title = {40th Frontiers in Education Conference},
  year = {2010},
  month = oct,
  days = {27--30},
  location = {Washington, DC, #USA#},
  isbn = {978-1-4244-6262-9},
  issn = {0190-5848}
}

@PROCEEDINGS{proceedings:foser:2010,
  booktitle = {{FSE/SDP} workshop on Future of Software Engineering Research ({FoSER '10})},
  title = {{FSE/SDP} workshop on Future of Software Engineering Research ({FoSER '10})},
  year = {2010},
  month = nov,
  days = {7--11},
  location = {Santa Fe, New Mexico, #USA#},
  isbn = {978-1-4503-0427-6},
  publisher = {ACM},
  abstract = {It my great pleasure and honor to welcome you to FoSER 2010: The FSE/SDP Workshop on the Future of Software Engineering Research. This workshop was organized in collaboration with and made possible by generous support from the Software Design and Productivity Coordinating Group (SDP) of the U.S. National Coordination Office (NCO) for Networking and Information Technology Research and Development (NITRD), and the National Science Foundation (NSF). This one-time, international working conference has brought together top academic and industrial researchers and government research funding agency personnel from around the world to engage in an extended discussion of consequential new ideas about the future of our field. The ideas produced by this workshop will be disseminated in two forms. First, the position papers accepted by the program committee will be published in a companion to the Proceedings of FSE-18. Second, the workshop findings will be published subsequently in a special report by NITRD/SDP. The call for papers for FoSER 2010 solicited 4-page position papers with new ideas about the future of software and software-reliant systems, and the research that will be needed to meet future needs. Papers were expected to be creative and thought-provoking, and to articulate compelling new perspectives, positions, problem formulations, assumptions and approaches. The workshop did not seek, and did not accept, technical research papers or abstracts. The workshop received a total of 139 position papers. Of these, 90 papers (65%) were accepted. Each paper was reviewed by at least two members of the workshop program committee. The committee was asked to accept all papers presenting significant new ideas about how our field should move forward.},
  papers-accepted = {90},
  papers-submitted = {139}
}

@PROCEEDINGS{proceedings:icalt:2010,
  booktitle = {International Conference on Advanced Learning Technologies},
  title = {IEEE International Conference on Advanced Learning Technologies},
  year = {2010},
  month = jul,
  days = {5-7},
  location = {Sousse, Tunisia},
  series = {International Conference on Advanced Learning Technologies},
  publisher = {IEEE Computer Society},
  papers-accepted = {80},
  papers-submitted = {258}
}

@PROCEEDINGS{proceedings:icer:2010,
  booktitle = {6th International Workshop on Computing Education Research},
  title = {6th International Workshop on Computing Education Research},
  year = {2010},
  month = aug,
  days = {8--11},
  location = {Aarhus, #Denmark#},
  isbn = {978-1-4503-0257-9},
  publisher = {ACM}
}

@PROCEEDINGS{proceedings:icse:2010,
  booktitle = {32nd ACM/IEEE International Conference on Software Engineering},
  year = {2010},
  month = may,
  location = {Cape Town, #South Africa#},
  isbn = {978-1-60558-719-6},
  address = {New York, NY, } # USA,
  publisher = {ACM}
}

@PROCEEDINGS{proceedings:icstw:2010,
  booktitle = {3rd International Conference on Software Testing, Verification, and Validation Workshops},
  title = {3rd International Conference on Software Testing, Verification, and Validation Workshops},
  year = {2010},
  isbn = {978-0-7695-4050-4},
  publisher = {IEEE Computer Society},
  acmid = {1799616}
}

@PROCEEDINGS{proceedings:itcse:2010,
  booktitle = {15th Annual Conference on Innovation and Technology in Computer Science Education},
  title = {15th Annual Conference on Innovation and Technology in Computer Science Education},
  year = {2010},
  month = jun,
  days = {26--30},
  location = {Bilkent, Ankara, #Turkey#},
  isbn = {978-1-60558-820-9},
  publisher = {ACM}
}

@PROCEEDINGS{proceedings:koli-calling:2010,
  booktitle = {10th Koli Calling International Conference on Computing Education Research},
  title = {10th Koli Calling International Conference on Computing Education Research},
  year = {2010},
  month = oct,
  days = {28--31},
  location = {Koli, #Finland#},
  isbn = {978-1-4503-0520-4},
  publisher = {ACM}
}

@PROCEEDINGS{proceedings:msr:2010,
  booktitle = {7th IEEE Working Conference on Mining Software Repositories},
  year = {2010},
  month = may,
  location = {Cape Town. #South Africa#},
  isbn = {978-1-4244-6802-7},
  e-isbn = {978-1-4244-6803-4},
  day = {2--3}
}

@PROCEEDINGS{proceedings:qsic:2010,
  booktitle = {10th International Conference on Quality Software},
  year = {2010},
  month = jul,
  days = {14--15},
  location = {Zhangjiajie, #China#},
  isbn = {978-0-7695-4131-0},
  e-isbn = {978-1-4244-8078-4},
  issn = {1550-6002}
}

@PROCEEDINGS{proceedings:quatic:2010,
  booktitle = {7th International Conference on the Quality of Information and Communications Technology},
  title = {7th International Conference on the Quality of Information and Communications Technology},
  year = {2010},
  month = sep # {--} # oct,
  days = {29--2},
  location = {Porto, #Portugal#},
  isbn = {9780769542416},
  address = {Porto},
  owner = {magsilva},
  timestamp = {2014.08.19}
}

@PROCEEDINGS{proceedings:rsse:2010,
  booktitle = {2nd International Workshop on Recommendation Systems for Software Engineering},
  year = {2010},
  month = may,
  location = {Cape Town, #South Africa#},
  isbn = {978-1-60558-974-9},
  address = {New York, NY, } # USA,
  publisher = {ACM},
  colocated-with = {32nd International Conference on Software Engineering},
  day = {4--4}
}

@PROCEEDINGS{proceedings:sigcse:2010,
  booktitle = {41st ACM Technical Symposium on Computer Science Education},
  title = {41st ACM Technical Symposium on Computer Science Education},
  year = {2010},
  month = mar,
  days = {10--13},
  location = {Milwaukee, Wisconsin, #USA#},
  isbn = {978-1-4503-0006-3},
  publisher = {ACM}
}

@PROCEEDINGS{proceedings:splash:2010,
  booktitle = {Conference on Systems, Programming, Languages and Applications: Software for Humanity (SPLASH 2010)},
  title = {Conference on Systems, Programming, Languages and Applications: Software for Humanity (SPLASH 2010)},
  year = {2010},
  month = oct,
  days = {17--21},
  location = {Reno/Tahoe, Nevada, #USA#},
  isbn = {978-1-4503-0240-1},
  publisher = {ACM}
}

@PROCEEDINGS{proceedings:wcre:2010,
  booktitle = {17th Working Conference on Reverse Engineering},
  title = {17th Working Conference on Reverse Engineering},
  year = {2010},
  month = oct,
  location = {Beverly, MA, #USA#},
  day = {13--16},
  issn = {1095-1350}
}

@PROCEEDINGS{proceedings:webmedia:2010,
  booktitle = {XVI Simpósio Brasileiro de Sistemas Multimídias e Web},
  year = {2010},
  month = oct,
  days = {5--8},
  location = {Belo Horizonte, MG, #Brazil#},
  isbn = {857669249-2},
  publisher = {SBC}
}

@STANDARD{standard:iso:24765,
  title = {ISO/IEC/IEEE 24765:2010 -- Systems and software engineering -- Vocabulary},
  organization = {ISO and IEC and IEEE},
  institution = {ISO and IEC and IEEE},
  month = dec,
  year = {2010},
  abstract = {The systems and software engineering disciplines are continuing to mature while information technology advances. This International Standard was prepared to collect and standardize terminology. Its purpose is to identify terms currently in use in the field and standard definitions for these terms. It is intended to serve as a useful reference for those in the Information Technology field, and to encourage the use of systems and software engineering standards prepared by ISO and liaison organizations IEEE Computer Society and Project Management Institute (PMI). This International Standard replaces IEEE Std 610.12-1990, IEEE Standard Glossary of Software Engineering Terminology, which was contributed by the IEEE as a source document. The approach and lexical exactitude of IEEE Std 610.12-1990 served as a model for this International Standard. Nevertheless, approximately two thirds of the definitions in this International Standard are new since IEEE Std 610.12 was last updated in 1990, a reflection of the continued evolution in the field.},
  doi = {10.1109/IEEESTD.2010.5733835},
  pages = {418}
}

@PROCEEDINGS{proceedings:compsac:2009,
  booktitle = {33rd International Computer Software and Applications Conference},
  year = {2009},
  month = jul,
  location = {Seattle, WA, #USA#},
  isbn = {978-0-7695-3726-9},
  volume = {1},
  publisher = {IEEE},
  issn = {0730-3157}
}

@PROCEEDINGS{proceedings:criwg:2009,
  booktitle = {15th International Conference on Groupware: Design, Implementation, and Use},
  title = {15th International Conference on Groupware: Design, Implementation, and Use},
  year = {2009},
  month = sep,
  location = {Douro, #Portugal#},
  isbn = {978-3-642-04215-7},
  volume = {5784},
  series = {Lecture Notes in Computer Science},
  address = {Berlin, } # Germany,
  publisher = {Springer-Verlag},
  day = {13--17}
}

@PROCEEDINGS{proceedings:ease:2009,
  booktitle = {13th international Conference on Evaluation and Assessment in Software Engineering},
  title = {13th international Conference on Evaluation and Assessment in Software Engineering},
  year = {2009},
  month = apr,
  location = {Swinton, #UK#},
  publisher = {British Computer Society},
  day = {20--21}
}

@PROCEEDINGS{proceedings:educase-aus:2009,
  booktitle = {EDUCAUSE in Australasia},
  year = {2009},
  month = apr # {--} # may,
  days = {29--2},
  location = {Melbourne, #Australia#}
}

@PROCEEDINGS{proceedings:elml:2009,
  booktitle = {International Conference on Mobile, Hybrid, and On-line Learning},
  title = {International Conference on Mobile, Hybrid, and On-line Learning},
  year = {2009},
  month = feb,
  days = {1-7},
  location = {Cancun, Mexico},
  series = {International Conference on Mobile, Hybrid, and On-line Learning},
  publisher = {IEEE Computer Society}
}

@PROCEEDINGS{proceedings:epoca:2009,
  booktitle = {2ª Escola Potiguar de Computação e suas Aplicações},
  title = {2ª Escola Potiguar de Computação e suas Aplicações},
  year = {2009},
  month = nov,
  days = {18--20},
  location = {Natal, RN, #Brazil#},
  series = {EPOCA}
}

@PROCEEDINGS{proceedings:esem:2009,
  booktitle = {3rd International Symposium on Empirical Software Engineering and Measurement},
  year = {2009},
  month = oct,
  days = {15--16},
  location = {Lake Buena Vista, FL, #USA#},
  isbn = {978-1-4244-4842-5},
  publisher = {IEEE Computer Society},
  acmid = {1671317}
}

@PROCEEDINGS{proceedings:fie:2009,
  booktitle = {39th IEEE Frontiers in Education Conference},
  year = {2009},
  month = oct,
  location = {San Antonio, TX, #USA#},
  day = {18--21},
  issn = {0190-5848}
}

@PROCEEDINGS{proceedings:hicss:2009,
  booktitle = {42nd Hawaii International Conference on System Sciences},
  title = {42nd Hawaii International Conference on System Sciences},
  year = {2009},
  month = jan,
  location = {Waikoloa, Hawaii, #USA#},
  isbn = {978-0-7695-3450-3},
  publisher = {IEEE Computer Society},
  day = {5--8},
  issn = {1530-1605}
}

@PROCEEDINGS{proceedings:iccee:2009,
  booktitle = {2nd International Conference on Computer and Electrical Engineering},
  title = {2nd International Conference on Computer and Electrical Engineering},
  year = {2009},
  month = aug,
  location = {Dubai, #UAE#},
  isbn = {978-1-4244-5365-8},
  volume = {1},
  day = {28--30}
}

@PROCEEDINGS{proceedings:icer:2009,
  booktitle = {5th International Workshop on Computing Education Research},
  title = {5th International Workshop on Computing Education Research},
  year = {2009},
  month = aug,
  days = {10--11},
  location = {Berkeley, CA, #USA#},
  isbn = {978-1-60558-615-1},
  address = {New York, NY, } # USA,
  publisher = {ACM}
}

@PROCEEDINGS{proceedings:latw:2009,
  booktitle = {10th Latin American Test Workshop (LATW '09)},
  title = {10th Latin American Test Workshop (LATW '09)},
  year = {2009},
  month = mar,
  days = {2--5},
  location = {Búzios, RJ, #Brazil#},
  isbn = {978-1-4244-4206-5}
}

@PROCEEDINGS{proceedings:msr:2009,
  booktitle = {6th IEEE International Working Conference on Mining Software Repositories},
  year = {2009},
  month = may,
  location = {Vancouver, BC, #Canada#},
  isbn = {978-1-4244-3493-0},
  publisher = {IEEE Computer Society},
  day = {16--17}
}

@PROCEEDINGS{proceedings:promise:2009,
  booktitle = {5th International Conference on Predictor Models in Software Engineering},
  title = {5th International Conference on Predictor Models in Software Engineering},
  year = {2009},
  location = {Vancouver, BC, #Canada#},
  isbn = {978-1-60558-634-2},
  address = {New York, NY, } # USA,
  publisher = {ACM}
}

@PROCEEDINGS{proceedings:re:2009,
  booktitle = {17th IEEE International Requirements Engineering Conference},
  year = {2009},
  month = aug # {--} # sep,
  days = {31--4},
  location = {Atlanta, Georgia, #USA#},
  isbn = {978-0-7695-3761-0},
  publisher = {IEEE Computer Society}
}

@PROCEEDINGS{proceedings:sbie:2009,
  booktitle = {XX Simpósio Brasileiro de Informática na Educação},
  title = {XX Simpósio Brasileiro de Informática na Educação},
  year = {2009},
  month = nov,
  location = {Florianópolis, SC, #Brazil#},
  series = {SBIE},
  publisher = {SBC},
  day = {17--20},
  issn = {2176-4301}
}

@PROCEEDINGS{proceedings:sew:2009,
  booktitle = {33rd Annual IEEE Software Engineering Workshop},
  title = {33rd Annual IEEE Software Engineering Workshop},
  year = {2009},
  month = oct,
  days = {13--15},
  location = {Skövde, #Sweden#},
  issn = {1550-6215}
}

@PROCEEDINGS{proceedings:sigcse:2009,
  booktitle = {40th ACM Technical Symposium on Computer Science Education},
  title = {40th ACM Technical Symposium on Computer Science Education},
  year = {2009},
  month = mar,
  days = {4--7},
  location = {Chattanooga, TN, #USA#},
  isbn = {978-1-60558-183-5},
  publisher = {ACM},
  papers-accepted = {100},
  papers-submitted = {302}
}

@STANDARD{standard:ieee:9945,
  title = {Information technology -- Portable Operating System Interface (POSIX) Operating System Interface (POSIX)},
  organization = {IEEE, ISO, IEC},
  number = {9945},
  month = sep,
  year = {2009},
  abstract = {POSIX.1-2008 is simultaneously IEEE Std 1003.1-2008? and The Open Group Technical Standard Base Specifications, Issue 7. POSIX.1-2008 defines a standard operating system interface and environment, including a command interpreter (or "shell"), and common utility programs to support applications portability at the source code level. POSIX.1-2008 is intended to be used by both application developers and system implementors and comprises four major components (each in an associated volume): a) General terms, concepts, and interfaces common to all volumes of this standard, including utility conventions and C-language header definitions, are included in the Base Definitions volume. b) Definitions for system service functions and subroutines, language-specific system services for the C programming language, function issues, including portability, error handling, and error recovery, are included in the System Interfaces volume. c) Definitions for a standard source code-level interface to command interpretation services (a "shell") and common utility programs for application programs are included in the Shell and Utilities volume.d) Extended rationale that did not fit well into the rest of the document structure, which contains historical information concerning the contents of POSIX.1-2008 and why features were included or discarded by the standard developers, is included in the Rationale (Informative) volume. The following areas are outside the scope of POSIX.1-2008:1)Graphics interfaces 2)Database management system interfaces 3)Record I/O considerations 4) Object or binary code portability 5) System configuration and resource availability POSIX.1-2008 describes the external characteristics and facilities that are of importance to application developers, rather than the internal construction techniques employed to achieve these capabilities. Special emphasis is placed on those functions and facilities that are needed in a wide variety of commercial applications.},
  doi = {10.1109/IEEESTD.2009.5393893},
  isbn = {978-0-7381-5798-6},
  keywords = {C language header definitions;IEEE Std 1003.1;POSIX. 1-2008;application developers;applications portability;base definitions volume;command interpreter;common utility programs;information technology;language specific system services;open group technical standard base specifications;portable operating system interface;source code level interface;system implementors;C language;IEEE standards;Unix;software portability;software standards;utility programs;},
  pages = {3830}
}

@PROCEEDINGS{proceedings:acm-se:2008,
  booktitle = {46th Annual Southeast Regional Conference on XX},
  title = {46th Annual Southeast Regional Conference on XX},
  year = {2008},
  month = mar,
  days = {28--29},
  location = {Auburn, AL, #USA#},
  isbn = {978-1-60558-105-7},
  address = {New York, NY, } # USA,
  publisher = {ACM},
  owner = {magsilva},
  timestamp = {2014.09.13}
}

@PROCEEDINGS{proceedings:acsc:2008,
  booktitle = {31st Australasian Conference on Computer Science},
  title = {31st Australasian Conference on Computer Science},
  year = {2008},
  month = jan,
  days = {22--25},
  location = {Wollongong, #Australia#},
  isbn = {978-1-920682-55-2},
  volume = {74},
  address = {Darlinghurst, } # Australia,
  publisher = {Australian Computer Society},
  owner = {magsilva},
  timestamp = {2014.08.30}
}

@PROCEEDINGS{proceedings:agile:2008,
  booktitle = {Agile Conference 2008},
  title = {Agile Conference 2008},
  year = {2008},
  month = aug,
  days = {4--8},
  location = {Toronto, Ontario, #Canada#},
  isbn = {978-0-7695-3321-6},
  owner = {magsilva},
  timestamp = {2014.01.16}
}

@PROCEEDINGS{proceedings:chi:2008,
  booktitle = {SIGCHI Conference on Human Factors in Computing Systems 2008},
  title = {SIGCHI Conference on Human Factors in Computing Systems 2008},
  year = {2008},
  month = apr,
  location = {Florence, #Italy#},
  isbn = {978-1-60558-011-1},
  address = {New York, NY, USA},
  publisher = {ACM},
  day = {5--10}
}

@PROCEEDINGS{proceedings:cseet:2008,
  booktitle = {21st Conference on Software Engineering Education and Training},
  title = {21st Conference on Software Engineering Education and Training},
  year = {2008},
  month = apr,
  days = {12--14},
  location = {Charleston, SC, #USA#},
  isbn = {978-0-7695-3144-1},
  publisher = {IEEE Computer Society}
}

@PROCEEDINGS{proceedings:ease:2008,
  booktitle = {12th International Conference on Evaluation and Assessment in Software Engineering (EASE)},
  title = {12th International Conference on Evaluation and Assessment in Software Engineering (EASE)},
  year = {2008},
  month = jun,
  location = {Bari, #Italy#},
  address = {University of Bari, Italy},
  day = {26--27},
  timestamp = {2013-11-27}
}

@PROCEEDINGS{proceedings:eselaw:,
  booktitle = {5th Experimental Software Engineering Latin American Workshop},
  title = {5th Experimental Software Engineering Latin American Workshop},
  year = {2008},
  month = nov,
  days = {5--7},
  location = {Salvador, BA, #Brazil#},
  owner = {magsilva},
  timestamp = {2014.08.15}
}

@PROCEEDINGS{proceedings:fie:2008,
  booktitle = {38th Annual Frontiers in Education Conference},
  title = {38th Annual Frontiers in Education Conference},
  year = {2008},
  month = oct,
  location = {Saratoga Springs, NY, #USA#},
  isbn = {978-1-4244-1969-2},
  e-isbn = {978-1-4244-1970-8},
  publisher = {IEEE},
  day = {22--25},
  issn = {0190-5848},
  timestamp = {2013-12-11}
}

@PROCEEDINGS{proceedings:fosm:2008,
  booktitle = {Frontiers of Software Maintenance 2008},
  title = {Frontiers of Software Maintenance 2008},
  year = {2008},
  month = sep # {--} # oct,
  location = {Beijing, #China#},
  isbn = {978-1-4244-2654-6},
  e-isbn = {978-1-4244-2655-3},
  day = {28--4}
}

@PROCEEDINGS{proceedings:icalt:2008,
  booktitle = {8th IEEE International Conference on Advanced Learning Technologies},
  year = {2008},
  month = jul,
  location = {Santander, #Spain#},
  isbn = {978-0-7695-3167-0},
  day = {1--5}
}

@PROCEEDINGS{proceedings:iceccs:2008,
  booktitle = {13th International Conference on Engineering of Complex Computer Systems},
  title = {13th International Conference on Engineering of Complex Computer Systems},
  year = {2008},
  month = mar # {--} # apr,
  days = {31--4},
  location = {Belfast, #Northern Ireland#},
  isbn = {0-7695-3139-3},
  publisher = {IEEE Computer Society}
}

@PROCEEDINGS{proceedings:icer:2008,
  booktitle = {4th International Workshop on Computing Education Research},
  year = {2008},
  location = {Sydney, #Australia#},
  isbn = {978-1-60558-216-0},
  publisher = {ACM}
}

@PROCEEDINGS{proceedings:icfp:2008,
  booktitle = {13th ACM SIGPLAN international conference on Functional programming},
  year = {2008},
  month = sep,
  location = {Victoria, BC, #Canada#},
  isbn = {978-1-59593-919-7},
  address = {New York, NY, } # USA,
  publisher = {ACM},
  day = {22--24}
}

@PROCEEDINGS{proceedings:icse:2008,
  booktitle = {30th International Conference on Software Engineering},
  year = {2008},
  month = may,
  days = {10--18},
  location = {Leipzig, #Germany#},
  isbn = {978-1-60558-079-1},
  publisher = {ACM, IEEE},
  issn = {0270-5257}
}

@PROCEEDINGS{proceedings:icsea:2008,
  booktitle = {3rd International Conference on Software Engineering Advances},
  title = {3rd International Conference on Software Engineering Advances},
  year = {2008},
  month = oct,
  days = {26--31},
  location = {Sliema, #Malta#},
  isbn = {978-0-7695-3372-8},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society}
}

@PROCEEDINGS{proceedings:icst:2008,
  booktitle = {1st International Conference on Software Testing, Verification, and Validation},
  title = {1st International Conference on Software Testing, Verification, and Validation},
  year = {2008},
  month = apr,
  days = {9--11},
  location = {Lillehammer, #Norway#},
  isbn = {978-0-7695-3127-4},
  publisher = {IEEE Computer Society}
}

@PROCEEDINGS{proceedings:itcse:2008,
  booktitle = {13th Annual Conference on Innovation and Technology in Computer Science Education},
  title = {13th Annual Conference on Innovation and Technology in Computer Science Education},
  year = {2008},
  month = jun # {--} # jul,
  days = {30--2},
  location = {Madrid, #Spain#},
  isbn = {978-1-60558-078-4},
  publisher = {ACM}
}

@PROCEEDINGS{proceedings:sast:2008,
  booktitle = {II Workshop Brasileiro de Teste de Software Sistemático},
  year = {2008},
  month = oct,
  days = {13},
  location = {Campinas, SP, #Brazil#}
}

@PROCEEDINGS{proceedings:sbie:2008,
  booktitle = {XIX Simpósio Brasileiro de Informática na Educação},
  title = {XIX Simpósio Brasileiro de Informática na Educação},
  year = {2008},
  month = nov,
  location = {Fortaleza, CE, #Brazil#},
  isbn = {857669207-4},
  series = {SBIE},
  address = {Fortaleza, CE, } # Brazil,
  publisher = {SBC}
}

@PROCEEDINGS{proceedings:sess:2008,
  booktitle = {4th International Workshop on Software Engineering for Secure Systems},
  title = {4th International Workshop on Software Engineering for Secure Systems},
  year = {2008},
  month = may,
  location = {Leipzig, #Germany#},
  isbn = {978-1-60558-042-5},
  address = {New York, NY, } # USA,
  publisher = {ACM}
}

@PROCEEDINGS{proceedings:sigcse:2008,
  booktitle = {39th {SIGCSE} Technical Symposium on Computer Science Education},
  title = {39th {SIGCSE} Technical Symposium on Computer Science Education},
  year = {2008},
  month = mar,
  days = {12--15},
  location = {Portland, OR, #USA#},
  isbn = {978-1-59593-799-5},
  publisher = {ACM}
}

@STANDARD{standard:ieee:1003.1,
  title = {IEEE Standard for Information Technology- Portable Operating System Interface (POSIX) Base Specifications},
  organization = {IEEE},
  number = {1003.1},
  revision = {7},
  month = dec,
  year = {2008},
  abstract = {POSIX.1-2008 is simultaneously IEEE Std 1003.1 -2008 and The Open Group Technical Standard Base Specifications, Issue 7. POSIX. 1-2008 defines a standard operating system interface and environment, including a command interpreter (or "shell"), and common utility programs to support applications portability at the source code level. POSIX. 1-2008 is intended to be used by both application developers and system implementors and comprises four major components (each in an associated volume): [1]General terms, concepts, and interfaces common to all volumes of this standard, including utility conventions and C-language header definitions, are included in the Base Definitions volume. [2] Definitions for system service functions and subroutines, language-specific system services for the C programming language, function issues, including portability, error handling, and error recovery, are included in the System Interfaces volume. [3] Definitions for a standard source code-level interface to command interpretation services (a "shell") and common utility programs for application programs are included in the Shell and Utilities volume. [4] Extended rationale that did not fit well into the rest of the document structure, which contains historical information concerning the contents of POSIX. 1-2008 and why features were included or discarded by the standard developers, is included in the Rationale (Informative) volume. The following areas are outside the scope of POSIX. 1-2008: Graphics interfaces Database management system interfaces Record I/O considerations Object or binary code portability System configuration and resource availability. POSIX. 1-2008 describes the external characteristics and facilities that are of importance to application developers, rather than the internal construction techniques employed to achieve these capabilities. Special emphasis is placed on those functions and facilities that are needed in a wide variety of commercial applications.},
  doi = {10.1109/IEEESTD.2008.4694976},
  e-isbn = {978-0-7381-5798-6},
  isbn = {978-0-7381-5799-3},
  journal = {IEEE Std 1003.1-2008 (Revision of IEEE Std 1003.1-2004)},
  keywords = {C-language header definitions;base specifications;command interpreter;common utility programs;language-specific system services;operating system interface;C language;application program interfaces;operating systems (computers);},
  pages = {3826}
}

@MISC{standard:itu:g1080,
  title = {Quality of experience requirements for IPTV services},
  month = dec,
  year = {2008},
  number = {G.1080},
  organization = {ITU},
  pages = {36},
  type = {Recommendation},
  url = {http://www.itu.int/rec/T-REC-G.1080-200812-I/en}
}

@PROCEEDINGS{proceedings:agile:2007,
  booktitle = {Agile Conference (AGILE) 2007},
  year = {2007},
  month = aug,
  location = {Washington, DC, #USA#},
  isbn = {0-7695-2872-4},
  publisher = {IEEE Computer Society},
  day = {13--17}
}

@PROCEEDINGS{proceedings:ccnc:2007,
  booktitle = {4th IEEE Consumer Communications and Networking Conference},
  title = {4th IEEE Consumer Communications and Networking Conference},
  year = {2007},
  month = jan
}

@PROCEEDINGS{proceedings:chi:2007,
  booktitle = {SIGCHI Conference on Human Factors in Computing Systems 2007},
  title = {SIGCHI Conference on Human Factors in Computing Systems 2007},
  year = {2007},
  location = {San Jose, CA, #USA#},
  isbn = {978-1-59593-593-9},
  address = {New York, NY, USA},
  publisher = {ACM}
}

@PROCEEDINGS{proceedings:cseet:2007,
  booktitle = {20th Conference on Software Engineering Education Training},
  title = {20th Conference on Software Engineering Education Training},
  year = {2007},
  month = jul,
  days = {3--5},
  location = {Dublin, #Ireland#},
  publisher = {IEEE Computer Society},
  issn = {1093-0175}
}

@PROCEEDINGS{proceedings:educase-aus:2007,
  booktitle = {EDUCAUSE in Australasia},
  year = {2007},
  month = apr # {--} # may,
  days = {29--2},
  location = {Melbourne, #Australia#}
}

@PROCEEDINGS{proceedings:esem:2007,
  booktitle = {1st International Symposiun on Empirical Software Engineering and Measurement},
  title = {1st International Symposiun on Empirical Software Engineering and Measurement},
  year = {2007},
  month = sep,
  days = {20--21},
  location = {Madrid, #Spain#},
  isbn = {978-0-7695-2886-1},
  publisher = {IEEE Computer Society},
  day = {20--21},
  issn = {1938-6451}
}

@PROCEEDINGS{proceedings:ess:2007,
  booktitle = {3rd International {ERCIM} Symposium on Software Evolution},
  title = {3rd International {ERCIM} Symposium on Software Evolution},
  year = {2007},
  month = oct,
  days = {5},
  location = {Paris, #France#},
  issn = {1863-2122},
  owner = {magsilva},
  timestamp = {2014.05.29}
}

@PROCEEDINGS{proceedings:floss:2007,
  booktitle = {1st International Workshop on Emerging Trends in FLOSS Research and Development},
  title = {1st International Workshop on Emerging Trends in FLOSS Research and Development},
  year = {2007},
  month = may,
  days = {20--26},
  location = {Minneapolis, MN, #USA#},
  papers-accepted = {13}
}

@PROCEEDINGS{proceedings:fose:2007,
  booktitle = {Future of Software Engineering},
  title = {Future of Software Engineering},
  year = {2007},
  month = may,
  location = {Minneapolis, MN, #USA#},
  isbn = {0-7695-2829-5},
  publisher = {IEEE Computer Society}
}

@PROCEEDINGS{proceedings:icse:2007,
  booktitle = {29th International Conference on Software Engineering},
  title = {29th International Conference on Software Engineering},
  year = {2007},
  month = may,
  days = {20--26},
  location = {Minneapolis, MN, #USA#},
  isbn = {0-7695-2828-7},
  publisher = {IEEE Computer Society},
  day = {20--26}
}

@PROCEEDINGS{proceedings:itcse:2007,
  booktitle = {12th Annual SIGCSE Conference on Innovation and Technology in Computer Science Education},
  year = {2007},
  month = jun,
  days = {23--27},
  location = {Dundee, #Scotland#},
  isbn = {978-1-59593-610-3},
  publisher = {ACM}
}

@PROCEEDINGS{proceedings:sbie:2007,
  booktitle = {XIX Simpósio Brasileiro de Informática na Educação},
  title = {XIX Simpósio Brasileiro de Informática na Educação},
  year = {2007},
  month = nov,
  location = {São Paulo, SP, #Brazil#},
  isbn = {978-85-7669-156-3},
  series = {SBIE},
  address = {São Paulo, SP, } # Brazil,
  publisher = {SBC}
}

@PROCEEDINGS{proceedings:taicpart-mutation:2007,
  booktitle = {Testing: Academic and Industrial Conference Practice and Research Techniques -- TAIC PART MUTATION 2007},
  title = {Testing: Academic and Industrial Conference Practice and Research Techniques -- TAIC PART MUTATION 2007},
  year = {2007},
  month = sep,
  days = {10--14},
  location = {Windsor, #UK#},
  isbn = {978-0-7695-2984-4},
  address = {Washington, DC, } # USA,
  publisher = {IEEE Computer Society}
}

@PROCEEDINGS{proceedings:webmedia:2007,
  booktitle = {13th Brazilian Symposium on Multimedia and the Web},
  year = {2007},
  month = oct,
  days = {21--24},
  location = {Gramado, RS, #Brazil#},
  series = {WebMedia}
}

@PROCEEDINGS{proceedings:www:2007,
  booktitle = {16th International Conference on World Wide Web},
  year = {2007},
  location = {Banff, Alberta, Canada},
  isbn = {978-1-59593-654-7},
  address = {New York, NY, USA},
  publisher = {ACM},
  owner = {magsilva},
  timestamp = {2014.05.18}
}

@INPROCEEDINGS{conference:micte:2006,
  title = {International Conference on Multimedia and Information Technologies for the Education (MICTE)},
  year = {2006}
}

@PROCEEDINGS{proceedings:ace:2006,
  booktitle = {8th Australasian Conference on Computing Education},
  year = {2006},
  location = {Hobart, Australia},
  isbn = {1-920682-34-1},
  volume = {52},
  address = {Darlinghurst, } # Australia,
  publisher = {Australian Computer Society},
  acmid = {1151882},
  numpages = {10},
  url = {http://dl.acm.org/citation.cfm?id=1151869.1151882}
}

@PROCEEDINGS{proceedings:aswec:2006,
  booktitle = {Australian Software Engineering Conference 2006},
  title = {Australian Software Engineering Conference 2006},
  year = {2006},
  month = apr,
  days = {18--21},
  location = {Sydney, #Australia#},
  isbn = {0-7695-2551-2},
  issn = {1530-0803},
  owner = {magsilva},
  timestamp = {2014.05.29}
}

@PROCEEDINGS{proceedings:chi:2006,
  booktitle = {Conference on human factors in computing systems},
  year = {2006},
  month = apr,
  days = {22--27},
  location = {Montreal, Quebec, #Canada#},
  isbn = {1-59593-298-4},
  publisher = {ACM}
}

@PROCEEDINGS{proceedings:doceng:2006,
  booktitle = {6th Symposium on Document Engineering},
  year = {2006},
  month = oct,
  days = {10--13},
  location = {Amsterdam, #Netherlands#},
  isbn = {1-59593-515-0},
  publisher = {ACM}
}

@PROCEEDINGS{proceedings:euroitv:2006,
  booktitle = {EuroITV 2006 - Beyond Usability, Broadcast, and TV},
  title = {EuroITV 2006 - Beyond Usability, Broadcast, and TV},
  year = {2006},
  month = may,
  days = {25-26},
  location = {Athens, Grécia},
  series = {EuroITV},
  address = {Athens, Grécia},
  publisher = {ACM}
}

@PROCEEDINGS{proceedings:iceis:2006,
  booktitle = {8th International Conference on Enterprise Information Systems},
  year = {2006},
  month = may,
  days = {23--27},
  location = {Paphos, #Cyprus#},
  isbn = {972-8865-41-4}
}

@PROCEEDINGS{proceedings:icer:2006,
  booktitle = {2nd International Workshop on Computing Education Research},
  title = {2nd International Workshop on Computing Education Research},
  year = {2006},
  month = sep,
  days = {9--10},
  location = {Canterbury, #UK#},
  isbn = {1-59593-494-4},
  address = {New York, NY, } # USA,
  publisher = {ACM}
}

@PROCEEDINGS{proceedings:icse:2006,
  booktitle = {28th International Conference on Software Engineering},
  title = {28th International Conference on Software Engineering},
  year = {2006},
  month = may,
  days = {20--28},
  location = {Shanghai, #China#},
  isbn = {1-59593-375-1},
  address = {New York, NY, USA},
  publisher = {ACM}
}

@PROCEEDINGS{proceedings:issep:2006,
  booktitle = {2006 International Conference on Informatics in Secondary Schools -- Evolution and Perspectives: The Bridge Between Using and Understanding Computers},
  title = {2006 International Conference on Informatics in Secondary Schools -- Evolution and Perspectives: The Bridge Between Using and Understanding Computers},
  year = {2006},
  month = nov,
  days = {7--11},
  location = {Vilnius, #Lithuania#},
  isbn = {3-540-48218-0},
  volume = {4226},
  series = {Lecture Notes in Computer Science},
  address = {Berlin, } # Heidelberg,
  publisher = {Springer-Verlag},
  owner = {magsilva},
  timestamp = {2014.08.30}
}

@PROCEEDINGS{proceedings:itcse:2006,
  booktitle = {11th Annual SIGCSE Conference on Innovation and Technology in Computer Science Education},
  year = {2006},
  month = jun,
  location = {Bologna, #Italy#},
  isbn = {1-59593-055-8},
  address = {New York, NY, USA},
  publisher = {ACM},
  day = {26--28}
}

@PROCEEDINGS{proceedings:msr:2006,
  booktitle = {2006 International Workshop on Mining Software Repositories},
  year = {2006},
  month = may,
  location = {Shanghai, #China#},
  isbn = {1-59593-397-2},
  publisher = {ACM},
  day = {22--23}
}

@PROCEEDINGS{proceedings:oopsla:2006,
  booktitle = {21st ACM SIGPLAN Symposium on Object-Oriented Programming Systems, Languages, and Applications},
  year = {2006},
  location = {Portland, Oregon, #USA#},
  isbn = {1-59593-491-X},
  address = {New York, NY, } # USA,
  publisher = {ACM}
}

@PROCEEDINGS{proceedings:semish:2006,
  booktitle = {XXXIII Seminário Integrado de Software e Hardware (SemiSH)},
  title = {XXXIII Seminário Integrado de Software e Hardware (SemiSH)},
  year = {2006},
  month = jun,
  days = {14--20},
  location = {Campo Grande, MS, #Brazil#}
}

@PROCEEDINGS{proceedings:sigcse:2006,
  booktitle = {37th SIGCSE Technical Symposium on Computer Science Education},
  title = {37th SIGCSE Technical Symposium on Computer Science Education},
  year = {2006},
  month = mar,
  days = {1--5},
  location = {Houston, Texas, #USA#},
  isbn = {1-59593-259-3},
  publisher = {ACM}
}

@PROCEEDINGS{proceedings:sigir:2006,
  booktitle = {29th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
  year = {2006},
  location = {Seattle, Washington, USA},
  isbn = {1-59593-369-7},
  address = {New York, NY, USA},
  publisher = {ACM},
  owner = {magsilva},
  timestamp = {2014.05.19}
}

@PROCEEDINGS{proceedings:wei:2006,
  booktitle = {XIV Workshop sobre Educação em Computação},
  title = {XIV Workshop sobre Educação em Computação},
  year = {2006},
  month = jul,
  location = {Campo Grande, MS, Brazil},
  series = {WEI}
}

@PROCEEDINGS{proceedings:wtvd:2006,
  booktitle = {Workshop de TV Digital},
  title = {Workshop de TV Digital},
  year = {2006},
  month = jun,
  days = {2},
  location = {Curitiba, PR, #Brasil#},
  isbn = {8576690721},
  publisher = {SBC}
}

@PROCEEDINGS{proceedings:enia:2005,
  booktitle = {V Encontro Nacional de Inteligência Artificial},
  year = {2005},
  month = jul,
  location = {São Leopoldo, RS, #Brazil#},
  day = {22--29},
  timestamp = {2013-09-20}
}

@PROCEEDINGS{proceedings:fie:2005,
  booktitle = {35th Frontiers in Education Conference},
  title = {35th Frontiers in Education Conference},
  year = {2005},
  month = oct,
  days = {19--22},
  location = {Indianapolis, IN, #USA#},
  isbn = {0-7803-9077-6},
  e-isbn = {0-7803-9078-4},
  issn = {0190-5848}
}

@PROCEEDINGS{proceedings:fse:2005,
  booktitle = {13th ACM SIGSOFT International Symposium on Foundations of Software Engineering},
  year = {2005},
  month = sep,
  location = {Lisbon, #Portugal#},
  isbn = {1-59593-014-0},
  address = {New York, NY, } # USA,
  publisher = {ACM},
  day = {5--9}
}

@PROCEEDINGS{proceedings:icalt:2005,
  booktitle = {Fifth IEEE International Conference on Advanced Learning Technologies},
  title = {International Conference on Advanced Learning Technologies},
  year = {2005},
  month = jul,
  days = {5-8},
  location = {Kaohsiung, Taiwan},
  isbn = {0-7695-2338-2},
  series = {International Conference on Advanced Learning Technologies},
  address = {Washington, DC, EUA},
  publisher = {IEEE Computer Society}
}

@PROCEEDINGS{proceedings:icalt:2006,
  booktitle = {Sixth IEEE International Conference on Advanced Learning Technologies},
  title = {Sixth IEEE International Conference on Advanced Learning Technologies},
  year = {2005},
  month = jul,
  days = {5-7},
  location = {Kerkrade, The Netherlands},
  isbn = {9781424430758},
  series = {International Conference on Advanced Learning Technologies},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  url = {http://www.ask4research.info/icalt/2006/}
}

@PROCEEDINGS{proceedings:icer:2005,
  booktitle = {1st International Workshop on Computing Education Research},
  year = {2005},
  month = oct,
  days = {1--2},
  location = {Seattle, WA, USA},
  isbn = {1-59593-043-4},
  publisher = {ACM}
}

@PROCEEDINGS{proceedings:itcse:2005,
  booktitle = {10th Annual SIGCSE Conference on Innovation and Technology in Computer Science Education},
  year = {2005},
  month = jun,
  location = {Capacrica, #Portugal#},
  isbn = {1-59593-024-8},
  address = {New York, NY, } # USA,
  publisher = {ACM},
  day = {26--29}
}

@PROCEEDINGS{proceedings:msr:2005,
  booktitle = {2005 International Workshop on Mining Software Repositories},
  year = {2005},
  month = may,
  location = {St. Louis, Missouri, #USA#},
  isbn = {1-59593-123-6},
  publisher = {ACM},
  day = {17}
}

@PROCEEDINGS{proceedings:multimedia:2005,
  booktitle = {7th International Symposium on Multimedia},
  year = {2005},
  month = dec,
  days = {12--14},
  location = {Invine, CA, #USA#},
  publisher = {IEEE Computer Society}
}

@PROCEEDINGS{proceedings:oopsla:2005,
  booktitle = {20th annual ACM SIGPLAN conference on Object-oriented programming, systems, languages, and applications},
  year = {2005},
  location = {San Diego, CA, #USA#},
  isbn = {1-59593-193-7},
  address = {New York, NY, } # USA,
  publisher = {ACM},
  timestamp = {2013-08-01}
}

@PROCEEDINGS{proceedings:sbie:2005,
  booktitle = {XVI Simpósio Brasileiro de Informática na Educação},
  title = {XVI Simpósio Brasileiro de Informática na Educação},
  year = {2005},
  month = nov,
  days = {9--11},
  location = {Juiz de Fora, MG, Brazil},
  series = {SBIE},
  publisher = {SBC},
  issn = {2176-4301}
}

@PROCEEDINGS{proceedings:sigcse:2005,
  booktitle = {36th SIGCSE Technical Symposium on Computer Science Education},
  title = {36th SIGCSE Technical Symposium on Computer Science Education},
  year = {2005},
  month = feb,
  location = {St. Louis, Missouri, #USA#},
  isbn = {1-58113-997-7},
  address = {New York, NY, } # USA,
  publisher = {ACM},
  day = {23--27}
}

@PROCEEDINGS{proceedings:cscw:2004,
  booktitle = {Computer Supported Cooperative Work 2004},
  title = {Computer Supported Cooperative Work},
  year = {2004},
  month = nov,
  days = {6-10},
  location = {Chicago, IL, USA},
  series = {Computer Supported Cooperative Work}
}

@PROCEEDINGS{proceedings:cscwd:2004,
  booktitle = {8th International Conference on Computer Supported Cooperative Work in Design},
  year = {2004},
  month = may,
  isbn = {0-7803-7941-1},
  volume = {2},
  day = {26--28}
}

@PROCEEDINGS{proceedings:doceng:2004,
  booktitle = {4th ACM symposium on Document engineering},
  year = {2004},
  month = oct,
  days = {28--30},
  location = {Milwaukee, Wisconsin, #USA#},
  isbn = {1-58113-938-1},
  publisher = {ACM}
}

@PROCEEDINGS{proceedings:euroitv:2004,
  booktitle = {European Conference on Interactive Television: Enhancing the Experience},
  title = {European Conference on Interactive Television: Enhancing the Experience},
  year = {2004},
  month = apr,
  days = {31-2},
  location = {Brighton, UK},
  series = {EuroITV}
}

@PROCEEDINGS{proceedings:icalt:2004,
  booktitle = {International Conference on Advanced Learning Technologies},
  title = {IEEE International Conference on Advanced Learning Technologies},
  year = {2004},
  month = aug,
  days = {5-7},
  location = {Joensuu, #Finland#},
  series = {International Conference on Advanced Learning Technologies},
  publisher = {IEEE Computer Society},
  papers-accepted = {80},
  papers-submitted = {258}
}

@PROCEEDINGS{proceedings:icse:2004,
  booktitle = {26th Internacional Conference on Software Engineering},
  title = {26th Internacional Conference on Software Engineering},
  year = {2004},
  month = may,
  location = {Edinburgh, #UK#},
  isbn = {0-7695-2163-0},
  day = {23--28},
  issn = {0270-5257}
}

@PROCEEDINGS{proceedings:issta:2004,
  booktitle = {International Symposium on Software Testing and Analysis 2004},
  title = {International Symposium on Software Testing and Analysis 2004},
  year = {2004},
  month = jul,
  days = {11--14},
  location = {Boston, MA, #USA#},
  isbn = {1-58113-820-2},
  address = {New York, NY, } # USA,
  publisher = {ACM}
}

@PROCEEDINGS{proceedings:sigcse:2004,
  booktitle = {35th SIGCSE Technical Symposium on Computer Science Education},
  year = {2004},
  month = mar,
  location = {Norfolk, VA, #USA#},
  isbn = {1-58113-798-2},
  day = {3--7}
}

@PROCEEDINGS{proceedings:std:icmc:2004,
  booktitle = {IX Simpósio de Teses e Dissertações},
  title = {IX Simpósio de Teses e Dissertações},
  year = {2004},
  month = nov,
  days = {19-20},
  location = {São Carlos, SP, Brazil},
  series = {Simpósio de Teses e Dissertações},
  organization = {ICMC-USP}
}

@PROCEEDINGS{proceedings:vlhcc:2004,
  booktitle = {20th IEEE Symposium on Visual Languages and Human Centric Computing},
  title = {20th IEEE Symposium on Visual Languages and Human Centric Computing},
  year = {2004},
  month = sep,
  location = {Rome, #Italy#},
  isbn = {0-7803-8696-5},
  day = {26--29},
  timestamp = {2013-10-11}
}

@PROCEEDINGS{proceedings:webmedia:2004,
  booktitle = {10th Brazilian Symposium on Multimedia and the Web},
  year = {2004},
  month = oct,
  days = {12--15},
  location = {Ribeirão Preto, SP, #Brazil#},
  isbn = {0-7695-2237-8},
  series = {WebMedia},
  publisher = {IEEE Computer Society}
}

@PROCEEDINGS{proceedings:wei:2004,
  booktitle = {Workshop de Educação em Computação -- Congresso da {SBC}},
  title = {Workshop de Educação em Computação -- Congresso da {SBC}},
  year = {2004},
  month = ago,
  days = {2--4},
  location = {Salvador, BA, #Brazil#},
  isbn = {85-88442-93-0}
}

@STANDARD{standard:iso:90003:2004,
  title = {{ISO/IEC} 90003:2004 - Software engineering -- Guidelines for the application of {ISO} 9001:2000 to computer software},
  organization = {{ISO/IEC}},
  year = {2004},
  abstract = {ISO/IEC 90003:2004 provides guidance for organizations in the application of ISO 9001:2000 to the acquisition, supply, development, operation and maintenance of computer software and related support services. ISO/IEC 90003:2004 does not add to or otherwise change the requirements of ISO 9001:2000. The guidelines provided in ISO/IEC 90003:2004 are not intended to be used as assessment criteria in quality management system registration/certification. The application of ISO/IEC 90003:2004 is appropriate to software that is * part of a commercial contract with another organization, * a product available for a market sector, * used to support the processes of an organization, * embedded in a hardware product, or * related to software services. Some organizations may be involved in all the above activities; others may specialize in one area. Whatever the situation, the organization's quality management system should cover all aspects (software related and non-software related) of the business. ISO/IEC 90003:2004 identifies the issues which should be addressed and is independent of the technology, life cycle models, development processes, sequence of activities and organizational structure used by an organization. Additional guidance and frequent references to the ISO/IEC JTC 1/SC 7 software engineering standards are provided to assist in the application of ISO 9001:2000: in particular ISO/IEC 12207, ISO/IEC TR 9126, ISO/IEC 14598, ISO/IEC 15939 and ISO/IEC TR 15504.},
  timestamp = {2008.10.07}
}

@PROCEEDINGS{proceedings:cate:2003,
  booktitle = {Computers and Advanced Technology in Education},
  title = {Computers and Advanced Technology in Education},
  year = {2003},
  month = jun # {--} # jul,
  days = {30 -- 2},
  location = {Rhodes, Greece},
  isbn = {0-88986-365-2},
  e-isbn = {0-88986-361-X},
  series = {Computers and Advanced Technology in Education},
  abstract = {The topics covered in this publication include: studies on teaching and learning technologies and processes for WBE; human resources issues of technology-based education; studies in web-based education; quality issues, testing, and assessment; communication technologies; software systems and tools for WBE: authoring tools; software systems for WBE: developing learning objects; applications of multimedia technologies; software systems for WBE: agent-based technology; web services for WBE; technology-based education: best practices; collaborative learning; studies in open and distance education; software systems and tools for WBE; design and development of online courseware; virtual reality and virtual scientific labs; and studies of teaching and learning technologies and processes.},
  issn = {1482-7905}
}

@PROCEEDINGS{proceedings:eista:2003,
  booktitle = {International Conference on Education and Information Systems: Technologies and Applications},
  year = {2003},
  month = jul # {--} # aug,
  location = {Orlando, FL, #USA#},
  publisher = {International Institute of Informatics and Systemics},
  day = {31--2}
}

@PROCEEDINGS{proceedings:euroitv:2003,
  booktitle = {European Conference on Interactive Television: from Viewers to Actors?},
  title = {European Conference on Interactive Television: from Viewers to Actors?},
  year = {2003},
  month = apr,
  days = {2--4},
  location = {Brighton, #UK#},
  series = {EuroITV},
  address = {Brighton, Reino Unido},
  publisher = {ACM}
}

@PROCEEDINGS{proceedings:icse:2003,
  booktitle = {25th International Conference on Software Engineering},
  title = {25th International Conference on Software Engineering},
  year = {2003},
  month = may,
  days = {3--10},
  location = {Portland, Oregon, #USA#},
  isbn = {0-7695-1877-X},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society}
}

@PROCEEDINGS{proceedings:itcse:2003,
  booktitle = {8th Annual Conference on Innovation and Technology in Computer Science Education},
  year = {2003},
  month = jun # {--} # jul,
  location = {Thessaloniki, #Greece#},
  isbn = {1-58113-672-2},
  address = {New York, NY, USA},
  publisher = {ACM},
  day = {30--2}
}

@PROCEEDINGS{proceedings:metrics:2003,
  booktitle = {9th International Software Metrics Symposium},
  title = {9th International Software Metrics Symposium},
  year = {2003},
  month = sep,
  days = {3--5},
  location = {Sydney, #Australia#},
  isbn = {0-7695-1987-3},
  publisher = {IEEE Computer Society},
  issn = {1530-1435 }
}

@PROCEEDINGS{proceedings:oopsla:2003,
  booktitle = {18th Annual ACM SIGPLAN Conference on Object-Oriented Programming, Systems, Languages, and Applications},
  year = {2003},
  location = {Anaheim, CA, #USA#},
  isbn = {1-58113-751-6},
  address = {New York, NY, } # USA,
  publisher = {ACM}
}

@PROCEEDINGS{proceedings:sigcse:2003,
  booktitle = {34th SIGCSE Technical Symposium on Computer Science Education},
  title = {34th SIGCSE Technical Symposium on Computer Science Education},
  year = {2003},
  month = feb,
  days = {19--23},
  location = {Reno, Navada, #USA#},
  isbn = {1-58113-648-X},
  address = {New York, NY, } # USA,
  publisher = {ACM}
}

@PROCEEDINGS{proceedings:std:icmc:2003,
  booktitle = {VIII Simpósio de Teses e Dissertações},
  title = {VIII Simpósio de Teses e Dissertações},
  year = {2003},
  month = oct,
  days = {29-30},
  location = {São Carlos, SP, Brazil},
  series = {Simpósio de Teses e Dissertações},
  organization = {ICMC-USP}
}

@PROCEEDINGS{proceedings:acsc:2002,
  booktitle = {25th Australasian conference on Computer Science},
  title = {25th Australasian conference on Computer Science},
  year = {2002},
  location = {Melbourne, Victoria, #Australia#},
  isbn = {0-909925-82-8},
  address = {Darlinghurst, Australia, } # Australia,
  publisher = {Australian Computer Society},
  timestamp = {2013-08-01}
}

@PROCEEDINGS{proceedings:crpit:2002,
  booktitle = {14th Conference on Tools Pacific: Objects for internet, mobile and embedded applications},
  year = {2002},
  location = {Sydney, #Australia#},
  isbn = {0-909925-88-7},
  address = {Darlinghurst, } # Australia,
  publisher = {Australian Computer Society},
  timestamp = {2013-08-01}
}

@PROCEEDINGS{proceedings:cseet:2002,
  booktitle = {15th Conference on Software Engineering Education and Training},
  title = {15th Conference on Software Engineering Education and Training},
  year = {2002},
  month = feb,
  days = {25--27},
  location = {Covington, Kentucky, #USA#},
  publisher = {IEEE Computer Society},
  issn = {1093-0175},
  owner = {magsilva},
  timestamp = {2014.09.13}
}

@PROCEEDINGS{proceedings:dsvis:2002,
  booktitle = {DSV-IS 2002: 9th International Workshop on Design, Specification and Verification of Interactive Systems},
  title = {DSV-IS 2002: 9th International Workshop on Design, Specification and Verification of Interactive Systems},
  year = {2002},
  month = jun,
  days = {12-14},
  location = {Rostock, Germany},
  isbn = {3-540-00266-9},
  series = {International Workshop on Design, Specification and Verification of Interactive Systems},
  address = {London, UK},
  publisher = {Springer-Verlag}
}

@PROCEEDINGS{proceedings:itcse:2002,
  booktitle = {7th Annual Conference on Innovation and Technology in Computer Science Education},
  title = {7th Annual Conference on Innovation and Technology in Computer Science Education},
  year = {2002},
  month = jun,
  days = {24--26},
  location = {Aarhus, #Denmark#},
  isbn = {1-58113-499-1},
  address = {New York, NY, } # USA,
  publisher = {ACM}
}

@PROCEEDINGS{proceedings:metrics:2002,
  booktitle = {8th International Symposium on Software Metrics},
  title = {8th International Symposium on Software Metrics},
  year = {2002},
  month = jun,
  days = {4--7},
  location = {Ottawa, #Canada#},
  isbn = {0-7695-1043-4},
  publisher = {IEEE Computer Society}
}

@PROCEEDINGS{proceedings:sbpc:2002,
  booktitle = {54ª Reunião Anual da {SBPC}},
  title = {54ª Reunião Anual da {SBPC}},
  year = {2002},
  month = jul,
  days = {8-12},
  location = {Goiânia, GO, Brazil},
  isbn = {85-86957-05-4},
  series = {Reunião Anual da SBPC},
  organization = {SBPC, UFG},
  day = {7--12},
  promoter = {SBPC}
}

@PROCEEDINGS{proceedings:sigcse:2002,
  booktitle = {33rd SIGCSE Technical Symposium on Computer Science Education},
  title = {33rd SIGCSE Technical Symposium on Computer Science Education},
  year = {2002},
  month = feb # {--} # mar,
  days = {27--3},
  location = {Covington, KY, #USA#},
  isbn = {1-58113-473-8},
  publisher = {ACM},
  papers-accepted = {74},
  papers-submitted = {235}
}

@PROCEEDINGS{proceedings:std:icmc:2002,
  booktitle = {VII Simpósio de Teses e Dissertações},
  title = {VII Simpósio de Teses e Dissertações},
  year = {2002},
  month = oct,
  days = {30-31},
  location = {São Carlos, SP, Brazil},
  series = {Simpósio de Teses e Dissertações},
  organization = {ICMC-USP},
  day = {30--31}
}

@PROCEEDINGS{proceedings:eaic,
  booktitle = {X Encontro Anual de Iniciação Científica},
  title = {X Encontro Anual de Iniciação Científica},
  year = {2001},
  month = sep,
  days = {17-19},
  location = {Ponta Grossa, PR, Brazil},
  series = {Encontro Anual de Iniciação Científica Científica},
  publisher = {UEPG},
  organization = {UEPG},
  day = {17--19},
  e-issn = {1676-0018},
  issn = {1519-7751}
}

@PROCEEDINGS{proceedings:fie:2001,
  booktitle = {31st Annual Frontiers in Education Conference},
  title = {31st Annual Frontiers in Education Conference},
  year = {2001},
  month = oct,
  days = {10--13},
  location = {Reno, Nevada, #USA#},
  isbn = {0-7803-6669-7},
  e-isbn = {0-7803-6671-9},
  issn = {0190-5848}
}

@PROCEEDINGS{proceedings:group:2001,
  booktitle = {2001 International ACM SIGGROUP Conference on Supporting Group Work},
  title = {2001 International ACM SIGGROUP Conference on Supporting Group Work},
  year = {2001},
  month = sep # {--} # oct,
  days = {30--03},
  location = {Boulder, Colorado, #USA#},
  isbn = {1-58113-294-8},
  address = {New York, NY, } # USA,
  publisher = {ACM},
  owner = {magsilva},
  timestamp = {2014.05.21}
}

@PROCEEDINGS{proceedings:iccsa:2001,
  booktitle = {2001 International Conference on Computer Systems and Applications},
  year = {2001},
  month = jun,
  location = {Beirut, #Lebanon#},
  isbn = {0-7695-1165-1},
  publisher = {ACS/IEEE},
  day = {26--29},
  tags = {component-based testing},
  timestamp = {2013-09-14}
}

@PROCEEDINGS{proceedings:icse:2001,
  booktitle = {23rd International Conference on Software Engineering},
  year = {2001},
  location = {Toronto, Ontario, #Canada#},
  isbn = {0-7695-1050-7},
  address = {Washington, DC, } # USA,
  publisher = {IEEE Computer Society}
}

@PROCEEDINGS{proceedings:icsm:2001,
  booktitle = {27th IEEE International Conference on Software Maintenance},
  year = {2001},
  month = nov,
  location = {Florence, #Italy#},
  isbn = {0-7695-1189-9},
  publisher = {IEEE Computer Society},
  day = {6--10},
  timestamp = {2013-09-14}
}

@PROCEEDINGS{proceedings:pacrim:2001,
  booktitle = {IEEE Pacific Rim Conference on Communications, Computers and Signal Processing},
  title = {IEEE Pacific Rim Conference on Communications, Computers and Signal Processing},
  year = {2001},
  month = aug,
  volume = {1},
  lang = {en}
}

@PROCEEDINGS{proceedings:sigcse:2001,
  booktitle = {32nd SIGCSE Technical Symposium on Computer Science Education},
  year = {2001},
  location = {Charlotte, North Carolina, #USA#},
  isbn = {1-58113-329-4},
  address = {New York, NY, } # USA,
  publisher = {ACM}
}

@PROCEEDINGS{proceedings:acse:2000,
  booktitle = {4th Australasian Conference on Computing Education},
  year = {2000},
  location = {Melbourne, #Australia#},
  isbn = {1-58113-271-9},
  address = {New York, NY, } # USA,
  publisher = {ACM}
}

@PROCEEDINGS{proceedings:cscw:2000,
  booktitle = {2000 Conference on Computer Supported Cooperative Work},
  title = {2000 Conference on Computer Supported Cooperative Work},
  year = {2000},
  month = dec,
  location = {Philadelphia, PA, #USA#},
  isbn = {1-58113-222-0},
  address = {Philadelphia, EUA},
  day = {2--6},
  owner = {magsilva},
  timestamp = {2013-10-11}
}

@PROCEEDINGS{proceedings:fmoods:2000,
  booktitle = {4th International Conference on Formal Methods for Open Object-based Distributed Systems},
  year = {2000},
  month = sep,
  days = {6--8},
  location = {Stanford, California, #USA#},
  isbn = {0-7923-7923-3},
  address = {Norwell, MA, USA},
  publisher = {Kluwer Academic},
  acmid = {358119},
  numpages = {20},
  url = {http://dl.acm.org/citation.cfm?id=358112.358119}
}

@PROCEEDINGS{proceedings:icece:2000,
  booktitle = {2nd International Conference on Engineering and Computer Education},
  title = {2nd International Conference on Engineering and Computer Education},
  year = {2000},
  month = aug,
  location = {São Paulo, SP, #Brazil#},
  day = {27--30}
}

@PROCEEDINGS{proceedings:icse:2000,
  booktitle = {22nd International Conference on Software Engineering},
  title = {22nd International Conference on Software Engineering},
  year = {2000},
  month = jun,
  days = {4--11},
  location = {Limerick, #Ireland#},
  isbn = {1-58113-253-0},
  publisher = {ACM}
}

@PROCEEDINGS{proceedings:sgcse:2000,
  booktitle = {31st SIGCSE Technical Symposium on Computer Science Education},
  title = {31st SIGCSE Technical Symposium on Computer Science Education},
  year = {2000},
  month = mar,
  days = {8--12},
  location = {Austin, Texas, #USA#},
  isbn = {1-58113-213-1},
  publisher = {ACM}
}

@PROCEEDINGS{proceedings:sigcse:1999,
  booktitle = {30th SIGCSE Technical Symposium on Computer Science Education},
  year = {1999},
  location = {New Orleans, Louisiana, #USA#},
  isbn = {1-58113-085-6},
  address = {New York, NY, } # USA,
  publisher = {ACM}
}

@PROCEEDINGS{proceedings:sigcse:1998,
  booktitle = {29th SIGCSE Technical Symposium on Computer Science Education},
  title = {29th SIGCSE Technical Symposium on Computer Science Education},
  year = {1998},
  month = feb # {--} # mar,
  days = {26--01},
  location = {Atlanta, Georgia, #USA#},
  isbn = {0-89791-994-7},
  address = {New York, NY, } # USA,
  publisher = {ACM},
  owner = {magsilva},
  timestamp = {2014.08.29}
}

@PROCEEDINGS{proceedings:icct:1997,
  booktitle = {8th International Conference on Concurrency Theory},
  title = {8th International Conference on Concurrency Theory},
  year = {1997},
  isbn = {3-540-63141-0},
  address = {London, } # UK,
  publisher = {Springer-Verlag},
  owner = {magsilva},
  timestamp = {2014.08.31}
}

@PROCEEDINGS{proceedings:iqw:1997,
  booktitle = {10th International Software Quality Week (QW'97)},
  title = {10th International Software Quality Week (QW'97)},
  year = {1997},
  month = may,
  days = {27--30},
  location = {San Francisco, CA, #USA#}
}

@PROCEEDINGS{proceedings:sigcse:1997,
  booktitle = {28th SIGCSE Technical Symposium on Computer Science Education},
  year = {1997},
  location = {San Jose, California, #USA#},
  isbn = {0-89791-889-4},
  address = {New York, NY, } # USA,
  publisher = {ACM}
}

@MISC{standard:iso:9074:1997,
  title = {Information processing systems -- Open systems interconnection -- {Estelle}: A formal description technique based on an extended state transition model},
  year = {1997},
  number = {8807},
  organization = {{ISO}},
  url = {http://www.iso.org/iso/iso_catalogue/catalogue_ics/catalogue_detail_ics.htm?csnumber=24403}
}

@PROCEEDINGS{proceedings:icse:1996,
  booktitle = {18th International Conference on Software Engineering},
  title = {18th International Conference on Software Engineering},
  year = {1996},
  month = mar,
  days = {25--29},
  location = {Berlin, #Germany#},
  isbn = {0-8186-7246-3},
  address = {Washington, DC, } # USA,
  publisher = {IEEE Computer Society},
  owner = {magsilva},
  timestamp = {2014.02.19}
}

@PROCEEDINGS{proceedings:issre:1996,
  booktitle = {VII International Symposium of Software Reliability Engineering (ISSRE'96)},
  title = {VII International Symposium of Software Reliability Engineering (ISSRE'96)},
  year = {1996},
  month = oct # {--} # nov,
  days = {30--2},
  location = {White Plains, NY, #USA#},
  isbn = {0-8186-7707-4},
  address = {White Plains, NY}
}

@PROCEEDINGS{proceedings:oopsla:1996,
  booktitle = {11th ACM SIGPLAN Conference on Object-oriented Programming, Systems, Languages, and Applications},
  title = {11th ACM SIGPLAN Conference on Object-oriented Programming, Systems, Languages, and Applications},
  year = {1996},
  location = {San Jose, California, #USA#},
  isbn = {0-89791-788-X},
  address = {New York, NY, } # USA,
  publisher = {ACM},
  timestamp = {2013-12-05}
}

@PROCEEDINGS{proceedings:icse:1994,
  booktitle = {16th International Conference on Software Engineering},
  title = {16th International Conference on Software Engineering},
  year = {1994},
  month = may,
  days = {16--21},
  location = {Sorrento, #Italy#},
  isbn = {0-8186-5855-X},
  address = {Los Alamitos, CA, } # USA,
  publisher = {IEEE Computer Society},
  issn = {0270-5257},
  owner = {magsilva},
  timestamp = {2014.09.25}
}

@PROCEEDINGS{procedings:hopl:1993,
  booktitle = {2nd Conference on History of Programming Languages},
  year = {1993},
  month = apr,
  days = {20--23},
  location = {Cambridge, Massachusetts, #USA#},
  isbn = {0-89791-570-4},
  publisher = {ACM}
}

@PROCEEDINGS{proceedings:metrics:1993,
  booktitle = {1st International Software Metrics Symposium},
  title = {1st International Software Metrics Symposium},
  year = {1993},
  month = may,
  days = {21--22},
  location = {Baltimore, MD, #USA#},
  isbn = {0-8186-3740-4},
  publisher = {IEEE Computer Society}
}

@PROCEEDINGS{proceedings:cscw:1992,
  booktitle = {International Conference on Computer-Supported Cooperative Work},
  year = {1992},
  location = {Toronto, Ontario, #Canada#},
  isbn = {0-89791-542-9},
  timestamp = {2013-08-02}
}

@PROCEEDINGS{proceedings:sbes:1992,
  booktitle = {6th Brazilian Symposium on Software Engineering},
  title = {6th Brazilian Symposium on Software Engineering},
  year = {1992},
  month = nov,
  days = {4--6},
  location = {Gramado, RS, Brazil},
  series = {Brazilian Symposium on Software Engineering},
  organization = {IF-UFRGS},
  papers-accepted = {22},
  papers-submitted = {57},
  promoter = {SBC, UFRGS},
  title-en = {6th Brazilian Symposium on Software Engineering},
  title-pt = {VI Simpósio Brasileiro de Engenharia de Software}
}

@PROCEEDINGS{proceedings:sbes-tools:1992,
  booktitle = {6th Brazilian Symposium on Software Engineering -- Tools Session},
  title = {6th Brazilian Symposium on Software Engineering -- Tools Session},
  year = {1992},
  month = nov,
  days = {4--6},
  location = {Gramado, RS, Brazil},
  series = {Brazilian Symposium on Software Engineering -- Tools Session},
  organization = {UFRGS},
  papers-accepted = {23},
  promoter = {SBC, UFRGS},
  title-en = {6th Brazilian Symposium on Software Engineering -- 1st Tools Session},
  title-pt = {VI Simpósio Brasileiro de Engenharia de Software - Sessão de Ferramentas}
}

@PROCEEDINGS{proceedings:stoc:1992,
  booktitle = {24th Annual ACM Symposium on Theory of Computing},
  title = {24th Annual ACM Symposium on Theory of Computing},
  year = {1992},
  location = {Victoria, British Columbia, #Canada#},
  isbn = {0-89791-511-9},
  address = {New York, NY, } # USA,
  publisher = {ACM}
}

@PROCEEDINGS{proceedings:icse:1991,
  booktitle = {13th International Conference on Software Engineering},
  year = {1991},
  location = {Austin, Texas, #USA#},
  publisher = {IEEE Computer Society},
  timestamp = {2013-08-01}
}

@PROCEEDINGS{proceedings:icse:1990,
  booktitle = {12th International Conference on Software Engineering},
  year = {1990},
  month = mar,
  location = {Nice, #France#},
  isbn = {0-89791-349-3},
  address = {Los Alamitos, CA, USA},
  publisher = {IEEE Computer Society},
  day = {26--30}
}

@MISC{standard:iso:7185:1990,
  title = {Information technology -- Programming languages -- {Pascal}},
  year = {1990},
  number = {7185},
  organization = {{ISO}},
  url = {http://www.iso.org/iso/catalogue_detail.htm?csnumber=13802}
}

@PROCEEDINGS{proceedings:oopsla:1989,
  booktitle = {Conference on Object-Oriented Programming Systems, Languages and Applications 1989},
  year = {1989},
  month = oct,
  location = {New Orleans, Louisiana, #USA#},
  isbn = {0-89791-333-7},
  publisher = {ACM},
  day = {1--6}
}

@PROCEEDINGS{proceedings:sigcse:1989,
  booktitle = {20th SIGCSE Technical Symposium on Computer Science Education},
  year = {1989},
  location = {Louisville, Kentucky, #USA#},
  isbn = {0-89791-298-5},
  address = {New York, NY, } # USA,
  publisher = {ACM}
}

@MISC{standard:iso:8807:1989,
  title = {Information processing systems -- Open systems interconnection -- {LOTOS} -- A formal description technique based on the temporal ordering of observational behaviour},
  year = {1989},
  number = {8807},
  organization = {{ISO}}
}

@MISC{standard:iso:9074:1989,
  title = {Information processing systems -- Open systems interconnection -- {Estelle}: A formal description technique based on an extended state transition model},
  year = {1989},
  number = {8807},
  organization = {{ISO}},
  url = {http://www.iso.org/iso/iso_catalogue/catalogue_ics/catalogue_detail_ics.htm?csnumber=16659}
}

@PROCEEDINGS{proceedings:icse:1987,
  booktitle = {9th International Conference on Software Engineering},
  title = {9th International Conference on Software Engineering},
  year = {1987},
  month = mar # {--} # apr,
  days = {30--2},
  location = {Monterey, California, #USA#},
  isbn = {0-89791-216-0},
  address = {Los Alamitos, CA, } # USA,
  publisher = {IEEE Computer Society},
  owner = {magsilva},
  timestamp = {2014.09.11}
}

@MISC{standard:ieee:1008:1987,
  title = {{IEEE} 1008 - {IEEE} Standard for Software Unit Testing},
  year = {1987},
  organization = {IEEE},
  owner = {magsilva},
  timestamp = {2009.04.30}
}

@PROCEEDINGS{proceedings:chi:1986,
  booktitle = {Conference on Human Factors in Computing Systems 1986},
  title = {Conference on Human Factors in Computing Systems 1986},
  year = {1986},
  month = apr,
  days = {12--17},
  location = {Boston, MA, #USA#},
  isbn = {0-89791-180-6},
  address = {New York, NY, } # USA,
  publisher = {ACM}
}

@PROCEEDINGS{proceedings:usenix:1986,
  booktitle = {{USENIX} Summer Conference},
  title = {{USENIX} Summer Conference},
  year = {1986},
  month = jun,
  location = {Altanta, GA, #USA#},
  publisher = {USENIX Association}
}

@PROCEEDINGS{proceedings:icse:1985,
  booktitle = {8th International Conference on Software Engineering},
  year = {1985},
  month = aug,
  days = {28--30},
  location = {Orlando, Florida, #USA#},
  isbn = {0-8186-0528-6},
  publisher = {IEEE Computer Society},
  issn = {0098-5589}
}

@STANDARD{standard:iso:5807:1995,
  title = {{ISO 5807:1985} -- Information processing -- Documentation symbols and conventions for data, program and system flowcharts, program network charts and system resources charts},
  organization = {{ISO}},
  year = {1985},
  url = {http://www.iso.org/iso/catalogue_detail.htm?csnumber=11955},
  abstract = {Defines symbols to be used in information processing documentation and gives guidance on conventions tor their use in data flowcharts, program flowcharts, system flowcharts, program network charts, system resources charts. Applicable in conjunction with ISO 2382/1.},
  pages = {25}
}

@PROCEEDINGS{proceedings:icse:1979,
  booktitle = {4th International Conference on Software Engineering},
  year = {1979},
  month = sep,
  location = {Munich, #Germany#},
  organization = {IEEE Computer Society},
  day = {17--19},
  owner = {magsilva},
  timestamp = {2013-08-02}
}

@PROCEEDINGS{proceedings:ldrs:1977,
  booktitle = {Conference on Language Design for Reliable Software},
  year = {1977},
  month = mar,
  days = {28--30},
  location = {Raleigh, NC, #USA#},
  publisher = {ACM},
  acmid = {808322}
}

@PROCEEDINGS{proceedings:ssew:1997,
  booktitle = {2nd Summer Software Engineering Workshop},
  year = {1977},
  month = sep,
  location = {Greenbeld, Maryland, #USA#},
  day = {19},
  timestamp = {2013-09-18}
}

@PROCEEDINGS{proceedings:icse:1976,
  booktitle = {2nd International Conference on Software Engineering},
  year = {1976},
  month = oct,
  days = {13--15},
  location = {San Francisco, California, #USA#},
  publisher = {IEEE Computer Society}
}

@PROCEEDINGS{proceedings:sosp:1973,
  booktitle = {4th ACM symposium on Operating system principles},
  year = {1973},
  month = oct,
  days = {15--17},
  location = {Yorktown Heights, NY, #USA#},
  publisher = {ACM}
}

@PROCEEDINGS{proceedings:ifip:1971,
  booktitle = {Information Processing Congress (IFIP)},
  year = {1971},
  month = aug,
  days = {23--28},
  location = {Ljubljana, #Yugoslavia#},
  isbn = {0-7204-2063-6},
  publisher = {North-Holland}
}

@PROCEEDINGS{proceedings:stoc:1971,
  booktitle = {3rd Annual ACM Symposium on Theory of Computing},
  title = {3rd Annual ACM Symposium on Theory of Computing},
  year = {1971},
  location = {Shaker Heights, Ohio, #USA#},
  address = {New York, NY, } # USA,
  publisher = {ACM}
}

@PROCEEDINGS{proceedings:wescon:1970,
  booktitle = {Western Electronic Show an Convention},
  title = {Western Electronic Show an Convention},
  year = {1970},
  month = aug,
  days = {25--28},
  location = {Los Angeles, CA, #USA#},
  publisher = {IEEE},
  owner = {magsilva},
  timestamp = {2014.10.22}
}

@PROCEEDINGS{proceedings:ifip:1968,
  booktitle = {IFIP Congress 1968},
  title = {IFIP Congress 1968},
  year = {1968},
  month = aug,
  days = {5--10},
  location = {Edinburgh, #UK#},
  publisher = {IEEE CS},
  owner = {magsilva},
  timestamp = {2014.10.23}
}

@PROCEEDINGS{proceedings:swat:1966,
  booktitle = {7th Annual Symposium on Switching and Automata Theory},
  title = {7th Annual Symposium on Switching and Automata Theory},
  year = {1966},
  month = oct,
  days = {26--28},
  location = {Berkeley, CA, #USA#},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  issn = {0272-4847},
  owner = {magsilva},
  timestamp = {2014.07.15}
}

@PROCEEDINGS{proceedings:afips:1963,
  booktitle = {Fall Joint Computer Conference},
  title = {Fall Joint Computer Conference},
  year = {1963},
  month = nov,
  days = {12--14},
  location = {Las Vegas, Nevada, #USA#},
  address = {New York, NY, USA},
  publisher = {ACM},
  owner = {magsilva},
  timestamp = {2014.07.15}
}

@PROCEEDINGS{proceedings:swct:1963,
  booktitle = {4th Annual Symposium on Switching Circuit Theory and Logical Design},
  title = {4th Annual Symposium on Switching Circuit Theory and Logical Design},
  year = {1963},
  month = oct,
  days = {28--30},
  location = {Chicago, IL, #USA#},
  publisher = {IEEE},
  owner = {magsilva},
  timestamp = {2014.07.15}
}

@comment{jabref-entrytype: Journal: req[journal;publisher;address;issn;e-issn] opt[]}

@comment{jabref-entrytype: Monograph: req[author;title;month;year;institution;address;pages] opt[]}

@comment{jabref-entrytype: Research-project: req[title;author;institution;number;funding;month;year;duration] opt[]}

